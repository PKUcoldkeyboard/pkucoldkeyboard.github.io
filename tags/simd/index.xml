<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>SIMD on Cuterwrite's Blog</title><link>https://cuterwrite.top/tags/simd/</link><description>Recent content in SIMD on Cuterwrite's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>cuterwrite</copyright><lastBuildDate>Tue, 13 Aug 2024 22:44:00 +0000</lastBuildDate><atom:link href="https://cuterwrite.top/tags/simd/index.xml" rel="self" type="application/rss+xml"/><item><title>Arm 矩阵加速：可伸缩矩阵扩展 SME</title><link>https://cuterwrite.top/p/arm-sme-for-performance/</link><pubDate>Tue, 13 Aug 2024 22:44:00 +0000</pubDate><guid>https://cuterwrite.top/p/arm-sme-for-performance/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-14_117622407_p0_master1200.webp" alt="Featured image of post Arm 矩阵加速：可伸缩矩阵扩展 SME" />&lt;h1 id="arm-矩阵加速可伸缩矩阵扩展-sme">Arm 矩阵加速：可伸缩矩阵扩展 SME&lt;/h1>
&lt;h2 id="1-sme-简介">1. SME 简介&lt;/h2>
&lt;p>可伸缩矩阵扩展 SME (Scalable Matrix Extension) SME 是在可伸缩向量扩展（Scalable Vector Extensions， SVE 和 SVE2）的基础上建立的，并增加了有效处理矩阵的能力，主要功能包括：&lt;/p>
&lt;ul>
&lt;li>计算 SVE 向量的外积（Outer product）&lt;/li>
&lt;li>矩阵块（tile） 存储&lt;/li>
&lt;li>tile 向量的加载、存储、插入和提取（包括动态转置）&lt;/li>
&lt;li>Streaming SVE 模式&lt;/li>
&lt;/ul>
&lt;p>下表总结了 SME、SVE 和 SVE2 的主要功能：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>SME&lt;/th>
&lt;th>SVE&lt;/th>
&lt;th>SVE2&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Streaming SVE 模式&lt;/td>
&lt;td>NEON DSP++&lt;/td>
&lt;td>可伸缩向量&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>动态矩阵转置&lt;/td>
&lt;td>多精度算术&lt;/td>
&lt;td>per-lane predication&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>向量外积&lt;/td>
&lt;td>匹配检测和直方图&lt;/td>
&lt;td>Gather-load 与 Scatter-store&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>加载、存储、插入和提取矩阵向量&lt;/td>
&lt;td>非时间性 scatter/gather&lt;/td>
&lt;td>预测向量化&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>按位置换（bitwise permute）&lt;/td>
&lt;td>ML 扩展（FP16 + DOT）&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>AE、SHA3、SM4、Crypto&lt;/td>
&lt;td>V8.6 BF16, FP 与 Int8 支持&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>SME 定义了以下新功能：&lt;/p>
&lt;ul>
&lt;li>新的架构状态，可以用来存储二维矩阵 tile&lt;/li>
&lt;li>Streaming SVE 模式，支持执行向量长度与 tile 长度匹配的 SVE2 指令。&lt;/li>
&lt;li>将两个向量的外积累加（或累减）到一个矩阵 tile 中的新指令。&lt;/li>
&lt;li>新的加载、存储和移动指令：可以将向量写入到矩阵 tile 的一行或一列，也可以将矩阵 tile 的一行或一列读取到向量。&lt;/li>
&lt;/ul>
&lt;p>与 SVE2 类似，SME 也是一种支持可伸缩向量长度的扩展，可实现向量长度无关性 (VLA)、per-lane predication、predication 驱动的循环控制和管理功能。&lt;/p>
&lt;h2 id="2-streaming-sve-模式">2. Streaming SVE 模式&lt;/h2>
&lt;p>SME 引入了 Streaming SVE 模式，该模式实现了 SVE2 指令集的一个子集，并增加了新的 SME 专用指令。&lt;/p>
&lt;p>Streaming SVE 模式支持对大型数据集进行高吞吐量地流式数据处理，流式数据通常具有简单的循环控制流和有限的条件性。&lt;/p>
&lt;p>在 Non-streaming SVE 模式下，支持完整的 SVE2 指令集，通常处理复杂的数据结构和复杂的判断。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-14_3443.webp"
alt="Streaming SVE 模式与 Non-streaming SVE 模式" width="80%" loading="lazy">&lt;figcaption>
&lt;h4>Streaming SVE 模式与 Non-streaming SVE 模式&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>大多数 SME 指令仅在 Streaming SVE 模式下可用。Streaming SVE 模式下的流向量长度（SVL）可能与非流向量长度（NSVL）不同。&lt;/p>
&lt;p>预期是：SVL 要比 NSVL 更长或是相同，也就是 SVL &amp;gt;= NSVL。例如，NSVL 的长度可以为 128-bit , 而 SVL 的长度可以为 512-bit 。&lt;/p>
&lt;p>SME 的 SVL 可以是 128-bit , 256-bit , 512-bit, 1024-bit 或是 2048-bit 。SVL 需要是 2 的次幂，而 NSVL 需要是 128 的整数倍。&lt;/p>
&lt;p>与 SVE2 类似，软件可以控制 &lt;code>SMCR_ELx.LEN&lt;/code> 寄存器位来设置 EL1, EL2, EL3 想用的有效 SVL 长度（可以设置为比硬件支持的 SVL 更短）。&lt;/p>
&lt;p>有关 Streaming SVE 模式的更多信息，请参阅《Arm 架构参考手册》第 B1.4.6 节（A-profile 架构）。&lt;/p>
&lt;h2 id="3-切换-non-streaming-和-streaming-sve-模式">3. 切换 Non-streaming 和 Streaming SVE 模式&lt;/h2>
&lt;p>如果 CPU 硬件实现既支持 Streaming SVE 模式的 SME ，又支持 Non-streaming SVE 模式的 SVE2 ，应用程序可以根据自己的需求动态切换这两个操作模式。&lt;/p>
&lt;p>为 SME 提供一个独立的操作模式，使 CPU 硬件实现可以为同一应用提供不同的向量长度。比如 CPU 硬件实现可以选择支持一个更长的 Streaming SVE 模式向量长度，并针对适用于高吞吐量的流操作对硬件进行优化。&lt;/p>
&lt;p>应用程序很容易在 Streaming SVE 模式和 Non-streaming SVE 模式之间动态切换。SME 引入的 &lt;code>PSTATE.{SM, ZA}&lt;/code> 位可以可启用和禁用 Streaming SVE 模式和 SME ZA 存储：&lt;/p>
&lt;ul>
&lt;li>SM: 启用与禁用 Streaming SVE 模式&lt;/li>
&lt;li>ZA：启用和禁用 ZA 存储访问&lt;/li>
&lt;/ul>
&lt;p>可以通过 &lt;code>MSR/MRS&lt;/code> 指令操作 Streaming Vector Control Register (SVCR) 来设置和读取 &lt;code>PSTATE.{SM, ZA}&lt;/code> 位，具体操作如下：&lt;/p>
&lt;ul>
&lt;li>&lt;code>MSR SVCRSM, #&amp;lt;imm&amp;gt; MSR SVCRSM，#&lt;/code>&lt;/li>
&lt;li>&lt;code>MSR SVCRZA, #&amp;lt;imm&amp;gt;&lt;/code>&lt;/li>
&lt;li>&lt;code>MSR SVCRSMZA, #&amp;lt;imm&amp;gt;&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>SMSTART 指令是设置 &lt;code>PSTATE.SM&lt;/code> 和 &lt;code>PSTATE.ZA&lt;/code> 的 &lt;code>MSR&lt;/code> 指令的别名&lt;/p>
&lt;ul>
&lt;li>&lt;code>SMSTART&lt;/code>：同时启用 Streaming SVE 模式和 ZA 存储访问&lt;/li>
&lt;li>&lt;code>SMSTART SM&lt;/code>：启用 Streaming SVE 模式&lt;/li>
&lt;li>&lt;code>SMSTART ZA&lt;/code>：启用 ZA 存储访问&lt;/li>
&lt;/ul>
&lt;p>SMSTOP 指令则是清除 &lt;code>PSTATE.SM&lt;/code> 和 &lt;code>PSTATE.ZA&lt;/code> 的 &lt;code>MSR&lt;/code> 指令的别名。&lt;/p>
&lt;ul>
&lt;li>&lt;code>SMSTOP&lt;/code>：同时禁用 Streaming SVE 模式和 ZA 存储访问&lt;/li>
&lt;li>&lt;code>SMSTOP SM&lt;/code>：禁用 Streaming SVE 模式&lt;/li>
&lt;li>&lt;code>SMSTOP ZA&lt;/code>：禁用 ZA 存储访问&lt;/li>
&lt;/ul>
&lt;p>下图展示了应用程序是如何在 Streaming SVE 模式和 Non-streaming SVE 模式之间切换的：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-15_Scalable_Matrix_p1.webp"
alt="应用程序切换 Streaming SVE 模式和 Non-streaming SVE 模式" width="50%" loading="lazy">&lt;figcaption>
&lt;h4>应用程序切换 Streaming SVE 模式和 Non-streaming SVE 模式&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>有关使用 SMSTART 和 SMSTOP 在 Streaming SVE 模式和 Non-Streaming SVE 模式之间切换的更多信息，请参阅《Arm 架构参考手册》中有关 A-profile 架构的 C6.2.327 和 C6.2.328 节。&lt;/p>
&lt;h2 id="4-sme-架构状态">4. SME 架构状态&lt;/h2>
&lt;p>与 SVE2 类似，在 Streaming SVE 模式，它有 &lt;code>Z0-Z31&lt;/code> 向量寄存器，和 &lt;code>P0-P15&lt;/code> Predicate 寄存器。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-15_4130_ARM2799_3_Scalable_Matrix_p1.webp"
alt="Streaming mode registers" width="70%" loading="lazy">
&lt;/figure>
&lt;p>SVE 向量寄存器的最低编号位 &lt;code>Zn&lt;/code> 也保存着固定长度的 &lt;code>Vn、Qn、Dn、Sn、Hn&lt;/code> 和 &lt;code>Bn&lt;/code> 寄存器。&lt;/p>
&lt;p>进入 Streaming SVE 模式（ &lt;code>PSTATE.SM&lt;/code> 由 0 变为 1）或退出 Streaming SVE 模式（ &lt;code>PSTATE.SM&lt;/code> 由 1 变为 0）时，所有这些寄存器都将置零。&lt;/p>
&lt;p>大多数 Non-streaming SVE2 指令可用于 Streaming SVE 模式，但&lt;strong>可能使用不同的向量长度&lt;/strong>（流模式使用 VSL 长度，非流模式使用 NVSL 长度）。可以使用 &lt;code>RDSVL&lt;/code> 指令读取当前的有效向量长度 VL。&lt;/p>
&lt;pre>&lt;code class="language-armasm">//Read multiple of Streaming SVE vector register size to Xd
RDSVL &amp;lt;Xd&amp;gt;, #&amp;lt;imm&amp;gt;
&lt;/code>&lt;/pre>
&lt;div class="notice notice-info" >
&lt;div class="notice-title">&lt;svg t="1705940100069" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6252" width="200" height="200">&lt;path d="M512 64C264.6 64 64 264.6 64 512s200.6 448 448 448 448-200.6 448-448S759.4 64 512 64z m32 664c0 4.4-3.6 8-8 8h-48c-4.4 0-8-3.6-8-8V456c0-4.4 3.6-8 8-8h48c4.4 0 8 3.6 8 8v272z m-32-344c-26.5 0-48-21.5-48-48s21.5-48 48-48 48 21.5 48 48-21.5 48-48 48z" p-id="6253" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>因为 SME 支持 Vector Length Agnostic (VLA) ，在 Streaming SVE 模式下，软件很少需要明确读 SVL 向量长度。在 Non-streaming SVE 模式下，通常使用 RDSVL 指令来确定 SVL 的值。&lt;/p>&lt;/div>
&lt;h2 id="5-za-array">5. ZA array&lt;/h2>
&lt;p>SME 新引入的 ZA (Z Array, ZA Storage) 是一个二维（2D）正方形数组，大小是 SVL x SVL。之所以叫 Z Array，也是因为它行与列的长度与 Streaming SVE 模式下的 Zn 寄存器一致。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-15_4314_ARM2799_4_Scalable_Matrix_p1.webp"
alt="ZA array" width="50%" loading="lazy">&lt;figcaption>
&lt;h4>ZA array&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>例如：如果 Streaming SVE 模式下的向量长度为 256-bit，即 Zn 寄存器的长度为 256-bit，那么 ZA 的大小为 256-bit x 256-bit。&lt;/p>
&lt;p>ZA array 可以通过以下方式访问：&lt;/p>
&lt;ul>
&lt;li>ZA array vector 访问&lt;/li>
&lt;li>ZA tiles&lt;/li>
&lt;li>ZA tile slices&lt;/li>
&lt;/ul>
&lt;h3 id="51-za-array-vector-访问">5.1 ZA array vector 访问&lt;/h3>
&lt;p>ZA array 的一行可以当成一个 SVL 长度的向量来访问，这个向量可以放数据类型长度为 8-bit, 16-bit, 32-bit, 64-bit 或 128-bit 的元素，比如 32-bit 的 fp32 浮点数。&lt;/p>
&lt;pre>&lt;code class="language-c">ZA.B[N], ZA.H[N], ZA.S[N], ZA.D[N], ZA.Q[N]
&lt;/code>&lt;/pre>
&lt;p>其中 &lt;code>B，H，S，D，Q&lt;/code> 分别表示 8-bit , 16-bit , 32-bit , 64-bit , 128-bit。&lt;/p>
&lt;p>ZA array vector 的数量与 SVL 中的字节数相同，例如，如果 SLV 是 256-bit ，那么 ZA array vector 的数量是 32 个，N 的范围是 0 到 31。&lt;/p>
&lt;p>为了支持上下文切换，SME 引入了新的 &lt;code>LDR&lt;/code> 和 &lt;code>STR&lt;/code> 指令，用于从内存加载和存储一个 ZA array vector。&lt;/p>
&lt;pre>&lt;code class="language-armasm">LDR ZA[&amp;lt;Wv&amp;gt;, &amp;lt;imm&amp;gt;], [&amp;lt;Xn|SP&amp;gt;{, #&amp;lt;imm&amp;gt;, MUL VL}]
STR ZA[&amp;lt;Wv&amp;gt;, &amp;lt;imm&amp;gt;], [&amp;lt;Xn|SP&amp;gt;{, #&amp;lt;imm&amp;gt;, MUL VL}]
&lt;/code>&lt;/pre>
&lt;h3 id="52-za-tiles">5.2 ZA tiles&lt;/h3>
&lt;p>ZA tile 是在 ZA 中的正方形的二维子矩阵。ZA tile 的宽度始终是 SVL，与 ZA array 的宽度相同。&lt;/p>
&lt;p>ZA 可以分成多少个可用的 ZA tile 是由元素的数据类型大小决定的：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>元素数据类型大小&lt;/th>
&lt;th>tile 数量&lt;/th>
&lt;th>tile 名称&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>8-bit&lt;/td>
&lt;td>1&lt;/td>
&lt;td>ZA0.B&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>16-bit&lt;/td>
&lt;td>2&lt;/td>
&lt;td>ZA0.H-ZA1.H&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>32-bit&lt;/td>
&lt;td>4&lt;/td>
&lt;td>ZA0.S-ZA3.S&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>64-bit&lt;/td>
&lt;td>8&lt;/td>
&lt;td>ZA0.D-ZA7.D&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>128-bit&lt;/td>
&lt;td>16&lt;/td>
&lt;td>ZA0.Q-ZA15.Q&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ul>
&lt;li>当元素数据类型为 8-bit 时，ZA 只能作为一个 ZA tile (ZA0.B) 被访问。&lt;/li>
&lt;li>当元素数据类型为 16-bit 时，ZA 可以作为 2 个 ZA tile (ZA0.H 和 ZA1.H) 被访问。&lt;/li>
&lt;li>当元素数据类型为 32-bit 时，ZA 可以作为 4 个 ZA tile (ZA0.S 到 ZA3.S) 被访问。&lt;/li>
&lt;li>当元素数据类型为 64-bit 时，ZA 可以作为 8 个 ZA tile (ZA0.D 到 ZA7.D) 被访问。&lt;/li>
&lt;li>当元素数据类型为 128-bit 时，ZA 可以作为 16 个 ZA tile (ZA0.Q 到 ZA15.Q) 被访问。&lt;/li>
&lt;/ul>
&lt;p>例如，如果 SVL 为 256-bit，元素数据类型大小为 8-bit，则 ZA 可以视为 ZA0.B，也可视为 32 个向量（32 行，每行大小为 32 x 8-bit，即每行 32 个元素）。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-15_ZA0B.webp"
alt="ZA0.B" width="50%" loading="lazy">
&lt;/figure>
&lt;p>如果 SVL 为 256-bit，元素数据类型大小为 16-bit，则 ZA 可以视为 2 个 ZA tile (ZA0.H 和 ZA1.H)，每个 tile 视为 16 个向量（16 行，每行大小为 16 x 16-bit，即每行 16 个元素）。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-15_ZA0H_ZA1H.webp"
alt="ZA0.H 和 ZA1.H" width="40%" loading="lazy">
&lt;/figure>
&lt;p>这样做的好处是充分利用了 ZA storage，在实际应用中，比如说当 SVL 为 256-bit，元素数据类型大小为 32-bit，ZA 的大小为 256-bit x 256-bit 时，&lt;strong>要对两个 Z 寄存器里的向量做外积运算&lt;/strong>，计算得到的外积结果是 8 x 8 的二维浮点数数组，这个外积只需要 ZA 的 1/4 的存储空间。将 ZA 分成 4 个 ZA tile，这样就可以充分利用 ZA storage。&lt;/p>
&lt;h3 id="53-za-tile-slices">5.3 ZA tile slices&lt;/h3>
&lt;p>一个 ZA tile 可以作为一个整体来访问，也可以以一个个 ZA tile slice 的方式访问。&lt;/p>
&lt;p>当作为一个整体访问时，指令可以使用 tile 的名字访问：&lt;/p>
&lt;pre>&lt;code class="language-text">ZA0.B, ZA0.H-ZA1.H, ZA0.S-ZA3.S, ZA0.D-ZA7.D or ZA0.Q-ZA15.Q
&lt;/code>&lt;/pre>
&lt;p>一个 ZA tile slice 是由其 ZA tile 中&lt;strong>水平方向或是垂直方向的连续元素组成的一维数组&lt;/strong>，即在 ZA tile 中的一行或是一列。&lt;/p>
&lt;p>对一个 ZA tile 的向量访问即是读写一个 ZA tile slice ：&lt;/p>
&lt;ul>
&lt;li>水平或垂直方向的 ZA tile slice 访问，由 ZA tile 名字后的 &lt;code>H&lt;/code> 或 &lt;code>V&lt;/code> 后缀来表示。&lt;/li>
&lt;li>具体的 ZA tile slice 由一个索引来表示，由 ZA tile 名字后的切片索引 &lt;code>[N]&lt;/code> 来表示。&lt;/li>
&lt;/ul>
&lt;p>例如，如果 SVL 为 128 位，元素数据类型大小为 8-bit，那么其水平的和垂直的 ZA tile slice 可由下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-15_6724_ARM2799_7_Scalable_Matrix_p1.webp"
alt="ZA tile slices" width="50%" loading="lazy">
&lt;/figure>
&lt;p>再例如，如果 SVL 为 128 位，元素数据类型大小为 16-bit，那么其水平的和垂直的 ZA tile slice 可由下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-15_6888_ARM2799_8_Scalable_Matrix_p1.webp"
alt="ZA tile slices" width="50%" loading="lazy">
&lt;/figure>
&lt;p>为了提高硬件访问 ZA tile 和 ZA tile slices 的效率，ZA tile 的 ZA tile slices 是交错排列的。&lt;/p>
&lt;p>下图显示了这种交错排列的示例。在此示例中，SVL 为 256 位，元素数据类型大小为 16 位。这意味着，ZA 可被视为两个 ZA tile（ZA0H 和 ZA1H），并具有交错的水平 tile slices ：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-15_4885_SME_interleave.webp"
alt="ZA tile slices" width="auto" loading="lazy">
&lt;/figure>
&lt;p>下图展示了不同的元素数据类型大小的水平和垂直方向 ZA tile slice 的混合视图:&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-15_7673_SME_V_H.webp"
alt="ZA tile slices" width="auto" loading="lazy">
&lt;/figure>
&lt;p>左侧各栏显示了 ZA 存储器每一行的不同处理方式。&lt;/p>
&lt;p>设 SIZE 为向量元素的大小，其中 SIZE 为 1、2、4、8、16，分别代表数据类型 B、H、S、D 或 Q。&lt;/p>
&lt;p>设 NUM_OF_ELEMENTS 为向量中的元素个数，即 bytes_of(SVL)/SIZE。&lt;/p>
&lt;p>水平 tile slice， &lt;code>ZAnH.&amp;lt;B|H|S|D|Q&amp;gt;[m]&lt;/code> 访问一个向量，该向量包含 ZA storage 中的整行（m x SIZE + n）。该向量包含数据类型为 B、H、S、D 或 Q 的元素。&lt;/p>
&lt;p>垂直 tile slice，&lt;code>ZAnV.&amp;lt;B|H|S|D|Q&amp;gt;[m] &lt;/code> 访问一个向量，该向量包含 ZA storage 中的整列（m x SIZE）。该向量包含数据类型为 B、H、S、D 或 Q 的元素。&lt;/p>
&lt;p>&lt;code>ZAnV.[m] &lt;/code> 访问一个包含列（m x SIZE）和行元素（i x SIZE + n）的向量，其中 i 为 0 ~ NUM_OF_ELEMENTS-1。该向量包含数据类型为 B、H、S、D 或 Q 的元素。&lt;/p>
&lt;p>使用混合元素数据类型大小以及水平和垂直 tile slice 的应用应小心处理重叠。&lt;/p>
&lt;p>有关 ZA Array、ZA array vectors、tile 和 tile slices 的更多信息，请参阅《Arm 架构参考手册》中有关 A-profile 架构的 B1.4.8 至 B1.4.12 节。&lt;/p>
&lt;h2 id="6-steaming-sve-模式下支持的指令">6. Steaming SVE 模式下支持的指令&lt;/h2>
&lt;p>某些指令在 Streaming SVE 模式下有限制：&lt;/p>
&lt;ul>
&lt;li>一些 SVE/SVE2 指令变为非法执行
&lt;ul>
&lt;li>Gathed-load 和 Scatter-store 指令&lt;/li>
&lt;li>使用 First Fault 寄存器的 SVE2 指令&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>大多的 NEON 指令变为 UNDEFINED&lt;/li>
&lt;/ul>
&lt;p>有关受 Streaming SVE 模式影响的指令的更多信息，请参阅文档 《Arm 架构参考手册》。&lt;/p>
&lt;p>SME 增加了几条新指令，其中包括：&lt;/p>
&lt;ul>
&lt;li>矩阵外积和累加或减法指令，包括 FMOPA、UMOPA 和 BFMOPA。
&lt;ul>
&lt;li>SVE2 向量寄存器（Z0-Z31）作为外积运算的行和列输入。&lt;/li>
&lt;li>ZA storage 保存二维矩阵 tile 的输出结果。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>将 SVE2 Z 向量与 ZA 的行或列做加法运算的指令&lt;/li>
&lt;li>对 ZA tiles 的清零操作指令&lt;/li>
&lt;li>增加了一些在 Streaming 和 Non-streaming 模式下都能使用的指令&lt;/li>
&lt;/ul>
&lt;h2 id="7-sme-指令">7. SME 指令&lt;/h2>
&lt;p>操作 ZA storage 的 SME 指令主要包括：&lt;/p>
&lt;ul>
&lt;li>计算两个向量的外积，并累加或累减，然后将结果放入一个 ZA tile 的指令&lt;/li>
&lt;li>将 SVE 向量（Z 寄存器）存入或取出 ZA tile 的行或列的指令&lt;/li>
&lt;li>水平或垂直方向上，一个 SVE 向量与 ZA tile 的加法指令&lt;/li>
&lt;li>给一个标量寄存器加上 Streaming SVE 模式下向量长度的倍数的指令&lt;/li>
&lt;/ul>
&lt;h3 id="71-外积并累加或累减指令">7.1 外积并累加或累减指令&lt;/h3>
&lt;p>为了帮助理解外积并累加或累减指令，让我们看看如何使用外积操作来做矩阵乘法。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_2313_Picture1_png-1280x960.webp"
alt="Outer product" width="auto" loading="lazy">
&lt;/figure>
&lt;p>计算两个向量 a 和 b 的外积会得到一个包含外积的结果矩阵 C：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_1665_Picture2_png-1280x960.webp"
alt="Outer product" width="auto" loading="lazy">
&lt;/figure>
&lt;p>现在考虑两个矩阵 a 和 b 的矩阵乘运算：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_8117_Picture3_png-1280x960.webp"
alt="Matrix multiplication" width="auto" loading="lazy">
&lt;/figure>
&lt;p>这个矩阵乘可以通过计算两次外积操作和两个结果矩阵的累加来实现（就是常用的手写计算的方法），如下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_3731_Picture4_png-1280x960.webp"
alt="Matrix multiplication with outer product" width="auto" loading="lazy">
&lt;/figure>
&lt;p>SME 为以下数据类型引入了高效的外积并累加或减法指令：&lt;/p>
&lt;ul>
&lt;li>8-bit, 16-bit 整数&lt;/li>
&lt;li>FP16, BF16, FP32 和 FP64 浮点数&lt;/li>
&lt;/ul>
&lt;p>这些指令计算两个 Z 向量寄存器（Zn 和 Zm）中两个向量的外积，将结果数组与一个 ZA tile（ZAda）中已有数据进行累加或累减，并将结果存入同一 ZA tile（ZAda）中。每个源向量由相应的控制 predicate 寄存器（Pn 和 Pm）独立地 predicate。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>输出数组&lt;/th>
&lt;th>输入向量&lt;/th>
&lt;th>描述&lt;/th>
&lt;th>示例&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>INT32&lt;/td>
&lt;td>INT8, INT8&lt;/td>
&lt;td>将四个 INT8 外积之和存入每个 INT32 元素&lt;/td>
&lt;td>SMOPA 或 SMOPS 或 UMOPA 或 UMOPS：带符号或无符号整数外积和，并累加或累减。例如： &lt;code>UMOPS &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.B, &amp;lt;Zm&amp;gt;.B&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>INT32&lt;/td>
&lt;td>INT16, INT16&lt;/td>
&lt;td>将两个 INT16 外积之和存入每个 INT32 元素&lt;/td>
&lt;td>SMOPA 或 SMOPS 或 UMOPA 或 UMOPS：带符号或无符号整数外积和，并累加或累减。例如： &lt;code>UMOPS &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.H, &amp;lt;Zm&amp;gt;.H&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>INT64&lt;/td>
&lt;td>INT16, INT16&lt;/td>
&lt;td>如果实现了 FEAT_SME_I16I64，则将四个 INT16 外积之和存入每个 INT64 元素&lt;/td>
&lt;td>SMOPA 或 SMOPS 或 UMOPA 或 UMOPS：带符号或无符号整数外积和，并累加或累减。例如： &lt;code>UMOPS &amp;lt;ZAda&amp;gt;.D, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.H, &amp;lt;Zm&amp;gt;.H&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>FP32&lt;/td>
&lt;td>BF16, BF16&lt;/td>
&lt;td>将两个 BF16 外积之和存入每个 FP32 元素&lt;/td>
&lt;td>BFMOPA 或 BFMOPS：BFloat16 外积和，并累加或累减。例如： &lt;code>BFMOPS &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.H, &amp;lt;Zm&amp;gt;.H&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>FP32&lt;/td>
&lt;td>FP16, FP16&lt;/td>
&lt;td>将两个 FP16 外积之和存入每个 FP32 元素&lt;/td>
&lt;td>FMOPA 或 FMOPS：半精度浮点外积和，并累加或累减。例如： &lt;code>FMOPS &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.H, &amp;lt;Zm&amp;gt;.H&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>FP32&lt;/td>
&lt;td>FP32, FP32&lt;/td>
&lt;td>简单的 FP32 外积&lt;/td>
&lt;td>FMOPA 或 FMOPS：浮点外积和，并累加或累减。例如： &lt;code>FMOPS &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.S, &amp;lt;Zm&amp;gt;.S&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>FP64&lt;/td>
&lt;td>FP64, FP64&lt;/td>
&lt;td>如果实现了 FEAT_SME_F64F64，则进行简单的 FP64 外积&lt;/td>
&lt;td>FMOPA 或 FMOPS：浮点外积和，并累加或累减。例如： &lt;code>FMOPS &amp;lt;ZAda&amp;gt;.D, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.D, &amp;lt;Zm&amp;gt;.D&lt;/code>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h4 id="711-fp32-fp64-外积并累加或累减指令">7.1.1 FP32, FP64 外积并累加或累减指令&lt;/h4>
&lt;p>那些输入向量和输出数组有同样数据类型（FP32， FP64）的指令相对简单。&lt;/p>
&lt;p>下例展示了 FP32 类型的外积并累加或累减指令。&lt;/p>
&lt;pre>&lt;code class="language-armasm">FMOPA &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.S, &amp;lt;Zm&amp;gt;.S
FMOPS &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.S, &amp;lt;Zm&amp;gt;.S
&lt;/code>&lt;/pre>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_3613751670-667e5f923c64.webp"
alt="FMOPA and FMOPS" width="auto" loading="lazy">
&lt;/figure>
&lt;p>这个例子中，假设 SVL 向量长度为 128，&lt;code>Zn.S&lt;/code> 和 &lt;code>Zm.S&lt;/code> 中存放了 4 个 FP32 数组成的向量，此指令计算 &lt;code>Zn.S&lt;/code> 和 &lt;code>Zm.S&lt;/code> 的外积，外积结果为图中灰色的矩阵，然后将此外积结果累加或累减 &lt;code>ZAda.S&lt;/code> 这个 ZA tile 中原有的值，将结果存入同一 ZA tile。&lt;/p>
&lt;h4 id="712-fp16-bf16-int16-int8-i16i64-类型的外积并累加或累减指令">7.1.2 FP16, BF16, INT16, INT8, I16I64 类型的外积并累加或累减指令&lt;/h4>
&lt;p>由于这些指令会扩大计算结果数据类型，因此这些操作不像前面 FP32，FP64 类型指令那么简单明了。&lt;/p>
&lt;ul>
&lt;li>BF16 指令计算两个 BF16 的外积的和，扩大结果类型为 FP32, 然后将结果与目标 tile 进行破坏性相加或相减。&lt;/li>
&lt;li>INT8 指令计算四个 INT8 的外积的和，扩大结果类型为 INT32，然后将结果与目标 tile 进行破坏性相加或相减。&lt;/li>
&lt;li>INT16 指令计算两个 INT16 的外积的和，扩大结果类型为 INT32，然后将结果与目标 tile 进行破坏性相加或相减。&lt;/li>
&lt;li>FP16 指令计算两个 FP16 的外积的和，扩大结果类型为 FP32，然后将结果与目标 tile 进行破坏性相加或相减。&lt;/li>
&lt;li>如果实现了 FEAT_SME_I16I64，I16I64 指令计算四个 INT16 的外积的和，扩大结果类型为 INT64, 然后将结果与目标 tile 进行破坏性相加或相减。&lt;/li>
&lt;/ul>
&lt;p>以下例子展示了 SVL 向量长度为 128 的 INT8 UMOPA 指令进行的操作：&lt;/p>
&lt;pre>&lt;code class="language-armasm">UMOPA &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.B, &amp;lt;Zm&amp;gt;.B
&lt;/code>&lt;/pre>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_1030_Picture6_png-1280x960.webp"
alt="INT8 UMOPA" width="auto" loading="lazy">
&lt;/figure>
&lt;p>每个输入寄存器（&lt;code>Zn.B&lt;/code>、&lt;code>Zm.B&lt;/code>）都被视为一个包含 4x4 元素的矩阵，可以看作是 4 个连续元素组成的块（如图中红线所标）被转置了。&lt;/p>
&lt;p>在这个例子中，因为 SVL 向量长度为 128-bit：&lt;/p>
&lt;ul>
&lt;li>第一源向量 &lt;code>Zn.B&lt;/code> ，包含一个无符号 8-bit 整数的 4x4 子矩阵。&lt;/li>
&lt;li>第二源向量 &lt;code>Zm.B&lt;/code> ，包含一个无符号 8-bit 整数的 4x4 子矩阵。&lt;/li>
&lt;li>UMOPA 指令计算出 4x4 扩大了的 32-bit 整数外积的和，然后破坏性地累加上目标 tile（ZAda）中的整数。&lt;/li>
&lt;/ul>
&lt;p>更笼统地说，UMOPA 指令是将第一个源向量中的子矩阵与第二个源向量中的子矩阵相乘。每个源向量包含一个(SVL/32) x 4 的无符号 8-bit 整数的子矩阵。然后将得到的 (SVL/32) x (SVL/32)扩大了的 32-bit 整数外积和破坏性地加上一个 32-bit 整数目标 tile。&lt;/p>
&lt;p>下面的例子展示了 SVL 为 128-bit 的 BF16 BFMOPA 进行的操作：&lt;/p>
&lt;pre>&lt;code class="language-armasm">BFMOPA &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.H, &amp;lt;Zm&amp;gt;.H
&lt;/code>&lt;/pre>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_6545_Picture7_png-1280x960.webp"
alt="BF16 BFMOPA" width="auto" loading="lazy">
&lt;/figure>
&lt;p>在这个例子中，因为 SVL 向量长度为 128-bit：&lt;/p>
&lt;ul>
&lt;li>第一源向量 &lt;code>Zn.H&lt;/code> ，包含一个 BF16 整数的 4x2 子矩阵，它被扩大成单精度浮点数。&lt;/li>
&lt;li>第二源向量 &lt;code>Zm.H&lt;/code> ，包含一个 BF16 整数的 2x4 子矩阵，它被扩大成单精度浮点数。&lt;/li>
&lt;li>BMOPA 指令计算出 4x4 单精度外积的和，然后破坏性地累加上目标 tile（ZAda）中的单精度浮点数。&lt;/li>
&lt;/ul>
&lt;p>更笼统地说，BFMOPA 指令扩大了存放在第一源向量里的(SVL/32) x2 BF16 子矩阵的类型为单精度，扩大了存放在第二源向量里的 2x (SVL/32) BF16 子矩阵的类型为单精度，将这两个子矩阵相乘。然后将得到的 (SVL/32) x (SVL/32)单精度外积和破坏性地加上一个单精度目标 tile。&lt;/p>
&lt;p>以下表格显示了几种数据类型和 SVL 长度的一条外积并累加或累减指令所做的对应数据类型的 MAC(乘累加)数量：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>128-bit&lt;/th>
&lt;th>256-bit&lt;/th>
&lt;th>512-bit&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>FP32&lt;/td>
&lt;td>16&lt;/td>
&lt;td>64&lt;/td>
&lt;td>256&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>FP64&lt;/td>
&lt;td>4&lt;/td>
&lt;td>16&lt;/td>
&lt;td>64&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>INT8&lt;/td>
&lt;td>64&lt;/td>
&lt;td>256&lt;/td>
&lt;td>1024&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>INT16&lt;/td>
&lt;td>32&lt;/td>
&lt;td>128&lt;/td>
&lt;td>512&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>BF16&lt;/td>
&lt;td>32&lt;/td>
&lt;td>128&lt;/td>
&lt;td>512&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>FP16&lt;/td>
&lt;td>32&lt;/td>
&lt;td>128&lt;/td>
&lt;td>512&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="72-带-predication-的-sme-指令">7.2 带 Predication 的 SME 指令&lt;/h3>
&lt;p>每个源向量都可以被其相应的控制 predicate 寄存器独立地 predicate:&lt;/p>
&lt;ul>
&lt;li>外积并累加或累减指令使用 Pn/M 和 Pn/M (没有/Z 形式)：Inactive 的源元素被当成具有 0 值。&lt;/li>
&lt;li>Slice move 指令使用 Pg/M: 目标 slice 中 Inactive 的元素保持不变。&lt;/li>
&lt;li>Tile slice load 指令使用 Pg/Z: 目标 tile slice 中的 Inactive 元素被设置为 0。&lt;/li>
&lt;li>Tile slice store 指令使用 Pg: Inactive 的元素不会写入内存。&lt;/li>
&lt;/ul>
&lt;p>Predication 让矩阵的维数不是 SVL 的倍数的情况更容易处理。&lt;/p>
&lt;p>例如下图的指令：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_2656_Picture12_png-600x0.webp"
alt="SME predication" width="auto" loading="lazy">
&lt;/figure>
&lt;p>输入向量 &lt;code>Z0&lt;/code> 被 &lt;code>P0&lt;/code> predicate，&lt;code>Z1&lt;/code> 被 &lt;code>P1&lt;/code> predicate。&lt;/p>
&lt;p>在这个例子中：&lt;/p>
&lt;ul>
&lt;li>SVL 向量长度为 512-bit。&lt;/li>
&lt;li>Z 寄存器中包含 16 个 FP32 数组成的向量。&lt;/li>
&lt;li>&lt;code>P0&lt;/code> 中最后两个元素是 inactive 的。&lt;/li>
&lt;li>&lt;code>P1&lt;/code> 中最后一个元素是 inactive 的。&lt;/li>
&lt;/ul>
&lt;p>这条指令更新 &lt;code>ZA0.S&lt;/code> 中 (16-2) x (16-1) 个 FP32 元素，因为使用了 &lt;code>Pn/M&lt;/code> , &lt;code>ZA0.S&lt;/code> 中剩下的元素保持不变。&lt;/p>
&lt;p>下图展示了更多的 predicated 外积并累加或累减的例子。图中被划线的文字表示被 inactive predicate 元素影响的计算部分。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_2072_Picture14_png-1280x960.webp"
alt="SME predication FMOPA" width="auto" loading="lazy">
&lt;/figure>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_3513_Picture16_png-1280x960.webp"
alt="SME predication UMOPA" width="auto" loading="lazy">
&lt;/figure>
&lt;h3 id="73-za-tile-与一个-z-向量的加运算">7.3 ZA tile 与一个 Z 向量的加运算&lt;/h3>
&lt;p>SME 包括 ZA tile 的行或列都加上一个向量的指令，这些指令也有 predication 的支持。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>指令&lt;/th>
&lt;th>说明&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>ADDHA&lt;/td>
&lt;td>将源向量添加到 ZA tile 的每个水平 slice 上&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ADDVA&lt;/td>
&lt;td>将源向量添加到 ZA tile 的每个垂直 slice 上&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>例如：&lt;/p>
&lt;pre>&lt;code class="language-armasm">ADDHA ZA0.S, P0/M, P1/M, Z1.S
&lt;/code>&lt;/pre>
&lt;p>将执行以下操作：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_ARM2799_9_Scalable_Matrix_p2_png-1200x0.webp"
alt="SME ADDHA" width="auto" loading="lazy">
&lt;/figure>
&lt;p>这个 ADDHA 指令将源向量 Z1 中的每个元素加上 ZA0.S tile 每一水平 slice 的相应 active 元素。&lt;/p>
&lt;p>Tile 中元素被一对 governing predicate 进行 predicate。 一个水平 slice 中的一个元素在下面情况下可以认为是 active：&lt;/p>
&lt;ul>
&lt;li>它在第二 governing predicate 对应的元素是 TRUE, 并且&lt;/li>
&lt;li>它在第一 governing predicate 对应的水平 slice 行号也为 TRUE,目标 tile 中 inactive 元素保持不变。&lt;/li>
&lt;/ul>
&lt;h3 id="74-tile-load-store-move-指令">7.4 Tile load, store, move 指令&lt;/h3>
&lt;p>SME tile load, store, move 指令可以：&lt;/p>
&lt;ul>
&lt;li>从内存读取数据，放入 ZA tile 的行或列&lt;/li>
&lt;li>将 ZA tile 的行或列写入内存&lt;/li>
&lt;li>将 ZA tile 的行移动到 SVE Z 向量寄存器&lt;/li>
&lt;li>将 SVE Z 向量寄存器移动到 ZA tile 行或列&lt;/li>
&lt;/ul>
&lt;h4 id="741-tile-slice-load-和-store-指令">7.4.1 Tile slice load 和 store 指令&lt;/h4>
&lt;p>LD1B、LD1H、LD1S、LD1D 和 LD1Q 指令分别将连续内存值加载到具有 8-bit、16-bit、32-bit、64-bit 或 128-bit 元素的 ZA tile slice 中。&lt;/p>
&lt;p>ST1B、ST1H、ST1S、ST1D 和 ST1Q 指令分别将包含 8-bit、16-bit、32-bit、64-bit 或 128-bit 元素的 ZA tile slice 存储到连续内存中。&lt;/p>
&lt;p>这些指令也支持 predication ，例如：&lt;/p>
&lt;pre>&lt;code class="language-armasm">LD1B ZA0H.B[W0, #imm], P0/Z, [X1, X2]
&lt;/code>&lt;/pre>
&lt;p>此 LD1B 指令执行 predicated 的连续 byte 读取，它从地址为(X1+X2)的内存读取数据到 ZA0 中行号为（W0+imm）的这个水平 tile slice 中。目标 tile slice 中 Inactive 的元素被设置为 0。&lt;/p>
&lt;pre>&lt;code class="language-armasm">ST1H ZA1V.H[W0, #imm], P2, [X1, X2, LSL #1]
&lt;/code>&lt;/pre>
&lt;p>此 ST1H 指令执行 predicated 连续 halfword 的存操作，它将 ZA1 中列号为（W0+imm）的垂直 tile slice 存到地址为（X1+X2*2）的内存， tile slice 中 Inactive 的元素不写入内存。&lt;/p>
&lt;h4 id="742-tile-slice-move-指令">7.4.2 Tile slice move 指令&lt;/h4>
&lt;p>MOV 指令（MOVA 指令的别名）将一个 Z 向量寄存器的值移动到一个 ZA tile slice，或将一个 ZA tile slice 中的值移动到一个 Z 向量寄存器。这条指令操作带指定元素大小的 ZA tile 的单个水平或垂直 tile slice。 Slice 的行号/列号由 slice 的检索寄存器加上立即数偏移指定。目标 slice 中 Inactive 的元素保持不变。&lt;/p>
&lt;p>例如：&lt;/p>
&lt;pre>&lt;code class="language-armasm">MOV ZA0H.B[W0, #imm], P0/M, Z0.B
&lt;/code>&lt;/pre>
&lt;p>或&lt;/p>
&lt;pre>&lt;code class="language-armasm">MOVA ZA0H.B[W0, #imm], P0/M, Z0.B
&lt;/code>&lt;/pre>
&lt;p>此指令将向量寄存器 &lt;code>Z0.B&lt;/code> 中的值移动到 &lt;code>ZA0H.B[W0,#imm]&lt;/code> 这个水平 ZA tile slice 中，使用 &lt;code>P0&lt;/code> 作为 predication 寄存器。目标 tile slice 中 Inactive 的元素保持不变。&lt;/p>
&lt;h3 id="75-za-array-vector-loadstore-指令">7.5 ZA array vector load/store 指令&lt;/h3>
&lt;p>SME LDR 指令从内存读取数据到一个 ZA array 向量，SME STR 指令将一个 ZA array 向量中的值存入内存。
这些指令是不带 predication 功能的。它们主要是为了软件的 context switching 时对 ZA storage 进行 save/restore。SME LDR/STR 指令也可以在 Non-streaming SVE 模式下，当 PSTATE.ZA 使能的情况下使用。
例如，下面的 STR 指令的 ZA array 向量是由一个向量选择寄存器 Wv（标量寄存器 W）加上可选的立即数（Wv+Imm）指定。访问内存的地址为：一个标量寄存器作为 base，加上相同的可选立即数偏移乘以当前向量长度 byte 数。&lt;/p>
&lt;pre>&lt;code class="language-armasm">STR ZA[&amp;lt;Wv&amp;gt;, &amp;lt;imm&amp;gt;], [&amp;lt;Xn|SP&amp;gt;{, #&amp;lt;imm&amp;gt;, MUL VL}]
&lt;/code>&lt;/pre>
&lt;h3 id="76-za-tile-清零指令">7.6 ZA tile 清零指令&lt;/h3>
&lt;p>SME ZERO 指令可以清零一组 64-bit ZA tile:&lt;/p>
&lt;pre>&lt;code class="language-armasm">ZERO { &amp;lt;mask&amp;gt;}
&lt;/code>&lt;/pre>
&lt;p>ZERO 指令可以清零多到 8 个名为 &lt;code>ZA0.D&lt;/code> 到 &lt;code>ZA8.D&lt;/code> 的 ZA tile，那些 tile 要清零由指令中的 mask 指定，剩下的其他 tile 保持不变。&lt;/p>
&lt;p>这条指令也可以在 Non-streaming SVE 模式，当 &lt;code>PSTATE.ZA&lt;/code> 开启的情况下使用。&lt;/p>
&lt;p>如果要清零整个 ZA array, 可以使用一个指令别名，&lt;code>ZERO {ZA}&lt;/code> 。&lt;/p>
&lt;h3 id="77-新的-sve2-指令">7.7 新的 SVE2 指令&lt;/h3>
&lt;p>SME 构架扩展加入了一些新的 SVE2 指令，这些指令也可以在 PE 实现了 SVE2, 处于 Non-streaming SVE 模式时使用。这些指令包括：&lt;/p>
&lt;ul>
&lt;li>选择一个 predicate 寄存器或是 all-false 的 Predicate select 指令&lt;/li>
&lt;li>翻转（Reverse）64-bit double word 元素的指令&lt;/li>
&lt;li>有符号/无符号钳位为更小/更大值向量的指令&lt;/li>
&lt;/ul>
&lt;p>下面介绍以下 Predicate select 指令。&lt;/p>
&lt;h4 id="771-psel-指令">7.7.1 PSEL 指令&lt;/h4>
&lt;p>PSEL 指令选择一个 predicate 寄存器或是 all-false 到目标 predicate 寄存器，如下所示：&lt;/p>
&lt;pre>&lt;code class="language-armasm">PSEL &amp;lt;Pd&amp;gt;, &amp;lt;Pn&amp;gt;, &amp;lt;Pm&amp;gt;.&amp;lt;T&amp;gt;[&amp;lt;Wv&amp;gt;, &amp;lt;imm&amp;gt;]
&lt;/code>&lt;/pre>
&lt;p>如果指令中第二源 predicate 寄存器（Pm）中指定的元素为 True, 这条指令将第一源 predicate 寄存器(Pn)的内容放到目标 predicate 寄存器(Pd), 否者设置目标 predicate 寄存器的值全部为 false。
例如以下指令，假设 W12 的值为 0：&lt;/p>
&lt;pre>&lt;code class="language-armasm">PSEL P0, P1, P2.B[W12, #0]
&lt;/code>&lt;/pre>
&lt;p>第二源 predicate 寄存器的[W12+0]即[0]个元素为 False, 因此目标寄存器 P0 被设置为全 0（all-false），如下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_4401_Picture10_png-1280x960.webp"
alt="SME PSEL" width="auto" loading="lazy">
&lt;/figure>
&lt;p>现在看看如下指令，仍然假设 W12 的值为 0，但这次立即数偏移为 1：&lt;/p>
&lt;pre>&lt;code class="language-armasm">PSEL P0, P1, P2.B[W12, #1]
&lt;/code>&lt;/pre>
&lt;p>第二源 predicate 寄存器的[W12+1]即[1]个元素为 True, 因此选择第一源 predicate 寄存器的值到目标寄存器 P0，如下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_0116_Picture11_png-1280x960.webp"
alt="SME PSEL" width="auto" loading="lazy">
&lt;/figure>
&lt;h2 id="参考文献">参考文献&lt;/h2>
&lt;ul>
&lt;li>&lt;a class="link" href="https://community.arm.com/arm-community-blogs/b/architectures-and-processors-blog/posts/arm-scalable-matrix-extension-introduction" target="_blank" rel="noopener" >Arm Scalable Matrix Extension (SME) Introduction
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/li>
&lt;li>&lt;a class="link" href="https://community.arm.com/arm-community-blogs/b/architectures-and-processors-blog/posts/arm-scalable-matrix-extension-introduction-p2" target="_blank" rel="noopener" >Arm Scalable Matrix Extension (SME) Instructions
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/li>
&lt;/ul></description></item><item><title>Arm 性能优化：可伸缩向量扩展 SVE</title><link>https://cuterwrite.top/p/arm-sve-for-performance/</link><pubDate>Sun, 11 Aug 2024 02:13:00 +0000</pubDate><guid>https://cuterwrite.top/p/arm-sve-for-performance/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-29_117622464_p0_master1200.webp" alt="Featured image of post Arm 性能优化：可伸缩向量扩展 SVE" />&lt;h1 id="arm-性能优化可伸缩向量扩展-sve">Arm 性能优化：可伸缩向量扩展 SVE&lt;/h1>
&lt;h2 id="1-sve-介绍">1. SVE 介绍&lt;/h2>
&lt;p>继固定 128 位向量长度指令集的 Neon 架构扩展之后，Arm 设计了可伸缩向量扩展 (SVE) 作为 AArch64 的下一代 SIMD 扩展。SVE 引入可伸缩概念，允许灵活的向量长度实现，并在 CPU 实现中提供一系列可能的值。向量长度可以从最小 128 位到最大 2048 位不等，以 128 位为增量。&lt;strong>SVE 设计保证相同的应用程序可以在支持 SVE 的不同实现上运行，而无需重新编译代码&lt;/strong>。SVE 提高了该架构对高性能计算 (HPC) 和机器学习 (ML) 应用程序的适用性，这些应用程序需要非常大量的数据处理。SVE2 是 SVE 和 Neon 的超集。SVE2 允许在数据级并行中使用更多功能域。SVE2 继承了 SVE 的概念、向量寄存器和操作原理。SVE 和 SVE2 定义了 32 个可伸缩向量寄存器。芯片合作伙伴可以选择合适的向量长度设计实现，硬件可在 128 位到 2048 位之间（以 128 位为增量）变化。SVE 和 SVE2 的优势在于，只有一个向量指令集使用可伸缩变量。&lt;/p>
&lt;p>SVE 设计理念使开发人员能够编写和构建一次软件，然后在具有各种 SVE 向量长度实现的不同 AArch64 硬件上运行相同的二进制文件。二进制文件的可移植性意味着开发人员不必知道其系统的向量长度实现。消除了重建二进制文件的需求，使软件更容易移植。除了可伸缩向量之外，SVE 和 SVE2 还包括：&lt;/p>
&lt;ul>
&lt;li>per-lane predication&lt;/li>
&lt;li>Gather Load/Scatter Store&lt;/li>
&lt;li>推测性向量化&lt;/li>
&lt;/ul>
&lt;p>这些特性有助于在处理大型数据集时对循环进行向量化和优化。&lt;/p>
&lt;p>SVE2 和 SVE 的主要区别在于指令集的功能覆盖范围。SVE 专为 HPC 和 ML 应用而设计。SVE2 扩展了 SVE 指令集，使其能够加速 HPC 和 ML 以外领域的数据处理。SVE2 指令集还可以加速以下应用中使用的常见算法：&lt;/p>
&lt;ul>
&lt;li>计算机视觉&lt;/li>
&lt;li>多媒体&lt;/li>
&lt;li>LTE 基处理&lt;/li>
&lt;li>基因组学&lt;/li>
&lt;li>内存数据库&lt;/li>
&lt;li>Web 服务&lt;/li>
&lt;li>通用软件&lt;/li>
&lt;/ul>
&lt;p>SVE 和 SVE2 都支持收集和处理大量数据。SVE 和 SVE2 不是 Neon 指令集的扩展。相反，SVE 和 SVE2 经过重新设计，以提供比 Neon 更好的数据并行性。但是，SVE 和 SVE2 的硬件逻辑覆盖了 Neon 硬件的实现。当微架构支持 SVE 或 SVE2 时，它也支持 Neon。要使用 SVE 和 SVE2，在该微架构上运行的软件必须首先支持 Neon。&lt;/p>
&lt;h2 id="2-sve-架构基础">2. SVE 架构基础&lt;/h2>
&lt;p>本节介绍 SVE 和 SVE2 共享的基本架构特性。与 SVE 一样，SVE2 也基于可扩展向量。除了 Neon 提供的现有寄存器库之外，SVE 和 SVE2 还添加了以下寄存器：&lt;/p>
&lt;ul>
&lt;li>32 个可伸缩向量寄存器，&lt;code>Z0-Z31&lt;/code>&lt;/li>
&lt;li>16 个可伸缩 Predicate 寄存器，&lt;code>P0-P15&lt;/code>
&lt;ul>
&lt;li>1 个 首故障 Predicate 寄存器，&lt;code>FFR&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>可伸缩向量系统控制寄存器, &lt;code>ZCR_ELx&lt;/code>&lt;/li>
&lt;/ul>
&lt;h3 id="21-可伸缩向量寄存器">2.1 可伸缩向量寄存器&lt;/h3>
&lt;p>可伸缩向量寄存器 &lt;code>Z0-Z31&lt;/code> 可以在微架构中实现为 128-2048 位。最低的 128 位与 Neon 的固定 128 位向量 &lt;code>V0-V31&lt;/code> 共享。&lt;/p>
&lt;p>下图显示了可伸缩向量寄存器 &lt;code>Z0-Z31&lt;/code>：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_Z-register.webp"
alt="Z 寄存器-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>可伸缩向量寄存器 Z0-Z31&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>可伸缩向量：&lt;/p>
&lt;ul>
&lt;li>可以容纳 64、32、16 和 8 位元素&lt;/li>
&lt;li>支持整数、双精度、单精度和半精度浮点元素&lt;/li>
&lt;li>可以针对每个异常级别（EL）配置向量长度&lt;/li>
&lt;/ul>
&lt;h3 id="22-可伸缩-predicate-寄存器">2.2 可伸缩 Predicate 寄存器&lt;/h3>
&lt;p>为了控制哪些活动元素参与运算，Predicate 寄存器（简称为 P 寄存器）在许多 SVE 指令中用作掩码，这也为向量运算提供了灵活性。下图显示了可伸缩 Predicate 寄存器 &lt;code>P0-P15&lt;/code> ：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_Predicate-register.webp"
alt="P 寄存器-2024-08-12" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>可伸缩 Predicate 寄存器 P0-P15&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>P 寄存器通常用作数据操作的位掩码：&lt;/p>
&lt;ul>
&lt;li>每个 P 寄存器是 Z 寄存器长度的 1/8&lt;/li>
&lt;li>&lt;code>P0-P7&lt;/code> 用于加载、存储和算术运算&lt;/li>
&lt;li>&lt;code>P8-P15&lt;/code> 用于循环管理&lt;/li>
&lt;li>FFR 是一个特殊的 P 寄存器，由 first-fault vector load 指令和 store 指令设置，用于指示每个元素的加载和存储操作的成功情况。FFR 旨在支持推测性内存访问，这使得在许多情况下向量化更容易和更安全。&lt;/li>
&lt;/ul>
&lt;h3 id="23-可伸缩向量系统控制寄存器">2.3 可伸缩向量系统控制寄存器&lt;/h3>
&lt;p>下图展示了可伸缩向量系统控制寄存器 &lt;code>ZCR_ELx&lt;/code> ：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_ZCR_Elx.webp"
alt="ZCR_Elx-2024-08-12" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>可伸缩向量系统控制寄存器 ZCR_Elx&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>可伸缩向量系统控制寄存器指示 SVE 实现特性：&lt;/p>
&lt;ul>
&lt;li>&lt;code>ZCR_Elx.LEN&lt;/code> 字段用于当前和较低异常级别的向量长度。&lt;/li>
&lt;li>大多数位当前保留供将来使用。&lt;/li>
&lt;/ul>
&lt;h3 id="24-sve-汇编语法">2.4 SVE 汇编语法&lt;/h3>
&lt;p>SVE 汇编语法格式由操作码、目标寄存器、P 寄存器（如果指令支持 Predicate 掩码）和输入操作数组成。以下指令示例将详细说明此格式。&lt;/p>
&lt;p>示例 1:&lt;/p>
&lt;pre>&lt;code class="language-armasm">LDFF1D {&amp;lt;Zt&amp;gt;.D}, &amp;lt;Pg&amp;gt;/Z, [&amp;lt;Xn|SP&amp;gt;, &amp;lt;Zm&amp;gt;.D, LSL #3]
&lt;/code>&lt;/pre>
&lt;p>其中：&lt;/p>
&lt;ul>
&lt;li>&lt;code>&amp;lt;Zt&amp;gt;&lt;/code> 是 Z 寄存器, &lt;code>Z0-Z31&lt;/code>&lt;/li>
&lt;li>&lt;code>&amp;lt;Zt&amp;gt;&lt;/code>.D 和 &lt;code>&amp;lt;Zm&amp;gt;.D&lt;/code> 指定目标和操作数向量的元素类型，不需要指定元素的数量。&lt;/li>
&lt;li>&lt;code>&amp;lt;Pg&amp;gt;&lt;/code> 是 P 寄存器, &lt;code>P0-P15&lt;/code>&lt;/li>
&lt;li>&lt;code>&amp;lt;Pg&amp;gt;/Z&lt;/code> 是对 P 寄存器归零。&lt;/li>
&lt;li>&lt;code>&amp;lt;Zm&amp;gt;&lt;/code> 指定 Gather Load 地址模式的偏移量。&lt;/li>
&lt;/ul>
&lt;p>示例 2:&lt;/p>
&lt;pre>&lt;code class="language-armasm">ADD &amp;lt;Zdn&amp;gt;.&amp;lt;T&amp;gt;, &amp;lt;Pg&amp;gt;/M, &amp;lt;Zdn&amp;gt;.&amp;lt;T&amp;gt;, &amp;lt;Zm&amp;gt;.&amp;lt;T&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>其中：&lt;/p>
&lt;ul>
&lt;li>&lt;code>&amp;lt;Pg&amp;gt;/M&lt;/code> 是合并 P 寄存器。&lt;/li>
&lt;li>&lt;code>&amp;lt;Zdn&amp;gt;&lt;/code> 既是目标寄存器，也是输入操作数之一。指令语法在两个位置都显示 &lt;code>&amp;lt;Zdn&amp;gt;&lt;/code> ，是为了方便起见。在汇编编码中，为了简化，它们只被编码一次。&lt;/li>
&lt;/ul>
&lt;p>示例 3:&lt;/p>
&lt;pre>&lt;code class="language-armasm">ORRS &amp;lt;Pd&amp;gt;.B, &amp;lt;Pg&amp;gt;.Z, &amp;lt;Pn&amp;gt;.B, &amp;lt;Pm&amp;gt;.B
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;code>S&lt;/code> 是 P 寄存器条件标志 &lt;code>NZCV&lt;/code> 的新解释。&lt;/li>
&lt;li>&lt;code>&amp;lt;Pg&amp;gt;&lt;/code> 控制 P 寄存器在示例操作中充当位掩码。&lt;/li>
&lt;/ul>
&lt;h3 id="25-sve-架构特性">2.5 SVE 架构特性&lt;/h3>
&lt;p>SVE 包括以下关键架构特性：&lt;/p>
&lt;ul>
&lt;li>per-lane predication&lt;/li>
&lt;/ul>
&lt;p>为了允许对所选元素进行灵活的操作，SVE 引入了 16 个 P 寄存器， &lt;code>P0-P15&lt;/code> ，用于指示对向量活动通道的有效操作。例如：&lt;/p>
&lt;pre>&lt;code class="language-armasm">ADD Z0.D, P0/M, Z0.D, Z1.D
&lt;/code>&lt;/pre>
&lt;p>活动元素 &lt;code>Z0&lt;/code> 和 &lt;code>Z1&lt;/code> 相加并将结果放入 &lt;code>Z0&lt;/code> 中，&lt;code>P0&lt;/code> 指示操作数的哪些元素是活动的和非活动的。&lt;code>P0&lt;/code> 后面的 &lt;strong>M&lt;/strong> 表示 Merging ，表示将非活动元素合并，因此 &lt;code>Z0&lt;/code> 的非活动元素在 &lt;code>ADD&lt;/code> 操作后将保持其初始值。如果 &lt;code>P0&lt;/code> 后面是 &lt;strong>Z&lt;/strong> ，则非活动元素将被清零，目标寄存器的非活动元素将在操作后归零。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_Per-lane_Predication.webp"
alt="Per-lane_Predication-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Per-lane predication merging&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>如果使用的是 &lt;strong>\Z&lt;/strong> ，则非活动元素将被清零，目标寄存器的非活动元素将在操作后归零。例如&lt;/p>
&lt;pre>&lt;code class="language-armasm">CPY Z0.B, P0/Z, #0xFF
&lt;/code>&lt;/pre>
&lt;p>表示将有符号整数 0xFF 复制到 &lt;code>Z0&lt;/code> 的活动通道中，而非活动通道将被清零。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_Per-lane_Predicate_Zeroing.webp"
alt="Per-lane_Predicate_Zeroing-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Per-lane predication zeroing&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;div class="notice notice-note" >
&lt;div class="notice-title">&lt;svg t="1705946198814" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="23141" width="200" height="200">&lt;path d="M195.541333 739.029333C151.594667 692.352 128 640 128 555.136c0-149.333333 104.832-283.178667 257.28-349.354667l38.101333 58.794667c-142.293333 76.970667-170.112 176.853333-181.205333 239.829333 22.912-11.861333 52.906667-16 82.304-13.269333 76.970667 7.125333 137.642667 70.314667 137.642667 148.864a149.333333 149.333333 0 0 1-149.333334 149.333333 165.162667 165.162667 0 0 1-117.248-50.304z m426.666667 0C578.261333 692.352 554.666667 640 554.666667 555.136c0-149.333333 104.832-283.178667 257.28-349.354667l38.101333 58.794667c-142.293333 76.970667-170.112 176.853333-181.205333 239.829333 22.912-11.861333 52.906667-16 82.304-13.269333 76.970667 7.125333 137.642667 70.314667 137.642666 148.864a149.333333 149.333333 0 0 1-149.333333 149.333333 165.162667 165.162667 0 0 1-117.248-50.304z" p-id="23142" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>并非所有指令都具有 Predicate 选项。此外，并非所有 Predicate 操作都同时具有合并和清零选项。您必须参考 &lt;a class="link" href="https://developer.arm.com/documentation/ddi0487/latest/t" target="_blank" rel="noopener" >AArch64 SVE Supplement
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
以了解每个指令的规范细节。&lt;/p>&lt;/div>
&lt;ul>
&lt;li>Gather Load 和 Scatter Store&lt;/li>
&lt;/ul>
&lt;p>SVE 中的寻址模式允许将向量用作 Gather Load 和 Scatter Store 指令中的基地址和偏移量，这使得能够访问非连续的内存位置。例如：&lt;/p>
&lt;pre>&lt;code class="language-armasm">LD1SB Z0.S, P0/Z, [Z1.S] // 将有符号字节从由 32 位向量基地址 Z1 生成的内存地址 Gather Load 到 Z0 的活动 32 位元素中。
LD1SB Z0.D, P0/Z, [X0, Z1.D] // 将有符号字节从由 64 位标量基地址 X0 加上 Z1.D 中的向量索引生成的内存地址 Gather Load 到 Z0 的活动元素中。
&lt;/code>&lt;/pre>
&lt;p>以下示例显示了加载操作 &lt;code>LD1SB Z0.S, P0/Z, [Z1.S]&lt;/code> ，其中 &lt;code>P0&lt;/code> 包含所有真元素，&lt;code>Z1&lt;/code> 包含分散的地址。加载后，&lt;code>Z0.S&lt;/code> 的每个元素的低位字节将用从分散内存位置获取的数据更新。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_gather-load_and_scatter_store_example.webp"
alt="gather-load_and_scatter_store_example-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Gather-load 与 Scatter-store 示例&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;ul>
&lt;li>P 寄存器驱动的循环控制和管理&lt;/li>
&lt;/ul>
&lt;p>作为 SVE 的一项关键特性，P 寄存器不仅可以灵活地控制向量运算的各个元素，还可以实现 P 寄存器驱动的循环控制。P 寄存器驱动的循环控制和管理使循环控制高效且灵活。此功能通过在 P 寄存器中注册活动和非活动元素索引，消除了处理部分向量的额外循环头和尾的开销。P 寄存器驱动的循环控制和管理意味着，在接下来的循环迭代中，只有活动元素才会执行预期的操作。例如：&lt;/p>
&lt;pre>&lt;code class="language-armasm">WHILEL0 P0.S, x8, x9 // 在 P0 中生成一个谓词，从最低编号的元素开始，当第一个无符号标量操作数 X8 的递增值小于第二个标量操作数 X9 时为真，之后为假，直到最高编号的元素。
B.FIRST Loop_start // B.FIRST（等效于 B.MI）或 B.NFRST（等效于 B.PL）通常用于根据上述指令测试结果进行分支，判断 P0 的第一个元素是真还是假，作为循环的结束或继续条件。
&lt;/code>&lt;/pre>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_Predicate-driver_loop_control_and_management_example.webp"
alt="Predicate-driver_loop_control_and_management_example-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>P 寄存器驱动的循环控制和管理示例&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;ul>
&lt;li>用于软件管理推测的向量分区&lt;/li>
&lt;/ul>
&lt;p>推测性加载可能会给传统向量的内存读取带来挑战，&lt;strong>如果在读取过程中某些元素发生错误，则难以逆转加载操作并跟踪哪些元素加载失败&lt;/strong>。Neon 不允许推测性加载。为了允许对向量进行推测性加载（例如 LDRFF），SVE 引入了 first-fault vector load 指令。为了允许向量访问跨越无效页面，SVE 还引入了 FFR 寄存器。&lt;strong>使用 first-fault vector load 指令加载到 SVE 向量时，FFR 寄存器会更新每个元素的加载成功或失败结果&lt;/strong>。当发生加载错误时，FFR 会立即注册相应的元素，将其余元素注册为 0 或 false，并且不会触发异常。通常，RDFFR 指令用于读取 FFR 状态。当第一个元素为假时，RDFFR 指令结束迭代。如果第一个元素为真，RDFFR 指令继续迭代。FFR 的长度与 P 向量相同。可以使用 SETFFR 指令初始化该值。以下示例使用 LDFF1D 从内存中读取数据，FFR 会相应地更新：&lt;/p>
&lt;pre>&lt;code class="language-armasm">LDFF1D Z0.D, P0/Z, [Z1.D, #0] // 使用首个故障行为将双字从由向量基地址 Z1 加 0 生成的内存地址收集加载到 Z0 的活动元素中。非活动元素不会读取设备内存或发出故障信号，并在目标向量中设置为零。从有效内存成功加载将 FFR 中的对应元素设置为真。首个故障加载将 FFR 中的对应元素和其余元素设置为假或 0。
&lt;/code>&lt;/pre>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_Vector-partioning-for-software-managed-speculation-example.webp"
alt="Vector-partioning-for-software-managed-speculation-example-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>用于软件管理推测的向量分区示例&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;ul>
&lt;li>扩展的浮点和水平规约&lt;/li>
&lt;/ul>
&lt;p>为了允许在向量中进行高效的归约操作，并满足对精度的不同要求，SVE 增强了浮点和水平归约操作。这些指令可能具有顺序（从低到高）或基于树（成对）的浮点归约顺序，其中操作顺序可能会导致不同的舍入结果。这些操作需要在可重复性和性能之间进行权衡。例如：&lt;/p>
&lt;pre>&lt;code class="language-armasm">FADDA D0, P0/M, D1, Z2.D // 从源头向量的低位到高位元素进行浮点加严格顺序归约，将结果累积到 SIMD&amp;amp;FP 标量寄存器中。该示例指令将 D1 与 Z2.D 的所有活动元素相加，并将结果存储到标量寄存器 D0 中。向量元素按从低到高的顺序严格处理，标量源 D1 提供初始值。源向量中的非活动元素将被忽略。而 FADDV 将执行递归成对归约，并将结果存储到标量寄存器中。
&lt;/code>&lt;/pre>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_Extended_Floating-poing-and-horizontal-reductions-example.webp"
alt="Extended_Floating-poing-and-horizontal-reductions-example-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>扩展的浮点和水平规约示例&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;h2 id="3-sve2-新增特性">3. SVE2 新增特性&lt;/h2>
&lt;p>本节介绍 SVE2 为 Arm AArch64 架构新增的特性。为了实现可伸缩的性能，SVE2 基于 SVE 构建，允许向量实现高达 2048 位。&lt;/p>
&lt;p>在 SVE2 中，添加了许多复制 Neon 中现有指令的指令，包括：&lt;/p>
&lt;ul>
&lt;li>转换后的 Neon 整数运算，例如，带符号绝对差累加 (SAB) 和带符号减半加法 (SHADD)。&lt;/li>
&lt;li>转换后的 Neon 扩展、缩小和成对运算，例如，无符号长加法 - 底部 (UADDLB) 和无符号长加法 - 顶部 (UADDLT)。&lt;/li>
&lt;/ul>
&lt;p>元素处理顺序发生了变化。SVE2 对交错的偶数和奇数元素进行处理，而 Neon 对窄或宽操作的低半部分和高半部分元素进行处理。下图说明了 Neon 和 SVE2 处理之间的区别：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_transformed_neon_widen_narraow_pairwise_operations.webp"
alt="transformed_neon_widen_narraow_pairwise_operations-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>转换后的 Neon 窄或宽操作对比&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;ul>
&lt;li>复数操作，例如带旋转的复整数乘加 (CMLA)。&lt;/li>
&lt;li>多精度运算，用于大整数运算和密码学，例如，带进位长加法 - 底部 (ADCLB)、带进位长加法 - 顶部 (ADCLT) 以及 SM4 加密和解密 (SM4E)。&lt;/li>
&lt;/ul>
&lt;p>为了向后兼容，最新架构中需要 Neon 和 VFP。虽然 SVE2 包含 SVE 和 Neon 的一些功能，但 SVE2 并不排除 Neon 在芯片上的存在。&lt;/p>
&lt;p>SVE2 支持针对 HPC 市场以外的新兴应用进行优化，例如，在机器学习 (ML)（UDOT 指令）、计算机视觉（TBL 和 TBX 指令）、基带网络（CADD 和 CMLA 指令）、基因组学（BDEP 和 BEXT 指令）和服务器（MATCH 和 NMATCH 指令）中。&lt;/p>
&lt;p>SVE2 增强了通用处理器大量数据操作的整体性能，而无需其他片外加速器。&lt;/p>
&lt;h2 id="4-使用-sve-编程">4. 使用 SVE 编程&lt;/h2>
&lt;p>本节介绍支持 SVE2 应用程序开发的软件工具和库。本节还介绍了如何为支持 SVE2 的目标开发应用程序，在支持 SVE2 的硬件上运行该应用程序，以及在任何 Armv8-A 硬件上模拟该应用程序。&lt;/p>
&lt;h3 id="41-软件和库支持">4.1 软件和库支持&lt;/h3>
&lt;p>要构建 SVE 或 SVE2 应用程序，你必须选择支持 SVE 和 SVE2 功能的编译器。&lt;/p>
&lt;ul>
&lt;li>GNU 工具 8.0+ 版本支持 SVE。&lt;/li>
&lt;li>&lt;a class="link" href="https://developer.arm.com/tools-and-software/server-and-hpc/compile/arm-compiler-for-linux" target="_blank" rel="noopener" >Arm Compiler for Linux
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
18.0+ 版本支持 SVE，20.0+ 版本支持 SVE 和 SVE2。&lt;/li>
&lt;li>GNU 和 Arm Compiler for Linux 编译器都支持优化 C/C++/Fortran 代码。&lt;/li>
&lt;li>LLVM（开源 Clang）5 及更高版本包括对 SVE 的支持，9 及更高版本包括对 SVE2 的支持。要了解 LLVM 工具的每个版本支持哪些 SVE 或 SVE2 功能，请参阅 &lt;a class="link" href="https://developer.arm.com/tools-and-software/open-source-software/developer-tools/llvm-toolchain/sve-support" target="_blank" rel="noopener" >LLVM 工具链 SVE 支持页面
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
。&lt;/li>
&lt;/ul>
&lt;p>&lt;a class="link" href="https://developer.arm.com/Tools%20and%20Software/Arm%20Performance%20Libraries" target="_blank" rel="noopener" >Arm Performance Libraries
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
针对数学例程进行了高度优化，可以链接到你的应用程序。Arm Performance Libraries 19.3+ 版本支持 SVE 的数学库。&lt;/p>
&lt;p>Arm Compiler for Linux 是 Arm Allinea Studio 的一部分，包含 Arm C/C++ 编译器、Arm Fortran 编译器和 Arm Performance Libraries。&lt;/p>
&lt;h3 id="42-如何使用-sve2-编程">4.2 如何使用 SVE2 编程&lt;/h3>
&lt;p>编写或生成 SVE 和 SVE2 代码的方法有多种。在本小节中，我们将探讨其中的一些方法。&lt;/p>
&lt;p>要编写或生成 SVE 和 SVE2 代码，你可以：&lt;/p>
&lt;ul>
&lt;li>编写 SVE 汇编代码&lt;/li>
&lt;li>使用 SVE 内部函数编程&lt;/li>
&lt;li>自动向量化&lt;/li>
&lt;li>使用 SVE 优化库&lt;/li>
&lt;/ul>
&lt;p>让我们更详细地了解这四种选择。&lt;/p>
&lt;h4 id="421-编写-sve-汇编代码">4.2.1 编写 SVE 汇编代码&lt;/h4>
&lt;p>你可以将 SVE 指令作为内联汇编编写到 C/C++ 代码中，或者作为完整的函数编写到汇编源代码中。例如：&lt;/p>
&lt;pre>&lt;code class="language-armasm"> .globl subtract_arrays // -- Begin function
.p2align 2
.type subtract_arrays, @function
subtract_arrays: // @subtract_arrays
.cfi_startproc
// %bb.0:
orr w9, wzr, #0x400
mov x8, xzr
whilelo p0.s, xzr, x9
.LBB0_1: // =&amp;gt;This Inner Loop Header: Depth=1
ld1w { z0.s }, p0/z, [x1, x8, lsl #2]
ld1w { z1.s }, p0/z, [x2, x8, lsl #2]
sub z0.s, z0.s, z1.s
st1w { z0.s }, p0, [x0, x8, lsl #2]
incw x8
whilelo p0.s, x8, x9
b.mi .LBB0_1
// %bb.2:
ret
.Lfunc_end0:
.size subtract_arrays, .Lfunc_end0-subtract_arrays
.cfi_endproc
&lt;/code>&lt;/pre>
&lt;p>如果你混合使用高级语言和汇编语言编写的函数，则必须熟悉针对 SVE 更新的&lt;a class="link" href="https://developer.arm.com/documentation/ihi0036/latest/" target="_blank" rel="noopener" >应用程序二进制接口 (ABI)
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
标准。&lt;a class="link" href="https://developer.arm.com/documentation/ihi0055/latest" target="_blank" rel="noopener" >Arm 架构过程调用标准 (AAPCS)
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
指定了数据类型和寄存器分配，并且与汇编编程最相关。AAPCS 要求：&lt;/p>
&lt;ul>
&lt;li>&lt;code>Z0-Z7&lt;/code> 和 &lt;code>P0-P3 &lt;/code>用于传递可伸缩向量参数和结果。&lt;/li>
&lt;li>&lt;code>Z8-Z15&lt;/code> 和 &lt;code>P4-P15&lt;/code> 是被调用者保存的。&lt;/li>
&lt;li>所有其他向量寄存器（&lt;code>Z16-Z31&lt;/code>）都可能被被调用函数破坏，调用函数负责在需要时备份和恢复它们。&lt;/li>
&lt;/ul>
&lt;h4 id="422-使用-sve-instruction-函数intrinsics">4.2.2 使用 SVE instruction 函数（Intrinsics）&lt;/h4>
&lt;p>SVE 内部函数是由编译器支持的函数，可以替换为相应的指令。程序员可以直接在 C 和 C++ 等高级语言中调用指令函数。SVE 的 ACLE（Arm C 语言扩展）定义了哪些 SVE 指令函数可用、它们的参数以及它们的功能。支持 ACLE 的编译器可以在编译期间将内部函数替换为映射的 SVE 指令。要使用 ACLE 内部函数，你必须包含头文件 &lt;code>arm_sve.h&lt;/code>，其中包含可在 C/C++ 中使用的向量类型和指令函数（针对 SVE）列表。每种数据类型都描述了向量中元素的大小和数据类型：&lt;/p>
&lt;ul>
&lt;li>&lt;code>svint8_t svuint8_t&lt;/code>&lt;/li>
&lt;li>&lt;code>svint16_t svuint16_t svfloat16_t&lt;/code>&lt;/li>
&lt;li>&lt;code>svint32_t svuint32_t svfloat32_t&lt;/code>&lt;/li>
&lt;li>&lt;code>svint64_t svuint64_t svfloat64_t&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>例如，&lt;code>svint64_t&lt;/code> 表示 64 位有符号整数向量，&lt;code>svfloat16_t&lt;/code> 表示半精度浮点数向量。&lt;/p>
&lt;p>以下示例 C 代码已使用 SVE 内部函数进行了手动优化：&lt;/p>
&lt;pre>&lt;code class="language-c">// intrinsic_example.c
#include &amp;lt;arm_sve.h&amp;gt;
svuint64_t uaddlb_array(svuint32_t Zs1, svuint32_t Zs2)
{
// widening add of even elements
svuint64_t result = svaddlb(Zs1, Zs2);
return result;
}
&lt;/code>&lt;/pre>
&lt;p>包含 &lt;code>arm_sve.h&lt;/code> 头文件的源代码可以使用 SVE 向量类型，就像数据类型可以用于变量声明和函数参数一样。要使用 Arm C/C++ 编译器编译代码并以支持 SVE 的 Armv8-A 架构为目标，请使用：&lt;/p>
&lt;pre>&lt;code class="language-bash">armclang -O3 -S -march=armv8-a+sve2 -o intrinsic_example.s intrinsic_example.c
&lt;/code>&lt;/pre>
&lt;p>此命令生成以下汇编代码：&lt;/p>
&lt;pre>&lt;code class="language-armasm">// instrinsic_example.s
uaddlb_array: // @uaddlb_array
.cfi_startproc
// %bb.0:
uaddlb z0.d, z0.s, z1.s
ret
&lt;/code>&lt;/pre>
&lt;h4 id="423-自动向量化">4.2.3 自动向量化&lt;/h4>
&lt;p>C/C++/Fortran 编译器（例如，适用于 Arm 平台的原生 &lt;a class="link" href="https://developer.arm.com/tools-and-software/server-and-hpc/compile/arm-compiler-for-linux" target="_blank" rel="noopener" >Arm Compiler for Linux
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
和 GNU 编译器）支持使用 SVE 或 SVE2 指令对 C、C++ 和 Fortran 循环进行向量化。要生成 SVE 或 SVE2 代码，请选择适当的编译器选项。例如，使用 armclang 启用 SVE2 优化的一个选项是 &lt;code>-march=armv8-a+sve2&lt;/code> 。如果要使用 SVE 版本的库，请将 &lt;code>-march=armv8-a+sve2&lt;/code> 与 &lt;code>-armpl=sve&lt;/code> 结合使用。&lt;/p>
&lt;h4 id="424-使用-svesve2-优化库">4.2.4 使用 SVE/SVE2 优化库&lt;/h4>
&lt;p>使用针对 SVE/SVE2 高度优化的库，例如 &lt;a class="link" href="https://developer.arm.com/Tools%20and%20Software/Arm%20Performance%20Libraries" target="_blank" rel="noopener" >Arm Performance Libraries
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
和 Arm Compute Libraries。Arm Performance Libraries 包含针对 BLAS、LAPACK、FFT、稀疏线性代数和 libamath 优化的数学函数的高度优化实现。要能够链接任何 Arm Performance Libraries 函数，您必须安装 Arm Allinea Studio 并在代码中包含 armpl.h。要使用 Arm Compiler for Linux 和 Arm Performance Libraries 构建应用程序，您必须在命令行中指定 &lt;code>-armpl=&amp;lt;arg&amp;gt;&lt;/code> 。如果您使用 GNU 工具，则必须使用 &lt;code>-L&amp;lt;armpl_install_dir&amp;gt;/lib&lt;/code> 将 Arm Performance Libraries 安装路径包含在链接器命令行中，并指定与 Arm Compiler for Linux &lt;code>-armpl=&amp;lt;arg&amp;gt;&lt;/code> 选项等效的 GNU 选项，即 &lt;code>-larmpl_lp64&lt;/code> 。有关更多信息，请参阅 Arm Performance Libraries 入门指南。&lt;/p>
&lt;h3 id="43-如何运行-svesve2-程序">4.3 如何运行 SVE/SVE2 程序&lt;/h3>
&lt;p>如果您无法访问 SVE 硬件，则可以使用模型或仿真器来运行代码。你可以选择以下几种模型和仿真器：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>QEMU&lt;/strong>： 交叉编译和原生模型，支持在具有 SVE 的 Arm AArch64 平台上进行建模。&lt;/li>
&lt;li>&lt;strong>Fast Models&lt;/strong>： 跨平台模型，支持在基于 x86 的主机上运行的具有 SVE 的 Arm AArch64 平台进行建模。支持 SVE2 的 架构包络模型 AEM 只对主要合作伙伴可用。&lt;/li>
&lt;li>&lt;strong>Arm Instruction Emulator (ArmIE)&lt;/strong>： 直接在 Arm 平台上运行。支持 SVE，并从 19.2+ 版本开始支持 SVE2。&lt;/li>
&lt;/ul>
&lt;h2 id="5-acle-intrinsics">5. ACLE Intrinsics&lt;/h2>
&lt;h3 id="51-acle-简介">5.1 ACLE 简介&lt;/h3>
&lt;p>ACLE (Arm C 语言扩展) 是在 C 和 C++ 代码中利用内部函数和其他特性来支持 Arm 的功能。&lt;/p>
&lt;ul>
&lt;li>ACLE (ARM C 语言扩展) 通过特定于 Arm 的特性扩展了 C/C++ 语言。
&lt;ul>
&lt;li>预定义宏：&lt;code>__ARM_ARCH_ISA_A64&lt;/code> 、 &lt;code>__ARM_BIG_ENDIAN&lt;/code> 等。&lt;/li>
&lt;li>内部函数：&lt;code>__clz(uint32_t x)&lt;/code> 、 &lt;code>__cls(uint32_t x)&lt;/code> 等。&lt;/li>
&lt;li>数据类型：SVE、NEON 和 FP16 数据类型。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>用于 SVE 的 ACLE 支持使用 ACLE 进行可变长度向量 (VLA) 编程。
&lt;ul>
&lt;li>几乎每个 SVE 指令都有一个对应的内部函数。&lt;/li>
&lt;li>数据类型用于表示 SVE 内部函数所使用的无大小向量。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>适用于以下用户的场景：
&lt;ul>
&lt;li>希望手动调整 SVE 代码的用户。&lt;/li>
&lt;li>希望适配或手动优化应用程序和库的用户。&lt;/li>
&lt;li>需要对 Arm 目标进行底层访问的用户。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="52-如何使用-acle">5.2 如何使用 ACLE&lt;/h3>
&lt;ul>
&lt;li>引入头文件
&lt;ul>
&lt;li>&lt;code>arm_acle.h&lt;/code> ：核心 ACLE&lt;/li>
&lt;li>&lt;code>arm_fp16.h&lt;/code> ：添加 FP16 数据类型。
&lt;ul>
&lt;li>目标平台需支持 FP16，即 &lt;code>march=armv8-a+fp16&lt;/code>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>arm_neon.h&lt;/code> ：添加 NEON Intrinsics 和数据类型。
&lt;ul>
&lt;li>目标平台需支持 NEON，即 &lt;code>march=armv8-a+simd&lt;/code>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>arm_sve.h&lt;/code> ：添加 SVE Intrinsics 和数据类型。
&lt;ul>
&lt;li>目标平台需支持 SVE，即 &lt;code>march=armv8-a+sve&lt;/code>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="53-sve-acle">5.3 SVE ACLE&lt;/h3>
&lt;ul>
&lt;li>首先需要做的是引入头文件&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-c">#include &amp;lt;arm_sve.h&amp;gt;
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>VLA 数据类型
&lt;ul>
&lt;li>&lt;code>svfloat64_t&lt;/code>, &lt;code>svfloat16_t&lt;/code>, &lt;code>svuint32_t&lt;/code> 等。&lt;/li>
&lt;li>命名规则：&lt;code>sv&amp;lt;datatype&amp;gt;&amp;lt;datasize&amp;gt;_t&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Predication
&lt;ul>
&lt;li>合并：&lt;code>_m&lt;/code>&lt;/li>
&lt;li>置零：&lt;code>_z&lt;/code>&lt;/li>
&lt;li>不确定：&lt;code>_x&lt;/code>&lt;/li>
&lt;li>P 寄存器的数据类型：&lt;code>svbool_t&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>使用泛型做函数重载，比如函数 &lt;code>svadd&lt;/code> 会根据参数类型自动选择对应的函数。&lt;/li>
&lt;li>函数命名规则：&lt;code>svbase[disambiguator][type0][type1]...[predication]&lt;/code>
&lt;ul>
&lt;li>base 指的是基本操作，比如 &lt;code>add&lt;/code>、&lt;code>mul&lt;/code>、&lt;code>sub&lt;/code> 等。&lt;/li>
&lt;li>disambiguator 用于区分相同基本操作的不同变体。&lt;/li>
&lt;li>typeN 指定了向量和 P 寄存器的类型。&lt;/li>
&lt;li>predication 指定了非活动元素的处理方式。&lt;/li>
&lt;li>例如： &lt;code>svfloat64_t svld1_f64&lt;/code>, &lt;code>svbool_t svwhilelt_b8&lt;/code>, &lt;code>svuint32_t svmla_u32_z&lt;/code>, &lt;code>svuint32_t svmla_u32_m&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="54-sve-常用-intrinsics">5.4 SVE 常用 Intrinsics&lt;/h3>
&lt;ul>
&lt;li>Predicate
&lt;ul>
&lt;li>Predicate 是一个 bool 类型的向量，用于控制计算过程中向量中对应位置是否参与运算&lt;/li>
&lt;li>&lt;code>svbool_t pg = svwhilelt_b32(i, num)&lt;/code> 产生 (i, i + 1, i + 2, &amp;hellip;, i + vl - 1) &amp;lt; num 的 predicate&lt;/li>
&lt;li>&lt;code>svbool_t pg = svptrue_b32()&lt;/code> 产生一个全为 true 的 predicate&lt;/li>
&lt;li>其中，b32 对应处理 32 位数据（int/float），此外还有 b8, b16, b64 对应的 intrinsic&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>内存数据存取
&lt;ul>
&lt;li>&lt;code>svld1(pg, *base)&lt;/code>： 从地址 base 中加载连续向量。&lt;/li>
&lt;li>&lt;code>svst1(pg, *base, vec)&lt;/code>： 将向量 vec 存储到地址 base 中。&lt;/li>
&lt;li>&lt;code>svld1_gather_index(pg, *base, vec_index)&lt;/code>： 从地址 base 中加载向量索引对应的数据。&lt;/li>
&lt;li>&lt;code>svst1_scatter_index(pg, *base, vec_index, vec)&lt;/code>： 将向量 vec 中数据存储到向量索引对应的位置。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>基础计算
&lt;ul>
&lt;li>&lt;code>svadd_z(pg, sv_vec1, sv_vec2)&lt;/code>&lt;/li>
&lt;li>&lt;code>svadd_m(pg, sv_vec1, sv_vec2)&lt;/code>&lt;/li>
&lt;li>&lt;code>svadd_x(pg, sv_vec1, sv_vec2)&lt;/code>&lt;/li>
&lt;li>&lt;code>svadd_x(pg, sv_vec1, x)&lt;/code>&lt;/li>
&lt;li>其中，&lt;code>_z&lt;/code> 表示将 pg 为 false 的位置置零，&lt;code>_m&lt;/code> 表示保留原值，&lt;code>_x&lt;/code> 表示不确定（什么值都有可能）。&lt;/li>
&lt;li>第二个操作数可以为标量数据。&lt;/li>
&lt;li>&lt;code>svmul&lt;/code>, &lt;code>svsub&lt;/code>, &lt;code>svsubr&lt;/code>, &lt;code>svdiv&lt;/code>, &lt;code>svdivr&lt;/code>：其中，&lt;code>svsubr&lt;/code> 相比 &lt;code>svsub&lt;/code> 交换了减数与被减数的位置。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>其它
&lt;ul>
&lt;li>&lt;code>svdup_f64(double x)&lt;/code>： 生成一个所有元素都为 x 的向量。&lt;/li>
&lt;li>&lt;code>svcntd()&lt;/code>：返回 64-bit 数据的向量长度：&lt;code>svcntb&lt;/code> 对应 8 位， &lt;code>svcnth&lt;/code> 对应 16 位，&lt;code>svcntw&lt;/code> 对应 32 位。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="55-sve-结构体-intrinsics">5.5 SVE 结构体 Intrinsics&lt;/h3>
&lt;p>对应结构体数据，SVE 提供了一些特殊的 Intrinsics，比如：&lt;code>svld3&lt;/code>, &lt;code>svget3&lt;/code>, &lt;code>svset3&lt;/code>, &lt;code>svst3&lt;/code> 等。这些 Intrinsics 用于处理结构体数据。&lt;/p>
&lt;p>例如，对于粒子结构体：&lt;/p>
&lt;pre>&lt;code class="language-c">typedef struct {
float x;
float y;
float z;
} Particle;
&lt;/code>&lt;/pre>
&lt;p>可以使用 &lt;code>svld3&lt;/code> 加载结构体中全部的数据为 3 个向量的组，然后使用 &lt;code>svget3&lt;/code> 从 3 个向量的组中提取一个向量, index 的值为 0, 1, 2 分别对应 x, y, z。&lt;/p>
&lt;pre>&lt;code class="language-c">Particle *ps;
float factor = 2.2;
// 初始化部分省略
for (int i = 0; i &amp;lt; num; i += svcntw()) {
svbool_t pg = svwhilelt_b32(i, num);
svfloat32x3_t sv_ps = svld3(pg, (float32_t *)&amp;amp;ps[i]);
svfloat32_t sv_ps_x = svget3(sv_ps, 0);
svfloat32_t sv_ps_y = svget3(sv_ps, 1);
// 执行计算
sv_ps_x = svmul_x(pg, sv_ps_x, factor);
sv_ps_y = svmul_x(pg, sv_ps_y, factor);
//保存结果
sv_ps = svset3(sv_ps, 0, sv_ps_x);
sv_ps = svset3(sv_ps, 1, sv_ps_y);
svst3(pg, (float32_t *)&amp;amp;ps[i], sv_ps);
}
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;code>svld3(pg, *base)&lt;/code>： 加载结构体中全部的数据为 3 个向量的组；其中，base 是 3 个元素结构体数组的地址。&lt;/li>
&lt;li>&lt;code>svget3(tuple, index)&lt;/code>： 从 3 个向量的组中提取一个向量；index 的值为 0、1 或 2。&lt;/li>
&lt;li>&lt;code>svset3(tuple, index, vec)&lt;/code>： 设置 3 个向量的组中的一个向量；index 的值为 0、1 或 2。&lt;/li>
&lt;li>&lt;code>svst3(pg, *base, vec)&lt;/code>： 将 3 个向量的组存储到结构体中；其中，base 是 3 个元素结构体数组的地址。&lt;/li>
&lt;/ul>
&lt;h3 id="56-sve-条件选择">5.6 SVE 条件选择&lt;/h3>
&lt;p>SVE 中提供了 &lt;code>svcmplt&lt;/code>、&lt;code>svcompact&lt;/code>、&lt;code>svcntp_b32&lt;/code> 等方法，可以根据条件选择保留向量中的元素。&lt;/p>
&lt;p>例如，对于无向量化的代码：&lt;/p>
&lt;pre>&lt;code class="language-c">for (int i = 0; i &amp;lt; num; i++) {
float tmp = provided[i];
if (tmp &amp;lt; mark) {
selected[count++] = tmp;
if (count &amp;gt;= maxSize) {
break;
}
}
}
&lt;/code>&lt;/pre>
&lt;p>该代码的作用是从 provided 数组中选择小于 mark 的元素，存储到 selected 数组中，直到 selected 数组满。&lt;/p>
&lt;p>用 SVE Intrinsic 改写：&lt;/p>
&lt;pre>&lt;code class="language-c">for (int i = 0; i &amp;lt; num; i += svcntw()) {
svbool_t pg = svwhilelt_b32(i, num);
svfloat32_t sv_tmp = svld1(pg, &amp;amp;provided[i]);
svbool_t pg_sel = svcmplt(pg, sv_tmp, mark);
sv_tmp = svcompact(pg_sel, sv_tmp);
svst1(pg, &amp;amp;selected[count], sv_tmp);
count += svcntp_b32(pg, pg_sel);
if (count &amp;gt;= maxSize) {
break;
}
}
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;code>svcmplt(pg, vec1, vec2)&lt;/code> ：比较两个向量的大小，返回一个 predicate，表示 vec1 中小于 vec2 的位置。&lt;/li>
&lt;li>&lt;code>svcompact(pg, sv_tmp)&lt;/code> ：压缩向量，将 pg 为 active 的数据按序移动到向量低位，其余位置置零。&lt;/li>
&lt;li>&lt;code>svcntp_b32(pg, pg2)&lt;/code> ：返回 pg2 中 active 的元素个数&lt;/li>
&lt;li>这段代码先将 provided 数组中的数据加载到 sv_tmp 中，然后使用 &lt;code>svcmplt&lt;/code> 生成一个 predicate，表示小于 mark 的位置。接着使用 &lt;code>svcompact&lt;/code> 压缩 sv_tmp，得到小于 mark 的数据，再通过 &lt;code>svst1&lt;/code> 存储到 selected 数组中。最后，使用 &lt;code>svcntp_b32&lt;/code> 统计 active 的元素个数，更新 count。&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_compact.webp"
alt="compact-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>svcompact 示意图（256-bit 向量）&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>由于进行了 compact 操作，所以 selected 数组从 count 位置连续存储新的小于 mark 的数据，剩下的位置被置零。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_svst1.webp"
alt="svst1-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>svst1 示意图（256-bit 向量）&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;h3 id="57-sve-向量化循环交织">5.7 SVE 向量化循环交织&lt;/h3>
&lt;p>SVE Intrinsic 实现的向量化循环交织，相比编译器自动向量化能大大减少读取向量的次数。&lt;/p>
&lt;p>例如，对于无向量化的代码：&lt;/p>
&lt;pre>&lt;code class="language-c">for (int j = offset; j &amp;lt; outerLen - offset; j++) {
int m2index = (j - offset) * innerLen;
int m1index = m2index + innerLen;
int m0index = m1index + innerLen;
int p1index = m0index + innerLen;
int p2index = p1index + innerLen;
for (int i = 0; i &amp;lt; innerLen; i++) {
res[m0index + i] = m2factor * field[m2index + i] +
m1factor * field[m1index + i] +
m0factor * field[m0index + i] +
p1factor * field[p1index + i] +
p2factor * field[p2index + i];
}
}
&lt;/code>&lt;/pre>
&lt;p>编译器对该代码进行自动向量化后，每次迭代需读取五次不同向量的数据，效率较低。&lt;/p>
&lt;p>用 SVE Intrinsic 改写：&lt;/p>
&lt;pre>&lt;code class="language-c">for (int i = 0; i &amp;lt; innerLen; i += svcntd()) {
svbool_t pg = svwhilelt_b32(i, innerLen);
int dataIndex = i;
svfloat64_t jm2Field = svld1(pg, &amp;amp;field[dataIndex]);
dataIndex += innerLen;
svfloat64_t jm1Field = svld1(pg, &amp;amp;field[dataIndex]);
dataIndex += innerLen;
svfloat64_t jm0Field = svld1(pg, &amp;amp;field[dataIndex]);
dataIndex += innerLen;
svfloat64_t jp1Field = svld1(pg, &amp;amp;field[dataIndex]);
for (int j = offset; j &amp;lt; outerLen - offset; j += 1) {
svfloat64_t jp2Field = svld1(pg, &amp;amp;field[(j + offset) * innerLen + i]);
svfloat64_t svRes = svmul_x(pg, jm2Field, m2factor);
svRes = svmad_x(pg, jm1Field, m1factor, svRes);
svRes = svmad_x(pg, jm0Field, m0factor, svRes);
svRes = svmad_x(pg, jp1Field, p1factor, svRes);
svRes = svmad_x(pg, jp2Field, p2factor, svRes);
svst1(pg, &amp;amp;res[j * innerLen + 1], svRes);
jm2Field = jm1Field;
jm1Field = jm0Field;
jm0Field = jp1Field;
jp1Field = jp2Field;
}
}
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;code>svmad_x(pg, vec1, vec2, vec3)&lt;/code> ：计算 vec1 * vec2 + vec3，返回一个向量。&lt;/li>
&lt;li>这段代码每次迭代只需读取一个向量，大大减少向量读取的次数。&lt;/li>
&lt;/ul>
&lt;h2 id="参考文献">参考文献&lt;/h2>
&lt;ol>
&lt;li>&lt;a class="link" href="https://developer.arm.com/-/media/Arm%20Developer%20Community/PDF/102340_0001_02_en_introduction-to-sve2.pdf?revision=b208e56b-6569-4ae2-b6f3-cd7d5d1ecac3" target="_blank" rel="noopener" >Introduction to SVE2
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/li>
&lt;li>&lt;a class="link" href="https://www.stonybrook.edu/commcms/ookami/support/_docs/5%20-%20Advanced%20SVE.pdf" target="_blank" rel="noopener" >SVE Deep Dive
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/li>
&lt;li>&lt;a class="link" href="https://arm-software.github.io/acle/main/acle.html" target="_blank" rel="noopener" >Arm C Language Extensions
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/li>
&lt;/ol></description></item><item><title>SSE 与 AVE 向量化编程</title><link>https://cuterwrite.top/p/simd/</link><pubDate>Sat, 12 Aug 2023 08:00:00 +0000</pubDate><guid>https://cuterwrite.top/p/simd/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/173b9c0b3728e5e9e05d12a4f6dda9a2a7560722.jpg@1256w_1776h_!web-article-pic.webp" alt="Featured image of post SSE 与 AVE 向量化编程" />&lt;h1 id="sse-与-ave-向量化编程">SSE 与 AVE 向量化编程&lt;/h1>
&lt;h2 id="一-向量化编程简介">一、 向量化编程简介&lt;/h2>
&lt;p>近年来，CPU 已经达到了一些物理和功率限制，因此在 GHz 方面，CPU 速度并没有显著提高。随着计算需求的不断增加，CPU 设计人员决定用三种解决方案来解决这个问题：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>增加更多核心&lt;/strong>。通过这种方式，操作系统可以在不同的内核之间分配正在运行的应用程序。此外，程序还可以创建多个线程来最大化核心使用率&lt;/li>
&lt;li>&lt;strong>将向量化操作应用到每个核心&lt;/strong>。该解决方案允许 CPU 对数据向量执行相同的指令。这只能在应用程序级别完成&lt;/li>
&lt;li>&lt;strong>多条指令的无序执行&lt;/strong>。如果现代 CPU 是独立的，那么它们最多可以同时执行四条指令。&lt;/li>
&lt;/ul>
&lt;p>向量寄存器始于 1997 年的 MMX 指令集。MMX 指令集具有 80 位的寄存器。之后发布了 SSE 指令集（从 SSE1 到 SEE4.2 有多个版本），具有 128 位寄存器。2011 年，英特尔发布了采用 AVX 指令集（256 位寄存器）的 Sandy Bridge 架构。2016 年，首款 AVX-512 CPU 发布，采用 512 位寄存器（最多 16x 32 位浮点矢量）。&lt;/p>
&lt;p>本文将重点介绍 SSE 和 AVX 指令集，因为它们通常出现在最近的处理器中。AVX-512 不在讨论范围内，但只需将 256 位寄存器更改为 512 位对应寄存器(ZMM 寄存器)，即可将本文中的所有示例应用于 AVX-512。&lt;/p>
&lt;h3 id="1-sseave-寄存器">1. SSE/AVE 寄存器&lt;/h3>
&lt;p>SSE 和 AVX 各有 16 个寄存器。在 SSE 中，它们被称为 XMM0-XMM15，而在 AVX 中，它们被称为 YMM0-YMM15。XMM 寄存器长度为 128 位，而 YMM 为 256 位。&lt;/p>
&lt;p>SSE 增加了三个类型定义： &lt;code>__m128&lt;/code> 、 &lt;code>__m128d&lt;/code> 和 &lt;code>__m128i&lt;/code> 。分别为浮点型、双精度型(D)和整型(I)。&lt;/p>
&lt;p>AVE 增加了三个类型定义： &lt;code>__m256&lt;/code> 、 &lt;code>__m256d&lt;/code> 和 &lt;code>__m256i&lt;/code> 。分别为浮点型、双精度型(D)和整型(I)。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230810233117.webp"
alt="20230810233117" width="90%" loading="lazy">
&lt;/figure>
&lt;div class="notice notice-warning" >
&lt;div class="notice-title">&lt;svg t="1705945674099" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="16953" width="200" height="200">&lt;path d="M512 106.666667a405.333333 405.333333 0 1 0 405.333333 405.333333A405.333333 405.333333 0 0 0 512 106.666667z m120.533333 489.6a25.621333 25.621333 0 0 1 0 36.266666 25.749333 25.749333 0 0 1-36.266666 0L512 548.266667l-84.266667 84.266666a25.749333 25.749333 0 0 1-36.266666 0 25.621333 25.621333 0 0 1 0-36.266666L475.733333 512l-84.266666-84.266667a25.642667 25.642667 0 0 1 36.266666-36.266666L512 475.733333l84.266667-84.266666a25.642667 25.642667 0 0 1 36.266666 36.266666L548.266667 512z" fill="#ffffff" p-id="16954">&lt;/path>&lt;/svg>&lt;/div>&lt;p>XMM 和 YMM 是重叠的：XMM 寄存器被视为相应 YMM 寄存器的下半部分。这可能会在混合使用 SSE 和 AVX 代码时带来一些性能问题。&lt;/p>&lt;/div>
&lt;p>浮点数据类型（如__m128、__m128d、__m256 和__m256d）在 GCC 编译器中被视为具有相同数据结构的类型。因此，GCC 允许以数组的形式访问这些数据类型的组件。即：下面代码是合法的。&lt;/p>
&lt;pre>&lt;code class="language-c">__m256 myvar = _mm256_set1_ps(6.665f); // Set all vector values to a single float
myvar[0] = 2.22f; // This is valid in GCC compiler
float f = (3.4f + myvar[0]) * myvar[7]; // This is valid in GCC compiler
&lt;/code>&lt;/pre>
&lt;p>例如，对于__m128 类型的变量，可以通过索引来访问其中的四个单精度浮点数组件。对于__m128d 类型的变量，可以通过索引来访问其中的两个双精度浮点数组件。类似地，对于__m256 和__m256d 类型的变量，可以通过索引来访问其中的八个单精度浮点数或四个双精度浮点数组件。&lt;/p>
&lt;p>而在 GCC 编译器中，__m128i 和__m256i 是用于处理整数向量的数据类型。它们被定义为联合体（union），可以表示不同长度的整数向量。然而，由于联合体的特性，访问其中的具体数据成员可能会有一些困难。为了从整数向量中提取单个数据值，可以使用 &lt;code>_mm_extract_epiXX()&lt;/code> 函数。这些函数允许从整数向量中提取指定位置的数据值，并将其作为标量返回。 &lt;code>_mm_extract_epiXX()&lt;/code> 函数中的 XX 表示整数向量的位宽，例如， &lt;code>_mm_extract_epi32()&lt;/code> 用于从 32 位整数向量中提取单个 32 位整数值。&lt;/p>
&lt;h3 id="2-ave-操作例子">2. AVE 操作例子&lt;/h3>
&lt;p>执行 AVX 指令的过程如下：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230810234918.webp"
alt="20230810234918" width="90%" loading="lazy">
&lt;/figure>
&lt;p>所有操作同时进行。就性能而言，在 AVX 中对浮点数执行单个 &lt;code>Add&lt;/code> 的消耗与在 AVX 中对 8 个浮点数执行 &lt;code>VAdd&lt;/code> 的消耗近似。在&lt;a class="link" href="https://www.agner.org/optimize/instruction_tables.pdf" target="_blank" rel="noopener" >Agner Fog&amp;rsquo;s instruction tables
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
中，可以获得更多有关指令延迟和吞吐量的信息。在 Sandy Bridge 架构上，&lt;code>VADDPS/D&lt;/code> 的延迟为 3，吞吐量为 1，就像 &lt;code>FADD(P)&lt;/code> 一样。&lt;/p>
&lt;h3 id="3-先决条件">3. 先决条件&lt;/h3>
&lt;p>SSE/AVX 需要目标机器具备相应的硬件支持。因此，为了确保程序在目标机器上能够正常运行，需要满足这些指令集扩展的先决条件。本文中的示例代码为了简化构建过程并确保程序在当前机器上正常运行，使用&lt;code>-march=native&lt;/code> 编译选项。这个选项会自动检测当前机器的 CPU 能力，并使用相应的指令集扩展。这样可以充分利用目标机器的硬件能力，提高程序的性能和效率。&lt;/p>
&lt;div class="notice notice-info" >
&lt;div class="notice-title">&lt;svg t="1705940100069" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6252" width="200" height="200">&lt;path d="M512 64C264.6 64 64 264.6 64 512s200.6 448 448 448 448-200.6 448-448S759.4 64 512 64z m32 664c0 4.4-3.6 8-8 8h-48c-4.4 0-8-3.6-8-8V456c0-4.4 3.6-8 8-8h48c4.4 0 8 3.6 8 8v272z m-32-344c-26.5 0-48-21.5-48-48s21.5-48 48-48 48 21.5 48 48-21.5 48-48 48z" p-id="6253" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>注意：编译后的二进制文件在没有 AVX 功能的计算机上将失败。如果需要适应不同 CPU 的二进制代码，则需要利用 CPU Flag 并调用不同的函数，或者针对不同的指令集生成不同的二进制代码。&lt;/p>&lt;/div>
&lt;p>由于操作系统、编译器和 CPU 都必须允许 SSE/AVX 扩展。我们可以运行以下脚本来检测系统功能：&lt;/p>
&lt;pre>&lt;code class="language-shell">#!/bin/bash
#CPU flag detection
echo -e &amp;quot;\e[32m&amp;gt;&amp;gt;&amp;gt; Getting CPU flag capabilities and number of cores\e[0m&amp;quot;
cat /proc/cpuinfo | egrep &amp;quot;(flags|model name|vendor)&amp;quot; | sort | uniq -c
#Compiler capabilities. -march=native is required!
echo -e &amp;quot;\e[32m&amp;gt;&amp;gt;&amp;gt; Getting GCC capabilities\e[0m&amp;quot;
gcc -march=native -dM -E - &amp;lt; /dev/null | egrep &amp;quot;SSE|AVX&amp;quot; | sort
#OS kernel version
echo -e &amp;quot;\e[32m&amp;gt;&amp;gt;&amp;gt; Getting OS Kernel Version\e[0m&amp;quot;
uname -a
&lt;/code>&lt;/pre>
&lt;p>在 CPU Flag 中，我们可以看到 SSE 和 AVX 的支持。我们将搜索 avx 标志。这表明 CPU 兼容 AVX。如果有 avx2，则表示 CPU 允许 AVX2 扩展。AVX 足以支持 8x32 位浮点矢量。AVX2 为整数增加了 256 位向量（例如 8x32 位整数）。尽管如此，256 位整数向量的执行速度似乎与两个 128 位向量相同，因此与 SSE 128 位整数向量相比，性能并没有显著提高。&lt;/p>
&lt;p>在 GCC 的输出中，我们可以看到 #define __AVX__ 1 等。这表明 GCC 允许使用 AVX 指令集扩展。&lt;/p>
&lt;div class="notice notice-info" >
&lt;div class="notice-title">&lt;svg t="1705940100069" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6252" width="200" height="200">&lt;path d="M512 64C264.6 64 64 264.6 64 512s200.6 448 448 448 448-200.6 448-448S759.4 64 512 64z m32 664c0 4.4-3.6 8-8 8h-48c-4.4 0-8-3.6-8-8V456c0-4.4 3.6-8 8-8h48c4.4 0 8 3.6 8 8v272z m-32-344c-26.5 0-48-21.5-48-48s21.5-48 48-48 48 21.5 48 48-21.5 48-48 48z" p-id="6253" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>记住始终使用 -march=native 或 -mavx， 如果运行 GCC 时没有使用正确的 march，就不会得到 &lt;strong>AVX&lt;/strong> 标志！ 默认的 GCC 参数是通用的，如果没有该标记，即使 CPU 支持 AVX，也无法启用 AVX。&lt;/p>&lt;/div>
&lt;p>最后，我们需要再次检查 Linux 内核是否为 2.6.30 或更高版本。理想的内核是 4.4.0 或更高版本。&lt;/p>
&lt;p>有了所有这些先决条件，我们就可以开始编写第一个 AVX 向量程序了。&lt;/p>
&lt;h2 id="二自动向量化">二、自动向量化&lt;/h2>
&lt;h3 id="1-gcc-自动向量化-flag">1. GCC 自动向量化 flag&lt;/h3>
&lt;p>GCC 是一种高级编译器，使用优化标志 -O3 或 -ftree-vectorize 时，编译器会搜索循环向量化（需要指定-mavx flag）。在源代码保持不变的情况下，GCC 编译出来的代码会完全不同。&lt;/p>
&lt;p>除非启用某些标志，否则 GCC 不会记录任何有关自动向量化的内容。如果需要自动向量化结果的详细信息，可以使用以下编译器 flag&lt;/p>
&lt;ul>
&lt;li>&lt;code>-fopt-info-vec&lt;/code> 或 &lt;code>-fopt-info-vec-optimized&lt;/code>：编译器将记录哪些循环（按行号）正在进行向量化优化。&lt;/li>
&lt;li>&lt;code>-fopt-info-vec-missed&lt;/code>：关于未被向量化的循环的详细信息，以及许多其他详细信息。&lt;/li>
&lt;li>&lt;code>-fopt-info-vec-note&lt;/code>：关于所有循环和正在进行的优化的详细信息。&lt;/li>
&lt;li>&lt;code>-fopt-info-vec-all&lt;/code>：所有以上的选项放在一起。&lt;/li>
&lt;/ul>
&lt;div class="notice notice-info" >
&lt;div class="notice-title">&lt;svg t="1705940100069" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6252" width="200" height="200">&lt;path d="M512 64C264.6 64 64 264.6 64 512s200.6 448 448 448 448-200.6 448-448S759.4 64 512 64z m32 664c0 4.4-3.6 8-8 8h-48c-4.4 0-8-3.6-8-8V456c0-4.4 3.6-8 8-8h48c4.4 0 8 3.6 8 8v272z m-32-344c-26.5 0-48-21.5-48-48s21.5-48 48-48 48 21.5 48 48-21.5 48-48 48z" p-id="6253" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>注意：还有类似的 -fopt-info-[options]-optimized 标志用于其他编译器优化，如内联： -fopt-info-inline-optimized&lt;/p>&lt;/div>
&lt;p>在以下示例中，我们将使用 -O3 和 -fopt-info-vec-optimized 启用 GCC 自动向量化。当然也可以更改编译器标志以查看不同的日志记录选项。&lt;/p>
&lt;pre>&lt;code class="language-cpp">// autovector.cpp
// compile: g++ -fopt-info-vec-optimized -o autovector autovector.cpp
#pragma GCC optimize(&amp;quot;O3&amp;quot;, &amp;quot;unroll-loops&amp;quot;, &amp;quot;omit-frame-pointer&amp;quot;, &amp;quot;inline&amp;quot;) // 优化选项
#pragma GCC option(&amp;quot;arch=native&amp;quot;, &amp;quot;tune=native&amp;quot;, &amp;quot;no-zero-upper&amp;quot;) // 启用 AVX
#pragma GCC target(&amp;quot;avx&amp;quot;) // 启用 AVX
#include &amp;lt;bits/stdc++.h&amp;gt;
#include &amp;lt;x86intrin.h&amp;gt; // AVX/SSE 指令集
int main()
{
const int N = 200000;
const int numTests = 10000;
float a[N], b[N], c[N], result[N];
auto start = std::chrono::high_resolution_clock::now();
// 数据初始化
for (int i = 0; i &amp;lt; N; ++i)
{
a[i] = ((float)i) + 0.1335f;
b[i] = 1.50f * ((float)i) + 0.9383f;
c[i] = 0.33f * ((float)i) + 0.1172f;
}
for (int i = 0; i &amp;lt; numTests; ++i)
{
for (int j = 0; j &amp;lt; N; ++j)
{
result[j] = a[j] + b[j] - c[j] + 3 * (float)i;
}
}
auto end = std::chrono::high_resolution_clock::now();
auto duration = std::chrono::duration_cast&amp;lt;std::chrono::microseconds&amp;gt;(end - start).count();
assert(result[2] == (2.0f + 0.1335f) + (1.50f * 2.0f + 0.9383f) - (0.33f * 2.0f + 0.1172f) +
3 * (float)(numTests - 1));
std::cout &amp;lt;&amp;lt; &amp;quot;CG&amp;gt; message -channel \&amp;quot;results\&amp;quot; Time used: &amp;quot; &amp;lt;&amp;lt; duration
&amp;lt;&amp;lt; &amp;quot;s, N * numTests=&amp;quot; &amp;lt;&amp;lt; (N * numTests) &amp;lt;&amp;lt; std::endl;
return 0;
}
&lt;/code>&lt;/pre>
&lt;p>如果一切正常，将看到编译器测试结果：&lt;/p>
&lt;pre>&lt;code class="language-text">autovector.cpp:15:23: optimized: loop vectorized using 32 byte vectors
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>将编译选项更改为 &lt;code>-fopt-info-vec-all&lt;/code>，可以看到更多的信息，包括向量化的循环的行号。&lt;/li>
&lt;li>在 autovector.cpp 第 1 行，将 O3 改为 O2 , 然后重新运行。将不会看到 loop vectorized ，而且非向量化编译会比向量化编译慢。&lt;/li>
&lt;/ul>
&lt;h3 id="2-循环向量化的要求">2. 循环向量化的要求&lt;/h3>
&lt;p>并非所有循环都能进行向量化。要进行向量化，对循环有一些严格的要求。&lt;/p>
&lt;ul>
&lt;li>一旦循环开始，循环计数就不能改变。这意味着，循环的终点可以是一个动态变量，可以随意增加或减少其值，但一旦循环开始，它就必须保持不变。&lt;/li>
&lt;li>使用 break 或 continue 句子会有一些限制。有时编译器会很聪明地让它起作用，但在某些情况下，循环不会被向量化。&lt;/li>
&lt;li>在循环内调用外部函数有一些限制&lt;/li>
&lt;li>循环不应该有数据依赖关系。&lt;/li>
&lt;li>条件句 (if/Else) 可以在不改变控制流的情况下使用，并且只用于有条件地将 A 或 B 值加载到 C 变量中。选择 A 或 B 是在编译器中使用掩码完成的，因此它同时计算分支 A 和 B ，而 C 将存储一个或另一个值：&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-c"> if ( s &amp;gt;= 0 ) {
x[i] = (-b[i]+s)/(2.0f*a[i]);
y[i] = (-b[i]-s)/(2.0f*a[i]);
}
else {
x[i] = 0.0f;
y[i] = 0.0f;
}
&lt;/code>&lt;/pre>
&lt;p>这是一个可向量循环。控制流从未改变，x[i] 和 y[i] 值总是设置为其中一个或另一个值。&lt;/p>
&lt;p>有关自动向量化的更多信息，请阅读&lt;a class="link" href="https://software.intel.com/sites/default/files/m/4/8/8/2/a/31848-CompilerAutovectorizationGuide.pdf" target="_blank" rel="noopener" >Intel C++编译器的矢量化
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
。该文档虽然面向 Intel 编译器，但它提供了有关自动向量化的有趣而完整的信息。&lt;/p>
&lt;p>自动向量化的好处是，它是自动完成的。编译器会尝试向量化循环，开发人员不需要做任何事情。但是有时(尤其是在高性能计算应用中)需要微调循环和向量化，通过使用手动 AVX 向量化来确保最大吞吐量。&lt;/p>
&lt;h2 id="三sseavx-的使用">三、SSE/AVX 的使用&lt;/h2>
&lt;p>支持 SSE/AVX 的 CPU 具有用于操作 XMM 和 YMM 寄存器的汇编指令。但在大多数编译器中，通过使用内置函数简化了这一过程，因此开发人员不需要直接使用汇编。&lt;/p>
&lt;h3 id="1-内置函数">1. 内置函数&lt;/h3>
&lt;p>编译器将汇编指令封装为函数，使用它们就像调用带有正确参数的函数一样简单。有时，如果 CPU 不支持指令集，些内置函数就会被模拟。&lt;/p>
&lt;p>SSE/AVX 内置函数使用以下命名约定：&lt;/p>
&lt;pre>&lt;code class="language-cpp">_&amp;lt;vector_size&amp;gt;_&amp;lt;intrin_op&amp;gt;_&amp;lt;suffix&amp;gt;
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;code>&amp;lt;vector_size&amp;gt;&lt;/code> 是指向量的大小。对于 128 位的 SSE， 它为 &lt;code>mm&lt;/code>，对于 256 位的 AVX/AVX2，它为 &lt;code>mm256&lt;/code>，对于 512 位的 AVX512， 它为 &lt;code>mm512&lt;/code> 。&lt;/li>
&lt;li>&lt;code>&amp;lt;intrin_op&amp;gt;&lt;/code> 是指内置函数的名称，例如 &lt;code>add&lt;/code> 或 &lt;code>sub&lt;/code>，&lt;code>mul&lt;/code> 等 。&lt;/li>
&lt;li>&lt;code>&amp;lt;suffix&amp;gt;&lt;/code> 是指内置函数的参数类型，例如 &lt;code>ps&lt;/code> 表示 float ，&lt;code>pd&lt;/code> 表示 double ，&lt;code>epi8&lt;/code> 表示 int8_t，&lt;code>epi32&lt;/code> 表示 int32_t , &lt;code>epu16&lt;/code> 表示 uint16_t 等。&lt;/li>
&lt;/ul>
&lt;p>你可以在&lt;a class="link" href="https://software.intel.com/sites/landingpage/IntrinsicsGuide" target="_blank" rel="noopener" >Intel Intrinsics Guide
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
中找到所有内置函数，它是 SSE/AVX 中提供的任何内置函数的完整参考。此外，还有一份 &lt;a class="link" href="https://db.in.tum.de/~finis/x86-intrin-cheatsheet-v2.2.pdf?lang=en" target="_blank" rel="noopener" >x86 内置函数 Cheet Sheet
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
，但由于内容更为复杂，阅读起来比较困难。&lt;/p>
&lt;h3 id="2-sseavx-没有提供的内置函数">2. SSE/AVX 没有提供的内置函数&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>缺少整数除法&lt;/strong>：由于某些原因，SSE 和 AVX 缺少整数除法运算符。有一些方法可以克服这一点：&lt;/p>
&lt;ul>
&lt;li>在线性代码中通过计算除法来完成操作。首先，从向量中取出单个数据，然后进行除法运算，最后将结果再次存储回向量中。然而，这种方法速度较慢。&lt;/li>
&lt;li>将整数向量转换为浮点数，将它们相除，然后再次转换为整数。&lt;/li>
&lt;li>对于编译时的已知除数，有一些魔法数（magic number）可以将常量除法转换为乘法运算。可以参考&lt;a class="link" href="https://libdivide.com/" target="_blank" rel="noopener" >libdivide
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
。&lt;/li>
&lt;li>对于 2 的幂除法，使用位移操作。除以整数 2 等于右移。只有当所有向量都被相同的 2 的幂整除时，才能进行右移操作。不过对有符号数进行右移时要注意！需要使用符号位移。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>缺少三角函数&lt;/strong>：内置函数中没有三角函数。可能的解决办法是用线性代码计算（对每个向量值逐一计算），或创建近似函数。泰勒级数和 Remez 近似函数的效果很好。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>缺少随机数生成器&lt;/strong>：此外，没有随机数生成器。但是从线性版本重新创建一个好的伪随机生成器是很简单的。只需确定伪随机数生成器中使用的位即可。填充向量首选 32 位或 64 位 RNG。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="3-性能损失">3. 性能损失&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>数据对齐&lt;/strong>： 旧的 CPU 架构不能使用向量化，除非数据在内存中与向量大小一致。其他一些 CPU 可以使用未对齐的数据，但性能会有所损失。在最近的处理器中，这种影响似乎可以忽略不计。但为了安全起见，如果不增加过多的开销，对齐数据可能是个好主意。有关数据对齐的资料，可参考&lt;a class="link" href="https://lemire.me/blog/2012/05/31/data-alignment-for-speed-myth-or-reality/" target="_blank" rel="noopener" >Data alignment for speed: myth or reality?
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/p>
&lt;ul>
&lt;li>在 GCC 中，可以使用以下变量属性进行数据对齐： &lt;code>__attribute__((aligned(16)))&lt;/code>、&lt;code>__attribute__((aligned(32)))&lt;/code>&lt;/li>
&lt;li>最简单的变量对齐声明：&lt;code>#define ALIGN __attribute__((aligned(32)))&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>SSE/AVX 转换损失&lt;/strong>： 将传统的 SSE 库与新的 AVX 架构混合使用还有一个大问题。由于 XMM 和 YMM 共享低 128 位，在 AVX 和 SSE 之间转换可能导致高 128 位出现未定义的值。为了解决这个问题，编译器需要保存高 128 位，清除它，执行旧的 SSE 操作，然后恢复旧值。但是这显著增加了 AVX 操作的开销，导致性能下降。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class="notice notice-tip" >
&lt;div class="notice-title">&lt;svg t="1705945832245" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="19409" width="200" height="200">&lt;path d="M512 74.666667C270.933333 74.666667 74.666667 270.933333 74.666667 512S270.933333 949.333333 512 949.333333 949.333333 753.066667 949.333333 512 753.066667 74.666667 512 74.666667z m238.933333 349.866666l-2.133333 2.133334-277.333333 277.333333c-10.666667 10.666667-29.866667 12.8-42.666667 2.133333L426.666667 704l-149.333334-149.333333c-12.8-12.8-12.8-32 0-44.8 10.666667-10.666667 29.866667-12.8 42.666667-2.133334l2.133333 2.133334 125.866667 125.866666 253.866667-253.866666c10.666667-10.666667 29.866667-12.8 42.666666-2.133334l2.133334 2.133334c12.8 12.8 12.8 32 4.266666 42.666666z" fill="#ffffff" p-id="19410">&lt;/path>&lt;/svg>&lt;/div>&lt;p>注意：这个问题并不意味着不能同时使用__m128 和__m256 而不影响性能。AVX 有一个针对__m128 的新指令集，带有 VEX 前缀。这些新的 VEX 指令与__M256 指令相结合没有任何问题。当非 VEX __m128 指令与 __m256 指令结合使用时，就会产生转换代价。当使用旧的 SSE 库链接到新的启用 AVX 的程序时，就会发生这种情况。&lt;/p>&lt;/div>
&lt;ul>
&lt;li>
&lt;p>为了避免转换损失，编译器可以使用 &lt;code>-mvzeroupper&lt;/code> 参数自动添加对 &lt;code>VZEROUPPER&lt;/code> (清除高 128 位)或 &lt;code>VZEROALL&lt;/code>（清除所有 YMM 寄存器）的调用，程序员也可以手动添加。如果不使用外部 SSE 库，且确定所有代码都启用了 VEX 并在编译时启用了 AVX 扩展，则可以使用 &lt;code>-mvzeroupper&lt;/code> 参数指示编译器避免添加 &lt;code>VZEROUPPER&lt;/code> 调用： &lt;code>-mno-vzeroupper&lt;/code>。更多关于 SSE/AVX 转换损失的资料，可参考&lt;a class="link" href="https://software.intel.com/en-us/articles/avoiding-avx-sse-transition-penalties" target="_blank" rel="noopener" >Avoiding AVX-SSE Transition Penalties
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
和 &lt;a class="link" href="https://stackoverflow.com/questions/41303780/why-is-this-sse-code-6-times-slower-without-vzeroupper-on-skylake" target="_blank" rel="noopener" >Why is this SSE code 6 times slower without VZEROUPPER on Skylake?
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>数据移动成本&lt;/strong>：在 AVX 寄存器中来回移动数据的成本很高。在某些情况下，如果有一些数据存储在线性结构中，那么将这些数据发送到 AVX 向量、执行一些操作并恢复这些数据的成本要比简单地执行线性计算高。因此，开发时必须考虑到数据加载和卸载的开销。请记住，在某些情况下，这将成为性能瓶颈。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="4-avx-使用例子计算平方根">4. AVX 使用例子：计算平方根&lt;/h3>
&lt;ul>
&lt;li>下面程序是对浮点数的 SQRT 计算进行向量化，显式使用 &lt;code>__m256&lt;/code> 数据类型来存储浮点数，从而减少数据加载的开销。&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-cpp">// vectorized_sqrt.cpp
// compile: g++ -o vectorized_sqrt vectorized_sqrt.cpp
#pragma GCC optimize(&amp;quot;O3&amp;quot;, &amp;quot;unroll-loops&amp;quot;, &amp;quot;omit-frame-pointer&amp;quot;, &amp;quot;inline&amp;quot;) // 优化选项
#pragma GCC option(&amp;quot;arch=native&amp;quot;, &amp;quot;tune=native&amp;quot;, &amp;quot;no-zero-upper&amp;quot;) // 启用 AVX
#pragma GCC target(&amp;quot;avx&amp;quot;) // 启用 AVX
#include &amp;lt;bits/stdc++.h&amp;gt;
#include &amp;lt;x86intrin.h&amp;gt; // AVX/SSE 指令集
const int N = 64000000;
const int V = N / 8;
float linear[N];
// 禁用自动向量化
__attribute__((optimize(&amp;quot;no-tree-vectorize&amp;quot;))) inline void normal_sqrt()
{
for (int i = 0; i &amp;lt; N; ++i)
{
linear[i] = sqrtf(linear[i]);
}
}
__m256 ALIGN vectorized[V];
inline void avx_sqrt()
{
for (int i = 0; i &amp;lt; V; ++i)
{
vectorized[i] = _mm256_sqrt_ps(vectorized[i]);
}
}
#define TIME \
std::chrono::duration_cast&amp;lt;std::chrono::duration&amp;lt;double&amp;gt;&amp;gt;( \
std::chrono::high_resolution_clock::now() - now) \
.count()
int main(int argc, char **argv)
{
// 数据初始化
for (int i = 0; i &amp;lt; N; ++i)
{
linear[i] = ((float)i) + 0.1335f;
}
for (int i = 0; i &amp;lt; V; ++i)
{
for (int v = 0; v &amp;lt; 8; ++v)
{
vectorized[i][v] = ((float)(i * 8 + v)) + 0.1335f;
}
}
// normal_sqrt benchmark
auto now = std::chrono::high_resolution_clock::now();
for (int i = 0; i &amp;lt; 20; ++i)
{
normal_sqrt();
}
auto linear_time = TIME;
std::cerr &amp;lt;&amp;lt; &amp;quot;Normal sqrtf: &amp;quot; &amp;lt;&amp;lt; linear_time &amp;lt;&amp;lt; std::endl;
// AVX sqrt benchmark
now = std::chrono::high_resolution_clock::now();
for (int i = 0; i &amp;lt; 20; ++i)
{
avx_sqrt();
}
auto avx_time = TIME;
std::cerr &amp;lt;&amp;lt; &amp;quot;AVX sqrtf: &amp;quot; &amp;lt;&amp;lt; avx_time &amp;lt;&amp;lt; std::endl;
// Check Values
for (int i = 0; i &amp;lt; V; ++i)
{
for (int v = 0; v &amp;lt; 8; ++v)
{
if (abs(linear[i * 8 + v] - vectorized[i][v]) &amp;gt; 0.00001f)
{
std::cerr &amp;lt;&amp;lt; &amp;quot;Error: AVX sqrtf is not equal to normal sqrtf!&amp;quot; &amp;lt;&amp;lt; std::endl;
std::cerr &amp;lt;&amp;lt; &amp;quot;linear[&amp;quot; &amp;lt;&amp;lt; i * 8 + v &amp;lt;&amp;lt; &amp;quot;] = &amp;quot; &amp;lt;&amp;lt; linear[i * 8 + v] &amp;lt;&amp;lt; std::endl;
std::cerr &amp;lt;&amp;lt; &amp;quot;vectorized[&amp;quot; &amp;lt;&amp;lt; i &amp;lt;&amp;lt; &amp;quot;][&amp;quot; &amp;lt;&amp;lt; v &amp;lt;&amp;lt; &amp;quot;] = &amp;quot; &amp;lt;&amp;lt; vectorized[i][v]
&amp;lt;&amp;lt; std::endl;
return -1;
}
}
}
std::cout &amp;lt;&amp;lt; &amp;quot;Linear to AVX improvement : &amp;quot; &amp;lt;&amp;lt; (linear_time / avx_time * 100) &amp;lt;&amp;lt; &amp;quot;%&amp;quot;
&amp;lt;&amp;lt; std::endl;
return 0;
}
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>可能会看到 600% 或更高的性能提升。也就是说，一旦加载了数据，AVX 的运行速度将是普通 sqrtf 的 7 倍。理论极限是 800%，但很少能达到。一般来说可以预期平均提高 300% 到 600%。运行结果如下：&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-text">Normal sqrtf: 1.51901
AVX sqrtf: 0.374871
Linear to AVX improvement : 405.209%
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>可以看到：运行速度提高了 405%。&lt;/li>
&lt;/ul>
&lt;h2 id="四c中的-sseavx-框架">四、C++中的 SSE/AVX 框架&lt;/h2>
&lt;h3 id="1-内置函数的复杂性">1. 内置函数的复杂性&lt;/h3>
&lt;p>直接使用内置函数会使代码编写和维护变得复杂。问题在于内置函数名很长，比如算术运算用函数符号书写：&lt;code>add(a,b)&lt;/code> 而不是 &lt;code>a + b&lt;/code>。导致下面的代码很难阅读：&lt;/p>
&lt;pre>&lt;code class="language-cpp">x = _mm256_div_ps(_mm256_add_ps(b, _mm256_sqrt_ps(_mm256_sub_ps(_mm256_mul_ps(b, b),
_mm256_mul_ps(_mm256_mul_ps(a, c),
_mm256_set1_ps(4.0f))))) , _mm256_mul_ps(a,_mm256_set1_ps(2.0f)));
&lt;/code>&lt;/pre>
&lt;p>而以下封装版本的可读性非常好：&lt;/p>
&lt;pre>&lt;code class="language-cpp">x = (b + sqrt(b * b - a * c * 4.0f)) / (a * 2.0f);
&lt;/code>&lt;/pre>
&lt;h3 id="2-用于-simd-计算的-c框架">2. 用于 SIMD 计算的 C++框架&lt;/h3>
&lt;p>现有的一些框架在新的类中封装了向量数据类型。然后，它们重载算术、逻辑和赋值运算符，以简化计算。其中，可以使用这两个框架：&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="http://www.agner.org/optimize/#vectorclass" target="_blank" rel="noopener" >Agner Fog&amp;rsquo;s C++ vector class library
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
： 内容完整，定期更新。而且还包含了三角函数。&lt;/li>
&lt;li>&lt;a class="link" href="https://gain-performance.com/ume/" target="_blank" rel="noopener" >Unified Multicore Environment
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
：一个较新的库&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/xtensor-stack/xsimd" target="_blank" rel="noopener" >xsimd Wrapper
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
：一个比较好用的 C++ Wrapper。&lt;/li>
&lt;/ul>
&lt;p>不过，这些库的体积都比较大，在代码大小有限（小于 100kb）的情况下，可以使用以下简单的封装版本，只需要关注一两种类型。&lt;/p>
&lt;a href="https://github.com/marchete/Course-SSE-and-AVX-Vectorization-ES/tree/master/projects/avx/framework" target="_blank" class="card-github fetch-waiting no-styling"
repo="marchete/Course-SSE-and-AVX-Vectorization-ES" id="repo-HhyP4FchLUca4waJ-card">
&lt;div class="gc-titlebar">
&lt;div class="gc-titlebar-left">
&lt;div class="gc-owner">
&lt;div id="repo-HhyP4FchLUca4waJ-avatar" class="gc-avatar">&lt;/div>
&lt;div class="gc-user">marchete&lt;/div>
&lt;/div>
&lt;div class="gc-divider">/&lt;/div>
&lt;div class="gc-repo">Course-SSE-and-AVX-Vectorization-ES&lt;/div>
&lt;/div>
&lt;div class="github-logo">&lt;/div>
&lt;/div>
&lt;div id="repo-HhyP4FchLUca4waJ-description" class="gc-description">Waiting for api.github.com...&lt;/div>
&lt;div class="gc-infobar">
&lt;div id="repo-HhyP4FchLUca4waJ-stars" class="gc-stars">0&lt;/div>
&lt;div id="repo-HhyP4FchLUca4waJ-forks" class="gc-forks">0&lt;/div>
&lt;div id="repo-HhyP4FchLUca4waJ-license" class="gc-license">unkown&lt;/div>
&lt;div id="repo-HhyP4FchLUca4waJ-language" class="gc-language">Waiting...&lt;/div>
&lt;/div>
&lt;/a>
&lt;script id="repo-HhyP4FchLUca4waJ-script" type="text/javascript" defer>
fetch('https://api.cuterwrite.top/api/repos/marchete\/Course-SSE-and-AVX-Vectorization-ES', {
referrerPolicy: "no-referrer"
})
.then(response => response.json())
.then(data => {
document.getElementById('repo-HhyP4FchLUca4waJ-description').innerText = data.description.replace(
/:[a-zA-Z0-9_]+:/g, '');
document.getElementById('repo-HhyP4FchLUca4waJ-language').innerText = data.language;
document.getElementById('repo-HhyP4FchLUca4waJ-forks').innerText = Intl.NumberFormat('en-us', {
notation: "compact",
maximumFractionDigits: 1
}).format(data.forks).replaceAll("\u202f", '');
document.getElementById('repo-HhyP4FchLUca4waJ-stars').innerText = Intl.NumberFormat('en-us', {
notation: "compact",
maximumFractionDigits: 1
}).format(data.stargazers_count).replaceAll("\u202f", '');
const avatarEl = document.getElementById('repo-HhyP4FchLUca4waJ-avatar');
avatarEl.style.backgroundImage = 'url(' + data.owner.avatar_url + ')';
avatarEl.style.backgroundColor = 'transparent';
if (data.license?.spdx_id) {
document.getElementById('repo-HhyP4FchLUca4waJ-license').innerText = data.license.spdx_id
} else {
document.getElementById('repo-HhyP4FchLUca4waJ-license').classList.add = "no-license"
};
document.getElementById('repo-HhyP4FchLUca4waJ-card').classList.remove("fetch-waiting");
console.log("[GITHUB-CARD] Loaded card for marchete\/Course-SSE-and-AVX-Vectorization-ES.")
}).catch(err => {
const c = document.getElementById('repo-HhyP4FchLUca4waJ-card');
c.classList.add("fetch-error");
console.warn("[GITHUB-CARD] (Error) Loading card for marchete\/Course-SSE-and-AVX-Vectorization-ES.")
})
&lt;/script>
&lt;ul>
&lt;li>除了内置函数，该封装版本还封装了一些特殊的函数：&lt;/li>
&lt;li>&lt;strong>Blend-based functions&lt;/strong>：blend 是根据掩码有条件地加载向量值的过程，这类函数用于混合两个向量的函数。
&lt;ul>
&lt;li>&lt;code>if_select(mask,value_true,value_false)&lt;/code> ：根据掩码对向量进行有条件加载。如果掩码为真，则返回 value_true，否则返回 value_false。&lt;/li>
&lt;li>&lt;code>if_add(mask,value,add_when_true)&lt;/code> ：条件加法。返回 &lt;code>value + (mask? add_when_true:0)&lt;/code> ，对于每个向量分量。&lt;/li>
&lt;li>&lt;code>if_sub, if_mul, if_div&lt;/code> ：与 if_add 类似，只是算术运算方式不同。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Horizontal functions&lt;/strong>：Horizontal 表示这些函数通过计算某些逻辑值或算术值，在单个向量变量内运行。
&lt;ul>
&lt;li>&lt;code>horizontal_or(mask)&lt;/code> ：如果掩码中的任何向量分量为 true。返回布尔值。&lt;/li>
&lt;li>&lt;code>horizontal_add(vector)&lt;/code> ：返回向量的所有分量的总和。返回值是一个数字(浮点型、双精度型或整型，具体取决于向量类型)。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="五masking-与-conditional-load">五、Masking 与 Conditional Load&lt;/h2>
&lt;h3 id="1-向量中的掩码">1. 向量中的掩码&lt;/h3>
&lt;p>掩码是向量之间逻辑运算的结果。它与布尔运算有许多相似之处（它们是对单个数字或其他布尔运算的逻辑运算结果），但在内部，每个掩码组件必须全部为 0 位或全部为 1 位。&lt;/p>
&lt;p>让我们比较具有大于运算符的两个 AVX 浮点向量：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230811173734.webp"
alt="20230811173734" width="90%" loading="lazy">
&lt;/figure>
&lt;p>输入是两个带有浮点分量的向量。逻辑运算的输出也是一个带浮点分量的向量，但其值的位数被设置为全 0 或全 1。全 1 表示 &amp;ldquo;真&amp;rdquo;，全 0 表示 &amp;ldquo;假&amp;rdquo;。对于浮点数，全 1 的值打印为-nan，对于整数，则打印为-1。存储的实际值并不重要。我们只需要知道它保存的是真值和假值。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>逻辑运算符的结果(&amp;gt;、&amp;lt;、==、&amp;amp;&amp;amp;、||等&lt;/strong>：以逻辑&amp;amp;&amp;amp;运算符为例：&lt;/p>
&lt;ul>
&lt;li>&lt;code>vector &amp;amp;&amp;amp; vector = mask&lt;/code>&lt;/li>
&lt;li>&lt;code>mask &amp;amp;&amp;amp; mask == mask&lt;/code>&lt;/li>
&lt;li>&lt;code>vector &amp;amp;&amp;amp; mask == ?????&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>最后一种情况，可能会有意想不到的结果，这就像试图做 3 &amp;gt; false，也许在 C++ 中这是可行的，但在逻辑意义上这是不正确的。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class="notice notice-info" >
&lt;div class="notice-title">&lt;svg t="1705940100069" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6252" width="200" height="200">&lt;path d="M512 64C264.6 64 64 264.6 64 512s200.6 448 448 448 448-200.6 448-448S759.4 64 512 64z m32 664c0 4.4-3.6 8-8 8h-48c-4.4 0-8-3.6-8-8V456c0-4.4 3.6-8 8-8h48c4.4 0 8 3.6 8 8v272z m-32-344c-26.5 0-48-21.5-48-48s21.5-48 48-48 48 21.5 48 48-21.5 48-48 48z" p-id="6253" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>注意：与布尔运算不同，并非零以外的任何数字都是 TRUE。只有所有位都设置为 1 的矢量成分才被视为 TRUE。不要使用其他值作为掩码。否则会失败，或得到意想不到的结果。&lt;/p>&lt;/div>
&lt;h3 id="2-条件加载">2. 条件加载&lt;/h3>
&lt;p>掩码可用于有条件地将值加载到向量中。比如可以使用掩码来有条件地控制值向量的加载：&lt;code>if_select(mask,value_true,value_false)&lt;/code> 可以表示为：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230811174342.webp"
alt="20230811174342" width="90%" loading="lazy">
&lt;/figure>
&lt;ul>
&lt;li>当掩码设置为 &lt;code>FALSE&lt;/code> 时，数据从 &lt;code>value_false&lt;/code> 向量加载；当设置为 &lt;code>TRUE&lt;/code> 时，数据从 &lt;code>value_true&lt;/code> 向量加载。这个概念简单而有效。&lt;/li>
&lt;/ul>
&lt;div class="notice notice-note" >
&lt;div class="notice-title">&lt;svg t="1705946198814" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="23141" width="200" height="200">&lt;path d="M195.541333 739.029333C151.594667 692.352 128 640 128 555.136c0-149.333333 104.832-283.178667 257.28-349.354667l38.101333 58.794667c-142.293333 76.970667-170.112 176.853333-181.205333 239.829333 22.912-11.861333 52.906667-16 82.304-13.269333 76.970667 7.125333 137.642667 70.314667 137.642667 148.864a149.333333 149.333333 0 0 1-149.333334 149.333333 165.162667 165.162667 0 0 1-117.248-50.304z m426.666667 0C578.261333 692.352 554.666667 640 554.666667 555.136c0-149.333333 104.832-283.178667 257.28-349.354667l38.101333 58.794667c-142.293333 76.970667-170.112 176.853333-181.205333 239.829333 22.912-11.861333 52.906667-16 82.304-13.269333 76.970667 7.125333 137.642667 70.314667 137.642666 148.864a149.333333 149.333333 0 0 1-149.333333 149.333333 165.162667 165.162667 0 0 1-117.248-50.304z" p-id="23142" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>代码示例 1：使用掩码和 SIMD-Framework 中的 v8f.h 实现条件加载。（主要使用 if_select(mask,value_true,value_false) 方法，该函数是 _mm256_blendv_ps 的封装）&lt;/p>&lt;/div>
&lt;pre>&lt;code class="language-cpp">#pragma GCC optimize(&amp;quot;O3&amp;quot;, &amp;quot;unroll-loops&amp;quot;, &amp;quot;omit-frame-pointer&amp;quot;, &amp;quot;inline&amp;quot;)
#pragma GCC option(&amp;quot;arch=native&amp;quot;, &amp;quot;tune=native&amp;quot;, &amp;quot;no-zeroupper&amp;quot;)
#pragma GCC target(&amp;quot;avx&amp;quot;)
#include &amp;lt;bits/stdc++.h&amp;gt;
#include &amp;lt;x86intrin.h&amp;gt;
#include &amp;quot;v8f.h&amp;quot;
using namespace std;
inline v8f testConditions(const v8f &amp;amp;value)
{
return if_select(value &amp;gt; 3.0f || (value &amp;lt;= -3.7f &amp;amp;&amp;amp; value &amp;gt; -15.0f), sqrt(2.0f * value + 1.5f),
(-2.0f * value - 8.7f));
}
inline bool validate(const v8f &amp;amp;test, const v8f &amp;amp;vector)
{
for (int j = 0; j &amp;lt; 8; ++j)
{
float value = test[j];
float expected;
if (value &amp;gt; 3.0f || (value &amp;lt;= -3.7f &amp;amp;&amp;amp; value &amp;gt; -15.0f))
{
expected = sqrt(2.0f * value + 1.5f);
}
else
{
expected = (-2.0f * value - 8.7f);
}
if (abs(expected - vector[j]) &amp;gt; 0.00001f)
{
cout &amp;lt;&amp;lt; &amp;quot;Assert Error:&amp;quot; &amp;lt;&amp;lt; expected &amp;lt;&amp;lt; &amp;quot; &amp;quot; &amp;lt;&amp;lt; vector[j] &amp;lt;&amp;lt; endl;
return false;
}
}
return true;
}
int main()
{
int validTests = 0;
int TotalTests = 1000;
for (int i = 0; i &amp;lt; TotalTests; ++i)
{
float offset = -500.0f + (1000.0f * i) / TotalTests;
v8f test(1.4f, 3.3f, -12.5f, -33.4f, 7.9f, -70.2f, 15.1f, 22.6f);
test += offset;
v8f result = testConditions(test);
if (validate(test, result))
{
++validTests;
}
}
cout &amp;lt;&amp;lt; &amp;quot;Valid Tests:&amp;quot; &amp;lt;&amp;lt; validTests &amp;lt;&amp;lt; &amp;quot;/&amp;quot; &amp;lt;&amp;lt; TotalTests &amp;lt;&amp;lt; &amp;quot; (&amp;quot;
&amp;lt;&amp;lt; (100 * validTests / TotalTests) &amp;lt;&amp;lt; &amp;quot;%)&amp;quot; &amp;lt;&amp;lt; endl;
if (validTests != TotalTests)
{
return -1;
}
return 0;
}
&lt;/code>&lt;/pre>
&lt;h3 id="3-性能">3. 性能&lt;/h3>
&lt;p>使用掩码的条件加载不是真正的分支，因此它们不会有误预测，并且 CPU 可以更好地利用无序执行。但这是有代价的。因为它们是无分支的，并且所有条件执行都是通过掩码操作完成的，所以总是计算和执行这两个分支。如果要对 &lt;code>value_false&lt;/code> 进行非常复杂的计算，那么即使只有 0.00001% 的时间会发生，也会一直进行计算。如果代码中有些部分很少需要，但计算成本很高，这可能会导致性能问题。在下一章数据流控制中，可以通过控制数据流的方法，根据某些条件提前退出循环。&lt;/p>
&lt;h2 id="六数据流控制">六、数据流控制&lt;/h2>
&lt;h3 id="1-共享数据流问题">1. 共享数据流问题&lt;/h3>
&lt;p>在线性编程中，创建条件分支 if、switch、continue 和 break 来控制数据流没有任何问题。你只需创建一个无限循环，并在条件满足时跳出循环即可。但是一个向量不仅有一个条件结果，而且同时有 N 个条件结果。向量的一部分可以准备退出循环(因为向量数据已达到退出条件)，但其余数据在退出之前仍有活动工作要做。&lt;/p>
&lt;div class="notice notice-info" >
&lt;div class="notice-title">&lt;svg t="1705940100069" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6252" width="200" height="200">&lt;path d="M512 64C264.6 64 64 264.6 64 512s200.6 448 448 448 448-200.6 448-448S759.4 64 512 64z m32 664c0 4.4-3.6 8-8 8h-48c-4.4 0-8-3.6-8-8V456c0-4.4 3.6-8 8-8h48c4.4 0 8 3.6 8 8v272z m-32-344c-26.5 0-48-21.5-48-48s21.5-48 48-48 48 21.5 48 48-21.5 48-48 48z" p-id="6253" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>如果向量分量已经计算完成，请冻结它以避免对其进行任何进一步的计算。具体做法是在任何数值赋值中屏蔽已完成的分量。未完成的向量分量会不断更新，但已完成的分量不会。因此，如果我有一个 8x 浮点矢量，而分量 0、1、4 和 7 已达到结束状态，我就需要在每次数据加载时加上一个掩码[false,false,true,true,false,true,false]&lt;/p>&lt;/div>
&lt;h3 id="2-避免执行计算开销很大的分支">2. 避免执行计算开销很大的分支&lt;/h3>
&lt;p>要节省 CPU 时间，最简单的方法是检查掩码内的所有值是否相同，要么全部为 &amp;ldquo;true&amp;rdquo;，要么全部为 &amp;ldquo;false&amp;rdquo;。当掩码内的所有值都相同时，我们就得到了一个简单的布尔值，要么为真，要么为假。这可以用来跳过部分代码，或使用普通的条件分支：if、switch、continue 和 break 等。&lt;/p>
&lt;p>在 SIMD-Framework 中，使用的是 &lt;code>horizontal_or(mask)&lt;/code>函数（封装了&lt;code>_xxx_testz_xx&lt;/code>）。该函数检查掩码内是否有任何值为真，如果存在真值则返回 true，否则返回 false。&lt;/p>
&lt;div class="notice notice-note" >
&lt;div class="notice-title">&lt;svg t="1705946198814" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="23141" width="200" height="200">&lt;path d="M195.541333 739.029333C151.594667 692.352 128 640 128 555.136c0-149.333333 104.832-283.178667 257.28-349.354667l38.101333 58.794667c-142.293333 76.970667-170.112 176.853333-181.205333 239.829333 22.912-11.861333 52.906667-16 82.304-13.269333 76.970667 7.125333 137.642667 70.314667 137.642667 148.864a149.333333 149.333333 0 0 1-149.333334 149.333333 165.162667 165.162667 0 0 1-117.248-50.304z m426.666667 0C578.261333 692.352 554.666667 640 554.666667 555.136c0-149.333333 104.832-283.178667 257.28-349.354667l38.101333 58.794667c-142.293333 76.970667-170.112 176.853333-181.205333 239.829333 22.912-11.861333 52.906667-16 82.304-13.269333 76.970667 7.125333 137.642667 70.314667 137.642666 148.864a149.333333 149.333333 0 0 1-149.333333 149.333333 165.162667 165.162667 0 0 1-117.248-50.304z" p-id="23142" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>代码示例 2：使用 horizontal_or(mask) 函数判断掩码内是否有任何值为真，减少分支计算&lt;/p>&lt;/div>
&lt;pre>&lt;code class="language-cpp">v8f result(0.0f);
for (int i = 0; i &amp;lt; 2000; i++)
{
v8f test(1.4f, 3.3f, -12.5f, -33.4f, 7.9f, -70.2f, 15.1f, 22.6f);
test += ((float)i) / 100.0f;
if (horizontal_or(test &amp;gt;= 38.0f))
{
result += if_select(test &amp;gt;= 38.0f, slowFunction(i), test);
}
else
{
// 全为 false，不需要执行 slowFunction，直接加上 test 向量即可
result += test;
}
}
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>通过使用 &lt;code>horizontal_or&lt;/code> ，还可以提前跳出循环。自动向量化无法实现这种优化，但手动向量化可以，而且是首选。&lt;/li>
&lt;/ul>
&lt;div class="notice notice-note" >
&lt;div class="notice-title">&lt;svg t="1705946198814" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="23141" width="200" height="200">&lt;path d="M195.541333 739.029333C151.594667 692.352 128 640 128 555.136c0-149.333333 104.832-283.178667 257.28-349.354667l38.101333 58.794667c-142.293333 76.970667-170.112 176.853333-181.205333 239.829333 22.912-11.861333 52.906667-16 82.304-13.269333 76.970667 7.125333 137.642667 70.314667 137.642667 148.864a149.333333 149.333333 0 0 1-149.333334 149.333333 165.162667 165.162667 0 0 1-117.248-50.304z m426.666667 0C578.261333 692.352 554.666667 640 554.666667 555.136c0-149.333333 104.832-283.178667 257.28-349.354667l38.101333 58.794667c-142.293333 76.970667-170.112 176.853333-181.205333 239.829333 22.912-11.861333 52.906667-16 82.304-13.269333 76.970667 7.125333 137.642667 70.314667 137.642666 148.864a149.333333 149.333333 0 0 1-149.333333 149.333333 165.162667 165.162667 0 0 1-117.248-50.304z" p-id="23142" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>代码示例 3：使用 horizontal_or 提前跳出循环，该程序需要同时进行 8 次并行模拟，以 200 个回合为限，计算最大连击得分。一旦在任何一次并行模拟中得分超过 1700 分，就结束模拟，并返回最大得分（一个浮点数值，不是包含所有得分的整个向量，只是最大值）和获得该得分的回合。&lt;/p>&lt;/div>
&lt;pre>&lt;code class="language-cpp">#pragma GCC optimize(&amp;quot;O3&amp;quot;, &amp;quot;unroll-loops&amp;quot;, &amp;quot;omit-frame-pointer&amp;quot;, &amp;quot;inline&amp;quot;)
#pragma GCC option(&amp;quot;arch=native&amp;quot;, &amp;quot;tune=native&amp;quot;, &amp;quot;no-zeroupper&amp;quot;)
#pragma GCC target(&amp;quot;avx&amp;quot;)
#include &amp;lt;bits/stdc++.h&amp;gt;
#include &amp;lt;x86intrin.h&amp;gt;
#include &amp;quot;v8f.h&amp;quot;
using namespace std;
int validateResult(const int &amp;amp;turn, const float &amp;amp;bestScore)
{
cout &amp;lt;&amp;lt; &amp;quot;Turn:&amp;quot; &amp;lt;&amp;lt; turn &amp;lt;&amp;lt; &amp;quot; bestScore:&amp;quot; &amp;lt;&amp;lt; std::setprecision(10) &amp;lt;&amp;lt; bestScore &amp;lt;&amp;lt; endl;
if (turn != 133)
{
cout &amp;lt;&amp;lt; &amp;quot;ERROR, Expected turn exit at 133 != &amp;quot; &amp;lt;&amp;lt; turn &amp;lt;&amp;lt; endl;
return -1;
}
if (bestScore != 1707.318481f)
{
cout &amp;lt;&amp;lt; &amp;quot;ERROR, Expected a bestScore of 1707.318481f != &amp;quot; &amp;lt;&amp;lt; std::setprecision(10)
&amp;lt;&amp;lt; bestScore &amp;lt;&amp;lt; endl;
return -1;
}
return 0;
}
int main()
{
int turn = 0;
v8f Scores(1.0f, 3.0f, 7.0f, 13.4f, 22.7f, 0.01f, 4.556f, 9.7f);
for (turn = 0; turn &amp;lt; 200; ++turn)
{
Scores += ((float)(turn) / 15.0f);
if (turn == 40)
{
Scores *= Scores / 15.0f + 2.0f;
}
if (turn == 70)
{
Scores += if_select(Scores &amp;lt; 430.0f, 850.0f, 120.0f);
}
// 利用 horizontal_or 提前退出循环
if (horizontal_or(Scores &amp;gt;= 1700.0f))
{
break;
}
}
cout &amp;lt;&amp;lt; &amp;quot;Scores: &amp;quot; &amp;lt;&amp;lt; Scores &amp;lt;&amp;lt; endl;
float bestScore = 0.0f;
// 遍历获取最大分量
for (int i = 0; i &amp;lt; 8; i++)
{
float score = get(Scores, i);
if (bestScore &amp;lt; score)
{
bestScore = score;
}
}
return validateResult(turn, bestScore);
}
&lt;/code>&lt;/pre>
&lt;h2 id="七数据对齐">七、数据对齐&lt;/h2>
&lt;p>数据对齐是一种强制编译器在特定字节边界的内存中创建数据对象的方法。这样做的目的是为了提高从处理器加载和存储数据的效率。无需赘述，当数据可以在特定字节边界的内存地址之间移动时，处理器就可以高效地移动数据。对于支持英特尔® AVX-512 指令的英特尔® 处理器来说，当数据起始地址位于 64 字节边界时，内存移动效果最佳。因此，需要强制编译器创建起始地址为 64 字节模的数据对象。&lt;/p>
&lt;p>除了在对齐边界上创建数据（使基指针对齐）外，编译器还能在已知数据访问（包括基指针和索引）对齐 64 字节时执行优化。在通常情况下，如果没有用户的帮助，编译器并不知道循环内部的数据是对齐的。这可能迫使编译器在生成代码时采取保守做法，从而影响性能。因此还必须通过编译指示(C/C++)或指令(Fortran)、选项(如 Fortran 中的-Align array64byte)以及子句/属性的组合来通知编译器进行对齐，以便英特尔编译器能够生成最佳代码。&lt;/p>
&lt;p>总而言之，需要两个步骤：&lt;/p>
&lt;ol>
&lt;li>数据对齐&lt;/li>
&lt;li>在性能关键区域(使用数据的区域)中使用 pragma/directives/clauses 来告诉编译器内存访问是对齐的&lt;/li>
&lt;/ol>
&lt;h3 id="1-数据对齐">1. 数据对齐&lt;/h3>
&lt;p>调整数据以提高应用性能非常重要。这通常意味着两点：&lt;/p>
&lt;ol>
&lt;li>在为数组（或指针）分配空间时对齐基指针&lt;/li>
&lt;li>确保每个向量化循环（对于每个线程）的起始索引具有良好的对齐属性&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>对齐静态数组（基指针）&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>静态数组的对齐十分简单，不过在 Windows 上与 Linux 上的声明有所区别，以 64 字节边界上静态声明 1000 元素单精度浮点数组为例&lt;/li>
&lt;li>在 Windows 上，使用 &lt;code>__declspec(align(64))&lt;/code> 修饰符：&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-c">__declspec(align(64)) float a[1000];
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>在 Linux 上，使用 &lt;code>__attribute__((aligned(64)))&lt;/code> 修饰符：&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-c">float a[1000] __attribute__((aligned(64)));
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>对齐动态数据&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>动态数据的对齐相对复杂，需要使用特殊的内存分配函数，如 &lt;code>_mm_malloc&lt;/code> 和 &lt;code>_mm_free&lt;/code> 来替代 &lt;code>malloc&lt;/code> 和 &lt;code>free&lt;/code> 函数。其中，这些函数的第二个参数是对齐参数（以字节为单位），比如 &lt;code>mm_malloc(p, 64)&lt;/code> 返回的数据将是 64 字节对齐的。&lt;/li>
&lt;/ul>
&lt;div class="notice notice-info" >
&lt;div class="notice-title">&lt;svg t="1705940100069" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6252" width="200" height="200">&lt;path d="M512 64C264.6 64 64 264.6 64 512s200.6 448 448 448 448-200.6 448-448S759.4 64 512 64z m32 664c0 4.4-3.6 8-8 8h-48c-4.4 0-8-3.6-8-8V456c0-4.4 3.6-8 8-8h48c4.4 0 8 3.6 8 8v272z m-32-344c-26.5 0-48-21.5-48-48s21.5-48 48-48 48 21.5 48 48-21.5 48-48 48z" p-id="6253" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>对于动态分配的 C/C++ 数组，仅仅在创建时使用 mm_malloc 对齐数据是不够的（这是一个必要条件），还需要在相关循环之前添加一个__assume_aligned(a, 64) 形式的子句。如果没有这一步，编译器将无法检测使用此类数组进行访问时的最佳对齐方式。&lt;/p>&lt;/div>
&lt;ul>
&lt;li>在 C++17 中，还可以使用 &lt;code>std::aligned_alloc&lt;/code> 函数来分配对齐的内存，但是这个函数只能在 C++17 中使用，而且只能在 Linux 上使用。使用方式如下：&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-cpp">float *a = std::static_cast&amp;lt;float *&amp;gt;std::aligned_alloc(64, 1000 * sizeof(float));
// 使用完毕后，需要释放内存
std::free(a);
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>对齐循环索引&lt;/strong>&lt;/p>
&lt;p>对于内存访问形式为 &lt;strong>a[i+n1]&lt;/strong> 的循环，必须满足特定的对齐要求。具体来说，用户必须确保 （i-loop 的下界 + n1）是 16 的倍数（假设数据类型为 float）。&lt;/p>
&lt;p>此外，除非在编译时信息可以在静态情况下获得（例如访问形式为 &lt;strong>x[i]&lt;/strong> ，并且所有线程的循环下界都是常数 0，或者在循环内部存在形式为 &lt;strong>b[i+16*k]&lt;/strong> 的访问），用户还必须通知编译器关于这个对齐要求。否则，这一步还需要在循环前添加一个 &lt;strong>__assume(n1%16==0)&lt;/strong> 或者 &lt;strong>#pragma vector aligned&lt;/strong> 的语句（ &lt;strong>仅限于 Windows 平台&lt;/strong> ）。以下是一个不满足数据对齐要求的例子：&lt;/p>
&lt;pre>&lt;code class="language-cpp">#define N 1000
float a[N] __attribute__((aligned(64)));
void process_array()
{
for (int i = 0; i &amp;lt; N; i++)
{
float result = a[i + 4]; // 访问 a[i+n1]，其中 n1 = 4
// 其它计算操作...
}
}
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>如果我们要确保内存访问的性能最佳，我们需要确保 i 和 n1 的组合是对齐的，以便在向量化指令集中能够更有效地执行。在上面的代码中，循环的下界是 i 的初始值 0 ，所以 (0 + 4) 不是 16 的倍数。为了满足对齐要求，我们需要进行调整，并且通知编译器这个对齐属性。&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-cpp">#define N 1000
float a[N] __attribute__((aligned(64)));
void process_array(int n1)
{
for (int i = 0; i &amp;lt; N; i += 16) // 调整循环的步长。
{
__assume((n1 % 16) == 0);
float result = a[i + n1]; // 访问 a[i+n1]
// 其它计算操作...
}
}
&lt;/code>&lt;/pre>
&lt;h3 id="2-通知编译器数据对齐">2. 通知编译器数据对齐&lt;/h3>
&lt;p>既然已经对齐了数据，那么在程序中实际使用数据时，就有必要告知编译器这些数据是对齐的。例如，将数据作为参数传递给性能关键的函数或子程序时，编译器如何知道参数是对齐的还是未对齐的？例如，数据通常在一个源文件中声明，但在许多其他源文件中使用。因此，这一信息必须由用户提供，因为编译器往往没有关于参数的信息。&lt;/p>
&lt;p>有两种方法可以告知编译器数据对齐情况。 一种方法是使用 &lt;strong>OpenMP SIMD ALIGNED&lt;/strong> 子句通知编译器在使用数据时的数据对齐情况。另一种方法则是使用英特尔专有子句在代码中指定数据对齐方式。&lt;/p>
&lt;p>编译器要为 i 循环内的（浮点数组）内存访问（如 &lt;strong>a[i+n1]&lt;/strong> 和 &lt;strong>X[i]&lt;/strong>）生成对齐的加载/存储，就必须知道：&lt;/p>
&lt;ol>
&lt;li>基数指针（a 和 X）已对齐。对于静态数组，可以使用上面讨论的技术实现对齐，例如使用 &lt;code>__declspec(align(64))&lt;/code> 。对于动态分配的数组，仅仅在创建时使用 &lt;code>mm_malloc&lt;/code> 或 &lt;code>aligned_alloc&lt;/code> 对齐数据是不够的，还需要如下所示的子句 &lt;code>__assume_aligned(a, 64)&lt;/code> 。&lt;/li>
&lt;li>编译器必须知道（i-loop 的下界 + n1）是 16 的倍数（假设数据类型为 float）。如果循环下界为 0 ，那么所需的信息就是 n1 是 16 的倍数。一种方法是添加一个 &lt;strong>__assume(n1%16==0)&lt;/strong> 形式的子句。&lt;/li>
&lt;/ol>
&lt;div class="notice notice-note" >
&lt;div class="notice-title">&lt;svg t="1705946198814" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="23141" width="200" height="200">&lt;path d="M195.541333 739.029333C151.594667 692.352 128 640 128 555.136c0-149.333333 104.832-283.178667 257.28-349.354667l38.101333 58.794667c-142.293333 76.970667-170.112 176.853333-181.205333 239.829333 22.912-11.861333 52.906667-16 82.304-13.269333 76.970667 7.125333 137.642667 70.314667 137.642667 148.864a149.333333 149.333333 0 0 1-149.333334 149.333333 165.162667 165.162667 0 0 1-117.248-50.304z m426.666667 0C578.261333 692.352 554.666667 640 554.666667 555.136c0-149.333333 104.832-283.178667 257.28-349.354667l38.101333 58.794667c-142.293333 76.970667-170.112 176.853333-181.205333 239.829333 22.912-11.861333 52.906667-16 82.304-13.269333 76.970667 7.125333 137.642667 70.314667 137.642666 148.864a149.333333 149.333333 0 0 1-149.333333 149.333333 165.162667 165.162667 0 0 1-117.248-50.304z" p-id="23142" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>代码示例 4： 在 Windows 上使用 __assume_aligned 和 __assume 指令来告知编译器数据对齐情况。&lt;/p>&lt;/div>
&lt;pre>&lt;code class="language-cpp">// compile options: -O3 -xcore-avx512 -qopt-report-phase=vec -qopt-report=5 -qopt-report-file=stdout -restrict -c
// 该编译指令将生成一个名为 stdout 的文件，其中包含有关向量化的信息。
// restrict 关键字：提示编译器：在该指针的生命周期内，其指向的对象不会被别的指针所引用。
#define N 1000
__declspec(align(64)) float X[N], X2[N];
void foo(float * restrict a, int n, int n1, int n2)
{
__assume_aligned(a, 64);
__assume((n1 % 16) == 0);
__assume((n2 % 16) == 0);
for (int i = 0; i &amp;lt; n; i++)
{
X[i] += a[i] + a[i + n1] + a[i - n1] + a[i + n2] + a[i - n2];
}
for (int i = 0; i &amp;lt; n; i++)
{
X2[i] += X[i] * a[i];
}
}
&lt;/code>&lt;/pre>
&lt;h2 id="八总结">八、总结&lt;/h2>
&lt;p>本文主要介绍了 SIMD 的基本概念，以及 SIMD 的优化思路，最后通过一些简单的示例代码，介绍了 SIMD 的使用方法。主要内容如下：&lt;/p>
&lt;ul>
&lt;li>在代码中使用 SSE 和 AVX 指令的硬件和软件要求。&lt;/li>
&lt;li>可用的向量数据类型。&lt;/li>
&lt;li>有关如何检查自动向量化使用情况的信息，以及有关可自动向量化的循环的提示。&lt;/li>
&lt;li>C++中的 SSE/AVX 框架。&lt;/li>
&lt;li>掩码和条件加载。&lt;/li>
&lt;li>数据流控制。&lt;/li>
&lt;li>数据对齐。&lt;/li>
&lt;/ul>
&lt;p>SIMD 的优势和劣势：&lt;/p>
&lt;p>&lt;strong>优势&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>与线性代码相比，潜在的性能提升 300%到 600%。&lt;/li>
&lt;li>与在 GPU 级别进行向量化编程的 CUDA 相似。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>劣势&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>性能取决于运行硬件。&lt;/li>
&lt;li>当存在大量数据加载和卸载时，性能不佳。&lt;/li>
&lt;li>数据流会变得很难控制，而且向量内每个值的执行时间都会影响整个向量的执行时间。在所有值都满足退出条件之前，不能提前退出。&lt;/li>
&lt;li>编码复杂。&lt;/li>
&lt;li>缺乏内置函数： 三角函数、随机数、整数除法等。&lt;/li>
&lt;/ul>
&lt;p>总的来说，SIMD 的优势远大于劣势，SIMD 的使用可以大大提高程序的性能，但是需要注意的是，SIMD 的使用需要编码复杂，而且需要硬件支持，所以在使用 SIMD 之前，需要对程序进行分析，判断是否有必要使用 SIMD。&lt;/p>
&lt;h2 id="参考资料">参考资料&lt;/h2>
&lt;p>[1] &lt;a class="link" href="https://www.codeproject.com/Articles/874396/Introduction-to-SIMD-instructions" target="_blank" rel="noopener" >Introduction to SIMD instructions
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/p>
&lt;p>[2] &lt;a class="link" href="https://www.agner.org/optimize/instruction_tables.pdf" target="_blank" rel="noopener" >Agner Fog&amp;rsquo;s instruction tables
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/p>
&lt;p>[3] &lt;a class="link" href="https://software.intel.com/sites/default/files/m/4/8/8/2/a/31848-CompilerAutovectorizationGuide.pdf" target="_blank" rel="noopener" >Intel C++编译器的矢量化
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/p>
&lt;p>[4] &lt;a class="link" href="https://software.intel.com/sites/landingpage/IntrinsicsGuide" target="_blank" rel="noopener" >Intel Intrinsics Guide
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/p>
&lt;p>[5] &lt;a class="link" href="https://db.in.tum.de/~finis/x86-intrin-cheatsheet-v2.2.pdf?lang=en" target="_blank" rel="noopener" >x86 内置函数 Cheet Sheet
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/p>
&lt;p>[6] &lt;a class="link" href="https://libdivide.com/" target="_blank" rel="noopener" >libdivide
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/p>
&lt;p>[7] &lt;a class="link" href="https://software.intel.com/en-us/articles/avoiding-avx-sse-transition-penalties" target="_blank" rel="noopener" >Avoiding AVX-SSE Transition Penalties
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/p>
&lt;p>[8] &lt;a class="link" href="https://stackoverflow.com/questions/41303780/why-is-this-sse-code-6-times-slower-without-vzeroupper-on-skylake" target="_blank" rel="noopener" >Why is this SSE code 6 times slower without VZEROUPPER on Skylake?
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/p>
&lt;p>[9] &lt;a class="link" href="https://www.intel.com/content/www/us/en/developer/articles/technical/data-alignment-to-assist-vectorization.html" target="_blank" rel="noopener" >Intel Data Alignment Guide
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/p></description></item></channel></rss>