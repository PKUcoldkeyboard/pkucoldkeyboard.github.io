<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>MySQL on Cuterwrite's Blog</title><link>https://cuterwrite.top/tags/mysql/</link><description>Recent content in MySQL on Cuterwrite's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>cuterwrite</copyright><lastBuildDate>Tue, 04 May 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://cuterwrite.top/tags/mysql/index.xml" rel="self" type="application/rss+xml"/><item><title>计算机基础知识点总结（数据库系统 + MySQL + Redis）</title><link>https://cuterwrite.top/p/database-system/</link><pubDate>Tue, 04 May 2021 00:00:00 +0000</pubDate><guid>https://cuterwrite.top/p/database-system/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/windmills-5614160_1920.7f194ofsigg0.webp" alt="Featured image of post 计算机基础知识点总结（数据库系统 + MySQL + Redis）" />&lt;h1 id="一数据库系统原理">一、数据库系统原理&lt;/h1>
&lt;h2 id="1-事务">1 事务&lt;/h2>
&lt;h3 id="11-概念">1.1 概念&lt;/h3>
&lt;p>事务指的是满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。&lt;/p>
&lt;h3 id="12-acid">1.2 ACID&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>原子性&lt;/p>
&lt;p>事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。&lt;/p>
&lt;p>回滚可以用回滚日志（Undo Log）来实现，回滚日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>一致性&lt;/p>
&lt;p>数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对同一个数据的读取结果都是相同的。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>隔离性&lt;/p>
&lt;p>一个事务所做的修改在最终提交以前，对其它事务是不可见的。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>持久性&lt;/p>
&lt;p>一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。系统发生崩溃可以用重做日志（Redo Log）进行恢复，从而实现持久性。与回滚日志记录数据的逻辑修改不同，重做日志记录的是数据页的物理修改。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/image-20191207210437023.png" width="90%" loading="lazy">
&lt;/figure>
&lt;hr>
&lt;p>原因：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>只有满足一致性，事务的执行结果才是正确的。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>事务满足持久化是为了能应对系统崩溃的情况。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="13-autocommit">1.3 AUTOCOMMIT&lt;/h3>
&lt;p>MySQL 默认采用自动提交模式。也就是说，如果不显式使用&lt;code>START TRANSACTION&lt;/code> 语句来开始一个事务，那么每个查询操作都会被当做一个事务并自动提交。&lt;/p>
&lt;h2 id="2-并发一致性问题">2 并发一致性问题&lt;/h2>
&lt;h3 id="21-丢失修改">2.1 丢失修改&lt;/h3>
&lt;p>丢失修改指一个事务的更新操作被另外一个事务的更新操作替换。一般在现实生活中常会遇到，例如：T&lt;!-- raw HTML omitted -->1&lt;!-- raw HTML omitted --> 和 T&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted --> 两个事务都对一个数据进行修改，T&lt;!-- raw HTML omitted -->1&lt;!-- raw HTML omitted --> 先修改并提交生效，T&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted --> 随后修改，T&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted --> 的修改覆盖了 T&lt;!-- raw HTML omitted -->1&lt;!-- raw HTML omitted --> 的修改。&lt;/p>
&lt;figure>&lt;img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/image-20191207221744244.png" width="90%" loading="lazy">
&lt;/figure>
&lt;h3 id="22-读脏数据">2.2 读脏数据&lt;/h3>
&lt;p>读脏数据指在不同的事务下，当前事务可以读到另外事务未提交的数据。例如：T&lt;!-- raw HTML omitted -->1&lt;!-- raw HTML omitted --> 修改一个数据但未提交，T&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted --> 随后读取这个数据。如果 T&lt;!-- raw HTML omitted -->1&lt;!-- raw HTML omitted --> 撤销了这次修改，那么 T&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted --> 读取的数据是脏数据。&lt;/p>
&lt;figure>&lt;img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/image-20191207221920368.png" width="90%" loading="lazy">
&lt;/figure>
&lt;h3 id="23-不可重复读">2.3 不可重复读&lt;/h3>
&lt;p>不可重复读指在一个事务内多次读取同一数据集合。在这一事务还未结束前，另一事务也访问了该同一数据集合并做了修改，由于第二个事务的修改，第一次事务的两次读取的数据可能不一致。例如：T&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted --> 读取一个数据，T&lt;!-- raw HTML omitted -->1&lt;!-- raw HTML omitted --> 对该数据做了修改。如果 T&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted --> 再次读取这个数据，此时读取的结果和第一次读取的结果不同。&lt;/p>
&lt;figure>&lt;img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/image-20191207222102010.png" width="90%" loading="lazy">
&lt;/figure>
&lt;h3 id="24-幻影读">2.4 幻影读&lt;/h3>
&lt;p>幻读本质上也属于不可重复读的情况，T&lt;!-- raw HTML omitted -->1&lt;!-- raw HTML omitted --> 读取某个范围的数据，T&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted --> 在这个范围内插入新的数据，T&lt;!-- raw HTML omitted -->1&lt;!-- raw HTML omitted --> 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。&lt;/p>
&lt;figure>&lt;img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/image-20191207222134306.png" width="90%" loading="lazy">
&lt;/figure>
&lt;h2 id="3-封锁">3 封锁&lt;/h2>
&lt;h3 id="31-封锁粒度">3.1 封锁粒度&lt;/h3>
&lt;p>MySQL 中提供了两种封锁粒度：行级锁以及表级锁。&lt;/p>
&lt;p>应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。&lt;/p>
&lt;p>但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。因此封锁粒度越小，系统开销就越大。&lt;/p>
&lt;p>在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。&lt;/p>
&lt;h3 id="32-封锁类型">3.2 封锁类型&lt;/h3>
&lt;h4 id="321-读写锁">3.2.1 读写锁&lt;/h4>
&lt;ul>
&lt;li>互斥锁（Exclusive），简写为 X 锁，又称写锁。&lt;/li>
&lt;li>共享锁（Shared），简写为 S 锁，又称读锁。&lt;/li>
&lt;/ul>
&lt;p>有以下两个规定：&lt;/p>
&lt;ul>
&lt;li>一个事务对数据对象 A 加了 X 锁，就可以对 A 进行读取和更新。加锁期间其它事务不能对 A 加任何锁。&lt;/li>
&lt;li>一个事务对数据对象 A 加了 S 锁，可以对 A 进行读取操作，但是不能进行更新操作。加锁期间其它事务能对 A 加 S 锁，但是不能加 X 锁。&lt;/li>
&lt;/ul>
&lt;p>锁的兼容关系如下：&lt;/p>
&lt;figure>&lt;img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/image-20191207213523777.png" width="90%" loading="lazy">
&lt;/figure>
&lt;h4 id="322-意向锁">3.2.2 意向锁&lt;/h4>
&lt;p>使用意向锁（Intention Locks）可以更容易地支持多粒度封锁。&lt;/p>
&lt;p>在存在行级锁和表级锁的情况下，事务 T 想要对表 A 加 X 锁，就需要先检测是否有其它事务对表 A 或者表 A 中的任意一行加了锁，那么就需要对表 A 的每一行都检测一次，这是非常耗时的。&lt;/p>
&lt;p>意向锁在原来的 X/S 锁之上引入了 IX/IS，IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。有以下两个规定：&lt;/p>
&lt;ul>
&lt;li>一个事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁；&lt;/li>
&lt;li>一个事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。&lt;/li>
&lt;/ul>
&lt;p>通过引入意向锁，事务 T 想要对表 A 加 X 锁，只需要先检测是否有其它事务对表 A 加了 X/IX/S/IS 锁，如果加了就表示有其它事务正在使用这个表或者表中某一行的锁，因此事务 T 加 X 锁失败。&lt;/p>
&lt;p>各种锁的兼容关系如下：&lt;/p>
&lt;figure>&lt;img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/image-20191207214442687.png" width="90%" loading="lazy">
&lt;/figure>
&lt;p>解释如下：&lt;/p>
&lt;ul>
&lt;li>任意 IS/IX 锁之间都是兼容的，因为它们只表示想要对表加锁，而不是真正加锁；&lt;/li>
&lt;li>这里兼容关系针对的是表级锁，而表级的 IX 锁和行级的 X 锁兼容，两个事务可以对两个数据行加 X 锁。（事务 T&lt;!-- raw HTML omitted -->1&lt;!-- raw HTML omitted --> 想要对数据行 R&lt;!-- raw HTML omitted -->1&lt;!-- raw HTML omitted --> 加 X 锁，事务 T&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted --> 想要对同一个表的数据行 R&lt;!-- raw HTML omitted -->2&lt;!-- raw HTML omitted --> 加 X 锁，两个事务都需要对该表加 IX 锁，但是 IX 锁是兼容的，并且 IX 锁与行级的 X 锁也是兼容的，因此两个事务都能加锁成功，对同一个表中的两个数据行做修改。）&lt;/li>
&lt;/ul>
&lt;h3 id="33-封锁协议">3.3 封锁协议&lt;/h3>
&lt;h4 id="331-三级封锁协议">3.3.1 三级封锁协议&lt;/h4>
&lt;ol>
&lt;li>一级封锁协议：事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。可以解决丢失修改问题，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。&lt;/li>
&lt;li>二级封锁协议：在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。可以解决读脏数据问题，因为如果一个事务在对数据 A 进行修改，根据 1 级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据。&lt;/li>
&lt;li>三级封锁协议：在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。可以解决不可重复读的问题，因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变。&lt;/li>
&lt;/ol>
&lt;h4 id="332-二段锁协议">3.3.2 二段锁协议&lt;/h4>
&lt;p>加锁和解锁分为两个阶段进行。&lt;/p>
&lt;p>可串行化调度是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。串行执行的事务互不干扰，不会出现并发一致性问题。&lt;/p>
&lt;p>事务遵循两段锁协议是保证可串行化调度的充分条件。例如以下操作满足两段锁协议，它是可串行化调度。&lt;/p>
&lt;h3 id="34-mysql-隐式与显示锁定">3.4 MySQL 隐式与显示锁定&lt;/h3>
&lt;p>MySQL 的 InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。&lt;/p>
&lt;p>InnoDB 也可以使用特定的语句进行显示锁定：&lt;/p>
&lt;pre>&lt;code class="language-sql">SELECT ... LOCK In SHARE MODE;
SELECT ... FOR UPDATE;
&lt;/code>&lt;/pre>
&lt;h2 id="4-隔离级别">4 隔离级别&lt;/h2>
&lt;h3 id="41-未提交读">4.1 未提交读&lt;/h3>
&lt;p>事务中的修改，即使没有提交，对其它事务也是可见的。&lt;/p>
&lt;h3 id="42-提交读">4.2 提交读&lt;/h3>
&lt;p>一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。&lt;/p>
&lt;h3 id="43-可重复读">4.3 可重复读&lt;/h3>
&lt;p>保证在同一个事务中多次读取同一数据的结果是一样的。&lt;/p>
&lt;h3 id="44-可串行化">4.4 可串行化&lt;/h3>
&lt;p>强制事务串行执行，这样多个事务互不干扰，不会出现并发一致性问题。&lt;/p>
&lt;p>该隔离级别需要加锁实现，因为要使用加锁机制保证同一时间只有一个事务执行，也就是保证事务串行执行。&lt;/p>
&lt;hr>
&lt;figure>&lt;img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/image-20191207223400787.png" width="90%" loading="lazy">
&lt;/figure>
&lt;h2 id="5-多版本并发控制">5 多版本并发控制&lt;/h2>
&lt;p>多版本并发控制（Multi-Version Concurrency Control, MVCC）是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。而未提交读隔离级别总是读取最新的数据行，要求很低，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。&lt;/p>
&lt;h3 id="51-基本思想">5.1 基本思想&lt;/h3>
&lt;p>在封锁一节中提到，加锁能解决多个事务同时执行时出现的并发一致性问题。在实际场景中读操作往往多于写操作，因此又引入了读写锁来避免不必要的加锁操作，例如读和读没有互斥关系。读写锁中读和写操作仍然是互斥的，而 MVCC 利用了多版本的思想，写操作更新最新的版本快照，而读操作去读旧版本快照，没有互斥关系，这一点和 CopyOnWrite 类似。&lt;/p>
&lt;p>在 MVCC 中事务的修改操作（DELETE、INSERT、UPDATE）会为数据行新增一个版本快照。&lt;/p>
&lt;p>脏读和不可重复读最根本的原因是事务读取到其它事务未提交的修改。在事务进行读取操作时，为了解决脏读和不可重复读问题，MVCC 规定只能读取已经提交的快照。当然一个事务可以读取自身未提交的快照，这不算是脏读。&lt;/p>
&lt;h3 id="52-版本号">5.2 版本号&lt;/h3>
&lt;ul>
&lt;li>系统版本号 SYS_ID：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。&lt;/li>
&lt;li>事务版本号 TRX_ID ：事务开始时的系统版本号。&lt;/li>
&lt;/ul>
&lt;h3 id="53-undo-日志">5.3 Undo 日志&lt;/h3>
&lt;p>MVCC 的多版本指的是多个版本的快照，快照存储在 Undo 日志中，该日志通过回滚指针 ROLL_PTR 把一个数据行的所有快照连接起来。&lt;/p>
&lt;p>例如在 MySQL 创建一个表 t，包含主键 id 和一个字段 x。我们先插入一个数据行，然后对该数据行执行两次更新操作。&lt;/p>
&lt;pre>&lt;code class="language-sql">INSERT INTO t(id, x) VALUES(1, &amp;quot;a&amp;quot;);
UPDATE t SET x=&amp;quot;b&amp;quot; WHERE id=1;
UPDATE t SET x=&amp;quot;c&amp;quot; WHERE id=1;
&lt;/code>&lt;/pre>
&lt;p>因为没有使用 &lt;code>START TRANSACTION&lt;/code> 将上面的操作当成一个事务来执行，根据 MySQL 的 AUTOCOMMIT 机制，每个操作都会被当成一个事务来执行，所以上面的操作总共涉及到三个事务。快照中除了记录事务版本号 TRX_ID 和操作之外，还记录了一个 bit 的 DEL 字段，用于标记是否被删除。&lt;/p>
&lt;figure>&lt;img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/image-20191208164808217.png" width="90%" loading="lazy">
&lt;/figure>
&lt;p>INSERT、UPDATE、DELETE 操作会创建一个日志，并将事务版本号 TRX_ID 写入。DELETE 可以看成是一个特殊的 UPDATE，还会额外将 DEL 字段设置为 1。&lt;/p>
&lt;h3 id="54-readview">5.4 ReadView&lt;/h3>
&lt;p>MVCC 维护了一个 ReadView 结构，主要包含了当前系统未提交的事务列表 TRX_IDs {TRX_ID_1, TRX_ID_2, &amp;hellip;}，还有该列表的最小值 TRX_ID_MIN 和 TRX_ID_MAX。&lt;/p>
&lt;figure>&lt;img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/image-20191208171445674.png" width="90%" loading="lazy">
&lt;/figure>
&lt;p>在进行 SELECT 操作时，根据数据行快照的 TRX_ID 与 TRX_ID_MIN 和 TRX_ID_MAX 之间的关系，从而判断数据行快照是否可以使用：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>TRX_ID &amp;lt; TRX_ID_MIN，表示该数据行快照时在当前所有未提交事务之前进行更改的，因此可以使用。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>TRX_ID &amp;gt; TRX_ID_MAX，表示该数据行快照是在事务启动之后被更改的，因此不可使用。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>TRX_ID_MIN &amp;lt;= TRX_ID &amp;lt;= TRX_ID_MAX，需要根据隔离级别再进行判断：&lt;/p>
&lt;ul>
&lt;li>提交读：如果 TRX_ID 在 TRX_IDs 列表中，表示该数据行快照对应的事务还未提交，则该快照不可使用。否则表示已经提交，可以使用。&lt;/li>
&lt;li>可重复读：都不可以使用。因为如果可以使用的话，那么其它事务也可以读到这个数据行快照并进行修改，那么当前事务再去读这个数据行得到的值就会发生改变，也就是出现了不可重复读问题。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>在数据行快照不可使用的情况下，需要沿着 Undo Log 的回滚指针 ROLL_PTR 找到下一个快照，再进行上面的判断。&lt;/p>
&lt;h3 id="55-快照读与当前读">5.5 快照读与当前读&lt;/h3>
&lt;h4 id="551-快照读">5.5.1 快照读&lt;/h4>
&lt;p>MVCC 的 SELECT 操作是快照中的数据，不需要进行加锁操作。&lt;/p>
&lt;h4 id="552-当前读">5.5.2 当前读&lt;/h4>
&lt;p>MVCC 其它会对数据库进行修改的操作（INSERT、UPDATE、DELETE）需要进行加锁操作，从而读取最新的数据。可以看到 MVCC 并不是完全不用加锁，而只是避免了 SELECT 的加锁操作。&lt;/p>
&lt;h2 id="6-next-key-locks">6 Next-Key Locks&lt;/h2>
&lt;p>Next-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。&lt;/p>
&lt;p>MVCC 不能解决幻影读问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读（REPEATABLE READ）隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。&lt;/p>
&lt;h3 id="61-record-locks">6.1 Record Locks&lt;/h3>
&lt;p>锁定一个记录上的索引，而不是记录本身。&lt;/p>
&lt;p>如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。&lt;/p>
&lt;h3 id="62-gap-locks">6.2 Gap Locks&lt;/h3>
&lt;p>锁定索引之间的间隙，但是不包含索引本身。&lt;/p>
&lt;h3 id="63-next-key-locks">6.3 Next-Key Locks&lt;/h3>
&lt;p>它是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。它锁定一个前开后闭区间。&lt;/p>
&lt;h1 id="二mysql">二、MySQL&lt;/h1>
&lt;h2 id="1-索引">1 索引&lt;/h2>
&lt;h3 id="11-b树原理">1.1 B+树原理&lt;/h3>
&lt;h4 id="111-数据结构">1.1.1 数据结构&lt;/h4>
&lt;p>B Tree 指的是 Balance Tree，也就是平衡树。平衡树是一颗查找树，并且所有叶子节点位于同一层。&lt;/p>
&lt;p>B+ Tree 是基于 B Tree 和&lt;strong>叶子节点顺序访问指针&lt;/strong>进行实现，它具有 B Tree 的平衡性，并且通过顺序访问指针来提高&lt;strong>区间查询&lt;/strong>的性能。&lt;/p>
&lt;p>在 B+ Tree 中，一个节点中的 key 从左到右非递减排列，如果某个指针的左右相邻 key 分别是 key&lt;!-- raw HTML omitted -->i&lt;!-- raw HTML omitted --> 和 key&lt;!-- raw HTML omitted -->i+1&lt;!-- raw HTML omitted -->，且不为 null，则该指针指向节点的所有 key 大于等于 key&lt;!-- raw HTML omitted -->i&lt;!-- raw HTML omitted --> 且小于等于 key&lt;!-- raw HTML omitted -->i+1&lt;!-- raw HTML omitted -->。&lt;/p>
&lt;figure>&lt;img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/33576849-9275-47bb-ada7-8ded5f5e7c73.png" width="90%" loading="lazy">
&lt;/figure>
&lt;h4 id="112-操作">1.1.2. 操作&lt;/h4>
&lt;p>进行查找操作时，首先在根节点进行&lt;strong>二分查找&lt;/strong>，找到一个 key 所在的指针，然后递归地在指针所指向的节点进行查找。直到查找到叶子节点，然后在叶子节点上进行二分查找，找出 key 所对应的 data。&lt;/p>
&lt;p>插入删除操作会破坏平衡树的平衡性，因此在进行插入删除操作之后，需要对树进行&lt;strong>分裂、合并、旋转&lt;/strong>等操作来维护平衡性。&lt;/p>
&lt;h4 id="113-与红黑树的比较">1.1.3 与红黑树的比较&lt;/h4>
&lt;p>红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用 B+ Tree 作为索引结构，这是因为使用 B+ 树访问磁盘数据有更高的性能。&lt;/p>
&lt;p>（一）B+ 树有更低的树高&lt;/p>
&lt;p>平衡树的树高 O(h)=O(log&lt;!-- raw HTML omitted -->d&lt;!-- raw HTML omitted -->N)，其中 d 为每个节点的出度。红黑树的出度为 2，而 B+ Tree 的出度一般都非常大，所以红黑树的树高 h 很明显比 B+ Tree 大非常多。&lt;/p>
&lt;p>（二）磁盘访问原理&lt;/p>
&lt;p>操作系统一般将内存和磁盘分割成固定大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I/O 就能完全载入一个节点。&lt;/p>
&lt;p>如果数据不在同一个磁盘块上，那么通常需要移动制动手臂进行寻道，而制动手臂因为其物理结构导致了移动效率低下，从而增加磁盘数据读取时间。B+ 树相对于红黑树有更低的树高，进行寻道的次数与树高成正比，在同一个磁盘块上进行访问只需要很短的磁盘旋转时间，所以 B+ 树更适合磁盘数据的读取。&lt;/p>
&lt;p>（三）磁盘预读特性&lt;/p>
&lt;p>为了减少磁盘 I/O 操作，磁盘往往不是严格按需读取，而是每次都会预读。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，并且只需要很短的磁盘旋转时间，速度会非常快。并且可以利用预读特性，相邻的节点也能够被预先载入。&lt;/p>
&lt;h3 id="12-mysql-索引">1.2 MySQL 索引&lt;/h3>
&lt;h4 id="121-b树索引">1.2.1 B+树索引&lt;/h4>
&lt;p>是大多数 MySQL 存储引擎的默认索引类型。&lt;/p>
&lt;p>因为不再需要进行全表扫描，只需要对树进行搜索即可，所以查找速度快很多。&lt;/p>
&lt;p>因为 B+ Tree 的有序性，所以除了用于查找，还可以用于排序和分组。&lt;/p>
&lt;p>可以指定多个列作为索引列，多个索引列共同组成键。&lt;/p>
&lt;p>适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。&lt;/p>
&lt;p>InnoDB 的 B+Tree 索引分为主索引和辅助索引。主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。&lt;/p>
&lt;figure>&lt;img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/45016e98-6879-4709-8569-262b2d6d60b9.png" width="90%" loading="lazy">
&lt;/figure>
&lt;p>辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。&lt;/p>
&lt;figure>&lt;img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/7c349b91-050b-4d72-a7f8-ec86320307ea.png" width="90%" loading="lazy">
&lt;/figure>
&lt;h4 id="122-哈希索引">1.2.2 哈希索引&lt;/h4>
&lt;p>哈希索引能以 O(1) 时间进行查找，但是失去了有序性：&lt;/p>
&lt;ul>
&lt;li>无法用于排序与分组；&lt;/li>
&lt;li>只支持精确查找，无法用于部分查找和范围查找。&lt;/li>
&lt;/ul>
&lt;p>InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。&lt;/p>
&lt;h4 id="123-全文索引">1.2.3 全文索引&lt;/h4>
&lt;p>MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。&lt;/p>
&lt;p>查找条件使用 MATCH AGAINST，而不是普通的 WHERE。&lt;/p>
&lt;p>全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。&lt;/p>
&lt;p>InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。&lt;/p>
&lt;h4 id="124-空间数据索引">1.2.4 空间数据索引&lt;/h4>
&lt;p>MyISAM 存储引擎支持空间数据索引（R-Tree），可以用于地理数据存储。空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。&lt;/p>
&lt;p>必须使用 GIS 相关的函数来维护数据。&lt;/p>
&lt;h3 id="13-索引优化">1.3 索引优化&lt;/h3>
&lt;h4 id="131-独立的列">1.3.1. 独立的列&lt;/h4>
&lt;p>在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。&lt;/p>
&lt;p>例如下面的查询不能使用 actor_id 列的索引：&lt;/p>
&lt;pre>&lt;code class="language-sql">SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5;
&lt;/code>&lt;/pre>
&lt;h4 id="132-多列索引">1.3.2. 多列索引&lt;/h4>
&lt;p>在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把 actor_id 和 film_id 设置为多列索引。&lt;/p>
&lt;pre>&lt;code class="language-sql">SELECT film_id, actor_ id FROM sakila.film_actor
WHERE actor_id = 1 AND film_id = 1;
&lt;/code>&lt;/pre>
&lt;h4 id="133-索引列的顺序">1.3.3. 索引列的顺序&lt;/h4>
&lt;p>让选择性最强的索引列放在前面。&lt;/p>
&lt;p>索引的选择性是指：不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，每个记录的区分度越高，查询效率也越高。&lt;/p>
&lt;p>例如下面显示的结果中 customer_id 的选择性比 staff_id 更高，因此最好把 customer_id 列放在多列索引的前面。&lt;/p>
&lt;pre>&lt;code class="language-sql">SELECT COUNT(DISTINCT staff_id)/COUNT(*) AS staff_id_selectivity,
COUNT(DISTINCT customer_id)/COUNT(*) AS customer_id_selectivity,
COUNT(*)
FROM payment;
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-html"> staff_id_selectivity: 0.0001
customer_id_selectivity: 0.0373
COUNT(*): 16049
&lt;/code>&lt;/pre>
&lt;h4 id="134-前缀索引">1.3.4. 前缀索引&lt;/h4>
&lt;p>对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。&lt;/p>
&lt;p>前缀长度的选取需要根据索引选择性来确定。&lt;/p>
&lt;h4 id="135-覆盖索引">1.3.5. 覆盖索引&lt;/h4>
&lt;p>索引包含所有需要查询的字段的值。&lt;/p>
&lt;p>具有以下优点：&lt;/p>
&lt;ul>
&lt;li>索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。&lt;/li>
&lt;li>一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用（通常比较费时）。&lt;/li>
&lt;li>对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。&lt;/li>
&lt;/ul>
&lt;h3 id="14-索引的优点">1.4 索引的优点&lt;/h3>
&lt;ul>
&lt;li>大大减少了服务器需要扫描的数据行数。&lt;/li>
&lt;li>帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，不需要排序和分组，也就不需要创建临时表）。&lt;/li>
&lt;li>将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。&lt;/li>
&lt;/ul>
&lt;h3 id="15-索引的使用条件">1.5 索引的使用条件&lt;/h3>
&lt;ul>
&lt;li>对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效；&lt;/li>
&lt;li>对于中到大型的表，索引就非常有效；&lt;/li>
&lt;li>但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。&lt;/li>
&lt;/ul>
&lt;h3 id="16-mysql-里的索引类型">1.6 MySQL 里的索引类型&lt;/h3>
&lt;ul>
&lt;li>普通索引&lt;/li>
&lt;li>唯一索引&lt;/li>
&lt;li>主键索引&lt;/li>
&lt;li>组合索引&lt;/li>
&lt;li>全文索引&lt;/li>
&lt;/ul>
&lt;h3 id="17-聚簇索引和非聚簇索引">1.7 聚簇索引和非聚簇索引&lt;/h3>
&lt;ul>
&lt;li>聚簇索引也叫簇类索引，是一种对磁盘上实际数据重新组织以按指定的一个或多个列的值排序。（聚簇索引就是主键的一种术语）&lt;/li>
&lt;li>非聚簇索引，叶级页指向表中的记录，记录的物理顺序与逻辑顺序没有必然的联系。&lt;/li>
&lt;/ul>
&lt;p>或者：&lt;/p>
&lt;ul>
&lt;li>聚簇索引：规定存储在磁盘上的数据是连续的，这个连续是指&lt;strong>物理顺序就是连续&lt;/strong>的。&lt;/li>
&lt;li>非聚簇索引：既然聚簇索引是连续的，那非聚簇索引就是不连续的。索引的存储和数据的存储是分离的，也就是说找到了索引但没找到数据，需要根据索引上的值(主键)再次回表查询,非聚簇索引也叫做辅助索引。&lt;/li>
&lt;/ul>
&lt;p>举例：&lt;/p>
&lt;p>第一种，直接根据主键查询获取所有字段数据，此时主键是聚簇索引，因为主键对应的索引叶子节点存储了 id=1 的所有字段的值。&lt;/p>
&lt;pre>&lt;code class="language-sql">select * from student where id = 1
&lt;/code>&lt;/pre>
&lt;p>第二种，根据编号查询编号和名称，编号本身是一个唯一索引，但查询的列包含了学生编号和学生名称，当命中编号索引时，该索引的节点的数据存储的是主键 ID，需要根据主键 ID 重新查询一次，所以这种查询下 no 不是聚簇索引&lt;/p>
&lt;pre>&lt;code class="language-sql">select no,name from student where no = 'test'
&lt;/code>&lt;/pre>
&lt;p>第三种，我们根据编号查询编号（有人会问知道编号了还要查询？要，你可能需要验证该编号在数据库中是否存在），这种查询命中编号索引时，直接返回编号，因为所需要的数据就是该索引，不需要回表查询，这种场景下 no 是聚簇索引&lt;/p>
&lt;pre>&lt;code class="language-sql">select no from student where no = 'test'
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>总结&lt;/strong>&lt;/p>
&lt;p>主键一定是聚簇索引，MySQL 的 InnoDB 中一定有主键，即便研发人员不手动设置，则会使用 unique 索引，没有 unique 索引，则会使用数据库内部的一个行的 id 来当作主键索引,其它普通索引需要区分 SQL 场景，当 SQL 查询的列就是索引本身时，我们称这种场景下该普通索引也可以叫做聚簇索引，MyisAM 引擎没有聚簇索引。&lt;/p>
&lt;h3 id="18-回表查询">1.8 回表查询&lt;/h3>
&lt;p>要说回表查询，先要从 InnoDB 的索引实现说起。InnoDB 有两大类索引，一类是聚集索引(Clustered Index)，一类是非聚簇索引(Secondary Index)。&lt;/p>
&lt;p>InnoDB 的聚集索引：InnoDB 聚集索引的叶子节点存储行记录，因此 InnoDB 必须要有且只有一个聚集索引。&lt;/p>
&lt;p>1.如果表定义了 PK(Primary Key，主键)，那么 PK 就是聚集索引。&lt;/p>
&lt;p>2.如果表没有定义 PK，则第一个 NOT NULL UNIQUE 的列就是聚集索引。&lt;/p>
&lt;p>3.否则 InnoDB 会另外创建一个隐藏的 ROWID 作为聚集索引。&lt;/p>
&lt;p>这种机制使得基于 PK 的查询速度非常快，因为直接定位的行记录。&lt;/p>
&lt;p>InnoDB 的普通索引：InnoDB 普通索引的叶子节点存储主键 ID(MyISAM 则是存储的行记录头指针)。&lt;/p>
&lt;p>回表查询：先通过非聚簇索引查询主键 ID，再通过主键 ID 查询数据。&lt;/p>
&lt;h2 id="2-查询性能优化">2 查询性能优化&lt;/h2>
&lt;h3 id="21-explain">2.1 Explain&lt;/h3>
&lt;p>Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。&lt;/p>
&lt;p>比较重要的字段有：&lt;/p>
&lt;ul>
&lt;li>select_type : 查询类型，有简单查询、联合查询、子查询等&lt;/li>
&lt;li>key : 使用的索引&lt;/li>
&lt;li>rows : 扫描的行数&lt;/li>
&lt;/ul>
&lt;h3 id="22-优化数据访问">2.2 优化数据访问&lt;/h3>
&lt;h4 id="221-减少请求的数据量">2.2.1 减少请求的数据量&lt;/h4>
&lt;ul>
&lt;li>只返回必要的列：最好不要使用 SELECT * 语句。&lt;/li>
&lt;li>只返回必要的行：使用 LIMIT 语句来限制返回的数据。&lt;/li>
&lt;li>缓存重复查询的数据：使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。&lt;/li>
&lt;/ul>
&lt;h4 id="222-减少扫描的行数">2.2.2 减少扫描的行数&lt;/h4>
&lt;p>最有效的方式是使用索引来覆盖查询。&lt;/p>
&lt;h3 id="23-重构查询方式">2.3 重构查询方式&lt;/h3>
&lt;h4 id="231-切分大查询">2.3.1 切分大查询&lt;/h4>
&lt;p>一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。&lt;/p>
&lt;h4 id="232-分解大连接查询">2.3.2 分解大连接查询&lt;/h4>
&lt;p>将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处有：&lt;/p>
&lt;ul>
&lt;li>让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。&lt;/li>
&lt;li>分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。&lt;/li>
&lt;li>减少锁竞争；&lt;/li>
&lt;li>在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。&lt;/li>
&lt;li>查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。&lt;/li>
&lt;/ul>
&lt;h2 id="3-存储引擎">3 存储引擎&lt;/h2>
&lt;h3 id="31-innodb">3.1 InnoDB&lt;/h3>
&lt;p>是 MySQL 默认的事务型存储引擎，只有在需要它不支持的特性时，才考虑使用其它存储引擎。&lt;/p>
&lt;p>实现了四个标准的隔离级别，默认级别是可重复读（REPEATABLE READ）。在可重复读隔离级别下，通过多版本并发控制（MVCC）+ Next-Key Locking 防止幻影读。&lt;/p>
&lt;p>主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。&lt;/p>
&lt;p>内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。&lt;/p>
&lt;p>支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。&lt;/p>
&lt;h3 id="32-myisam">3.2 MyISAM&lt;/h3>
&lt;p>设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。&lt;/p>
&lt;p>提供了大量的特性，包括压缩表、空间数据索引等。&lt;/p>
&lt;p>不支持事务。&lt;/p>
&lt;p>不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入（CONCURRENT INSERT）。&lt;/p>
&lt;p>可以手工或者自动执行检查和修复操作，但是和事务恢复以及崩溃恢复不同，可能导致一些数据丢失，而且修复操作是非常慢的。&lt;/p>
&lt;p>如果指定了 DELAY_KEY_WRITE 选项，在每次修改执行完成时，不会立即将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作。&lt;/p>
&lt;h3 id="33-区别">3.3 区别&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>外键：InnoDB 支持外键。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>备份：InnoDB 支持在线热备份。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>其它特性：MyISAM 支持压缩表和空间数据索引。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="4-数据类型">4 数据类型&lt;/h2>
&lt;ul>
&lt;li>整型：tinyint、smallint、mediumint、int、bigint&lt;/li>
&lt;li>浮点数：float、double、decimal&lt;/li>
&lt;li>字符串：char、varchar&lt;/li>
&lt;li>时间和日期：datetime、timestamp&lt;/li>
&lt;/ul>
&lt;h2 id="5-分表">5 分表&lt;/h2>
&lt;h3 id="51-水平切分">5.1 水平切分&lt;/h3>
&lt;p>水平切分又称为 Sharding，它是将同一个表中的记录拆分到多个结构相同的表中。&lt;/p>
&lt;p>当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓存单个数据库的压力。&lt;/p>
&lt;figure>&lt;img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/63c2909f-0c5f-496f-9fe5-ee9176b31aba.jpg" width="90%" loading="lazy">
&lt;/figure>
&lt;h3 id="52-垂直切分">5.2 垂直切分&lt;/h3>
&lt;p>垂直切分是将一张表按列切分成多个表，通常是按照列的关系密集程度进行切分，也可以利用垂直切分将经常被使用的列和不经常被使用的列切分到不同的表中。&lt;/p>
&lt;p>在数据库的层面使用垂直切分将按数据库中表的密集程度部署到不同的库中，例如将原来的电商数据库垂直切分成商品数据库、用户数据库等。&lt;/p>
&lt;figure>&lt;img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/e130e5b8-b19a-4f1e-b860-223040525cf6.jpg" width="90%" loading="lazy">
&lt;/figure>
&lt;h3 id="53-sharding-策略">5.3 Sharding 策略&lt;/h3>
&lt;ul>
&lt;li>哈希取模：hash(key) % N；&lt;/li>
&lt;li>范围：可以是 ID 范围也可以是时间范围；&lt;/li>
&lt;li>映射表：使用单独的一个数据库来存储映射关系。&lt;/li>
&lt;/ul>
&lt;h3 id="54-sharding-存在的问题">5.4 Sharding 存在的问题&lt;/h3>
&lt;h4 id="541-事务问题">5.4.1. 事务问题&lt;/h4>
&lt;p>使用分布式事务来解决，比如 XA 接口。&lt;/p>
&lt;h4 id="542-连接">5.4.2. 连接&lt;/h4>
&lt;p>可以将原来的连接分解成多个单表查询，然后在用户程序中进行连接。&lt;/p>
&lt;h4 id="543-id-唯一性">5.4.3. ID 唯一性&lt;/h4>
&lt;ul>
&lt;li>使用全局唯一 ID（GUID）&lt;/li>
&lt;li>为每个分片指定一个 ID 范围&lt;/li>
&lt;li>分布式 ID 生成器 (如 Twitter 的 Snowflake 算法)&lt;/li>
&lt;/ul>
&lt;h2 id="6-复制">6 复制&lt;/h2>
&lt;h3 id="61-主从复制">6.1 主从复制&lt;/h3>
&lt;p>主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>binlog 线程&lt;/strong> ：负责将主服务器上的数据更改写入二进制日志（Binary log）中。&lt;/li>
&lt;li>&lt;strong>I/O 线程&lt;/strong> ：负责从主服务器上读取二进制日志，并写入从服务器的中继日志（Relay log）。&lt;/li>
&lt;li>&lt;strong>SQL 线程&lt;/strong> ：负责读取中继日志，解析出主服务器已经执行的数据更改并在从服务器中重放（Replay）。&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/master-slave.png" width="90%" loading="lazy">
&lt;/figure>
&lt;h3 id="62-读写分离">6.2 读写分离&lt;/h3>
&lt;p>主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。&lt;/p>
&lt;p>读写分离能提高性能的原因在于：&lt;/p>
&lt;ul>
&lt;li>主从服务器负责各自的读和写，极大程度缓解了锁的争用；&lt;/li>
&lt;li>从服务器可以使用 MyISAM，提升查询性能以及节约系统开销；&lt;/li>
&lt;li>增加冗余，提高可用性。&lt;/li>
&lt;/ul>
&lt;p>读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h1 id="三redis">三、Redis&lt;/h1>
&lt;h2 id="1-概述">1 概述&lt;/h2>
&lt;p>Redis 是速度非常快的非关系型（NoSQL）内存键值数据库，可以存储键和五种不同类型的值之间的映射。&lt;/p>
&lt;p>键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。&lt;/p>
&lt;p>Redis 支持很多特性，例如将内存中的数据持久化到硬盘中，使用复制来扩展读性能，使用分片来扩展写性能。&lt;/p>
&lt;h2 id="2-数据类型">2 数据类型&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">数据类型&lt;/th>
&lt;th style="text-align:center">可以存储的值&lt;/th>
&lt;th style="text-align:center">操作&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">STRING&lt;/td>
&lt;td style="text-align:center">字符串、整数或者浮点数&lt;/td>
&lt;td style="text-align:center">对整个字符串或者字符串的其中一部分执行操作&amp;lt;/br&amp;gt; 对整数和浮点数执行自增或者自减操作&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">LIST&lt;/td>
&lt;td style="text-align:center">列表&lt;/td>
&lt;td style="text-align:center">从两端压入或者弹出元素 &amp;lt;/br&amp;gt; 对单个或者多个元素进行修剪，&amp;lt;/br&amp;gt; 只保留一个范围内的元素&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">SET&lt;/td>
&lt;td style="text-align:center">无序集合&lt;/td>
&lt;td style="text-align:center">添加、获取、移除单个元素&amp;lt;/br&amp;gt; 检查一个元素是否存在于集合中&amp;lt;/br&amp;gt; 计算交集、并集、差集&amp;lt;/br&amp;gt; 从集合里面随机获取元素&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">HASH&lt;/td>
&lt;td style="text-align:center">包含键值对的无序散列表&lt;/td>
&lt;td style="text-align:center">添加、获取、移除单个键值对&amp;lt;/br&amp;gt; 获取所有键值对&amp;lt;/br&amp;gt; 检查某个键是否存在&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">ZSET&lt;/td>
&lt;td style="text-align:center">有序集合&lt;/td>
&lt;td style="text-align:center">添加、获取、删除元素&amp;lt;/br&amp;gt; 根据分值范围或者成员来获取元素&amp;lt;/br&amp;gt; 计算一个键的排名&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="3-数据结构">3 数据结构&lt;/h2>
&lt;h3 id="31-字典">3.1 字典&lt;/h3>
&lt;p>dictht 是一个散列表结构，使用拉链法解决哈希冲突。&lt;/p>
&lt;h3 id="32-跳跃表">3.2 跳跃表&lt;/h3>
&lt;p>是有序集合的底层实现之一。&lt;/p>
&lt;p>跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。&lt;/p>
&lt;figure>&lt;img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/beba612e-dc5b-4fc2-869d-0b23408ac90a.png" width="90%" loading="lazy">
&lt;/figure>
&lt;p>在查找时，从上层指针开始查找，找到对应的区间之后再到下一层去查找。下图演示了查找 22 的过程。&lt;/p>
&lt;figure>&lt;img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/0ea37ee2-c224-4c79-b895-e131c6805c40.png" width="90%" loading="lazy">
&lt;/figure>
&lt;p>与红黑树等平衡树相比，跳跃表具有以下优点：&lt;/p>
&lt;ul>
&lt;li>插入速度非常快速，因为不需要进行旋转等操作来维护平衡性；&lt;/li>
&lt;li>更容易实现；&lt;/li>
&lt;li>支持无锁操作。&lt;/li>
&lt;/ul>
&lt;h2 id="4-使用场景">4 使用场景&lt;/h2>
&lt;h3 id="41-计数器">4.1 计数器&lt;/h3>
&lt;p>可以对 String 进行自增自减运算，从而实现计数器功能。&lt;/p>
&lt;p>Redis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。&lt;/p>
&lt;h3 id="42-缓存">4.2 缓存&lt;/h3>
&lt;p>将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。&lt;/p>
&lt;h3 id="43-查找表">4.3 查找表&lt;/h3>
&lt;p>例如 DNS 记录就很适合使用 Redis 进行存储。&lt;/p>
&lt;p>查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。&lt;/p>
&lt;h3 id="44-消息队列">4.4 消息队列&lt;/h3>
&lt;p>List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息&lt;/p>
&lt;p>不过最好使用 Kafka、RabbitMQ 等消息中间件。&lt;/p>
&lt;h3 id="45-会话缓存">4.5 会话缓存&lt;/h3>
&lt;p>可以使用 Redis 来统一存储多台应用服务器的会话信息。&lt;/p>
&lt;p>当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。&lt;/p>
&lt;h3 id="46-分布式锁">4.6 分布式锁&lt;/h3>
&lt;p>在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。&lt;/p>
&lt;p>可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。&lt;/p>
&lt;h3 id="47-其他">4.7 其他&lt;/h3>
&lt;p>Set 可以实现交集、并集等操作，从而实现共同好友等功能。&lt;/p>
&lt;p>ZSet 可以实现有序性操作，从而实现排行榜等功能。&lt;/p>
&lt;h2 id="5-键的过期时间">5 键的过期时间&lt;/h2>
&lt;p>Redis 可以为每个键设置过期时间，当键过期时，会自动删除该键。&lt;/p>
&lt;p>对于散列表这种容器，只能为整个键设置过期时间（整个散列表），而不能为键里面的单个元素设置过期时间。&lt;/p>
&lt;h2 id="6-数据淘汰策略">6 数据淘汰策略&lt;/h2>
&lt;p>可以设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略。&lt;/p>
&lt;p>Redis 具体有 6 种淘汰策略：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">策略&lt;/th>
&lt;th style="text-align:center">描述&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">volatile-lru&lt;/td>
&lt;td style="text-align:center">从已设置过期时间的数据集中挑选最近最少使用的数据淘汰&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">volatile-ttl&lt;/td>
&lt;td style="text-align:center">从已设置过期时间的数据集中挑选将要过期的数据淘汰&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">volatile-random&lt;/td>
&lt;td style="text-align:center">从已设置过期时间的数据集中任意选择数据淘汰&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">allkeys-lru&lt;/td>
&lt;td style="text-align:center">从所有数据集中挑选最近最少使用的数据淘汰&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">allkeys-random&lt;/td>
&lt;td style="text-align:center">从所有数据集中任意选择数据进行淘汰&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">noeviction&lt;/td>
&lt;td style="text-align:center">禁止驱逐数据&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>作为内存数据库，出于对性能和内存消耗的考虑，Redis 的淘汰算法实际实现上并非针对所有 key，而是抽样一小部分并且从中选出被淘汰的 key。&lt;/p>
&lt;p>使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用 allkeys-lru 淘汰策略，将最近最少使用的数据淘汰。&lt;/p>
&lt;p>Redis 4.0 引入了 volatile-lfu 和 allkeys-lfu 淘汰策略，LFU 策略通过统计访问频率，将访问频率最少的键值对淘汰。&lt;/p>
&lt;h2 id="7-持久化">7 持久化&lt;/h2>
&lt;p>Redis 是内存型数据库，为了保证数据在断电后不会丢失，需要将内存中的数据持久化到硬盘上。&lt;/p>
&lt;h3 id="71-rdb">7.1 RDB&lt;/h3>
&lt;p>将某个时间点的所有数据都存放到硬盘上。&lt;/p>
&lt;p>可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。&lt;/p>
&lt;p>如果系统发生故障，将会丢失最后一次创建快照之后的数据。&lt;/p>
&lt;p>如果数据量很大，保存快照的时间会很长。&lt;/p>
&lt;h3 id="72-aof">7.2 AOF&lt;/h3>
&lt;p>将写命令添加到 AOF 文件（Append Only File）的末尾。&lt;/p>
&lt;p>使用 AOF 持久化需要设置同步选项，从而确保写命令同步到磁盘文件上的时机。这是因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，然后由操作系统决定什么时候同步到磁盘。有以下同步选项：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">选项&lt;/th>
&lt;th style="text-align:center">同步频率&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">always&lt;/td>
&lt;td style="text-align:center">每个写命令都同步&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">everysec&lt;/td>
&lt;td style="text-align:center">每秒同步一次&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">no&lt;/td>
&lt;td style="text-align:center">让操作系统来决定何时同步&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ul>
&lt;li>always 选项会严重减低服务器的性能；&lt;/li>
&lt;li>everysec 选项比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器性能几乎没有任何影响；&lt;/li>
&lt;li>no 选项并不能给服务器性能带来多大的提升，而且也会增加系统崩溃时数据丢失的数量。&lt;/li>
&lt;/ul>
&lt;p>随着服务器写请求的增多，AOF 文件会越来越大。Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。&lt;/p>
&lt;h2 id="8-事务">8 事务&lt;/h2>
&lt;p>一个事务包含了多个命令，服务器在执行事务期间，不会改去执行其它客户端的命令请求。&lt;/p>
&lt;p>事务中的多个命令被一次性发送给服务器，而不是一条一条发送，这种方式被称为流水线，它可以减少客户端与服务器之间的网络通信次数从而提升性能。&lt;/p>
&lt;p>Redis 最简单的事务实现方式是使用 MULTI 和 EXEC 命令将事务操作包围起来。&lt;/p>
&lt;h2 id="9-事件">9 事件&lt;/h2>
&lt;p>Redis 服务器是一个事件驱动程序。&lt;/p>
&lt;h3 id="91-文件事件">9.1 文件事件&lt;/h3>
&lt;p>服务器通过套接字与客户端或者其它服务器进行通信，文件事件就是对套接字操作的抽象。&lt;/p>
&lt;p>Redis 基于 Reactor 模式开发了自己的网络事件处理器，使用 I/O 多路复用程序来同时监听多个套接字，并将到达的事件传送给文件事件分派器，分派器会根据套接字产生的事件类型调用相应的事件处理器。&lt;/p>
&lt;figure>&lt;img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/9ea86eb5-000a-4281-b948-7b567bd6f1d8.png" width="90%" loading="lazy">
&lt;/figure>
&lt;h3 id="92-时间事件">9.2 时间事件&lt;/h3>
&lt;p>服务器有一些操作需要在给定的时间点执行，时间事件是对这类定时操作的抽象。&lt;/p>
&lt;p>时间事件又分为：&lt;/p>
&lt;ul>
&lt;li>定时事件：是让一段程序在指定的时间之内执行一次；&lt;/li>
&lt;li>周期性事件：是让一段程序每隔指定时间就执行一次。&lt;/li>
&lt;/ul>
&lt;p>Redis 将所有时间事件都放在一个无序链表中，通过遍历整个链表查找出已到达的时间事件，并调用相应的事件处理器。&lt;/p>
&lt;h3 id="93-事件的调度与执行">9.3 事件的调度与执行&lt;/h3>
&lt;p>服务器需要不断监听文件事件的套接字才能得到待处理的文件事件，但是不能一直监听，否则时间事件无法在规定的时间内执行，因此监听时间应该根据距离现在最近的时间事件来决定。&lt;/p>
&lt;p>从事件处理的角度来看，服务器运行流程如下：&lt;/p>
&lt;figure>&lt;img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/c0a9fa91-da2e-4892-8c9f-80206a6f7047.png" width="90%" loading="lazy">
&lt;/figure>
&lt;h2 id="10-复制">10 复制&lt;/h2>
&lt;p>通过使用 slaveof host port 命令来让一个服务器成为另一个服务器的从服务器。&lt;/p>
&lt;p>一个从服务器只能有一个主服务器，并且不支持主主复制。&lt;/p>
&lt;h3 id="101-连接过程">10.1 连接过程&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>主服务器创建快照文件，发送给从服务器，并在发送期间使用缓冲区记录执行的写命令。快照文件发送完毕之后，开始向从服务器发送存储在缓冲区中的写命令；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>从服务器丢弃所有旧数据，载入主服务器发来的快照文件，之后从服务器开始接受主服务器发来的写命令；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>主服务器每执行一次写命令，就向从服务器发送相同的写命令。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="102-主从链">10.2 主从链&lt;/h3>
&lt;p>随着负载不断上升，主服务器可能无法很快地更新所有从服务器，或者重新连接和重新同步从服务器将导致系统超载。为了解决这个问题，可以创建一个中间层来分担主服务器的复制工作。中间层的服务器是最上层服务器的从服务器，又是最下层服务器的主服务器。&lt;/p>
&lt;figure>&lt;img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/395a9e83-b1a1-4a1d-b170-d081e7bb5bab.png" width="90%" loading="lazy">
&lt;/figure>
&lt;h2 id="11-哨兵">11 哨兵&lt;/h2>
&lt;p>Sentinel（哨兵）可以监听集群中的服务器，并在主服务器进入下线状态时，自动从从服务器中选举出新的主服务器。&lt;/p>
&lt;h2 id="12-分片">12 分片&lt;/h2>
&lt;p>分片是将数据划分为多个部分的方法，可以将数据存储到多台机器里面，这种方法在解决某些问题时可以获得线性级别的性能提升。&lt;/p>
&lt;p>假设有 4 个 Redis 实例 R0，R1，R2，R3，还有很多表示用户的键 user:1，user:2，&amp;hellip; ，有不同的方式来选择一个指定的键存储在哪个实例中。&lt;/p>
&lt;ul>
&lt;li>最简单的方式是范围分片，例如用户 id 从 0~1000 的存储到实例 R0 中，用户 id 从 1001~2000 的存储到实例 R1 中，等等。但是这样需要维护一张映射范围表，维护操作代价很高。&lt;/li>
&lt;li>还有一种方式是哈希分片，使用 CRC32 哈希函数将键转换为一个数字，再对实例数量求模就能知道应该存储的实例。&lt;/li>
&lt;/ul>
&lt;p>根据执行分片的位置，可以分为三种分片方式：&lt;/p>
&lt;ul>
&lt;li>客户端分片：客户端使用一致性哈希等算法决定键应当分布到哪个节点。&lt;/li>
&lt;li>代理分片：将客户端请求发送到代理上，由代理转发请求到正确的节点上。&lt;/li>
&lt;li>服务器分片：Redis Cluster。&lt;/li>
&lt;/ul>
&lt;h2 id="13-io-多路复用">13 IO 多路复用&lt;/h2>
&lt;h3 id="131-什么是-io-多路复用">13.1 什么是 IO 多路复用&lt;/h3>
&lt;p>IO 多路复用是一种同步 IO 模型，实现一个线程可以监视多个文件句柄；一旦某个文件句柄就绪，就能够通知应用程序进行相应的读写操作；没有文件句柄就绪时会阻塞应用程序，交出 cpu。多路是指网络连接，复用指的是同一个线程&lt;/p>
&lt;h3 id="132-为什么需要-io-多路复用">13.2 为什么需要 IO 多路复用&lt;/h3>
&lt;p>解决 BIO 和 NIO 的问题。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>BIO：服务端采用单线程，当 accept 一个请求后，在 recv 或 send 调用阻塞时，将无法 accept 其他请求（必须等上一个请求处 recv 或 send 完），无法处理并发。&lt;/p>
&lt;p>当服务器端采用多线程，当 accept 一个请求后，开启线程进行 recv，可以完成并发处理，但随着请求数增加需要增加系统线程，大量的线程占用很大的内存空间，并且线程切换会带来很大的开销，10000 个线程真正发生读写事件的线程数不会超过 20%，每次 accept 都开一个线程也是一种资源浪费&lt;/p>
&lt;/li>
&lt;li>
&lt;p>NIO：服务器端当 accept 一个请求后，加入 fds 集合，每次轮询一遍 fds 集合 recv(非阻塞)数据，没有数据则立即返回错误，每次轮询所有 fd（包括没有发生读写事件的 fd）会很浪费 cpu&lt;/p>
&lt;/li>
&lt;li>
&lt;p>IO 多路复用：服务器端采用单线程通过 select/epoll 等系统调用获取 fd 列表，遍历有事件的 fd 进行 accept/recv/send，使其能支持更多的并发连接请求&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="133-io-多路复用的实现方式">13.3 IO 多路复用的实现方式&lt;/h3>
&lt;ul>
&lt;li>select&lt;/li>
&lt;li>poll&lt;/li>
&lt;li>epoll&lt;/li>
&lt;/ul>
&lt;h3 id="134-select-缺点">13.4 select 缺点&lt;/h3>
&lt;ul>
&lt;li>单个进程所打开的 FD 是有限制的，通过 FD_SETSIZE 设置，默认 1024&lt;/li>
&lt;li>每次调用 select，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大&lt;/li>
&lt;li>对 socket 扫描时是线性扫描（对所有的 fds 遍历扫描），采用轮询的方法，效率较低（高并发时）&lt;/li>
&lt;/ul>
&lt;h3 id="135-poll-与-select-对比">13.5 poll 与 select 对比&lt;/h3>
&lt;p>poll 与 select 相比，只是没有 fd 的限制，其它基本一样&lt;/p>
&lt;h3 id="136-poll-缺点">13.6 poll 缺点&lt;/h3>
&lt;ul>
&lt;li>每次调用 poll，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大&lt;/li>
&lt;li>对 socket 扫描时是线性扫描，采用轮询的方法，效率较低（高并发时）&lt;/li>
&lt;/ul>
&lt;h3 id="137-epoll-缺点">13.7 epoll 缺点&lt;/h3>
&lt;p>epoll 只能工作在 linux 下&lt;/p>
&lt;h3 id="138-epoll-的应用">13.8 epoll 的应用&lt;/h3>
&lt;ul>
&lt;li>Redis&lt;/li>
&lt;li>nginx&lt;/li>
&lt;/ul>
&lt;h3 id="139-selectpollepoll-之间的区别">13.9 select/poll/epoll 之间的区别&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>select&lt;/th>
&lt;th>poll&lt;/th>
&lt;th>epoll&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>数据结构&lt;/td>
&lt;td>bitmap&lt;/td>
&lt;td>数组&lt;/td>
&lt;td>红黑树&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>最大连接数&lt;/td>
&lt;td>1024&lt;/td>
&lt;td>无上限&lt;/td>
&lt;td>无上限&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>fd 拷贝&lt;/td>
&lt;td>每次调用 select 拷贝&lt;/td>
&lt;td>每次调用 poll 拷贝&lt;/td>
&lt;td>fd 首次调用 epoll_ctl 拷贝，每次调用 epoll_wait 不拷贝&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>工作效率&lt;/td>
&lt;td>轮询：O(n)&lt;/td>
&lt;td>轮询：O(n)&lt;/td>
&lt;td>回调：O(1)&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="1310-epoll-lt-和-et-模式的区别">13.10 epoll LT 和 ET 模式的区别&lt;/h3>
&lt;p>epoll 有 EPOLLLT 和 EPOLLET 两种触发模式，LT 是默认的模式，ET 是“高速”模式。&lt;/p>
&lt;ul>
&lt;li>LT 模式下，只要这个 fd 还有数据可读，每次 epoll_wait 都会返回它的事件，提醒用户程序去操作&lt;/li>
&lt;li>ET 模式下，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论 fd 中是否还有数据可读。所以在 ET 模式下，read 一个 fd 的时候一定要把它的 buffer 读完，或者遇到 EAGAIN 错误&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>本文转载自：https://github.com/CyC2018/CS-Notes，用于个人复习。&lt;/p></description></item></channel></rss>