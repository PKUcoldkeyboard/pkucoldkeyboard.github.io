<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>分布式计算 on Cuterwrite's Blog</title><link>https://cuterwrite.top/tags/distributed-computing/</link><description>Recent content in 分布式计算 on Cuterwrite's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>cuterwrite</copyright><lastBuildDate>Sat, 30 Dec 2023 01:00:00 +0000</lastBuildDate><atom:link href="https://cuterwrite.top/tags/distributed-computing/index.xml" rel="self" type="application/rss+xml"/><item><title>在 HPC 上运行 Apache Spark</title><link>https://cuterwrite.top/p/run-spark-on-hpc/</link><pubDate>Sat, 30 Dec 2023 01:00:00 +0000</pubDate><guid>https://cuterwrite.top/p/run-spark-on-hpc/</guid><description>&lt;img src="https://cloud.cuterwrite.fun/img/crop_afb480a4096d16305dc5696f8072d0c0195413.jpg@1256w_2094h_!web-article-pic-2023-12-30.webp" alt="Featured image of post 在 HPC 上运行 Apache Spark" />&lt;h1 id="在-hpc-上运行-apache-spark">
&lt;a href="#%e5%9c%a8-hpc-%e4%b8%8a%e8%bf%90%e8%a1%8c-apache-spark" class="header-anchor">#&lt;/a>
在 HPC 上运行 Apache Spark
&lt;/h1>
&lt;h2 id="一概述">
&lt;a href="#%e4%b8%80%e6%a6%82%e8%bf%b0" class="header-anchor">#&lt;/a>
一、概述
&lt;/h2>
&lt;p>&lt;a class="link" href="https://spark.apache.org/" target="_blank" rel="noopener" >Apache Spark
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
是一个多语言引擎，用于在单节点机器或集群上执行数据工程、数据科学和机器学习任务。本文将为您提供在高性能计算（HPC）集群系统上运行多节点 Spark 集群的指南，并展示一个使用 PySpark 的作业示例。&lt;/p>
&lt;h2 id="二开始">
&lt;a href="#%e4%ba%8c%e5%bc%80%e5%a7%8b" class="header-anchor">#&lt;/a>
二、开始
&lt;/h2>
&lt;h3 id="1-下载-openjdk-1102">
&lt;a href="#1-%e4%b8%8b%e8%bd%bd-openjdk-1102" class="header-anchor">#&lt;/a>
1. 下载 OpenJDK-11.0.2
&lt;/h3>
&lt;p>从 &lt;a class="link" href="https://jdk.java.net/archive/" target="_blank" rel="noopener" >OpenJDK 官方网站
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
下载 OpenJDK-11.0.2。选择 Linux 的对应版本并下载。解压下载的文件并将其放置在 &lt;code>${HOME}/software/openjdk&lt;/code> 中并重命名为 &lt;code>11.0.2&lt;/code> 。&lt;/p>
&lt;h3 id="2-下载-spark-342">
&lt;a href="#2-%e4%b8%8b%e8%bd%bd-spark-342" class="header-anchor">#&lt;/a>
2. 下载 Spark-3.4.2
&lt;/h3>
&lt;p>从 &lt;a class="link" href="https://spark.apache.org/downloads.html" target="_blank" rel="noopener" >Apache Spark 下载页面
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
下载 Spark 。本文使用的是 Spark-3.4.2，但本指南应该也适用于更新的版本。解压下载的文件并将目录重命名为 3.4.2，放置在 ${HOME}/software/spark 文件夹中。&lt;/p>
&lt;h3 id="3-配置-modulefile">
&lt;a href="#3-%e9%85%8d%e7%bd%ae-modulefile" class="header-anchor">#&lt;/a>
3. 配置 modulefile
&lt;/h3>
&lt;p>在自定义目录中安装软件后，需要将软件的可执行文件路径等添加到相应的环境变量中才能使用。&lt;code>module&lt;/code> 是一款环境变量管理工具，通过 &lt;code>module&lt;/code> 实现软件环境变量的管理，快速加载和切换软件环境。集群中安装了一些常用的软件和库，可以通过 &lt;code>module&lt;/code> 进行加载使用。&lt;/p>
&lt;p>在这里，我们需要编写 &lt;code>modulefile&lt;/code> 来管理自己的 JDK 和 Spark 软件环境，以便快速加载 Java 和 Spark 环境。&lt;/p>
&lt;ul>
&lt;li>在 &lt;code>${HOME}/modulefiles/openjdk&lt;/code> 中创建名为 &lt;code>11.0.2&lt;/code> 的文本文件，内容为：&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-shell">#%Module1.0
##
## openjdk modulefile
##
proc ModulesHelp { } {
puts stderr &amp;quot;This module sets up the environment for OpenJdk 11.0.2 \n&amp;quot;
}
module-whatis &amp;quot;For more information, \$ module help openjdk/11.0.2\n&amp;quot;
conflict openjdk
# 注意！这里需要进行修改
set root &amp;lt;PATH/WHERE/OPENJDK/DIRECTORY/IS&amp;gt;
prepend-path PATH ${root}/bin
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>在 &lt;code>${HOME}/modulefiles/spark&lt;/code> 中创建名为 &lt;code>3.4.2&lt;/code> 的文本文件， 内容为：&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-shell">#%Module1.0
##
## spark modulefile
##
proc ModulesHelp { } {
global version
puts stderr &amp;quot;This module loads Apache Spark environment variables and updates the PATH.&amp;quot;
puts stderr &amp;quot; &amp;quot;
puts stderr &amp;quot;Version: $version&amp;quot;
}
module-whatis &amp;quot;Loads Apache Spark environment variables and updates the PATH. \n For more information, \$ module help spark/3.4.2 .\n&amp;quot;
conflict spark
# Set the version and installation path
set version 3.4.2
# 注意！这里需要进行修改
set root &amp;lt;PATH/WHERE/SPARK/DIRECTORY/IS&amp;gt;
# Set the environment variables
setenv SPARK_HOME ${root}
setenv SPARK_CONF_DIR ${root}/conf
setenv PYSPARK_PYTHON python3
# Update the PATH
prepend-path PATH ${root}/bin
prepend-path PATH ${root}/sbin
# Update the CLASSPATH
prepend-path CLASSPATH ${root}/jars/*
&lt;/code>&lt;/pre>
&lt;h3 id="4-使用-pip-安装-pyspark-库">
&lt;a href="#4-%e4%bd%bf%e7%94%a8-pip-%e5%ae%89%e8%a3%85-pyspark-%e5%ba%93" class="header-anchor">#&lt;/a>
4. 使用 pip 安装 pyspark 库
&lt;/h3>
&lt;ul>
&lt;li>创建虚拟 Conda 环境 pyspark&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-shell">conda create -n pyspark python=3.10
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>安装 pyspark&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-shell">conda activate pyspark
pip install pyspark
&lt;/code>&lt;/pre>
&lt;h3 id="5-编写环境加载脚本-set-spark-envsh">
&lt;a href="#5-%e7%bc%96%e5%86%99%e7%8e%af%e5%a2%83%e5%8a%a0%e8%bd%bd%e8%84%9a%e6%9c%ac-set-spark-envsh" class="header-anchor">#&lt;/a>
5. 编写环境加载脚本 set-spark-env.sh
&lt;/h3>
&lt;ul>
&lt;li>在 &lt;code>${HOME}/scripts&lt;/code> 目录下编写 &lt;code>set-spark-env.sh&lt;/code> 脚本文件：&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-shell">#!/bin/bash
source /etc/profile
# 注意！这里需要修改为你的 Conda 的安装路径
export CONDA_PATH=&amp;lt;PATH/WHERE/CONDA/DIRECTORY/IS&amp;gt;
export PATH=$CONDA_PATH/bin:$PATH
export MODULEPATH=${HOME}/modulefiles:$MODULEPATH
source activate
conda activate pyspark
module load openjdk
module load spark
&lt;/code>&lt;/pre>
&lt;h3 id="6-编写-sbatch-脚本">
&lt;a href="#6-%e7%bc%96%e5%86%99-sbatch-%e8%84%9a%e6%9c%ac" class="header-anchor">#&lt;/a>
6. 编写 sbatch 脚本
&lt;/h3>
&lt;ul>
&lt;li>为了启动 Spark 集群，我们使用以下 Slurm 脚本来请求计算节点。Slurm 脚本请求四个节点，并生成一个 master 节点和三个 worker 节点的 Spark 集群。可以通过更改 Slurm 脚本中的 &lt;code>-N&lt;/code> 选项的值来增加或减少工作节点的数量。&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-shell">#!/bin/bash
#SBATCH --export=ALL
#SBATCH --mem=0
#SBATCH -p C28M250G
#SBATCH -t 1:00:00
#SBATCH -N 4
#SBATCH -J spark_test
#SBATCH -o o.spark_test
#SBATCH -e e.spark_test
source ~/scripts/set-spark-env.sh
workdir=`pwd`
nodes=($(scontrol show hostnames ${SLURM_JOB_NODELIST} | sort | uniq ))
numnodes=${#nodes[@]}
last=$(( $numnodes - 1 ))
export SCRATCH=${workdir}/scratch
master=${nodes[0]}
masterurl=&amp;quot;spark://${master}:7077&amp;quot;
ssh ${nodes[0]} &amp;quot;source ~/scripts/set-spark-env.sh; start-master.sh&amp;quot;
for i in $( seq 1 $last )
do
ssh ${nodes[$i]} &amp;quot;source ~/scripts/set-spark-env.sh; start-worker.sh ${masterurl}&amp;quot;
done
ssh ${nodes[0]} &amp;quot;cd ${workdir}; source ~/scripts/set-spark-env.sh; /usr/bin/time -v spark-submit --deploy-mode client --executor-cores 28 --executor-memory 240G --conf spark.standalone.submit.waitAppCompletion=true --master $masterurl spark_test.py&amp;quot;
wait
echo 'end'
exit
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>该 Slurm 脚本会提交一个用于测试的 python 脚本（ &lt;code>spark_test.py&lt;/code> ），内容如下。此脚本运行 PySpark 代码来测试 Spark 集群。复制下面的内容，并将其保存在 sbatch 脚本所在目录中的 &lt;code>spark_test.py&lt;/code> 文件。你也可以更改 &lt;code>spark_test.py&lt;/code> 文件的路径，但必须适当地更新 Slurm 脚本。&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-py">#spark_test.py
import random
from pyspark.sql import SparkSession
import pyspark.sql.functions as F
spark = SparkSession.builder.appName('Test-app').getOrCreate()
#Generate sample dataset
cola_list = ['2022-01-01', '2022-01-02', '2022-01-03' ]
colb_list = ['CSC', 'PHY', 'MAT', 'ENG', 'CHE', 'ENV', 'BIO', 'PHRM']
colc_list = [100, 200, 300, 400, 500, 600, 700, 800, 900]
# declaring a random.seed value to generate same data in every run
random.seed(1)
sample_data = []
for idx in range(1000):
sample_data.append([random.choice(cola_list), random.choice(colb_list), random.choice(colc_list)])
columns= [&amp;quot;date&amp;quot;, &amp;quot;org&amp;quot;, &amp;quot;value&amp;quot;]
#creating a Spark dataframe
df = spark.createDataFrame(data = sample_data, schema = columns)
res = (df.groupBy('date','org')
.agg(F.count('value').alias('count_value')))
res.show()
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>如果启动了 Spark 集群并且 &lt;code>spark-test.py&lt;/code> 成功执行，那么日志文件 &lt;code>o.spark_test&lt;/code> 中的输出应该如下：&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-log">starting org.apache.spark.deploy.master.Master, logging to ...
starting org.apache.spark.deploy.worker.Worker, logging to ...
starting org.apache.spark.deploy.worker.Worker, logging to ...
starting org.apache.spark.deploy.worker.Worker, logging to ...
+----------+----+-----------+
| date| org|count_value|
+----------+----+-----------+
|2022-01-03| BIO| 37|
|2022-01-02| ENV| 53|
|2022-01-03| CHE| 39|
|2022-01-03| PHY| 46|
|2022-01-01| CSC| 45|
|2022-01-03| CSC| 48|
|2022-01-01| BIO| 39|
|2022-01-01| MAT| 42|
|2022-01-02| CHE| 44|
|2022-01-03| ENV| 33|
|2022-01-01| ENG| 33|
|2022-01-02| ENG| 28|
|2022-01-01| ENV| 33|
|2022-01-02| CSC| 45|
|2022-01-02| MAT| 51|
|2022-01-01| PHY| 38|
|2022-01-01|PHRM| 40|
|2022-01-03|PHRM| 42|
|2022-01-02|PHRM| 43|
|2022-01-03| ENG| 56|
+----------+----+-----------+
only showing top 20 rows
end
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>Spark 还提供了一个 web UI 来监控集群，您可以通过将 master 节点端口转发到本地机器来在本地机器上访问它。
&lt;ul>
&lt;li>例如，如果 master 节点在 &lt;code>cpu1&lt;/code> 上运行，则可以在本地计算机终端上运行以下代码。&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-cmd"> ssh -t -t &amp;lt;USERNAME&amp;gt;@&amp;lt;LOGIN_NODE_IP&amp;gt; -L 8080:localhost:8080 \
-i &amp;lt;PRIVATE_KEY_LOCATION&amp;gt; ssh cpu1 -L 8080:127.0.0.1:8080
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>然后就可以在本地机器上的 Web 浏览器上使用地址 &lt;a class="link" href="http://localhost:8080/" target="_blank" rel="noopener" >http://localhost:8080/
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
访问 Spark Web UI。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="三总结">
&lt;a href="#%e4%b8%89%e6%80%bb%e7%bb%93" class="header-anchor">#&lt;/a>
三、总结
&lt;/h2>
&lt;p>在本文中，我们介绍了如何在 HPC 集群上部署和运行 Apache Spark 集群。通过遵循本指南中的步骤，你应该能够成功地在 HPC 环境中运行 Spark 作业。请注意，根据你的具体 HPC 环境和配置，可能需要进行一些调整。&lt;/p>
&lt;blockquote class="alert-blockquote alert-note">
&lt;p class="alert-heading">
&lt;svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16">
&lt;path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z">&lt;/path>
&lt;/svg>
&lt;span>注释&lt;/span>
&lt;/p>
&lt;p>&lt;a class="link" href="https://spark.apache.org/docs/latest/" target="_blank" rel="noopener" >Spark 官方文档
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
是一个非常有用的工具，通过它可以帮助你找到 Spark 的具体说明并解决问题。所以实际遇到问题时要多使用它。&lt;/p>
&lt;/blockquote></description></item><item><title>基于 Flink Native Kubernetes 的词频统计实验</title><link>https://cuterwrite.top/p/flink-native-k8s/</link><pubDate>Fri, 23 Dec 2022 00:00:00 +0000</pubDate><guid>https://cuterwrite.top/p/flink-native-k8s/</guid><description>&lt;img src="https://cloud.cuterwrite.fun/blog/YSFD_P2_50.webp" alt="Featured image of post 基于 Flink Native Kubernetes 的词频统计实验" />&lt;h1 id="基于-flink-native-kubernetes-的词频统计实验">
&lt;a href="#%e5%9f%ba%e4%ba%8e-flink-native-kubernetes-%e7%9a%84%e8%af%8d%e9%a2%91%e7%bb%9f%e8%ae%a1%e5%ae%9e%e9%aa%8c" class="header-anchor">#&lt;/a>
基于 Flink Native Kubernetes 的词频统计实验
&lt;/h1>
&lt;h2 id="1-简介">
&lt;a href="#1-%e7%ae%80%e4%bb%8b" class="header-anchor">#&lt;/a>
1 简介
&lt;/h2>
&lt;h3 id="11-实验环境">
&lt;a href="#11-%e5%ae%9e%e9%aa%8c%e7%8e%af%e5%a2%83" class="header-anchor">#&lt;/a>
1.1 实验环境
&lt;/h3>
&lt;p>本实验主要使用 Ubuntu 20.04 64 位作为系统环境，采用 3 台 4 核 8GB 云服务器作为 Kubernetes 集群部署机器，1 台 4 核 8GB 云服务器作为集群管理工具 Kuboard Spary 部署机器，并作为 NFS Server 部署机器。使用的软件如下：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>名称&lt;/th>
&lt;th>版本&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>kuboard spary&lt;/td>
&lt;td>v1.2.3-amd64&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>kubernetes&lt;/td>
&lt;td>v1.25.4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>calico&lt;/td>
&lt;td>v3.23.3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>etcd&lt;/td>
&lt;td>v3.5.5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>crictl&lt;/td>
&lt;td>v1.25.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>crun&lt;/td>
&lt;td>1.4.5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>krew&lt;/td>
&lt;td>v0.4.3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>runc&lt;/td>
&lt;td>v1.1.4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>cni&lt;/td>
&lt;td>v1.1.1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>nerdctl&lt;/td>
&lt;td>1.0.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>coredns&lt;/td>
&lt;td>v1.8.6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>dnsautoscaler&lt;/td>
&lt;td>1.8.5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>pod_infra&lt;/td>
&lt;td>3.7&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>flink&lt;/td>
&lt;td>1.16.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>hadoop&lt;/td>
&lt;td>3.2.3&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="12-集群规划">
&lt;a href="#12-%e9%9b%86%e7%be%a4%e8%a7%84%e5%88%92" class="header-anchor">#&lt;/a>
1.2 集群规划
&lt;/h3>
&lt;ul>
&lt;li>Kuborad Spary&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>主机名&lt;/th>
&lt;th>IP&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>kuborad&lt;/td>
&lt;td>192.168.0.15&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ul>
&lt;li>NFS Server&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>主机名&lt;/th>
&lt;th>IP&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>NFS-server&lt;/td>
&lt;td>192.168.0.15&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ul>
&lt;li>Kubernetes 集群规划&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>主机名&lt;/th>
&lt;th>IP&lt;/th>
&lt;th>控制节点&lt;/th>
&lt;th>etcd 节点&lt;/th>
&lt;th>工作节点&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>node1&lt;/td>
&lt;td>192.168.0.6&lt;/td>
&lt;td>是&lt;/td>
&lt;td>是&lt;/td>
&lt;td>是&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>node2&lt;/td>
&lt;td>192.168.0.7&lt;/td>
&lt;td>是&lt;/td>
&lt;td>是&lt;/td>
&lt;td>是&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>node3&lt;/td>
&lt;td>192.168.0.14&lt;/td>
&lt;td>是&lt;/td>
&lt;td>是&lt;/td>
&lt;td>是&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="2-kubernetes-集群部署">
&lt;a href="#2-kubernetes-%e9%9b%86%e7%be%a4%e9%83%a8%e7%bd%b2" class="header-anchor">#&lt;/a>
2 Kubernetes 集群部署
&lt;/h2>
&lt;ul>
&lt;li>这部分内容已经在&lt;a class="link" href="https://cuterwrite.top/p/spark-on-k8s/" target="_blank" rel="noopener" >Spark on K8s
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
实验中给出详细步骤，这里不再重复。&lt;/li>
&lt;/ul>
&lt;h2 id="3-flink-native-kubernetes-部署">
&lt;a href="#3-flink-native-kubernetes-%e9%83%a8%e7%bd%b2" class="header-anchor">#&lt;/a>
3 Flink Native Kubernetes 部署
&lt;/h2>
&lt;h3 id="31-配置-flink-用户权限">
&lt;a href="#31-%e9%85%8d%e7%bd%ae-flink-%e7%94%a8%e6%88%b7%e6%9d%83%e9%99%90" class="header-anchor">#&lt;/a>
3.1 配置 flink 用户权限
&lt;/h3>
&lt;ul>
&lt;li>创建用户&lt;code>flink&lt;/code> 并配置权限&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-shell">kubectl create serviceaccount flink -n bigdata
kubectl create clusterrolebinding flink-role-binding-flink \
--clusterrole=edit \
--serviceaccount=bigdata:flink
&lt;/code>&lt;/pre>
&lt;h3 id="32-创建-session-cluster">
&lt;a href="#32-%e5%88%9b%e5%bb%ba-session-cluster" class="header-anchor">#&lt;/a>
3.2 创建 session cluster
&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>在安装了 Flink 的节点上进入 flink 根目录，执行以下命令并指定资源：&lt;/p>
&lt;pre>&lt;code class="language-shell">./bin/kubernetes-session.sh \
-Dkubernetes.namespace=bigdata \
-Dkubernetes.jobmanager.service-account=flink \
-Dkubernetes.rest-service.exposed.type=NodePort \
-Dkubernetes.cluster-id=flink-session-cluster \
-Dtaskmanager.memory.process.size=2048m \
-Dkubernetes.taskmanager.cpu=1 \
-Dkubernetes.jobmanager.replicas=1 \
-Dtaskmanager.numberOfTaskSlots=3 \
-Dresourcemanager.taskmanager-timeout=3600000
&lt;/code>&lt;/pre>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20221223121223.png" width="90%" loading="lazy">
&lt;/figure>
&lt;p>可以看到，控制台提示创建成功，并且提示了 Flink Web UI 的访问地址为：&lt;a class="link" href="http://192.168.0.6:32077%EF%BC%8C%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0Web" target="_blank" rel="noopener" >http://192.168.0.6:32077，可以看到 Web
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
UI 界面如下：&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/web%20ui.png" width="90%" loading="lazy">
&lt;/figure>
&lt;/li>
&lt;li>
&lt;p>继续在 flink 根目录下执行以下命令，将官方自带的 WindowJoin 任务提交到 session cluster 测试部署是否成功：&lt;/p>
&lt;pre>&lt;code class="language-shell">./bin/flink run -d \
--target kubernetes-session \
-Dkubernetes.namespace=bigdata \
-Dkubernetes.cluster-id=flink-session-cluster \
-Dkubernetes.service-account=flink \
-Dkubernetes.namespace=bigdata \
-Dkubernetes.taskmanager.cpu=1 \
examples/streaming/WindowJoin.jar
&lt;/code>&lt;/pre>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/bash.webp" width="90%" loading="lazy">
&lt;/figure>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/flink-run.webp" width="90%" loading="lazy">
&lt;/figure>
&lt;p>可以看到&lt;code>WindowJoin.jar&lt;/code> 已经被提交到 session cluster，占用 1 个 Slot，总共 Slot 数为 4&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="4-编写-wordcount-程序">
&lt;a href="#4-%e7%bc%96%e5%86%99-wordcount-%e7%a8%8b%e5%ba%8f" class="header-anchor">#&lt;/a>
4 编写 WordCount 程序
&lt;/h2>
&lt;ul>
&lt;li>配置 POM 文件：&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-xml">&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;project xmlns=&amp;quot;http://maven.apache.org/POM/4.0.0&amp;quot;
xmlns:xsi=&amp;quot;http://www.w3.org/2001/XMLSchema-instance&amp;quot;
xsi:schemaLocation=&amp;quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&amp;quot;&amp;gt;
&amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt;
&amp;lt;groupId&amp;gt;com.cuterwrite&amp;lt;/groupId&amp;gt;
&amp;lt;artifactId&amp;gt;FlinkApp&amp;lt;/artifactId&amp;gt;
&amp;lt;version&amp;gt;1.0-SNAPSHOT&amp;lt;/version&amp;gt;
&amp;lt;properties&amp;gt;
&amp;lt;flink.version&amp;gt;1.16.0&amp;lt;/flink.version&amp;gt;
&amp;lt;maven.compiler.source&amp;gt;11&amp;lt;/maven.compiler.source&amp;gt;
&amp;lt;maven.compiler.target&amp;gt;11&amp;lt;/maven.compiler.target&amp;gt;
&amp;lt;project.build.sourceEncoding&amp;gt;UTF-8&amp;lt;/project.build.sourceEncoding&amp;gt;
&amp;lt;/properties&amp;gt;
&amp;lt;dependencies&amp;gt;
&amp;lt;!-- Flink dependencies --&amp;gt;
&amp;lt;dependency&amp;gt;
&amp;lt;groupId&amp;gt;org.apache.flink&amp;lt;/groupId&amp;gt;
&amp;lt;artifactId&amp;gt;flink-java&amp;lt;/artifactId&amp;gt;
&amp;lt;version&amp;gt;${flink.version}&amp;lt;/version&amp;gt;
&amp;lt;scope&amp;gt;provided&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;dependency&amp;gt;
&amp;lt;groupId&amp;gt;org.apache.flink&amp;lt;/groupId&amp;gt;
&amp;lt;artifactId&amp;gt;flink-streaming-java&amp;lt;/artifactId&amp;gt;
&amp;lt;version&amp;gt;${flink.version}&amp;lt;/version&amp;gt;
&amp;lt;scope&amp;gt;provided&amp;lt;/scope&amp;gt;
&amp;lt;/dependency&amp;gt;
&amp;lt;/dependencies&amp;gt;
&amp;lt;build&amp;gt;
&amp;lt;plugins&amp;gt;
&amp;lt;plugin&amp;gt;
&amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;
&amp;lt;artifactId&amp;gt;maven-shade-plugin&amp;lt;/artifactId&amp;gt;
&amp;lt;version&amp;gt;3.1.1&amp;lt;/version&amp;gt;
&amp;lt;executions&amp;gt;
&amp;lt;execution&amp;gt;
&amp;lt;phase&amp;gt;package&amp;lt;/phase&amp;gt;
&amp;lt;goals&amp;gt;
&amp;lt;goal&amp;gt;shade&amp;lt;/goal&amp;gt;
&amp;lt;/goals&amp;gt;
&amp;lt;configuration&amp;gt;
&amp;lt;artifactSet&amp;gt;
&amp;lt;excludes&amp;gt;
&amp;lt;exclude&amp;gt;com.google.code.findbugs:jsr305&amp;lt;/exclude&amp;gt;
&amp;lt;/excludes&amp;gt;
&amp;lt;/artifactSet&amp;gt;
&amp;lt;filters&amp;gt;
&amp;lt;filter&amp;gt;
&amp;lt;!-- Do not copy the signatures in the META-INF folder.
Otherwise, this might cause SecurityExceptions when using the JAR. --&amp;gt;
&amp;lt;artifact&amp;gt;*:*&amp;lt;/artifact&amp;gt;
&amp;lt;excludes&amp;gt;
&amp;lt;exclude&amp;gt;META-INF/*.SF&amp;lt;/exclude&amp;gt;
&amp;lt;exclude&amp;gt;META-INF/*.DSA&amp;lt;/exclude&amp;gt;
&amp;lt;exclude&amp;gt;META-INF/*.RSA&amp;lt;/exclude&amp;gt;
&amp;lt;/excludes&amp;gt;
&amp;lt;/filter&amp;gt;
&amp;lt;/filters&amp;gt;
&amp;lt;transformers&amp;gt;
&amp;lt;transformer implementation=&amp;quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&amp;quot;&amp;gt;
&amp;lt;!-- Replace this with the main class of your job --&amp;gt;
&amp;lt;mainClass&amp;gt;com.cuterwrite.WordCount&amp;lt;/mainClass&amp;gt;
&amp;lt;/transformer&amp;gt;
&amp;lt;transformer implementation=&amp;quot;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer&amp;quot;/&amp;gt;
&amp;lt;/transformers&amp;gt;
&amp;lt;/configuration&amp;gt;
&amp;lt;/execution&amp;gt;
&amp;lt;/executions&amp;gt;
&amp;lt;/plugin&amp;gt;
&amp;lt;/plugins&amp;gt;
&amp;lt;/build&amp;gt;
&amp;lt;/project&amp;gt;
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>编写&lt;code>WordCount.java&lt;/code>：&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-java">package com.cuterwrite;
import org.apache.flink.api.common.functions.FlatMapFunction;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.streaming.api.datastream.DataStreamSource;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.functions.sink.SinkFunction;
import org.apache.flink.streaming.api.windowing.assigners.TumblingProcessingTimeWindows;
import org.apache.flink.streaming.api.windowing.time.Time;
import org.apache.flink.util.Collector;
import org.slf4j.LoggerFactory;
import org.slf4j.Logger;
public class WordCount {
private static final Logger log = LoggerFactory.getLogger(WordCount.class);
public WordCount() {}
public static void main(String[] args) throws Exception {
StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
env.setParallelism(3);
// 监听 9999 端口的 socket 输入
DataStreamSource&amp;lt;String&amp;gt; text = env.socketTextStream(&amp;quot;192.168.0.6&amp;quot;, 9999);
text.flatMap(new FlatMapFunction&amp;lt;String, Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt;() {
@Override
public void flatMap(String value, Collector&amp;lt;Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt; collector) throws Exception {
String[] tokens = value.toLowerCase().split(&amp;quot; &amp;quot;);
for (String token : tokens) {
collector.collect(new Tuple2&amp;lt;&amp;gt;(token, 1));
}
}
// 合并相同单词的频数
})
.keyBy(item -&amp;gt; item.f0)
.window(TumblingProcessingTimeWindows.of(Time.seconds(5)))
.sum(1)
.addSink(new SinkFunction&amp;lt;Tuple2&amp;lt;String, Integer&amp;gt;&amp;gt;() {
@Override
public void invoke(Tuple2&amp;lt;String, Integer&amp;gt; value, Context context) throws Exception {
log.info(&amp;quot;单词：&amp;quot; + value.f0 + &amp;quot;,频率：&amp;quot; + value.f1);
}
});
env.execute(&amp;quot;Word Count&amp;quot;);
}
}
&lt;/code>&lt;/pre>
&lt;h2 id="5-实验结果">
&lt;a href="#5-%e5%ae%9e%e9%aa%8c%e7%bb%93%e6%9e%9c" class="header-anchor">#&lt;/a>
5 实验结果
&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>提交 WordCount 程序 jar 包&lt;/p>
&lt;pre>&lt;code class="language-shell">./bin/flink run -d \
--target kubernetes-session \
-Dkubernetes.namespace=bigdata \
-Dkubernetes.cluster-id=flink-session-cluster \
-Dkubernetes.service-account=flink \
-Dkubernetes.namespace=bigdata \
/root/FlinkApp-1.0-SNAPSHOT.jar
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>查看 Flink Web UI：&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202022-12-23%20143910.png" width="90%" loading="lazy">
&lt;/figure>
&lt;/li>
&lt;li>
&lt;p>使用 socket 传输字符进行测试：&lt;/p>
&lt;pre>&lt;code class="language-shell">nc 192.168.0.6 9999
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>实验结果：&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/log.webp" width="90%" loading="lazy">
&lt;/figure>
&lt;/li>
&lt;/ul></description></item><item><title>基于 Spark on k8s 的词频统计实验</title><link>https://cuterwrite.top/p/spark-on-k8s/</link><pubDate>Fri, 23 Dec 2022 00:00:00 +0000</pubDate><guid>https://cuterwrite.top/p/spark-on-k8s/</guid><description>&lt;img src="https://cloud.cuterwrite.fun/blog/92.webp" alt="Featured image of post 基于 Spark on k8s 的词频统计实验" />&lt;h1 id="基于-spark-on-k8s-的词频统计实验">
&lt;a href="#%e5%9f%ba%e4%ba%8e-spark-on-k8s-%e7%9a%84%e8%af%8d%e9%a2%91%e7%bb%9f%e8%ae%a1%e5%ae%9e%e9%aa%8c" class="header-anchor">#&lt;/a>
基于 Spark on k8s 的词频统计实验
&lt;/h1>
&lt;h2 id="1-简介">
&lt;a href="#1-%e7%ae%80%e4%bb%8b" class="header-anchor">#&lt;/a>
1 简介
&lt;/h2>
&lt;h3 id="11-实验环境">
&lt;a href="#11-%e5%ae%9e%e9%aa%8c%e7%8e%af%e5%a2%83" class="header-anchor">#&lt;/a>
1.1 实验环境
&lt;/h3>
&lt;p>本实验主要使用 Ubuntu 20.04 64 位作为系统环境，采用 6 台 4 核 8GB 云服务器作为 Kubernetes 集群部署机器，1 台 2 核 4GB 云服务器作为集群管理工具 Kuboard Spary 部署机器，1 台 2 核 4GB 云服务器作为 NFS Server（使用 Centos 7.6 系统）部署机器。&lt;/p>
&lt;p>使用的软件如下：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>名称&lt;/th>
&lt;th>版本&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>kuboard spary&lt;/td>
&lt;td>v1.2.3-amd64&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>kubernetes&lt;/td>
&lt;td>v1.25.4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>calico&lt;/td>
&lt;td>v3.23.3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>etcd&lt;/td>
&lt;td>v3.5.5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>crictl&lt;/td>
&lt;td>v1.25.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>crun&lt;/td>
&lt;td>1.4.5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>krew&lt;/td>
&lt;td>v0.4.3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>runc&lt;/td>
&lt;td>v1.1.4&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>cni&lt;/td>
&lt;td>v1.1.1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>nerdctl&lt;/td>
&lt;td>1.0.0&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>coredns&lt;/td>
&lt;td>v1.8.6&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>dnsautoscaler&lt;/td>
&lt;td>1.8.5&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>pod_infra&lt;/td>
&lt;td>3.7&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>spark&lt;/td>
&lt;td>3.3.1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>hadoop&lt;/td>
&lt;td>3.2.3&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="12-集群规划">
&lt;a href="#12-%e9%9b%86%e7%be%a4%e8%a7%84%e5%88%92" class="header-anchor">#&lt;/a>
1.2 集群规划
&lt;/h3>
&lt;ul>
&lt;li>Kuborad Spary&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>主机名&lt;/th>
&lt;th>IP&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>kuborad&lt;/td>
&lt;td>192.168.0.115&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ul>
&lt;li>NFS Server&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>主机名&lt;/th>
&lt;th>IP&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>NFS-server&lt;/td>
&lt;td>192.168.0.132&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ul>
&lt;li>Kubernetes 集群规划&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>主机名&lt;/th>
&lt;th>IP&lt;/th>
&lt;th>控制节点&lt;/th>
&lt;th>etcd 节点&lt;/th>
&lt;th>工作节点&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>node1&lt;/td>
&lt;td>192.168.0.76&lt;/td>
&lt;td>是&lt;/td>
&lt;td>是&lt;/td>
&lt;td>是&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>node2&lt;/td>
&lt;td>192.168.0.213&lt;/td>
&lt;td>是&lt;/td>
&lt;td>是&lt;/td>
&lt;td>是&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>node3&lt;/td>
&lt;td>192.168.0.2&lt;/td>
&lt;td>是&lt;/td>
&lt;td>是&lt;/td>
&lt;td>是&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>node4&lt;/td>
&lt;td>192.168.0.41&lt;/td>
&lt;td>否&lt;/td>
&lt;td>否&lt;/td>
&lt;td>是&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>node5&lt;/td>
&lt;td>192.168.0.73&lt;/td>
&lt;td>否&lt;/td>
&lt;td>否&lt;/td>
&lt;td>是&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>node6&lt;/td>
&lt;td>192.168.0.12&lt;/td>
&lt;td>否&lt;/td>
&lt;td>否&lt;/td>
&lt;td>是&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="2-部署-kubernetes-集群">
&lt;a href="#2-%e9%83%a8%e7%bd%b2-kubernetes-%e9%9b%86%e7%be%a4" class="header-anchor">#&lt;/a>
2 部署 Kubernetes 集群
&lt;/h2>
&lt;h3 id="21-安装-kuboard-spray">
&lt;a href="#21-%e5%ae%89%e8%a3%85-kuboard-spray" class="header-anchor">#&lt;/a>
2.1 安装 Kuboard-Spray
&lt;/h3>
&lt;p>Kuboard-Spray 是一款可以在图形界面引导下完成 Kubernetes 高可用集群离线安装的工具，开源仓库的地址为 &lt;a class="link" href="https://github.com/eip-work/kuboard-spray" target="_blank" rel="noopener" >Kuboard-Spray
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/p>
&lt;ul>
&lt;li>
&lt;p>在 kuborad 节点上安装 docker-ce&lt;/p>
&lt;pre>&lt;code class="language-shell"># 1. 安装必备的系统工具
sudo apt-get remove docker docker-engine docker.io containerd runc;
sudo apt-get install apt-transport-https ca-certificates curl gnupg2 software-properties-common;
# 2. 安装 GPG 证书
curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/docker.gpg;
# 3. 写入软件源信息
echo \
&amp;quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/docker.gpg] https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/ubuntu \
$(lsb_release -cs) stable&amp;quot; | sudo tee /etc/apt/sources.list.d/docker.list &amp;gt; /dev/null
# 4. 更新并安装 Docker-CE
sudo apt-get update;
sudo apt-get install docker-ce;
# 5. 配置 docker 镜像加速器(可以在阿里云获取地址)
sudo mkdir -p /etc/docker;
sudo tee /etc/docker/daemon.json &amp;lt;&amp;lt;-'EOF'
{
&amp;quot;registry-mirrors&amp;quot;: [
&amp;quot;https://docker.mirrors.ustc.edu.cn&amp;quot;,
&amp;quot;https://cr.console.aliyun.com/&amp;quot; ]
}
EOF
sudo systemctl daemon-reload;
sudo systemctl restart docker;
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>在 kuboard 节点上执行以下命令：&lt;/p>
&lt;pre>&lt;code class="language-shell">docker run -d \
--privileged \
--restart=unless-stopped \
--name=kuboard-spray \
-e TZ=Asia/Shanghai \
-p 80:80/tcp \
-v /var/run/docker.sock:/var/run/docker.sock \
-v ~/kuboard-spray-data:/data \
eipwork/kuboard-spray:v1.2.3-amd64
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>在浏览器打开地址 &lt;code>http://这台机器的 IP&lt;/code>，输入用户名 &lt;code>admin&lt;/code>，默认密码 &lt;code>Kuboard123&lt;/code>，即可登录 Kuboard-Spray 界面。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="22-加载离线资源包">
&lt;a href="#22-%e5%8a%a0%e8%bd%bd%e7%a6%bb%e7%ba%bf%e8%b5%84%e6%ba%90%e5%8c%85" class="header-anchor">#&lt;/a>
2.2 加载离线资源包
&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>在 Kuboard-Spray 界面中，导航到 &lt;code>系统设置&lt;/code> &amp;ndash;&amp;gt; &lt;code>资源包管理&lt;/code> 界面，可以看到已经等候您多时的 &lt;code>Kuboard-Spray 离线资源包&lt;/code>，如下图所示&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2022-12-08-16-02-14-image.png" width="90%" loading="lazy">
&lt;/figure>
&lt;/li>
&lt;li>
&lt;p>点击 &lt;code>导入&lt;/code> 按钮，在界面的引导下完成资源包的加载。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="23-安装-kubernetes-集群">
&lt;a href="#23-%e5%ae%89%e8%a3%85-kubernetes-%e9%9b%86%e7%be%a4" class="header-anchor">#&lt;/a>
2.3 安装 Kubernetes 集群
&lt;/h3>
&lt;p>在 Kuboard-Spray 界面中，导航到 &lt;code>集群管理&lt;/code> 界面，点击界面中的 &lt;code>添加集群安装计划&lt;/code> 按钮，填写表单如下：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>集群名称： 自定义名称，本文中填写为 &lt;code>kuboard&lt;/code>，此名称不可以修改；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>资源包：选择前面步骤中导入的离线资源包。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>点击 &lt;code>确定&lt;/code> 按钮后，将进入集群规划页面，在该界面中添加每个集群节点的连接参数并设置节点的角色，如下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2022-12-08-20-13-12-image.png" width="90%" loading="lazy">
&lt;/figure>
&lt;p>&lt;strong>重要&lt;/strong>： kuboard-spray 所在机器不能当做 K8S 集群的一个节点，因为安装过程中会重启集群节点的容器引擎，这会导致 kuboard-spray 被重启掉。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>注意：&lt;/p>
&lt;ul>
&lt;li>最少的节点数量是 1 个；&lt;/li>
&lt;li>ETCD 节点、控制节点的总数量必须为奇数；&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>点击上图的 &lt;code>保存&lt;/code> 按钮，再点击 &lt;code>执行&lt;/code> 按钮，可以启动集群的离线安装过程，安装结果如下：&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2022-12-08-22-22-52-image.png" width="90%" loading="lazy">
&lt;/figure>
&lt;/li>
&lt;/ul>
&lt;h2 id="3-部署-spark-on-k8s">
&lt;a href="#3-%e9%83%a8%e7%bd%b2-spark-on-k8s" class="header-anchor">#&lt;/a>
3 部署 Spark on k8s
&lt;/h2>
&lt;h3 id="31-制作-spark-容器镜像">
&lt;a href="#31-%e5%88%b6%e4%bd%9c-spark-%e5%ae%b9%e5%99%a8%e9%95%9c%e5%83%8f" class="header-anchor">#&lt;/a>
3.1 制作 spark 容器镜像
&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>下载 spark-3.3.1-bin-hadoop3&lt;/p>
&lt;pre>&lt;code class="language-shell">wget https://mirrors.pku.edu.cn/apache/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz;
tar -xzf spark-3.3.1-bin-hadoop.tgz;
mv spark-3.3.1-bin-hadoop spark;
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>修改 Dockerfile 默认 apt 源加速&lt;/p>
&lt;pre>&lt;code class="language-shell">cd spark/kubernetes/dockerfiles/spark;
// 修改 Dockerfile 内容
// 修改前：
sed -i 's/http:\/\/deb.\(.*\)/https:\/\/deb.\1/g' /etc/apt/sources.list
// 修改后：
sed -i 's#http://deb.debian.org#https://mirrors.ustc.edu.cn#g' /etc/apt/source.list
sed -i 's|security.debian.org/debian-security|mirrors.ustc.edu.cn/debian-security|g' /etc/apt/source.list
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>构建 docker 镜像&lt;/p>
&lt;pre>&lt;code class="language-shell">cd spark/bin;
// -r &amp;lt;repo&amp;gt; -t &amp;lt;tag&amp;gt;
./docker-image-tool.sh -r cuterwrite -t 0.1 build;
&lt;/code>&lt;/pre>
&lt;/li>
&lt;li>
&lt;p>推送镜像到阿里云仓库（参考容器镜像服务-&amp;gt;实例列表-&amp;gt;镜像仓库）&lt;/p>
&lt;pre>&lt;code class="language-shell">docker login --username=[阿里云账号] registry.cn-hangzhou.aliyuncs.com;
docker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/[repository]:[镜像版本号];
docker push registry.cn-hangzhou.aliyuncs.com/[repository]:[镜像版本号];
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ul>
&lt;h3 id="32-创建命名空间">
&lt;a href="#32-%e5%88%9b%e5%bb%ba%e5%91%bd%e5%90%8d%e7%a9%ba%e9%97%b4" class="header-anchor">#&lt;/a>
3.2 创建命名空间
&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>访问 Kuboard，通常默认用户名为 &lt;code>admin&lt;/code>，默认密码为 &lt;code>Kuboard123&lt;/code>，访问地址为第一个控制节点的 80 端口（取决于安装时的参数），如下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2022-12-09-00-41-32-image.png" width="90%" loading="lazy">
&lt;/figure>
&lt;/li>
&lt;li>
&lt;p>点击进入 default 集群，在下图所示的页面点击创建&lt;code>spark&lt;/code> 命名空间：&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2022-12-09-00-43-13-image.png" width="90%" loading="lazy">
&lt;/figure>
&lt;/li>
&lt;/ul>
&lt;h3 id="33-配置-spark-用户权限">
&lt;a href="#33-%e9%85%8d%e7%bd%ae-spark-%e7%94%a8%e6%88%b7%e6%9d%83%e9%99%90" class="header-anchor">#&lt;/a>
3.3 配置 spark 用户权限
&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>创建用户&lt;code>spark&lt;/code> 并配置权限&lt;/p>
&lt;pre>&lt;code class="language-shell">kubectl create serviceaccount spark
kubectl create clusterrolebinding spark-role --clusterrole=edit --serviceaccount=spark:spark --namesparce=spark
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ul>
&lt;h3 id="34-配置-spark-历史服务器">
&lt;a href="#34-%e9%85%8d%e7%bd%ae-spark-%e5%8e%86%e5%8f%b2%e6%9c%8d%e5%8a%a1%e5%99%a8" class="header-anchor">#&lt;/a>
3.4 配置 spark 历史服务器
&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>创建一个名为&lt;code>spark-history-server&lt;/code> 的 deployment，配置如下：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>容器信息：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>名称：spark-history-server&lt;/p>
&lt;/li>
&lt;li>
&lt;p>容器镜像：registry.cn-hangzhou.aliyuncs.com/[用户名]/spark:0.1（需配置仓库仓库名和密码）&lt;/p>
&lt;/li>
&lt;li>
&lt;p>环境变量：SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=hdfs://192.168.0.238:8020/sparkhistory（需提前部署 HDFS)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>容器端口：18080，端口名称 http&lt;/p>
&lt;/li>
&lt;li>
&lt;p>参数：[&amp;quot;/opt/spark/bin/spark-class&amp;quot;, &amp;ldquo;org.apache.spark.deploy.history.HistoryServer&amp;rdquo;]&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>服务信息：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>端口：18080&lt;/p>
&lt;/li>
&lt;li>
&lt;p>协议：TCP&lt;/p>
&lt;/li>
&lt;li>
&lt;p>目标端口：18080&lt;/p>
&lt;/li>
&lt;li>
&lt;p>NodePort：30080&lt;/p>
&lt;/li>
&lt;li>
&lt;p>类型：NodePort&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>测试配置是否成功：&lt;/p>
&lt;pre>&lt;code class="language-shell">./spark-submit \
--master k8s://https://127.0.0.1:6443 \
--deploy-mode cluster \
--name spark-pi \
--class org.apache.spark.examples.SparkPi \
--conf spark.kubernetes.executor.request.cores=1 \
--conf spark.kubernetes.executor.limit.cores=1 \
--conf spark.kubernetes.driver.limit.cores=1 \
--conf spark.kubernetes.driver.request.cores=1 \
--conf spark.eventLog.enabled=true \
--conf spark.eventLog.dir=hdfs://192.168.0.238:8020/sparkhistory \
--conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
--conf spark.kubernetes.namespace=bigdata \
--conf spark.executor.instances=2 \
--conf spark.kubernetes.file.upload.path=/tmp \
--conf spark.kubernetes.container.pullSecrets=aliyun-repository \
--conf spark.kubernetes.container.image=registry.cn-hangzhou.aliyuncs.com/cuterwrite/spark:0.1 \
hdfs://192.168.0.238:8020/user/root/jars/spark-examples_2.12-3.3.1.jar
&lt;/code>&lt;/pre>
&lt;p>提交任务成功后可以在 Kuboard 管理界面看到一个新启动的容器组：&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2022-12-19-16-35-20-image.png" width="90%" loading="lazy">
&lt;/figure>
&lt;p>访问 spark 历史服务器，可以看到以下记录：&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2022-12-19-18-50-59-image.png" width="90%" loading="lazy">
&lt;/figure>
&lt;/li>
&lt;/ul>
&lt;h2 id="4-编写-wordcount-程序">
&lt;a href="#4-%e7%bc%96%e5%86%99-wordcount-%e7%a8%8b%e5%ba%8f" class="header-anchor">#&lt;/a>
4 编写 WordCount 程序
&lt;/h2>
&lt;p>&lt;code>WordCount.java&lt;/code>&lt;/p>
&lt;pre>&lt;code class="language-python">package com.cuterwrite;
import org.apache.spark.api.java.function.FlatMapFunction;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Encoders;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import java.util.Arrays;
import java.util.Iterator;
public class WordCount {
public static void main(String[] args) throws Exception {
SparkSession spark = SparkSession.builder().appName(&amp;quot;WordCount&amp;quot;).getOrCreate();
Dataset&amp;lt;String&amp;gt; lines = spark.read().textFile(&amp;quot;hdfs://192.168.0.238:8020/input/news.txt&amp;quot;);
Dataset&amp;lt;String&amp;gt; words = lines.flatMap(new FlatMapFunction&amp;lt;String, String&amp;gt;() {
@Override
public Iterator&amp;lt;String&amp;gt; call(String line) throws Exception {
return Arrays.asList(line.split(&amp;quot; &amp;quot;)).iterator();
}
}, Encoders.STRING());
Dataset&amp;lt;Row&amp;gt; wordCounts = words.groupBy(&amp;quot;value&amp;quot;).count();
wordCounts.write().format(&amp;quot;csv&amp;quot;).save(&amp;quot;hdfs://192.168.0.238:8020/output/word_count_result&amp;quot;);
}
}
&lt;/code>&lt;/pre>
&lt;h2 id="5-实验结果">
&lt;a href="#5-%e5%ae%9e%e9%aa%8c%e7%bb%93%e6%9e%9c" class="header-anchor">#&lt;/a>
5 实验结果
&lt;/h2>
&lt;ul>
&lt;li>提交词频统计任务到&lt;code>Kubernetes&lt;/code>&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-shell">./spark-submit \
--master k8s://https://127.0.0.1:6443 \
--deploy-mode cluster \
--name wordcount \
--class com.cuterwrite.WordCount \
--conf spark.kubernetes.executor.request.cores=2 \
--conf spark.kubernetes.executor.limit.cores=2 \
--conf spark.kubernetes.driver.limit.cores=1 \
--conf spark.kubernetes.driver.request.cores=1 \
--conf spark.eventLog.enabled=true \
--conf spark.eventLog.dir=hdfs://192.168.0.238:8020/sparkhistory \
--conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
--conf spark.kubernetes.namespace=bigdata \
--conf spark.executor.instances=3 \
--conf spark.kubernetes.file.upload.path=/tmp \
--conf spark.kubernetes.container.pullSecrets=aliyun-repository \
--conf spark.kubernetes.container.image=registry.cn-hangzhou.aliyuncs.com/cuterwrite/spark:0.1 \
hdfs://192.168.0.238:8020/user/root/jars/SparkApp-1.0.jar
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>执行结果：&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-shell">hdfs dfs -cat output/wordCount/_temporary/0/task_202212221534101760903765384745539_0002_m_000000/*
&lt;/code>&lt;/pre>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/1671723913622.jpg" width="90%" loading="lazy">
&lt;/figure>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/1671723670687.jpg" width="90%" loading="lazy">
&lt;/figure></description></item></channel></rss>