<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>CUDA on Cuterwrite's Blog</title><link>https://cuterwrite.top/tags/cuda/</link><description>Recent content in CUDA on Cuterwrite's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>cuterwrite</copyright><lastBuildDate>Mon, 04 Sep 2023 00:55:55 +0000</lastBuildDate><atom:link href="https://cuterwrite.top/tags/cuda/index.xml" rel="self" type="application/rss+xml"/><item><title>CUDA 基础：内存访问模式</title><link>https://cuterwrite.top/p/cuda-base-memory-access-mode/</link><pubDate>Mon, 04 Sep 2023 00:55:55 +0000</pubDate><guid>https://cuterwrite.top/p/cuda-base-memory-access-mode/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/14ce26d6f495200cea2cfa76fefadf88eaab94e5.jpg@1256w_754h_!web-article-pic-2023-09-04.webp" alt="Featured image of post CUDA 基础：内存访问模式" />&lt;h1 id="cuda-基础内存访问模式">CUDA 基础：内存访问模式&lt;/h1>
&lt;p>大多数设备端数据访问都是从全局内存开始的，并且多数 GPU 应用程序容易受内存带宽的限制。因此，最大限度地利用全局内存带宽是调控核函数性能的基本。如果不能正确地调控全局内存的使用，其他优化方案很可能也收效甚微。&lt;/p>
&lt;p>为了在读写数据时达到最佳的性能，内存访问操作必须满足一定的条件。CUDA 执行模型的显著特征之一就是指令必须以线程束为单位进行发布和执行。存储操作也是同样。在执行内存指令时，线程束中的每个线程都提供了一个正在加载或存储的内存地址。在线程束的 32 个线程中，每个线程都提出了一个包含请求地址的单一内存访问请求，它并由一个或多个设备内存传输提供服务。根据线程束中内存地址的分布，内存访问可以被分成不同的模式。&lt;/p>
&lt;h2 id="一对齐与合并访问">一、对齐与合并访问&lt;/h2>
&lt;p>全局内存通过缓存实现加载和存储的过程如下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904151729-2023-09-04.webp"
alt="20230904151729-2023-09-04" width="auto" loading="lazy">
&lt;/figure>
&lt;p>全局内存是一个逻辑内存空间，用户可以通过核函数访问它。所有应用程序数据最初存在于 DRAM 上，即物理设备内存中。核函数的内存请求通常是在 DRAM 设备和片上内存间以 128 字节或 32 字节内存事务来实现。&lt;/p>
&lt;p>所有对全局内存的访问都会通过二级缓存，也有许多访问会通过一级缓存，这取决于访问类型和 GPU 架构。如果这两级缓存都被用到，那么内存访问是由一个 128 字节的内存事务实现的。如果只使用二级缓存，那么这个内存访问是由一个 32 字节的内存事务来实现的。对全局内存缓存其架构，如果允许使用一级缓存，那么可以在编译时选择启用或禁用一级缓存。&lt;/p>
&lt;p>一行一级缓存是 128 字节，它映射到设备内存中一个 128 字节 的对齐段。如果线程束中的每个线程请求一个 4 字节的值，那么每次请求就会获取 128 字节的数据，这恰好与缓存行和设备内存段的大小相契合。&lt;/p>
&lt;p>因此在优化应用程序时，需要注意设备内存访问的两个特性：&lt;/p>
&lt;ul>
&lt;li>对齐内存访问&lt;/li>
&lt;li>合并内存访问&lt;/li>
&lt;/ul>
&lt;p>我们把一次内存请求：也就是从核函数发起请求，到硬件响应返回数据这个过程称为一个内存事务（加载和存储都行）。&lt;/p>
&lt;p>当一个内存事务的首个访问地址是缓存粒度（32 或 128 字节）的偶数倍的时候：比如二级缓存 32 字节的偶数倍 64，128 字节的偶数倍 256 的时候，这个时候被称为对齐内存访问，非对齐访问就是除上述的其他情况，&lt;strong>非对齐的内存访问会造成带宽浪费&lt;/strong>。&lt;/p>
&lt;p>当一个线程束内的线程访问的内存都在一个内存块里的时候，就会出现合并访问。&lt;/p>
&lt;p>&lt;strong>对齐合并访问的状态是理想化的，也是最高速的访问方式&lt;/strong>，当线程束内的所有线程访问的数据在一个内存块，并且数据是从内存块的首地址开始被需要的，那么对齐合并访问出现了。为了最大化全局内存访问的理想状态，尽量将线程束访问内存组织成对齐合并的方式，这样的效率是最高的。下面看一个例子。&lt;/p>
&lt;p>一个线程束加载数据，使用一级缓存，并且这个事务所请求的所有数据在一个 128 字节的对齐的地址段上，如下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904152703-2023-09-04.webp"
alt="20230904152703-2023-09-04" width="auto" loading="lazy">
&lt;/figure>
&lt;p>上面蓝色表示全局内存，下面橙色是线程束要的数据，绿色就是对齐的地址段。&lt;/p>
&lt;p>而如果一个事务加载的数据分布在不一个对齐的地址段上，就会有以下两种情况：&lt;/p>
&lt;ol>
&lt;li>连续的，但是不在一个对齐的段上，比如，请求访问的数据分布在内存地址 1~128 ，那么 0~127 和 128~255 这两段数据要传递两次到 SM 。&lt;/li>
&lt;li>不连续的，也不在一个对齐的段上，比如，请求访问的数据分布在内存地址 0~63 和 128~191 上，明显这也需要两次加载。&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904152901-2023-09-04.webp"
alt="20230904152901-2023-09-04" width="auto" loading="lazy">
&lt;/figure>
&lt;p>上图就是典型的一个线程束，数据分散开了，thread 0 的请求在 128 之前，后面还有请求在 256 之后，所以需要三个内存事务，而利用率，也就是从主存取回来的数据被使用到的比例，只有 $\frac{128}{128 \times 3}$ 的比例。这个比例低会造成带宽的浪费，最极端的表现，就是如果每个线程的请求都在不同的段，也就是一个 128 字节的事务只有 1 个字节是有用的，那么利用率只有 $\frac{1}{128}$ 。&lt;/p>
&lt;p>这里总结一下内存事务的优化关键：&lt;strong>用最少的事务次数满足最多的内存请求&lt;/strong>。事务数量和吞吐量的需求随设备的计算能力变化。&lt;/p>
&lt;h2 id="二全局内存读取">二、全局内存读取&lt;/h2>
&lt;p>在 SM 中，数据通过以下 3 种缓存 / 缓冲路径进行传输，具体使用何种方式取决于引用了哪种类型的设备内存：&lt;/p>
&lt;ul>
&lt;li>一级和二级缓存&lt;/li>
&lt;li>常量缓存&lt;/li>
&lt;li>只读缓存&lt;/li>
&lt;/ul>
&lt;p>一 / 二级缓存是默认路径。想要通过其它两种路径传输数据需要&lt;strong>应用程序显式说明&lt;/strong>，但想要提升性能还要取决于使用地访问模式。全局内存加载操作是否会通过一级缓存取决于两个因素：&lt;/p>
&lt;ul>
&lt;li>设备的计算能力：比较老的设备可能没有一级缓存&lt;/li>
&lt;li>编译器选项&lt;/li>
&lt;/ul>
&lt;p>在 Fermi GPU 和 Kepler K40 及以后的 GPU （计算能力为 3.5 及以上）中，可以通过编译器标志启用或禁用全局内存负载的一级缓存。默认情况下，在 Fermi 设备上对于全局内存加载可以使用一级缓存，在 K40 及以上 GPU 中禁用。以下标志通知编译器禁用一级缓存：&lt;/p>
&lt;pre>&lt;code class="language-text">-Xptxas -dlcm=cg
&lt;/code>&lt;/pre>
&lt;p>如果一级缓存被禁用，所有对全局内存的加载请求将直接进入到二级缓存；如果二级缓存缺失，则由 DRAM 完成请求。每一次内存事务可由一个、两个或四个部分执行，每个部分有 32 个字节。一级缓存也可以使用下列标识符直接启用:&lt;/p>
&lt;pre>&lt;code class="language-text">-Xptxas -dlcm=ca
&lt;/code>&lt;/pre>
&lt;p>设置这个标志后，全局内存加载请求首先尝试通过一级缓存。如果一级缓存缺失，该请求转向二级缓存。如果二级缓存缺失，则请求由 DRAM 完成。在这种模式下，一个内存加载请求由一个 128 字节的设备内存事务实现。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904164822-2023-09-04.webp"
alt="20230904164822-2023-09-04" width="auto" loading="lazy">
&lt;/figure>
&lt;p>在 Kepler K10、K20 和 K20X GPU 中一级缓存不用来缓存全局内存加载。一级缓存专门用于&lt;strong>缓存寄存器溢出到本地内存中的数据&lt;/strong>。&lt;/p>
&lt;p>内存加载可以分为两类：&lt;/p>
&lt;ul>
&lt;li>缓存加载&lt;/li>
&lt;li>没有缓存的加载&lt;/li>
&lt;/ul>
&lt;p>内存访问有以下特点：&lt;/p>
&lt;ul>
&lt;li>是否使用缓存：一级缓存是否介入加载过程&lt;/li>
&lt;li>对齐与非对齐的：如果访问的第一个地址是 32 的倍数&lt;/li>
&lt;li>合并与非合并，访问连续数据块则是合并的&lt;/li>
&lt;/ul>
&lt;h3 id="1-缓存加载">1. 缓存加载&lt;/h3>
&lt;p>下面是使用一级缓存的加载过程&lt;/p>
&lt;ol>
&lt;li>对齐合并的访问，总线利用率 $100\%$&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904165226-2023-09-04.webp"
alt="20230904165226-2023-09-04" width="auto" loading="lazy">
&lt;/figure>
&lt;ol start="2">
&lt;li>对齐的，但是不是连续的，每个线程访问的数据都在一个块内，但是位置是交叉的，总线利用率 $100\%$&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904165245-2023-09-04.webp"
alt="20230904165245-2023-09-04" width="auto" loading="lazy">
&lt;/figure>
&lt;ol start="3">
&lt;li>连续非对齐的，线程束请求一个连续的非对齐的，32 个 4 字节数据，那么会出现，数据横跨两个块，但是没有对齐，当启用一级缓存的时候，就要两个 128 字节的事务来完成，总线利用率为 $50\%$&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904165306-2023-09-04.webp"
alt="20230904165306-2023-09-04" width="auto" loading="lazy">
&lt;/figure>
&lt;ol start="4">
&lt;li>线程束所有线程请求同一个地址，那么肯定落在一个缓存行范围内，那么如果按照请求的是 4 字节数据来说，总线利用率是 $\frac{4}{128}=3.125\% $&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904165516-2023-09-04.webp"
alt="20230904165516-2023-09-04" width="auto" loading="lazy">
&lt;/figure>
&lt;ol start="5">
&lt;li>比较坏的情况，前面提到过最坏的，就是每个线程束内的线程请求的都是不同的缓存行内，这里比较坏的情况就是，所有数据分布在 $N$ 个缓存行，其中 $1\leq N \leq 32$ ，那么请求 32 个 4 字节的数据，就需要 $N$ 个事务来完成，总线利用率也是 $\frac{1}{N}$&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904165524-2023-09-04.webp"
alt="20230904165524-2023-09-04" width="auto" loading="lazy">
&lt;/figure>
&lt;p>CPU 和 GPU 的一级缓存有显著的差异， GPU 的一级缓存可以通过编译选项等控制，CPU 不可以，而且 CPU 的一级缓存是的替换算法是有使用频率和时间局部性的， GPU 则没有。&lt;/p>
&lt;h3 id="2-没有缓存的加载">2. 没有缓存的加载&lt;/h3>
&lt;p>没有缓存的加载是指的没有通过一级缓存，二级缓存则是不得不经过的。&lt;/p>
&lt;p>当不使用一级缓存的时候，&lt;strong>内存事务的粒度变为 32 字节&lt;/strong>，更细粒度的加载可以为非对齐或非合并的内存访问带来更好的总线利用率。&lt;/p>
&lt;ol>
&lt;li>对齐合并访问 128 字节，不用说，还是最理想的情况，使用 4 个段，总线利用率 $100\%$&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904170430-2023-09-04.webp"
alt="20230904170430-2023-09-04" width="auto" loading="lazy">
&lt;/figure>
&lt;ol start="2">
&lt;li>对齐不连续访问 128 字节，都在四个段内，且互不相同，这样的总线利用率也是 $100\%$&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904170454-2023-09-04.webp"
alt="20230904170454-2023-09-04" width="auto" loading="lazy">
&lt;/figure>
&lt;ol start="3">
&lt;li>连续不对齐，一个段 32 字节，所以，一个连续的 128 字节的请求，即使不对齐，最多也不会超过五个段，总线利用率至少为 $\frac{4}{5}=80\%$&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904170542-2023-09-04.webp"
alt="20230904170542-2023-09-04" width="auto" loading="lazy">
&lt;/figure>
&lt;ol start="4">
&lt;li>所有线程访问一个 4 字节的数据，那么此时的总线利用率是 $\frac{4}{32} = 12.5\%$ ，在这种情况下，非缓存加载性能也是优于缓存加载的性能。&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904170609-2023-09-04.webp"
alt="20230904170609-2023-09-04" width="auto" loading="lazy">
&lt;/figure>
&lt;ol start="5">
&lt;li>最坏的情况：所有目标数据分散在内存的各个角落，那么需要 $N$ 个内存段，由于请求的 128 个字节最多落在 $N$ 个 32 字节的内存分段内而不是 $N$ 个 128 字节的缓存行内，所以相比于缓存加载，即便是最坏的情况也有所改善。需要注意这里比较的前提是$N$ 不变，然而在实际情况下，当使用大粒度的缓存行时，$N$ 有可能会减少。&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904170847-2023-09-04.webp"
alt="20230904170847-2023-09-04" width="auto" loading="lazy">
&lt;/figure>
&lt;h3 id="3-只读缓存">3. 只读缓存&lt;/h3>
&lt;p>只读缓存最初是预留给纹理内存加载用的。对计算能力为 3.5 及以上的 GPU 来说，只读缓存也支持使用全局内存加载代替一级缓存。&lt;/p>
&lt;p>只读缓存的加载粒度是 32 个字节。通常，对分散读取来说，这些更细粒度的加载要优于一级缓存。&lt;/p>
&lt;p>有两种方式可以指导内存通过只读缓存进行读取:&lt;/p>
&lt;ul>
&lt;li>使用函数 __ldg&lt;/li>
&lt;li>在间接引用的指针上使用修饰符&lt;/li>
&lt;/ul>
&lt;p>例如：&lt;/p>
&lt;pre>&lt;code class="language-c">__global__ void copyKernel(float *in, float *out)
{
int idx = blockDim * blockIdx.x + threadIdx.x;
out[idx] = __ldg(&amp;amp;in[idx]);
}
&lt;/code>&lt;/pre>
&lt;p>然后就能强制使用只读缓存了。&lt;/p>
&lt;p>也可以将常量 restrict 修饰符应用到指针上。这些修饰符帮助 nvcc 编译器识别无别名指针(即专门用来访问特定数组的指针)。nvcc 将自动通过只读缓存指导无别名指针的加载。&lt;/p>
&lt;pre>&lt;code class="language-c">__global__ void copyKernel(int * __restrict__ out, const int* __restrict__ in)
{
int idx = blockDim * blockIdx.x + threadIdx.x;
out[idx] = in[idx];
}
&lt;/code>&lt;/pre>
&lt;h2 id="三全局内存写入">三、全局内存写入&lt;/h2>
&lt;p>内存的存储操作相对简单。一级缓存不能用在 Fermi 或 Kepler GPU 上进行存储操作，在发送到设备内存之间存储操作&lt;strong>只通过二级缓存&lt;/strong>。存储操作在 &lt;strong>32 个字节段&lt;/strong>的粒度上被执行。内存事务可以同时被分为一段、两段或四段。例如，如果两个地址同属于一个 128 字节区域，但是不属于一个对齐的 64 字节区域，则会执行一个四段事务（也就是说，执行一个四段事务比执行两个一段事务效果更好）。&lt;/p>
&lt;ol>
&lt;li>对齐的，访问一个连续的 128 字节范围。存储操作使用一个四段事务完成：&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904172018-2023-09-04.webp"
alt="20230904172018-2023-09-04" width="auto" loading="lazy">
&lt;/figure>
&lt;ol start="2">
&lt;li>分散在一个 192 字节的范围内，不连续，使用 3 个一段事务完成：&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904172036-2023-09-04.webp"
alt="20230904172036-2023-09-04" width="auto" loading="lazy">
&lt;/figure>
&lt;ol start="3">
&lt;li>对齐的，在一个 64 字节的范围内，使用一个两段事务完成：&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904172052-2023-09-04.webp"
alt="20230904172052-2023-09-04" width="auto" loading="lazy">
&lt;/figure>
&lt;ol start="4">
&lt;li>非对齐写入示例与读取情况类似，且更简单，因为始终不经过一级缓存，这里就略过了。&lt;/li>
&lt;/ol>
&lt;h2 id="四结构体数组与数组结构体">四、结构体数组与数组结构体&lt;/h2>
&lt;p>数组结构体（AoS）和结构体数组（SoA）是 C 语言中常见的两种数组组织方式。当存储结构化数据集时，它们代表了可以采用的两种强大的数据组织方式（结构体和数组）。&lt;/p>
&lt;p>下面是存储成对的浮点数据数据集的例子。首先，考虑这些成对数据元素集如何使用 AoS 方法进行存储。如下定义一个结构体，命名为 innerStruct ：&lt;/p>
&lt;pre>&lt;code class="language-c">struct innerStruct
{
float x;
float y;
};
&lt;/code>&lt;/pre>
&lt;p>然后，按照下面的方法定义这些结构体数组。这是利用 AoS 方式来组织数据的。它存储的是空间上相邻的数据，这在 CPU 上会有良好的缓存局部性。&lt;/p>
&lt;pre>&lt;code class="language-c">struct innerStruct myAoS[N];
&lt;/code>&lt;/pre>
&lt;p>接下来，考虑使用 SoA 方法来存储数据：&lt;/p>
&lt;pre>&lt;code class="language-c">struct innerArray
{
float x[N];
float y[N];
};
&lt;/code>&lt;/pre>
&lt;p>这里，在原结构体中每个字段的所有值都被分到各自的数组中。这不仅能将相邻数据点紧密存储起来，也能将跨数组的独立数据点存储起来。可以使用如下结构体定义一个变量：&lt;/p>
&lt;pre>&lt;code class="language-c">struct innerArray mySoA;
&lt;/code>&lt;/pre>
&lt;p>下图说明了 AoS 和 SoA 方法的内存布局。用 AoS 模式在 GPU 上存储示例数据并执行一个只有 $x$ 字段的应用程序，将导致 $50\%$ 的带宽损失，因为 $y$ 值在每 32 个字节段或 128 个字节缓存行上隐式地被加载。 AoS 格式也在不需要的 $y$ 值上浪费了二级缓存空间。&lt;/p>
&lt;p>用 SoA 模式存储数据充分利用了 GPU 的内存带宽。由于没有相同字段元素的交叉存取， GPU 上的 SoA 布局提供了合并内存访问，并且可以对全局内存实现更高效的利用。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904173436-2023-09-04.webp"
alt="20230904173436-2023-09-04" width="auto" loading="lazy">
&lt;/figure>
&lt;p>当 32 个线程同时访问的时候， SoA 的访问就是连续的，而 AoS 则是不连续的。&lt;/p>
&lt;p>对比 AoS 和 SoA 的内存布局，我们能得到下面结论：&lt;/p>
&lt;ul>
&lt;li>并行编程范式，尤其是 SIMD（单指令多数据）对 SoA 更友好。 CUDA 中普遍倾向于 SoA 因为这种内存访问可以有效地合并。&lt;/li>
&lt;/ul>
&lt;h2 id="五性能调整">五、性能调整&lt;/h2>
&lt;p>优化设备内存带宽利用率有两个目标：&lt;/p>
&lt;ol>
&lt;li>对齐及合并内存访问，以减少带宽的浪费&lt;/li>
&lt;li>足够的并发内存操作，以隐藏内存延迟&lt;/li>
&lt;/ol>
&lt;p>实现并发内存访问量最大化是通过以下方式得到的：&lt;/p>
&lt;ol>
&lt;li>增加每个线程中执行独立内存操作的数量&lt;/li>
&lt;li>对核函数启动的执行配置进行试验，已充分体现每个 SM 的并行性&lt;/li>
&lt;/ol>
&lt;p>按照这个思路对程序进行优化，则有两种方法：展开技术和增大并行性。&lt;/p>
&lt;h3 id="1-展开技术">1. 展开技术&lt;/h3>
&lt;p>包含了内存操作的展开循环增加了更独立的内存操作。考虑如下 readOffsetUnroll4 核函数，每个线程都执行 4 个独立的内存操作。因为每个加载过程都是独立的，所以可以调用更多的并发内存访问：&lt;/p>
&lt;pre>&lt;code class="language-c">__global__ void readOffsetUnroll4(float *A, float *B, float *C, const int n, int offset)
{
unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;
unsigned int k = i + offset;
if (k + 3 * blockDim.x &amp;lt; n)
{
C[i] = A[k];
C[i + blockDim.x] = A[k + blockDim.x] + B[k + blockDim.x];
C[i + 2 * blockDim.x] = A[k + 2 * blockDim.x] + B[k + 2 * blockDim.x];
C[i + 3 * blockDim.x] = A[k + 3 * blockDim.x] + B[k + 3 * blockDim.x];
}
}
&lt;/code>&lt;/pre>
&lt;p>启用一级缓存编译选项：&lt;/p>
&lt;pre>&lt;code class="language-shell">nvcc -O3 readSegmentUnroll.cu -o readSegmentUnroll -Xptxas -dlcm=ca
&lt;/code>&lt;/pre>
&lt;p>结果表明，展开技术对性能有非常好的影响，甚至比地址对齐还要好。对于 I/O 密集型的核函数，充分说明内存访问并行有很高的优先级。&lt;/p>
&lt;h3 id="2-增大并行性">2. 增大并行性&lt;/h3>
&lt;p>可以通过调整块的大小来实现并行性调整：&lt;/p>
&lt;ul>
&lt;li>线程块最内层维度的大小对性能起着关键的作用&lt;/li>
&lt;li>在所有其它情况下，线程块的数量越多，一般性能越高。因此，增大并行性仍然是性能优化的一个重要因素。&lt;/li>
&lt;/ul>
&lt;h2 id="参考资料">参考资料&lt;/h2>
&lt;p>[1] CUDA C 编程权威指南，机械工业出版社，（美）程润伟（John Cheng） 等著&lt;/p></description></item><item><title>CUDA 基础：内存管理</title><link>https://cuterwrite.top/p/cuda-base-memory-manage/</link><pubDate>Sat, 02 Sep 2023 05:55:55 +0000</pubDate><guid>https://cuterwrite.top/p/cuda-base-memory-manage/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/fb80f7f3a9a0e016420a324823ef950b9847fb8d.jpg@1256w_2128h_!web-article-pic-2023-09-02.webp" alt="Featured image of post CUDA 基础：内存管理" />&lt;h1 id="cuda-基础内存管理">CUDA 基础：内存管理&lt;/h1>
&lt;p>CUDA 编程的内存管理与 C 语言的类似，需要程序员显式地管理主机和设备之间的数据移动。随着 CUDA 版本的升级，NVIDIA 正系统地实现主机和设备内存空间的统一，但对于大多数应用程序来说，仍需要手动移动数据。本文重点在于如何使用 CUDA 函数来显式地管理内存和数据移动。&lt;/p>
&lt;ul>
&lt;li>分配和释放设备内存&lt;/li>
&lt;li>在主机和设备之间传输数据&lt;/li>
&lt;/ul>
&lt;p>为了达到最优性能，CUDA 提供了在主机端准备设备内存的函备内存的函数，并且显式地向设备传输数据和从设备中获取数据。&lt;/p>
&lt;h2 id="一内存分配和释放">一、内存分配和释放&lt;/h2>
&lt;p>CUDA 编程模型假设了一个包含一个主机和一个设备的异构系统，每一个异构系统都有自己独立的内存空间。核函数在设备内存空间中运行，CUDA 运行时提供函数以分配和释放设备内存。用户可以在主机上使下列函数分配全局内存：&lt;/p>
&lt;pre>&lt;code class="language-c">cudaError_t cudaMalloc(void **devPtr, size_t size);
&lt;/code>&lt;/pre>
&lt;p>这个函数在设备上分配了 count 字节的全局内存，并用 devptr 指针返回该内存的地址。所分配的内存支持任何变量类型，包括整型、浮点类型变量、布尔类型等。如果 cudaMalloc 函数执行失败则返回 cudaErrorMemoryAllocation 。在已分配的全局内存中的值不会被清除。用户需要用从主机上传输的数据来填充所分配的全局内存，或用下列函数将其初始化：&lt;/p>
&lt;pre>&lt;code class="language-c">cudaError_t cudaMemset(void *devPtr, int value, size_t count);
&lt;/code>&lt;/pre>
&lt;p>这个函数用存储在变量 value 中的值来填充从设备内存地址 devPtr 处开始的 count 字节。&lt;/p>
&lt;p>一旦一个应用程序不再使用已分配的全局内存，那么可以以下代码释放该内存空间：&lt;/p>
&lt;pre>&lt;code class="language-c">cudaError_t cudaFree(void *devPtr);
&lt;/code>&lt;/pre>
&lt;p>这个函数释放了 devPtr 指向的全局内存，该内存必须在此前使用了一个设备分配函数（如 cudaMalloc）来进行分配。否则，它将返回一个错误 cudaErrorInvalidDevicePointer 。如果地址空间已经被释放，那么 cudaFree 也返回一个错误。&lt;/p>
&lt;p>设备内存的分配和释放操作成本较高，所以应用程序应&lt;strong>重利用设备内存&lt;/strong>，以减少对整体性能的影响。&lt;/p>
&lt;h2 id="二内存传输">二、内存传输&lt;/h2>
&lt;p>一旦分配好了全局内存，就可以使用下列函数从主机向设备传输数据：&lt;/p>
&lt;pre>&lt;code class="language-c">cudaError_t cudaMemcpy(void *dst, const void *src, size_t count, cudaMemcpyKind kind);
&lt;/code>&lt;/pre>
&lt;p>这个函数从内存位置 src 复制了 count 字节到内存位置 dst 。变量 kind 指定了复制的方向，可以有下列取值：&lt;/p>
&lt;ul>
&lt;li>cudaMemcpyHostToHost：从主机内存复制到主机内存&lt;/li>
&lt;li>cudaMemcpyHostToDevice：从主机内存复制到设备内存&lt;/li>
&lt;li>cudaMemcpyDeviceToHost：从设备内存复制到主机内存&lt;/li>
&lt;li>cudaMemcpyDeviceToDevice：从设备内存复制到设备内存&lt;/li>
&lt;/ul>
&lt;p>如果指针 dst 和 src 与 kind 指定的复制方向不一致，那么 cudaMemcpy 的行为就是未定义行为。这个函数在大多数情况下都是同步的。&lt;/p>
&lt;p>下图为 CPU 内存和 GPU 内存间的连接性能。从图中可以看到 GPU 芯片和板载 GDDR5 GPU 内存之间的理论峰值带宽非常高，对于 Fermi C2050 GPU 来说为 144GB/s 。CPU 和 GPU 之间通过 PCIe Gen2 总线相连，这种连接的理论带宽要低得多，为 8GB/s（ PCIe Gen3 总线最大理论限制值是 16GB/s）。这种差距意味着如果管理不当的话，主机和设备间的数据传输会降低应用程序的整体性能。因此，CUDA 编程的一个基本原则应是尽可能地减少主机与设备之间的传输。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230902212815-2023-09-02.webp"
alt="20230902212815-2023-09-02" width="auto" loading="lazy">
&lt;/figure>
&lt;h2 id="三固定内存">三、固定内存&lt;/h2>
&lt;p>分配的主机内存默认是 pageable（可分页），它的意思也就是因页面错误导致的操作，该操作按照操作系统的要求将主机虚拟内存上的数据移动到不同的物理位置。虚拟内存给人一种比实际可用内存大得多的假象，就如同一级缓存好像比实际可用的片上内存大得多一样。&lt;/p>
&lt;p>GPU &lt;strong>不能在可分页主机内存上安全地访问数据&lt;/strong>，因为当主机操作系统在物理位置上移动该数据时，它无法控制。当从可分页主机内存传输数据到设备内存时，CUDA 驱动程序首先分配&lt;strong>临时页面锁定的或固定的&lt;/strong>主机内存，将主机源数据复制到固定内存中，然后从固定内存传输数据给设备内存，如下图左边部分所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230903003123-2023-09-03.webp"
alt="20230903003123-2023-09-03" width="auto" loading="lazy">
&lt;/figure>
&lt;p>左边是正常分配内存，传输过程是：锁页-复制到固定内存-复制到设备&lt;/p>
&lt;p>右边是分配时就是固定内存，直接传输到设备上。&lt;/p>
&lt;p>下面函数用来分配固定内存：&lt;/p>
&lt;pre>&lt;code class="language-c">cudaError_t cudaMallocHost(void ** devPtr,size_t count);
&lt;/code>&lt;/pre>
&lt;p>这个函数分配了 count 字节的主机内存，这些内存是页面锁定的并且对设备来说是可访问的。由于固定内存能被设备直接访问，所以它能用比可分页内存高得多的带宽进行读写。然而，分配过多的固定内存可能会降低主机系统的性能，因为它减少了用于存储虚拟内存数据的可分页内存的数量，其中分页内存对主机系统是可用的。&lt;/p>
&lt;p>固定的主机内存释放使用：&lt;/p>
&lt;pre>&lt;code class="language-c">cudaError_t cudaFreeHost(void * devPtr);
&lt;/code>&lt;/pre>
&lt;p>总的来说，固定内存的释放和分配成本比可分页内存要高很多，但是传输速度更快，所以对于大规模数据，固定内存效率更高。应该尽量使用流来使内存传输和计算之间同时进行。&lt;/p>
&lt;h2 id="四零拷贝内存">四、零拷贝内存&lt;/h2>
&lt;p>通常来说，主机不能直接访问设备变量，同时设备也不能直接访问主机变量。但有一个例外：零拷贝内存。&lt;strong>主机和设备都可以访问零拷贝内存&lt;/strong>。&lt;/p>
&lt;p>GPU 线程可以直接访问零拷贝内存。在 CUDA 核函数中使用零拷贝内存有以下几个优势。&lt;/p>
&lt;ul>
&lt;li>当设备内存不足时可利用主机内存&lt;/li>
&lt;li>避免主机和设备间的显式数据传输&lt;/li>
&lt;li>提高 PCIe 传输率&lt;/li>
&lt;/ul>
&lt;p>当使用零拷贝内存来共享主机和设备间的数据时，用户必须同步主机和设备间的内存访问，同时更改主机和设备的零拷贝内存中的数据将导致不可预知的后果。&lt;/p>
&lt;p>零拷贝内存是固定内存，不可分页，该内存映射到设备地址空间中。用户可以通过下列函数创建零拷贝内存：&lt;/p>
&lt;pre>&lt;code class="language-c">cudaError_t cudaHostAlloc(void ** pHost,size_t count,unsigned int flags)
&lt;/code>&lt;/pre>
&lt;p>最后一个标志参数，可以选择以下值：&lt;/p>
&lt;ul>
&lt;li>cudaHostAllocDefalt：和 cudaMallocHost 函数一致&lt;/li>
&lt;li>cudaHostAllocPortable：返回能被所有 CUDA 上下文使用的固定内存&lt;/li>
&lt;li>cudaHostAllocMapped：产生零拷贝内存，可以实现主机写入和设备读取被映射到设备地址空间中的主机内存&lt;/li>
&lt;li>cudaHostAllocWriteCombined：返回写结合内存，在某些设备上这种内存传输效率更高&lt;/li>
&lt;/ul>
&lt;p>注意，零拷贝内存虽然不需要显式的传递到设备上，但是设备还不能通过 pHost 直接访问对应的内存地址，设备需要访问主机上的零拷贝内存，需要先获得另一个地址，这个地址帮助设备访问到主机对应的内存，方法是：&lt;/p>
&lt;pre>&lt;code class="language-c">cudaError_t cudaHostGetDevicePointer(void ** pDevice,void * pHost,unsigned int flags)
&lt;/code>&lt;/pre>
&lt;p>pDevice 就是设备上访问主机零拷贝内存的指针了，此处 flags 必须设置为 0 。&lt;/p>
&lt;p>在进行频繁的读写操作时，使用零拷贝内存作为设备内存的补充将显著降低性能。因为每一次映射到内存的传输必须经过 PCIe 总线。与全局内存相比，延迟也显著增加。&lt;/p>
&lt;p>注意不要过度使用零拷贝内存。由于其延迟较高，从零拷贝内存中读取设备核函数可能很慢。&lt;/p>
&lt;h2 id="五统一虚拟寻址">五、统一虚拟寻址&lt;/h2>
&lt;p>计算能力为 2.0 及以上版本的设备支持一种特殊的寻址方式，称为&lt;strong>统一虚拟寻址（UVA）&lt;/strong>。UVA，在 CUDA 4.0 中被引入，支持 64 位 Linux 系统。有了 UVA，主机内存和设备内存可以共享同一个虚拟地址空间，如下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230903004449-2023-09-03.webp"
alt="20230903004449-2023-09-03" width="auto" loading="lazy">
&lt;/figure>
&lt;p>UVA 之前，我们要管理所有的设备和主机内存，尤其是它们的指针，零拷贝内存尤其麻烦。有了 UVA，由指针指向的内存空间对应用程序代码来说是透明的。&lt;/p>
&lt;p>通过 UVA，由 cudaHostAlloc 分配的固定主机内存具有相同的主机和设备指针。因此，可以将返回的指针直接传递给核函数。&lt;/p>
&lt;p>前面的零拷贝内存，可以知道以下几个方面：&lt;/p>
&lt;ul>
&lt;li>分配映射的固定主机内存&lt;/li>
&lt;li>使用 CUDA 运行时函数获取映射到固定内存的设备指针&lt;/li>
&lt;li>将设备指针传递给核函数&lt;/li>
&lt;/ul>
&lt;p>有了 UVA ，可以不用上面的那个获得设备上访问零拷贝内存的函数了：&lt;/p>
&lt;pre>&lt;code class="language-c">cudaError_t cudaHostGetDevicePointer(void ** pDevice, void * pHost, unsigned flags);
&lt;/code>&lt;/pre>
&lt;p>因为 UVA 之后，主机和设备的指针都是一样的，所以可以直接传递给核函数了。&lt;/p>
&lt;h2 id="六统一内存寻址">六、统一内存寻址&lt;/h2>
&lt;p>在 CUDA 6.0 中，引入了&lt;strong>统一内存寻址&lt;/strong>这一新特性，它用于简化 CUDA 编程模型中的内存管理。统一内存中创建了一个托管内存池，内存池中已分配的空间可以用相同的内存地址（即指针）在 CPU 和 GPU 上进行访问。底层系统在统一内存空间中自动在主机和设备之间进行数据传输。这种数据传输对应用程序是透明的，这大大简化了程序代码。&lt;/p>
&lt;p>统一内存寻址依赖于 UVA 的支持，但它们是完全不同的技术。 UVA 为系统中的所有处理器提供了一个单一的虚拟内存地址空间。但是， UVA 不会自动将数据从一个物理位置转移到另一个位置，这是统一内存寻址的一个特有功能。&lt;/p>
&lt;p>统一内存寻址提供了一个&lt;strong>单指针到数据&lt;/strong>模型，在概念上它类似于零拷贝内存。但是零拷贝内存在主机内存中进行分配，因此，由于受到在 PCIe 总线上访问零拷贝内存的影响，核函数的性能将具有较高的延迟。另一方面，统一内存寻址将内存和执行空间分离，因此可以根据需要将数据透明地传输到主机或设备上，以提升局部性和性能。&lt;/p>
&lt;p>托管内存指的是由底层系统自动分配的统一内存，未托管内存就是用户自己分配的内存，这时候对于核函数，可以传递给它两种类型的内存，已托管和未托管内存，可以同时传递。&lt;/p>
&lt;p>托管内存可以是静态的，也可以是动态的，添加 managed 关键字修饰托管内存变量。静态声明的托管内存作用域是文件，这一点可以注意一下。&lt;/p>
&lt;p>托管内存分配方式：&lt;/p>
&lt;pre>&lt;code class="language-c">cudaError_t cudaMallocManaged(void ** devPtr, size_t size, unsigned int flags);
&lt;/code>&lt;/pre>
&lt;p>这个函数分配 size 字节的托管内存，并用 devPtr 返回一个指针。该指针在所有设备和主机上都是有效的。使用托管内存的程序行为与使用未托管内存的程序副本行为在功能上是一致的。但是，使用托管内存的程序可以利用自动数据传输和重复指针消除功能。&lt;/p>
&lt;p>在 CUDA 6.0 中，设备代码不能调用 cudaMallocManaged 函数。所有的托管内存必须在主机端动态声明或者在全局范围内静态声明。&lt;/p>
&lt;h2 id="参考资料">参考资料&lt;/h2>
&lt;p>[1] CUDA C 编程权威指南，机械工业出版社，（美）程润伟（John Cheng） 等著&lt;/p></description></item><item><title>CUDA 基础：内存模型概述</title><link>https://cuterwrite.top/p/cuda-base-memory-model/</link><pubDate>Fri, 01 Sep 2023 04:00:00 +0000</pubDate><guid>https://cuterwrite.top/p/cuda-base-memory-model/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/47a9b8a012cf3a3f552c9aba3aeaa93fe669cf70.jpg@1256w_970h_!web-article-pic-2023-09-01.webp" alt="Featured image of post CUDA 基础：内存模型概述" />&lt;h1 id="cuda-基础内存模型概述">CUDA 基础：内存模型概述&lt;/h1>
&lt;p>内存的访问和管理是所有编程语言的重要部分。在现代加速器中，内存管理对高性能计算有着很大的影响。&lt;/p>
&lt;p>因为多数工作负载被加载和存储数据的速度所限制，所以有大量低延迟、高带宽的内存对性能是十分有利的。然而，大容量、高性能的内存造价高且不容易生产。因此，在现有的硬件存储子系统下，必须依靠&lt;strong>内存模型&lt;/strong>获得最佳的延迟和带宽。CUDA 内存模型结合了主机和设备的内存系统，展现了完整的内存层次结构，能显式地控制数据布局以优化性能。&lt;/p>
&lt;h2 id="一内存层次结构的优点">一、内存层次结构的优点&lt;/h2>
&lt;p>程序具有局部性特点，包括：&lt;/p>
&lt;ol>
&lt;li>时间局部性：如果一个数据被访问，那么它在不久的将来也会被访问。&lt;/li>
&lt;li>空间局部性：如果一个数据被访问，那么它附近的数据也会被访问。&lt;/li>
&lt;/ol>
&lt;p>现代计算机的内存结构主要如下：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230901232704-2023-09-01.webp"
alt="20230901232704-2023-09-01" width="auto" loading="lazy">
&lt;/figure>
&lt;p>一个内存层次结构由具有不同延迟、带宽和容量的多级内存组成。通常，随着从处理器到内存延迟的增加，内存的容量也在增加。&lt;/p>
&lt;p>CPU 和 GPU 的主存都采用的是 DRAM（动态随机存取存储器），而低延迟内存（如 CPU 一级缓存）使用的则是 SRAM（静态随机存取存储器）。内存层次结构中最大且最慢的级别通常使用磁盘或闪存驱动来实现。在这种内存层次结构中，当数据被处理器频繁使用时，该数据保存在低延迟、低容量的存储器中；而当该数据被存储起来以备后用时，数据就存储在高延迟、大容量的存储器中。这种内存层次结构符合大内存低延迟的设想。&lt;/p>
&lt;p>GPU 和 CPU 的内存设计有相似的准则和模型。但它们的主要区别是，CUDA 编程模型能将内存层次结构更好地呈现给用户，能让我们显式地控制它的行为。&lt;/p>
&lt;h2 id="二cuda-内存模型">二、CUDA 内存模型&lt;/h2>
&lt;p>对于程序员来说，一般有两种类型的存储器：&lt;/p>
&lt;ol>
&lt;li>可编程的：你需要显式地控制哪些数据存放在可编程内存中&lt;/li>
&lt;li>不可编程的：你不能决定数据的存放位置，程序将自动生成存放位置以获得良好的性能&lt;/li>
&lt;/ol>
&lt;p>CPU 内存结构中，一级二级缓存都是不可编程（完全不可控制）的存储设备。另一方面，CUDA 内存模型相对于 CPU 来说更为丰富，提出了多种可编程内存的类型：&lt;/p>
&lt;ul>
&lt;li>寄存器&lt;/li>
&lt;li>共享内存&lt;/li>
&lt;li>本地内存&lt;/li>
&lt;li>常量内存&lt;/li>
&lt;li>纹理内存&lt;/li>
&lt;li>全局内存&lt;/li>
&lt;/ul>
&lt;p>下图所示为这些内存空间的层次结构，每种都有不同的作用域、生命周期和缓存行为。一个核函数中的线程都有自己私有的&lt;strong>本地内存&lt;/strong>。一个线程块有自己的&lt;strong>共享内存&lt;/strong>，对同一线程块中所有线程都可见，其内容持续线程块的整个生命周期。所有线程都可以访问&lt;strong>全局内存&lt;/strong>。所有线程都能访问的只读内存空间有：&lt;strong>常量内存空间和纹理内存空间&lt;/strong>。全局内存、常量内存和纹理内存空间有不同的用途。&lt;strong>纹理内存&lt;/strong>为各种数据布局提供了不同的寻址模式和滤波模式。对于一个应用程序来说， &lt;strong>全局内存、常量内存和纹理内存&lt;/strong>中的内容具有相同的生命周期。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230901233955-2023-09-01.webp"
alt="20230901233955-2023-09-01" width="auto" loading="lazy">
&lt;/figure>
&lt;h3 id="1-寄存器">1. 寄存器&lt;/h3>
&lt;p>寄存器无论是在 CPU 还是在 GPU 都是速度最快的内存空间，但是和 CPU 不同的是 GPU 的寄存器储量要多一些，而且当我们在核函数内不加修饰的声明一个变量，此变量就存储在寄存器中，但是 CPU 运行的程序有些不同，只有当前在计算的变量存储在寄存器中，其余在主存中，使用时传输至寄存器。在核函数声明的数组中，&lt;strong>如果用于引用该数组的索引是常量且能在编译时确定&lt;/strong>，那么该数组也存储在寄存器中。&lt;/p>
&lt;p>寄存器变量对于每个线程来说都是私有的，一个核函数通常使用寄存器来保存需要频繁访问的线程私有变量。寄存器变量与核函数的生命周期相同。一旦核函数执行完毕，就不能对寄存器变量进行访问了。&lt;/p>
&lt;p>寄存器是 SM 中的稀缺资源，Fermi 架构中每个线程最多 63 个寄存器。Kepler 结构扩展到 255 个 寄存器，一个线程如果使用更少的寄存器，那么就会有更多的常驻线程块，SM 上并发的线程块越多，效率越高，性能和使用率也就越高。&lt;/p>
&lt;p>那么问题就来了，如果一个线程里面的变量太多，以至于寄存器完全不够呢？这时候寄存器发生溢出，本地内存就会过来帮忙存储多出来的变量，这种情况会对效率产生非常负面的影响，所以，不到万不得已，一定要避免此种情况发生。&lt;/p>
&lt;p>为了避免寄存器溢出，可以在核函数的代码中配置额外的信息来辅助编译器优化，比如：&lt;/p>
&lt;pre>&lt;code class="language-cpp">__global__ void
__lauch_bounds__(maxThreadaPerBlock, minBlocksPerMultiprocessor)
kernel(...) {
/* kernel code */
}
&lt;/code>&lt;/pre>
&lt;p>这里面在核函数定义前加了一个 关键字 &lt;strong>lauch_bounds&lt;/strong> ，然后它后面对应了两个变量：&lt;/p>
&lt;ol>
&lt;li>maxThreadaPerBlock：线程块内包含的最大线程数，线程块由核函数来启动&lt;/li>
&lt;li>minBlocksPerMultiprocessor：可选参数，每个 SM 中预期的最小的常驻内存块参数。注意，对于一定的核函数，优化的启动边界会因为不同的结构而不同
也可以在编译选项中加入 &lt;strong>-maxrregcount=32&lt;/strong> 来指定每个线程使用的最大寄存器数。&lt;/li>
&lt;/ol>
&lt;h3 id="2-本地内存">2. 本地内存&lt;/h3>
&lt;p>核函数中符合存储在寄存器中但不能进入被该核函数分配的寄存器空间中的变量将溢出到本地内存中。编译器可能存放到本地内存中的变量有：&lt;/p>
&lt;ul>
&lt;li>在编译时使用未知索引引用的本地数组&lt;/li>
&lt;li>可能会占用大量寄存器空间的较大本地结构体或数组&lt;/li>
&lt;li>任何不满足核函数寄存器限定条件的变量&lt;/li>
&lt;/ul>
&lt;p>本地内存实质上是和全局内存一样在同一块存储区域当中的，其访问特点——高延迟，低带宽。对于计算能力 2.0 以上的设备，本地内存存储在每个 SM 的一级缓存，或者设备的二级缓存上。&lt;/p>
&lt;h3 id="3-共享内存">3. 共享内存&lt;/h3>
&lt;p>在核函数中使用 &lt;strong>__shared__&lt;/strong> 修饰符修饰的变量存放在共享内存中。&lt;/p>
&lt;p>因为共享内存是片上内存，所以与本地内存或全局内存相比，它具有更高的带宽和更低的延迟。它的使用类似于 CPU 一级缓存，但它是可编程的。&lt;/p>
&lt;p>每一个 SM 都有一定数量的由线程块分配的共享内存。因此，必须非常小心不要过度使用共享内存，否则将在不经意间限制活跃线程束的数量。&lt;/p>
&lt;p>共享内存在核函数的范围内声明，其生命周期伴随着整个线程块。当一个线程块执行结束后，其分配的共享内存将被释放并重新分配给其他线程块。&lt;/p>
&lt;p>共享内存是线程之间相互通信的基本方式。因为共享内存是块内线程可见的，所以就有竞争问题的存在，也可以通过共享内存进行通信，当然，为了避免内存竞争，可以使用同步语句：&lt;/p>
&lt;pre>&lt;code class="language-cpp">__syncthreads();
&lt;/code>&lt;/pre>
&lt;p>此语句相当于在线程块执行时各个线程的一个障碍点，当块内所有线程都执行到本障碍点的时候才能进行下一步的计算，这样可以设计出避免内存竞争的共享内存使用程序。但是，该语句频繁使用会影响内核执行效率。SM 中的一级缓存和共享内存都使用 64KB 的片上内存，它通过静态划分，但在运行时可以通过如下指令进行动态配置：&lt;/p>
&lt;pre>&lt;code class="language-cpp">cudaError_t cudaFuncSetCacheConfig ( const void* func, cudaFuncCache cacheConfig )
&lt;/code>&lt;/pre>
&lt;p>这个函数在每个核函数的基础上配置了片上内存划分，为 func 指定的核函数设置了配置。支持的缓存配置如下：&lt;/p>
&lt;pre>&lt;code class="language-text">cudaFuncCachePreferNone // 无参考值，默认设置
cudaFuncCachePreferShared // 48k 共享内存，16k 一级缓存
cudaFuncCachePreferL1 // 48k 一级缓存，16k 共享内存
cudaFuncCachePreferEqual // 32k 一级缓存，32k 共享内存
&lt;/code>&lt;/pre>
&lt;p>Fermi 架构支持前三种，后面的设备都支持。&lt;/p>
&lt;h3 id="4-常量内存">4. 常量内存&lt;/h3>
&lt;p>常量内存驻留在设备内存中，每个 SM 都有专用的常量内存缓存，常量内存使用 &lt;strong>__constant__&lt;/strong> 修饰符修饰。&lt;/p>
&lt;p>常量变量必须在全局空间内和所有核函数之外进行声明。对于所有计算能力的设备，都只可以声明 64kB 的常量内存，常量内存是静态声明的，并对同一编译单元中的所有核函数可见。&lt;/p>
&lt;p>核函数只能从常量内存中读取数据（只读）。因此，常量内存必须在主机端使用下面的函数来初始化：&lt;/p>
&lt;pre>&lt;code class="language-cpp">cudaError_t cudaMemcpyToSymbol ( const void* symbol, const void* src, size_t count, size_t offset = 0, cudaMemcpyKind kind = cudaMemcpyHostToDevice )
&lt;/code>&lt;/pre>
&lt;p>这个函数将 count 个字节从 src 指向的内存复制到 symbol 指向的内存中，这个变量存放在设备的全局内存或常量内存中。在大多数情况下这个函数是同步的。&lt;/p>
&lt;p>线程束中的所有线程从相同的内存地址中读取数据时，常量内存表现最好。举个例子，数学公式中的系数就是一个很好的使用常量内存的例子，因为一个线程束中所有的线程使用相同的系数来对不同数据进行相同的计算。如果线程束里每个线程都从不同的地址空间读取数据，并且只读一次，那么常量内存中就不是最佳选择，因为每从一个常量内存中读取一次数据，都会广播给线程束里的所有线程。&lt;/p>
&lt;h3 id="5-纹理内存">5. 纹理内存&lt;/h3>
&lt;p>纹理内存驻留在设备内存中，并在每个 SM 的只读缓存中缓存。&lt;strong>纹理内存&lt;/strong>是一种通过指定的只读缓存访问的全局内存。只读缓存包括硬件滤波的支持，它可以将浮点插入作为读过程的一部分来执行。纹理内存是对&lt;strong>二维空间局部性&lt;/strong>的优化所以线程束里使用纹理内存访问二维数据的线程可以达到最优性能。对于一些应用程序来说，这是理想的内存，并由于缓存和滤波硬件的支持所以有较好的性能优势。然而对于另一些应用程序来说，与全局内存相比，使用纹理内存更慢。&lt;/p>
&lt;p>总的来说纹理内存设计目的应该是为了 GPU 本职工作显示设计的，但是对于某些特定的程序可能效果更好，比如需要滤波的程序，可以直接通过硬件完成。&lt;/p>
&lt;h3 id="6-全局内存">6. 全局内存&lt;/h3>
&lt;p>全局内存是 GPU 中最大、&lt;strong>延迟最高&lt;/strong>并且最常使用的内存。 global 指的是其作用域和生命周期。它的声明可以在任何 SM 设备上被访问到，并且贯穿应用程序的整个生命周期。一个全局内存变量可以被静态声明或动态声明。可以使用 &lt;strong>__device__&lt;/strong> 修饰符在设备代码中静态地声明一个变量。&lt;/p>
&lt;p>默认通过 cudaMalloc 声明的所有在 GPU 上访问的内存都是全局内存，也就是没有对内存进行任何优化。因为全局内存的性质，当有多个核函数同时执行的时候，如果使用到了同一全局变量，应注意内存竞争。&lt;/p>
&lt;p>全局内存访问是对齐，也就是一次要读取指定大小 $(32，64，128)$ 整数倍字节的内存，所以当线程束执行内存加载/存储时，需要满足的传输数量通常取决与以下两个因素：&lt;/p>
&lt;ol>
&lt;li>跨线程的内存地址分布&lt;/li>
&lt;li>内存事务的对齐方式&lt;/li>
&lt;/ol>
&lt;p>在一般情况下，用来满足内存请求的事务越多，未使用的字节被传输回的可能性就越高，这就造成了数据吞吐率的降低。&lt;/p>
&lt;p>对于一个给定的线程束内存请求，事务数量和数据吞吐率是由设备的计算能力来确定的。对于计算能力为 1.0 和 1.1 的设备，全局内存访问的要求是非常严格的。对于计算能力高于 1.1 的设备，由于内存事务被缓存，所以要求较为宽松。缓存的内存事务利用数据局部性来提高数据吞吐率。&lt;/p>
&lt;h3 id="7-gpu-缓存">7. GPU 缓存&lt;/h3>
&lt;p>与 CPU 缓存类似， GPU 缓存是不可编程的内存。在 GPU 上有 4 种缓存：&lt;/p>
&lt;ul>
&lt;li>一级缓存&lt;/li>
&lt;li>二级缓存&lt;/li>
&lt;li>只读常量缓存&lt;/li>
&lt;li>只读纹理缓存&lt;/li>
&lt;/ul>
&lt;p>每个 SM 都有一个一级缓存，所有的 SM 共享一个二级缓存。一级和二级缓存都被用来在存储本地内存和全局内存中的数据，也包括寄存器溢出的部分。对 Fermi GPU 和 Kepler K40 或其后发布的 GPU 来说，CUDA 允许我们配置读操作的数据是使用一级和二级缓存，还是只使用二级缓存。&lt;/p>
&lt;p>在 CPU 上，内存的加载和存储都可以被缓存。但是，在 GPU 上只有内存加载操作可以被缓存，内存存储操作不能被缓存。&lt;/p>
&lt;p>每个 SM 也有一个只读常量缓存和只读纹理缓存，它们用于在设备内存中提高来自于各自内存空间内的读取性能。&lt;/p>
&lt;h3 id="8-cuda-变量声明总结">8. CUDA 变量声明总结&lt;/h3>
&lt;p>用表格进行总结：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">修饰符&lt;/th>
&lt;th style="text-align:center">变量名&lt;/th>
&lt;th style="text-align:center">存储器&lt;/th>
&lt;th style="text-align:center">作用域&lt;/th>
&lt;th style="text-align:center">生命周期&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">无&lt;/td>
&lt;td style="text-align:center">float var&lt;/td>
&lt;td style="text-align:center">寄存器&lt;/td>
&lt;td style="text-align:center">线程&lt;/td>
&lt;td style="text-align:center">线程&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">无&lt;/td>
&lt;td style="text-align:center">float var[100]&lt;/td>
&lt;td style="text-align:center">本地&lt;/td>
&lt;td style="text-align:center">线程&lt;/td>
&lt;td style="text-align:center">线程&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">__shared__&lt;/td>
&lt;td style="text-align:center">float var*&lt;/td>
&lt;td style="text-align:center">共享内存&lt;/td>
&lt;td style="text-align:center">块&lt;/td>
&lt;td style="text-align:center">块&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">__device__&lt;/td>
&lt;td style="text-align:center">float var*&lt;/td>
&lt;td style="text-align:center">全局内存&lt;/td>
&lt;td style="text-align:center">全局&lt;/td>
&lt;td style="text-align:center">应用程序&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">__constant__&lt;/td>
&lt;td style="text-align:center">float var*&lt;/td>
&lt;td style="text-align:center">常量内存&lt;/td>
&lt;td style="text-align:center">全局&lt;/td>
&lt;td style="text-align:center">应用程序&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>设备存储器的重要特征：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">存储器&lt;/th>
&lt;th style="text-align:center">片上/片外&lt;/th>
&lt;th style="text-align:center">缓存&lt;/th>
&lt;th style="text-align:center">存取&lt;/th>
&lt;th style="text-align:center">范围&lt;/th>
&lt;th style="text-align:center">生命周期&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">寄存器&lt;/td>
&lt;td style="text-align:center">片上&lt;/td>
&lt;td style="text-align:center">n/a&lt;/td>
&lt;td style="text-align:center">R/W&lt;/td>
&lt;td style="text-align:center">一个线程&lt;/td>
&lt;td style="text-align:center">线程&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">本地&lt;/td>
&lt;td style="text-align:center">片外&lt;/td>
&lt;td style="text-align:center">1.0 以上有&lt;/td>
&lt;td style="text-align:center">R/W&lt;/td>
&lt;td style="text-align:center">一个线程&lt;/td>
&lt;td style="text-align:center">线程&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">共享&lt;/td>
&lt;td style="text-align:center">片上&lt;/td>
&lt;td style="text-align:center">n/a&lt;/td>
&lt;td style="text-align:center">R/W&lt;/td>
&lt;td style="text-align:center">块内所有线程&lt;/td>
&lt;td style="text-align:center">块&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">全局&lt;/td>
&lt;td style="text-align:center">片外&lt;/td>
&lt;td style="text-align:center">1.0 以上有&lt;/td>
&lt;td style="text-align:center">R/W&lt;/td>
&lt;td style="text-align:center">所有线程+主机&lt;/td>
&lt;td style="text-align:center">主机配置&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">常量&lt;/td>
&lt;td style="text-align:center">片外&lt;/td>
&lt;td style="text-align:center">有&lt;/td>
&lt;td style="text-align:center">R&lt;/td>
&lt;td style="text-align:center">所有线程+主机&lt;/td>
&lt;td style="text-align:center">主机配置&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">纹理&lt;/td>
&lt;td style="text-align:center">片外&lt;/td>
&lt;td style="text-align:center">有&lt;/td>
&lt;td style="text-align:center">R&lt;/td>
&lt;td style="text-align:center">所有线程+主机&lt;/td>
&lt;td style="text-align:center">主机配置&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="9-静态全局内存">9. 静态全局内存&lt;/h3>
&lt;p>CPU 内存有动态分配和静态分配两种类型，从内存位置来说，动态分配在堆上进行，静态分配在站上进行，在代码上的表现是一个需要 new，malloc 等类似的函数动态分配空间，并用 delete 和 free 来释放。在 CUDA 中也有类似的动态静态之分，需要 cudaMalloc 的就是动态分配，静态分配与动态分配相同是，也需要显式的将内存 copy 到设备端。下面代码是一个静态分配的例子：&lt;/p>
&lt;pre>&lt;code class="language-cpp">#include &amp;lt;cuda_runtime.h&amp;gt;
#include &amp;quot;dbg.h&amp;quot;
__device__ float devData;
__global__ void checkGlobalVariable()
{
printf(&amp;quot;Device: the value of devData is %f\n&amp;quot;, devData);
devData += 2.0f;
}
int main(int argc, char **argv)
{
float value = 3.14f;
CHECK(cudaMemcpyToSymbol(devData, &amp;amp;value, sizeof(float)));
printf(&amp;quot;Host: copied %f to the global variable\n&amp;quot;, value);
checkGlobalVariable&amp;lt;&amp;lt;&amp;lt;1, 1&amp;gt;&amp;gt;&amp;gt;();
CHECK(cudaMemcpyFromSymbol(&amp;amp;value, devData, sizeof(float)));
printf(&amp;quot;Host: the value changed by the kernel to %f\n&amp;quot;, value);
CHECK(cudaDeviceReset());
return EXIT_SUCCESS;
}
&lt;/code>&lt;/pre>
&lt;p>运行结果为：&lt;/p>
&lt;pre>&lt;code class="language-text">Host: copied 3.140000 to the global variable
Device: the value of devData is 3.140000
Host: the value changed by the kernel to 5.140000
&lt;/code>&lt;/pre>
&lt;p>唯一要注意的就是这一句：&lt;/p>
&lt;pre>&lt;code class="language-cpp">cudaMemcpyToSymbol(devData,&amp;amp;value,sizeof(float));
&lt;/code>&lt;/pre>
&lt;p>设备上的变量定义和主机变量定义的不同，设备变量在代码中定义的时候其实就是一个指针，这个指针指向何处，主机端是不知道的，指向的内容也不知道，想知道指向的内容，唯一的办法还是通过显式的办法即 cudaMemcpyToSymbol 传输过来。&lt;/p>
&lt;p>此外还需要注意的是：&lt;/p>
&lt;ol>
&lt;li>在主机端，devData 只是一个标识符，不是设备全局内存的变量地址&lt;/li>
&lt;li>在核函数中，devData 就是一个全局内存中的变量。主机代码不能直接访问设备变量，设备也不能访问主机变量，这就是 CUDA 编程与 CPU 多核最大的不同之处&lt;/li>
&lt;/ol>
&lt;p>一方面，是无法使用 cudaMemcpy 来给静态变量赋值的，除非：&lt;/p>
&lt;pre>&lt;code class="language-cpp">float *dptr = NULL;
cudaGetSymbolAddress((void**)&amp;amp;dptr,devData);
cudaMemcpy(dptr, &amp;amp;value, sizeof(float), cudaMemcpyHostToDevice);
&lt;/code>&lt;/pre>
&lt;p>另一方面，主机端不可以对设备变量进行取地址操作，该操作是非法的。想要得到 devData 的地址可以用下面方法：&lt;/p>
&lt;pre>&lt;code class="language-cpp">float *dptr = NULL;
cudaGetSymbolAddress((void**)&amp;amp;dptr, devData);
&lt;/code>&lt;/pre>
&lt;p>当然也有一个例外，可以直接从主机引用 GPU 内存——CUDA 固定内存。&lt;/p>
&lt;p>CUDA 运行时 API 能访问主机和设备变量，但这取决于你给正确的函数是否提供了正确的参数，使用运行时 API ，如果参数填错，尤其是主机和设备上的指针，结果是无法预测的。&lt;/p>
&lt;h2 id="参考资料">参考资料&lt;/h2>
&lt;p>[1] CUDA C 编程权威指南，机械工业出版社，（美）程润伟（John Cheng） 等著&lt;/p></description></item><item><title>CUDA 基础：线程束执行的本质</title><link>https://cuterwrite.top/p/cuda-base-warp/</link><pubDate>Thu, 31 Aug 2023 00:00:00 +0000</pubDate><guid>https://cuterwrite.top/p/cuda-base-warp/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230831184001-2023-08-31.webp" alt="Featured image of post CUDA 基础：线程束执行的本质" />&lt;h1 id="cuda-基础线程束执行的本质">CUDA 基础：线程束执行的本质&lt;/h1>
&lt;h2 id="1-线程束和线程块">1. 线程束和线程块&lt;/h2>
&lt;p>线程束是 SM 中基本的执行单元，当一个线程块的网格被启动后，网格中的线程块分布在 SM 中。一旦线程块被调度在一个 SM 上，线程块中的线程会被进一步划分为线程束。一个线程束由 32 个连续的线程组成（目前的 GPU 都是 32 个线程，但不保证未来是 32 个），在一个线程束中，所有的线程按照单指令多线程（SIMT）方式执行；也就是说，所有线程都执行相同的指令，每个线程在私有数据上进行操作。下图展示了线程块的逻辑视图和硬件视图之间的关系：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230831184443-2023-08-31.webp"
alt="20230831184443-2023-08-31" width="90%" loading="lazy">
&lt;/figure>
&lt;p>然而，从硬件的角度来看，所有的线程都被组织成了一维的，线程块可以被配置为一维、二维、三维的。在一个块中，每个线程都有唯一的 ID 。对于一维的线程块，唯一的线程 ID 被存储在 CUDA 的内置变量 threadIdx.x 中，并且，threadIdx.x 中拥有连续值得线程被分组到线程束中。例如，一个有 128 个线程的一维线程块被组织到 4 个线程束里，如下所示：&lt;/p>
&lt;pre>&lt;code class="language-text">warp0: thread 0, .........., thread 31
warp1: thread 32, ........., thread 63
warp2: thread 64, ........., thread 95
warp3: thread 96, ........., thread 127
&lt;/code>&lt;/pre>
&lt;p>线程块是一个逻辑产物，因为在计算机里，内存总是一维线性存在的，所以执行起来也是一维的访问线程块中的线程，但是我们在写程序的时候却可以以二维三维的方式进行，原因是方便我们写程序，比如处理图像或者三维的数据，三维块就会变得很直接，很方便。&lt;/p>
&lt;ul>
&lt;li>在块中，每个线程有唯一的编号（可能是个三维的编号），threadIdx&lt;/li>
&lt;li>网格中，每个线程块也有唯一的编号(可能是个三维的编号)，blockIdx&lt;/li>
&lt;li>那么每个线程就有在网格中的唯一编号。&lt;/li>
&lt;/ul>
&lt;p>用 $x$ 维度作为最内层的维度， $y$ 维度作为第二个维度， $z$ 维度作为最外层的维度，则二维或三维线程块的逻辑布局可以转化为一维物理布局。例如，对于一个给定的二维线程块，在一个块中每个线程的独特标识符都可以用内置变量 threadIdx 和 blockDim 来计算：&lt;/p>
&lt;pre>&lt;code class="language-c">tid = threadIdx.x + threadIdx.y * blockDim.x;
&lt;/code>&lt;/pre>
&lt;p>对于一个三维线程块，可以用下面的方式计算：&lt;/p>
&lt;pre>&lt;code class="language-c">tid = threadIdx.x + threadIdx.y * blockDim.x + threadIdx.z * blockDim.x * blockDim.y;
&lt;/code>&lt;/pre>
&lt;p>在 C 语言中，假设三维数组 t 保存了所有的线程，那么 (threadIdx.x, threadIdx.y, threadIdx.z) 就相当于：&lt;/p>
&lt;pre>&lt;code class="language-c">t[z][y][x];
&lt;/code>&lt;/pre>
&lt;p>一个线程块的线程束的数量可以根据下式确定：&lt;/p>
&lt;p>$$
\mathrm{WarpsPerBlock} = \left \lceil \frac{\mathrm{threadsPerBlock}}{\mathrm{warpSize}} \right \rceil
$$&lt;/p>
&lt;p>因此，硬件总是给一个线程块分配一定数量的线程束。线程束不会在不同的线程块之间分离。如果线程块的大小不是线程束大小的偶数倍，那么在最后的线程束里有些线程就不会活跃。比如说一个在 $x$ 轴中有 40 个线程、在 $y$ 轴中有 2 个线程的二维线程块。从应用程序的角度来看，在一个二维网格中共有 80 个线程。&lt;/p>
&lt;p>硬件为这个线程块配置了 3 个线程束，使总共 96 个硬件线程去支持 80 个软件线程。注意，最后半个线程束是不活跃的。即使这些线程未被使用，它们仍然消耗 SM 的资源，如寄存器。&lt;/p>
&lt;div class="notice notice-info" >
&lt;div class="notice-title">&lt;svg t="1705940100069" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6252" width="200" height="200">&lt;path d="M512 64C264.6 64 64 264.6 64 512s200.6 448 448 448 448-200.6 448-448S759.4 64 512 64z m32 664c0 4.4-3.6 8-8 8h-48c-4.4 0-8-3.6-8-8V456c0-4.4 3.6-8 8-8h48c4.4 0 8 3.6 8 8v272z m-32-344c-26.5 0-48-21.5-48-48s21.5-48 48-48 48 21.5 48 48-21.5 48-48 48z" p-id="6253" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>&lt;strong>从逻辑角度来看：&lt;/strong> 线程块是线程的集合，它们可以组织为一维、二维或三维布局。&lt;/p>
&lt;p>&lt;strong>从硬件角度来看：&lt;/strong> 线程块是一维线程束的集合。在线程块中线程被组织成一维布局，每 32 个连续线程组成一个线程束。&lt;/p>&lt;/div>
&lt;h2 id="2-线程束分化">2. 线程束分化&lt;/h2>
&lt;p>控制流是高级编程语言的基本构造中的一种。GPU 支持传统的、C 风格的、显式的控制流结构，例如，if···then···else、for 和 while。&lt;/p>
&lt;p>CPU 拥有复杂的硬件以执行分支预测，也就是在每个条件检查中预测应用程序的控制流会使用哪个分支。如果预测正确，CPU 中的分支只需付出很小的性能代价。如果预测不正确，CPU 可能会停止运行很多个周期，因为指令流水线被清空了。我们不必完全理解为什么 CPU 擅长处理复杂的控制流。这个解释只是作为对比的背景。当我们的程序包含大量的分支判断时，从程序角度来说，程序的逻辑是很复杂的，因为一个分支就会有两条路可以走，如果有 10 个分支，那么一共有 1024 条路走，CPU 采用流水线化作业，如果每次等到分支执行完再执行下面的指令会造成很大的延迟，所以现在处理器都采用分支预测技术，而 CPU 的这项技术相对于 GPU 来说高级了不止一点点，而这也是 GPU 与 CPU 的不同，设计初衷就是为了解决不同的问题。CPU 适合逻辑复杂计算量不大的程序，比如操作系统，控制系统，GPU 适合大量计算简单逻辑的任务，所以被用来算数。&lt;/p>
&lt;p>GPU 是相对简单的设备，它没有复杂的分支预测机制。一个线程束中的所有线程在同周期中必须执行相同的指令，如果一个线程执行一条指令，那么线程束中的所有线程都必须执行该指令。如果在同一线程束中的线程使用不同的路径通过同一个应用程序，这可能会产生问题。例如，思考下面的语句:&lt;/p>
&lt;pre>&lt;code class="language-c">if (cond) {
...
} else {
...
}
&lt;/code>&lt;/pre>
&lt;p>假设在一个线程束中有 16 个线程执行这段代码，cond 为 true，但对于其他 16 个来说 cond 为 false 。一半的线程束需要执行 if 语句块中的指令，而另一半需要执行 else 语句块中的指令。在同一线程束中的线程执行不同的指令，被称为&lt;strong>线程束分化&lt;/strong>。我们已经知道，在一个线程束中所有线程在每个周期中必须执行相同的指令，所以线程束分化似乎会产生一个悖论。&lt;/p>
&lt;p>如果一个线程束中的线程产生分化，线程束将连续执行每一个分支路径，而禁用不执行这一路径的线程。线程束分化会导致性能明显地下降。在前面的例子中可以看到，线程中并行线程的数量减少了一半: 只有 16 个线程同时活跃地执行，而其他 16 个被禁用了。条件分支越多，并行性削弱越严重。此外，线程束分化只发生在同一个线程束中。在不同的线程束中，不同的条件值不会引起线程束分化。&lt;/p>
&lt;p>执行过程如下：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230831205444-2023-08-31.webp"
alt="20230831205444-2023-08-31" width="90%" loading="lazy">
&lt;/figure>
&lt;p>因为线程束分化导致的性能下降就应该用线程束的方法解决，根本思路是&lt;strong>避免同一个线程束内的线程分化&lt;/strong>，而让我们能控制线程束内线程行为的原因是线程块中线程分配到线程束是有规律的而不是随机的。这就使得我们根据线程编号来设计分支是可以的，补充说明下，当一个线程束中所有的线程都执行 if 或者，都执行 else 时，不存在性能下降；只有当线程束内有分歧产生分支的时候，性能才会急剧下降。&lt;/p>
&lt;p>线程束内的线程是可以被我们控制的，那么我们就把都执行 if 的线程塞到一个线程束中，或者让一个线程束中的线程都执行 if ，另外线程都执行 else 的这种方式可以将效率提高很多。&lt;/p>
&lt;p>举以下一个低效的核函数为例：&lt;/p>
&lt;pre>&lt;code class="language-c">__global__ void mathKernel1(float *c) {
int tid = blockIdx.x * blockDim.x + threadIdx.x;
float a, b;
a = b = 0.0f;
if (tid % 2 == 0) {
a = 100.0f;
} else {
b = 200.0f;
}
c[tid] = a + b;
}
&lt;/code>&lt;/pre>
&lt;p>这种情况下，线程束内的线程会产生分化，因为线程束内的线程会有一半执行 if ，另一半执行 else ，这样就会导致性能下降。我们可以通过下面的方式来优化：&lt;/p>
&lt;pre>&lt;code class="language-c">__global__ void mathKernel2(float *c) {
int tid = blockIdx.x * blockDim.x + threadIdx.x;
float a, b;
a = b = 0.0f;
if ((tid / warpSize) % 2 == 0) {
a = 100.0f;
} else {
b = 200.0f;
}
c[tid] = a + b;
}
&lt;/code>&lt;/pre>
&lt;p>假设只配置一个大小为 64 的一维线程块，那么只有 2 个线程束，第一个线程束内的线程编号 tid 从 0 到 31， tid / warpSize 都等于 0，那么都执行 if 语句；第二个线程束内的线程编号 tid 从 32 到 63， tid / warpSize 都等于 1，那么都执行 else 语句。这样就避免了线程束内的线程分化，效率较高。&lt;/p>
&lt;p>在 CUDA 中，对线程束分化的评价指标为&lt;strong>分支效率 (branch efficiency)&lt;/strong>，它是一个 0 到 100 之间的百分比，表示线程束中的线程在同一周期中执行的分支指令的百分比。分支效率越高，性能越好。分支效率的计算公式如下：&lt;/p>
&lt;p>$$
\mathrm{branch\ efficiency} = \frac{\mathrm{branches - divergent\ branches}}{\mathrm{branches}}
$$&lt;/p>
&lt;p>以上线程束分化例子的完整代码如下：&lt;/p>
&lt;a href="https://github.com/PKUcoldkeyboard/cuda-demo/blob/main/Chap3/simpleDivergence.cu" target="_blank" class="card-github fetch-waiting no-styling"
repo="PKUcoldkeyboard/cuda-demo" id="repo-bQu4o1SjEFvzCxAf-card">
&lt;div class="gc-titlebar">
&lt;div class="gc-titlebar-left">
&lt;div class="gc-owner">
&lt;div id="repo-bQu4o1SjEFvzCxAf-avatar" class="gc-avatar">&lt;/div>
&lt;div class="gc-user">PKUcoldkeyboard&lt;/div>
&lt;/div>
&lt;div class="gc-divider">/&lt;/div>
&lt;div class="gc-repo">cuda-demo&lt;/div>
&lt;/div>
&lt;div class="github-logo">&lt;/div>
&lt;/div>
&lt;div id="repo-bQu4o1SjEFvzCxAf-description" class="gc-description">Waiting for api.github.com...&lt;/div>
&lt;div class="gc-infobar">
&lt;div id="repo-bQu4o1SjEFvzCxAf-stars" class="gc-stars">0&lt;/div>
&lt;div id="repo-bQu4o1SjEFvzCxAf-forks" class="gc-forks">0&lt;/div>
&lt;div id="repo-bQu4o1SjEFvzCxAf-license" class="gc-license">unkown&lt;/div>
&lt;div id="repo-bQu4o1SjEFvzCxAf-language" class="gc-language">Waiting...&lt;/div>
&lt;/div>
&lt;/a>
&lt;script id="repo-bQu4o1SjEFvzCxAf-script" type="text/javascript" defer>
fetch('https://api.cuterwrite.top/api/repos/PKUcoldkeyboard\/cuda-demo', {
referrerPolicy: "no-referrer"
})
.then(response => response.json())
.then(data => {
document.getElementById('repo-bQu4o1SjEFvzCxAf-description').innerText = data.description.replace(
/:[a-zA-Z0-9_]+:/g, '');
document.getElementById('repo-bQu4o1SjEFvzCxAf-language').innerText = data.language;
document.getElementById('repo-bQu4o1SjEFvzCxAf-forks').innerText = Intl.NumberFormat('en-us', {
notation: "compact",
maximumFractionDigits: 1
}).format(data.forks).replaceAll("\u202f", '');
document.getElementById('repo-bQu4o1SjEFvzCxAf-stars').innerText = Intl.NumberFormat('en-us', {
notation: "compact",
maximumFractionDigits: 1
}).format(data.stargazers_count).replaceAll("\u202f", '');
const avatarEl = document.getElementById('repo-bQu4o1SjEFvzCxAf-avatar');
avatarEl.style.backgroundImage = 'url(' + data.owner.avatar_url + ')';
avatarEl.style.backgroundColor = 'transparent';
if (data.license?.spdx_id) {
document.getElementById('repo-bQu4o1SjEFvzCxAf-license').innerText = data.license.spdx_id
} else {
document.getElementById('repo-bQu4o1SjEFvzCxAf-license').classList.add = "no-license"
};
document.getElementById('repo-bQu4o1SjEFvzCxAf-card').classList.remove("fetch-waiting");
console.log("[GITHUB-CARD] Loaded card for PKUcoldkeyboard\/cuda-demo.")
}).catch(err => {
const c = document.getElementById('repo-bQu4o1SjEFvzCxAf-card');
c.classList.add("fetch-error");
console.warn("[GITHUB-CARD] (Error) Loading card for PKUcoldkeyboard\/cuda-demo.")
})
&lt;/script>
&lt;p>编译命令为：（强制 CUDA 编译器不利用分支预测去优化内核，使用 Tesla T4 GPU）&lt;/p>
&lt;pre>&lt;code class="language-shell">nvcc -g -G -arch=sm_75 -o simpleDivergence simpleDivergence.cu
&lt;/code>&lt;/pre>
&lt;p>运行结果为：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230831223456-2023-08-31.webp"
alt="20230831223456-2023-08-31" width="90%" loading="lazy">
&lt;/figure>
&lt;p>代码中的 Warmup 部分是提前启动一次 GPU，因为第一次启动 GPU 时会比第二次速度慢一些，具体原因未知，可以去查一下 CUDA 的相关技术文档了解内容。我们可以通过 Nvidia Nsight Compute 来查看分支效率（&lt;strong>旧版的 nvprof 被弃用了&lt;/strong>，metrics 参数对应的修改可以参考 &lt;a class="link" href="https://blog.csdn.net/weixin_44334901/article/details/128596081" target="_blank" rel="noopener" >CUDA 编程性能分析工具 nvprof/ncu &amp;ndash;metrics 参数含义
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
，而且运行 ncu 时候必须使用 root 权限），结果如下所示：&lt;/p>
&lt;pre>&lt;code class="language-text">[58735] simpleDivergence@127.0.0.1
warmingup(float *) (1, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
Section: Command line profiler metrics
---------------------------------------------------- ----------- ------------
Metric Name Metric Unit Metric Value
---------------------------------------------------- ----------- ------------
smsp_sass_average_branch_targets_threads_uniform.pct 100.00%
---------------------------------------------------- ----------- ------------
mathKernel1(float *) (1, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
Section: Command line profiler metrics
---------------------------------------------------- ----------- ------------
Metric Name Metric Unit Metric Value
---------------------------------------------------- ----------- ------------
smsp_sass_average_branch_targets_threads_uniform.pct 83.33%
---------------------------------------------------- ----------- ------------
mathKernel2(float *) (1, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
Section: Command line profiler metrics
---------------------------------------------------- ----------- ------------
Metric Name Metric Unit Metric Value
---------------------------------------------------- ----------- ------------
smsp_sass_average_branch_targets_threads_uniform.pct 100.00%
---------------------------------------------------- ----------- ------------
mathKernel3(float *) (1, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
Section: Command line profiler metrics
---------------------------------------------------- ----------- ------------
Metric Name Metric Unit Metric Value
---------------------------------------------------- ----------- ------------
smsp_sass_average_branch_targets_threads_uniform.pct 71.43%
---------------------------------------------------- ----------- ------------
mathKernel4(float *) (1, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
Section: Command line profiler metrics
---------------------------------------------------- ----------- ------------
Metric Name Metric Unit Metric Value
---------------------------------------------------- ----------- ------------
smsp_sass_average_branch_targets_threads_uniform.pct 100.00%
---------------------------------------------------- ----------- ------------
&lt;/code>&lt;/pre>
&lt;p>CUDA 的 nvcc 编译器仍然是在 mathKernel1 和 mathKernel3 上执行有限的优化，以保证分支效率在 50% 以上。注意，mathKernel2 不报告分支分化的唯一原因是它的分支粒度是线程束大小的倍数。此外，把 mathKernel1 中的 if&amp;hellip;else 语句分离为 mathKernel3 的多个 if 语句，可以使分支分化的数量翻倍。&lt;/p>
&lt;h2 id="3-资源分配">3. 资源分配&lt;/h2>
&lt;p>前面提到，每个 SM 上执行的基本单位是线程束，也就是说，单指令通过指令调度器广播给某线程束的全部线程，这些线程同一时刻执行同一命令，当然也有分支情况，也有很多线程束没执行，那么这些没执行的线程束情况又如何呢？可以将这些没执行的线程束分为两类：一类是已经激活的，也就是说这类线程束其实已经在 SM 上准备就绪了，只是没轮到它执行，这时候它的状态为阻塞，另一类是可能分配到 SM 了，但是还没上片，这类就称之为未激活线程束。而每个 SM 上有多少个线程束处于激活状态，取决于以下资源：&lt;/p>
&lt;ul>
&lt;li>程序计数器&lt;/li>
&lt;li>寄存器&lt;/li>
&lt;li>共享内存&lt;/li>
&lt;/ul>
&lt;p>线程束一旦被激活来到片上，那么它就不会再离开 SM 直到执行结束。&lt;/p>
&lt;p>每个 SM 都有 32 位的寄存器组，每个架构寄存器的数量不一样，其存储于寄存器文件中，为每个线程进行分配，同时，固定数量的共享内存，在线程块之间分配。&lt;/p>
&lt;p>一个 SM 上被分配多少个线程块和线程束取决于 SM 中可用的寄存器和共享内存，以及内核需要的寄存器和共享内存大小。 当 kernel 占用的资源较少，那么更多的线程处于活跃状态，相反则线程越少。&lt;/p>
&lt;ol>
&lt;li>寄存器资源的分配&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230901150726-2023-09-01.webp"
alt="20230901150726-2023-09-01" width="90%" loading="lazy">
&lt;/figure>
&lt;ol start="2">
&lt;li>共享内存的分配&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230901150743-2023-09-01.webp"
alt="20230901150743-2023-09-01" width="90%" loading="lazy">
&lt;/figure>
&lt;p>上面讲的主要是线程束，如果从逻辑上来看线程块的话，可用资源的分配也会影响常驻线程块的数量。特别是当 SM 内的资源没办法处理一个完整块，那么程序将无法启动。&lt;/p>
&lt;p>以下是资源列表：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230901150843-2023-09-01.webp"
alt="20230901150843-2023-09-01" width="90%" loading="lazy">
&lt;/figure>
&lt;p>当寄存器和共享内存分配给了线程块，这个线程块处于活跃状态，所包含的线程束称为活跃线程束。活跃的线程束又分为三类：&lt;/p>
&lt;ul>
&lt;li>选定的线程束&lt;/li>
&lt;li>阻塞的线程束&lt;/li>
&lt;li>符合条件的线程束&lt;/li>
&lt;/ul>
&lt;p>当 SM 要执行某个线程束的时候，执行的这个线程束叫做选定的线程束，准备要执行的叫符合条件的线程束，如果线程束不符合条件还没准备好就是阻塞的线程束。
满足下面的要求，线程束才算是符合条件的：&lt;/p>
&lt;ul>
&lt;li>32 个 CUDA 核心可以用于执行&lt;/li>
&lt;li>执行所需要的资源全部就位&lt;/li>
&lt;/ul>
&lt;p>Kepler 活跃的线程束数量从开始到结束不得大于 64，可以等于。任何周期选定的线程束小于等于 4 。由于计算资源是在线程束之间分配的，且线程束的整个生命周期都在片上，所以线程束的上下文切换是非常快速的。下一节将说明如何通过大量的活跃的线程束切换来隐藏延迟。&lt;/p>
&lt;h2 id="4-延迟隐藏">4. 延迟隐藏&lt;/h2>
&lt;p>SM 依赖线程级并行，以最大化功能单元的利用率，因此，利用率与常驻线程束的数量直接相关。在指令发出和完成之间的时钟周期被定义为&lt;strong>指令延迟&lt;/strong>。当每个时钟周期中所有的线程调度器都有一个符合条件的线程束时，可以达到计算资源的完全利用。这就可以保证，通过在其他常驻线程束中发布其他指令，可以&lt;strong>隐藏每个指令的延迟&lt;/strong>。&lt;/p>
&lt;p>与在 CPU 上用 C 语言编程相比，&lt;strong>延迟隐藏&lt;/strong>在 CUDA 编程中尤为重要。CPU 核心是为同时最小化延迟一个或两个线程而设计的，而 GPU 则是为处理大量并发和轻量级线程以最大化吞吐量而设计的。GPU 的指令延迟被其他线程束的计算隐藏。&lt;/p>
&lt;p>考虑到指令延迟，指令可以被分为两种基本类型：&lt;/p>
&lt;ul>
&lt;li>算术指令&lt;/li>
&lt;li>内存指令&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>算术指令延迟&lt;/strong>是一个算术操作从开始到它产生输出之间的时间。&lt;strong>内存指令延迟&lt;/strong>是指发送出的加载或存储操作和数据到达目的地之间的时间。对于每种情况，相应的延迟大约为：&lt;/p>
&lt;ul>
&lt;li>算术操作为 10～20 个周期&lt;/li>
&lt;li>全局内存访问为 400～800 个周期&lt;/li>
&lt;/ul>
&lt;p>下图是阻塞线程束到可选线程束的过程逻辑图：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230901151502-2023-09-01.webp"
alt="20230901151502-2023-09-01" width="90%" loading="lazy">
&lt;/figure>
&lt;p>其中线程束 0 （Warp 0） 阻塞两段时间后恢复可选模式，但是在这段等待时间中，SM 没有闲置。那么至少需要多少线程，线程束来保证最小化延迟呢？可以根据利特尔法则（Little&amp;rsquo;s Law）提供一个合理的近似值。它起源于队列理论中的一个定理，也可以用于 GPU 中：&lt;/p>
&lt;p>$$
\mathrm{所需线程束}=\mathrm{延迟}\times \mathrm{吞吐量}
$$&lt;/p>
&lt;div class="notice notice-info" >
&lt;div class="notice-title">&lt;svg t="1705940100069" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6252" width="200" height="200">&lt;path d="M512 64C264.6 64 64 264.6 64 512s200.6 448 448 448 448-200.6 448-448S759.4 64 512 64z m32 664c0 4.4-3.6 8-8 8h-48c-4.4 0-8-3.6-8-8V456c0-4.4 3.6-8 8-8h48c4.4 0 8 3.6 8 8v272z m-32-344c-26.5 0-48-21.5-48-48s21.5-48 48-48 48 21.5 48 48-21.5 48-48 48z" p-id="6253" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>注意带宽和吞吐量的区别，带宽一般指的是理论峰值，最大每个时钟周期能执行多少个指令，吞吐量是指实际操作过程中每分钟处理多少个指令。简单来说，带宽通常是指理论峰值，而吞吐量是指已达到的值。&lt;/p>&lt;/div>
&lt;p>这个可以想象成一个瀑布，像这样，绿箭头是线程束，只要线程束足够多，吞吐量是不会降低的：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230901151942-2023-09-01.webp"
alt="20230901151942-2023-09-01" width="90%" loading="lazy">
&lt;/figure>
&lt;p>假设在 kernel 里一条指令的平均延迟是 5 个周期。为了保持在每个周期内执行 6 个线程束的吞吐量，则至少需要 30 个未完成的线程束。&lt;/p>
&lt;p>对于算术运算来说，其所需的并行可以表示成隐藏算术延迟所需要的操作数量。下面的表格出了 Fermi 和 Kepler 设备所需的操作数量。示例中的算术运算是一个 32 位的浮点数乘加运算 (a + b $\times$ c)，表示在每个 SM 中每个时钟周期内的操作数量。吞吐量因不同的算术指令而不同。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230901152413-2023-09-01.webp"
alt="20230901152413-2023-09-01" width="90%" loading="lazy">
&lt;/figure>
&lt;p>吞吐量由 SM 中每个周期内的操作数量确定，而执行一条指令的一个线程束对应 32 个操作。因此，为保持计算资源的充分利用，对于 Fermi GPU 而言，每个 SM 中所需的线程束数量通过计算为 $640 \div 32 = 20 $ 个线程束。因此，算术运算所需的并行可以用操作的数量或线程束的数量来表示。这个简单的单位转换表明，有两种方法可以提高并行：&lt;/p>
&lt;ul>
&lt;li>指令级并行（ILP）：一个线程中有很多独立的指令&lt;/li>
&lt;li>线程级并行（TLP）：很多并发地符合条件的线程&lt;/li>
&lt;/ul>
&lt;p>同样，与指令周期隐藏延迟类似，&lt;strong>内存隐藏延迟&lt;/strong>是靠内存读取的并发操作来完成的，需要注意的是，指令隐藏的关键目的是使用全部的计算资源，而内存读取的延迟隐藏是为了使用全部的内存带宽，内存延迟的时候，计算资源正在被别的线程束使用，所以我们不考虑内存读取延迟的时候计算资源在做了什么，我们的根本目的是把计算资源，内存读取的带宽资源全部使用满，这样就能达到理论的最大效率。同样下表根据利特尔法则给出了需要多少线程束来最小化内存读取延迟，不过这里有个单位换算过程，机器的性能指标内存读取速度给出的是 GB/s 的单位，而我们需要的是每个时钟周期读取字节数，所以要用这个速度除以频率，例如 Tesla C2070 的内存带宽是 144 GB/s，转化成时钟周期： $\frac{144\mathrm{GB/s}}{1.566 \mathrm{GHz}}=92\mathrm{B/t}$，这样就能得到单位时间周期的内存带宽了。即下表的数据：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230901152915-2023-09-01.webp"
alt="20230901152915-2023-09-01" width="90%" loading="lazy">
&lt;/figure>
&lt;p>需要说明的是这个速度不是单个 SM 的而是整个 GPU 设备的。Fermi 需要并行的读取 74KB 的数据才能让 GPU 带宽满载，如果每个线程读取 4 个字节，我们大约需要 18500 个线程，大约 579 个线程束才能达到这个峰值。&lt;/p>
&lt;p>所以，延迟的隐藏取决于活动的线程束的数量，数量越多，隐藏得越好，但是线程束的数量又受到上面的说的资源影响。所以这里就需要寻找最优的执行配置来达到最优的延迟隐藏。&lt;/p>
&lt;p>那么我们怎么样确定一个线程束的下界呢，使得当高于这个数字时 SM 的延迟能充分的隐藏，其实这个公式很简单，也很好理解，就是 SM 的计算核心数乘以单条指令的延迟，比如 32 个单精度浮点计算器，每次计算延迟 20 个时钟周期，那么我需要最少 $32 \times 20 =640$ 个线程使设备处于忙碌状态。然而，这只是一个下边界。&lt;/p>
&lt;h2 id="5-占用率">5. 占用率&lt;/h2>
&lt;p>在每个 CUDA 核心里指令是顺序执行的。当一个线程束阻塞时，SM 切换执行其他符合条件的线程束。理想情况下，我们想要有足够的线程束占用设备的核心。占用率是每个 SM 中活跃的线程束占最大线程束数量的比值。即：&lt;/p>
&lt;p>$$
\mathrm{Occupancy} = \frac{\mathrm{Active\ Warps}}{\mathrm{Max\ Warps}}
$$&lt;/p>
&lt;p>通过以下代码可以查询设备的最大线程束数量：&lt;/p>
&lt;pre>&lt;code class="language-c">int dev = 0;
cudaDeviceProp deviceProp;
CHECK(cudaGetDeviceProperties(&amp;amp;deviceProp, dev));
log_info(&amp;quot;Device %d: %s&amp;quot;, dev, deviceProp.name);
log_info(&amp;quot;Number of SMs: %d&amp;quot;, deviceProp.multiProcessorCount);
log_info(&amp;quot;Total amount of constant memory: %4.2f KB&amp;quot;, deviceProp.totalConstMem / 1024.0);
log_info(&amp;quot;Total amount of shared memory per block: %4.2f KB&amp;quot;,
deviceProp.sharedMemPerBlock / 1024.0);
log_info(&amp;quot;Total number of registers available per block: %d&amp;quot;, deviceProp.regsPerBlock);
log_info(&amp;quot;Warp size: %d&amp;quot;, deviceProp.warpSize);
log_info(&amp;quot;Maximum number of threads per block: %d&amp;quot;, deviceProp.maxThreadsPerBlock);
log_info(&amp;quot;Maximum number of threads per multiprocessor: %d&amp;quot;,
deviceProp.maxThreadsPerMultiProcessor);
log_info(&amp;quot;Maximum number of warps per multiprocessor: %d&amp;quot;,
deviceProp.maxThreadsPerMultiProcessor / 32);
return 0;
&lt;/code>&lt;/pre>
&lt;p>输出结果为：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230901155126-2023-09-01.webp"
alt="20230901155126-2023-09-01" width="90%" loading="lazy">
&lt;/figure>
&lt;p>可以看到 RTX4090 最大 64 个线程束每个 SM。&lt;/p>
&lt;p>内核使用寄存器的数量会影响 SM 内线程束的数量，nvcc 的编译选项也有手动控制寄存器的使用。也可以通过调整线程块内线程的多少来提高占用率，当然要合理不能太极端：&lt;/p>
&lt;ul>
&lt;li>小的线程块：每个线程块中线程太少，会在所有资源没用完就达到了线程束的最大要求&lt;/li>
&lt;li>大的线程块：每个线程块中太多线程，会导致每个 SM 中每个线程可用的硬件资源较少。&lt;/li>
&lt;/ul>
&lt;p>一个确定网格和线程块大小的基本准则如下：&lt;/p>
&lt;ol>
&lt;li>保持每个块中线程数量是线程束大小（32）的倍数&lt;/li>
&lt;li>避免块太小：每个块至少要有 128 或 256 个线程&lt;/li>
&lt;li>根据内核资源的需求调整块大小&lt;/li>
&lt;li>块的数量要远远多于 SM 的数量，从而在设备中可以显示有足够的并行&lt;/li>
&lt;li>通过实验得到最佳执行配置和资源使用情况&lt;/li>
&lt;/ol>
&lt;p>尽管在每种情况下会遇到不同的硬件限制，但它们都会导致计算资源未被充分利用，阻碍隐藏指令和内存延迟的并行的建立。占用率唯一注重的是在每个 SM 中并发线程或线程束的数量。然而，充分的占用率不是性能优化的唯一目标。内核一旦达到一定级别的占用率，进一步增加占用率可能不会改进性能。为了提高性能，可以调整很多其他因素。&lt;/p>
&lt;h2 id="6-同步">6. 同步&lt;/h2>
&lt;p>栅栏同步是一个原语，它在许多并行编程语言中都很常见。在 CUDA 中，同步可以在两个级别执行：&lt;/p>
&lt;ul>
&lt;li>线程块内同步&lt;/li>
&lt;li>系统级别&lt;/li>
&lt;/ul>
&lt;p>块级别的就是同一个块内的线程会同时停止在某个设定的位置，用&lt;/p>
&lt;pre>&lt;code class="language-c">__syncthreads();
&lt;/code>&lt;/pre>
&lt;p>这个函数完成，这个函数只能同步同一个块内的线程，不能同步不同块内的线程，想要同步不同块内的线程，就只能让核函数执行完成，控制程序交换主机，这种方式来同步所有线程。当__syncthreads 被调用时，在同一个线程块中每个线程都必须等待直至该线程块中所有其他线程都已经达到这个同步点。线程产生的所有全局内存和共享内存访问，将会在栅栏后对线程块中所有其他的线程可见。该函数可以协调同一个块中线程之间的通信，但它强制线程束空闲，从而可能对性能产生负面影响。&lt;/p>
&lt;p>在不同的块之间没有线程同步。块间同步，唯一安全的方法是在每个内核执行结束端使用全局同步点；也就是说，在全局同步之后，终止当前的核函数，开始执行新的核函数。&lt;/p>
&lt;p>不同块中的线程不允许相互同步，因此 GPU 可以以任意顺序执行块。这使得 CUDA 程序在大规模并行 GPU 上是可扩展的。&lt;/p>
&lt;h2 id="7-可扩展性">7. 可扩展性&lt;/h2>
&lt;p>对于任何并行应用程序而言，可扩展性是一个理想的特性。可扩展性意味着为并行应用程序提供了额外的硬件资源，相对于增加的资源，并行应用程序会产生加速。例如，若一个 CUDA 程序在两个 SM 中是可扩展的，则与在一个 SM 中运行相比，在两个 SM 中运行会使运行时间减半。一个可扩展的并行程序可以高效地使用所有的计算资源以提高性能。可扩展性意味着增加的计算核心可以提高性能。串行代码本身是不可扩展的，因为在成千上万的内核上运行一个串行单线程应用程序，对性能是没有影响的。并行代码有可扩展的潜能，但真正的可扩展性取决于算法设计和硬件特性。&lt;/p>
&lt;p>能够在可变数量的计算核心上执行相同的应用程序代码的能力被称为&lt;strong>透明可扩展性&lt;/strong>。一个透明的可扩展平台拓宽了现有应用程序的应用范围，并减少了开发人员的负担，因为它们可以避免新的或不同的硬件产生的变化。可扩展性比效率更重要。一个可扩展但效率很低的系统可以通过简单添加硬件核心来处理更大的工作负载。一个效率很高但不可扩展的系统可能很快会达到可实现性能的上限。&lt;/p>
&lt;p>CUDA 内核启动时，线程块分布在多个 SM 中。网格中的线程块以并行或连续或任意的顺序被执行。这种独立性使得 CUDA 程序在任意数量的计算核心间可以扩展。&lt;/p>
&lt;p>下图展示了 CUDA 架构可扩展性的一个例子。左侧的 GPU 有两个 SM， 可以同时执行两个块；右侧的 GPU 有 4 个 SM ，可以同时执行 4 个块。不修改任何代码，一个应用程序可以在不同的 GPU 配置上运行，并且所需的执行时间根据可用的资源而改变。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230901163747-2023-09-01.webp"
alt="20230901163747-2023-09-01" width="90%" loading="lazy">
&lt;/figure>
&lt;h2 id="参考资料">参考资料&lt;/h2>
&lt;p>[1] CUDA C 编程权威指南，机械工业出版社，（美）程润伟（John Cheng） 等著&lt;/p></description></item><item><title>CUDA 编程：从基础到应用</title><link>https://cuterwrite.top/p/cuda-tutorial/</link><pubDate>Tue, 11 Jul 2023 00:00:00 +0000</pubDate><guid>https://cuterwrite.top/p/cuda-tutorial/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/ba25bc69cbefbfac1287056fee570cee2b6458ff.jpg@1256w_880h_!web-article-pic.avif" alt="Featured image of post CUDA 编程：从基础到应用" />&lt;h1 id="cuda-编程从基础到应用">CUDA 编程：从基础到应用&lt;/h1>
&lt;h2 id="一什么是-cuda">一、什么是 CUDA&lt;/h2>
&lt;ul>
&lt;li>CUDA 是 NVIDIA 推出的一种通用并行计算平台和编程模型，可以利用 GPU 的强大计算能力来加速各种应用程序。&lt;/li>
&lt;li>CUDA 的优势在于：
&lt;ul>
&lt;li>提供了一套简单易用的编程接口，支持 C/C++/Fortran/Python 等多种语言。&lt;/li>
&lt;li>兼容各种操作系统，如 Windows/Linux/MacOS 等。&lt;/li>
&lt;li>支持多种 GPU 架构，如 Tesla/Fermi/Kepler/Maxwell/Pascal/Volta/Turing/Ampere 等。&lt;/li>
&lt;li>支持多种并行编程模式，如数据并行/任务并行/流并行等。&lt;/li>
&lt;li>支持多种优化技术，如共享内存/纹理内存/常量内存/原子操作/同步机制等。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Why CUDA?
&lt;ul>
&lt;li>串行速度提升已经结束
&lt;ul>
&lt;li>无法继续提升频率&lt;/li>
&lt;li>难以继续降低功耗&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>当前计算机性能提升趋势
&lt;ul>
&lt;li>计算机没有变得更快，而是变得更宽
&lt;ul>
&lt;li>多核 CPU、GPU、超级计算机&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>数据级别并行
&lt;ul>
&lt;li>同样的指令作用于多个数据&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>线程级别的并行&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="二cpu-vs-gpu">二、CPU vs. GPU&lt;/h2>
&lt;ul>
&lt;li>CPU 和 GPU 都是计算机中的重要组件，但它们有着不同的设计目标和特点。&lt;/li>
&lt;li>CPU 的特点是：
&lt;ul>
&lt;li>拥有较少的核心数，但每个核心都有较高的时钟频率和较强的运算能力。&lt;/li>
&lt;li>拥有较大的缓存和复杂的控制流机制，可以有效地降低延迟和提高串行代码的性能。&lt;/li>
&lt;li>更适合于处理复杂的单任务或少量的多任务，如操作系统/数据库/编译器等。&lt;/li>
&lt;li>类比于摩托车，可以灵活地在城市中穿梭。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>GPU 的特点是：
&lt;ul>
&lt;li>拥有较多的核心数，但每个核心都有较低的时钟频率和较弱的运算能力。&lt;/li>
&lt;li>拥有较小的缓存和简单的控制流机制，可以有效地提高吞吐量和利用大规模并行架构。&lt;/li>
&lt;li>更适合于处理大量相似或简单的任务，如图形渲染/科学计算/机器学习等。&lt;/li>
&lt;li>类比于大巴车，可以承载更多的乘客。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>CPU&lt;/th>
&lt;th>GPU&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>缓存&lt;/td>
&lt;td>大缓存：掩盖较长的存储器延迟&lt;/td>
&lt;td>小缓存：但通过更快的存储提高吞吐量&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>运算器&lt;/td>
&lt;td>强大的运算器：降低运算延迟&lt;/td>
&lt;td>更节能的运算器：延迟大但总吞吐量大&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>控制机制&lt;/td>
&lt;td>复杂的控制机制：分支预测等&lt;/td>
&lt;td>简单的控制流机制：无分支预测&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>线程&lt;/td>
&lt;td>线程高度轻量级：大量并发&lt;/td>
&lt;td>线程高度轻量级：大量并发&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="三异构计算">三、异构计算&lt;/h2>
&lt;ul>
&lt;li>异构计算是指利用不同类型的处理器协同工作来完成一个任务，如 CPU+GPU、CPU+FPGA、CPU+ASIC 等。&lt;/li>
&lt;li>异构计算的优势在于：
&lt;ul>
&lt;li>可以充分发挥每种处理器的特长，提高性能和效率。&lt;/li>
&lt;li>可以降低功耗和成本，延长设备寿命和节约资源。&lt;/li>
&lt;li>可以增加灵活性和可扩展性，适应不同场景和需求。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>异构计算的挑战在于：
&lt;ul>
&lt;li>需要设计合适的编程模型和接口，实现不同处理器之间的协调和通信。&lt;/li>
&lt;li>需要考虑不同处理器之间的负载均衡和数据一致性，避免性能瓶颈和错误发生。&lt;/li>
&lt;li>需要优化不同处理器之间的数据传输和转换，减少开销和延迟。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>CPU+GPU
&lt;ul>
&lt;li>利用 CPU 处理复杂控制流&lt;/li>
&lt;li>利用 GPU 处理大规模运算&lt;/li>
&lt;li>CPU 与 GPU 之间通过 PCIe 总线通信
&lt;ul>
&lt;li>新显卡支持 NVLink 连接（5-12 倍 PCIe3.0)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="四cuda-编程模型">四、CUDA 编程模型&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>CUDA 编程模型是基于数据并行思想设计的一种分层抽象模型，可以将一个复杂的问题分解为多个简单的子问题，并将其映射到 GPU 上执行。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>CUDA 编程模型包括以下几个层次：&lt;/p>
&lt;ul>
&lt;li>线程（thread）：线程是 CUDA 中最基本的执行单元，每个线程都有自己独立的寄存器、指令指针、栈空间等。&lt;/li>
&lt;li>块（block）：块是由多个线程组成的一维或二维的逻辑分组，每个块都有自己独立的共享内存、同步机制等。&lt;/li>
&lt;li>网格（grid）：网格是由多个块组成的一维或二维的逻辑分组，每个网格都有自己独立的全局内存、常量内存、纹理内存等。&lt;/li>
&lt;li>设备（device）：设备是指 GPU 本身，包括多个流式处理器（SM）、多个 CUDA 核心（core）、多个缓存、总线等。&lt;/li>
&lt;li>主机（host）：主机是指 CPU 本身，包括内存、硬盘、键盘、鼠标等。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>CUDA 编程模型的执行流程如下：&lt;/p>
&lt;ul>
&lt;li>在主机端编写并行代码，称为核函数（kernel），并使用&lt;code>__global__&lt;/code>修饰符标记。&lt;/li>
&lt;li>在主机端调用核函数，并使用&lt;code>&amp;lt;&amp;lt;&amp;lt; grid,block &amp;gt;&amp;gt;&amp;gt;&lt;/code>语法指定网格和块的维度，称为执行配置。&lt;/li>
&lt;li>在设备端执行核函数，每个块被分配到一个 SM 上，每个线程被分配到一个 core 上。&lt;/li>
&lt;li>在设备端完成核函数后，返回主机端继续执行后续代码。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>2 级架构&lt;/p>
&lt;ul>
&lt;li>每个 GPU 拥有多个 Streaming Multiprocessor(SM)
&lt;ul>
&lt;li>具体数目及设计因产品而异&lt;/li>
&lt;li>SM 共用显存&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>每个 SM 拥有多个 CUDA core
&lt;ul>
&lt;li>数目因产品而异&lt;/li>
&lt;li>Core 共用调度器和指令缓存&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>2 级架构下的执行模型：线程束（warp）&lt;/p>
&lt;ul>
&lt;li>CUDA 线程以 32 个为一组在 GPU 上执行
&lt;ul>
&lt;li>线程束以单指令多线程的方式运行（SIMT）
&lt;ul>
&lt;li>所有线程在不同数据上执行相同的指令&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>SMIT、SIMD、SMT
&lt;ul>
&lt;li>灵活度：SIMD &amp;lt; SIMT &amp;lt; SMT&lt;/li>
&lt;li>性能： SIMD &amp;gt; SIMT &amp;gt; SMT&lt;/li>
&lt;li>SIMT 与 SIMD 相比：多个状态寄存器，多个地址，独立的执行路径&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>SM 负责调度并执行线程束
&lt;ul>
&lt;li>线程束调度时会产生上下文切换&lt;/li>
&lt;li>调度方式因架构而异&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Host 与 device&lt;/p>
&lt;ul>
&lt;li>Host（CPU）相关：运行在 CPU 上的代码及主机内存&lt;/li>
&lt;li>Device（GPU）相关：运行在 GPU 上的代码及显存（设备内存）&lt;/li>
&lt;li>通过在主机上调用核函数（kernel）执行并行代码&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>指明 host 与 device 代码&lt;/p>
&lt;ul>
&lt;li>&lt;code>__host__&lt;/code>从主机端调用，在主机端执行&lt;/li>
&lt;li>&lt;code>__global__&lt;/code>从主机端调用，在设备端执行&lt;/li>
&lt;li>&lt;code>__device__&lt;/code>从设备端调用，在设备端执行&lt;/li>
&lt;li>&lt;code>__host__&lt;/code>和&lt;code>__device__&lt;/code>可以一起使用&lt;/li>
&lt;li>&lt;code>&amp;lt;&amp;lt;&amp;lt; 1,4 &amp;gt;&amp;gt;&amp;gt;&lt;/code>：执行配置
&lt;ul>
&lt;li>指明网格中有 1 个块&lt;/li>
&lt;li>每块中有 4 个线程&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>cudaDeviceSynchronize()
&lt;ul>
&lt;li>与 OpenMP 不同，CUDA 核函数为异步执行&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>核函数限制条件（&lt;code>__global__&lt;/code>函数）
&lt;ul>
&lt;li>只能访问设备内存&lt;/li>
&lt;li>必须返回 void&lt;/li>
&lt;li>不支持可变数量的参数&lt;/li>
&lt;li>参数不可为引用类型&lt;/li>
&lt;li>不支持静态变量&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>指明网格及块的维度&lt;/p>
&lt;ul>
&lt;li>形式为&lt;code>&amp;lt;&amp;lt;&amp;lt; grid,block &amp;gt;&amp;gt;&amp;gt;&lt;/code>
&lt;ul>
&lt;li>grid 与 block 为 dim3 类型&lt;/li>
&lt;li>grid 与 block 的大小受到计算能力的限制&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/grid-of-thread-blocks.webp"
alt="grid-of-thread-blocks" width="auto" loading="lazy">
&lt;/figure>
&lt;ul>
&lt;li>GPU 架构与线程执行
&lt;ul>
&lt;li>一个 CUDA core 执行一个线程&lt;/li>
&lt;li>一个 SM 执行一个 block 中的线程&lt;/li>
&lt;li>GPU 中执行 grid 中的所有线程&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>确定线程编号
&lt;ul>
&lt;li>使用内置变量 threadIdx、blockIdx、blockDim&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>CUDA 编程例子：向量加法
&lt;pre>&lt;code class="language-c">__global__ void VecAdd(int *a, int *b, int *c)
{
int tid = blockIdx.x;
if (tid &amp;lt; N) {
c[tid] = a[tid] + b[tid];
}
}
int main()
{
...
// Kernel invocation with N threads
VecAdd&amp;lt;&amp;lt;&amp;lt;1, N&amp;gt;&amp;gt;&amp;gt;(A, B, C);
...
}
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>GPU 内存管理：&lt;/p>
&lt;ul>
&lt;li>创建：cudaMalloc&lt;/li>
&lt;li>拷贝：cudaMemcpy
&lt;ul>
&lt;li>使用 cudaMemcpyHostToDevice 与 cudaMemcpyDeviceToHost 指明拷贝方向&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>释放：cudaFree&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>处理错误&lt;/p>
&lt;ul>
&lt;li>使用宏定义&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>block 中最大线程限制：n 必须不大于 1024&lt;/p>
&lt;/li>
&lt;li>
&lt;p>同一个 block 只在一个 SM 上执行：没有充分利用 GPU 计算资源&lt;/p>
&lt;/li>
&lt;li>
&lt;p>思路：使用多个 block&lt;/p>
&lt;ul>
&lt;li>每个 block 使用 m 个 thread（如 m=32）&lt;/li>
&lt;li>grid,block 设置：&lt;code>&amp;lt;&amp;lt;&amp;lt; n/m, m &amp;gt;&amp;gt;&amp;gt;&lt;/code>
&lt;ul>
&lt;li>n 无法被 m 整除？&lt;/li>
&lt;li>需对 n/m 向上取整&lt;/li>
&lt;li>需判断 tid 是否会超过范围&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>确定 thread 的全局编号&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="五cuda-线程执行模型">五、CUDA 线程执行模型&lt;/h2>
&lt;ul>
&lt;li>逻辑视图
&lt;ul>
&lt;li>每个线程块由一个 SM 执行&lt;/li>
&lt;li>由硬件调度&lt;/li>
&lt;li>无法控制线程块的执行顺序&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>硬件视图
&lt;ul>
&lt;li>所有线程块在硬件上都是一维的&lt;/li>
&lt;li>三维线程将沿 x-&amp;gt;y-&amp;gt;z 的顺序展开到一维&lt;/li>
&lt;li>展开后的一维线程每 32 个形成一个线程束
&lt;ul>
&lt;li>最后不足 32 的部分也将创建线程
&lt;ul>
&lt;li>不活跃&lt;/li>
&lt;li>仍将消耗 SM 资源&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>线程束调度
&lt;ul>
&lt;li>线程束切换开销为 0
&lt;ul>
&lt;li>SM 保存每个线程束的执行上下文&lt;/li>
&lt;li>在整个线程束的生命周期中保存于芯片内&lt;/li>
&lt;li>上下文切换没有损失&lt;/li>
&lt;li>可切换同一 SM 上不同线程块的线程束&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>SM 中常驻线程块数量受可用资源限制
&lt;ul>
&lt;li>资源：程序计数器、寄存器、共享内存&lt;/li>
&lt;li>活跃线程束：具备计算资源的线程束
&lt;ul>
&lt;li>Kepler 上最大为 64&lt;/li>
&lt;li>选定的线程束：被调度到执行单元的线程束（Kepler 上最大为 4）&lt;/li>
&lt;li>符合条件的线程束：准备执行但尚未执行&lt;/li>
&lt;li>阻塞的线程束：没做好执行准备（指令参数未就绪，无可用 CUDA core）&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>活跃线程束于延迟隐藏
&lt;ul>
&lt;li>满载：线程调度器在每个时钟周期都有符合条件的线程束&lt;/li>
&lt;li>通过调度符合条件的线程束，可以有效的掩盖指令延迟
&lt;ul>
&lt;li>算数指令：算数操作从开始到产生输出（10~20 时钟周期）&lt;/li>
&lt;li>内存指令：发出加载/存储操作到数据到达目的地（全局内存~800 时钟周期）&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>应适当增加活跃线程束
&lt;ul>
&lt;li>Little&amp;rsquo;s law&lt;/li>
&lt;li>线程数不宜过少（每个线程处理的任务数与线程数需要平衡）&lt;/li>
&lt;li>线程块资源不易过多（如，共享内存的大小与活跃线程块数量需要平衡）&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>线程束执行
&lt;ul>
&lt;li>每个线程束以 SIMD 方式在 SM 上执行
&lt;ul>
&lt;li>线程束内同时执行同样语句&lt;/li>
&lt;li>线程束外的视角看来为 SIMT&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>分支分化
&lt;ul>
&lt;li>线程束出现不同的控制流&lt;/li>
&lt;li>性能优化：避免分支分化，因为线程束只能执行相同的逻辑，在执行某一个路径的线程时会禁用另一路径的线程。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>busy waiting vs signal
&lt;ul>
&lt;li>busy waiting：如，使用 while 循环不断检查条件是否满足&lt;/li>
&lt;li>signal：当条件满足由系统发送指令
&lt;ul>
&lt;li>__syncthreads()：只能在线程块内同步，不能在不同的线程块同步&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>busy waiting 的问题：死锁&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>减少分支分化的影响
&lt;ul>
&lt;li>减少 if 语句
&lt;ul>
&lt;li>尤其是减少基于 threadIdx 的 if 语句&lt;/li>
&lt;li>使用条件赋值代替条件语句&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>平衡分支执行时间
&lt;ul>
&lt;li>避免出现执行时间过长的分支&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="六cuda-原子操作">六、CUDA 原子操作&lt;/h2>
&lt;ul>
&lt;li>原子指令
&lt;ul>
&lt;li>执行过程不能分解为更小的部分：不被中断&lt;/li>
&lt;li>避免竞争条件出现&lt;/li>
&lt;li>竞争条件
&lt;ul>
&lt;li>程序运行结果依赖于不可控的执行顺序&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>CUDA 原子操作：
&lt;ul>
&lt;li>基本操作：atomicCAS
&lt;ul>
&lt;li>其它所有原子操作均可由 atomicCAS()实现&lt;/li>
&lt;li>CAS：compare and swap
&lt;ul>
&lt;li>读取目标位置(address)并与预期值(old_val)进行比较
&lt;ul>
&lt;li>相等则将 new_val 写入目标位置&lt;/li>
&lt;li>不相等则不发生变化&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>返回目标位置中原值：可用来检查 CAS 操作是否成功&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>原子指令与并发控制：原子指令在并发控制中起着重要的作用。在多线程或多进程的环境中，当多个线程或进程尝试同时访问和修改共享数据时，如果没有适当的控制机制，可能会导致数据的不一致性。原子指令通过确保某些操作在执行过程中不会被其他线程或进程中断，来避免这种情况。&lt;/li>
&lt;li>竞争条件与死锁：竞争条件是并发编程中的一个主要问题，它发生在两个或更多的线程或进程在无序或未同步的情况下访问和修改共享数据，导致结果不可预测。原子指令是解决竞争条件的一种方法，但也可能引入另一个问题 - 死锁。死锁是指两个或更多的进程或线程互相等待对方释放资源，导致所有进程或线程都无法继续执行。&lt;/li>
&lt;li>CUDA 原子操作与 GPU 编程：在 GPU 编程中，由于大量的线程并行执行，可能会有多个线程同时访问和修改同一块内存。CUDA 的原子操作提供了一种机制，使得在这种情况下仍能保证数据的一致性。然而，过度依赖原子操作可能会导致性能下降，因为它们违反了 GPU 编程的基本原则——并行执行。因此，在设计 GPU 算法时，应尽量减少原子操作的使用，或者寻找可以避免使用原子操作的算法。&lt;/li>
&lt;li>CUDA 原子操作的应用：在某些情况下，CUDA 原子操作是必要的。例如，在统计或计数问题中，需要多个线程共享一个计数器，并且每个线程都可能需要增加计数器的值。在这种情况下，使用 CUDA 原子操作可以保证计数器的正确性。另一个例子是图形处理，其中可能需要多个线程同时更新像素的值。使用 CUDA 原子操作可以避免同时更新导致的数据不一致问题。&lt;/li>
&lt;/ul></description></item></channel></rss>