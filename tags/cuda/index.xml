<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>CUDA on cuterwrite</title>
        <link>https://cuterwrite.top/tags/cuda/</link>
        <description>Recent content in CUDA on cuterwrite</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>cuterwrite</copyright>
        <lastBuildDate>Tue, 11 Jul 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://cuterwrite.top/tags/cuda/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>CUDA编程：从基础到应用</title>
        <link>https://cuterwrite.top/p/cuda-tutorial/</link>
        <pubDate>Tue, 11 Jul 2023 00:00:00 +0000</pubDate>
        
        <guid>https://cuterwrite.top/p/cuda-tutorial/</guid>
        <description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/ba25bc69cbefbfac1287056fee570cee2b6458ff.jpg@1256w_880h_!web-article-pic.avif" alt="Featured image of post CUDA编程：从基础到应用" /&gt;&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;  &lt;em&gt;generated with &lt;a class=&#34;link&#34; href=&#34;https://github.com/thlorenz/doctoc&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DocToc&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#cuda%E7%BC%96%E7%A8%8B%E4%BB%8E%E5%9F%BA%E7%A1%80%E5%88%B0%E5%BA%94%E7%94%A8&#34; &gt;CUDA编程：从基础到应用&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#%E4%B8%80%E4%BB%80%E4%B9%88%E6%98%AFcuda&#34; &gt;一、什么是CUDA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#%E4%BA%8Ccpu-vs-gpu&#34; &gt;二、CPU vs. GPU&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#%E4%B8%89%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97&#34; &gt;三、异构计算&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%9B%9Bcuda%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B&#34; &gt;四、CUDA编程模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#%E4%BA%94cuda%E7%BA%BF%E7%A8%8B%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9E%8B&#34; &gt;五、CUDA线程执行模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#%E5%85%ADcuda%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C&#34; &gt;六、CUDA原子操作&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h1 id=&#34;cuda编程从基础到应用&#34;&gt;CUDA编程：从基础到应用&lt;/h1&gt;
&lt;h2 id=&#34;一什么是cuda&#34;&gt;一、什么是CUDA&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;CUDA是NVIDIA推出的一种通用并行计算平台和编程模型，可以利用GPU的强大计算能力来加速各种应用程序。&lt;/li&gt;
&lt;li&gt;CUDA的优势在于：
&lt;ul&gt;
&lt;li&gt;提供了一套简单易用的编程接口，支持C/C++/Fortran/Python等多种语言。&lt;/li&gt;
&lt;li&gt;兼容各种操作系统，如Windows/Linux/MacOS等。&lt;/li&gt;
&lt;li&gt;支持多种GPU架构，如Tesla/Fermi/Kepler/Maxwell/Pascal/Volta/Turing/Ampere等。&lt;/li&gt;
&lt;li&gt;支持多种并行编程模式，如数据并行/任务并行/流并行等。&lt;/li&gt;
&lt;li&gt;支持多种优化技术，如共享内存/纹理内存/常量内存/原子操作/同步机制等。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Why CUDA?
&lt;ul&gt;
&lt;li&gt;串行速度提升已经结束
&lt;ul&gt;
&lt;li&gt;无法继续提升频率&lt;/li&gt;
&lt;li&gt;难以继续降低功耗&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;当前计算机性能提升趋势
&lt;ul&gt;
&lt;li&gt;计算机没有变得更快，而是变得更宽
&lt;ul&gt;
&lt;li&gt;多核CPU、GPU、超级计算机&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;数据级别并行
&lt;ul&gt;
&lt;li&gt;同样的指令作用于多个数据&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;线程级别的并行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;二cpu-vs-gpu&#34;&gt;二、CPU vs. GPU&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;CPU和GPU都是计算机中的重要组件，但它们有着不同的设计目标和特点。&lt;/li&gt;
&lt;li&gt;CPU的特点是：
&lt;ul&gt;
&lt;li&gt;拥有较少的核心数，但每个核心都有较高的时钟频率和较强的运算能力。&lt;/li&gt;
&lt;li&gt;拥有较大的缓存和复杂的控制流机制，可以有效地降低延迟和提高串行代码的性能。&lt;/li&gt;
&lt;li&gt;更适合于处理复杂的单任务或少量的多任务，如操作系统/数据库/编译器等。&lt;/li&gt;
&lt;li&gt;类比于摩托车，可以灵活地在城市中穿梭。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;GPU的特点是：
&lt;ul&gt;
&lt;li&gt;拥有较多的核心数，但每个核心都有较低的时钟频率和较弱的运算能力。&lt;/li&gt;
&lt;li&gt;拥有较小的缓存和简单的控制流机制，可以有效地提高吞吐量和利用大规模并行架构。&lt;/li&gt;
&lt;li&gt;更适合于处理大量相似或简单的任务，如图形渲染/科学计算/机器学习等。&lt;/li&gt;
&lt;li&gt;类比于大巴车，可以承载更多的乘客。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;CPU&lt;/th&gt;
&lt;th&gt;GPU&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;缓存&lt;/td&gt;
&lt;td&gt;大缓存：掩盖较长的存储器延迟&lt;/td&gt;
&lt;td&gt;小缓存：但通过更快的存储提高吞吐量&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;运算器&lt;/td&gt;
&lt;td&gt;强大的运算器：降低运算延迟&lt;/td&gt;
&lt;td&gt;更节能的运算器：延迟大但总吞吐量大&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;控制机制&lt;/td&gt;
&lt;td&gt;复杂的控制机制：分支预测等&lt;/td&gt;
&lt;td&gt;简单的控制流机制：无分支预测&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;线程&lt;/td&gt;
&lt;td&gt;线程高度轻量级：大量并发&lt;/td&gt;
&lt;td&gt;线程高度轻量级：大量并发&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;三异构计算&#34;&gt;三、异构计算&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;异构计算是指利用不同类型的处理器协同工作来完成一个任务，如CPU+GPU、CPU+FPGA、CPU+ASIC等。&lt;/li&gt;
&lt;li&gt;异构计算的优势在于：
&lt;ul&gt;
&lt;li&gt;可以充分发挥每种处理器的特长，提高性能和效率。&lt;/li&gt;
&lt;li&gt;可以降低功耗和成本，延长设备寿命和节约资源。&lt;/li&gt;
&lt;li&gt;可以增加灵活性和可扩展性，适应不同场景和需求。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;异构计算的挑战在于：
&lt;ul&gt;
&lt;li&gt;需要设计合适的编程模型和接口，实现不同处理器之间的协调和通信。&lt;/li&gt;
&lt;li&gt;需要考虑不同处理器之间的负载均衡和数据一致性，避免性能瓶颈和错误发生。&lt;/li&gt;
&lt;li&gt;需要优化不同处理器之间的数据传输和转换，减少开销和延迟。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CPU+GPU
&lt;ul&gt;
&lt;li&gt;利用CPU处理复杂控制流&lt;/li&gt;
&lt;li&gt;利用GPU处理大规模运算&lt;/li&gt;
&lt;li&gt;CPU与GPU之间通过PCIe总线通信
&lt;ul&gt;
&lt;li&gt;新显卡支持NVLink连接（5-12倍PCIe3.0)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;四cuda编程模型&#34;&gt;四、CUDA编程模型&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;CUDA编程模型是基于数据并行思想设计的一种分层抽象模型，可以将一个复杂的问题分解为多个简单的子问题，并将其映射到GPU上执行。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CUDA编程模型包括以下几个层次：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;线程（thread）：线程是CUDA中最基本的执行单元，每个线程都有自己独立的寄存器、指令指针、栈空间等。&lt;/li&gt;
&lt;li&gt;块（block）：块是由多个线程组成的一维或二维的逻辑分组，每个块都有自己独立的共享内存、同步机制等。&lt;/li&gt;
&lt;li&gt;网格（grid）：网格是由多个块组成的一维或二维的逻辑分组，每个网格都有自己独立的全局内存、常量内存、纹理内存等。&lt;/li&gt;
&lt;li&gt;设备（device）：设备是指GPU本身，包括多个流式处理器（SM）、多个CUDA核心（core）、多个缓存、总线等。&lt;/li&gt;
&lt;li&gt;主机（host）：主机是指CPU本身，包括内存、硬盘、键盘、鼠标等。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CUDA编程模型的执行流程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在主机端编写并行代码，称为核函数（kernel），并使用&lt;code&gt;__global__&lt;/code&gt;修饰符标记。&lt;/li&gt;
&lt;li&gt;在主机端调用核函数，并使用&lt;code&gt;&amp;lt;&amp;lt;&amp;lt; grid,block &amp;gt;&amp;gt;&amp;gt;&lt;/code&gt;语法指定网格和块的维度，称为执行配置。&lt;/li&gt;
&lt;li&gt;在设备端执行核函数，每个块被分配到一个SM上，每个线程被分配到一个core上。&lt;/li&gt;
&lt;li&gt;在设备端完成核函数后，返回主机端继续执行后续代码。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;2级架构&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个GPU拥有多个Streaming Multiprocessor(SM)
&lt;ul&gt;
&lt;li&gt;具体数目及设计因产品而异&lt;/li&gt;
&lt;li&gt;SM共用显存&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;每个SM拥有多个CUDA core
&lt;ul&gt;
&lt;li&gt;数目因产品而异&lt;/li&gt;
&lt;li&gt;Core共用调度器和指令缓存&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;2级架构下的执行模型：线程束（warp）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CUDA线程以32个为一组在GPU上执行
&lt;ul&gt;
&lt;li&gt;线程束以单指令多线程的方式运行（SIMT）
&lt;ul&gt;
&lt;li&gt;所有线程在不同数据上执行相同的指令&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;SMIT、SIMD、SMT
&lt;ul&gt;
&lt;li&gt;灵活度：SIMD &amp;lt; SIMT &amp;lt; SMT&lt;/li&gt;
&lt;li&gt;性能： SIMD &amp;gt; SIMT &amp;gt; SMT&lt;/li&gt;
&lt;li&gt;SIMT与SIMD相比：多个状态寄存器，多个地址，独立的执行路径&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;SM负责调度并执行线程束
&lt;ul&gt;
&lt;li&gt;线程束调度时会产生上下文切换&lt;/li&gt;
&lt;li&gt;调度方式因架构而异&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Host与device&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Host（CPU）相关：运行在CPU上的代码及主机内存&lt;/li&gt;
&lt;li&gt;Device（GPU）相关：运行在GPU上的代码及显存（设备内存）&lt;/li&gt;
&lt;li&gt;通过在主机上调用核函数（kernel）执行并行代码&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;指明host与device代码&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;__host__&lt;/code&gt;从主机端调用，在主机端执行&lt;/li&gt;
&lt;li&gt;&lt;code&gt;__global__&lt;/code&gt;从主机端调用，在设备端执行&lt;/li&gt;
&lt;li&gt;&lt;code&gt;__device__&lt;/code&gt;从设备端调用，在设备端执行&lt;/li&gt;
&lt;li&gt;&lt;code&gt;__host__&lt;/code&gt;和&lt;code&gt;__device__&lt;/code&gt;可以一起使用&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;&amp;lt;&amp;lt; 1,4 &amp;gt;&amp;gt;&amp;gt;&lt;/code&gt;：执行配置
&lt;ul&gt;
&lt;li&gt;指明网格中有1个块&lt;/li&gt;
&lt;li&gt;每块中有4个线程&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;cudaDeviceSynchronize()
&lt;ul&gt;
&lt;li&gt;与OpenMP不同，CUDA核函数为异步执行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;核函数限制条件（&lt;code&gt;__global__&lt;/code&gt;函数）
&lt;ul&gt;
&lt;li&gt;只能访问设备内存&lt;/li&gt;
&lt;li&gt;必须返回void&lt;/li&gt;
&lt;li&gt;不支持可变数量的参数&lt;/li&gt;
&lt;li&gt;参数不可为引用类型&lt;/li&gt;
&lt;li&gt;不支持静态变量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;指明网格及块的维度&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;形式为&lt;code&gt;&amp;lt;&amp;lt;&amp;lt; grid,block &amp;gt;&amp;gt;&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;grid与block为dim3类型&lt;/li&gt;
&lt;li&gt;grid与block的大小受到计算能力的限制&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/grid-of-thread-blocks.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;grid-of-thread-blocks&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPU架构与线程执行
&lt;ul&gt;
&lt;li&gt;一个CUDA core执行一个线程&lt;/li&gt;
&lt;li&gt;一个SM执行一个block中的线程&lt;/li&gt;
&lt;li&gt;GPU中执行grid中的所有线程&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;确定线程编号
&lt;ul&gt;
&lt;li&gt;使用内置变量threadIdx、blockIdx、blockDim&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CUDA编程例子：向量加法
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c++&#34; data-lang=&#34;c++&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;__global__&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;VecAdd&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;// Kernel invocation with N threads
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;n&#34;&gt;VecAdd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GPU内存管理：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;创建：cudaMalloc&lt;/li&gt;
&lt;li&gt;拷贝：cudaMemcpy
&lt;ul&gt;
&lt;li&gt;使用cudaMemcpyHostToDevice与cudaMemcpyDeviceToHost指明拷贝方向&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;释放：cudaFree&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;处理错误&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用宏定义&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;block中最大线程限制：n必须不大于1024&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;同一个block只在一个SM上执行：没有充分利用GPU计算资源&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;思路：使用多个block&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个block使用m个thread（如m=32）&lt;/li&gt;
&lt;li&gt;grid,block设置：&lt;code&gt;&amp;lt;&amp;lt;&amp;lt; n/m, m &amp;gt;&amp;gt;&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;n无法被m整除？&lt;/li&gt;
&lt;li&gt;需对n/m向上取整&lt;/li&gt;
&lt;li&gt;需判断tid是否会超过范围&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;确定thread的全局编号&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;五cuda线程执行模型&#34;&gt;五、CUDA线程执行模型&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;逻辑视图
&lt;ul&gt;
&lt;li&gt;每个线程块由一个SM执行&lt;/li&gt;
&lt;li&gt;由硬件调度&lt;/li&gt;
&lt;li&gt;无法控制线程块的执行顺序&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;硬件视图
&lt;ul&gt;
&lt;li&gt;所有线程块在硬件上都是一维的&lt;/li&gt;
&lt;li&gt;三维线程将沿x-&amp;gt;y-&amp;gt;z的顺序展开到一维&lt;/li&gt;
&lt;li&gt;展开后的一维线程每32个形成一个线程束
&lt;ul&gt;
&lt;li&gt;最后不足32的部分也将创建线程
&lt;ul&gt;
&lt;li&gt;不活跃&lt;/li&gt;
&lt;li&gt;仍将消耗SM资源&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;线程束调度
&lt;ul&gt;
&lt;li&gt;线程束切换开销为0
&lt;ul&gt;
&lt;li&gt;SM保存每个线程束的执行上下文&lt;/li&gt;
&lt;li&gt;在整个线程束的生命周期中保存于芯片内&lt;/li&gt;
&lt;li&gt;上下文切换没有损失&lt;/li&gt;
&lt;li&gt;可切换同一SM上不同线程块的线程束&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;SM中常驻线程块数量受可用资源限制
&lt;ul&gt;
&lt;li&gt;资源：程序计数器、寄存器、共享内存&lt;/li&gt;
&lt;li&gt;活跃线程束：具备计算资源的线程束
&lt;ul&gt;
&lt;li&gt;Kepler上最大为64&lt;/li&gt;
&lt;li&gt;选定的线程束：被调度到执行单元的线程束（Kepler上最大为4）&lt;/li&gt;
&lt;li&gt;符合条件的线程束：准备执行但尚未执行&lt;/li&gt;
&lt;li&gt;阻塞的线程束：没做好执行准备（指令参数未就绪，无可用CUDA core）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;活跃线程束于延迟隐藏
&lt;ul&gt;
&lt;li&gt;满载：线程调度器在每个时钟周期都有符合条件的线程束&lt;/li&gt;
&lt;li&gt;通过调度符合条件的线程束，可以有效的掩盖指令延迟
&lt;ul&gt;
&lt;li&gt;算数指令：算数操作从开始到产生输出（10~20时钟周期）&lt;/li&gt;
&lt;li&gt;内存指令：发出加载/存储操作到数据到达目的地（全局内存~800时钟周期）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;应适当增加活跃线程束
&lt;ul&gt;
&lt;li&gt;Little&amp;rsquo;s law&lt;/li&gt;
&lt;li&gt;线程数不宜过少（每个线程处理的任务数与线程数需要平衡）&lt;/li&gt;
&lt;li&gt;线程块资源不易过多（如，共享内存的大小与活跃线程块数量需要平衡）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;线程束执行
&lt;ul&gt;
&lt;li&gt;每个线程束以SIMD方式在SM上执行
&lt;ul&gt;
&lt;li&gt;线程束内同时执行同样语句&lt;/li&gt;
&lt;li&gt;线程束外的视角看来为SIMT&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;分支分化
&lt;ul&gt;
&lt;li&gt;线程束出现不同的控制流&lt;/li&gt;
&lt;li&gt;性能优化：避免分支分化，因为线程束只能执行相同的逻辑，在执行某一个路径的线程时会禁用另一路径的线程。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;busy waiting vs signal
&lt;ul&gt;
&lt;li&gt;busy waiting：如，使用while循环不断检查条件是否满足&lt;/li&gt;
&lt;li&gt;signal：当条件满足由系统发送指令
&lt;ul&gt;
&lt;li&gt;__syncthreads()：只能在线程块内同步，不能在不同的线程块同步&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;busy waiting的问题：死锁&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;减少分支分化的影响
&lt;ul&gt;
&lt;li&gt;减少if语句
&lt;ul&gt;
&lt;li&gt;尤其是减少基于threadIdx的if语句&lt;/li&gt;
&lt;li&gt;使用条件赋值代替条件语句&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;平衡分支执行时间
&lt;ul&gt;
&lt;li&gt;避免出现执行时间过长的分支&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;六cuda原子操作&#34;&gt;六、CUDA原子操作&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;原子指令
&lt;ul&gt;
&lt;li&gt;执行过程不能分解为更小的部分：不被中断&lt;/li&gt;
&lt;li&gt;避免竞争条件出现&lt;/li&gt;
&lt;li&gt;竞争条件
&lt;ul&gt;
&lt;li&gt;程序运行结果依赖于不可控的执行顺序&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CUDA原子操作：
&lt;ul&gt;
&lt;li&gt;基本操作：atomicCAS
&lt;ul&gt;
&lt;li&gt;其它所有原子操作均可由atomicCAS()实现&lt;/li&gt;
&lt;li&gt;CAS：compare and swap
&lt;ul&gt;
&lt;li&gt;读取目标位置(address)并与预期值(old_val)进行比较
&lt;ul&gt;
&lt;li&gt;相等则将new_val写入目标位置&lt;/li&gt;
&lt;li&gt;不相等则不发生变化&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;返回目标位置中原值：可用来检查CAS操作是否成功&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;原子指令与并发控制：原子指令在并发控制中起着重要的作用。在多线程或多进程的环境中，当多个线程或进程尝试同时访问和修改共享数据时，如果没有适当的控制机制，可能会导致数据的不一致性。原子指令通过确保某些操作在执行过程中不会被其他线程或进程中断，来避免这种情况。&lt;/li&gt;
&lt;li&gt;竞争条件与死锁：竞争条件是并发编程中的一个主要问题，它发生在两个或更多的线程或进程在无序或未同步的情况下访问和修改共享数据，导致结果不可预测。原子指令是解决竞争条件的一种方法，但也可能引入另一个问题 - 死锁。死锁是指两个或更多的进程或线程互相等待对方释放资源，导致所有进程或线程都无法继续执行。&lt;/li&gt;
&lt;li&gt;CUDA原子操作与GPU编程：在GPU编程中，由于大量的线程并行执行，可能会有多个线程同时访问和修改同一块内存。CUDA的原子操作提供了一种机制，使得在这种情况下仍能保证数据的一致性。然而，过度依赖原子操作可能会导致性能下降，因为它们违反了GPU编程的基本原则——并行执行。因此，在设计GPU算法时，应尽量减少原子操作的使用，或者寻找可以避免使用原子操作的算法。&lt;/li&gt;
&lt;li&gt;CUDA原子操作的应用：在某些情况下，CUDA原子操作是必要的。例如，在统计或计数问题中，需要多个线程共享一个计数器，并且每个线程都可能需要增加计数器的值。在这种情况下，使用CUDA原子操作可以保证计数器的正确性。另一个例子是图形处理，其中可能需要多个线程同时更新像素的值。使用CUDA原子操作可以避免同时更新导致的数据不一致问题。&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        
    </channel>
</rss>
