<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Spark on Cuterwrite&#39;s Blog</title>
        <link>http://localhost:1313/tags/spark/</link>
        <description>Recent content in Spark on Cuterwrite&#39;s Blog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>cuterwrite</copyright>
        <lastBuildDate>Sat, 30 Dec 2023 01:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/tags/spark/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>在 HPC 上运行 Apache Spark</title>
        <link>http://localhost:1313/p/run-spark-on-hpc/</link>
        <pubDate>Sat, 30 Dec 2023 01:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/p/run-spark-on-hpc/</guid>
        <description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/crop_afb480a4096d16305dc5696f8072d0c0195413.jpg@1256w_2094h_!web-article-pic-2023-12-30.webp" alt="Featured image of post 在 HPC 上运行 Apache Spark" /&gt;&lt;h1 id=&#34;在-hpc-上运行-apache-spark&#34;&gt;在 HPC 上运行 Apache Spark&lt;/h1&gt;
&lt;h2 id=&#34;一概述&#34;&gt;一、概述&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://spark.apache.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34; &gt;Apache Spark
    &lt;span style=&#34;white-space: nowrap;&#34;&gt;&lt;svg width=&#34;.8em&#34; height=&#34;.8em&#34; viewBox=&#34;0 0 21 21&#34;
            xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;
            &lt;path d=&#34;m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z&#34; fill=&#34;currentColor&#34; /&gt;
            &lt;path d=&#34;M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z&#34;
                fill=&#34;currentColor&#34;&gt;
        &lt;/svg&gt;&lt;/span&gt;
    
&lt;/a&gt;
 是一个多语言引擎，用于在单节点机器或集群上执行数据工程、数据科学和机器学习任务。本文将为您提供在高性能计算（HPC）集群系统上运行多节点 Spark 集群的指南，并展示一个使用 PySpark 的作业示例。&lt;/p&gt;
&lt;h2 id=&#34;二开始&#34;&gt;二、开始&lt;/h2&gt;
&lt;h3 id=&#34;1-下载-openjdk-1102&#34;&gt;1. 下载 OpenJDK-11.0.2&lt;/h3&gt;
&lt;p&gt;从 &lt;a class=&#34;link&#34; href=&#34;https://jdk.java.net/archive/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34; &gt;OpenJDK 官方网站
    &lt;span style=&#34;white-space: nowrap;&#34;&gt;&lt;svg width=&#34;.8em&#34; height=&#34;.8em&#34; viewBox=&#34;0 0 21 21&#34;
            xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;
            &lt;path d=&#34;m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z&#34; fill=&#34;currentColor&#34; /&gt;
            &lt;path d=&#34;M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z&#34;
                fill=&#34;currentColor&#34;&gt;
        &lt;/svg&gt;&lt;/span&gt;
    
&lt;/a&gt;
 下载 OpenJDK-11.0.2。选择 Linux 的对应版本并下载。解压下载的文件并将其放置在 &lt;code&gt;${HOME}/software/openjdk&lt;/code&gt; 中并重命名为 &lt;code&gt;11.0.2&lt;/code&gt; 。&lt;/p&gt;
&lt;h3 id=&#34;2-下载-spark-342&#34;&gt;2. 下载 Spark-3.4.2&lt;/h3&gt;
&lt;p&gt;从 &lt;a class=&#34;link&#34; href=&#34;https://spark.apache.org/downloads.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34; &gt;Apache Spark 下载页面
    &lt;span style=&#34;white-space: nowrap;&#34;&gt;&lt;svg width=&#34;.8em&#34; height=&#34;.8em&#34; viewBox=&#34;0 0 21 21&#34;
            xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;
            &lt;path d=&#34;m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z&#34; fill=&#34;currentColor&#34; /&gt;
            &lt;path d=&#34;M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z&#34;
                fill=&#34;currentColor&#34;&gt;
        &lt;/svg&gt;&lt;/span&gt;
    
&lt;/a&gt;
 下载 Spark 。本文使用的是 Spark-3.4.2，但本指南应该也适用于更新的版本。解压下载的文件并将目录重命名为 3.4.2，放置在 ${HOME}/software/spark 文件夹中。&lt;/p&gt;
&lt;h3 id=&#34;3-配置-modulefile&#34;&gt;3. 配置 modulefile&lt;/h3&gt;
&lt;p&gt;在自定义目录中安装软件后，需要将软件的可执行文件路径等添加到相应的环境变量中才能使用。&lt;code&gt;module&lt;/code&gt; 是一款环境变量管理工具，通过 &lt;code&gt;module&lt;/code&gt; 实现软件环境变量的管理，快速加载和切换软件环境。集群中安装了一些常用的软件和库，可以通过 &lt;code&gt;module&lt;/code&gt; 进行加载使用。&lt;/p&gt;
&lt;p&gt;在这里，我们需要编写 &lt;code&gt;modulefile&lt;/code&gt; 来管理自己的 JDK 和 Spark 软件环境，以便快速加载 Java 和 Spark 环境。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 &lt;code&gt;${HOME}/modulefiles/openjdk&lt;/code&gt; 中创建名为 &lt;code&gt;11.0.2&lt;/code&gt; 的文本文件，内容为：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#%Module1.0
##
## openjdk modulefile
##

proc ModulesHelp { } {
    puts stderr &amp;quot;This module sets up the environment for OpenJdk 11.0.2 \n&amp;quot;
}

module-whatis &amp;quot;For more information, \$ module help openjdk/11.0.2\n&amp;quot;

conflict openjdk

# 注意！这里需要进行修改
set root &amp;lt;PATH/WHERE/OPENJDK/DIRECTORY/IS&amp;gt;

prepend-path PATH ${root}/bin
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;在 &lt;code&gt;${HOME}/modulefiles/spark&lt;/code&gt; 中创建名为 &lt;code&gt;3.4.2&lt;/code&gt; 的文本文件， 内容为：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#%Module1.0
##
## spark modulefile
##

proc ModulesHelp { } {
    global version

    puts stderr &amp;quot;This module loads Apache Spark environment variables and updates the PATH.&amp;quot;
    puts stderr &amp;quot; &amp;quot;
    puts stderr &amp;quot;Version: $version&amp;quot;
}


module-whatis &amp;quot;Loads Apache Spark environment variables and updates the PATH. \n For more information, \$ module help spark/3.4.2 .\n&amp;quot;

conflict spark

# Set the version and installation path
set version 3.4.2

# 注意！这里需要进行修改
set root &amp;lt;PATH/WHERE/SPARK/DIRECTORY/IS&amp;gt;

# Set the environment variables
setenv SPARK_HOME ${root}
setenv SPARK_CONF_DIR ${root}/conf
setenv PYSPARK_PYTHON python3

# Update the PATH
prepend-path PATH ${root}/bin
prepend-path PATH ${root}/sbin


# Update the CLASSPATH
prepend-path CLASSPATH ${root}/jars/*

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;4-使用-pip-安装-pyspark-库&#34;&gt;4. 使用 pip 安装 pyspark 库&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;创建虚拟 Conda 环境 pyspark&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;conda create -n pyspark python=3.10
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;安装 pyspark&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;conda activate pyspark
pip install pyspark
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;5-编写环境加载脚本-set-spark-envsh&#34;&gt;5. 编写环境加载脚本 set-spark-env.sh&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;在 &lt;code&gt;${HOME}/scripts&lt;/code&gt; 目录下编写 &lt;code&gt;set-spark-env.sh&lt;/code&gt; 脚本文件：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#!/bin/bash

source /etc/profile

# 注意！这里需要修改为你的 Conda 的安装路径
export CONDA_PATH=&amp;lt;PATH/WHERE/CONDA/DIRECTORY/IS&amp;gt;
export PATH=$CONDA_PATH/bin:$PATH

export MODULEPATH=${HOME}/modulefiles:$MODULEPATH

source activate
conda activate pyspark

module load openjdk
module load spark

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;6-编写-sbatch-脚本&#34;&gt;6. 编写 sbatch 脚本&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;为了启动 Spark 集群，我们使用以下 Slurm 脚本来请求计算节点。Slurm 脚本请求四个节点，并生成一个 master 节点和三个 worker 节点的 Spark 集群。可以通过更改 Slurm 脚本中的 &lt;code&gt;-N&lt;/code&gt; 选项的值来增加或减少工作节点的数量。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#!/bin/bash
#SBATCH --export=ALL
#SBATCH --mem=0
#SBATCH -p C28M250G
#SBATCH -t 1:00:00
#SBATCH -N 4
#SBATCH -J spark_test
#SBATCH -o o.spark_test
#SBATCH -e e.spark_test

source ~/scripts/set-spark-env.sh
workdir=`pwd`
nodes=($(scontrol show hostnames ${SLURM_JOB_NODELIST} | sort | uniq ))
numnodes=${#nodes[@]}
last=$(( $numnodes - 1 ))

export SCRATCH=${workdir}/scratch

master=${nodes[0]}
masterurl=&amp;quot;spark://${master}:7077&amp;quot;

ssh ${nodes[0]} &amp;quot;source ~/scripts/set-spark-env.sh; start-master.sh&amp;quot;
for i in $( seq 1 $last )
do
    ssh ${nodes[$i]} &amp;quot;source ~/scripts/set-spark-env.sh; start-worker.sh ${masterurl}&amp;quot;
done

ssh ${nodes[0]} &amp;quot;cd ${workdir}; source ~/scripts/set-spark-env.sh; /usr/bin/time -v spark-submit --deploy-mode client --executor-cores 28 --executor-memory 240G --conf spark.standalone.submit.waitAppCompletion=true --master $masterurl spark_test.py&amp;quot;
wait
echo &#39;end&#39;
exit

&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;该 Slurm 脚本会提交一个用于测试的 python 脚本（ &lt;code&gt;spark_test.py&lt;/code&gt; ），内容如下。此脚本运行 PySpark 代码来测试 Spark 集群。复制下面的内容，并将其保存在 sbatch 脚本所在目录中的 &lt;code&gt;spark_test.py&lt;/code&gt; 文件。你也可以更改 &lt;code&gt;spark_test.py&lt;/code&gt; 文件的路径，但必须适当地更新 Slurm 脚本。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;#spark_test.py
import random
from pyspark.sql import SparkSession
import pyspark.sql.functions as F


spark = SparkSession.builder.appName(&#39;Test-app&#39;).getOrCreate()

#Generate sample dataset
cola_list = [&#39;2022-01-01&#39;, &#39;2022-01-02&#39;, &#39;2022-01-03&#39; ]
colb_list = [&#39;CSC&#39;, &#39;PHY&#39;, &#39;MAT&#39;, &#39;ENG&#39;, &#39;CHE&#39;, &#39;ENV&#39;, &#39;BIO&#39;, &#39;PHRM&#39;]
colc_list = [100, 200, 300, 400, 500, 600, 700, 800, 900]


# declaring a random.seed value to generate same data in every run
random.seed(1)
sample_data = []
for idx in range(1000):
    sample_data.append([random.choice(cola_list), random.choice(colb_list), random.choice(colc_list)])

columns= [&amp;quot;date&amp;quot;, &amp;quot;org&amp;quot;, &amp;quot;value&amp;quot;]
#creating a Spark dataframe
df = spark.createDataFrame(data = sample_data, schema = columns)

res = (df.groupBy(&#39;date&#39;,&#39;org&#39;)
       .agg(F.count(&#39;value&#39;).alias(&#39;count_value&#39;)))
res.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;如果启动了 Spark 集群并且 &lt;code&gt;spark-test.py&lt;/code&gt; 成功执行，那么日志文件 &lt;code&gt;o.spark_test&lt;/code&gt; 中的输出应该如下：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-log&#34;&gt;starting org.apache.spark.deploy.master.Master, logging to ...
starting org.apache.spark.deploy.worker.Worker, logging to ...
starting org.apache.spark.deploy.worker.Worker, logging to ...
starting org.apache.spark.deploy.worker.Worker, logging to ...
+----------+----+-----------+
|      date| org|count_value|
+----------+----+-----------+
|2022-01-03| BIO|         37|
|2022-01-02| ENV|         53|
|2022-01-03| CHE|         39|
|2022-01-03| PHY|         46|
|2022-01-01| CSC|         45|
|2022-01-03| CSC|         48|
|2022-01-01| BIO|         39|
|2022-01-01| MAT|         42|
|2022-01-02| CHE|         44|
|2022-01-03| ENV|         33|
|2022-01-01| ENG|         33|
|2022-01-02| ENG|         28|
|2022-01-01| ENV|         33|
|2022-01-02| CSC|         45|
|2022-01-02| MAT|         51|
|2022-01-01| PHY|         38|
|2022-01-01|PHRM|         40|
|2022-01-03|PHRM|         42|
|2022-01-02|PHRM|         43|
|2022-01-03| ENG|         56|
+----------+----+-----------+
only showing top 20 rows

end
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Spark 还提供了一个 web UI 来监控集群，您可以通过将 master 节点端口转发到本地机器来在本地机器上访问它。
&lt;ul&gt;
&lt;li&gt;例如，如果 master 节点在 &lt;code&gt;cpu1&lt;/code&gt; 上运行，则可以在本地计算机终端上运行以下代码。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-cmd&#34;&gt;  ssh -t -t  &amp;lt;USERNAME&amp;gt;@&amp;lt;LOGIN_NODE_IP&amp;gt; -L 8080:localhost:8080 \
  -i &amp;lt;PRIVATE_KEY_LOCATION&amp;gt; ssh cpu1  -L 8080:127.0.0.1:8080
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;然后就可以在本地机器上的 Web 浏览器上使用地址 &lt;a class=&#34;link&#34; href=&#34;http://localhost:8080/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34; &gt;http://localhost:8080/
    &lt;span style=&#34;white-space: nowrap;&#34;&gt;&lt;svg width=&#34;.8em&#34; height=&#34;.8em&#34; viewBox=&#34;0 0 21 21&#34;
            xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;
            &lt;path d=&#34;m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z&#34; fill=&#34;currentColor&#34; /&gt;
            &lt;path d=&#34;M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z&#34;
                fill=&#34;currentColor&#34;&gt;
        &lt;/svg&gt;&lt;/span&gt;
    
&lt;/a&gt;
 访问 Spark Web UI。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;三总结&#34;&gt;三、总结&lt;/h2&gt;
&lt;p&gt;在本文中，我们介绍了如何在 HPC 集群上部署和运行 Apache Spark 集群。通过遵循本指南中的步骤，你应该能够成功地在 HPC 环境中运行 Spark 作业。请注意，根据你的具体 HPC 环境和配置，可能需要进行一些调整。&lt;/p&gt;



&lt;div class=&#34;notice notice-note&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg t=&#34;1705946198814&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 1024 1024&#34; version=&#34;1.1&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; p-id=&#34;23141&#34; width=&#34;200&#34; height=&#34;200&#34;&gt;&lt;path d=&#34;M195.541333 739.029333C151.594667 692.352 128 640 128 555.136c0-149.333333 104.832-283.178667 257.28-349.354667l38.101333 58.794667c-142.293333 76.970667-170.112 176.853333-181.205333 239.829333 22.912-11.861333 52.906667-16 82.304-13.269333 76.970667 7.125333 137.642667 70.314667 137.642667 148.864a149.333333 149.333333 0 0 1-149.333334 149.333333 165.162667 165.162667 0 0 1-117.248-50.304z m426.666667 0C578.261333 692.352 554.666667 640 554.666667 555.136c0-149.333333 104.832-283.178667 257.28-349.354667l38.101333 58.794667c-142.293333 76.970667-170.112 176.853333-181.205333 239.829333 22.912-11.861333 52.906667-16 82.304-13.269333 76.970667 7.125333 137.642667 70.314667 137.642666 148.864a149.333333 149.333333 0 0 1-149.333333 149.333333 165.162667 165.162667 0 0 1-117.248-50.304z&#34; p-id=&#34;23142&#34; fill=&#34;#ffffff&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://spark.apache.org/docs/latest/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34; &gt;Spark 官方文档
    &lt;span style=&#34;white-space: nowrap;&#34;&gt;&lt;svg width=&#34;.8em&#34; height=&#34;.8em&#34; viewBox=&#34;0 0 21 21&#34;
            xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;
            &lt;path d=&#34;m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z&#34; fill=&#34;currentColor&#34; /&gt;
            &lt;path d=&#34;M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z&#34;
                fill=&#34;currentColor&#34;&gt;
        &lt;/svg&gt;&lt;/span&gt;
    
&lt;/a&gt;
 是一个非常有用的工具，通过它可以帮助你找到 Spark 的具体说明并解决问题。所以实际遇到问题时要多使用它。&lt;/p&gt;&lt;/div&gt;

</description>
        </item>
        <item>
        <title>基于 Spark on k8s 的词频统计实验</title>
        <link>http://localhost:1313/p/spark-on-k8s/</link>
        <pubDate>Fri, 23 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/p/spark-on-k8s/</guid>
        <description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/92.webp" alt="Featured image of post 基于 Spark on k8s 的词频统计实验" /&gt;&lt;h1 id=&#34;基于-spark-on-k8s-的词频统计实验&#34;&gt;基于 Spark on k8s 的词频统计实验&lt;/h1&gt;
&lt;h2 id=&#34;1-简介&#34;&gt;1 简介&lt;/h2&gt;
&lt;h3 id=&#34;11-实验环境&#34;&gt;1.1 实验环境&lt;/h3&gt;
&lt;p&gt;本实验主要使用 Ubuntu 20.04 64 位作为系统环境，采用 6 台 4 核 8GB 云服务器作为 Kubernetes 集群部署机器，1 台 2 核 4GB 云服务器作为集群管理工具 Kuboard Spary 部署机器，1 台 2 核 4GB 云服务器作为 NFS Server（使用 Centos 7.6 系统）部署机器。&lt;/p&gt;
&lt;p&gt;使用的软件如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;版本&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;kuboard spary&lt;/td&gt;
&lt;td&gt;v1.2.3-amd64&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kubernetes&lt;/td&gt;
&lt;td&gt;v1.25.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;calico&lt;/td&gt;
&lt;td&gt;v3.23.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;etcd&lt;/td&gt;
&lt;td&gt;v3.5.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;crictl&lt;/td&gt;
&lt;td&gt;v1.25.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;crun&lt;/td&gt;
&lt;td&gt;1.4.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;krew&lt;/td&gt;
&lt;td&gt;v0.4.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;runc&lt;/td&gt;
&lt;td&gt;v1.1.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cni&lt;/td&gt;
&lt;td&gt;v1.1.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;nerdctl&lt;/td&gt;
&lt;td&gt;1.0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;coredns&lt;/td&gt;
&lt;td&gt;v1.8.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;dnsautoscaler&lt;/td&gt;
&lt;td&gt;1.8.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pod_infra&lt;/td&gt;
&lt;td&gt;3.7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;spark&lt;/td&gt;
&lt;td&gt;3.3.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;hadoop&lt;/td&gt;
&lt;td&gt;3.2.3&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;12-集群规划&#34;&gt;1.2 集群规划&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Kuborad Spary&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;IP&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;kuborad&lt;/td&gt;
&lt;td&gt;192.168.0.115&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;NFS Server&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;IP&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;NFS-server&lt;/td&gt;
&lt;td&gt;192.168.0.132&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;Kubernetes 集群规划&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;主机名&lt;/th&gt;
&lt;th&gt;IP&lt;/th&gt;
&lt;th&gt;控制节点&lt;/th&gt;
&lt;th&gt;etcd 节点&lt;/th&gt;
&lt;th&gt;工作节点&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;node1&lt;/td&gt;
&lt;td&gt;192.168.0.76&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;node2&lt;/td&gt;
&lt;td&gt;192.168.0.213&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;node3&lt;/td&gt;
&lt;td&gt;192.168.0.2&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;node4&lt;/td&gt;
&lt;td&gt;192.168.0.41&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;node5&lt;/td&gt;
&lt;td&gt;192.168.0.73&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;node6&lt;/td&gt;
&lt;td&gt;192.168.0.12&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;2-部署-kubernetes-集群&#34;&gt;2 部署 Kubernetes 集群&lt;/h2&gt;
&lt;h3 id=&#34;21-安装-kuboard-spray&#34;&gt;2.1 安装 Kuboard-Spray&lt;/h3&gt;
&lt;p&gt;Kuboard-Spray 是一款可以在图形界面引导下完成 Kubernetes 高可用集群离线安装的工具，开源仓库的地址为 &lt;a class=&#34;link&#34; href=&#34;https://github.com/eip-work/kuboard-spray&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34; &gt;Kuboard-Spray
    &lt;span style=&#34;white-space: nowrap;&#34;&gt;&lt;svg width=&#34;.8em&#34; height=&#34;.8em&#34; viewBox=&#34;0 0 21 21&#34;
            xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;
            &lt;path d=&#34;m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z&#34; fill=&#34;currentColor&#34; /&gt;
            &lt;path d=&#34;M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z&#34;
                fill=&#34;currentColor&#34;&gt;
        &lt;/svg&gt;&lt;/span&gt;
    
&lt;/a&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在 kuborad 节点上安装 docker-ce&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 1. 安装必备的系统工具
sudo apt-get remove docker docker-engine docker.io containerd runc;
sudo apt-get install apt-transport-https ca-certificates curl gnupg2 software-properties-common;

# 2. 安装 GPG 证书
curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/docker.gpg;
# 3. 写入软件源信息
echo \
  &amp;quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/docker.gpg] https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/ubuntu \
  $(lsb_release -cs) stable&amp;quot; | sudo tee /etc/apt/sources.list.d/docker.list &amp;gt; /dev/null

# 4. 更新并安装 Docker-CE

sudo apt-get update;
sudo apt-get install docker-ce;

# 5. 配置 docker 镜像加速器(可以在阿里云获取地址)

sudo mkdir -p /etc/docker;
sudo tee /etc/docker/daemon.json &amp;lt;&amp;lt;-&#39;EOF&#39;
{
 &amp;quot;registry-mirrors&amp;quot;: [
    &amp;quot;https://docker.mirrors.ustc.edu.cn&amp;quot;,
    &amp;quot;https://cr.console.aliyun.com/&amp;quot; ]
}
EOF
sudo systemctl daemon-reload;
sudo systemctl restart docker;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在 kuboard 节点上执行以下命令：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker run -d \
  --privileged \
  --restart=unless-stopped \
  --name=kuboard-spray \
  -e TZ=Asia/Shanghai \
  -p 80:80/tcp \
  -v /var/run/docker.sock:/var/run/docker.sock \
  -v ~/kuboard-spray-data:/data \
  eipwork/kuboard-spray:v1.2.3-amd64
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在浏览器打开地址 &lt;code&gt;http://这台机器的 IP&lt;/code&gt;，输入用户名 &lt;code&gt;admin&lt;/code&gt;，默认密码 &lt;code&gt;Kuboard123&lt;/code&gt;，即可登录 Kuboard-Spray 界面。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;22-加载离线资源包&#34;&gt;2.2 加载离线资源包&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在 Kuboard-Spray 界面中，导航到 &lt;code&gt;系统设置&lt;/code&gt; &amp;ndash;&amp;gt; &lt;code&gt;资源包管理&lt;/code&gt; 界面，可以看到已经等候您多时的 &lt;code&gt;Kuboard-Spray 离线资源包&lt;/code&gt;，如下图所示&lt;/p&gt;
&lt;figure&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/2022-12-08-16-02-14-image.png&#34; width=&#34;90%&#34; loading=&#34;lazy&#34;&gt;
  &lt;/figure&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;点击 &lt;code&gt;导入&lt;/code&gt; 按钮，在界面的引导下完成资源包的加载。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;23-安装-kubernetes-集群&#34;&gt;2.3 安装 Kubernetes 集群&lt;/h3&gt;
&lt;p&gt;在 Kuboard-Spray 界面中，导航到 &lt;code&gt;集群管理&lt;/code&gt; 界面，点击界面中的 &lt;code&gt;添加集群安装计划&lt;/code&gt; 按钮，填写表单如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;集群名称： 自定义名称，本文中填写为 &lt;code&gt;kuboard&lt;/code&gt;，此名称不可以修改；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;资源包：选择前面步骤中导入的离线资源包。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;点击 &lt;code&gt;确定&lt;/code&gt; 按钮后，将进入集群规划页面，在该界面中添加每个集群节点的连接参数并设置节点的角色，如下图所示：&lt;/p&gt;
&lt;figure&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/2022-12-08-20-13-12-image.png&#34; width=&#34;90%&#34; loading=&#34;lazy&#34;&gt;
  &lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;重要&lt;/strong&gt;： kuboard-spray 所在机器不能当做 K8S 集群的一个节点，因为安装过程中会重启集群节点的容器引擎，这会导致 kuboard-spray 被重启掉。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最少的节点数量是 1 个；&lt;/li&gt;
&lt;li&gt;ETCD 节点、控制节点的总数量必须为奇数；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;点击上图的 &lt;code&gt;保存&lt;/code&gt; 按钮，再点击 &lt;code&gt;执行&lt;/code&gt; 按钮，可以启动集群的离线安装过程，安装结果如下：&lt;/p&gt;
&lt;figure&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/2022-12-08-22-22-52-image.png&#34; width=&#34;90%&#34; loading=&#34;lazy&#34;&gt;
  &lt;/figure&gt;

&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;3-部署-spark-on-k8s&#34;&gt;3 部署 Spark on k8s&lt;/h2&gt;
&lt;h3 id=&#34;31-制作-spark-容器镜像&#34;&gt;3.1 制作 spark 容器镜像&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;下载 spark-3.3.1-bin-hadoop3&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;wget https://mirrors.pku.edu.cn/apache/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz;
tar -xzf spark-3.3.1-bin-hadoop.tgz;
mv spark-3.3.1-bin-hadoop spark;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;修改 Dockerfile 默认 apt 源加速&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd spark/kubernetes/dockerfiles/spark;
// 修改 Dockerfile 内容
// 修改前：
sed -i &#39;s/http:\/\/deb.\(.*\)/https:\/\/deb.\1/g&#39; /etc/apt/sources.list
// 修改后：
sed -i &#39;s#http://deb.debian.org#https://mirrors.ustc.edu.cn#g&#39; /etc/apt/source.list
sed -i &#39;s|security.debian.org/debian-security|mirrors.ustc.edu.cn/debian-security|g&#39; /etc/apt/source.list
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;构建 docker 镜像&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cd spark/bin;
// -r &amp;lt;repo&amp;gt; -t &amp;lt;tag&amp;gt;
./docker-image-tool.sh -r cuterwrite -t 0.1 build;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;推送镜像到阿里云仓库（参考容器镜像服务-&amp;gt;实例列表-&amp;gt;镜像仓库）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;docker login --username=[阿里云账号] registry.cn-hangzhou.aliyuncs.com;
docker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/[repository]:[镜像版本号];
docker push registry.cn-hangzhou.aliyuncs.com/[repository]:[镜像版本号];
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;32-创建命名空间&#34;&gt;3.2 创建命名空间&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;访问 Kuboard，通常默认用户名为 &lt;code&gt;admin&lt;/code&gt;，默认密码为 &lt;code&gt;Kuboard123&lt;/code&gt;，访问地址为第一个控制节点的 80 端口（取决于安装时的参数），如下图所示：&lt;/p&gt;
&lt;figure&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/2022-12-09-00-41-32-image.png&#34; width=&#34;90%&#34; loading=&#34;lazy&#34;&gt;
  &lt;/figure&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;点击进入 default 集群，在下图所示的页面点击创建&lt;code&gt;spark&lt;/code&gt; 命名空间：&lt;/p&gt;
&lt;figure&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/2022-12-09-00-43-13-image.png&#34; width=&#34;90%&#34; loading=&#34;lazy&#34;&gt;
  &lt;/figure&gt;

&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;33-配置-spark-用户权限&#34;&gt;3.3 配置 spark 用户权限&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;创建用户&lt;code&gt;spark&lt;/code&gt; 并配置权限&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubectl create serviceaccount spark
kubectl create clusterrolebinding spark-role --clusterrole=edit --serviceaccount=spark:spark --namesparce=spark
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;34-配置-spark-历史服务器&#34;&gt;3.4 配置 spark 历史服务器&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;创建一个名为&lt;code&gt;spark-history-server&lt;/code&gt; 的 deployment，配置如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;容器信息：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;名称：spark-history-server&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;容器镜像：registry.cn-hangzhou.aliyuncs.com/[用户名]/spark:0.1（需配置仓库仓库名和密码）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;环境变量：SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=hdfs://192.168.0.238:8020/sparkhistory（需提前部署 HDFS)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;容器端口：18080，端口名称 http&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;参数：[&amp;quot;/opt/spark/bin/spark-class&amp;quot;, &amp;ldquo;org.apache.spark.deploy.history.HistoryServer&amp;rdquo;]&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;服务信息：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;端口：18080&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;协议：TCP&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;目标端口：18080&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;NodePort：30080&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;类型：NodePort&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;测试配置是否成功：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;./spark-submit \
    --master k8s://https://127.0.0.1:6443 \
    --deploy-mode cluster \
    --name spark-pi \
    --class org.apache.spark.examples.SparkPi \
    --conf spark.kubernetes.executor.request.cores=1 \
    --conf spark.kubernetes.executor.limit.cores=1 \
    --conf spark.kubernetes.driver.limit.cores=1 \
    --conf spark.kubernetes.driver.request.cores=1 \
    --conf spark.eventLog.enabled=true \
    --conf spark.eventLog.dir=hdfs://192.168.0.238:8020/sparkhistory \
    --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
    --conf spark.kubernetes.namespace=bigdata \
    --conf spark.executor.instances=2 \
    --conf spark.kubernetes.file.upload.path=/tmp \
    --conf spark.kubernetes.container.pullSecrets=aliyun-repository \
    --conf spark.kubernetes.container.image=registry.cn-hangzhou.aliyuncs.com/cuterwrite/spark:0.1 \
hdfs://192.168.0.238:8020/user/root/jars/spark-examples_2.12-3.3.1.jar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;提交任务成功后可以在 Kuboard 管理界面看到一个新启动的容器组：&lt;/p&gt;
&lt;figure&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/2022-12-19-16-35-20-image.png&#34; width=&#34;90%&#34; loading=&#34;lazy&#34;&gt;
  &lt;/figure&gt;

&lt;p&gt;访问 spark 历史服务器，可以看到以下记录：&lt;/p&gt;
&lt;figure&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/2022-12-19-18-50-59-image.png&#34; width=&#34;90%&#34; loading=&#34;lazy&#34;&gt;
  &lt;/figure&gt;

&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;4-编写-wordcount-程序&#34;&gt;4 编写 WordCount 程序&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;WordCount.java&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;package com.cuterwrite;

import org.apache.spark.api.java.function.FlatMapFunction;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Encoders;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;

import java.util.Arrays;
import java.util.Iterator;

public class WordCount {
    public static void main(String[] args) throws Exception {
        SparkSession spark = SparkSession.builder().appName(&amp;quot;WordCount&amp;quot;).getOrCreate();
        Dataset&amp;lt;String&amp;gt; lines = spark.read().textFile(&amp;quot;hdfs://192.168.0.238:8020/input/news.txt&amp;quot;);
        Dataset&amp;lt;String&amp;gt; words = lines.flatMap(new FlatMapFunction&amp;lt;String, String&amp;gt;() {
            @Override
            public Iterator&amp;lt;String&amp;gt; call(String line) throws Exception {
                return Arrays.asList(line.split(&amp;quot; &amp;quot;)).iterator();
            }
        }, Encoders.STRING());
        Dataset&amp;lt;Row&amp;gt; wordCounts = words.groupBy(&amp;quot;value&amp;quot;).count();
        wordCounts.write().format(&amp;quot;csv&amp;quot;).save(&amp;quot;hdfs://192.168.0.238:8020/output/word_count_result&amp;quot;);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;5-实验结果&#34;&gt;5 实验结果&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;提交词频统计任务到&lt;code&gt;Kubernetes&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;./spark-submit \
    --master k8s://https://127.0.0.1:6443 \
    --deploy-mode cluster \
    --name wordcount \
    --class com.cuterwrite.WordCount \
    --conf spark.kubernetes.executor.request.cores=2 \
    --conf spark.kubernetes.executor.limit.cores=2 \
    --conf spark.kubernetes.driver.limit.cores=1 \
    --conf spark.kubernetes.driver.request.cores=1 \
    --conf spark.eventLog.enabled=true \
    --conf spark.eventLog.dir=hdfs://192.168.0.238:8020/sparkhistory \
    --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
    --conf spark.kubernetes.namespace=bigdata \
    --conf spark.executor.instances=3 \
    --conf spark.kubernetes.file.upload.path=/tmp \
    --conf spark.kubernetes.container.pullSecrets=aliyun-repository \
    --conf spark.kubernetes.container.image=registry.cn-hangzhou.aliyuncs.com/cuterwrite/spark:0.1 \
hdfs://192.168.0.238:8020/user/root/jars/SparkApp-1.0.jar
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;执行结果：&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;hdfs dfs -cat output/wordCount/_temporary/0/task_202212221534101760903765384745539_0002_m_000000/*
&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/1671723913622.jpg&#34; width=&#34;90%&#34; loading=&#34;lazy&#34;&gt;
&lt;/figure&gt;

&lt;figure&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/1671723670687.jpg&#34; width=&#34;90%&#34; loading=&#34;lazy&#34;&gt;
&lt;/figure&gt;

</description>
        </item>
        
    </channel>
</rss>
