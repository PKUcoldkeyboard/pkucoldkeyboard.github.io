<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="集合通信是进程集合里的所有进程进行数据交换的同时操作，实现了一对多，多对一，全体对全体的数据交换。本文深入讨论了一对多通信如广播和散播，多对一通信如收集，以及如何聚合所有进程的数据。然后，本文介绍了如何进行同步以确保所有进程在相同的执行点进行数据交换。接着，本文介绍了规约，一种特殊的集合通信操作，它将所有进程的数据聚合并进行运算，得出一个单一结果。总的来说，本文为读者提供了关于 MPI 集合通信的深入解析，包括其定义、功能和几种主要的通信模式。"><title>MPI 与并行计算（三）：集合通信</title>
<link rel=canonical href=https://cuterwrite.top/p/mpi-tutorial/3/><link rel=stylesheet href=/scss/style.min.a0fc0ff3a44cb4af39d6dcb774c100f62193b9919d28e898a77df106978b3e04.css><meta property='og:title' content="MPI 与并行计算（三）：集合通信"><meta property='og:description' content="集合通信是进程集合里的所有进程进行数据交换的同时操作，实现了一对多，多对一，全体对全体的数据交换。本文深入讨论了一对多通信如广播和散播，多对一通信如收集，以及如何聚合所有进程的数据。然后，本文介绍了如何进行同步以确保所有进程在相同的执行点进行数据交换。接着，本文介绍了规约，一种特殊的集合通信操作，它将所有进程的数据聚合并进行运算，得出一个单一结果。总的来说，本文为读者提供了关于 MPI 集合通信的深入解析，包括其定义、功能和几种主要的通信模式。"><meta property='og:url' content='https://cuterwrite.top/p/mpi-tutorial/3/'><meta property='og:site_name' content="Cuterwrite's Blog"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='MPI'><meta property='article:tag' content='并行计算'><meta property='article:published_time' content='2023-07-19T15:00:00+00:00'><meta property='article:modified_time' content='2023-07-19T15:00:00+00:00'><meta property='og:image' content='https://cuterwrite-1302252842.file.myqcloud.com/blog/20230720002052.webp'><meta name=twitter:title content="MPI 与并行计算（三）：集合通信"><meta name=twitter:description content="集合通信是进程集合里的所有进程进行数据交换的同时操作，实现了一对多，多对一，全体对全体的数据交换。本文深入讨论了一对多通信如广播和散播，多对一通信如收集，以及如何聚合所有进程的数据。然后，本文介绍了如何进行同步以确保所有进程在相同的执行点进行数据交换。接着，本文介绍了规约，一种特殊的集合通信操作，它将所有进程的数据聚合并进行运算，得出一个单一结果。总的来说，本文为读者提供了关于 MPI 集合通信的深入解析，包括其定义、功能和几种主要的通信模式。"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://cuterwrite-1302252842.file.myqcloud.com/blog/20230720002052.webp'><link rel="shortcut icon" href=/favicon.ico><script async src=https://analytics.cuterwrite.top/uma data-website-id=635c2011-51a9-4ffc-b360-f5572bb94276 data-domains=cuterwrite.top></script></head><body class="article-page
line-numbers"><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hue4d14694a57c01a222a16c47db12c89c_369633_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>😉</span></figure><div class=site-meta><h1 class=site-name><a href=/>Cuterwrite's Blog</a></h1><h2 class=site-description>欢迎来到我的个人博客。我是cuterwrite，一个热爱生活、不断探索的人。在这里，我分享我的想法、经验和学习，希望可以帮助到你，也欢迎你与我分享你的看法。</h2></div></header><ol class=menu-social><li><a href=https://analytics.cuterwrite.top/share/WcwRpn3giAassmyW/cuterwrite target=_blank title=Analytics rel=me><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 5H7A2 2 0 005 7v12a2 2 0 002 2h10a2 2 0 002-2V7a2 2 0 00-2-2h-2"/><rect x="9" y="3" width="6" height="4" rx="2"/><path d="M9 17v-5"/><path d="M12 17v-1"/><path d="M15 17v-3"/></svg></a></li><li><a href=https://status.cuterwrite.top target=_blank title=Upptime rel=me><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-chart-line"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 19h16"/><path d="M4 15l4-6 4 2 4-5 4 4"/></svg></a></li><li><a href=/index.xml target=_blank title=RSS rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-rss" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="5" cy="19" r="1"/><path d="M4 4a16 16 0 0116 16"/><path d="M4 11a9 9 0 019 9"/></svg></a></li><li><a href=https://github.com/PKUcoldkeyboard target=_blank title=GitHub rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://www.zhihu.com/people/kong-tiao-cheng-tai-lang-30-57 target=_blank title=zhihu rel=me><svg t="1705591931290" class="icon" viewBox="0 0 1280 1024" xmlns="http://www.w3.org/2000/svg" p-id="21048" width="32" height="32"><path d="M341.08 296.26v435.08l46.86.02 15.42 52.74 84.02-52.74h99.06V296.26H341.08zm195.5 387.86H480.7l-55.8 35.02-10.16-34.94-23.8-.08V343.5h145.64v340.62zM299.66 495.34H195c3.48-54.2 4.4-103.18 4.4-146.92h102.32s3.94-45.12-17.16-44.62h-177c6.98-26.24 15.74-53.32 26.24-81.34.0.0-48.14.0-64.54 43.14-6.78 17.8-26.42 86.28-61.4 156.24 11.78-1.28 50.74-2.36 73.68-44.42 4.22-11.78 5.02-13.32 10.28-29.06h57.74c0 21-2.4 133.76-3.36 146.88H41.66c-23.48.0-31.12 47.24-31.12 47.24H141.7C132.9 642.2 85.66 726.24.0 792.68c40.98 11.7 81.82-1.86 102-19.8.0.0 45.96-41.8 71.18-138.5L281.1 764.26s15.82-53.78-2.48-79.98c-15.16-17.84-56.12-66.12-73.58-83.62L175.8 623.9c8.72-27.96 13.98-55.1 15.74-81.34h123.3s-.18-47.24-15.18-47.24v.02zm824.04-3.2c41.66-51.28 89.96-117.14 89.96-117.14s-37.3-29.6-54.76-8.12c-12 16.3-73.66 96.4-73.66 96.4l38.46 28.86zM823.52 373.96c-18.02-16.5-51.82 4.26-51.82 4.26s79.04 110.08 82.24 114.9l38.92-27.46s-51.34-75.22-69.32-91.72h-.02zM1280 516.7c-39.56.0-261.82 1.86-262.12 1.86v-202c9.62.0 24.84-.8 45.7-2.4 81.76-4.82 140.26-8 175.54-9.62.0.0 24.44-54.38-1.18-66.88-6.14-2.36-46.34 9.16-46.34 9.16s-330.44 32.98-464.72 36.1c3.2 17.64 15.24 34.16 31.56 39.1 26.62 6.96 45.38 3.4 98.3 1.78 49.66-3.2 87.36-4.86 113.02-4.86v199.62H702.82s5.64 44.62 51.02 45.7h215.88V706.1c0 27.94-22.38 43.98-48.96 42.24-28.16.22-52.16-2.3-83.38-3.62 3.98 7.94 12.66 28.78 38.62 43.68 19.76 9.62 32.34 13.14 52.04 13.14 59.12.0 91.34-34.56 89.78-90.62V564.28h244.72c19.36.0 17.4-47.56 17.4-47.56l.06-.02z" fill="#707070" p-id="21049"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>主页 | Home</span></a></li><li><a href=/about/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>关于 | About</span></a></li><li><a href=/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>归档 | Archives</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>搜索 | Search</span></a></li><li><a href=https://cuterwrite.top/image-hosting target=_blank><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-album"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 4m0 2a2 2 0 012-2h12a2 2 0 012 2v12a2 2 0 01-2 2H6a2 2 0 01-2-2z"/><path d="M12 4v7l2-2 2 2V4"/></svg>
<span>图册 | Gallery</span></a></li><li><a href=https://draw.cuterwrite.top target=_blank><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-artboard"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M8 8m0 1a1 1 0 011-1h6a1 1 0 011 1v6a1 1 0 01-1 1H9a1 1 0 01-1-1z"/><path d="M3 8h1"/><path d="M3 16h1"/><path d="M8 3v1"/><path d="M16 3v1"/><path d="M20 8h1"/><path d="M20 16h1"/><path d="M8 20v1"/><path d="M16 20v1"/></svg>
<span>画板 | Canvas</span></a></li><li><a href=https://it-tools.tech target=_blank><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-tools"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M3 21h4L20 8a1.5 1.5.0 00-4-4L3 17v4"/><path d="M14.5 5.5l4 4"/><path d="M12 8 7 3 3 7l5 5"/><path d="M7 8 5.5 9.5"/><path d="M16 12l5 5-4 4-5-5"/><path d="M16 17l-1.5 1.5"/></svg>
<span>工具 | Tools</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ul><li><a href=#1-定义>1. 定义</a></li><li><a href=#2-集合通信实现的功能>2. 集合通信实现的功能</a></li><li><a href=#3-一对多通信广播>3. 一对多通信：广播</a></li><li><a href=#4-多对一通信收集>4. 多对一通信：收集</a></li><li><a href=#5-一对多通信散播>5. 一对多通信：散播</a></li><li><a href=#6-聚合>6. 聚合</a></li><li><a href=#7-同步>7. 同步</a></li><li><a href=#8-规约>8. 规约</a></li></ul></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/mpi-tutorial/3/><img src=https://cuterwrite-1302252842.file.myqcloud.com/blog/20230720002052.webp loading=lazy alt="Featured image of post MPI 与并行计算（三）：集合通信"></a></div><div class=article-details><header class=article-category><a href=/categories/hpc/ style=background-color:#ffd06f;color:#fff>高性能计算</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/mpi-tutorial/3/>MPI 与并行计算（三）：集合通信</a></h2><h3 class=article-subtitle>集合通信是进程集合里的所有进程进行数据交换的同时操作，实现了一对多，多对一，全体对全体的数据交换。本文深入讨论了一对多通信如广播和散播，多对一通信如收集，以及如何聚合所有进程的数据。然后，本文介绍了如何进行同步以确保所有进程在相同的执行点进行数据交换。接着，本文介绍了规约，一种特殊的集合通信操作，它将所有进程的数据聚合并进行运算，得出一个单一结果。总的来说，本文为读者提供了关于 MPI 集合通信的深入解析，包括其定义、功能和几种主要的通信模式。</h3></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>2023-07-19</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 5 分钟</time></div></footer></div></header><section class=article-content><h1 id=mpi-与并行计算三集合通信>MPI 与并行计算（三）：集合通信</h1><h2 id=1-定义>1. 定义</h2><ul><li><strong>集合通信（Collective Communication）</strong>：是一个进程组中的所有进程都参加的全局通信操作。</li><li>特点：<ul><li>通信空间中的所有进程都参与通信操作</li><li>每一个进程都需要调用该操作函数</li></ul></li></ul><p><strong>数据移动类型</strong></p><ul><li>Broadcast</li></ul><figure><img src=https://cuterwrite-1302252842.file.myqcloud.com/img/bcast_p2p.gif alt=bcast_p2p width=auto loading=lazy></figure><ul><li>Scatter</li></ul><figure><img src=https://cuterwrite-1302252842.file.myqcloud.com/blog/scatter.webp alt=scatter width=auto loading=lazy></figure><ul><li>Gather</li></ul><figure><img src=https://cuterwrite-1302252842.file.myqcloud.com/blog/gather.webp alt=gather width=auto loading=lazy></figure><ul><li>AllGather</li><li>Alltoall</li></ul><figure><img src=https://cuterwrite-1302252842.file.myqcloud.com/blog/20230720003014.webp alt=20230720003014 width=auto loading=lazy></figure><h2 id=2-集合通信实现的功能>2. 集合通信实现的功能</h2><ul><li><p>集合通信一般实现三个功能：通信、聚合和同步</p><div class=table-wrapper><table><thead><tr><th style=text-align:center>类型</th><th style=text-align:center>函数名</th><th style=text-align:center>含义</th></tr></thead><tbody><tr><td style=text-align:center>通信</td><td style=text-align:center>MPI_Bcast</td><td style=text-align:center>一对多广播同样的消息</td></tr><tr><td style=text-align:center>通信</td><td style=text-align:center>MPI_Gather</td><td style=text-align:center>多对一收集各个进程的消息</td></tr><tr><td style=text-align:center>通信</td><td style=text-align:center>MPI_Gatherv</td><td style=text-align:center>MPI_Gather 的一般化</td></tr><tr><td style=text-align:center>通信</td><td style=text-align:center>MPI_Allgather</td><td style=text-align:center>全局收集</td></tr><tr><td style=text-align:center>通信</td><td style=text-align:center>MPI_Allgatherv</td><td style=text-align:center>MPI_Allgather 的一般化</td></tr><tr><td style=text-align:center>通信</td><td style=text-align:center>MPI_Scatter</td><td style=text-align:center>一对多散播不同的消息</td></tr><tr><td style=text-align:center>通信</td><td style=text-align:center>MPI_Scatterv</td><td style=text-align:center>MPI_Scatter 的一般化</td></tr><tr><td style=text-align:center>通信</td><td style=text-align:center>MPI_Alltoall</td><td style=text-align:center>多对多全局交换消息</td></tr><tr><td style=text-align:center>通信</td><td style=text-align:center>MPI_Alltoallv</td><td style=text-align:center>MPI_Alltoall 的一般化</td></tr><tr><td style=text-align:center>聚合</td><td style=text-align:center>MPI_Reduce</td><td style=text-align:center>多对一规约</td></tr><tr><td style=text-align:center>聚合</td><td style=text-align:center>MPI_Allreduce</td><td style=text-align:center>MPI_Reduce 的一般化</td></tr><tr><td style=text-align:center>聚合</td><td style=text-align:center>MPI_Scan</td><td style=text-align:center>多对多扫描</td></tr><tr><td style=text-align:center>聚合</td><td style=text-align:center>MPI_Reduce_scatter</td><td style=text-align:center>MPI_Reduce 的一般化</td></tr><tr><td style=text-align:center>同步</td><td style=text-align:center>MPI_Barrier</td><td style=text-align:center>路障同步</td></tr></tbody></table></div></li><li><p>通信：集合通信，按照通信方向的不同，又可以分为三种：一对多通信，多对一通信和多对多通信。</p></li><li><p>一对多通信：一个进程向其它所有的进程发送消息，这个负责发送消息的进程叫做 Root 进程。</p></li><li><p>多对一通信：一个进程负责从其它所有的进程接收消息，这个接收的进程也叫做 Root 进程。</p></li><li><p>多对多通信：每一个进程都向其它所有的进程发送或者接收消息。</p></li></ul><h2 id=3-一对多通信广播>3. 一对多通信：广播</h2><ul><li><strong>广播</strong>是一对多通信的典型例子，其调用格式为：<code>MPI_Bcast(void *buffer, int count, MPI_Datatype datatype, int root, MPI_Comm comm)</code></li></ul><div class="notice notice-note"><div class=notice-title><svg t="1705946198814" class="icon notice-icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" p-id="23141" width="200" height="200"><path d="M195.541333 739.029333C151.594667 692.352 128 640 128 555.136c0-149.333333 104.832-283.178667 257.28-349.354667L423.381333 264.576C281.088 341.546667 253.269333 441.429333 242.176 504.405333c22.912-11.861333 52.906667-16 82.304-13.269333 76.970667 7.125333 137.642667 70.314667 137.642667 148.864A149.333333 149.333333.0 01312.789333 789.333333a165.162667 165.162667.0 01-117.248-50.304zm426.666667.0C578.261333 692.352 554.666667 640 554.666667 555.136c0-149.333333 104.832-283.178667 257.28-349.354667L850.048 264.576c-142.293333 76.970667-170.112 176.853333-181.205333 239.829333 22.912-11.861333 52.906667-16 82.304-13.269333 76.970667 7.125333 137.642667 70.314667 137.642666 148.864A149.333333 149.333333.0 01739.456 789.333333a165.162667 165.162667.0 01-117.248-50.304z" p-id="23142" fill="#fff"/></svg></div><p>示例 1：广播</p></div><pre><code class=language-c>// bcast.c
#include &lt;stdio.h&gt;
#include &lt;mpi.h&gt;

int main(int argc, char *argv[])
{
    int rank, size;
    int data;
    MPI_Init(&amp;argc, &amp;argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);
    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);

    if (rank == 0)
    {
        data = 123;
    }
    MPI_Bcast(&amp;data, 1, MPI_INT, 0, MPI_COMM_WORLD);
    printf(&quot;Process %d got data %d\n&quot;, rank, data);
    MPI_Finalize();
    return 0;
}
</code></pre><ul><li>结果：</li></ul><pre><code class=language-shell>root@ubuntu:~# mpicc bcast.c -o bcast
root@ubuntu:~# mpirun -n 2 ./bcast
Process 0 got data 123
Process 1 got data 123
</code></pre><ul><li>广播的特点<ul><li>标号为 Root 的进程发送相同的消息给通信域 Comm 中的所有进程。</li><li>消息的内容如同点对点通信一样由三元组&lt;Address, Count, Datatype>标识。</li><li>对 Root 进程来说，这个三元组既定义了发送缓冲也定义了接收缓冲。对其它进程来说，这个三元组只定义了接收缓冲</li></ul></li></ul><h2 id=4-多对一通信收集>4. 多对一通信：收集</h2><ul><li>收集是多对一通信的典型例子，其调用格式为：<code>MPI_Gather(void *sendbuf, int sendcount, MPI_Datatype sendtype, void *recvbuf, int recvcount, MPI_Datatype recvtype, int root, MPI_Comm comm)</code></li></ul><figure><img src=https://cuterwrite-1302252842.file.myqcloud.com/blog/20230720004519.webp alt=20230720004519 width=90% loading=lazy></figure><div class="notice notice-note"><div class=notice-title><svg t="1705946198814" class="icon notice-icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" p-id="23141" width="200" height="200"><path d="M195.541333 739.029333C151.594667 692.352 128 640 128 555.136c0-149.333333 104.832-283.178667 257.28-349.354667L423.381333 264.576C281.088 341.546667 253.269333 441.429333 242.176 504.405333c22.912-11.861333 52.906667-16 82.304-13.269333 76.970667 7.125333 137.642667 70.314667 137.642667 148.864A149.333333 149.333333.0 01312.789333 789.333333a165.162667 165.162667.0 01-117.248-50.304zm426.666667.0C578.261333 692.352 554.666667 640 554.666667 555.136c0-149.333333 104.832-283.178667 257.28-349.354667L850.048 264.576c-142.293333 76.970667-170.112 176.853333-181.205333 239.829333 22.912-11.861333 52.906667-16 82.304-13.269333 76.970667 7.125333 137.642667 70.314667 137.642666 148.864A149.333333 149.333333.0 01739.456 789.333333a165.162667 165.162667.0 01-117.248-50.304z" p-id="23142" fill="#fff"/></svg></div><p>示例 2：收集</p></div><pre><code class=language-c>// gather.c
#include &lt;mpi.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

int main(int argc, char *argv[])
{
    int rank, size;
    // 分布变量
    int data[2];
    int *buf;
    MPI_Init(&amp;argc, &amp;argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);
    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);

    data[0] = rank * 2 + 1;
    data[1] = rank * rank * 3 + 2;

    if (rank == 0)
    {
        // 开辟接收缓存区
        buf = malloc(2 * size * sizeof(int));
    }

    MPI_Gather(data, 2, MPI_INT, buf, 2, MPI_INT, 0, MPI_COMM_WORLD);

    if (rank == 0)
    {
        for (int i = 0; i &lt; 2 * size; i++)
        {
            printf(&quot;%d &quot;, buf[i]);
        }
        printf(&quot;\n&quot;);
        free(buf);
    }
    MPI_Finalize();
    return 0;
}
</code></pre><ul><li>结果：</li></ul><pre><code class=language-shell>root@ubuntu:~# mpicc gather.c -o gather
root@ubuntu:~# mpirun -n 2 ./gather
1 2 3 5
</code></pre><ul><li>收集的特点<ul><li>在收集操作中，Root 进程从进程域 Comm 的所有进程(包括它自已)接收消息。</li><li>这 n 个消息按照进程的标识 rank 排序进行拼接，然后存放在 Root 进程的接收缓冲中。</li><li>接收缓冲由三元组&lt;RecvAddress, RecvCount, RecvDatatype>标识，发送缓冲由三元组&lt;SendAddress, SendCount, SendDatatype>标识，所有非 Root 进程忽略接收缓冲。</li></ul></li></ul><h2 id=5-一对多通信散播>5. 一对多通信：散播</h2><ul><li>散播是一个一对多操作，其调用格式为：<code>MPI_Scatter(void *sendbuf, int sendcount, MPI_Datatype sendtype, void *recvbuf, int recvcount, MPI_Datatype recvtype, int root, MPI_Comm comm)</code></li></ul><figure><img src=https://cuterwrite-1302252842.file.myqcloud.com/blog/20230720005711.webp alt=20230720005711 width=90% loading=lazy></figure><div class="notice notice-note"><div class=notice-title><svg t="1705946198814" class="icon notice-icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" p-id="23141" width="200" height="200"><path d="M195.541333 739.029333C151.594667 692.352 128 640 128 555.136c0-149.333333 104.832-283.178667 257.28-349.354667L423.381333 264.576C281.088 341.546667 253.269333 441.429333 242.176 504.405333c22.912-11.861333 52.906667-16 82.304-13.269333 76.970667 7.125333 137.642667 70.314667 137.642667 148.864A149.333333 149.333333.0 01312.789333 789.333333a165.162667 165.162667.0 01-117.248-50.304zm426.666667.0C578.261333 692.352 554.666667 640 554.666667 555.136c0-149.333333 104.832-283.178667 257.28-349.354667L850.048 264.576c-142.293333 76.970667-170.112 176.853333-181.205333 239.829333 22.912-11.861333 52.906667-16 82.304-13.269333 76.970667 7.125333 137.642667 70.314667 137.642666 148.864A149.333333 149.333333.0 01739.456 789.333333a165.162667 165.162667.0 01-117.248-50.304z" p-id="23142" fill="#fff"/></svg></div><p>示例 3：散播</p></div><pre><code class=language-c>// scatter.c
#include &lt;mpi.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

int main(int argc, char *argv[])
{
    int rank, size;
    int *buf;
    int data[2];
    MPI_Init(&amp;argc, &amp;argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);
    MPI_Comm_size(MPI_COMM_WORLD, &amp;size);

    if (rank == 0)
    {
        buf = malloc(2 * size * sizeof(int));
        for (int i = 0; i &lt; 2 * size; i++)
        {
            buf[i] = i;
        }
    }

    MPI_Scatter(buf, 2, MPI_INT, data, 2, MPI_INT, 0, MPI_COMM_WORLD);
    printf(&quot;rank = %d, data = %d %d\n&quot;, rank, data[0], data[1]);

    if (rank == 0)
    {
        free(buf);
    }
    MPI_Finalize();
    return 0;
}
</code></pre><ul><li>结果：</li></ul><pre><code class=language-shell>root@ubuntu:~# mpicc scatter.c -o scatter
root@ubuntu:~# mpirun -n 2 ./scatter
rank = 0, data = 0 1
rank = 1, data = 2 3
</code></pre><ul><li>散播的特点<ul><li>Scatter 执行与 Gather 相反的操作。</li><li>Root 进程给所有进程(包括它自已)发送一个不同的消息，这 n (n 为进程域 comm 包括的进程个数)个消息在 Root 进程的发送缓冲区中按进程标识的顺序有序地存放。</li><li>每个接收缓冲由三元组&lt;RecvAddress, RecvCount, RecvDatatype>标识，所有的非 Root 进程忽略发送缓冲。对 Root 进程，发送缓冲由三元组&lt;SendAddress,SendCount, SendDatatype>标识。</li></ul></li></ul><h2 id=6-聚合>6. 聚合</h2><ul><li>集合通信的聚合功能使得 MPI 进行通信的同时完成一定的计算。</li><li>MPI 聚合的功能分三步实现：<ul><li>首先是通信的功能，即消息根据要求发送到目标进程，目标进程也已经收到了各自需要的消息</li><li>然后是对消息的处理，即执行计算功能</li><li>最后把处理结果放入指定的接收缓冲区</li></ul></li><li>MPI 提供了两种类型的聚合操作: 归约(Reduce)和扫描(Scan)。</li></ul><h2 id=7-同步>7. 同步</h2><ul><li>同步功能用来协调各个进程之间的进度和步伐 。目前 MPI 的实现中支持一个同步操作，即<strong>路障同步(Barrier)</strong>。</li><li>路障同步的调用格式为：<code>MPI_Barrier(MPI_Comm comm)</code><ul><li>在路障同步操作<code>MPI_Barrier(Comm)</code>中，通信域 Comm 中的所有进程相互同步。</li><li>在该操作调用返回后，可以保证组内所有的进程都已经执行完了调用之前的所有操作，可以开始该调用后的操作。</li></ul></li></ul><h2 id=8-规约>8. 规约</h2><p>MPI_REDUCE 将组内每个进程输入缓冲区中的数据按给定的操作 op 进行运算，并将其结果返回到序列号为 root 的进程的输出缓冲区中，输入缓冲区由参数 sendbuf、count 和 datatype 定义，输出缓冲区由参数 recvbuf count 和 datatype 定义，要求两者的元素数目和类型都必须相同，因为所有组成员都用同样的参数 count、datatype、op、root 和 comm 来调用此例程 故而所有进程都提供长度相同、元素类型相同的输入和输出缓冲区，每个进程可能提供一个元素或一系列元素 组合操作依次针对每个元素进行。</p><p>操作 op 始终被认为是可结合的 并且所有 MPI 定义的操作被认为是可交换的，用户自定义的操作被认为是可结合的，但可以不是可交换的。MPI 中已经定义好的一些操作,它们是为函数<code>MPI_Reduce</code> 和一些其他的相关函数,如<code>MPI_Allreduce</code>、<code>MPI_Reduce_scatter</code> 和<code>MPI_Scan</code> 而定义的 这些操作用来设定相应的 op。</p><p>MPI 预定的归约操作如下:</p><div class=table-wrapper><table><thead><tr><th style=text-align:center>操作</th><th style=text-align:center>含义</th><th style=text-align:center>操作</th><th style=text-align:center>含义</th></tr></thead><tbody><tr><td style=text-align:center>MPI_MAX</td><td style=text-align:center>最大值</td><td style=text-align:center>MPI_MIN</td><td style=text-align:center>最小值</td></tr><tr><td style=text-align:center>MPI_SUM</td><td style=text-align:center>求和</td><td style=text-align:center>MPI_PROD</td><td style=text-align:center>求积</td></tr><tr><td style=text-align:center>MPI_LAND</td><td style=text-align:center>逻辑与</td><td style=text-align:center>MPI_BAND</td><td style=text-align:center>按位与</td></tr><tr><td style=text-align:center>MPI_LOR</td><td style=text-align:center>逻辑或</td><td style=text-align:center>MPI_BOR</td><td style=text-align:center>按位或</td></tr><tr><td style=text-align:center>MPI_LXOR</td><td style=text-align:center>逻辑异或</td><td style=text-align:center>MPI_BXOR</td><td style=text-align:center>按位异或</td></tr><tr><td style=text-align:center>MPI_MAXLOC</td><td style=text-align:center>最大值和位置</td><td style=text-align:center>MPI_MINLOC</td><td style=text-align:center>最小值和位置</td></tr></tbody></table></div><div class="notice notice-note"><div class=notice-title><svg t="1705946198814" class="icon notice-icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" p-id="23141" width="200" height="200"><path d="M195.541333 739.029333C151.594667 692.352 128 640 128 555.136c0-149.333333 104.832-283.178667 257.28-349.354667L423.381333 264.576C281.088 341.546667 253.269333 441.429333 242.176 504.405333c22.912-11.861333 52.906667-16 82.304-13.269333 76.970667 7.125333 137.642667 70.314667 137.642667 148.864A149.333333 149.333333.0 01312.789333 789.333333a165.162667 165.162667.0 01-117.248-50.304zm426.666667.0C578.261333 692.352 554.666667 640 554.666667 555.136c0-149.333333 104.832-283.178667 257.28-349.354667L850.048 264.576c-142.293333 76.970667-170.112 176.853333-181.205333 239.829333 22.912-11.861333 52.906667-16 82.304-13.269333 76.970667 7.125333 137.642667 70.314667 137.642666 148.864A149.333333 149.333333.0 01739.456 789.333333a165.162667 165.162667.0 01-117.248-50.304z" p-id="23142" fill="#fff"/></svg></div><p>示例 4：计算 pi 值</p></div><pre><code class=language-c>// reduce.c
#include &lt;math.h&gt;
#include &lt;mpi.h&gt;
#include &lt;stdio.h&gt;

double f(double);
double f(double x)
{
    return 4.0 / (1.0 + x * x);
}

int main(int argc, char **argv)
{
    int done      = 0, n, myid, numprocs, i;
    double PI25DT = 3.141592653589793238462643;
    double mypi, pi, h, sum, x;
    double startwtime = 0.0, endwtime;
    int namelen;
    char process_name[MPI_MAX_PROCESSOR_NAME];
    MPI_Init(&amp;argc, &amp;argv);
    MPI_Comm_size(MPI_COMM_WORLD, &amp;numprocs);
    MPI_Comm_rank(MPI_COMM_WORLD, &amp;myid);
    MPI_Get_processor_name(process_name, &amp;namelen);

    fprintf(stdout, &quot;Process %d of %d is on %s\n&quot;, myid, numprocs, process_name);
    n = 0;
    if (myid == 0)
    {
        fprintf(stdout, &quot;Enter the number of intervals: (0 quits) &quot;);
        fflush(stdout);
        scanf(&quot;%d&quot;, &amp;n);
        startwtime = MPI_Wtime();
    }
    /* 将 n 广播给所有进程 */
    MPI_Bcast(&amp;n, 1, MPI_INT, 0, MPI_COMM_WORLD);
    /* 矩形宽度 */
    h = 1.0 / (double)n;
    /* 矩形面积初值 */
    sum = 0.0;
    /* 每个进程计算自己的部分 */
    for (i = myid + 1; i &lt;= n; i += numprocs)
    {
        x = h * ((double)i - 0.5);
        sum += f(x);
    }
    /* 各个进程并行计算得到的和 */
    mypi = h * sum;
    MPI_Reduce(&amp;mypi, &amp;pi, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD);
    /* 将部分和累加得到最终结果 */
    if (myid == 0)
    {
        printf(&quot;pi is approximately %.16f, Error is %.16f\n&quot;, pi, fabs(pi - PI25DT));
        endwtime = MPI_Wtime();
        printf(&quot;wall clock time = %f\n&quot;, endwtime - startwtime);
        fflush(stdout);
    }
    MPI_Finalize();
    return 0;
}
</code></pre></section><footer class=article-footer><section class=article-tags><a href=/tags/mpi/>MPI</a>
<a href=/tags/parallel-computing/>并行计算</a></section><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer><script type=text/javascript src=/js/prism.js async></script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/openmpi-with-ucx/><div class=article-image><img src=https://cuterwrite-1302252842.file.myqcloud.com/img/cropped_2024010204-2024-02-03.webp loading=lazy data-key=openmpi-with-ucx data-hash=https://cuterwrite-1302252842.file.myqcloud.com/img/cropped_2024010204-2024-02-03.webp></div><div class=article-details><h2 class=article-title>编译安装 UCX 1.15.0 与 OpenMPI 5.0.0：详尽指南</h2></div></a></article><article class=has-image><a href=/p/mpi-tutorial/5/><div class=article-image><img src=https://cuterwrite-1302252842.file.myqcloud.com/img/9a5806864623b04c918b9d8bee35c49fc2790c52.jpg@1256w_828h_!web-article-pic.avif loading=lazy data-key=mpi-tutorial/5 data-hash=https://cuterwrite-1302252842.file.myqcloud.com/img/9a5806864623b04c918b9d8bee35c49fc2790c52.jpg@1256w_828h_!web-article-pic.avif></div><div class=article-details><h2 class=article-title>MPI 与并行计算（五）：MPI 扩展</h2></div></a></article><article class=has-image><a href=/p/mpi-tutorial/4/><div class=article-image><img src=https://cuterwrite-1302252842.file.myqcloud.com/blog/20230720120242.webp loading=lazy data-key=mpi-tutorial/4 data-hash=https://cuterwrite-1302252842.file.myqcloud.com/blog/20230720120242.webp></div><div class=article-details><h2 class=article-title>MPI 与并行计算（四）：数据类型</h2></div></a></article><article class=has-image><a href=/p/mpi-tutorial/2/><div class=article-image><img src=https://cuterwrite-1302252842.file.myqcloud.com/blog/20230719212254.webp loading=lazy data-key=mpi-tutorial/2 data-hash=https://cuterwrite-1302252842.file.myqcloud.com/blog/20230719212254.webp></div><div class=article-details><h2 class=article-title>MPI 与并行计算（二）：点到点通信</h2></div></a></article><article class=has-image><a href=/p/mpi-tutorial/1/><div class=article-image><img src=https://cuterwrite-1302252842.file.myqcloud.com/blog/20230719012753.webp loading=lazy data-key=mpi-tutorial/1 data-hash=https://cuterwrite-1302252842.file.myqcloud.com/blog/20230719012753.webp></div><div class=article-details><h2 class=article-title>MPI 与并行计算（一）：并行环境及编程模型</h2></div></a></article></div></div></aside><script>(function(){if(/^localhost|^127/.test(location.hostname))return;let e=document.createElement("script");e.src="https://giscus.app/client.js",e.dataset.repo="PKUcoldkeyboard/pkucoldkeyboard.github.io",e.dataset.repoId="MDEwOlJlcG9zaXRvcnkzMzU4NzI5OTI=",e.dataset.category="Comments",e.dataset.categoryId="DIC_kwDOFAUD4M4CZV4F",e.dataset.mapping="title",e.dataset.strict="0",e.dataset.reactionsEnabled="1",e.dataset.emitMetadata="0",e.dataset.inputPosition="top",e.dataset.theme="light",e.dataset.lang="zh-CN",e.dataset.loading="lazy",e.crossOrigin="anonymous",e.async=!0;let t=document.querySelector(".main"),n=t.childNodes[t.childNodes.length-1];t.insertBefore(e,n.nextSibling)})();function setGiscusTheme(e){let t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:{setConfig:{theme:e}}},"https://giscus.app")}(function(){if(/^localhost|^127/.test(location.hostname))return;addEventListener("message",t=>{if(event.origin!=="https://giscus.app")return;e()}),window.addEventListener("onColorSchemeChange",e);function e(){setGiscusTheme(document.documentElement.dataset.scheme==="light"?"light":"dark_dimmed")}})()</script><footer class=site-footer><section class=copyright>&copy;
2021 -
2024 cuterwrite</section><section class=running-time>本博客已稳定运行
<span id=runningdays class=running-days></span></section><section class=totalcount>发表了61篇文章 ·
总计262.64k字</section><section class=powerby>Welcome to cuterwrite's blog!<br>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.17.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计<br><span>基于 <a href=https://github.com/CaiJimmy/hugo-theme-stack/tree/v3.25.0 target=_blank rel=noopener><b style=color:#9e8f9f>v3.25.0</b></a> 分支版本修改</span><br></section></footer><script>let s1="2021-4-17";s1=new Date(s1.replace(/-/g,"/"));let s2=new Date,timeDifference=s2.getTime()-s1.getTime(),days=Math.floor(timeDifference/(1e3*60*60*24)),hours=Math.floor(timeDifference%(1e3*60*60*24)/(1e3*60*60)),minutes=Math.floor(timeDifference%(1e3*60*60)/(1e3*60)),result=days+"天"+hours+"小时"+minutes+"分钟";document.getElementById("runningdays").innerHTML=result</script><script>(function(){var t,e=window;if(e.ChannelIO)return e.console.error("ChannelIO script included twice.");t=function(){t.c(arguments)},t.q=[],t.c=function(e){t.q.push(e)},e.ChannelIO=t;function n(){if(e.ChannelIOInitialized)return;e.ChannelIOInitialized=!0;var n,t=document.createElement("script");t.type="text/javascript",t.async=!0,t.src="https://cdn.channel.io/plugin/ch-plugin-web.js",n=document.getElementsByTagName("script")[0],n.parentNode&&n.parentNode.insertBefore(t,n)}document.readyState==="complete"?n():(e.addEventListener("DOMContentLoaded",n),e.addEventListener("load",n))})(),ChannelIO("boot",{pluginKey:"3182ceac-0382-4734-98f5-1e6fec11c935"})</script><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.bootcdn.net/ajax/libs/photoswipe/4.1.3/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.bootcdn.net/ajax/libs/photoswipe/4.1.3/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.bootcdn.net/ajax/libs/photoswipe/4.1.3/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.bootcdn.net/ajax/libs/photoswipe/4.1.3/photoswipe.min.css crossorigin=anonymous></main></div><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.font.im/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>