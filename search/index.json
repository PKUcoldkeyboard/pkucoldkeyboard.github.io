[{"content":" 1、命令返回值 2、多数据库 3、命令大全  1、通用命令  keys pattern exists key del key type key   2、字符串类型  简介 set key value / get key incr key incrby key increment decr key decrby key decrement incrbyfloat key increment append key value strlen key mget key / mset key1 value1 \u0026hellip; 位操作 使用场景   3、hash类型  简介 hset key field value hget key field hmset key field value hmget key field hgetall key hexists key field hsetnx key field value hincrby key field increment hdel key field 其他命令 使用场景   4、list类型  简介 lpush key value1\u0026hellip; rpush key value1\u0026hellip; lpop key rpop key llen key lrange key start stop lrem key count value lindex key index lset key index value ltrim key start end linsert key before|after pivot value rpoplpush source destination 使用场景   5、set类型  简介 sadd key member srem key member smembers sismember key member sdiff key1 key2 \u0026hellip; sinter key1 key2\u0026hellip; sunion key1 key2\u0026hellip; scard key sdiffstore/sinterstore/sunionstore destination key1 key2\u0026hellip; srandmember key count spop 使用场景   6、zset类型  简介 zadd key score member zscore key member zrange key start stop [withscores] zrangebyscore key min max [withscores] limit offset count zrevrangebyscore key max min [withscores] limit offset count zincrby key increment member zcard key zcount key min max zrem key member1 \u0026hellip; zremrangebyranke key start stop zremrangebyscore key min max zrank key member zrevrank key member      1、命令返回值  状态回复  OK：成功 PONG：响应PING   错误回复：命令不存在或者命令格式有误  Error Unknown command   整数回复：  INCR命令：返回递增后的键值 DBSIZE命令：返回键的数量   字符串回复：  请求键的值或者请求一个其他类型键中的某个元素   多行字符串回复：  请求非字符串类型键的元素列表 Keys (Pattern)：返回数据库中符合指定规则的键名    2、多数据库  一个Redis实例提供了多个用来存储数据的字典，客户端可以指定数据存储在哪个字典中。 数据库默认从0开始递增命名，默认支持16个数据库（DB0，DB1，\u0026hellip;，DB15） 不支持自定义数据库名字，也不支持单独设置访问密码  3、命令大全 1、通用命令 keys pattern 获得符合规则的键名列表，支持？、*、[]、\\x四种通配符\n keys命令会遍历所有键，不建议在生产环境中使用 命令不区分大小写  exists key  如果键存在返回1，否则返回0  del key  删除一个或多个键，返回删除的键的个数  type key  获得键值的数据类型  2、字符串类型 简介  字符串类型是Redis中最基本的数据类型，它能存储任何形式的字符串，包括二进制数据，可以存储邮箱、JSON、或者一张图片，允许存储的最大容量是512MB  set key value / get key  赋值与取值  incr key  递增数字，让当前键值递增，并返回递增后的值 如果key不存在时会默认键值为0  incrby key increment  增加指定的整数  decr key  同上  decrby key decrement  同上  incrbyfloat key increment  增加指定浮点数  append key value  尾部追加  strlen key  字符串长度  mget key / mset key1 value1 \u0026hellip;  同时获取/设置多个键值  位操作  getbit key offset setbit key offset value bitcount key bittop  使用场景  文章访问量统计：为每篇文章使用一个名为post:文h章ID:page.view的键来记录文章的访问量，每次访问文章的时候使用incr命令。（键命名建议：“对象类型：对象ID：对象属性”） 生成自增ID：对于每一类对象使用名为对象类型：count的键来存储当前类型对象的数量（如users:count），每次新增一个对象时都使用incr命令，返回值就是该新增对象的ID。 存储文章数据：JSON存储  3、hash类型 简介  散列类型适合存储对象：使用对象类别和ID构成键名，使用字段表示属性，字段值则存储属性值。一个键最多存2^32 - 1个元素  hset key field value  hset car price 500  hget key field  hget car price  hmset key field value hmget key field hgetall key hexists key field hsetnx key field value   当字段不存在时赋值\n  原子操作，线程安全\n  hincrby key field increment hdel key field 其他命令  hkeys hvals hlen  使用场景  存储文章数据 存储文章缩略名：使用slug.to.id的键来存储文章缩略名和ID之间的映射关系。这样就可以用hexists判断缩略名是否存在，使用hget命令来获取缩略名对应的文章ID  4、list类型 简介  可以存储一个有序的字符串列表，常用操作是向列表两端添加元素 底层：双向链表，添加复杂度O（1） 适用场景：只关心最新的内容 一个键最多存2^32 - 1个元素  lpush key value1\u0026hellip; rpush key value1\u0026hellip; lpop key rpop key llen key lrange key start stop  获取列表片段（两边都是闭区间） 支持负索引（与python类似） 0，-1会返回所有元素 start \u0026gt; stop：返回空 stop \u0026gt; len：返回start,start + len  lrem key count value  删除列表中前count个值为value的元素，返回值是实际删除的元素个数 count\u0026gt;0时，从列表左边开始删除 count\u0026lt;0时，从列表右边开始删除 count=0时，删除所有  lindex key index  索引取值，支持负数  lset key index value  索引赋值  ltrim key start end  删除指定索引外的全部值  linsert key before|after pivot value  首先查找pivot，然后插入其前面或后面  rpoplpush source destination  将一个元素转到另一个列表  使用场景  存储文章ID列表 存储评论列表  5、set类型 简介  无序、唯一 最多2^32 - 1个元素 常用操作：插入、删除、判断某个元素是否存在、交集、并集、差集  sadd key member srem key member smembers  返回所有元素  sismember key member   判断元素是否在集合中\n  O（1）\n  sdiff key1 key2 \u0026hellip;  求差集（ key1 - key2）  sinter key1 key2\u0026hellip;  求交集  sunion key1 key2\u0026hellip;  求并集  scard key  获取元素个数  sdiffstore/sinterstore/sunionstore destination key1 key2\u0026hellip;  存储集合操作的结果  srandmember key count  count\u0026gt;0时，获取不重复的随机count个元素 count\u0026lt;0时，获取可能重复的随机count个元素  spop  随机选择一个元素弹出  使用场景  存储文章标签 通过标签搜索文章  6、zset类型 简介  有序 唯一 可以获取某一范围的袁旭 底层：散列表和跳表，读取速度为O(logn)  zadd key score member  支持整数、双精度浮点数，甚至-inf和+inf 可以修改score  zscore key member zrange key start stop [withscores]   获得排名在某个范围的元素\n  可以添加分数\n  复杂度为O(logn + m)\n  zrangebyscore key min max [withscores] limit offset count  获得指定分数范围的元素，两边是闭区间 支持inf 数字前添加左圆括号表示开区间 可以用limit限制返回的个数  zrevrangebyscore key max min [withscores] limit offset count  同上，改成降序  zincrby key increment member  增加某个元素的分数  zcard key  元素数量  zcount key min max  分数范围内个数  zrem key member1 \u0026hellip; zremrangebyranke key start stop  根据排名范围删除元素  zremrangebyscore key min max  根据分数范围删除元素  zrank key member  获取元素排名  zrevrank key member  降序排名  ","date":"2021-04-07T00:00:00Z","permalink":"https://cuterwrite.top/p/redis-1/","title":"Redis入门"},{"content":" Spring Cloud alibaba笔记  SOA与微服务的区别： Spring Cloud Alibaba与Spring Cloud Netflix的对比 什么是Spring Boot？ IOC/DI（控制反转与依赖注入） Spring发展过程 自动装配的实现 手写实现一个Starter  1 Starter的功能 2 Starter的命名规范 3 实现基于Redis的Starter   Apache Dubbo Zookeeper Dubbo集成Zookeeper  1 需要解决的问题 2 实现步骤 3 原理 4 实战Dubbo Spring Cloud   Dubbo的高级应用  1 集群容错 2 负载均衡 3 服务降级   主机绑定规则 Dubbo源码分析  1 核心点 2 生成IDE工程的命令 3 SPI(Service Provider Interface) 4 Dubbo中的SPI思想 5 Dubbo中的SPI原理 6 自适应扩展点 7 Protocol自适应扩展点源码 8 IOC 9 AOP 10 Dubbo集成Spring机制（略）   什么是Nacos？  1 关键特性 2 Nacos集群   搭建Nacos注册中心的注意点 Nacos实现原理  1 模块组成 2 注册中心的原理 3 Nacos源码（略）   Nacos实现统一配置管理  1 Nacos集成Spring Boot 2 Nacos集成Spring Cloud 3 动态更新配置 4 基于DataID配置yaml的文件扩展名 5 不同环境的配置切换 6 自定义Namespace和Group   Nacos Config实现原理（略） Spring Cloud加载配置的原理（略） Nacos源码（略） Sentinel限流及熔断  1 服务限流的作用及实现 2 服务熔断和降级 3 Sentinel的特性 4 Sentinel的组成： 5 Sentinel基本应用： 6 Sentinel资源保护规则  1 QPS流量控制行为   7 Sentinel实现服务熔断   Sentinel集成Spring Cloud 基于Sentinel Dashboard来实现流控配置 Sentinel自定义URL限流异常 Sentinel对URL资源清洗 Sentinel集成Nacos实现动态流控规则 Sentinel集成Nacos实现规则同步  1 Sentinel Dashboard源码修改： 2 Sentinel Dashboard规则同步   Sentinel集成Dubbo实现限流  1 Dubbo服务接入Sentinel Dashboard 2 Dubbo服务限流规则   Sentinel热点限流  1 热点参数限流的使用 2 @SentinelResource 3 热点参数规则说明   Sentinel的工作原理（略） Spring Cloud Sentinel工作原理（略） Sentinel核心源码分析（略）  1 限流的源码实现 2 实时指标数据统计 3 服务降级的实现原理   什么是分布式事务？  1 分布式事务问题的理论模型  1 X/Open分布式模型 2 两阶段提交协议 3 三阶段提交协议 4 CAP定理和BASE理论   2 分布式事务问题的常见解决方案  1 TCC补偿性方案 2 基于可靠性消息的最终一致性方案 3 最大努力通知型   3 分布式事务框架Seata  1 AT模式 2 Saga模式        Spring Cloud alibaba笔记 SOA与微服务的区别：  SOA关注的是服务的重用性及解决信息孤岛问题 微服务关注的是解耦，虽然解耦和可重用性从特定的角度来看是一样的，但本质上是有区别的，解耦是降低业务之间的耦合度，而重用性关注的是服务的复用。 微服务会更多地关注在DevOps的持续交付上，因为服务粒度细化之后使得开发运维变得更加重要，因此微服务与容器化技术的结合更加紧密。  Spring Cloud Alibaba与Spring Cloud Netflix的对比  Alibaba开源组件在没有织入Spring Cloud生态之前，已经在各大公司广泛应用，所以容易实现技术整合及迁移。 Alibaba开源组件在服务治理上和处理高并发的能力上有天然的优势。  什么是Spring Boot？ 帮助开发者快速构建一个基于Spring Framework及Spring生态体系的应用解决方案，也是对于“约定优于配置”理念的最佳实践。\nIOC/DI（控制反转与依赖注入）  IOC：把对象的生命周期托管到Spring容器中，而反转是指对象的获取方式被反转了。 当使用IOC容器之后，客户端类不需要通过new来创建这些对象，而是直接从IOC容器中获得。早期的Spring中，主要通过XML的方式来定义Bean，Spring会解析XML文件，把定义的Bean转载到IOC容器中。 DI：IOC容器在运行期间，动态地把某种依赖关系注入组件中。 DI的三种方法：接口注入、构造方法注入、setter方法注入；目前是基于注解的形式：有@Autowired、@Inject和@Resource  Spring发展过程  J2EE的EJB时代 Spring XML配置文件时代 JavaConfig的无配置化注入时代 Spring Boot时代：约定优于配置，核心为：  Starter组件：开箱即用 自动装配：自动根据上下文完成Bean的装配 Actuator：应用监控 Spring Boot CLI：脚手架    自动装配的实现   实现原理：@EnableAutoConfiguration，这个注解的声明在启动类注解@SpringBootApplication内。进一步又涉及到@Enable注解（本质上是对@Configuration和@Bean的封装）；使用Enable注解后，Spring会解析到@Import导入的配置类，从而根据这个配置类中的描述来实现Bean的装配。\n  例子：可以直接使用@Autowired来注入redisTemplate实例。\n  EnableAutoConfiguration的原理\n@Import：导入一个AutoConfigurationImportSelector类。\n@AutoConfigurationPackage：把使用了该注解的类所在的类所在的包及子包下所有组件扫描到Spring IoC容器中\n  AutoConfigurationImportSelector：是ImportSelector的实现类，只有一个selectImports抽象方法，并且返回一个String数组，在这个数组中可以指定需要装配到IOC容器的类，当@Import中导入一个ImportSelectord的实现类后，会把该实现类中返回的Class名称都装载到IOC容器中。\n  ImportSelector与@Configuration的区别：前者可以实现批量装配，并且还可以通过逻辑处理来实现Bean的选择性装配，也就是根据上下文来决定哪些类能够被IOC容器初始化。\n  自动装配原理总结：\n 通过@Import(AutoConfigurationImportSelector)实现配置类的导入 AutoConfigurationImportSelector类实现了ImportSelector接口，重写了方法selectImports，用于实现选择性批量配置类的装配。 通过Spring提供的SpringFactoriesLoader机制，扫描classpath路径下的META-INF/spring.factories，读取需要实现自动装配的配置类。 通过条件筛选的方式，把不符合条件的配置类移除，最终完成自动装配。    @Conditional条件装配\n是Spring Framework提供的一个核心注解，这个注解的作用是提供自动装配的条件约束，一般与@Configuration和**@Bean**配合使用。\n简单来说，Spring在解析@Configuration配置类时，如果该配置类增加了@Conditional注解，那么就会根据该注解配置的条件来决定是否要实现Bean的装配。\n@Configuration public class ConditionConfig { @Bean @Conditional(GpCondition.class) public ThirdClass thirdClass() { return new ThirdClass(); } } 表示：如果GpCondition类中的matches返回true，则装载ThirdClass这个类。\n  @Conditional在Spring Boot中的扩展\n常用装配注解：\n@ConditionalOnBean\n@ConditionalOnMissingBean\n@ConditionalOnResource\n@ConditionalOnProperties\n  spring-autoconfigure-metadata\n用于实现批量自动装配条件配置，作用和@Conditional一致，只是把这些条件配置放在了配置文件中。\n两个条件：\n（1）配置文件的路径和名称必须是/META-INF/spring-autoconfigure-metadata.properties\n（2）配置文件中key的配置格式：自动配置类的类全路径名.条件=值\n好处：有效降低Spring Boot的启动时间，通过这种过滤方式可以减少配置类的加载数量，因为这个过滤发生在配置类的装载之前，所以它可以降低Spring Boot启动时装载Bean的耗时。\n  手写实现一个Starter 1 Starter的功能  涉及相关组件的Jar包依赖 自动实现Bean的装配 自动声明并且加载application.properties文件中的属性配置。  2 Starter的命名规范 Starter的命名主要分为官方命名和自定义组件命名两类，这种命名格式不是强制性的，也是一种约定俗成的方式。\n 官方命名格式：spring-boot-starter-模块名称 自定义命名格式：模块名称-spring-boot-starter  3 实现基于Redis的Starter  创建一个工程，命名为redis-spring-boot-starter 添加Jar包依赖 定义属性类，实现在application.properties中配置Redis的连接参数，使用@ConfigurationProperties，把当前类中的属性和配置文件中的配置进行绑定，并且规定前缀。 定义需要自动装配的配置类，主要就是把RedissonClient装配到IOC容器中。  Apache Dubbo   什么是Dubbo：一个分布式服务框架，主要实现多个系统之间的高性能、透明化调用，简单来说就是一个RPC框架，但是和普通的RPC框架不同，它提供了服务治理功能，比如服务注册、监控、路由、容错等。\n  服务提供者开发流程：\n 创建一个普通的Maven工程provider，并创建两个模块：api和provider，其中provider是一个Spring Boot工程 在api模块中定义接口，并且通过mvn install安装到本地仓库 在provider模块的pom文件中引入api和dubbo组件。 在provider中实现接口，并且使用@DubboService注解发布服务 在application.properties文件（或yml）中添加Dubbo服务的配置信息，包括application.name、protocal.name、protocol.port和registry.address 启动Spring Boot    服务调用者的开发流程：\n 创建一个Spring Boot项目consumer，添加Jar包依赖（Dubbo和api） 在application.properties中配置dubbo.application.name 使用@DubboReference注解获取一个远程代理对象。    Zookeeper   Zookeeper是一个高性能的分布式协调中间件，基于Java编写。\n  Zookeeper的数据结构：数据模型和分布式文件系统类似，是一种层次化的属性结构，区别是：Zookeeper的数据是结构化存储的，并没有在物理上体现出文件和目录。Zookeeper树中的每个节点被称为Znode，Znode维护了一个stat状态信息，其中包含数据变化的时间和版本等。并且每个Znode可以设置一个value值，Zookeeper并不用于通用的数据库或者大容量的对象存储，它只是管理和协调有关的数据，所以value的数据大小不建议设置得非常大，否则会带来更大的网络开销。Zookeeper上的每一个节点的数据都是允许读和写的，读表示指定获得Znode上的value数据，写表示修改Znode上的value数据。另外，节点的创建规则和文件系统中文件的创建规则类似，必须按照层次创建。例如：创建/node/node1/node1-1，先要创建/node/node1这两个层次节点。\n  Zookeeper的特性：Znode在被创建后，需要指定节点的类型，节点类型分为：\n  Watcher机制：\n  Znode的订阅/通知机制：当Znode节点状态发生变化时或者Zookeeper客户端连接状态发生变化时，会触发事件通知。这个机制在服务注册与发现中，针对服务调用者及时感知到服务提供者的变化提供了非常好的解决方案。\n  Zookeeper提供的Java API中，提供了三种机制来针对Znode进行注册监听，分别是：\n  常用应用场景分析\n 分布式锁：（1）多线程中Synchronized和Lock用于解决共享资源访问的数据安全性问题，但范围是线程级别的。（2）在分布式架构中，多个进程对同一个共享资源的访问，也存在数据安全性问题，因此也需要使用锁的形式来解决这类问题，而解决分布式环境下多进程对于共享资源访问带来的安全性问题的方案就是使用分布式锁。锁的本质是排他性，也就是避免同一时刻多个进程同时访问某一个共享资源。（3）如果使用Zookeeper实现分布式锁来达到排他性的目的，只需要用到节点的特性：临时节点，以及同级节点的唯一性。（4）具体实现：a.获得锁的过程：所有客户端可以去Zookeeper服务器上/Exclusive_Locks节点下创建一个临时节点/lock。Zookeeper基于同级节点的唯一性，会保证所有客户端中只有一个客户端能创建成功，创建成功的客户端获得了排它锁，没有获得锁的客户端就需要通过Watcher机制监听/Exclusive_Locks节点下子节点的变更事件，用于实时监听/lock节点的变化情况以作出反应。 b.释放锁的过程：①获得锁的客户端因为异常断开了和服务端的连接，临时节点会自动删除。②获得锁的客户端执行完业务逻辑后，主动删除创建的lock节点。 Master选举：分布式系统中的集群模式，某一机器宕机后，其他节点会接替故障节点继续工作。（1）Zookeeper有两种方式来实现Master选举的场景。假设集群中有3个节点，需要选举出Master，那么三个节点同时去Zookeeper服务器上创建一个临时节点/master-election，由于节点的唯一性，只会有一个客户端创建成功，创建成功就称为Master。同时，其他没有创建成功的客户端，针对该节点注册Watcher事件，监控master，一旦/master-election节点被删除，其他客户端重新发起master选举。（2）方法二：利用临时有序节点的特性来实现。所有参与选举的节点在/master节点下创建一个临时有序节点，编号最小的节点表示master，后续的节点监听上一个节点的删除事件，用于触发重新选举。      Dubbo集成Zookeeper 1 需要解决的问题  服务动态上下线感知：服务调用者要感知到服务提供者上下线的变化。 负载均衡  2 实现步骤  在provider模块中添加Zookeeper相关依赖 修改application.properties配置文件，修改dubbo的registry-addr为zookeeper服务器的地址，表示当前Dubbo服务需要注册到Zookeeper上。 consumer只需要修改application.properties，设置dubbo的registry-addr即可  3 原理   Dubbo服务注册到Zookeeper上之后，可以在Zookeeper服务器上看到图下所示的树形结构。\n  其中URL是临时节点，其他皆为持久化节点，如果注册该节点的服务器下线了，那么这个服务器的URL地址就会被移除。\n  当Dubbo服务消费者启动时，会对/providers下的子节点注册Watcher监听，这样就可以感知到服务提供方的上下线变化，从而防止请求发送到已经下线的服务器造成访问失败。同时，服务消费者会在/consumers下写入自己的URL，这样可以在监控平台上看到某个Dubbo服务正在被哪些服务调用。最重要的是，如果服务消费者需要调用一个服务，那么它会先去/providers路径下获得所有该服务的提供方URL列表，然后通过负载均衡算法计算出一个地址进行远程访问。\n  此外，Dubbo还可以针对不同的情况实现以下功能：\n 基于临时节点的特性，当服务器宕机或者下线时，注册中心会自动删除该服务提供者的信息。 注册中心重启时，Dubbo能自动恢复注册数据及订阅请求。 为了保证节点操作的安全性，Zookeeper提供了ACL权限控制，在Dubbo中可以通过register.username和password来设置节点的验证信息。 注册中心默认的根节点为/dubbo，如果需要针对不同环境设置不同的根节点，可以使用registry.group修改根节点名称。    4 实战Dubbo Spring Cloud  创建service-provider工程，创建两个子模块api和provider，前者为maven工程，后者为Spring Boot工程 在api中声明接口，并执行mvn install 在provider中添加api、Spring Boot、Spring Cloud和Spring Cloud Alibaba相关组件的依赖。（包括spring-cloud-starter、spring-cloud-starter-dubbo、api、discovery） 在父pom中显示声明dependencyManagement配置版本。 在provider中创建接口的实现类，并且声明@DubboService 在application.properties中配置Dubbo相关信息。 启动provider服务。 创建consumer，依赖与provider类似，同样在application.properties中配置Dubbo相关信息。注意：dubbo-cloud-subscribed-services表示服务调用者订阅的服务提供方的应用名称列表，如果有多个应用名称，可以通过\u0026quot;,\u0026ldquo;分开，默认值为“*” 使用@DubboReference消费服务，启动即可。  Dubbo的高级应用 1 集群容错 Dubbo默认提供6种容错模式，默认为Failover Cluster，此外可以根据实际需求自行扩展。\n 配置方式：在@DubboService中增加参数cluster=\u0026ldquo;failfast\u0026quot;即可。 推荐：查询语句容错策略建议使用默认的Failover Cluster，而增删改操作建议使用Failfast Cluster或者使用Failover Cluster(retries=0)，防止出现数据重复添加等其他问题！建议在设计接口的时候把查询接口方法单独做成一个接口提供查询。  2 负载均衡 Dubbo提供了4种负载均衡策略，默认为random，也可以自行扩展（基于SPI机制）。\n3 服务降级 服务降级是一种系统保护策略，当服务器访问压力较大时，可以根据当前业务情况对不重要的服务进行降级，以保证核心业务的正常运行。所谓的降级，就是把一些非必要的功能在流量较大的时间段暂时关闭，比如在双十一大促时，淘宝会把查看历史订单、商品评论等功能关闭。\n降级的分类：\n 是否自动化：人工降级、自动降级 功能划分：读服务降级和写服务降级  自动降级更多来自于系统出现某些异常时自动触发“兜底的流畅”，比如：\n 故障降级：调用的远程服务挂了，网络故障或者RPC服务返回异常。这类情况在业务情况下可以通过设置兜底数据响应给客户端。 限流降级：为了保护系统不被压垮，在系统中会针对核心业务进行限流，当请求流量达到阈值时，后续的请求会被拦截。  Dubbo提供了一种Mock配置来实现服务降级，也就是当服务提供方出现网络异常无法访问时，客户端不抛出异常，步骤如下：\n 在consumer中创建MockService，这个类只需要实现降级的接口即可，重写接口中的抽象方法实现本地数据的返回。 在@DubboReference中增加mock参数，制定MockService的位置。 在不启动Dubbo服务或者服务端的返回值超过默认的超时时间时，得到的数据就是MockService中的数据。  主机绑定规则 主机绑定表示的是Dubbo服务对外发布的IP地址，默认情况下Dubbo会按照以下顺序来查找并绑定主机IP地址。\n  查找环境变量DUBBO_IP_TO_BIND属性配置的IP地址。\n  查找dubbo.protocol.host属性的IP地址，默认是空，如果没有配置或者IP地址不合法则继续查找。\n  通过LocalHost.getHostAddress获取本机IP地址，获取失败则继续。\n  如果配置了注册中心的地址，则使用Socket通信连接到注册中心的地址后，使用for循环通过socket.getLocalAddress().getHostAddress()扫描各个网卡来获取网卡IP的地址。\n  建议：通过dubbo.protocal.host设置主机地址，防止注册错误的IP地址，使服务消费者无法调用。\n  docker部署解决方案：使用\u0026ndash;net=host绑定网络，然后配置application.yml\n配置inetutils下的两个参数\n  Dubbo源码分析 1 核心点  SPI机制 自适应扩展点 IOC和AOP Dubbo如何与Spring集成。  2 生成IDE工程的命令  mvn idea:idea mvn eclipse:eclipse  3 SPI(Service Provider Interface)  自适应扩展点：AdaptiveExtension 指定名称扩展点：Extension(name) 激活扩展点：ActivateExtension(url,key)  SPI是JDK内置的一种服务提供发现机制，主要用于服务的扩展实现。SPI机制在很多场景中都有运用，比如数据库连接，JDK提供了Driver接口，这个驱动类由不同的数据库厂商来实现，然后JDK利用SPI机制从classpath下找到相应的驱动来获得指定数据库的连接。这种插拔式的扩展加载方式，也同样遵循一定的协议约定，比如所有的扩展点必须要放在resources/META-INF/services目录下，SPI机制会默认扫描这个路径下的属性文件以完成加载。\n4 Dubbo中的SPI思想 Dubbo或者SpringFactoriesLoader并没有使用JDK内置的SPI机制，只是利用了SPI的思想。Dubbo SPI的相关逻辑被封装在了ExtensionLoader类中，通过ExtensionLoader我们可以加载指定的实现类。\nDubbo的SPI扩展有两个规则：\n 和JDK内置的SPI一样，需要在resources目录下创建任一目录结构：META-INF/dubbo、META-INF/dubbp/internal、META-INF/services，在对应的目录下创建以接口全路径名命名的文件，Dubbo会去三个目录下加载相应扩展点。 文件内容和JDK内置的SPI不一样，内容是key-value形式的数据，key是一个字符串，value是一个对应扩展点的实现，这样的方式可以按照需要加载指定的实现类。  实现步骤如下：\n 在一个依赖了Dubbo框架的工程中，创建一个扩展点及一个实现。其中，扩展点需要声明@SPI注解。 在resources/META-INF/dubbo目录下创建以SPI接口命名的文件 使用ExtensionLoader.getExtensionLoader.getExtension(key)获得指定名称的扩展点实现。  5 Dubbo中的SPI原理 （1）ExtensionLoader.getExtensionLoader：这个方法用于返回一个ExtensionLoader实例，逻辑如下：\n 先从缓存中获取与扩展类对应的ExtensionLoader 缓存未命中，则创建一个新的实例，保存到eEXTENXION_LOADERS集合中缓存起来。 在ExtensionLoader构造方法中，初始化一个objectFactory  （2）getExtension：这个方法用于根据指定名称获取对应的扩展点并返回。\n name用于参数的判断，如果name=\u0026ldquo;true\u0026rdquo;，则返回一个默认的扩展实现。 创建一个Holder对象，用户缓存该扩展点的实例。 如果缓存中不存在，则通过createExtension(name)创建一个扩展点。  （3）createExtension()：去指定的路径下查找name对应的扩展点的实现。\n 通过getExtensionClasses().get(name)获取一个扩展类 通过反射实例化之后缓存到EXTENSION_INSTANCES集合中。 injectExtension实例依赖注入 把扩展类对象通过Wrapper进行包装。  （4）getExtensionClasses()\n 从缓存中换取已经被加载的扩展类 如果缓存未命中，则调用loadExtensionClasses加载扩展类。  （5）loadExtensionClasses()\n 通过cacheDefaultExtensionName方法获取当且扩展接口的默认扩展对象，并且缓存。 调用loadDirectory方法加载指定文件目录下的配置文件。  （6）cacheDefaultExtensionName()\n 获得指定扩展接口的@SPI注解 得到@SPI注解中的名字，保存到cacheDefaultName属性中。  6 自适应扩展点 Adaptive Extension：能够根据上下文动态匹配一个扩展类，使用方式如下：\nExtensionLoader.getExtensionLoader(class).getAdaptiveExtension(); 自适应扩展点通过@Adaptive注解声明，有两种使用方式\n（1）@Adaptive注解定义在类上面，表示当前类为自适应扩展点。\n（2）@Adaptive注解定义上方法层面，会通过动态代理的方式生成一个动态字节码，进行自适应匹配。\n7 Protocol自适应扩展点源码 ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); 首先是getExtensionLoader：\n（1）从缓存中获取自适应扩展点实例。\n（2）如果缓存未命中，则通过createAdaptiveExtension创建自适应扩展点。\n然后是createAdaptiveExtension：\n（1）getAdaptiveExtensionClass：获取一个自适应扩展类的实例。\n（2）injectExtension完成依赖注入。\n接着是getAdaptiveExtensionClass：\n（1）通过getExtensionClasses方法加载当前传入类型的所有扩展点，缓存在一个集合中。\n（2）如果cachedAdaptiveClass为空，则调用createAdaptiveExtensionClass进行创建。\n8 IOC 上文中的injectExtension就是依赖注入的实现，整体逻辑为：\n（1）遍历被加载的扩展类中的所有set方法。\n（2）得到set方法中的参数类型，如果参数类型是对象类型，则获得这个set方法中的属性名称。\n（3）使用自适应扩展点加载该属性名称对应的扩展类。\n（4）调用set完成赋值。\n简单来说，injectExtension方法的主要功能是，如果当前加载的扩展类中存在一个成员对象，并且为它提供了set方法，那么就会通过自适应扩展点进行加载并赋值。\n9 AOP 面向切面编程，意图是把业务逻辑和功能逻辑分离，然后在运行期间或者类加载期间进行织入，可以降低代码的复杂性，以及提高重用性。\ninstance = injectExtension((T)WrapperClass.getConstructor(type).newInstance(instance)); 这段代码分别用到了依赖注入和AOP，AOP体现在基于Wrapper装饰器类实现对原有的扩展类instance进行包装。\n10 Dubbo集成Spring机制（略） p89\n什么是Nacos？ Nacos致力于解决微服务中的统一配置、服务注册与发现等问题。它提供了一组简单易用的特性集，帮助开发者快速实现动态服务发现、服务配置、服务元数据以及流量管理。\n1 关键特性   服务发现和服务健康监测\nNacos基于DNS和基于RPC的服务发现。服务提供者通过原生SDK、OpenAPI或一个独立的Agent TODO注册Service后，服务消费者可以使用DNS或HTTP\u0026amp;API查找和发现服务。\nNacos提供对服务的实时的健康检查，阻止向不健康的主机或服务实例发送请求。Nacos支持传输层（PING或TCP）和应用层（如HTTP、MYSQL、用户自定义）的健康检查。对于复杂的云环境和网络拓扑环境（如VPC、边缘网络等）服务的健康检查，Nacos提供了agent上报和服务端主动监测两种健康检查模式。Nacos还提供了统一的健康检查仪表盘。\n  动态配置服务\n业务服务一般都会维护一个本地配置文件，然后把一些常量配置到这个文件中。这种方式在某些场景会存在某些问题，比如配置变更时需要重新部署应用。而动态配置服务可以以中心化、外部化和动态化的方式管理所有环境的应用配置和服务配置。\n  动态DNS服务\n支持权重路由，让开发者更容易实现中间层负载均衡、更灵活的路由策略、流量控制，以及数据中心内网的简单DNS服务。\n  服务及其元数据管理\n  2 Nacos集群 包含一个Leader节点和多个Follower节点。\n数据一致性算法采用的Raft（Etcd、Redis哨兵选举也是这个算法）\n3个或3个以上Nacos节点才能构成集群。\n搭建Nacos注册中心的注意点  dubbo.scan.base-packages功能等同于@DubboComponentScan dubbo.registry.address：Dubbo服务注册中心的配置地址，它的值spring-cloud://url表示挂载到Spring Cloud注册中心，不配置的话会提示没有配置注册中心的错误。 spring.cloud.nacos.discovery.server-addr：Nacos服务注册中心的地址。  Nacos实现原理 1 模块组成  Provider App Consumer App Name Server Nacos Server Nacos Console  整体来说，服务提供者通过Virtual IP访问Nacos Server高可用集群，基于Open API完成服务的注册和服务的查询。Nacos Server本身可以支持主备模式，所以底层会采用数据一致性算法来完成主从节点的整体同步。服务消费者也是如此。\n2 注册中心的原理 服务注册的功能主要体现在：\n 服务实例在启动时注册到服务注册表，并在关闭时注销。（Open API） 服务消费者查询服务注册表，获得可用实例。 服务注册中心需要调用服务实例的健康检查API来验证它是否能够处理请求。（心跳机制）  3 Nacos源码（略）  服务注册 服务地址的获取 服务地址变化的感知  Nacos实现统一配置管理 各个应用自己独立维护本地配置方式的不足：\n1 Nacos集成Spring Boot  在application.properties中配置nacos.config.server-addr 创建NacosConfigController，用于从Nacos Server动态读取配置。 @NacosPropertiesSource：用于加载dataId为example的配置源，autoRefreshed表示开启自动更新。 @NacosValue：设置属性的值，其中info表示key，而Local Hello World表示默认值。也就是说如果key不存在，则使用默认值。这是一种高可用的策略。  2 Nacos集成Spring Cloud  spring.cloud.nacos.config.prefix表示Nacos配置中心上的DataID的前缀。 spring.cloud.nacos.config.server-addr表示Nacos配置中心的地址。 在Nacos Console创建配置 在启动类中，读取配置中心的数据。 注意坑：配置文件必须用bootstrap.yml这个名称，因为bootstrap加载顺序优于application，因为需要在bootstrap配置文件中添加连接到配置中心的配置属性来加载外部配置中心的配置信息。  3 动态更新配置 通过一个while循环不断读取info属性，当info属性发生变化时，控制台可以监听到。\n4 基于DataID配置yaml的文件扩展名 DataID默认规则是${prefix}-${spring.profile.active}.${file-extension}\n 在默认情况下，会去Nacos服务器上加载DataID以${spring.application.name}.${file-extension:properties}为前缀的基础配置。例如：在不通过spring.cloud.nacos.config.prefix指定DataID时，会默认读取DataID为nacos-config-demo.properties的配置信息。 如果明确指定了spring.cloud.nacos.config.prefix，则会加载DataID为指定值的配置。 spring.profile.active表示多环境支持。  在实际应用中，如果使用YAML格式配置，则需要声明spring.cloud.nacos.config.file-extension=yaml\n5 不同环境的配置切换 Spring Boot多环境支持配置步骤如下：\n 在resource目录下根据不同环境创建不同的配置：  application-dev.properties application-test.properties application-prod.properties   定义一个application.properties默认配置，在该配置中通过spring.profile.active=${env}来指定使用哪个环境的配置，如果${env}的值为prod，表示使用prod环境。 也可以通过设置 VM Options=-Dspring.profiles.active=prod来指定。  Nacos Config配置步骤如下：\n 在bootstrap.properties中声明spring.profiles.active=prod 在Nacos控制台新增DataID为nacos-config-demo-prod.properties的配置项。  6 自定义Namespace和Group  Namespace：解决多环境及多租户数据的隔离问题。  使用：在bootstrap.properties里指定spring.cloud.nacos.config.namespace   Group：用于分组管理Data ID  使用：在bootstrap.properties里指定spring.cloud.nacos.config.group    Nacos Config实现原理（略）  获取配置 监听配置 发布配置 删除配置  分为两类：配置的CRUD和配置的动态监听\nSpring Cloud加载配置的原理（略） Nacos源码（略） Sentinel限流及熔断 1 服务限流的作用及实现 主要作用：损失一部分用户的可用性，为大部分用户提供稳定可靠的服务。\n  计算器算法：在制定周期内累加访问次数，当访问次数达到阈值时，触发限流策略。\n  滑动窗口算法：源于TCP拥塞控制，原理是在固定窗口中分割出多个小时间窗口，分别在每个小时间窗口中记录访问次数，然后根据时间将窗口往前滑动并删除过期的小时间窗口。最终只需要统计滑动窗口范围内所有小时间窗口总的计数即可。（Sentinel的原理）\n  令牌桶算法：每一个请求，都需要从令牌桶中获取一个令牌，如果没有获得令牌，则触发限流策略。\n特性：短时间内新增的流量系统能够正常处理。\n  漏桶限流算法：用于控制数据注入网络的速度，平滑网络上的突发流量。\n  2 服务熔断和降级 在微服务架构中，由于服务拆分粒度较细，会出现请求链路较长的情况，用户发起一个请求操作，需要调用多个微服务才能完成。\n雪崩效应：某个服务因为网络延迟或者请求超时等原因不可用时，就会导致当前请求阻塞，一旦某个链路上被依赖的服务不可用，很可能出现请求堆积而产生雪崩。\n所以，服务熔断就是用来解决这个问题的方案，它指的是当某个服务提供者无法正常为服务调用者提供服务时，为了防止整个系统出现雪崩效应，暂时将出现故障的接口隔离出来，断绝与外部接口的联系，当触发熔断后，后续一段时间内该服务调用者的请求都会直接失败，直至目标服务恢复正常。\n3 Sentinel的特性  丰富的应用场景：秒杀、消息削峰填谷、集群流量控制等。 实时监控 开源生态支持 SPI扩展点支持  4 Sentinel的组成：  核心库（Java客户端）：不依赖任何框架与库，能够运行于所有Java运行时环境。 控制台（Dashboard）  5 Sentinel基本应用： 步骤如下：\n（1）定义资源：限流保护的最基本元素，比如一个方法。\n（2）定义限流规则\n（3）检验规则是否生效\n限流规则：通过initFlowRules方法设置\n grade：限流阈值类型，有QPS模式和并发线程数模式。 count：限流阈值 resource：设置需要保护的资源  6 Sentinel资源保护规则 Sentinel支持多种保护规则：流量控制规则、熔断降级规则、系统保护规则、来源访问控制规则、热点参数规则。\n 限流规则：先通过FlowRules来定义限流规则，然后通过FlowRuleManager.loadRules来加载规则列表。  1 QPS流量控制行为 通过controlBehavior设置，包含：\n 直接拒接 Warm UP，冷启动 匀速排队 冷启动 + 匀速排队  7 Sentinel实现服务熔断 通过DegradeRule实现：\n grade：熔断策略，支持秒级RT、秒级异常比例、分钟异常数。默认是秒级RT。 timeWindow：熔断降级的时间窗口，单位为s。也就是出发熔断降级之后多长时间内自动熔断。 rtSlowRequestAmount：在RT模式下，1s内持续多少个请求的平均RT超出阈值后出发熔断，默认值是5 minRequestAmout：触发的异常熔断最小请求数，请求数小于该值时即使异常比例超出阈值也不会触发熔断，默认值是5.  三种熔断策略：\n 平均响应时间RT：如果1s内持续进来5个请求，对应的平均响应时间都超过了阈值(count，单位为ms)，那么在接下来的时间窗口内，对这个方法的调用都会自动熔断，抛出DegradeException 异常比例 最近一分钟异常数：如果timeWindow小于60s，则结束熔断状态后仍然可能再进入熔断状态。  Sentinel集成Spring Cloud 步骤如下：\n  创建项目，集成Spring Cloud依赖。\n  添加Sentinel依赖。\n  创建一个REST接口，并且通过@SentinelResource配置限流保护资源。\n  在上述代码中，配置限流资源有几种情况\n Sentinel starter在默认情况下会为所有的HTTP服务提供限流埋点，所以如果只想对HTTP服务进行限流，只需添加依赖即可。 如果想要对特定的方法进行限流或降级，则需要通过@SentinelResource注解来定义资源。 可以通过SphU.entry()方法来配置资源。    手动配置流控规则，可以借助Sentinel的InitFunc SPI扩展接口来实现，只需要实现自己的InitFunc接口，并在init方法中编写规则加载的逻辑即可。\n  基于Sentinel Dashboard来实现流控配置 步骤如下：\n  启动Sentinel Dashboard\n  在application.yml中增加以下配置\n  提供一个REST接口\n  进入Sentinel Dashboard中配置流控规则。\n  访问簇点链路，找到资源名称。\n  单机流控按钮设置流控规则\n  注意sentinel的坑：\nSentinel自定义URL限流异常 默认情况下，URL触发限流后会返回Blocked by Sentinel字符串\n在实际应用中，大都采用JSON格式，所以如果希望修改触发限流之后的返回结果形式，则可以通过自定义限流异常来处理，实现UrlBlockHandler并且重写blocked方法。\n还有一种场景，当触发限流后，希望跳转到一个降级页面，可以通过下面这个配置来实现。\nspring.cloud.sentinel.servlet.block-page={url}\nSentinel对URL资源清洗 Sentinel中HTTP服务的限流默认由Sentinel-Web-Servlet包中的CommonFilter来实现，这个Filter会把每个不同的URL都作为不同的资源来处理。\n举例：\n 限流统计不准确，实际需求是控制clean方法总的QPS，结果统计的是每个URL的QPS 导致Sentinel中资源数量过多，默认资源数量阈值为6000，对于多出的资源规则将不会生效。  针对这个问题可以通过URLCleaner接口来实现资源清洗，也就是对于/clean/{id}这个URL，我们可以统一归集到/clean/*资源下，具体代码如下：\nSentinel集成Nacos实现动态流控规则 Sentinel的理念是只需要开发者关注资源的定义，默认会对资源进行流控。当然我们还需要自定义流控规则，前面有两种方式：\n 通过FlowRuleManager.loadRules(List rules)手动加载流控规则 在Sentinel Dashboard上针对资源动态创建流控规则。  针对第一种方式，如果接入Sentinel Dashboard，那么同样支持动态修改流控规则。但是，这里会存在一个问题，基于Sentinel Dashboard所配置的流控规则，都是保存在内存中的，一旦应用重启，这些规则都会被清除。为了解决这个问题，Sentinel提供了动态数据源支持。\n目前，Sentinel支持Consul、Zookeeper、Redis、Nacos、Apollo、etcd等数据源的扩展，我们使用Nacos的方式来扩展。\n步骤如下：\n  添加Nacos数据源依赖包\n  创建一个REST接口用于测试。\n  在application.yml中添加数据源配置。\n配置说明：\nrule-type：flow、degrade、param-flow、gw-flow等\ndata-type：Spring Cloud Alibaba提供了JSON和XML两种格式。如果需要自定义，则可以将值配置为custom，并配置converter-class指向converter类。\n  登录Nacos控制台，创建流控配置规则，配置信息如下：\n  最后，登录Sentinel Dashboard，找到执行项目名称菜单下的“流控规则”，就可以看到在Nacos上所配置的流控规则已经被加载了。\n  当在Nacos控制台修改流控规则后，可以同步在Sentinel Dashboard上看到流控规则的变化。\n 注意：在Sentinel Dashboard上修改无法同步到Nacos上。    强烈建议：不要在Nacos上修改流控规则，因为这种修改的危险系数很高。这就意味着流控规则的管理应该集中在Sentinel Dashboard上，所以我们需要实现Sentinel Dashboard来动态维护规则并同步到Nacos上，目前官方还没有提供支持，但可以自己实现。\n  这里有一个坑：出现了空指针异常org.springframework.beans.factory.BeanCreationException: Error creating bean with name \u0026lsquo;ds1-sentinel-nacos-datasource\u0026rsquo;: FactoryBean threw exception on object creation; nested exception is java.lang.NullPointerException，出现原因是Spring-Cloud-Alibaba与Sentinel的版本对应不上，解决办法是把Spring Cloud Alibaba的版本升到2.2.5.RELEASE即可。\n  Sentinel集成Nacos实现规则同步 Sentinel Dashboard的“流控规则”下的所有操作，都会调用Sentinel源码中的FlowControllerV1类，这个类包含流控规则本地化的CRUD\n另外，在com.alibaba.csp.sentinel.dashboard.controller.v2包下存在一个FlowControllerV2类，这个类同样提供流控规则的CRUD，和V1版本不同的是，它可以实现指定数据源的规则拉取和同步。\nFlowControllerV2依赖以下两个非常重要的类\n DynamicRuleProvider：动态规则的拉取，从指定数据源中获取流控规则后在Sentinel Dashboard中展示。 DynamicRulePublisher：动态规则的发布，将在Sentinel Dashboard中修改的规则同步到指定数据源中。  这里我们扩展这两个类，然后集成Nacos来实现Sentinel Dashboard规则的同步。\n1 Sentinel Dashboard源码修改： 具体步骤如下：\n  打开sentinel-dashboard工程，在pom.xml中把sentinel-datasource-nacos依赖的scope注释掉。\n  修改resouces/app/scripts/directives/sidebar/sidebar.html文件下的代码，将dashboard.flowV1改成dashboard.flow\n修改之后，会调用FlowControllerV2中的接口。\n  在com.alibaba.csp.sentinel.dashboard.rule包中创建一个nacos包，并创建一个类用来加载外部化配置。\n  创建一个Nacos配置类NacosConfiguration\n 注入Converter转换器，将FlowRuleEntity转化为FlowRule，以及反向转化。 注入Nacos配置服务ConfigService    创建一个常量类NacosConstants，分别表示默认的GROUP_ID和DATA_ID的后缀。\n  实现动态从Nacos配置中心获取流控规则。\n  创建一个流控规则发布类，在Sentinel Dashboard上修改完配置后，需要调用该发布方法将数据持久化到Nacos中。\n  修改FlowControllerV2类，将上面配置的两个类注入进来，表示规则的拉取和规则的发布统一用我们前面自定义的两个实例。\n  在application.properties文件中添加nacos服务端的配置信息。\n  将代码打包成一个fat jar\n  详见https://blog.csdn.net/weixin_42073629/article/details/107117433 或者test包中的nacos代码\n  2 Sentinel Dashboard规则同步 应用程序需要修改的地方比较少，只需注意配置文件中data-id的命名要以-sentinel-flow结尾即可。\nSentinel集成Dubbo实现限流 Sentinel提供了与Dubbo整合的模块Sentinel Apache Dubbo Adapter，可以针对服务提供者和服务消费者进行流控，在使用的时候，只需要添加以下依赖。\n添加后该依赖后，Dubbo服务中的接口和方法（包括服务端和消费端）就会成为Sentinel中的资源，只需针对指定资源配置流控规则就可以实现Sentinel流控功能。\nSentinel Apache Dubbo Adapter实现限流的核心原理是基于Dubbo的SPI机制实现Filter扩展，Dubbo的Filter机制是专门为服务提供者和服务消费者调用过程进行拦截设计的，每次执行远程方法，该拦截都会被执行。\n同时，Sentinel Apache Dubbo Adapter还可以自定义开启或者关闭某个Filter的功能，下面表示关闭消费端的过滤器。\n 1 Dubbo服务接入Sentinel Dashboard   引入sentinel-transport-simple-http依赖\n  添加启动参数\n  登录Sentinel Dashboard之后，进入“簇点链路”，就可以看到资源信息。\n  需要注意的是，限流可以通过服务接口或服务方法设置\n 服务接口：resourceName为接口的全限定名（包+接口名） 服务方法：resourceName为接口全限定名：方法名（包+接口名:方法名）    2 Dubbo服务限流规则 两种方式\n Sentinel Dashboard FlowRuleManager.loadRules(List rules)  Sentinel Apache Dubbo Adapter组件中没有实现规则持久化，因此有以下步骤来支持：\n 在dubbo服务中添加sentinel-datasource-nacos依赖 通过Sentinel提供的InitFunc扩展点，实现Nacos数据源的配置   访问Sentinel Dashboard，在针对某个资源创建流控规则时，这个规则会同步保存到Nacos的配置中心，而当Nacos配置中心发生变化时，会触发事件机制通知Dubbo应用重新加载流控规则。  Sentinel热点限流 热点数据表示经常访问的数据，在有限场景中我们希望针对这些访问频次非常高的数据进行限流，比如针对一段时间内频繁访问的用户ID地址进行限流，或者针对频繁访问的某个用户ID进行限流。\nSentinel提供了热点参数限流的规则，它是一种特殊的限流，在普通限流的基础上对同一个受保护的资源区根据请求中的参数分别处理，该策略只对包含热点参数的资源调用生效。热点限流在以下场景使用较多：\n 服务网关层：例如防止网络爬虫和恶意攻击，一种常用方法就是限制爬虫的IP地址。 写数据的服务：例如业务系统提供写数据的服务，数据会写入数据库之类的存储系统。存储系统的底层会加锁写磁盘上的文件，部分存储系统会将某一类数据写入同一个文件中。如果底层写同一文件，会出现抢占锁的情况，导致出现大量超时和失败。出现这种情况时一般有两种解决方法：修改存储设计、对热点参数限流。  Sentinel通过LRU策略结合滑动窗口机制来实现热点参数的统计，其中LRU策略可以统计单位时间内最常访问的热点数据，滑动窗口机制可以协助统计每个参数的QPS。\n1 热点参数限流的使用  引用热点参数限流依赖包sentinel-parameter-flow-control 接下来创建一个REST接口，并定义限流埋点，此处针对参数ID配置热点限流规则。 针对不同的热点参数，需要通过SphU.entry(resourceName,EntryType.IN,1,id)方法设置，其最后一个参数是一个数组，有多个热点参数就按照次序依次传入，该配置表示后续会针对该参数进行热点限流。 通过ParamFlowRuleManager.loadRules加载热点参数规则。  2 @SentinelResource 如果是通过@SentinelResource注解来定义资源，当注解所配置得方法上有参数时，Sentinel会把这些参数传入SphU.entry中\n3 热点参数规则说明  durationInSec：统计窗口时间长度，单位为s maxQueueingTimeMS：最长排队等待时长，只有当流控为controlBehavior设置为匀速排队模式时生效。 paramIdx：热点参数的索引，属于必填项，对应的是SphU.entry中的参数索引位置。 paramFlowItemList：针对指定参数值单独设置限流阈值，不受count阈值的限制。  Sentinel的工作原理（略）  工作流程：由各个Slot插槽组成（责任链模式） p229  Spring Cloud Sentinel工作原理（略）  starter自动装配 p232  Sentinel核心源码分析（略）  sentinel-adapter sentinel-core sentinel-dashboard sentinel-demo sentinel-extension sentinel-transport  1 限流的源码实现 2 实时指标数据统计 3 服务降级的实现原理 什么是分布式事务？ 事务：作为单个逻辑工作单元执行的多个数据库操作，要么同时成功，要么同时失败，必须满足ACID特性。（单库多表）\n在微服务架构下，随着业务服务的拆分及数据库的拆分，举例说，订单和库存分别拆分成两个独立的数据库，当客户端发起一个下单操作，需要在订单服务对应的数据库创建订单，同时基于RPC通信调用库存服务完成商品库存的扣减。\n这样，原来的单库事务操作就变成了多个数据库的事务操作 =\u0026gt; 数据不一致问题。\n1 分布式事务问题的理论模型 核心原因：存储资源的分布性\n在实际应用中，应该尽可能从设计层面去避免分布式事务的问题。\n1 X/Open分布式模型 X/Open DTP是X/Open这个组织定义的一套分布式事务的标准。这个标准提出了两阶段提交（2PC，2-phase-commit）来保证分布式事务的完整性。X/Open DTP包含以下三种角色。\n AP：Application RM：Resource Manager TM：Transaction Manager  如果TM需要能够管理多个数据库的事务，则实现步骤如下：\n 配置TM，把多个RM注册到TM，相当于TM注册RM作为数据源。 AP从TM管理的RM中获取连接，如果RM是数据库则获取JDBC连接。 AP向TM发起一个全局事务，生成全局事务ID（XID），XID会通知各个RM。 AP通过第二步获得的连接直接操作RM完成数据库操作。这时，AP在每次操作会把XID传递给RM。 AP结束全局事务，TM会通知各个RM全局事务结束。 根据各个RM的事务执行结果，执行提交或者回滚操作。  其中，TM和多个RM之间的事务控制，是基于XA协议来完成的。目前Oracle、MySQL、DB2都实现了XA接口，因此都能作为RM。\n2 两阶段提交协议 第一阶段：事务的准备阶段\n第二阶段：事务的提交或回滚阶段\n这两个阶段都是由事务管理器发起的，流程如下：\n 准备阶段：TM通知RM准备分支事务，记录事务日志，并告知TM的准备结果。 提交/回滚阶段：如果所有的RM在准备阶段都明确返回成功，TM向所有RM发起提交指令完成数据的变更；反之，则TM向所有RM发送回滚指令。  然而，它并不是完美的，也有缺点：\n 同步阻塞：所有RM都是事务阻塞型的，对于任何一次指令都必须要有明确的响应才能进行下一步，否则会处于阻塞状态。 过于保守：任何一个节点失败都会导致数据回滚。 TM的单点故障：如果TM在第二阶段故障，则所有RM会一直处于锁定状态。 “脑裂”导致数据不一致问题：在第二阶段中，TM向所有RM发送commit请求后，发生局部网络异常导致只有一部分RM接受到commit，剩余未收到请求的则没提交，导致数据出现不一致问题。  3 三阶段提交协议 利用超时机制解决了同步阻塞的问题\n CanCommit（询问阶段）：TM向RM发送事务执行请求，询问是否可以完成指令，参与者只需回答是或者不是即可，不需要做真正的事务操作，这个阶段会有超时中止机制。 PreCommit（准备阶段）：TM根据RM的反馈结果决定是否继续，如果在询问阶段所有RM都能执行操作，则TM向所有RM发送PreCommit请求，RM收到请求后写redo和undo日志，执行事务操作但是不提交事务，然后返回ACK响应等待TM的下一步通知。如果询问阶段任意参与者返回不能执行操作的结果，则TM发送事务中断请求。 DoCommit（提交或回滚阶段）：根据上一步骤的执行结果，如果每个RM都返回成功，则TM发送事务提交指令，反之则中止。  三阶段提交协议与二阶段提交协议的区别\n 增加了一个CanCommit阶段，可以尽早发现无法执行操作而中止后续的行为。 在准备阶段之后，TM和RM都引入超时机制，一旦超时，TM和RM会继续提交事务，并且认为处于成功状态，因为这种情况下事务默认为成功的可能性比较大。  实际上，一旦超时，在三阶段提交协议下仍然可能出现数据不一致的问题，当然概率是比较小的。另外，最大的好处是基于超时机制来避免资源的永久锁定。\n4 CAP定理和BASE理论 XA协议：二阶段提交和三阶段提交，数据一致性强，但可用性低。\nCAP定理：布鲁尔定理，指在分布式系统中不可能同时满足一致性C、可用性A、分区容错性P，最多同时满足两个。\n C：数据在多个副本中要保持强一致 A：系统对外提供的服务必须一直处于可用状态。 P：在分布式系统中遇到任何网络分区故障，系统仍然能够正常对外提供服务。  在分布式系统中，要么满足CP，要么满足AP，不可能实现CAP或者CA，因为网络通信不是绝对可靠的。\n AP：放弃强一致性，实现最终的一致。（很多互联网公司的主要选择） CP：放弃高可用性，实现强一致性。（2PC和3PC，存在问题：用户完成一个操作可能会等待较长的时间，用户体验差）  BASE理论：由于CAP中CA不可兼得衍生出来的一种新的思想。核心思想是：牺牲数据的强一致性来获得高可用性，有三个特性：\n Basically Avaliable（基本可用）：分布式系统出现故障时，允许损失一部分功能的可用性，保证核心功能的可用。 Soft State（软状态）：允许系统中的数据存在中间状态，这个状态不影响系统的可用性，也就是允许系统中不同节点的数据副本之间的同步存在延时。 Eventually Consistent（最终一致性）：中间状态的数据在经过一段时间之后，会达到一个最终的数据一致性。  2 分布式事务问题的常见解决方案 1 TCC补偿性方案 TCC（Try-Confirm-Cancel）是一种比较成熟的分布式数据一致性解决方案，它实际上是把一个完整的业务拆分为如下三个步骤\n Try：这个阶段主要是对数据的校验或者资源的预留。 Confirm：确定真正执行的任务，只操作Try阶段预留的资源。 Cancel：取消执行，释放Try阶段预留的资源。  本质：二阶段提交的思想，第一阶段通过Try准备，第二阶段通过Confirm/Cancel\n2 基于可靠性消息的最终一致性方案 基于可靠性消息的最终一致性方案是互联网公司比较常用的分布式数据一致性解决方案，它主要利用消息中间件（Kafka、RocketMQ或RabbitMQ）的可靠性机制来实现数据一致性的投递。\n总结：消费者没有向消息中间件服务器发送确认之前，这个消息会被重复投递，确保消息的可靠性消费。\n3 最大努力通知型 与基于可靠性消息的最终一致性方案实现类似，是一种比较简单的柔性事务解决方案。\n如果没有返回一个消息确认时，则不断进行重试，直到收到一个消息确认或者达到最大重试次数。\n3 分布式事务框架Seata 提供了AT、TCC、Saga和XA四种事务模式。\n1 AT模式 Seata最主推的分布式事务解决方案，基于XA演进而来，分为TM、RM和TC，TC作为Seata的服务器独立部署。\n2 Saga模式 又称长事务解决方案，主要描述的是在没有2PC的情况下如何解决分布式事务问题。其核心思想是：把一个业务流程中的长事务拆分为多个本地短事务，业务流程中的每个参与者都提交真实提交给本地段事务，当其中一个参与者失败，则通过补偿机制补偿前面已经成功的参与者。\n两种补偿恢复方式：\n 向后恢复：如果任一子事务失败，则撤销执行结果。 向前恢复：不进行补偿，而是对失败的事务进行redo，这种方式比较适合于事务必须要执行成功的场景。  优点：\n 一阶段直接提交本地事务 没有锁等待，性能较高 在事件驱动的模式下，短事务可以异步执行。 补偿机制的实现比较简单。  缺点：不提供原子性和隔离性支持\n协调模式：\n 事件/编排式 命令/协同式  ","date":"2021-04-07T00:00:00Z","permalink":"https://cuterwrite.top/p/spring-cloud-alibaba-1/","title":"Spring Cloud Alibaba笔记"}]