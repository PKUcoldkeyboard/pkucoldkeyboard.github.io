[{"content":" Table of Contents generated with DocToc\n程序调试与优化分析工具 一、概述 二、程序调试分析工具简介 1. gdb 2. Valgrind 三、程序优化分析工具简介 1. gprof 2. perf 3. Vtune 总结 参考资料 程序调试与优化分析工具 一、概述 在编程中我们通常会遇到如下问题：\n程序运行慢，效率低 消耗了大量的内存 segmentation fault 程序崩溃 程序运行结果不正确\u0026hellip;\u0026hellip; 随着处理器复杂度的增加\n我们不再能够轻松地跟踪代码段的执行 静态/动态分支预测、预取、顺序调度\u0026hellip;\u0026hellip; 仅使用墙钟时间来衡量代码性能是不够的。 我们还需要了解到底发生了什么 对于性能评估，有直接和间接两种方法\n直接方法：需要某些形式的显示插装 追踪 为每个测量事件生成记录 只有在产生大量数据情况下，出现的性能异常数据才有用 聚合 减少数据在运行时平均/最小/最大测量 适用于应用程序和体系结构和描述和优化 间接方法：不需要插装，可不修改应用程序 事实上，直接和间接方法的界限有些模糊 聚合：如gprof，可以不修改程序，但是需要重新编译链接 实际编程中，常见的分析工具如下：\n类型 工具 程序调试 gdb 程序调试 valgrind 程序优化 gprof 程序优化 perf 程序优化 Intel VTune Amplifier 二、程序调试分析工具简介 程序中的错误按其性质可以分为三种： 编译错误 ：即语法错误，主要是程序代码中有不符合所用编程语言语法规则的错误。 运行时错误 ：如对负数开平方、除数为0、循环终止条件永远不能达到等。 逻辑错误 ：这类错误往往是编程前对求解的问题理解不正确或算法不正确引起的，它们很难查找（数组越界、空指针） 程序调试就是查找程序中的错误，诊断其准确位置，并予以改正。 1. gdb GDB是GNU开源组织发布的一个强大的UNIX下的程序调试工具 GDB具备如下4个方面的功能： 启动程序，可以按用户要求影响程序的运行行为 可以让被调试的程序在用户所指定的断点处暂停（断点可以是条件表达式） 当程序被暂停时，可以检查此时用户程序中所发生的事情 动态改变用户程序的执行环境，这样就可以先纠正一个错误的影响，然后再纠正其他错误 为了发挥GDB的全部功能，需要在编译源程序时使用-g选项 gcc -g test.c -o proc 启动GDB，以参数形式将可执行程序传递给GDB\ngdb program gdb ./proc gdb -p pid gdb -p `pidof proc` gdb program core gdb ./proc core.xxx gdb attach pid gdb attach 2313 启动gdb后就显示其提示符：（gdb），并等待用户输入相应的内部命令\n设置断点、设置运行参数和环境变量、跟踪调试命令、查看栈信息…… 用户可以利用命令quit终止其执行，退出gdb环境\ngdb常用命令列表如下：\n命令 解释 简写 file 装入想要调试的可执行文件 无 list 列出产生执行文件源代码的一部分 l next 执行一行源代码但不进入函数内部 n step 执行一行源代码而且进入函数内部 s run 执行当前被调试的程序 r continue 继续执行程序 c quit 终止GDB q print 输出当前指定变量的值 p break 在代码里设置断点 b info break 查看设置断点的信息 ib delete 删除设置的断点 d watch 监视一个变量的值，一旦值有变化，程序停住 wa help GDB中的帮助命令 h 设置断点：\n编译源程序时需要使用-g选项 在GDB中用break命令（其缩写形式为b）设置断点： break linenum 在当前文件指定行linenum处设置断点，停在该行开头 break linenum if condition 在当前文件指定行linenum处设置断点，但仅在条件表达式condition成立时才停止程序执行 break function 在当前文件函数function的入口处设置断点 break file:linenum 在源文件file的linenum行上设置断点 break file:function 在源文件file的函数function的入口处设置断点 break *address 运行程序在指定的内存地址address处停止 break 不带任何参数，则表示在下一条指令处停止 断点应设置在可执行的行上，不应是变量定义之类的语句 删除断点：\ndelete [bkptnums] 显示断点：\ninfo breakpoints [num] info break [num] 运行程序：\nrun [args] 程序的单步跟踪和\nstep [N] 参数N表示每步执行的语句行数，进入被调用函数内部执行 next [N] 参数N表示每步执行的语句行数，被调用函数被当做一条指令执行 stepi（缩写为si）或nexti（缩写为ni）命令一条一条地执行机器指令 程序的连续执行\n利用continue，c或fg命令连续执行到下一个断点 显示源文件命令list （l）\nlist：没有参数，显示当前行之后或周围的10多行 list -：显示之前的10行 list [file]:num：显示源文件file中给定行号num周围的10行。如果缺少file，则默认为当前文件。例如，list 100 list start, end：显示从行号start至end之间的代码行。例如，list 20,38 list [file:]fun：显示源文件file中指定函数function的代码行。如果缺少file，则默认为当前文件。例如，list meng1.c:square set listsize linenum : 可以使用该命令设置一次显示的行数 查看运行时数据命令print （p）\n当被调试的程序停止时，可以用print命令或同义命令inspect来查看当前程序中运行的数据 print命令的一般使用格式：print [/fmt] exp print i （或p i） 显示当前变量i的值 print i*j (或p i*j) 将根据程序当前运行的实际情况显示出i*j的值 print所支持的运算符： 取地址\u0026amp;符号 @ 是一个与数组有关的双目运算符，使用形式如 print array@10 打印从array（数组名，即数组的基地址）开始的10个值 print array[3]@5 打印从array第三个元素开始的5个数组元素的数值 file::i 或 function ::i 表示文件或者函数中i的值 GDB使用示例\n// test.c #include \u0026lt;stdio.h\u0026gt; int sum(int n); int main(int argc, char **argv) { int i, result = 0; for (i = 1; i \u0026lt;= 50; i++) { result += i; } printf(\u0026#34;result[1-50]=%d\\n\u0026#34;, result); printf(\u0026#34;result[1-100]=%d\\n\u0026#34;, sum(100)); } int sum(int n) { int i, sum; for (i = 1; i \u0026lt;= n; i++) { sum += i; } return sum; } 编译带调试信息的可执行文件 gcc -g test.c -o test 启动GDB gdb test 调试结果 GNU gdb (Ubuntu 9.2-0ubuntu1~20.04.1) 9.2 Copyright (C) 2020 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later \u0026lt;http://gnu.org/licenses/gpl.html\u0026gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \u0026#34;show copying\u0026#34; and \u0026#34;show warranty\u0026#34; for details. This GDB was configured as \u0026#34;x86_64-linux-gnu\u0026#34;. Type \u0026#34;show configuration\u0026#34; for configuration details. For bug reporting instructions, please see: \u0026lt;http://www.gnu.org/software/gdb/bugs/\u0026gt;. Find the GDB manual and other documentation resources online at: \u0026lt;http://www.gnu.org/software/gdb/documentation/\u0026gt;. For help, type \u0026#34;help\u0026#34;. Type \u0026#34;apropos word\u0026#34; to search for commands related to \u0026#34;word\u0026#34;... Reading symbols from test... (gdb) list 1 #include \u0026lt;stdio.h\u0026gt; 2 3 int sum(int n); 4 5 int main(int argc, char **argv) 6 { 7 int i, result = 0; 8 for (i = 1; i \u0026lt;= 50; i++) 9 { 10 result += i; (gdb) 11 } 12 printf(\u0026#34;result[1-50]=%d\\n\u0026#34;, result); 13 printf(\u0026#34;result[1-100]=%d\\n\u0026#34;, sum(100)); 14 } 15 16 int sum(int n) 17 { 18 int i, sum; 19 for (i = 1; i \u0026lt;= n; i++) 20 { (gdb) 21 sum += i; 22 } 23 return sum; 24 } (gdb) b 8 Breakpoint 1 at 0x1163: file test.c, line 8. (gdb) info b Num Type Disp Enb Address What 1 breakpoint keep y 0x0000000000001163 in main at test.c:8 (gdb) r Starting program: /root/workspace/test Breakpoint 1, main (argc=1, argv=0x7fffffffe2d8) at test.c:8 8 for (i = 1; i \u0026lt;= 50; i++) (gdb) p i $1 = 0 (gdb) p result $2 = 0 (gdb) n 10 result += i; (gdb) n 8 for (i = 1; i \u0026lt;= 50; i++) (gdb) p i $3 = 1 (gdb) p result $4 = 1 (gdb) d 1 (gdb) info b No breakpoints or watchpoints. (gdb) c Continuing. result[1-50]=1275 result[1-100]=26895 [Inferior 1 (process 286758) exited normally] (gdb) q 总的来说，GDB调试的过程为： 编译带调试信息的可执行文件 启动GDB，开始调试 GDB中查看文件 设置断点 查看断点情况 运行代码 跟踪变量值 删除所设断点 恢复程序运行 退出GDB 2. Valgrind Valgrind是一个Linux下灵活的调试和剖析工具 收集各种有用的运行时信息，可以帮助找到程序中潜在的bug和性能瓶颈 Valgrind包含多个工具： 工具 功能 Memcheck 这是valgrind应用最广泛的工具，一个重量级的内存检查器，能够发现开发中绝大多数内存错误使用情况，比如：使用未初始化的内存、使用已经释放了的内存、内存访问越界等 Callgrind 主要用来检查程序中函数调用过程中出现的问题 Cachegrind 主要用来检查程序中缓存使用出现的问题 Helgrind 主要用来检查多线程程序中出现的竞争问题 Massif 主要用来检查程序中堆栈使用中出现的问题 Extensio 可以利用core提供的功能，自己编写特定的内存调试工具 Valgrind使用需要先进行安装，在ubuntu下可以使用apt-get进行安装 sudo apt-get install valgrind 为了使Valgrind发现的错误更精确，建议在编译时加上-g参数，编译优化选择O0，即： gcc -g -O0 test.c -o test valgrind命令格式为: valgrind [options] prog-and-args [options]\n[options]: 常用选项，适用于所有Valgrind工具 \u0026ndash;tool=\u0026lt;name\u0026gt;： 最常用的选项，运行valgrind中名为toolname的工具，默认memcheck -h|\u0026ndash;help：显示帮助信息 \u0026ndash;version：显示valgrind内核的版本，每个工具都有各自的版本 -q|\u0026ndash;quiet：安静地运行，只打印错误信息 -v|\u0026ndash;verbose：更详细的信息，增加错误数统计 \u0026hellip;\u0026hellip; Memcheck内存错误检查：\n可以检查出下列几种错误 使用已经释放的内存 内存块越界 使用未初始化的变量 内存泄漏 同一个内存块释放多次 Memcheck命令行选项： \u0026ndash;leak-check=\u0026lt;no|summary|yes|full\u0026gt; [default: summary] summary是给出最后leak的汇总，yes或者full将会给出比较详细的leak信息 \u0026ndash;leak-resolution=\u0026lt;low|med|high\u0026gt; [default: high] 用于合并leak信息来源的backtraces，low是有两层匹配的时候就可以合并，med是四层，high必须完全比配。该选项不影响查找leak的能力，只影响结果的显示方式 Cachegrind缓存检查\n通过模拟cpu的1,3级缓存，收集应用程序运行时关于cpu的一些统计数据，最后在将明细数据和汇总信息打印出来 执行方式： $ valgrind \u0026ndash;tool=cachegrind your_application cachegrind的结果也会以输出文件的方式输出更多的细节，输出文件的缺省文件名是cachegrind.out.，其中是当前进程的pid。该文件名可以通过\u0026ndash;cachegrind-out-file选择指定更可读的文件名，这个文件将会成为cg_annotate的输入 Cachegrind命令行选项： \u0026ndash;cache-sim=no|yes [yes] 指定是否收集cache accesses和miss counts \u0026ndash;branch-sim=no|yes [no] 指定是否收集branch instruction和misprediction counts Callgrind函数调用分析\nCallgrind收集程序运行时的一些数据，建立函数调用关系图，还可以有选择地进行cache模拟。被分析的程序编译时要加-g，编译优化选项建议选择-O2 执行方式： $ valgrind \u0026ndash;tool=callgrind your_application 输出文件的缺省文件名是callgrind.out. ，其中是当前进程的pid Cachegrind命令行选项： \u0026ndash;callgrind-out-file= 指定profile data的输出文件，而不是缺省命名规则生成的文件 \u0026ndash;dump-line=\u0026lt;no|yes\u0026gt; [default: yes] 事件计数将以source line作为统计的粒度，但是源程序在编译的时候加入-g选项 Helgrind多线程分析器\n主要用来检查多线程程序中出现的竞争问题 执行方式： $ valgrind \u0026ndash;tool=helgrind your_application Massif堆栈分析\n堆栈分析器，它能测量程序在堆栈中使用了多少内存，告诉我们堆块，堆管理块和栈的大小。Massif能帮助我们减少内存的使用 执行方式： $ valgrind \u0026ndash;tool=massif your_application 输出文件：massif..ps massif. .txt，其中是当前进程的pid Valgrind使用示例1：内存检查\n// test.c #include \u0026lt;stdlib.h\u0026gt; void f(void) { int* x = malloc(10 * sizeof(int)); x[10] = 0; // 问题1：数组下标越界 // 问题2：内存泄漏，没有free(x) } int main(int argc, char** argv) { f(); return 0; } 编译并运行： gcc -g -O0 test.c -o test valgrind --tool=memcheck --leak-check=full ./test 输出结果： ==292701== Memcheck, a memory error detector ==292701== Copyright (C) 2002-2017, and GNU GPL\u0026#39;d, by Julian Seward et al. ==292701== Using Valgrind-3.15.0 and LibVEX; rerun with -h for copyright info ==292701== Command: ./test ==292701== ==292701== Invalid write of size 4 ==292701== at 0x10916B: f (test.c:6) ==292701== by 0x10918B: main (test.c:12) ==292701== Address 0x4a4b068 is 0 bytes after a block of size 40 alloc\u0026#39;d ==292701== at 0x483B7F3: malloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so) ==292701== by 0x10915E: f (test.c:5) ==292701== by 0x10918B: main (test.c:12) ==292701== ==292701== ==292701== HEAP SUMMARY: ==292701== in use at exit: 40 bytes in 1 blocks ==292701== total heap usage: 1 allocs, 0 frees, 40 bytes allocated ==292701== ==292701== 40 bytes in 1 blocks are definitely lost in loss record 1 of 1 ==292701== at 0x483B7F3: malloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so) ==292701== by 0x10915E: f (test.c:5) ==292701== by 0x10918B: main (test.c:12) ==292701== ==292701== LEAK SUMMARY: ==292701== definitely lost: 40 bytes in 1 blocks ==292701== indirectly lost: 0 bytes in 0 blocks ==292701== possibly lost: 0 bytes in 0 blocks ==292701== still reachable: 0 bytes in 0 blocks ==292701== suppressed: 0 bytes in 0 blocks ==292701== ==292701== For lists of detected and suppressed errors, rerun with: -s ==292701== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0) 可以看到：valgrind检测到了两个错误，一个是内存越界，一个是内存泄漏 Invalid write of size 4：提示了内存越界的错误 40 bytes in 1 blocks are definitely lost in loss record 1 of 1：提示了内存泄漏的错误 Valgrind使用示例2：Cachegrind缓存检查\n// test.c #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main(void) { char *arr = malloc(4); int *arr2 = malloc(sizeof(int)); strcpy(arr, \u0026#34;1234\u0026#34;); exit(arr2[0]); } 编译并运行： gcc -g -O0 test.c -o test valgrind --tool=cachegrind ./test 当前目录下会生成一个cachegrind.out.文件，其中是当前进程的pid，使用ls命令查看： $ ls cachegrind.out.293847 test test.c 使用cg_annnotate命令查看cachegrind.out.文件的内容： $ cg_annotate cachegrind.out.293847 -------------------------------------------------------------------------------- I1 cache: 32768 B, 64 B, 8-way associative D1 cache: 32768 B, 64 B, 8-way associative LL cache: 31457280 B, 64 B, 15-way associative Command: ./test Data file: cachegrind.out.293847 Events recorded: Ir I1mr ILmr Dr D1mr DLmr Dw D1mw DLmw Events shown: Ir I1mr ILmr Dr D1mr DLmr Dw D1mw DLmw Event sort order: Ir I1mr ILmr Dr D1mr DLmr Dw D1mw DLmw Thresholds: 0.1 100 100 100 100 100 100 100 100 Include dirs: User annotated: Auto-annotation: off /* 以下内容省略 */ 可以看到，cachegrind.out.文件中记录了程序运行时的缓存信息，包括I1 cache，D1 cache，LL cache等，这些信息可以帮助我们分析程序的缓存使用情况 cachegrind输出的信息中，我们比较关注的是： Ir: 指令读取次数 I1mr：指令读取miss次数 ILmr：指令读取miss次数 Dr：数据读取次数 D1mr：数据读取miss次数 DLmr：数据读取miss次数 Dw：数据写入次数 D1mw：数据写入miss次数 DLmw：数据写入miss次数 Valgrind使用示例3：Callgrind调用图检查\n// test.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; void f(void) { int *x = malloc(10 * sizeof(int)); x[10] = 0; // 问题1: 数组下标越界 } //问题2: 内存没有释放 int main(void) { int i; f(); printf(\u0026#34;i=%d\\n\u0026#34;, i); // 问题3：变量没有赋初值 return 0; } 编译并运行： gcc -g -O2 test.c -o test valgrind --tool=callgrind ./test 当前目录下会生成一个callgrind.out.文件，其中是当前进程的pid，使用ls命令查看： $ ls callgrind.out.295036 test test.c 使用callgrind_annotate命令查看callgrind.out.文件的内容： $ callgrind_annotate callgrind.out.295036 -------------------------------------------------------------------------------- Profile data file \u0026#39;callgrind.out.295036\u0026#39; (creator: callgrind-3.15.0) -------------------------------------------------------------------------------- I1 cache: D1 cache: LL cache: Timerange: Basic block 0 - 43734 Trigger: Program termination Profiled target: ./test (PID 295036, part 1) Events recorded: Ir Events shown: Ir Event sort order: Ir Thresholds: 99 Include dirs: User annotated: Auto-annotation: off -------------------------------------------------------------------------------- Ir -------------------------------------------------------------------------------- 193,311 PROGRAM TOTALS -------------------------------------------------------------------------------- Ir file:function -------------------------------------------------------------------------------- 71,545 /build/glibc-SzIz7B/glibc-2.31/elf/dl-addr.c:_dl_addr [/usr/lib/x86_64-linux-gnu/libc-2.31.so] /* 以下内容省略 */ 可以看到，callgrind.out.文件中记录了程序运行时的调用图信息，包括函数调用次数，函数调用路径等，这些信息可以帮助我们分析程序的调用图使用情况 callgrind输出的信息中，我们比较关注的是： Ir：指令读取次数 三、程序优化分析工具简介 运行缓慢的代码将消耗大量的CPU时间, 因此，我们必需评估代码的运行效率, 在整个代码的设计和实现周期里都需考虑性能。 Amdahl定律：在一个系统中，如果某部分的执行时间占总执行时间的比例为p，那么优化这部分的执行时间，系统的整体执行时间至少降低p倍。 $$ \\begin{array}{c}T_{new} = T_{old} \\times (1-p) + \\frac{T_{old} \\times p}{k} \\ = T_{old} \\times (1-p + \\frac{p}{k})\\end{array} $$\n根据Amdahl定律，对热点部分进行性能优化能够获得最大收益 常见的程序优化分析工具有： gprof perf Vtune \u0026hellip;\u0026hellip; 1. gprof Gprof，又称GNU profiler，是Linux/Unix系统上的性能profiling软件，其功能是获得程序各个函数运行时间，帮助找出耗时最多的函数，以及显示函数调用关系，包括调用次数，帮助分析程序运行流程。\n基本原理为：\n编译链接程序时，编译器在程序的每个函数中都加入了一个函数，程序里的每一个函数都会调用该函数, 该函数 会在内存中保存一张函数调用图，并通过函数调用堆栈的形式查找子函数和父函数的地址 调用图也保存了所有与函数相关的调用时间，调用次数等信息 Gprof需要先使用-pg编译和链接应用程序\nifort -pg -O3 -o prog prog.f90 执行应用程序使之生成供gprof分析的数据，生成gmon.out ./prog 使用gprof程序分析应用程序生成的数据 gprof prog gmon.out \u0026gt; gprof.out gprof的输出信息包括： 序号 列名 说明 1 time 函数执行时间占总执行时间的百分比 2 cumulative seconds 函数和上列函数累计执行的时间 3 self seconds 函数本身所执行的时间 4 calls 函数被调用次数 5 self ms/call 每一次调用花费在函数的时间 6 total ms/call 每一次调用，花费在函数及其衍生函数的平均时间 7 name 函数名 gprof常用的命令选项有： 选项 说明 -b 不再输出统计图表中每个字段的详细描述 -p 只输出函数的调用图 -q 只输出函数的时间消耗列表 -e Name 不再输出函数Name及其子函数的调用图 -E Name 不再输出函数Name及其子函数的调用图，在总时间和百分比时间计算中排除了由函数Name及其子函数所用的时间 -f Name 输出函数Name及其子函数的调用图 -F Name 输出函数Name及其子函数的调用图，类似于-f，但它在总时间和百分比时间计算中仅使用所打印的例程的时间 对于由多个源文件组成的程序，编译时需要在生成每个.o文件的时候加上-pg参数，同时在链接的时候也要加上-pg参数 -pg参数只能记录源代码中各个函数的调用关系，而不能记录库函数的调用情况 要想记录每个库函数（如memcpy、memset、sprintf等函数）的调用情况，链接的时候必须指定库函数的动态（或者静态）链接库libc_p.a，即加上-lc_p，而不是-lc $ gcc example1.c –pg -lc_p -o example1 若只有部分代码在编译时指定了-pg参数，则生成的gmon.out文件中将缺少部分函数，也没有这些函数的调用关系，但是并不影响gprof对其它函数进行记录 gprof使用示例\n// test.c #include \u0026lt;stdio.h\u0026gt; int fast_multiply(int x, int y) { return x * y; } int slow_multiply(int x, int y) { int i, j, z; for (i = 0, z = 0; i \u0026lt; x; i++) z = z + y; return z; } int main(int argc, char *argv[]) { int i, j; int x, y; for (i = 0; i \u0026lt; 200; i++) { for (j = 0; j \u0026lt; 30; j++) { x = fast_multiply(i, j); y = slow_multiply(i, j); } } printf(\u0026#34;x=%d, y=%d\\n\u0026#34;, x, y); return 0; } 编译链接并运行程序 gcc -pg -o test test.c ./test 在当前目录下生成gmon.out文件，使用gprof分析 gprof -b test gmon.out \u0026gt; gprof.out gprof.out文件内容如下 Flat profile: Each sample counts as 0.01 seconds. no time accumulated % cumulative self self total time seconds seconds calls Ts/call Ts/call name 0.00 0.00 0.00 6000 0.00 0.00 fast_multiply 0.00 0.00 0.00 6000 0.00 0.00 slow_multiply Call graph granularity: each sample hit covers 2 byte(s) no time propagated index % time self children called name 0.00 0.00 6000/6000 main [8] [1] 0.0 0.00 0.00 6000 fast_multiply [1] ----------------------------------------------- 0.00 0.00 6000/6000 main [8] [2] 0.0 0.00 0.00 6000 slow_multiply [2] ----------------------------------------------- Index by function name [1] fast_multiply [2] slow_multiply 可以看到：程序中只有两个函数，fast_multiply和slow_multiply，gprof分析结果中也只有这两个函数，但是这两个函数的调用次数都是6000次，这是因为gprof默认的采样周期是0.01秒，而程序运行时间很短，所以两个函数的调用次数都是6000次，如果程序运行时间更长，那么两个函数的调用次数就会不一样了。 2. perf Perf是内置于Linux内核源码树中的性能剖析(profiling)工具，基于事件采样原理，以性能事件为基础，支持针对处理器相关性能指标与操作系统相关性能指标的性能剖析，常用于性能瓶颈的查找与热点代码的定位。\nPerf包含22种子工具的工具集，以下是最常用的5种：\nperf list：列出当前系统支持的所有性能事件。包括硬件性能事件、软件性能事件以及检查点 perf top：类似于Linux的top命令，对系统性能进行实时分析 perf stat：剖析某个特定进程的性能概况，包括CPI、Cache丢失率等 perf record：收集采样信息，并将其记录在数据文件中 perf report：读取perf record创建的数据文件，并给出热点分析结果 perf list\n查看当前软硬件平台支持的性能事件列表 事件分为以下三种： Hardware Event: 由PMU硬件产生的事件，比如cache命中，当要了解程序对硬件特性的使用情况时，便需要对这些事件进行采样 Software Event: 内核软件产生的事件，比如进程切换、tick数等 Tracepoint event: 内核中的静态tracepoint所触发的事件，这些tracepoint用来判断程序运行期间内核的行为细节，比如slab分配器的分配次数等 命令格式：perf list [hw | sw | cache | tracepoint] perf list工具仅列出了具有字符描述的硬件性能事件 perf top\n主要用于实时分析各个函数在某个性能事件上的热度，能够快速的定位热点函数，包括应用程序函数、模块函数与内核函数，甚至能够定位到热点指令，默认的性能事件为cpu cycles 命令格式： perf top [\u0026lt;options\u0026gt;] 常用命令行参数 -e ：指明要分析的性能事件 -p ：仅分析目标进程及其创建的线程 -k ：带符号表的内核映像所在的路径 -K：不显示属于内核或模块的符号 -U：不显示属于用户态程序的符号 -d ：界面的刷新周期，默认为2s -G：得到函数的调用关系图 perf stat\n用于分析指定程序的性能概况 命令格式：perf stat [\u0026lt;options\u0026gt;] [\u0026lt;command\u0026gt;] 常用命令行参数 -p ：仅分析目标进程及其创建的线程 -a：从所有CPU上收集性能数据 -r ：重复执行命令求平均 -C ：从指定CPU上收集性能数据 -v：显示更多性能数据 -n：只显示任务的执行时间 -x ：指定输出列的分隔符 -o ：指定输出文件。\u0026ndash;append指定追加模式，\u0026ndash;pre 执行目标程序前先执行的程序，\u0026ndash;post 执行目标程序后再执行的程序 perf record\n收集采样信息，并将其记录在数据文件中 随后可以通过其它工具(perf report)对数据文件进行分析，结果类似于perf top 命令格式：perf record [\u0026lt;options\u0026gt;] [\u0026lt;command\u0026gt;] perf report\n读取perf record创建的数据文件，并给出热点分析结果 命令格式：perf report [\u0026lt;options\u0026gt;] [\u0026lt;datafile\u0026gt;] perf使用示例\napt-get安装perf sudo apt-get install linux-tools-common linux-tools-generic linux-tools-`uname -r` 使用perf list查看当前系统支持的性能事件 perf list perf list结果： 使用perf top查看当前系统的热点函数 perf top perf top结果： 使用perf stat查看测试程序的性能概况\n使用在gprof时的程序代码test.c\n执行perf stat\nperf stat ./test perf stat结果： 使用perf record和perf report查看热点函数 perf record ./test perf report perf report结果： 进阶：火炬图FlameGraph：基于perf record和perf report的结果绘制火炬图\n下载FlameGraph工具：\ngit clone https://github.com/brendangregg/FlameGraph.git 收集性能数据：\nperf record -g ./test 对可执行文件test进行采样，每秒99次，采样结果保存在perf.data文件中 使用FlameGraph生成火炬图：运行以下命令使用FlameGraph生成火炬图：\nperf script | ./FlameGraph/stackcollapse-perf.pl \u0026gt; out.perf-folded ./FlameGraph/flamegraph.pl out.perf-folded \u0026gt; perf.svg FlameGrpah绘制结果：\n3. Vtune Intel VTune Amplifier XE是Intel针对其处理器的性能测试分析工具，支持Windows/Linux，提供图形用户界面和命令行接口，支持C、C++、Fortran、C#、Java、.NET 等多种语言。 Vtune基于硬件性能监视部件(PMU)性能测试，获得微体系结构级数据 指令类型与数目 存储访问事件 指令流水线事件 Vtune性能分析粒度包括：进程、线程、子程序、代码行 Vtune可以帮助用户分析算法选择，标识出应用程序怎样更好的利用可用的硬件资源，可以帮助用户如下性能方面问题： 程序中或者整个系统中时间消耗最多的函数 没有有效利用处理器时间的代码片段 优化串行和线程化性能的最好代码片段 影响程序性能的同步对象 程序的I/O操作是否花费很多时间，以及在哪里、为什么花费时间 不同的同步方法，不同的线程数量或者不同算法对于性能的影响 线程活跃性和变迁 代码中硬件相关的瓶颈 Vtune还可以提供寻找热点、分析锁和等待以及标识硬件问题等功能 Vtune命令格式为： amplxe-cl \u0026lt;-action\u0026gt; [-action-option] [-global-option] [[--] \u0026lt;target\u0026gt; [target-options]] amplxe-cl：VTune Amplifier命令行工具名称\n\u0026lt;-action\u0026gt; ：要执行的操作，如collect或report。每个命令必须只有一个操作。如，一个命令中不能同时有收集数据和生成报表\n[-action-option] ：操作选项，用于修改特定操作的行为。每个操作可以有多个操作选项，操作选项使用不当会导致使用错误\n[-global-option] ：全局选项，用于以相同的方式修改所有操作的行为。每个操作可以有多个全局选项\n[\u0026ndash;] ：要分析的目标程序\n[target-options] ：目标程序参数选项\nActions：amplxe-cl支持不同的命令选项\ncollect：运行指定的分析类型并将数据收集到结果中 collect-with：运行用户设置的基于事件的硬件采样或用户模式采样，并跟踪收集 command：向正在运行的收集操作发出命令 finalize：执行符号解析以完成或重新获得结果 help： 显示命令行参数的简短解释 import：导入一个或多个收集数据文件/目录 report：从分析结果中生成指定类型的报表 version：显示amplxe-cl版本信息 Action Options\n定义适用于指定操作的行为，如“-result-dir”选项是指定收集操作结果的目录路径 若要访问操作的可用操作选项列表，请使用命令“amplxe-cl –help” ，其中 是可用操作之一；要查看所有可用的操作, 请使用命令“amplxe-cl –help” 如果在同一命令行上使用了相反的操作选项，则将应用最后的操作选项 忽略上下文中冗余或没有意义的操作选项 使用不适当的操作选项，会导致意外行为返回使用错误 Global Options\n定义适用于所有操作的行为，如“-quiet”选项会取消所有操作的非必需消息。每个命令可能有一个或多个全局选项 Vtune使用示例：\n同样使用在gprof时的程序代码test.c，但是需要使用icc编译器编译，因为Vtune只支持icc编译器编译的程序\n安装icc编译器：Intel C++ Compiler\n注：icc编译器是收费的，需要购买或者申请学生许可 安装Vtune：Intel Vtune\nUbuntu下apt安装Vtune\nwget -O- https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB \\ | gpg --dearmor | sudo tee /usr/share/keyrings/oneapi-archive-keyring.gpg \u0026gt; /dev/null echo \u0026#34;deb [signed-by=/usr/share/keyrings/oneapi-archive-keyring.gpg] https://apt.repos.intel.com/oneapi all main\u0026#34; | sudo tee /etc/apt/sources.list.d/oneAPI.list sudo apt update sudo apt install intel-oneapi-vtune 编译程序： icc test.c -o test 激活vtune环境： source /opt/intel/oneapi/vtune/latest/amplxe-vars.sh 收集hosspot数据： ampxel-cl -collect hotspots -result-dir res ./test 总结 本文介绍了几种常用的程序调试与优化分析工具，这些工具在软件开发过程中发挥着重要的作用。调试工具如gdb和Valgrind帮助开发人员快速定位和解决程序中的错误和问题，保障了代码的质量和稳定性。而优化分析工具，如gprof、perf和Vtune，则专注于提升程序性能，帮助开发人员找到性能瓶颈并进行优化。\n通过合理使用这些工具，开发人员可以更高效地开发和维护代码，减少调试时间，提高软件性能，并且为用户提供更好的使用体验。在今后的软件开发过程中，了解和掌握这些工具将是提高开发技能和水平的重要一步。同时，不断了解新的调试与优化工具也是跟上技术发展的必要途径。\n参考资料 [1] gdb官方网站\n[2] valgrind官方网站\n[3] gprof官方文档\n[4] perf文档\n[5] Intel Vtune Profiler\n","date":"2023-08-02T01:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/1c86d46879544786889dcdbaa1cf158f1fb36107.jpg@1256w_1774h_!web-article-pic.jpg","permalink":"https://cuterwrite.top/p/debug-and-optimize/","title":"程序调试与优化分析工具"},{"content":" Table of Contents generated with DocToc\n高性能异步I/O框架：io_uring 一、 引言 1. Linux原生aio接口 2. io_uring接口 3. liburing库 二、io_uring的核心数据结构与原理 1. io_uring的核心数据结构 2. io_uring的三种工作模式： 3. io_uring的系统调用API 4. io_uring的高级特性 三、io_uring的使用示例 1. 在项目中引入liburing 2. 代码示例 3. 最佳实践 结论 参考文献 高性能异步I/O框架：io_uring 一、 引言 1. Linux原生aio接口 在Linux中，有很多方法可以进行基于文件的I/O。最早的和最基本的就是系统调用read(2)和write(2)。后来增加了允许传入偏移量的pread(2)和pwrite(2)，以及基于vector的preadv(2)和pwrite(2)。再后来，Linux提供了preadv2(2)和pwritev2(2)。它们进一步扩展了API以允许修饰符标志。抛开这些系统调用的不同点不谈，它们有一个共同的特点：都是同步接口。这意味着当数据准备好读（或写入）时，系统调用才会返回。对于某些场景，这远远不够，因此还需要异步接口。POSIX提供了aio_read(3)和aio_write(3)来满足这种需求，但是它们的实现通常性能不佳。Linux原生aio接口是Linux内核中提供的一种异步I/O接口，它使用io_submit(2)、io_getevents(2)等系统调用来提交和获取I/O请求，并使用struct iocb来描述每个I/O请求。它支持O_DIRECT（或非缓冲）访问的异步I/O，并且可以使用信号或回调函数来通知I/O完成事件。\n然而，Linux原生aio接口存在着许多的限制与不足之处：\n最大的限制是它只能支持O_DIRECT（或非缓冲）访问的异步I/O。由于O_DIRECT的限制（缓存绕过和大小/对齐限制），这使得原生aio接口在大多数情况下都无法使用。对于普遍的缓冲I/O，接口会以同步方式运行。 即使满足了I/O 异步的所有约束条件，有时也会出现阻塞。I/O 提交可能会通过多种方式导致阻塞： 如果执行 I/O 时需要元数据，提交就会阻塞，等待元数据。 对于存储设备，有固定数量的请求槽可用。如果这些插槽目前都在使用中，提交就会阻塞，等待有一个插槽可用。 I/O请求元数据开销大：每次I/O提交都需要复制64 + 8字节的数据，而每次完成则需要复制32字节的数据。这意味着对于所谓的零拷贝I/O来说，每次操作都需要复制104字节的内存。根据I/O的大小不同，这种内存复制的开销可能是明显可见的。而且，暴露的完成事件环缓冲区实际上会妨碍完成操作的速度，并且很难（甚至不可能）从应用程序中正确地使用。这可能意味着使用这个API进行I/O操作时，完成操作的效率会受到影响。此外，在Spectre/Meltdown漏洞修复后，I/O总是需要至少两个系统调用（提交+等待完成），这会导致严重的性能下降。这可能是因为在修复这些漏洞后，系统对于系统调用的处理变得更加复杂和缓慢。 IOPOLL支持不好。 随着时间的推移，尽管有一些努力试图解决这些限制，但没有成功。随着具备亚10微秒延迟和非常高IOPS的设备的出现，这个接口开始显现出其性能缺陷。对于这些类型的设备来说，慢速和非确定性的提交延迟是一个很大的问题，而且单个核心无法提供足够的性能。此外，由于前面提到的限制，可以说原生的Linux aio接口用途并不广泛。它被限制在应用程序的一小部分领域中，并且伴随着一些问题。\n2. io_uring接口 io_uring是Linux内核中的一种新的异步I/O接口，旨在提供高效和可扩展的I/O操作。它通过使用一对环形队列（提交队列和完成队列）作为应用程序和内核之间的通信通道，实现了零拷贝的I/O操作。\nio_uring的设计目标是在提供高性能的同时解决传统异步I/O接口的一些限制和问题。它避免了内存复制和内存方向性，通过共享数据结构和内存来优雅地实现应用程序和内核之间的协调。这种设计使得io_uring能够更高效地处理I/O请求，并且不需要频繁的系统调用来同步和通信。\n通过io_uring，应用程序可以作为生产者将I/O请求提交到提交队列，而内核作为消费者处理这些请求。一旦请求完成，内核会生成相应的完成事件，并将其放入完成队列中，应用程序可以从完成队列中消费这些事件。这种异步的方式使得应用程序能够更好地利用系统资源，提高I/O操作的效率和性能。\nio_uring的优势主要在于：\n使用方便：简单且强大的系统调用，提供三个系统调用，liburing用户态库编程友好 (io_uring_setup, io_uring_enter, io_uring_register)。 通用性强：提供内核统一的异步编程框架，既支持传统I/O (Buffer I/O + Direct I/O)，也支持类epoll型编程。 特性丰富：支持非常多的高级特性。 高性能：I/O请求overhead小。 3. liburing库 liburing是一个基于io_uring接口的用户空间库，它是Linux内核开发者Axboe于2019年发布的一个开源项目。io_uring是一种新的Linux异步I/O接口，它通过使用一对环形缓冲区（ring buffer）来实现用户空间和内核空间之间的通信，从而避免了传统异步I/O接口（如AIO）所需的系统调用、信号、回调等机制。这样，用户空间可以直接向内核提交I/O请求，并从内核获取I/O结果，而无需等待或切换上下文。这大大提高了异步I/O操作的效率和性能。\nliburing是对io_uring接口的封装和扩展，它提供了一套简洁和灵活的API，让开发者可以方便地使用io_uring的功能，而无需关心底层的细节和复杂性。liburing主要包括以下几个组件：\nliburing.h：定义了liburing库的主要数据结构和函数 liburing.a：提供了liburing库的静态链接版本 liburing.so：提供了liburing库的动态链接版本 liburing/io_uring.h：定义了io_uring接口相关的数据结构和常量 liburing/compat.h：提供了一些兼容性相关的宏定义 二、io_uring的核心数据结构与原理 1. io_uring的核心数据结构 每个io_uring实例都有两个环形队列(称为ring)，在内核和应用程序之间共享： 提交队列：submission queue( SQ ) 完成队列：completion queue( CQ ) 这两个队列： 都是单生产者、单消费者的队列，size为2的幂次方。 提供无锁接口，内部使用内存屏障来进行同步。 请求时： 应用创建SQ Entries (SQE)，更新SQ tail 内核消费SQE，更新SQ head 完成后： 内核为完成的一个或多个请求创建CQ Entries (CQE)，更新CQ tail 应用消费CQE，更新CQ head 完成事件可能以任意顺序到达，到总是与特定的SQE相关联的 消费CQE过程无需切换内核态 这样做的好处在于： 原本需要多次系统调用，现在变成批处理一次提交 此外，io_uring 使异步 I/O 的使用场景也不再仅限于数据库应用， 普通的非数据库应用也能用 2. io_uring的三种工作模式： 中断驱动模式 (interrupt-driven) 默认模式, 可通过io_uring_enter()提交I/O请求，然后直接检查CQ状态判断是否完成。 轮询模式 (polling) Busy waiting for I/O completion，而不是通过异步IRQ(Interrupt Request)来接收通知 这种模式需要文件系统和块设备支持轮询功能。相比中断驱动模式，这种方式延迟更低，但是CPU占用率可能会更高。 目前，只有指定了O_DIRECT标志打开的文件描述符才能使用这种模式。当一个读或写请求提交给轮询上下文之后，应用必须调用io_uring_enter()来轮询CQ队列，判断请求是否完成。 对于一个io_uring实例来说，不支持混合使用轮询和非轮询模式。 内核轮询模式 (kernel polling) 这种模式会创建一个内核线程来执行SQ的轮询工作。 使用这种模式的io_uring实例，应用无需切到内核态就能触发I/O操作。通过SQ来提交SQE，以及监控CQ的完成状态，应用无需任何系统调用，就能提交和收割I/O。 如果内核线程的空闲事件超过了用户的配置值，它会通知应用，然后进入idle状态。这种情况下，应用必须调用io_uring_enter()来唤醒内核线程。如果I/O一直很繁忙，内核线程是不会sleep的。 3. io_uring的系统调用API io_uring的系统调用API有三个，分别是：\nio_uring_setup(2) io_uring_register(2) io_uring_enter(2) 首先是io_uring_setup(2)：\nint io_uring_setup(unsigned entries, struct io_uring_params *p); 用于创建一个io_uring实例，返回一个文件描述符，用于后续的io_uring系统调用。 参数： entries：SQ和CQ的大小，必须是2的幂次方 params：io_uring的参数，包括flags、sq_thread_cpu等 返回值： 成功：返回一个文件描述符 失败：返回-1，并设置errno 创建一个SQ和一个CQ，它们的大小都是entries。如果entries是0，那么SQ和CQ的大小都是默认值(4096)。SQ和CQ在应用和内核之间共享，避免了在初始化和完成I/O时拷贝数据 io_uring_register(2)：\nint io_uring_register(int fd, unsigned int opcode, const void *arg, unsigned int nr_args); 注册用于异步I/O的文件或用户缓冲区，使内核能长时间持有对该文件在内核内部的数据结构引用，或创建应用内存的长期映射，这个操作只会在注册时执行一次，而不是每个I/O操作都会处理，因此减少了per-I/O的overhead开销。 参数： fd：文件描述符 opcode：操作码，用于指定注册的类型，如IORING_REGISTER_BUFFERS、IORING_REGISTER_FILES等 arg：指向一个数组，数组中的每个元素都是一个指向用户缓冲区或文件描述符的指针 nr_args：arg数组的大小 返回值： 成功：返回0 失败：返回-1，并设置errno 注册的缓冲区将会被锁定到内存中，并计入用户的RLIMIT_MEMLOCK限制。如果注册的是文件描述符，那么内核会增加对该文件的引用计数，直到应用调用io_uring_unregister(2)来注销它。 每个缓冲区有1GB的大小限制。 缓冲区必须是匿名的、非文件后端的内存，例如malloc(3)或带MAP_ANONYMOUS标识的mmap(2)返回的内存。 Huge pages也是支持的。整个Huge page都会被pin到内核，即使只使用其中一部分。 已经注册的缓冲区无法调整大小，想调整只能先unregister，再重新注册。 io_uring_enter(2):\nint io_uring_enter(unsigned int fd, unsigned int to_submit, unsigned int min_complete, unsigned int flags, sigset_t *sig); 这个系统调用用于初始化和完成（initiate and complete）I/O，使用共享的 SQ 和 CQ。单次调用同时执行： 提交新的I/O请求 等待I/O完成 参数： fd：io_uring实例的文件描述符 to_submit：SQ中提交的I/O请求数量 min_complete：最少完成的I/O请求数量 flags：用于指定I/O请求的类型，如IORING_ENTER_GETEVENTS、IORING_ENTER_SQ_WAKEUP等 sig：用于指定信号集，如果flags指定了IORING_ENTER_GETEVENTS，那么sig必须是一个有效的信号集 在默认模式下，如果指定了min_complete，那么io_uring_enter(2)会等待至少min_complete个I/O请求完成，然后返回。如果没有指定min_complete，那么io_uring_enter(2)会等待SQ中所有的I/O请求完成，然后返回。在polling模式下，如果指定了min_complete，如果min_complete为0，则要求内核返回当前以及完成的所有 events，无阻塞；如果min_complete大于0，如果有事件完成，内核仍然立即返回；如果没有完成事件，内核会 poll，等待指定的次数完成，或者这个进程的时间片用完。 4. io_uring的高级特性 io_uring还提供了一些用于特殊场景的高级特性 File registration(文件注册)：每次发起一个指定文件描述的操作，内核都需要花费一些时钟周期(cycles)文件描述符映射到内部表示。对于那些 针对同一文件进行重复操作 的场景，io_uring 支持提前注册这些文件，后面直接查找就行了。 Buffer registration(缓冲区注册)：与 file registration 类似，Direct I/O 场景中，内核需要 map/unmap memory areas。io_uring 支持提前注册这些缓冲区（buffers）。 Poll ring(轮询环形缓冲区)：对于非常快是设备，处理中断的开销是比较大的。io_uring 允许用户关闭中断，使用轮询模式。 Linked operations(链接操作)：允许用户发送串联的请求。这两个请求同时提交，但后面的会等前面的处理完才开始执行。 三、io_uring的使用示例 liburing提供了一个简单的高层 API， 可用于一些基本场景，应用程序避免了直接使用更底层的系统调用。此外，这个 API 还避免了一些重复操作的代码，如设置 io_uring 实例。\n1. 在项目中引入liburing apt-get安装liburing 在ubuntu系统下安装liburing十分简单，只需要执行以下命令即可 （注意：ubuntu版本需要大于等于20.04，因为内核版本需要大于等于5.4） sudo apt-get install liburing-dev 在项目中引入liburing的头文件 #include \u0026#34;liburing.h\u0026#34; 在项目中引入liburing的库文件 -luring 手动安装 下载liburing的源码 git clone https://github.com/axboe/liburing.git 编译liburing cd liburing ./configure make -j sudo make install 在项目中引入liburing的头文件 #include \u0026#34;liburing.h\u0026#34; 在项目中引入liburing的库文件 -luring 2. 代码示例 使用4个SQE，从输入文件中读取最多16KB的数据。 #include \u0026#34;liburing.h\u0026#34; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;sys/stat.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;errno.h\u0026gt; // io_uring 队列长度 #define QUEUE_DEPTH 4 int main(int argc, char** argv) { int fd, pending, done; void* buf; // 1. 初始化一个 io_uring 实例 struct io_uring ring; // 创建一个io_uring实例，队列长度为QUEUE_DEPTH，flags为0，使用默认模式 int ret = io_uring_queue_init(QUEUE_DEPTH, \u0026amp;ring, 0); if (ret) { fprintf(stderr, \u0026#34;io_uring_queue_init: %s\\n\u0026#34;, strerror(-ret)); return 1; } // 2. 打开输入文件，指定 O_DIRECT 标志 fd = open(argv[1], O_RDONLY | O_DIRECT); struct stat st; fstat(fd, \u0026amp;st); // 3. 初始化4个读缓冲区 size_t filesize = 0; struct iovec *iovecs = calloc(QUEUE_DEPTH, sizeof(struct iovec)); for (int i = 0; i \u0026lt; QUEUE_DEPTH; i++) { if (posix_memalign(\u0026amp;buf, 4096, 4096)) { perror(\u0026#34;posix_memalign\u0026#34;); return 1; } iovecs[i].iov_base = buf; iovecs[i].iov_len = 4096; filesize += 4096; } // 4. 依次准备4个读请求，指定将随后读入的数据写入 iovecs 中 struct io_uring_sqe *sqe; size_t offset = 0; int i = 0; do { sqe = io_uring_get_sqe(\u0026amp;ring); io_uring_prep_readv(sqe, fd, \u0026amp;iovecs[i], 1, offset); offset += iovecs[i].iov_len; i++; // 如果超出文件大小，停止准备后面的 SQE if (offset \u0026gt;= st.st_size) { break; } } while (1); // 5. 提交 SQE 读请求 ret = io_uring_submit(\u0026amp;ring); if (ret \u0026lt; 0) { fprintf(stderr, \u0026#34;io_uring_submit: %s\\n\u0026#34;, strerror(-ret)); return 1; } else if (ret != i) { fprintf(stderr, \u0026#34;io_uring_submit submitted less %d\\n\u0026#34;, ret); return 1; } // 6. 等待读请求完成 struct io_uring_cqe *cqe; done = 0; pending = ret; filesize = 0; for (int i = 0; i \u0026lt; pending; i++) { // 等待一个读完成事件 io_uring_wait_cqe(\u0026amp;ring, \u0026amp;cqe); done++; if (cqe-\u0026gt;res != 4096 \u0026amp;\u0026amp; cqe-\u0026gt;res + filesize != st.st_size) { fprintf(stderr, \u0026#34;cqe-\u0026gt;res: %d\\n\u0026#34;, cqe-\u0026gt;res); return 1; } filesize += cqe-\u0026gt;res; // 更新完成队列 io_uring_cqe_seen(\u0026amp;ring, cqe); } // 7. 打印统计信息 printf(\u0026#34;Submitted = %d, completed = %d, bytes = %lu\\n\u0026#34;, pending, done, (unsigned long)filesize); // 8. 销毁资源 close(fd); io_uring_queue_exit(\u0026amp;ring); return 0; } link-cp：使用io_uring高级特性 SQE chaining实现复制文件功能，将创建一个长度为2的 SQE 链，第一个 SQE 用于读，第二个 SQE 用于写。 #include \u0026lt;assert.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;inttypes.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;sys/ioctl.h\u0026gt; #include \u0026lt;sys/stat.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026#34;liburing.h\u0026#34; #define QD 64 #define BS (32 * 1024) struct io_data { size_t offset; int index; struct iovec iov; }; static int infd, outfd; static int inflight; static int setup_context(unsigned entries, struct io_uring *ring) { int ret; ret = io_uring_queue_init(entries, ring, 0); if (ret \u0026lt; 0) { fprintf(stderr, \u0026#34;queue_init: %s\\n\u0026#34;, strerror(-ret)); return -1; } return 0; } static int get_file_size(int fd, off_t *size) { struct stat st; if (fstat(fd, \u0026amp;st) \u0026lt; 0) return -1; if (S_ISREG(st.st_mode)) { *size = st.st_size; return 0; } else if (S_ISBLK(st.st_mode)) { unsigned long long bytes; if (ioctl(fd, BLKGETSIZE64, \u0026amp;bytes) != 0) return -1; *size = bytes; return 0; } return -1; } static void queue_rw_pair(struct io_uring *ring, off_t size, off_t offset) { struct io_uring_sqe *sqe; struct io_data *data; void *ptr; ptr = malloc(size + sizeof(*data)); data = ptr + size; data-\u0026gt;index = 0; data-\u0026gt;offset = offset; data-\u0026gt;iov.iov_base = ptr; data-\u0026gt;iov.iov_len = size; sqe = io_uring_get_sqe(ring); io_uring_prep_readv(sqe, infd, \u0026amp;data-\u0026gt;iov, 1, offset); sqe-\u0026gt;flags |= IOSQE_IO_LINK; io_uring_sqe_set_data(sqe, data); sqe = io_uring_get_sqe(ring); io_uring_prep_writev(sqe, outfd, \u0026amp;data-\u0026gt;iov, 1, offset); io_uring_sqe_set_data(sqe, data); } static int handle_cqe(struct io_uring *ring, struct io_uring_cqe *cqe) { struct io_data *data = io_uring_cqe_get_data(cqe); int ret = 0; data-\u0026gt;index++; if (cqe-\u0026gt;res \u0026lt; 0) { if (cqe-\u0026gt;res == -ECANCELED) { queue_rw_pair(ring, data-\u0026gt;iov.iov_len, data-\u0026gt;offset); inflight += 2; } else { printf(\u0026#34;cqe error: %s\\n\u0026#34;, strerror(-cqe-\u0026gt;res)); ret = 1; } } if (data-\u0026gt;index == 2) { void *ptr = (void *)data - data-\u0026gt;iov.iov_len; free(ptr); } io_uring_cqe_seen(ring, cqe); return ret; } static int copy_file(struct io_uring *ring, off_t insize) { struct io_uring_cqe *cqe; off_t this_size; off_t offset; offset = 0; while (insize) { int has_inflight = inflight; int depth; while (insize \u0026amp;\u0026amp; inflight \u0026lt; QD) { this_size = BS; if (this_size \u0026gt; insize) this_size = insize; queue_rw_pair(ring, this_size, offset); offset += this_size; insize -= this_size; inflight += 2; } if (has_inflight != inflight) io_uring_submit(ring); if (insize) depth = QD; else depth = 1; while (inflight \u0026gt;= depth) { int ret; ret = io_uring_wait_cqe(ring, \u0026amp;cqe); if (ret \u0026lt; 0) { printf(\u0026#34;wait cqe: %s\\n\u0026#34;, strerror(-ret)); return 1; } if (handle_cqe(ring, cqe)) return 1; inflight--; } } return 0; } int main(int argc, char *argv[]) { struct io_uring ring; off_t insize; int ret; if (argc \u0026lt; 3) { printf(\u0026#34;%s: infile outfile\\n\u0026#34;, argv[0]); return 1; } infd = open(argv[1], O_RDONLY); if (infd \u0026lt; 0) { perror(\u0026#34;open infile\u0026#34;); return 1; } outfd = open(argv[2], O_WRONLY | O_CREAT | O_TRUNC, 0644); if (outfd \u0026lt; 0) { perror(\u0026#34;open outfile\u0026#34;); return 1; } if (setup_context(QD, \u0026amp;ring)) return 1; if (get_file_size(infd, \u0026amp;insize)) return 1; ret = copy_file(\u0026amp;ring, insize); close(infd); close(outfd); io_uring_queue_exit(\u0026amp;ring); return ret; } copy_file()：高层复制循环逻辑；它会调用 queue_rw_pair(ring, this_size, offset) 来构造 SQE pair；并通过一次 io_uring_submit() 调用将所有构建的 SQE pair 提交。 这个函数维护了一个最大 DQ 数量的 inflight SQE，只要数据 copy 还在进行中；否则，即数据已经全部读取完成，就开始等待和收割所有的 CQE。 queue_rw_pair() 构造一个 read-write SQE pair. read SQE 的 IOSQE_IO_LINK flag 表示开始一个 chain，write SQE 不用设置这个 flag，标志着这个 chain 的结束。用户 data 字段设置为同一个 data 描述符，并且在随后的 completion 处理中会用到。 handle_cqe() 从 CQE 中提取之前由 queue_rw_pair() 保存的 data 描述符，并在描述符中记录处理进展（index）。 如果之前请求被取消，它还会重新提交 read-write pair。 一个 CQE pair 的两个 member 都处理完成之后（index==2），释放共享的 data descriptor。最后通知内核这个 CQE 已经被消费。 3. 最佳实践 io_uring是一个高性能的异步I/O框架，它在Linux内核中引入了一种新的I/O模型，可以显著提高I/O操作的吞吐量和响应速度。然而，要充分发挥io_uring的优势，需要注意一些优化和最佳实践。\n优化 说明 批量提交（Batch Submission） io_uring支持批量提交多个I/O请求，以减少系统调用的开销。通过一次性提交多个请求，可以减少上下文切换和系统调用的次数，提高效率。建议根据系统的负载和性能需求，合理选择批量提交的数量。 预分配I/O请求（Pre-allocate I/O Requests） 在使用io_uring之前，可以预先分配一定数量的I/O请求，避免在运行时动态分配请求的开销。这样可以减少内存分配和释放的次数，提高性能。 使用I/O链接（I/O Linking） io_uring支持将多个I/O请求链接在一起，形成一个链表。这样可以减少上下文切换的开销，提高效率。在链接I/O请求时，需要注意保持请求的顺序和正确处理链接的完成。 使用I/O向量（I/O Vector） io_uring支持使用I/O向量来进行批量的读写操作。通过使用I/O向量，可以减少系统调用的次数，提高效率。在使用I/O向量时，需要注意正确设置每个向量的偏移量和长度。 使用事件完成通知（Event Completion Notification） io_uring支持使用事件完成通知来提高效率。通过使用事件完成通知，可以避免轮询等待I/O完成，而是在I/O完成时立即得到通知。这样可以减少CPU的占用和响应时间。 合理设置I/O队列深度（I/O Queue Depth） io_uring的性能受到I/O队列深度的影响。较大的队列深度可以提高并发性能，但也会增加内存开销。建议根据系统的负载和性能需求，合理设置I/O队列深度。 使用合适的内存分配策略 io_uring的性能也受到内存分配策略的影响。建议使用高效的内存分配器，如jemalloc或tcmalloc，来减少内存分配和释放的开销。 避免阻塞操作 io_uring是一个异步I/O框架，应尽量避免在io_uring的上下文中进行阻塞操作。阻塞操作会导致io_uring的性能下降，甚至可能引起死锁。 使用合适的文件描述符（File Descriptor） io_uring支持对文件、套接字和管道等不同类型的文件描述符进行操作。在使用io_uring时，需要根据实际情况选择合适的文件描述符类型，并正确设置相关的参数。 注意错误处理 在使用io_uring时，需要注意正确处理错误。io_uring的错误码可能是负数，可以使用errno.h中定义的错误码来进行解析和处理。 通过遵循上述优化和最佳实践，可以充分发挥io_uring的性能优势，提高系统的I/O性能和响应速度。然而，需要根据具体的应用场景和需求，进行合理的调优和配置。在实际使用中，可以通过性能测试和监测来评估和优化io_uring的性能。\n结论 io_uring是一个高性能的异步I/O框架，通过在Linux内核中引入新的I/O模型，它能够显著提高I/O操作的吞吐量和响应速度。本章节我们深入探讨了io_uring的优化和最佳实践，以帮助开发者充分发挥其性能优势。\n在使用io_uring时，我们可以采取一系列优化措施来提高性能。首先，批量提交多个I/O请求可以减少系统调用的开销，提高效率。此外，预分配I/O请求、使用I/O链接和I/O向量等技术也能够减少内存分配和系统调用的次数，进一步提升性能。\n除了以上的优化技巧，我们还介绍了一些最佳实践。合理设置I/O队列深度、使用事件完成通知和选择合适的文件描述符类型等都能够对性能产生积极影响。此外，避免阻塞操作和正确处理错误也是使用io_uring时需要注意的事项。\n通过遵循这些优化和最佳实践，开发者可以充分发挥io_uring的性能优势，提高系统的I/O性能和响应速度。然而，需要根据具体的应用场景和需求，进行合理的调优和配置。在实际使用中，可以通过性能测试和监测来评估和优化io_uring的性能。\nio_uring作为一个新兴的异步I/O框架，具有很大的潜力和广阔的应用前景。它已经在许多领域得到了广泛的应用，如数据库、网络服务器和存储系统等。随着对io_uring的进一步研究和优化，相信它将在未来发挥更大的作用，并成为开发者们的首选工具之一。\n参考文献 [1] io_uring官方文档：https://kernel.dk/io_uring.pdf\n[2] How io_uring and eBPF Will Revolutionize Programming in Linux[1], ScyllaDB\n[3] 2020 An Introduction to the io_uring Asynchronous I/O Framework[2], Oracle, 2020\n[4] liburing GitHub仓库：https://github.com/axboe/liburing\n","date":"2023-08-01T01:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/20230801145236.png","permalink":"https://cuterwrite.top/p/efficient-liburing/","title":"高性能异步I/O框架：io_uring"},{"content":" Table of Contents generated with DocToc\nRDMA技术及其编程方法（二）：编程指导 一、libibverbs简介 二、Verbs API详解 1. 简介 2. Verbs对象创建层次 3. 两个动态库 三、Connection Manager 1. 连接的建立 2. CM的抽象类型（RDMACM） 四、 RDMACM程序解析——被动方 1. 创建事件channel 2. 创建连接ID 3. 绑定地址 4. 创建Listener，返回端口/地址 5. 等待连接请求 6. 创建PD、CQ和Send-Receive QP 7. 最后的操作 五、 RDMACM程序解析——主动方 1. 创建事件channel 2. 创建连接ID 3. 绑定地址 4. 创建QP 5. 解析路由 6. 建立连接 7. 最后的操作 六、实战：基于RDMA的client-server程序 1. server端 2. client端 3. 项目实现 参考文献 RDMA技术及其编程方法（二）：编程指导 一、libibverbs简介 libibverbs由Roland Dreier自2006年开始开发和维护，实际上是*nix中的Verbs API标准 开源 Verbs的核心部分自2005年起集成到Linux内核中\u0026ndash;内核2.6.11 Inbox in several *nix distributions 目前有多个硬件供应商提供的级别较低的库 对所有启用RDMA的传输协议使用相同的API InfiniBand： 支持RDMA的网络体系结构 需要支持它的网卡和InfiniBand交换机。 RoCE：基于以太网/IP帧的RDMA数据包封装 需要支持它的网卡和标准以太网交换机 iWARP：提供基于流控制传输协议(SCTP)和传输控制协议(TCP)的RDMA 需要支持它的网卡和标准以太网交换机 libibverbs是完全线程安全的 libibverbs本身是线程安全的 用户态空间低级驱动程序库也是线程安全的 应用程序可以在多线程中使用RDMA资源 销毁一个线程中的资源并在另一个线程中使用它将导致segmentation fault，这个问题在非多线程代码中也会发生\n使用libibverbs的基本须知 tips 说明 头文件引入 #include\u0026lt;infiniband/verbs.h\u0026gt; 编译时链接 -libverbs 所有的input structures需要为zeroed 使用memset()或结构初始化、如果该structure有扩充的需求，则零值将保留遗留行为 大多数资源句柄都是指针，因此使用错误的句柄可能会导致分段错误 使用NULL检查句柄 返回指针的Verbs成功时返回有效值，失败时返回NULL 检查返回值 返回整形变量的Verbs如果成功则返回零，如果成功则返回-1或errno 检查返回值 二、Verbs API详解 1. 简介 在内核和用户态空间均可使用 Verbs中的类 资源管理：Qps、CQs、SRQs等等 WR处理：post send, 轮询CQ等等 内存注册 地址句柄 Verbs中的操作 Device操作 上下文操作 PD操作 QP bringup 活跃QP操作 2. Verbs对象创建层次 获取devide列表 打开请求的device 查询device功能 分配PD内存空间 注册内存域MR 关联并创建完成队列CQ 创建QP Bring up a QP Post WR并且轮询CQ 清理资源 3. 两个动态库 libibverbs.so 用于直接通过用户态空间访问InfiniBand硬件的库 Infiniband(根据Infiniband规范)和iWarp(iWARP动词规范)的RDMA Verbs的实现 它处理创建、修改、查询和销毁资源的控制路径，如保护域(PD)、完成队列(CQ)、队列对(QP)、共享接收队列(SRQ)、地址句柄(AH)、内存区域(MR) 它还处理发送和接收发布到QPS和SRQ的数据，使用轮询和完成事件从CQs获取完成 librdmacm.so 用户态空间的RDMA连接管理器 使用Socket语义的RDMA(InfiniBand、ROCE和iWARP)通信管理库 三、Connection Manager 1. 连接的建立 基于Infiniband通信管理(CM)协议（在通用服务接口(GSI)上定义的协议QP：QP1）\n提供以下服务\n在对等RC和QP之间交换必要的参数，使它们为通信做好准备 初始化器请求连接到远程上的服务ID（服务ID映射） 类TCP握手：请求/响应/即用消息 查找给定服务ID的远程UD和QP序号 服务ID请求/响应消息 加载备用路径 连接管理器（Connection Manager，CM）是一个用户态空间的库，它提供了一个通用的接口，用于在RDMA网络中建立连接。它可以用于建立连接，也可以用于查找远程QP的地址，以便在不建立连接的情况下发送数据。\n需要在对等QP之间交换信息 负责RC、UC、RD连接的建立 应用程序使用SA来获取其他信息(例如路径记录) SIDR用于UD 2. CM的抽象类型（RDMACM） 类似于Socket连接模式的语义 对IB和ROCE都使用基于IP的寻址模式 类 说明 rdma_create/destroy_id creates/destroys a connection identifier (equivalent to a socket) rdma_create/destroy_qp allocate/destroy a qp for communication rdma_bind_addr set local port to listen on rdma_resolve_addr obtain local RDMA device to reach remote address rdma_resolve_route determine route to remote address rdma_get_src_port query local port rdma_get_local_addr query local ip rdma_get_peer_addr query remote ip rdma_connect/disconnect connect/disconnect rc qps, or resolve service id to qp for ud qps rdma_listen listen for incoming connections rdma_accept/reject accept/reject incoming connection requests rdma_create/destroy_event_channel allocate/destroy an event channel rdma_get_cm_event get next event rdma_ack_cm_event acknowledge event(s) to rdmacm rdma_join/leave_multicast join/leave multicast addresses 使用rdmacm的基本须知 tips 说明 头文件引入 #include\u0026lt;rdma/rdma_cma.h\u0026gt; 编译时链接 -lrdmacm 四、 RDMACM程序解析——被动方 流程如下：\n创建事件channel，以便我们可以接收rdmacm事件，如连接请求和连接建立通知。 创建连接ID并绑定到地址。 创建Listener并返回端口/地址。 等待连接请求 创建PD、CQ和Send-Receive QP 接受连接请求 等待建立连接 视情况发布操作 1. 创建事件channel 打开用于报告通信事件的channel。异步事件将通过事件channel报告给用户，对应方法为struct rdma_event_channel * rdma_create_event_channel(void)。 事件channel用于定向rdma_cm_id上的所有事件。对于许多客户端来说，单个事件channel可能就足够了，然而，当管理大量的连接或cm_id时，用户可能会发现将不同cm_id的事件定向到不同的channel进行处理是有用的。 必须通过调用rdma_destroy_event_channel销毁所有创建的事件channel。用户应该调用rdma_get_cm_event来检索事件channel上的事件。 struct rdma_event_channel *channel = rdma_create_event_channel(); if (!channel) { perror(\u0026#34;rdma_create_event_channel\u0026#34;); return -1; } struct rdma_cm_event* event; // 此处会阻塞，直到有事件发生 int err = rdma_get_cm_event(channel, \u0026amp;event); if (err) { perror(\u0026#34;rdma_get_cm_event\u0026#34;); return err; } // 中间处理代码... rdma_destroy_event_channel(channel); 每个事件channel都映射到一个文件描述符。可以像使用和操作任何其他FD一样使用和操作关联的文件描述符，以更改其行为。 2. 创建连接ID 创建用于跟踪通信信息的标识符，对应方法为int rdma_create_id(struct rdma_event_channel *channel, struct rdma_cm_id **id, void *context, enum rdma_port_space ps)。 输入参数： channel：事件channel id：指向rdma_cm_id指针的指针，用于返回新创建的rdma_cm_id context：用户上下文，将在事件中返回给用户 ps：RDMA端口空间，指定要使用的端口空间 rdma_cm_id在概念上等同于用于RDMA通信的套接字。不同之处在于，RDMA通信需要显式绑定到指定的RDMA设备，然后才能进行通信，并且大多数操作本质上是异步的。 端口空间 RDMA_PS_TCP：提供可靠、面向连接的QP通信。与TCP不同，RDMA端口空间提供基于消息的通信，而不是基于流的通信。 RDMA_PS_UDP：提供不可靠、无连接的QP通信。支持数据报和组播通信。 销毁：在调用此函数并确认相关事件之前，用户必须释放任何与rdma_cm_id相关的QP。 struct rdma_cm_id *listen_id; int err = rdma_create_id(channel, \u0026amp;listen_id, NULL, RDMA_PS_TCP); if (err) { perror(\u0026#34;rdma_create_id\u0026#34;); return err; } // 中间处理代码... rdma_destroy_id(listen_id); 3. 绑定地址 将源地址与rdma_cm_id相关联。对应方法为int rdma_bind_addr(struct rdma_cm_id *id, struct sockaddr *addr)。 地址中可以包含通配符。 如果绑定到特定本地地址，则rdma_cm_id也将绑定到本地RDMA设备。 通常，在调用rdma_listen以绑定到特定端口号之前调用此函数，但也可以在调用rdma_resolve_addr以绑定到特定地址之前在主动方调用该函数。 如果用于绑定到端口0，rdma_cm将选择一个可用端口，可以使用rdma_get_src_port检索该端口。 /* sockaddr_in是IPV4的地址结构体 * AF_INET：IPV4 * htons：将主机字节序转换为网络字节序（小端存储）, 20079是端口号 * INADDR_ANY：表示任意地址 */ struct sockaddr_in addr = { .sin_family = AF_INET, .sin_port = htons(20079), .sin_addr = { .s_addr = INADDR_ANY }, }; err = rdma_bind_addr(listen_id, (struct sockaddr *)\u0026amp;addr); if (err) { perror(\u0026#34;rdma_bind_addr\u0026#34;); return err; } 4. 创建Listener，返回端口/地址 初始化传入连接请求或数据报服务查找的Listener。对应方法为int rdma_listen(struct rdma_cm_id *id, int backlog)。 侦听将被限制为本地绑定源地址 在调用此函数之前，用户必须已通过调用rdma_bind_addr将rdma_cm_id绑定到本地地址。 如果rdma_cm_id绑定到特定的IP地址，则侦听将仅限于该地址和关联的RDMA设备。 如果rdma_cm_id仅绑定到RDMA端口号，则将在所有RDMA设备上进行侦听。 返回已绑定到本地地址的rdma_cm_id的本地端口号。对应方法为uint16_t rdma_get_src_port(struct rdma_cm_id *id)。 返回已绑定到本地设备的rdma_cm_id的本地IP地址。对应方法为struct sockaddr * rdma_get_local_addr(struct rdma_cm_id *id)。 解析目的节点和服务地址，并返回建立通信所需的信息。提供与getaddrinfo等效的RDMA功能(配合rdma_create_ep使用)。对应方法为int rdma_getaddrinfo (char *node, char *service, struct rdma_addrinfo *hints, struct rdma_addrinfo **res)。 node: 可选，目的节点的主机名，或者点分十进制的IPv4/IPv6十六进制地址 service：地址的服务名称或端口号。 hints：一个包含有关调用方支持的服务类型的提示的rdma_addrinfo结构的引用。 res：指向包含响应信息的rdma_addrinfo结构的LinkedList的指针。 // 等待连接请求的最大数量 int backlog = 10; err = rdma_listen(listen_id, backlog); if (err) { perror(\u0026#34;rdma_listen\u0026#34;); return err; } uint16_t port = rdma_get_src_port(listen_id); port = ntohs(port); printf(\u0026#34;listening on port %u.\\n\u0026#34;, port); struct sockaddr *local_addr = rdma_get_local_addr(listen_id); if (local_addr-\u0026gt;sa_family == AF_INET) { struct sockaddr_in *sin = (struct sockaddr_in *)local_addr; char ip[INET_ADDRSTRLEN]; // 需要加上头文件 #include \u0026lt;arpa/inet.h\u0026gt; inet_ntop(AF_INET, \u0026amp;(sin-\u0026gt;sin_addr), ip, INET_ADDRSTRLEN); printf(\u0026#34;Local IP address is: %s\\n\u0026#34;, ip); printf(\u0026#34;Local port is: %d\\n\u0026#34;, ntohs(sin-\u0026gt;sin_port)); } struct rdma_addrinfo hints; memset(\u0026amp;hints, 0, sizeof(hints)); hints.ai_flags = RAI_PASSIVE; hints.ai_port_space = RDMA_PS_TCP; struct rdma_addrinfo *res; err = rdma_getaddrinfo(NULL, \u0026#34;20079\u0026#34;, \u0026amp;hints, \u0026amp;res); if (err) { perror(\u0026#34;rdma_getaddrinfo\u0026#34;); return err; } // do something with struct rdma_addrinfo *cur = res... 5. 等待连接请求 检索通信事件。如果没有挂起的事件，默认情况下，调用将阻塞，直到接收到事件。对应方法为int rdma_get_cm_event(struct rdma_event_channel *channel, struct rdma_cm_event **event)。 通过修改与给定通道相关联的文件描述符，可以更改此函数的默认同步行为。 所有报告的事件都必须通过调用rdma_ack_cm_event进行确认。 rdma_cm_id 的销毁将被阻塞，直到相关事件被确认。 struct rdma_cm_event* event; // 此处会阻塞，直到有事件发生 err = rdma_get_cm_event(channel, \u0026amp;event); 6. 创建PD、CQ和Send-Receive QP 分配与指定的rdma_cm_id相关联的QP，并将其转换为用于发送和接收。对应方法为int rdma_create_qp(struct rdma_cm_id *id, struct ibv_pd *pd, struct ibv_qp_init_attr *qp_init_attr)。 在调用此函数之前，rdma_cm_id必须绑定到本地RDMA设备，且保护域PD必须用于同一设备。 被分配给rdma_cm_id的QP会由 librdmacm 自动转换状态. 分配完毕后，QP 将准备就绪，处理接收信息的发布。如果 QP 未连接，它将准备好发布发送。 pd = ibv_alloc_pd(cm_client_id-\u0026gt;verbs); if (!pd) { perror(\u0026#34;Failed to allocate a protection domain\u0026#34;); return -1; } io_completion_channel = ibv_create_comp_channel(cm_client_id-\u0026gt;verbs); if (!io_completion_channel) { perror(\u0026#34;Failed to create an I/O completion event channel\u0026#34;); return -1; } cq = ibv_create_cq(cm_client_id-\u0026gt;verbs, 10, NULL, io_completion_channel, 0); if (!cq) { perror(\u0026#34;Failed to create a completion queue\u0026#34;); return -1; } ret = ibv_req_notify_cq(cq, 0); if (ret) { perror(\u0026#34;Failed to request notifications\u0026#34;); return -1; } bzero(\u0026amp;qp_init_attr, sizeof(qp_init_attr)); qp_init_attr.qp_type = IBV_QPT_RC; qp_init_attr.cap.max_send_wr = 10; qp_init_attr.cap.max_recv_wr = 10; qp_init_attr.cap.max_send_sge = 1; qp_init_attr.cap.max_recv_sge = 1; qp_init_attr.send_cq = cq; qp_init_attr.recv_cq = cq; ret = rdma_create_qp(cm_client_id, pd, \u0026amp;qp_init_attr); if (ret) { perror(\u0026#34;Failed to create QP\u0026#34;); return -1; } client_qp = cm_client_id-\u0026gt;qp; 7. 最后的操作 Accept请求连接 等待连接建立 发布操作 五、 RDMACM程序解析——主动方 1. 创建事件channel 与被动方相同 2. 创建连接ID 与被动方相同 3. 绑定地址 将目的地址和可选源地址从IP地址解析为RDMA地址。如果成功，则指定的rdma_cm_id将绑定到本地设备。对应方法为int rdma_resolve_addr (struct rdma_cm_id *id, struct sockaddr *src_addr, struct sockaddr *dst_addr, int timeout_ms)。 此方法用于将给定的目标IP地址映射到可用的RDMA地址。 IP到RDMA地址的映射使用本地路由表或通过ARP完成。 如果给定源地址，则将rdma_cm_id绑定到该地址，就像调用rdma_ind_addr一样。 如果没有给出源地址，并且rdma_cm_id尚未绑定到设备，则rdma_cm_id将根据本地路由表绑定到源地址。 在此方法调用之后，rdma_cm_id将绑定到RDMA设备。 该方法调用通常在调用 rdma_resolve_route 和 rdma_connect 之前在主动方上进行。 InfiniBand特定\n此方法还会将目标IP地址和源IP地址(如果给定)映射到GID。 为了执行映射，IPoIB必须同时在本地和远程节点上运行。 4. 创建QP 与被动方相同 5. 解析路由 解析指向目标地址的 RDMA 路由，以建立连接。目标地址必须已通过调用 rdma_resolve_addr 解析。对应方法为int rdma_resolve_route (struct rdma_cm_id *id, int timeout_ms); 6. 建立连接 对应方法为int rdma_connect (struct rdma_cm_id *id, struct rdma_conn_param *conn_param);\nid：指向rdma_cm_id的指针 conn_param：指向rdma_conn_param结构的指针，包含连接参数 对于 RDMA_PS_TCP 类型的 rdma_cm_id，该调用会向远程目的地发起连接请求\n对于 RDMA_PS_UDP 类型的 rdma_cm_id，它会启动对提供数据报服务的远程 QP 的查询\n7. 最后的操作 等待连接建立 发布操作 六、实战：基于RDMA的client-server程序 1. server端 工作流程： 初始化RDMA资源 等待client连接 分配并固定服务器缓冲区buffer 接受客户端连接 将有关本地服务器缓冲区的信息发送到客户端 等待断开连接 2. client端 工作流程： 初始化RDMA资源 连接server 通过发送/接收exchange接收服务器端缓冲区信息 从（第一个）本地缓冲区向服务器缓冲区进行 RDMA 写入。 进行 RDMA 读取，将服务器缓冲区的内容读入第二个本地缓冲区。 比较第一缓冲区和第二缓冲区的内容，并进行匹配 断开连接 3. 项目实现 RDMA-examples\rRDMA-examples: A repository of practical code examples showcasing the fundamental concepts and usage of RDMA (Remote Direct Memory Access) technology. C\r4. 补充：RDMA应用程序标准流程 参考文献 Mellanox Technologies, Inc. (2017). RDMA Aware Networks Programming User Manual. Mellanox Technologies, Inc. ","date":"2023-07-27T01:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/20230725145210.png","permalink":"https://cuterwrite.top/p/rdma-tutorial/2/","title":"RDMA技术及其编程方法（二）：编程指导"},{"content":" Table of Contents generated with DocToc\nRDMA技术及其编程方法（一）：RDMA技术 一、 RDMA技术简介 二、 RDMA工作原理 1. Infiband与以太网的对比 2. RDMA中的重要概念 3. QPs/WRs执行模型 4. 通信语义 5. 传输服务 6. RDMA架构层级结构 三、Verbs与OFA Verbs API 1. Verbs简介 2. OFA Verbs API支持应用 四、总结 参考文献 RDMA技术及其编程方法（一）：RDMA技术 一、 RDMA技术简介 RDMA: Remote Direct Memory Access RDMA就是一种远程直接内存访问技术，它可以让远程主机直接访问本地内存，而不需要经过CPU的参与，从而大大减少了CPU的开销，提高了数据传输的效率。 术语 含义 Remote 数据在同一网络中的节点之间传输 Direct （1）传输过程没有操作系统内核的参与 （2）所有关于传输的协议都负载在网卡上 Memory （1）在用户态的应用程序的虚拟内存之间传输（2）没有额外的内存拷贝或缓存 Access send、receive、read、write、原子操作 RDMA的各种协议 InfiniBand - (41.8% of top 500 supercomputers) InfiniBand是一个工业标准的分组交换网络 在高性能计算机系统中越来越多地被采用 用户层网络，可绕过操作系统内核 SDR 4x - 8 Gbps DDR 4x - 16 Gbps QDR 4x - 32 Gbps FDQ 4x - 54 Gbps RoCE - RDMA over Converged Ethernet 允许在以太网络上执行RDMA的网络协议 RoCE v1 - 10 Gbps RoCE v2 - 25 Gbps iWarp - internet Wide Area RDMA Protocol 运行在TCP/IP协议栈上的RDMA协议 10 Gbps RDMA的支持嵌入在内核之中：Kernel中的drivers/infiniband RDMA协议优势 Zero-copy：零拷贝，能够读写远程内存，能够直接访问远程缓冲区，无需在不同软件层之间复制数据 Kernel bypass：跳过内核，可在相同的代码上下文（即用户空间或内核）中收发数据，节省了上下文切换时间 No CPU involvement：无CPU参与，可使用专用硬件收发数据，而不需要CPU干预。可降低远程端的CPU使用率，因为不需要它执行任何主动操作 Message based transactions：基于消息的事务，可在不同的连接上同时执行多个事务，而无需等待任何事务完成 Scatter/gather entries support：支持分散/聚集条目，可在单个操作中传输多个缓冲区，而无需将它们合并到单个缓冲区中 二、 RDMA工作原理 1. Infiband与以太网的对比 Feature/Network Type InfiniBand Ethernet Addressing lids, gid macs, IP addresses Path resolution Path queries ARP Lossless network Credit-based flow control Pause frames/PFC QoS SLs/VLs Priorities/TC Virtual networks Pkeys VLANs 可以看到，InfiniBand与以太网的区别首先在于网络地址的表示方式不同，以太网使用mac地址和IP地址，而InfiniBand使用lid和gid 其次，网络的路径解析方式不同，以太网使用ARP地址解析协议，而InfiniBand使用path queries； 然后，在网络的可靠性方面，以太网使用Pause frames/PFC（Priority-based Flow Control，基于优先级的流量控制），而InfiniBand使用的是Credit-based flow control(基于信用的流量控制) 接着在网络的服务质量方面，以太网使用Priorities/TC（Traffic Class，流量类别），而InfiniBand使用SLs/VLs（Service Level，服务等级） 最后，在网络的虚拟化方面，以太网使用VLANs（Virtual Local Area Network，虚拟局域网），而InfiniBand使用Pkeys（Partition Keys，分区键）。 2. RDMA中的重要概念 缩写 全称 说明 PD Protection Domain 保护域，是RDMA中的一种资源管理机制。PD定义了一组内存区域和访问权限，用于控制RDMA操作的安全性。PD与QP、MR均有关联。 MR Memory Region 内存区域，是RDMA中的一种抽象，用于描述应用程序中的内存区域。MR定义了一块内存区域的起始地址、大小和访问权限，并与PD关联。包含R_Key和L_Key。MR的配套机制用来解决RDMA操作中的两个问题：（1）APP提供的地址都是虚拟地址，经过MMU的转换才能得到真实的物理地址，RDMA网卡是如何得到真实物理地址从而去内存中读取或写入数据的？（2）假设网卡有能力获取目的地址，但如果用户恶意指定了一个非法的虚拟地址，网卡就有可能被指使去读写系统关键内存，如何预防？因此，MR的作用之一就是实现虚拟地址与物理地址的转换，APP只能看到虚拟地址，而且会在发起RDMA Write时把本地和对端的内存的虚拟地址传递给RDMA网卡。网卡需要知道APP提供的虚拟地址所对应的物理地址才能访问系统内存。在注册MR的过程中，软件会在内存中创建并填写一个虚拟地址到物理地址的映射表供网卡查询。MR的第二个作用是控制HCA访问内存的权限，程序在注册MR时会产生两把钥匙L_KEY（Local）和R_KEY（Remote）。 QP Queue Pair 队列对，是RDMA中的一种通信机制。QR由发送队列（Send Queue, SQ）和接收队列（Receive Queue, RQ）组成，用于发送和接收RDMA操作的请求和数据。SQ专门用来存放发送任务，RQ专门用来存放接收任务。在一次SEND-RECV流程中，发送端需要把表示一次发送任务的WR放到SQ里面(这种操作称为Post Send)，接收端需要把表示一次接收任务的WR放到QP里面（称为Post Receive），这样硬件才知道收到数据之后放到内存中的哪个位置。在RDMA中，通信的基本对象是QP，而不是节点。对于每个节点来说，每个进程都可以申请和使用若干个QP，而每个本地QP可以连接到一个远端的QP。每个节点中的QP都有一个唯一的编号，称为QPN，通过QPN可以唯一确定一个节点上的QP。 CQ Completion Queue 完成队列，用于存储RDMA操作的完成事件。当RDMA操作完成时，相关的完成事件会被放入CQ中，应用程序可以通过轮询或事件通知方式获取这些完成事件。CQ与QP相关联。CQ中有很多元素，称为CQE。CQE是硬件完成任务之后返回给软件的“完成报告”，与WR相反。每个CQE都包含某个WR的完成信息。 WR Work Request 工作请求，用于描述RDMA操作的请求。WR包含了操作类型、源地址、目的地址等信息，应用程序通过将WR放入QP的发送队列来触发RDMA操作。 SGE Scatter/Gather Element 即将读或写的内存地址。必须提供L_Key或R_Key来认证MR的连接 WC Work Completion 工作完成，用于描述RDMA操作的完成事件。WC包含了操作类型、状态、传输长度等信息，应用程序可以通过读取CQ中的WC来获取RDMA操作的结果。 3. QPs/WRs执行模型 硬件提供 针对每个QP上下文 虚拟到物理内存的转换 安全的进程控制机制 可靠性(取决于传输服务) 操作系统管理资源创建 但不发布WR和轮询CQ 结果 应用程序以安全的方式直接访问硬件 软件处理缓冲区而不是信息包 在快速路径中不需要操作系统干预。 完全异步的过程 4. 通信语义 Channel（消息传递） 请求者提供源缓冲区 接收者提供目的缓冲区 Remote Direct Memory Access（RDMA） 请求者同时提供源缓冲区和目标缓冲区 同时支持RDMA读取和写入 5. 传输服务 分类：Connected（连接）与Datagram（数据报）\n分类：Reliable（可靠）与Unreliable（不可靠）\n两两组合形成四种类型的传输：\nReliable Connected（RC），例如TCP Unreliable Datagram（UD），例如UDP UC也可以实现 RD不支持，虽然它是由规范定义的，但在API/DIVER/硬件中不支持 QP的传输类型：\n可靠连接RC QP仅与一个远程QP关联 由一个QP的发送队列发送的消息被可靠地递送到另一个QP的接收队列。 数据包按顺序发送 发送端，每条消息都被划分为长度为路径MTU的数据包，接收方将数据包重组为消息。支持发送、RDMA write/read 不可靠连接RC QP仅与一个远程QP关联 连接是不可靠的，即发送的数据包可能会丢失 消息出错时不会重传，错误处理必须由更高级别的协议提供。 支持发送、RDMA write 不可靠数据报UD 队列对可以向/从任何其他多个QP发送和接收单数据包消息。 不能保证有序和数据包到达，并且发送的数据包可能会被接收方丢弃。 支持广播消息(一对多) 只支持发送操作 RDMA支持的传输操作\nSend（立即） 发送方需要加上时间戳 接收方也需要在某些地方加上该时间戳用来标识该消息 RDMA Write（立即） RDMA Read（异步） Atomic operations（原子操作） 发送方发送读/写请求，并指定其将访问读写的本地和远程地址 Send操作流程：\n接收方需要发送接收请求（Receive Request, RR）给发送方 发送方发送Send操作请求（Send Request, SR）给接收方 只在可靠连接中发送ACK 接收方轮询CQ，获取SR的完成事件 发送方轮询CQ，获取RR的完成事件 RDMA Write操作流程： 请求方发送Send操作请求（Send Request, SR）加上远程地址与key给接收方 只在可靠连接中发送ACK 请求方轮询CQ，获取SR的完成事件 RDMA Write操作是一端应用主动写入远端内存的行为，除了准备阶段，远端CPU不需要参与，也不感知何时有数据写入、数据在何时接收完毕，所以这是一种单端操作。 需要注意的是，操作发起端的应用程序是通过虚拟地址来读写远端内存的，上层应用可以非常方便的对其进行操作。实际的虚拟地址——物理地址的转换由RDMA网卡完成。 RDMA Read与Atomic操作流程： 请求方发送Send操作请求（Send Request, SR）加上远程地址与key给接收方 只在可靠连接中发送ACK 请求方轮询CQ，获取SR的完成事件 小结：UD、UC、RC三种QP传输方式对比，w/o-\u0026gt;with/without 操作原语 UD UC RC Send(w/o immediate) 支持 支持 支持 RDMA Write(w/o immediate) 不支持 支持 支持 RDMA Read 不支持 不支持 支持 Atomic operations 不支持 不支持 支持 连接类型 数据报（一对多） 连接（一对一） 连接（一对一） 最大消息大小 最大路径MTU 2GB 2GB 广播 支持 不支持 不支持 6. RDMA架构层级结构 三、Verbs与OFA Verbs API 1. Verbs简介 Verbs是对为使用RDMA的应用程序提供的功能的抽象描述 Verbs不是API Verbs有多种实现 Verbs可以被分为两大类 控制：管理资源，通常需要切换上下文。 创建/销毁/修改/查询/处理事件 数据：使用资源发送/接收数据，不需要切换上下文。 发送Send/发送Receive/轮询CQ/请求完成事件 Verbs是对RDMA编程的底层描述。 Verbs旨在提供延迟、带宽、消息速率等方面的最佳性能。它可以被视作许多应用构建的基石。 Sockets 存储 并行计算 InfiniBand规范以Verbs接口形式编写 所需行为的语义描述 没有语法或操作系统特定的详细信息 可以自由定义实现 函数、结构、类型等的语法。 OpenFabrics Alliance (OFA) Verbs API 一种Verbs接口，由OpenFabrics Alliance（OFA）组织定义和推广。OFA Verbs是基于RDMA Verbs的扩展，提供了更加统一和标准化的RDMA编程接口。OFA Verbs是RDMA领域的一个重要标准，被广泛应用于高性能计算、数据中心和云计算等领域。 旨在提供一个开放、跨平台的RDMA编程接口，使应用程序能够在不同的RDMA硬件和操作系统上进行移植和开发 OFA统一InfiniBand市场的战略 OFA面向Linux、FreeBSD、Windows等操作系统实现 应用程序的软件接口：支持C/C++程序的数据结构、函数原型 用户态空间和内核态空间的变体：大多数应用程序和库都在用户态空间中 客户端-服务器编程模型 与TCP/IP套接字有一些明显的相似之处 而许多的其它不同之处，则是由于RDMA与TCP/IP的不同导致 2. OFA Verbs API支持应用 MPI： Message Passing Interface，支持多种版本 OpenMPI MVAPICH Intel MPI 文件系统： Lustre NFS_RDMA DDN和NetApp公司生产的存储设备 SRP：SCSI RDMA (Remote) Protocol – Linux kernel iSER – iSCSI Extensions for RDMA – Linux kernel 伪Socket库 SDP – Sockets Direct Protocol – supported by Oracle rsockets – RDMA Sockets – supported by Intel mva – Mellanox Messaging Accelerator SMC-R – proposed by IBM 四、总结 RDMA技术是一种远程直接内存访问技术，它可以让远程主机直接访问本地内存，而不需要经过CPU的参与，从而大大减少了CPU的开销，提高了数据传输的效率。 RDMA技术的各种协议：InfiniBand、RoCE、iWarp RDMA技术的优势：Zero-copy、Kernel bypass、No CPU involvement、Message based transactions、Scatter/gather entries support RDMA技术的传输服务：Connected（连接）与Datagram（数据报）、Reliable（可靠）与Unreliable（不可靠） RDMA技术的QP传输类型：RC、UC、UD RDMA技术的操作原语：Send、RDMA Write、RDMA Read、Atomic operations RDMA技术的Verbs与OFA Verbs API RDMA技术的应用：MPI、文件系统、存储设备、伪Socket库 参考文献 Mellanox Technologies, Inc. (2017). RDMA Aware Networks Programming User Manual. Mellanox Technologies, Inc. ","date":"2023-07-21T01:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/20230722162905.png","permalink":"https://cuterwrite.top/p/rdma-tutorial/1/","title":"RDMA技术及其编程方法（一）：RDMA简介与原理"},{"content":" Table of Contents generated with DocToc\nMPI与并行计算（五）：MPI扩展 1. 动态进程 2. 远程存储访问（Remote Memory Access，RMA） 3. 并行I/O（MPI-IO） 4. 正确地使用MPI-IO 5. 总结 MPI与并行计算（五）：MPI扩展 1. 动态进程 MPI-1假定所有的进程都是静态的，运行时不能增加和删除进程。MPI-2引入了动态进程的概念：\nMPI-1不定义如何创建进程和如何建立通信。MPI-2中的动态进程机制以可移植的方式(平台独立)提供了这种能力。 动态进程有利于将PVM程序移植到MPI上。并且还可能支持一些重要的应用类型， 如Client/Server和Process farm。 动态进程允许更有效地使用资源和负载平衡。例如，所用节点数可以按需要减少和增加。 支持容错。当一个节点失效时，可以在另一个节点上创建一个新进程运行该节点上的进程的工作。 在MPI-1中 一个MPI程序一旦启动，一直到该MPI程序结束，进程的个数是固定的，在程序运行过程中是不可能动态改变的。在MPI-2中，允许在程序运行过程中动态改变进程的数目，并提供了动态进程创建和管理的各种调用。\n组间通信域在动态进程管理中处于核心的地位，只有掌握了它的基本概念，才能准确把握和使用进程的动态特性和动态进程之间的通信。\n在MPI-2中，对点到点通信和组通信都给出了使用组间通信域时的确切含义。在语法上，不管是使用组内还是组间通信域，二者没有任何区别，但其语义是不同的。\n对于构成组间通信域的两个进程组，调用进程把自己所在的组看作是本地组，而把另一个组称为远地组，使用组间通信域的一个特点是本地组进程发送的数据被远地组进程接收而本地组接收的数据必然来自远地组。 在使用组间通信域的点到点通信中，发送语句指定的目的进程是远地组中的进程编号，接收进程指出的源进程编号也是远地组的进程编号。 如图所示为组间通信域上的点到点通信 对于组通信，如果使用组间通信域，则其含义分不同的形式而有所不同：对于多对多通信，本地进程组的所有进程向远地进程组的所有进程发送数据，同时本地进程组的所有进程从远地进程组的所有进程接收数据，如图所示：\n此外，组间通信域上的一对多通信或多对一通信如图所示： 示例1：动态进程的创建和通信\n// dynamic.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;mpi.h\u0026gt; int main(int argc, char *argv[]) { int rank, size, color, new_rank, new_size; MPI_Comm new_comm; MPI_Init(\u0026amp;argc, \u0026amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;size); color = rank / 2; // 0, 0, 1, 1, 2, 2, 3, 3 MPI_Comm_split(MPI_COMM_WORLD, color, rank, \u0026amp;new_comm); MPI_Comm_rank(new_comm, \u0026amp;new_rank); MPI_Comm_size(new_comm, \u0026amp;new_size); printf(\u0026#34;rank = %d, size = %d, new_rank = %d, new_size = %d\\n\u0026#34;, rank, size, new_rank, new_size); MPI_Finalize(); return 0; } 在16个进程中，每两个进程一组，共8组，每组的进程编号相同，运行结果如下： root@ubuntu:~# mpicc dynamic.c -o dynamic root@ubuntu:~# mpirun -n 16 ./dynamic rank = 0, size = 16, new_rank = 0, new_size = 2 rank = 1, size = 16, new_rank = 1, new_size = 2 rank = 2, size = 16, new_rank = 0, new_size = 2 rank = 3, size = 16, new_rank = 1, new_size = 2 rank = 4, size = 16, new_rank = 0, new_size = 2 rank = 5, size = 16, new_rank = 1, new_size = 2 rank = 6, size = 16, new_rank = 0, new_size = 2 rank = 7, size = 16, new_rank = 1, new_size = 2 rank = 8, size = 16, new_rank = 0, new_size = 2 rank = 9, size = 16, new_rank = 1, new_size = 2 rank = 10, size = 16, new_rank = 0, new_size = 2 rank = 11, size = 16, new_rank = 1, new_size = 2 rank = 12, size = 16, new_rank = 0, new_size = 2 rank = 13, size = 16, new_rank = 1, new_size = 2 rank = 14, size = 16, new_rank = 0, new_size = 2 rank = 15, size = 16, new_rank = 1, new_size = 2 2. 远程存储访问（Remote Memory Access，RMA） 在MPI-2中增加远程存储访问的能力，主要是为了使MPI在编写特定算法和通信模型的并行程序时更加自然和简洁。因为在许多情况下，都需要一个进程对另外一个进程的存储区域进行直接访问。 MPI-2对远程存储的访问主要是通过窗口来进行的，为了进行远程存储访问，首先需要定义一个窗口，该窗口开在各个进程的一段本地进程存储空间，其目的是为了让其它的进程可以通过这一窗口来访问本地的数据。 定义好窗口之后，就可以通过窗口来访问远程存储区域的数据了。MPI-2提供了三种基本的访问形式，即读、写和累计，读操作只是从远端的窗口获取数据，并不对远端数据进行任何修改；写操作将本地的内容写入远端的窗口，它修改远端窗口的内容；累计操作就更复杂一些，它将远端窗口的数据和本地的数据进行某种指定方式的运算之后，再将运算的结果写入远端窗口。 MPI-2就是通过读、写和累计三种操作来实现对远程存储的访问和更新的。除了基本的窗口操作之外MPI-2还提供了窗口管理功能 用来实现对窗口操作的同步管理。MPI-2对窗口的同步管理有三种方式 ： 栅栏方式fence：在这种方式下，对窗口的操作必须放在一对栅栏语句之间，这样可以保证当栅栏语句结束之后，其内部的窗口操作可以正确完成。 握手方式：在这种方式下，调用窗口操作的进程需要将具体的窗口调用操作放在以MPI_WIN_START开始，以MPI_WIN_COMPLETE结束的调用之间。相应的,被访问的远端进程需要以一对调用MPI_WIN_POST和MPI_WIN_WAIT与之相适应。MPI_WIN_POST允许其它的进程对自己的窗口进行访问，而MPI_WIN_WAIT调用结束之后可以保证对本窗口的调用操作全部完成。MPI_WIN_START申请对远端进程窗口的访问，只有当远端窗口执行了MPI_WIN_POST操作之后才可以访问远端窗口，MPI_WIN_COMPLETE完成对远端窗口访问操作。 锁方式：在这种方式下，不同的进程通过对特定的窗口加锁来实现互斥访问。当然用户根据需要可以使用共享的锁，这是就可以允许使用共享锁的进程对同一窗口同时访问。远端存储的访问窗口是具体的实现形式，通过窗口操作实现来实现单边通信，通过对窗口的管理操作来实现对窗口操作的同步控制。 窗口操作 说明 MPI_Win_create 创建窗口 MPI_Win_free 释放窗口 MPI_Win_fence 栅栏同步 MPI_Win_start 握手同步 MPI_Win_complete 握手同步 MPI_Win_post 握手同步 MPI_Win_wait 握手同步 MPI_Win_lock 锁同步 MPI_Win_unlock 锁同步 MPI_Win_test 锁同步 MPI_Win_lock_all 锁同步 MPI_Win_unlock_all 锁同步 MPI_Win_flush 锁同步 MPI_Win_flush_all 锁同步 MPI_Win_flush_local 锁同步 MPI_Win_flush_local_all 锁同步 MPI_Win_shared_query 查询窗口 小结：窗口是远程存储访问中的重要概念，其实MPI-2的远程存储访问就是各进程将自己的一部分内存区域开辟成其它所有进程都可以访问的窗口，从而使其它的进程实现对自己数据的远程访问，窗口操作是相对简单的，对窗口访问的同步控制是需要注意的问题。 示例2：远程存储访问\n// rma.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;mpi.h\u0026gt; int main(int argc, char *argv[]) { int rank, size, i, j, *buf, *winbuf; MPI_Win win; MPI_Init(\u0026amp;argc, \u0026amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;size); buf = (int *)malloc(size * sizeof(int)); MPI_Win_create(buf, size * sizeof(int), sizeof(int), MPI_INFO_NULL, MPI_COMM_WORLD, \u0026amp;win); for (i = 0; i \u0026lt; size; i++) buf[i] = 0; MPI_Win_fence(0, win); if (rank == 0) { for (i = 0; i \u0026lt; size; i++) buf[i] = i; } MPI_Win_fence(0, win); if (rank == 1) { for (i = 0; i \u0026lt; size; i++) printf(\u0026#34;buf[%d] = %d\\n\u0026#34;, i, buf[i]); } MPI_Win_free(\u0026amp;win); MPI_Finalize(); return 0; } 3. 并行I/O（MPI-IO） MPI-1没有对并行文件I/O给出任何定义，原因在于并行I/O过于复杂，很难找到一个统一的标准。但是，I/O是很多应用不可缺少的部分，MPI-2在大量实践的基础上，提出了一个并行I/O的标准接口。MPI-2提供的关于并行文件I/O的调用十分丰富，根据读写定位方法的不同，可以分为三种：\n指定显示的偏移：这种调用没有文件指针的概念 每次读写操作都必须明确指定读写文件的位置。 各进程拥有独立的文件指针：这种方式的文件操作不需要指定读写的位置每一个进程都有一个相互独立的文件指针，读写的起始位置就是当前指针的位置。读写完成后文件指针自动移到下一个有效数据的位置。这种方式的文件操作需要每一个进程都定义各自在文件中的文件视图（view），文件视图（view）数据是文件连续或不连续的一部分，各个进程对文件视图（view）的操作就如同是对一个打开的独立的连续文件的操作一样。 共享文件指针：在这种情况下，每一个进程对文件的操作都是从当前共享文件指针的位置开始，操作结束后共享文件指针自动转移到下一个位置。共享指针位置的变化对所有进程都是可见的，各进程使用的是同一个文件指针。任何一个进程对文件的读写操作都会引起其它所有进程文件指针的改变。 MPI-IO文件访问过程 在进行I/O之前，必须要通过调用MPI_File_open打开文件 每个进程都需要定义文件指针用来控制文件访问 I/O操作完成后，必须通过调用MPI_File_close来关闭文件 并行文件的基本操作 打开：MPI_File_open(comm, filename, amode, info, fh) comm：组内通信域 filename：文件名 amode：打开模式 info：传递给运行时的信息 fh：返回的文件句柄 文件访问模式 含义 MPI_MODE_RDONLY 只读 MPI_MODE_RDWR 读写 MPI_MODE_WRONLY 只写 MPI_MODE_CREATE 若文件不存在则创建 MPI_MODE_EXCL 创建不存在的新文件，若文件已存在则报错 MPI_MODE_DELETE_ON_CLOSE 关闭文件时删除文件 MPI_MODE_UNIQUE_OPEN 文件只能被一个进程打开 MPI_MODE_SEQUENTIAL 文件只能被顺序访问 MPI_MODE_APPEND 追加方式打开，初始文件指针指向文件末尾 关闭：MPI_File_close(fh) fh：文件句柄 删除：MPI_File_delete(filename, info) filename：文件名 info：传递给运行时的信息 修改文件大小：MPI_File_set_size(fh, size) fh：文件句柄 size：新的文件大小(字节) 查看文件大小：MPI_File_get_size(fh, size) fh：文件句柄 size：文件大小(字节) 预申请空间：MPI_File_preallocate(fh, size) fh：文件句柄 size：预申请的空间大小(字节) 示例3：并行I/O - 指定显示偏移并行读\n#include \u0026lt;mpi.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;sys/stat.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main(int argc, char **argv) { int rank, size; MPI_File fh; MPI_Status status; MPI_Init(\u0026amp;argc, \u0026amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;size); char *filename = \u0026#34;testfile\u0026#34;; struct stat st; stat(filename, \u0026amp;st); int filesize = st.st_size; int bufsize = filesize / size; MPI_File_open(MPI_COMM_WORLD, filename, MPI_MODE_RDONLY, MPI_INFO_NULL, \u0026amp;fh); MPI_Offset offset = rank * bufsize; if (rank == size - 1) { bufsize += filesize % size; } char* buf = (char*)malloc(bufsize * sizeof(char)); printf(\u0026#34;Buf size: %d\\n\u0026#34;, bufsize); MPI_File_read_at(fh, offset, buf, bufsize, MPI_CHAR, \u0026amp;status); printf(\u0026#34;Process %d read: %s\\n\u0026#34;, rank, buf); MPI_File_close(\u0026amp;fh); MPI_Finalize(); free(buf); return 0; } tesfile文件内容为： ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz01234567891 运行结果为： root@ubuntu:~# mpicc read.c -o read root@ubuntu:~# mpirun -n 2 ./read Buf size: 125 Process 1 read: ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz01234567891 Buf size: 124 Process 0 read: ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789 4. 正确地使用MPI-IO 正确使用MPI-IO 根据I/O需求，每个应用都有其特定的I/O访问模式 对于不同的I/O系统，同样的I/O访问模式也可以使用不同的I/O函数和I/O方式实现 通常MPI-IO中I/O访问模式的实现方式可分为4级：level0-level3 以分布式数组访问为例 level0：每个进程对本地数组的一行发出一个独立的读请求（就像在unix中一样） MPI_File_open(..., file, ..., \u0026amp;fh); for (i = 0; i \u0026lt; n_local_rows; i++) { MPI_File_seek(fh, ...); MPI_File_read(fh, \u0026amp;(A[i][0]), ...); } MPI_File_close(\u0026amp;fh); level1：类似于level 0，但每个过程都使用集合I/O函数 MPI_File_open(MPI_COMM_WORLD, file, ...,\u0026amp;fh); for (i = 0; i \u0026lt; n_local_rows; i++) { MPI_File_seek(fh, ...); MPI_File_read_all(fh, \u0026amp;(A[i][0]), ...); } MPI_File_close(\u0026amp;fh); level2：每个进程创建一个派生数据类型来描述非连续访问模式，定义一个文件视图，并调用独立的I/O函数 MPI_Type_create_subarray(...,\u0026amp;subarray, ...); MPI_Type_commit(\u0026amp;subarray); MPI_File_open(..., file, ..., \u0026amp;fh); MPI_File_set_view(fh, ..., subarray, ...); MPI_File_read(fh, A, ...); MPI_File_close(\u0026amp;fh); level3：类似于level 0，但每个过程都使用集合I/O函数 MPI_Type_create_subarray(...,\u0026amp;subarray, ...); MPI_Type_commit(\u0026amp;subarray); MPI_File_open(MPI_COMM_WORLD, file,...,\u0026amp;fh); MPI_File_set_view(fh, ..., subarray, ...); MPI_File_read_all(fh, A, ...); MPI_File_close(\u0026amp;fh); 5. 总结 MPI-IO有许多功能，可以帮助用户获得高性能I/O 支持非连续性访问 派生数据类型 文件视图 集合I/O 用户应该根据应用程序I/O特性来选择适合的I/O访问模式实现 同时，MPI-IO不是实现并行I/O的唯一选择。目前已有一些更高级的库可代替MPI-IO HDF5、netCDF\u0026hellip;\u0026hellip; 这些库都是基于MPI-IO实现 ","date":"2023-07-20T03:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/9a5806864623b04c918b9d8bee35c49fc2790c52.jpg@1256w_828h_!web-article-pic.avif","permalink":"https://cuterwrite.top/p/mpi-tutorial/5/","title":"MPI与并行计算（五）：MPI扩展"},{"content":" Table of Contents generated with DocToc\nMPI与并行计算（四）：数据类型 1. 预定义数据类型 2. 派生数据类型 MPI与并行计算（四）：数据类型 1. 预定义数据类型 MPI支持异构计算(Heterogeneous Computing)，它指在不同计算机系统上运行程序，每台计算可能有不同生产厂商，不同操作系统。 MPI通过提供预定义数据类型来解决异构计算中的互操作性问题，建立它与具体语言的对应关系。\nMPI中预定义的数据类型如下： MPI数据类型(C语言绑定) C语言数据类型 MPI_CHAR char MPI_SHORT short MPI_INT int MPI_LONG long MPI_UNSIGNED_CHAR unsigned char MPI_UNSIGNED_SHORT unsigned short MPI_UNSIGNED unsigned MPI_UNSIGNED_LONG unsigned long MPI_FLOAT float MPI_DOUBLE double MPI_LONG_DOUBLE long double MPI_BYTE 无 MPI_PACKED 无 2. 派生数据类型 MPI提供了全面而强大的**构造函数(Constructor Function)**来定义派生数据类型。派生数据类型是一种抽象的数据结构，可以用来描述数据的组织形式，而不是数据本身。 派生数据类型可以用类型图来描述，这是一种通用的类型描述方法，它是一系列二元组\u0026lt;基类型，偏移\u0026gt;的集合，可以表示成如下格式： \u0026lt;基类型1，偏移1\u0026gt;，\u0026lt;基类型2，偏移2\u0026gt;，...，\u0026lt;基类型n，偏移n\u0026gt; 在派生数据类型中，基类型可以是任何MPI预定义数据类型，也可以是其它的派生数据类型，即支持数据类型的嵌套定义。\n如图，阴影部分是基类型所占用的空间，其它空间可以是特意留下的，也可以是为了方便数据对齐。 基类型指出了该类型图中包括哪些基本的数据类型，而偏移则指出该基类型在整个类型图中的起始位置，基类型可以是预定义类型或派生类型，偏移可正可负，没有递增或递减的顺序要求，而一个类型图中包括的所有基类型的集合称为某类型的类型表，表示为：\n类型表={基类型1，基类型2，...，基类型n} 将类型图和一个数据缓冲区的基地址结合起来 可以说明一个通信缓冲区内的数据分布情况 预定义数据类型是通用数据类型的特例，比如MPI_INT是一个预先定义好了的数据类型句柄，其类型图为{(int, 0)}，有一个基类型入口项int和偏移0，其它的基本数据类型与此相似，数据类型的跨度被定义为该数据类型的类型图中从第一个基类型到最后一个基类型间的距离 即如果某一个类型的类型图为: typemap={(type0,disp0),...,(typen-1,dispn-1)}, 则该类型图的下界定义为： lb(typemap)=min{dispj}, j=0,...,n-1 该类型图的上界定义为： ub(typemap)=max{dispj+sizeof(typej)}, j=0,...,n-1 该类型图的跨度定义为： extent(typemap)=ub(typemap)-lb(typemap) + e 由于不同的类型有不同的对齐位置的要求 e(extent)就是能够使类型图的跨度满足该类型的类型表中的所有的类型都能达到下一个对齐要求所需要的最小非负整数值 假设type={(double, 0), (char, 8)}，进一步假设double型的值必须严格分配到地址为8的倍数的存储空间，则该数据类型的extent是16（(从9循环到下一个8的倍数)，一个由一个字符后面紧跟一个双精度值的数据类型,其extent也是16 函数名 含义 MPI_Type_contiguous 定义由相同数据类型的元素组成的类型 MPI_Type_vector 定义由成块的元素组成的类型，块之间具有相同间隔 MPI_Type_indexed 定义由成块的元素组成的类型，块长度和偏移由参数指定 MPI_Type_struct 定义由不同数据类型的元素组成的类型 MPI_Type_commit 提交一个派生数据类型 MPI_Type_free 释放一个派生数据类型 示例1： 派生数据类型的使用\n// evenElements.c: 从数组A中选取偶数元素发送给进程destination double A[100]; MPI_Datatype evenElements; ... // 省略初始化过程 MPI_Type_vector(50, 1, 2, MPI_DOUBLE, \u0026amp;evenElements); MPI_Type_commit(\u0026amp;evenElements); MPI_Send(A, 1, evenElements, destination, ...); 首先声明一个类型为MPI_Data_type的变量EvenElements 调用构造函数MPI_Type_vector(count, blocklength, stride, oldtype, \u0026amp;newtype)来定义派生数据类型 新的派生数据类型必须先调用函数MPI_Type_commit获得MPI系统的确认后才能调用MPI_Send进行消息发送 ","date":"2023-07-20T01:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/20230720120242.png","permalink":"https://cuterwrite.top/p/mpi-tutorial/4/","title":"MPI与并行计算（四）：数据类型"},{"content":" Table of Contents generated with DocToc\nMPI与并行计算（三）：集合通信 1. 定义 2. 集合通信实现的功能 3. 一对多通信：广播 4. 多对一通信：收集 5. 一对多通信：散播 6. 聚合 7. 同步 8. 规约 MPI与并行计算（三）：集合通信 1. 定义 集合通信（Collective Communication）：是一个进程组中的所有进程都参加的全局通信操作。 特点： 通信空间中的所有进程都参与通信操作 每一个进程都需要调用该操作函数 数据移动类型 Broadcast Scatter Gather AllGather Alltoall 2. 集合通信实现的功能 集合通信一般实现三个功能：通信、聚合和同步\n类型 函数名 含义 通信 MPI_Bcast 一对多广播同样的消息 通信 MPI_Gather 多对一收集各个进程的消息 通信 MPI_Gatherv MPI_Gather的一般化 通信 MPI_Allgather 全局收集 通信 MPI_Allgatherv MPI_Allgather的一般化 通信 MPI_Scatter 一对多散播不同的消息 通信 MPI_Scatterv MPI_Scatter的一般化 通信 MPI_Alltoall 多对多全局交换消息 通信 MPI_Alltoallv MPI_Alltoall的一般化 聚合 MPI_Reduce 多对一规约 聚合 MPI_Allreduce MPI_Reduce的一般化 聚合 MPI_Scan 多对多扫描 聚合 MPI_Reduce_scatter MPI_Reduce的一般化 同步 MPI_Barrier 路障同步 通信：集合通信，按照通信方向的不同，又可以分为三种：一对多通信，多对一通信和多对多通信。\n一对多通信：一个进程向其它所有的进程发送消息，这个负责发送消息的进程叫做Root进程。\n多对一通信：一个进程负责从其它所有的进程接收消息，这个接收的进程也叫做Root进程。\n多对多通信：每一个进程都向其它所有的进程发送或者接收消息。\n3. 一对多通信：广播 广播是一对多通信的典型例子，其调用格式为：MPI_Bcast(void *buffer, int count, MPI_Datatype datatype, int root, MPI_Comm comm) 示例1：广播\n// bcast.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;mpi.h\u0026gt; int main(int argc, char *argv[]) { int rank, size; int data; MPI_Init(\u0026amp;argc, \u0026amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;size); if (rank == 0) { data = 123; } MPI_Bcast(\u0026amp;data, 1, MPI_INT, 0, MPI_COMM_WORLD); printf(\u0026#34;Process %d got data %d\\n\u0026#34;, rank, data); MPI_Finalize(); return 0; } 结果： root@ubuntu:~# mpicc bcast.c -o bcast root@ubuntu:~# mpirun -n 2 ./bcast Process 0 got data 123 Process 1 got data 123 广播的特点 标号为Root的进程发送相同的消息给通信域Comm中的所有进程。 消息的内容如同点对点通信一样由三元组\u0026lt;Address, Count, Datatype\u0026gt;标识。 对Root进程来说，这个三元组既定义了发送缓冲也定义了接收缓冲。对其它进程来说，这个三元组只定义了接收缓冲 4. 多对一通信：收集 收集是多对一通信的典型例子，其调用格式为：MPI_Gather(void *sendbuf, int sendcount, MPI_Datatype sendtype, void *recvbuf, int recvcount, MPI_Datatype recvtype, int root, MPI_Comm comm) 示例2：收集\n// gather.c #include \u0026lt;mpi.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; int main(int argc, char *argv[]) { int rank, size; // 分布变量 int data[2]; int *buf; MPI_Init(\u0026amp;argc, \u0026amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;size); data[0] = rank * 2 + 1; data[1] = rank * rank * 3 + 2; if (rank == 0) { // 开辟接收缓存区 buf = malloc(2 * size * sizeof(int)); } MPI_Gather(data, 2, MPI_INT, buf, 2, MPI_INT, 0, MPI_COMM_WORLD); if (rank == 0) { for (int i = 0; i \u0026lt; 2 * size; i++) { printf(\u0026#34;%d \u0026#34;, buf[i]); } printf(\u0026#34;\\n\u0026#34;); free(buf); } MPI_Finalize(); return 0; } 结果： root@ubuntu:~# mpicc gather.c -o gather root@ubuntu:~# mpirun -n 2 ./gather 1 2 3 5 收集的特点 在收集操作中，Root进程从进程域Comm的所有进程(包括它自已)接收消息。 这n个消息按照进程的标识rank排序进行拼接，然后存放在Root进程的接收缓冲中。 接收缓冲由三元组\u0026lt;RecvAddress, RecvCount, RecvDatatype\u0026gt;标识，发送缓冲由三元组\u0026lt;SendAddress, SendCount, SendDatatype\u0026gt;标识，所有非Root进程忽略接收缓冲。 5. 一对多通信：散播 散播是一个一对多操作，其调用格式为：MPI_Scatter(void *sendbuf, int sendcount, MPI_Datatype sendtype, void *recvbuf, int recvcount, MPI_Datatype recvtype, int root, MPI_Comm comm) 示例3：散播\n// scatter.c #include \u0026lt;mpi.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; int main(int argc, char *argv[]) { int rank, size; int *buf; int data[2]; MPI_Init(\u0026amp;argc, \u0026amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;size); if (rank == 0) { buf = malloc(2 * size * sizeof(int)); for (int i = 0; i \u0026lt; 2 * size; i++) { buf[i] = i; } } MPI_Scatter(buf, 2, MPI_INT, data, 2, MPI_INT, 0, MPI_COMM_WORLD); printf(\u0026#34;rank = %d, data = %d %d\\n\u0026#34;, rank, data[0], data[1]); if (rank == 0) { free(buf); } MPI_Finalize(); return 0; } 结果： root@ubuntu:~# mpicc scatter.c -o scatter root@ubuntu:~# mpirun -n 2 ./scatter rank = 0, data = 0 1 rank = 1, data = 2 3 散播的特点 Scatter执行与Gather相反的操作。 Root进程给所有进程(包括它自已)发送一个不同的消息，这n (n为进程域comm包括的进程个数)个消息在Root进程的发送缓冲区中按进程标识的顺序有序地存放。 每个接收缓冲由三元组\u0026lt;RecvAddress, RecvCount, RecvDatatype\u0026gt;标识，所有的非Root进程忽略发送缓冲。对Root进程，发送缓冲由三元组\u0026lt;SendAddress,SendCount, SendDatatype\u0026gt;标识。 6. 聚合 集合通信的聚合功能使得MPI进行通信的同时完成一定的计算。 MPI聚合的功能分三步实现： 首先是通信的功能，即消息根据要求发送到目标进程，目标进程也已经收到了各自需要的消息 然后是对消息的处理，即执行计算功能 最后把处理结果放入指定的接收缓冲区 MPI提供了两种类型的聚合操作: 归约(Reduce)和扫描(Scan)。 7. 同步 同步功能用来协调各个进程之间的进度和步伐 。目前MPI的实现中支持一个同步操作，即路障同步(Barrier)。 路障同步的调用格式为：MPI_Barrier(MPI_Comm comm) 在路障同步操作MPI_Barrier(Comm)中，通信域Comm中的所有进程相互同步。 在该操作调用返回后，可以保证组内所有的进程都已经执行完了调用之前的所有操作，可以开始该调用后的操作。 8. 规约 MPI_REDUCE将组内每个进程输入缓冲区中的数据按给定的操作op进行运算，并将其结果返回到序列号为root的进程的输出缓冲区中，输入缓冲区由参数sendbuf、count和datatype定义，输出缓冲区由参数recvbuf count和datatype定义，要求两者的元素数目和类型都必须相同，因为所有组成员都用同样的参数count、datatype、op、root和comm来调用此例程 故而所有进程都提供长度相同、元素类型相同的输入和输出缓冲区，每个进程可能提供一个元素或一系列元素 组合操作依次针对每个元素进行。\n操作op始终被认为是可结合的 并且所有MPI定义的操作被认为是可交换的，用户自定义的操作被认为是可结合的，但可以不是可交换的。MPI中已经定义好的一些操作,它们是为函数MPI_Reduce和一些其他的相关函数,如MPI_Allreduce、MPI_Reduce_scatter和MPI_Scan而定义的 这些操作用来设定相应的op。\nMPI预定的归约操作如下:\n操作 含义 操作 含义 MPI_MAX 最大值 MPI_MIN 最小值 MPI_SUM 求和 MPI_PROD 求积 MPI_LAND 逻辑与 MPI_BAND 按位与 MPI_LOR 逻辑或 MPI_BOR 按位或 MPI_LXOR 逻辑异或 MPI_BXOR 按位异或 MPI_MAXLOC 最大值和位置 MPI_MINLOC 最小值和位置 示例4：计算pi值\n// reduce.c #include \u0026lt;math.h\u0026gt; #include \u0026lt;mpi.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; double f(double); double f(double x) { return 4.0 / (1.0 + x * x); } int main(int argc, char **argv) { int done = 0, n, myid, numprocs, i; double PI25DT = 3.141592653589793238462643; double mypi, pi, h, sum, x; double startwtime = 0.0, endwtime; int namelen; char process_name[MPI_MAX_PROCESSOR_NAME]; MPI_Init(\u0026amp;argc, \u0026amp;argv); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;numprocs); MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;myid); MPI_Get_processor_name(process_name, \u0026amp;namelen); fprintf(stdout, \u0026#34;Process %d of %d is on %s\\n\u0026#34;, myid, numprocs, process_name); n = 0; if (myid == 0) { fprintf(stdout, \u0026#34;Enter the number of intervals: (0 quits) \u0026#34;); fflush(stdout); scanf(\u0026#34;%d\u0026#34;, \u0026amp;n); startwtime = MPI_Wtime(); } /* 将n广播给所有进程 */ MPI_Bcast(\u0026amp;n, 1, MPI_INT, 0, MPI_COMM_WORLD); /* 矩形宽度 */ h = 1.0 / (double)n; /* 矩形面积初值 */ sum = 0.0; /* 每个进程计算自己的部分 */ for (i = myid + 1; i \u0026lt;= n; i += numprocs) { x = h * ((double)i - 0.5); sum += f(x); } /* 各个进程并行计算得到的和 */ mypi = h * sum; MPI_Reduce(\u0026amp;mypi, \u0026amp;pi, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD); /* 将部分和累加得到最终结果 */ if (myid == 0) { printf(\u0026#34;pi is approximately %.16f, Error is %.16f\\n\u0026#34;, pi, fabs(pi - PI25DT)); endwtime = MPI_Wtime(); printf(\u0026#34;wall clock time = %f\\n\u0026#34;, endwtime - startwtime); fflush(stdout); } MPI_Finalize(); return 0; } ","date":"2023-07-19T15:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/20230720002052.png","permalink":"https://cuterwrite.top/p/mpi-tutorial/3/","title":"MPI与并行计算（三）：集合通信"},{"content":" Table of Contents generated with DocToc\nMPI与并行计算（二）：点到点通信 1. MPI的通信模式 2. 标准通信模式：MPI_Send和MPI_Recv 3. 缓冲通信模式 4. 就绪通信模式 5. 同步通信模式 6. 阻塞通信与非阻塞通信 7. 非阻塞的发送和接收 8. 总结 MPI与并行计算（二）：点到点通信 1. MPI的通信模式 通信模式：指的是缓冲管理以及发送方和接收方之间的同步方式。 MPI支持四种通信模式：标准通信模式、缓冲通信模式、就绪通信模式和同步通信模式 2. 标准通信模式：MPI_Send和MPI_Recv 由MPI决定是否缓冲消息 没有足够的系统缓冲区时或出于性能的考虑， MPI可能进行直接拷贝： 仅当相应的接收开始后，发送语句才能返回 MPI缓冲消息：发送语句地相应的接收语句完成前返回 发送的结束 == 消息已从发送方发出，而不是滞留在发送方的系统缓冲区中 非本地的：发送操作的成功与否依赖于接收操作 理论上要求有接收进程的recv调用配合，发送函数是MPI_Send()。 示例1：标准通信模式\n#include \u0026lt;mpi.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;thread\u0026gt; #define BUF_SIZE 10 int main(int argc, char *argv[]) { int myid, numprocs; int other; int sb[BUF_SIZE]; int rb[BUF_SIZE]; // 初始化MPI环境 MPI_Init(\u0026amp;argc, \u0026amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;myid); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;numprocs); MPI_Status status; for (int i = 0; i \u0026lt; BUF_SIZE; i++) { sb[i] = myid + i; } if (myid == 0) { other = 1; } else if (myid == 1) { other = 0; } if (myid == 0) { std::cout \u0026lt;\u0026lt; \u0026#34;process \u0026#34; \u0026lt;\u0026lt; myid \u0026lt;\u0026lt; \u0026#34; tring send...\u0026#34; \u0026lt;\u0026lt; std::endl; MPI_Send(sb, BUF_SIZE, MPI_INT, other, 1, MPI_COMM_WORLD); std::cout \u0026lt;\u0026lt; \u0026#34;process \u0026#34; \u0026lt;\u0026lt; myid \u0026lt;\u0026lt; \u0026#34; tring receiving...\u0026#34; \u0026lt;\u0026lt; std::endl; MPI_Recv(rb, BUF_SIZE, MPI_INT, other, 1, MPI_COMM_WORLD, \u0026amp;status); } else if (myid == 1) { // sleep 10s, 与缓冲通信模式相比，这里的发送和接收操作是阻塞的 std::this_thread::sleep_for(std::chrono::seconds(10)); std::cout \u0026lt;\u0026lt; \u0026#34;process \u0026#34; \u0026lt;\u0026lt; myid \u0026lt;\u0026lt; \u0026#34; tring receiving...\u0026#34; \u0026lt;\u0026lt; std::endl; MPI_Recv(rb, BUF_SIZE, MPI_INT, other, 1, MPI_COMM_WORLD, \u0026amp;status); std::cout \u0026lt;\u0026lt; \u0026#34;process \u0026#34; \u0026lt;\u0026lt; myid \u0026lt;\u0026lt; \u0026#34; tring send...\u0026#34; \u0026lt;\u0026lt; std::endl; MPI_Send(sb, BUF_SIZE, MPI_INT, other, 1, MPI_COMM_WORLD); } std::cout \u0026lt;\u0026lt; \u0026#34;Hello World! Process \u0026#34; \u0026lt;\u0026lt; myid \u0026lt;\u0026lt; \u0026#34; of \u0026#34; \u0026lt;\u0026lt; numprocs \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Send buffer: \u0026#34; \u0026lt;\u0026lt; std::endl; for (int i = 0; i \u0026lt; BUF_SIZE; i++) { std::cout \u0026lt;\u0026lt; sb[i] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } std::cout \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Receive buffer: \u0026#34; \u0026lt;\u0026lt; std::endl; for (int i = 0; i \u0026lt; BUF_SIZE; i++) { std::cout \u0026lt;\u0026lt; rb[i] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } std::cout \u0026lt;\u0026lt; std::endl; MPI_Finalize(); return 0; } 运行结果： root@ubuntu:~# mpicxx -o mpi mpi.cpp root@ubuntu:~# mpirun -n 2 ./mpi process 0 tring send... process 0 tring receiving... process 1 tring receiving... process 1 tring send... Hello World! Process 1 of 2 Send buffer: 1 2 3 4 5 6 7 8 9 10 Receive buffer: 0 1 2 3 4 5 6 7 8 9 Hello World! Process 0 of 2 Send buffer: 0 1 2 3 4 5 6 7 8 9 Receive buffer: 1 2 3 4 5 6 7 8 9 10 这就是点对点通信的基本用法，通过发送和接收操作，进程之间可以进行数据交换和协调工作。 3. 缓冲通信模式 前提: 用户显示地指定用于缓冲消息的系统缓冲区MPI_Buffer_attach(*buffer, *size) 。 发送是本地的: 完成不依赖于与其匹配的接收操作。 发送的结束仅表明消息进入系统的缓冲区中，发送缓冲区可以重用，而对接收方的情况并不知道。 缓冲模式在相匹配的接收未开始的情况下，总是将送出的消息放在缓冲区内，这样发送者可以很快地继续计算,然后由系统处理放在缓冲区中的消息。 占用内存，一次内存拷贝。 函数调用形式为：MPI_Bsend()。B表示缓冲，缓冲通信模式主要用于解开阻塞通信的发送与接收之间的耦合。 作用总结：通常情况下，MPI发送和接收操作是阻塞的，即发送操作会等待接收方准备好接收，接收操作会等待发送方发送数据。但是，MPI提供了一种称为缓冲区（buffering）的机制，可以使发送操作立即返回，而不需要等待接收方准备好。 示例2：缓冲通信模式\n#include \u0026lt;mpi.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;thread\u0026gt; int main(int argc, char **argv) { int myid, numprocs; // 初始化 MPI_Init(\u0026amp;argc, \u0026amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;myid); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;numprocs); int s1, s2; // 取缓冲区的上界，以字节为单位 MPI_Pack_size(7, MPI_CHAR, MPI_COMM_WORLD, \u0026amp;s1); MPI_Pack_size(2, MPI_DOUBLE, MPI_COMM_WORLD, \u0026amp;s2); int buffer_size = 2 * MPI_BSEND_OVERHEAD + s1 + s2; char *buffer = new char[buffer_size]; // 装配一个用于通信的缓冲区 MPI_Buffer_attach(buffer, buffer_size); char msg1[7] = \u0026#34;Hello\u0026#34;; double msg2[2] = {1.0, 2.0}; char rmsg1[7]; double rmsg2[2]; if (myid == 0) { MPI_Bsend(msg1, 7, MPI_CHAR, 1, 1, MPI_COMM_WORLD); MPI_Bsend(msg2, 2, MPI_DOUBLE, 1, 2, MPI_COMM_WORLD); std::cout \u0026lt;\u0026lt; \u0026#34;Send msg1: \u0026#34; \u0026lt;\u0026lt; msg1 \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Send msg2: \u0026#34; \u0026lt;\u0026lt; msg2[0] \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; msg2[1] \u0026lt;\u0026lt; std::endl; } else if (myid == 1) { // sleep 10s std::this_thread::sleep_for(std::chrono::seconds(10)); MPI_Recv(rmsg1, 7, MPI_CHAR, 0, 1, MPI_COMM_WORLD, MPI_STATUS_IGNORE); MPI_Recv(rmsg2, 2, MPI_DOUBLE, 0, 2, MPI_COMM_WORLD, MPI_STATUS_IGNORE); std::cout \u0026lt;\u0026lt; \u0026#34;Receive msg1: \u0026#34; \u0026lt;\u0026lt; rmsg1 \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;Receive msg2: \u0026#34; \u0026lt;\u0026lt; rmsg2[0] \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; rmsg2[1] \u0026lt;\u0026lt; std::endl; } MPI_Buffer_detach(\u0026amp;buffer, \u0026amp;buffer_size); free(buffer); MPI_Finalize(); return 0; } 运行结果： root@ubuntu:~# mpicxx -o mpi mpi.cpp root@ubuntu:~# mpirun -n 2 ./mpi Send msg1: Hello Send msg2: 1 2 Receive msg1: Hello Receive msg2: 1 2 4. 就绪通信模式 发送请求仅当有匹配的接收后才能发出，否则出错。在就绪模式下，系统默认与其相匹配的接收已经调用。 接收必须先于发送。 它不可以不依赖于接收方的匹配的接收请求而任意发出 其函数调用形式为：MPI_RSend()。R表示就绪，仅当对方的接收操作启动并准备就绪时，才可以发送数据。 示例3：就绪通信模式\n#include \u0026lt;mpi.h\u0026gt; #include \u0026lt;iostream\u0026gt; int main(int argc, char **argv) { int myid, numprocs; // 初始化 MPI_Init(\u0026amp;argc, \u0026amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;myid); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;numprocs); MPI_Status status; int buffer[10]; if (myid == 0) { for (int i = 0; i \u0026lt; 10; i++) { buffer[i] = -1; } MPI_Recv(buffer, 10, MPI_INT, 1, 1, MPI_COMM_WORLD, \u0026amp;status); for (int i = 0; i \u0026lt; 10; i++) { if (buffer[i] != i) { std::cout \u0026lt;\u0026lt; \u0026#34;error\u0026#34; \u0026lt;\u0026lt; std::endl; break; } } } else if (myid == 1) { for (int i = 0; i \u0026lt; 10; i++) { buffer[i] = i; } MPI_Rsend(buffer, 10, MPI_INT, 0, 1, MPI_COMM_WORLD); } MPI_Finalize(); return 0; } 5. 同步通信模式 本质特征：收方接收该消息的缓冲区已准备好， 不需要附加的系统缓冲区 任意发出：发送请求可以不依赖于收方的匹配的接收请求而任意发出 成功结束： 仅当收方已发出接收该消息的请求后才成功返回，否则将阻塞。意味着： 发送方缓冲区可以重用 收方已发出接收请求 是非本地的 函数调用形式为：MPI_Ssend()。S表示同步。 示例4：同步通信模式\n#include \u0026lt;mpi.h\u0026gt; #include \u0026lt;iostream\u0026gt; int main(int argc, char **argv) { int myid, numprocs; // 初始化 MPI_Init(\u0026amp;argc, \u0026amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;myid); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;numprocs); MPI_Status status; int buffer[10]; if (myid == 0) { for (int i = 0; i \u0026lt; 10; i++) { buffer[i] = -1; } MPI_Recv(buffer, 10, MPI_INT, 1, 1, MPI_COMM_WORLD, \u0026amp;status); std::cout \u0026lt;\u0026lt; \u0026#34;process \u0026#34; \u0026lt;\u0026lt; myid \u0026lt;\u0026lt; \u0026#34; receiving...\u0026#34; \u0026lt;\u0026lt; std::endl; for (int i = 0; i \u0026lt; 10; i++) { if (buffer[i] != i) { std::cout \u0026lt;\u0026lt; \u0026#34;error\u0026#34; \u0026lt;\u0026lt; std::endl; break; } } } else if (myid == 1) { for (int i = 0; i \u0026lt; 10; i++) { buffer[i] = i; } std::cout \u0026lt;\u0026lt; \u0026#34;process \u0026#34; \u0026lt;\u0026lt; myid \u0026lt;\u0026lt; \u0026#34; sending...\u0026#34; \u0026lt;\u0026lt; std::endl; MPI_Ssend(buffer, 10, MPI_INT, 0, 1, MPI_COMM_WORLD); } MPI_Finalize(); return 0; } 6. 阻塞通信与非阻塞通信 阻塞通信调用时，整个程序只能执行通信相关的内容，而无法执行计算相关的内容；非阻塞调用的初衷是尽量让通信和计算重叠进行，提高程序整体执行效率。\n非阻塞通信调用返回意味着通信开始启动；而非阻塞通信完成则需要调用其他的接口来查询。\n非阻塞通信的调用接口 非阻塞通信的完成查询接口 非阻塞通信的发送和接受过程都需要同时具备以上两个要素：调用与完成。（1）”调用“按照通信方式的不同（标准、缓存、同步、就绪），有各种函数接口；（2）”完成“是重点，因为程序员需要知道非阻塞调用是否执行完成了，来做下一步的操作。\nMPI为“完成”定义了一个内部变量MPI_Request request，每个request与一个在非阻塞调用发生时与该调用发生关联（这里的调用包括发送和接收）。“完成”不区分通信方式的不同，统一用MPI_Wait系列函数来完成。\nMPI_Wait(MPI_Request *request)，均等着request执行完毕了，再往下进行 对于非重复非阻塞通信，MPI_Wait系列函数调用的返回，还意味着request对象被释放了，程序员不用再显式释放request变量。 对于重复非阻塞通信，MPI_Wait系列函数调用的返回，意味着将于request对象关联的非阻塞通信处于不激活状态，并不释放request 7. 非阻塞的发送和接收 int MPI_Isend(void *buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm, MPI_Request *request) buf: 发送缓冲区的起始地址 count: 发送数据的个数 datatype: 发送数据的类型 dest: 目标进程的rank tag: 消息标签 comm: 通信子 request: 非阻塞通信完成对象 MPI_Ibsend/MPI_Issend/MPI_Irsend: 缓冲/同步/就绪通信的非阻塞发送 int MPI_Irecv(void *buf, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm comm, MPI_Request *request) 8. 总结 理解各种模式通信过程的行为，关键是弄清楚各个模式对缓冲使用的方式。简而言之，各个模式使用缓冲的特点可总结为：标准的Send实际利用了MPI环境提供的默认缓冲区；Bsend实际相当于将MPI环境提供的buffer放在用户空间管理；Rsend实际相当于不要缓冲区，但发送端不能提前等待；Ssend实际也相当于不要缓冲区，但允许等待；异步方式下各个模式工作原理也是类似的，只不过可将其理解为MPI环境会另起一个线程在后台做实际的消息传输，通过MPI_Waitxxxx,MPI_Testxxx等机制与MPI进程的主线程进行通信和同步。\n通信模式 阻塞型 非阻塞型 缓冲方式 发送方等待 接收方等待 是否本地 是否阻塞 标准通信 MPI_Send MPI_Isend MPI环境提供的默认缓冲区 是 是 是 是 缓冲通信 MPI_Bsend MPI_Ibsend 用户空间管理 否 是 是 是 就绪通信 MPI_Rsend MPI_Irsend 无 否 是 否 是 同步通信 MPI_Ssend MPI_Issend 无 否 是 否 是 ","date":"2023-07-19T13:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/20230719212254.png","permalink":"https://cuterwrite.top/p/mpi-tutorial/2/","title":"MPI与并行计算（二）：点到点通信"},{"content":" Table of Contents generated with DocToc\nMPI与并行计算（一）：并行环境及编程模型 1. 什么是MPI 2. MPI的发展过程 3. 为什么要用MPI 4. 并行编程模式 5. MPI的工作模式 6. MPI消息传递通信的基本概念 7. MPI程序编译、运行 8. MPI的四个基本接口 MPI与并行计算（一）：并行环境及编程模型 1. 什么是MPI Massage Passing Interface：是消息传递函数库的标准规范，由MPI论坛开发，支持Fortran和C。\n一种新的库描述，不是一种语言。共有上百个函数调用接口，在Fortran和C语言中可以直接对这些函数进行调用。 MPI是一种标准或规范的代表，而不是特指某一个对它的具体实现。迄今为止所有的并行计算机制造商都提供对MPI的支持。 Intel MPI OpenMPI mpich MPI是一种消息传递编程模型，并成为这种编程模型的代表和事实上的标准。 2. MPI的发展过程 MPI 1.1：1995 MPICH:是MPI最流行的非专利实现,由Argonne国家实验室和密西西比州立大学联合开发,具有更好的可移植性. MPI 1.2~2.0：动态进程, 并行 I/O, 支持F90和C++(1997) 3. 为什么要用MPI 高可移植性：MPI已在IBM PC机上、 MS Windows上、所有主要的Unix工作站上和所有主流的并行机上得到实现。使用MPI作消息传递的C或Fortran并行程序可不加改变地运行在IBMPC、 MS Windows、 Unix工作站、以及各种并行机上。 4. 并行编程模式 隐式并行：借助编译器和运行时环境的支持发掘程序的并行性，对串行程序进行并行化。 数据并行：数据并行依靠所处理的数据集合无关性，借助数据划分来驱动程序之间的并行执行。 消息传递：消息传递模型可以通过如下的几个概念加以定义： 一组仅有本地内存空间的进程 进程之间通过发送和接收消息进行通信 进程之间需要使用协同操作完成数据传递，如发送操作必须要求有与之配对的接收操作 共享变量：并行代码分别驻留在不同的处理器上，通过读写公共存储器中的共享变量进行同步和通信，一般适合在多核系统，SMP系统上运行。分布式存储系统可以在运行时库支持下通过自定义机制以共享变量的方式运行。 5. MPI的工作模式 运行方式：以串行方式编写，运行时分别执行不同的块。 资源分配：所有程序元素只要没有进行显示区分，无论是代码、函数、全局变量还是局部变量，都默认的由全部进程共同拥有，所有进程看到的虽然是相同的名字，但在“物理”上却彼此无关。 显示区分：就是指程序员需在程序设计阶段通过显示的条件判断来指定在不同进程上运行不同的代码块。这正是MPI程序的特点，也恰好是难点之一。 一个典型的MPI程序代码模式如下：\n// Inititalization code block if (rank == process1) { // define works to be carried out by process1 } else if (rank == process2) { // define works to be carried out by process2 } else if (rank == process3) { // define works to be carried out by process3 } else if (rank == process4) { // define works to be carried out by process4 }...else if (rank == processn) { // define works to be carried out by processn } else { // define works to be carried out by all processes } 6. MPI消息传递通信的基本概念 消息：一个消息可以比做一个封信。需要定义消息的内容以及消息的发送与接收者。前者称为消息的缓冲(Message Buffer)，后者称为消息信封(Message Envelop)。在MPI中，消息缓冲由三元组\u0026lt;起始地址，数据个数，数据类型\u0026gt;来标识，而消息信封则是由三元组\u0026lt;源/目标进程，消息标签，通讯域\u0026gt;来标识。如下为MPI_Send的消息缓冲和消息信封。 缓冲区：MPI环境定义了3种缓冲区：应用缓冲区，系统缓冲区和用户向系统注册的缓冲区。\n应用缓冲区：保存将要发送或接收的消息内容即上述的消息缓冲。 系统缓冲区：MPI环境为通信所准备的存储空间。 用户缓冲区：指用户向系统注册的缓冲区，用户使用某些API(如MPI_Bsend)时，在程序中显示申请的存储空间，然后注册到MPI环境中供通信所用。 通信子：MPI环境管理进程及通信的基本设施。MPI_COMM_WORLD就是MPI环境启动时默认创建的通信子。对某个进程的操作必须放在通信子内方可有效。\n进程号：进程号即进程的rank，指在某个通信子内某个进程号rank为num。在一个通信子内，每一个进程都有它唯一的num，这个标识号是在进程初始化时由系统分配，从0开始编号。\n进程组：定义一个通信子，也就指定了一组共享该空间的进程，这些进程组成了该通信子的进程组(group)。\n通信协议：MPI环境依据实现的策略不同，可能采用如下一种或几种协议。\n立即通信协议，总是假定目标进程具有保存消息数据的能力。 集中通信协议，在目标准备好之后，才可以执行发送动作。 短消息协议，消息数据与信封封装在一起发送。 7. MPI程序编译、运行 MPI环境安装： 更新apt源：sudo apt-get update 安装build-essential：sudo apt-get install -y build-essential 安装mpich: sudo apt-get install -y mpich MPI程序编译：mpicc Intel MPI Mpich/OpenMPI Fortran mpiifort mpi90 C mpiicc mpicc C++ mpiicpc mpicxx mpicc编译示例\nmpicc -o mpi mpi.c MPI程序运行：mpirun 使用mpirun来运行mpi程序（intel mpi、mpich、openmpi等） 用法：mpirun -n 进程数 可执行文件名 示例：mpirun -n 2 ./example 第一个MPI程序示例 - Hello World\n// mpi.c #include \u0026lt;mpi.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; int main(int argc, char **argv) { MPI_Init(\u0026amp;argc, \u0026amp;argv); printf(\u0026#34;Hello World!\\n\u0026#34;); MPI_Finalize(); return 0; } 编译与运行mpi.c mpicc -o mpi mpi.c mpirun -n 2 ./mpi 注意： root用户运行mpirun时，需要加上\u0026ndash;allow-run-as-root参数，否则会报错。\n8. MPI的四个基本接口 接口名 功能 MPI_Init(\u0026amp;argc, \u0026amp;argv) 初始化MPI环境，MPI系统将通过argc, argv得到命令行参数 MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;myrank) 缺省的通信子为MPI_COMMON_WORLD，获得进程所在缺省通信子的编号，赋值给myrank MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;nprocs) 获得缺省通信子中进程的个数，赋值给nprocs MPI_Finalize() 一般放在程序最后一行，如果没有此行，MPI程序将不会终止 MPI初始化：MPI_Init int MPI_Init(int *argc, char ***argv) MPI_Init是MPI程序的第一个调用，它完成MPI程序的所有初始化工作。所有的MPI程序的第一条可执行语句都是这条语句。 启动MPI环境,标志并行代码的开始. 要求main必须带参数运行,否则出错 MPI结束：MPI_Finalize int MPI_Finalize(void) MPI_FINALIZE是MPI程序的最后一个调用，它结束MPI程序的运行，它是MPI程序的最后一条可执行语句，否则程序的运行结果是不可预知的。 标志并行代码的结束,结束除主进程外其它进程。 之后串行代码仍可在主进程(rank = 0)上运行(如果必须)。 进程号：MPI_Comm_rank int MPI_Comm_rank(MPI_Comm comm, int *rank) MPI_COMM_RANK是MPI程序中的一个重要函数，它返回调用进程在通信子中的进程号，即rank。 通信子：MPI_COMM_WORLD 进程号：rank 进程数：MPI_Comm_size int MPI_Comm_size(MPI_Comm comm, int *size) MPI_COMM_SIZE是MPI程序中的一个重要函数，它返回通信子中的进程数，即size。 通信子：MPI_COMM_WORLD 进程数：size 示例2：打印进程ID和进程数\n// mpi.c #include \u0026lt;mpi.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; int main(int argc, char **argv) { int myrank, nprocs; MPI_Init(\u0026amp;argc, \u0026amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;myrank); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;nprocs); printf(\u0026#34;Hello World! I\u0026#39;m %d of %d\\n\u0026#34;, myrank, nprocs); MPI_Finalize(); return 0; } 结果： root@ubuntu:~# mpicc -o mpi mpi.c root@ubuntu:~# mpirun -n 2 ./mpi Hello World! I\u0026#39;m 0 of 2 Hello World! I\u0026#39;m 1 of 2 ","date":"2023-07-18T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/20230719012753.png","permalink":"https://cuterwrite.top/p/mpi-tutorial/1/","title":"MPI与并行计算（一）：并行环境及编程模型"},{"content":" Table of Contents generated with DocToc\nCUDA编程：从基础到应用 一、什么是CUDA 二、CPU vs. GPU 三、异构计算 四、CUDA编程模型 五、CUDA线程执行模型 六、CUDA原子操作 CUDA编程：从基础到应用 一、什么是CUDA CUDA是NVIDIA推出的一种通用并行计算平台和编程模型，可以利用GPU的强大计算能力来加速各种应用程序。 CUDA的优势在于： 提供了一套简单易用的编程接口，支持C/C++/Fortran/Python等多种语言。 兼容各种操作系统，如Windows/Linux/MacOS等。 支持多种GPU架构，如Tesla/Fermi/Kepler/Maxwell/Pascal/Volta/Turing/Ampere等。 支持多种并行编程模式，如数据并行/任务并行/流并行等。 支持多种优化技术，如共享内存/纹理内存/常量内存/原子操作/同步机制等。 Why CUDA? 串行速度提升已经结束 无法继续提升频率 难以继续降低功耗 当前计算机性能提升趋势 计算机没有变得更快，而是变得更宽 多核CPU、GPU、超级计算机 数据级别并行 同样的指令作用于多个数据 线程级别的并行 二、CPU vs. GPU CPU和GPU都是计算机中的重要组件，但它们有着不同的设计目标和特点。 CPU的特点是： 拥有较少的核心数，但每个核心都有较高的时钟频率和较强的运算能力。 拥有较大的缓存和复杂的控制流机制，可以有效地降低延迟和提高串行代码的性能。 更适合于处理复杂的单任务或少量的多任务，如操作系统/数据库/编译器等。 类比于摩托车，可以灵活地在城市中穿梭。 GPU的特点是： 拥有较多的核心数，但每个核心都有较低的时钟频率和较弱的运算能力。 拥有较小的缓存和简单的控制流机制，可以有效地提高吞吐量和利用大规模并行架构。 更适合于处理大量相似或简单的任务，如图形渲染/科学计算/机器学习等。 类比于大巴车，可以承载更多的乘客。 CPU GPU 缓存 大缓存：掩盖较长的存储器延迟 小缓存：但通过更快的存储提高吞吐量 运算器 强大的运算器：降低运算延迟 更节能的运算器：延迟大但总吞吐量大 控制机制 复杂的控制机制：分支预测等 简单的控制流机制：无分支预测 线程 线程高度轻量级：大量并发 线程高度轻量级：大量并发 三、异构计算 异构计算是指利用不同类型的处理器协同工作来完成一个任务，如CPU+GPU、CPU+FPGA、CPU+ASIC等。 异构计算的优势在于： 可以充分发挥每种处理器的特长，提高性能和效率。 可以降低功耗和成本，延长设备寿命和节约资源。 可以增加灵活性和可扩展性，适应不同场景和需求。 异构计算的挑战在于： 需要设计合适的编程模型和接口，实现不同处理器之间的协调和通信。 需要考虑不同处理器之间的负载均衡和数据一致性，避免性能瓶颈和错误发生。 需要优化不同处理器之间的数据传输和转换，减少开销和延迟。 CPU+GPU 利用CPU处理复杂控制流 利用GPU处理大规模运算 CPU与GPU之间通过PCIe总线通信 新显卡支持NVLink连接（5-12倍PCIe3.0) 四、CUDA编程模型 CUDA编程模型是基于数据并行思想设计的一种分层抽象模型，可以将一个复杂的问题分解为多个简单的子问题，并将其映射到GPU上执行。\nCUDA编程模型包括以下几个层次：\n线程（thread）：线程是CUDA中最基本的执行单元，每个线程都有自己独立的寄存器、指令指针、栈空间等。 块（block）：块是由多个线程组成的一维或二维的逻辑分组，每个块都有自己独立的共享内存、同步机制等。 网格（grid）：网格是由多个块组成的一维或二维的逻辑分组，每个网格都有自己独立的全局内存、常量内存、纹理内存等。 设备（device）：设备是指GPU本身，包括多个流式处理器（SM）、多个CUDA核心（core）、多个缓存、总线等。 主机（host）：主机是指CPU本身，包括内存、硬盘、键盘、鼠标等。 CUDA编程模型的执行流程如下：\n在主机端编写并行代码，称为核函数（kernel），并使用__global__修饰符标记。 在主机端调用核函数，并使用\u0026lt;\u0026lt;\u0026lt; grid,block \u0026gt;\u0026gt;\u0026gt;语法指定网格和块的维度，称为执行配置。 在设备端执行核函数，每个块被分配到一个SM上，每个线程被分配到一个core上。 在设备端完成核函数后，返回主机端继续执行后续代码。 2级架构\n每个GPU拥有多个Streaming Multiprocessor(SM) 具体数目及设计因产品而异 SM共用显存 每个SM拥有多个CUDA core 数目因产品而异 Core共用调度器和指令缓存 2级架构下的执行模型：线程束（warp）\nCUDA线程以32个为一组在GPU上执行 线程束以单指令多线程的方式运行（SIMT） 所有线程在不同数据上执行相同的指令 SMIT、SIMD、SMT 灵活度：SIMD \u0026lt; SIMT \u0026lt; SMT 性能： SIMD \u0026gt; SIMT \u0026gt; SMT SIMT与SIMD相比：多个状态寄存器，多个地址，独立的执行路径 SM负责调度并执行线程束 线程束调度时会产生上下文切换 调度方式因架构而异 Host与device\nHost（CPU）相关：运行在CPU上的代码及主机内存 Device（GPU）相关：运行在GPU上的代码及显存（设备内存） 通过在主机上调用核函数（kernel）执行并行代码 指明host与device代码\n__host__从主机端调用，在主机端执行 __global__从主机端调用，在设备端执行 __device__从设备端调用，在设备端执行 __host__和__device__可以一起使用 \u0026lt;\u0026lt;\u0026lt; 1,4 \u0026gt;\u0026gt;\u0026gt;：执行配置 指明网格中有1个块 每块中有4个线程 cudaDeviceSynchronize() 与OpenMP不同，CUDA核函数为异步执行 核函数限制条件（__global__函数） 只能访问设备内存 必须返回void 不支持可变数量的参数 参数不可为引用类型 不支持静态变量 指明网格及块的维度\n形式为\u0026lt;\u0026lt;\u0026lt; grid,block \u0026gt;\u0026gt;\u0026gt; grid与block为dim3类型 grid与block的大小受到计算能力的限制 GPU架构与线程执行 一个CUDA core执行一个线程 一个SM执行一个block中的线程 GPU中执行grid中的所有线程 确定线程编号 使用内置变量threadIdx、blockIdx、blockDim CUDA编程例子：向量加法 __global__ void VecAdd(int *a, int *b, int *c) { int tid = blockIdx.x; if (tid \u0026lt; N) { c[tid] = a[tid] + b[tid]; } } int main() { ... // Kernel invocation with N threads VecAdd\u0026lt;\u0026lt;\u0026lt;1, N\u0026gt;\u0026gt;\u0026gt;(A, B, C); ... } GPU内存管理：\n创建：cudaMalloc 拷贝：cudaMemcpy 使用cudaMemcpyHostToDevice与cudaMemcpyDeviceToHost指明拷贝方向 释放：cudaFree 处理错误\n使用宏定义 block中最大线程限制：n必须不大于1024\n同一个block只在一个SM上执行：没有充分利用GPU计算资源\n思路：使用多个block\n每个block使用m个thread（如m=32） grid,block设置：\u0026lt;\u0026lt;\u0026lt; n/m, m \u0026gt;\u0026gt;\u0026gt; n无法被m整除？ 需对n/m向上取整 需判断tid是否会超过范围 确定thread的全局编号 五、CUDA线程执行模型 逻辑视图 每个线程块由一个SM执行 由硬件调度 无法控制线程块的执行顺序 硬件视图 所有线程块在硬件上都是一维的 三维线程将沿x-\u0026gt;y-\u0026gt;z的顺序展开到一维 展开后的一维线程每32个形成一个线程束 最后不足32的部分也将创建线程 不活跃 仍将消耗SM资源 线程束调度 线程束切换开销为0 SM保存每个线程束的执行上下文 在整个线程束的生命周期中保存于芯片内 上下文切换没有损失 可切换同一SM上不同线程块的线程束 SM中常驻线程块数量受可用资源限制 资源：程序计数器、寄存器、共享内存 活跃线程束：具备计算资源的线程束 Kepler上最大为64 选定的线程束：被调度到执行单元的线程束（Kepler上最大为4） 符合条件的线程束：准备执行但尚未执行 阻塞的线程束：没做好执行准备（指令参数未就绪，无可用CUDA core） 活跃线程束于延迟隐藏 满载：线程调度器在每个时钟周期都有符合条件的线程束 通过调度符合条件的线程束，可以有效的掩盖指令延迟 算数指令：算数操作从开始到产生输出（10~20时钟周期） 内存指令：发出加载/存储操作到数据到达目的地（全局内存~800时钟周期） 应适当增加活跃线程束 Little\u0026rsquo;s law 线程数不宜过少（每个线程处理的任务数与线程数需要平衡） 线程块资源不易过多（如，共享内存的大小与活跃线程块数量需要平衡） 线程束执行 每个线程束以SIMD方式在SM上执行 线程束内同时执行同样语句 线程束外的视角看来为SIMT 分支分化 线程束出现不同的控制流 性能优化：避免分支分化，因为线程束只能执行相同的逻辑，在执行某一个路径的线程时会禁用另一路径的线程。 busy waiting vs signal busy waiting：如，使用while循环不断检查条件是否满足 signal：当条件满足由系统发送指令 __syncthreads()：只能在线程块内同步，不能在不同的线程块同步 busy waiting的问题：死锁 减少分支分化的影响 减少if语句 尤其是减少基于threadIdx的if语句 使用条件赋值代替条件语句 平衡分支执行时间 避免出现执行时间过长的分支 六、CUDA原子操作 原子指令 执行过程不能分解为更小的部分：不被中断 避免竞争条件出现 竞争条件 程序运行结果依赖于不可控的执行顺序 CUDA原子操作： 基本操作：atomicCAS 其它所有原子操作均可由atomicCAS()实现 CAS：compare and swap 读取目标位置(address)并与预期值(old_val)进行比较 相等则将new_val写入目标位置 不相等则不发生变化 返回目标位置中原值：可用来检查CAS操作是否成功 原子指令与并发控制：原子指令在并发控制中起着重要的作用。在多线程或多进程的环境中，当多个线程或进程尝试同时访问和修改共享数据时，如果没有适当的控制机制，可能会导致数据的不一致性。原子指令通过确保某些操作在执行过程中不会被其他线程或进程中断，来避免这种情况。 竞争条件与死锁：竞争条件是并发编程中的一个主要问题，它发生在两个或更多的线程或进程在无序或未同步的情况下访问和修改共享数据，导致结果不可预测。原子指令是解决竞争条件的一种方法，但也可能引入另一个问题 - 死锁。死锁是指两个或更多的进程或线程互相等待对方释放资源，导致所有进程或线程都无法继续执行。 CUDA原子操作与GPU编程：在GPU编程中，由于大量的线程并行执行，可能会有多个线程同时访问和修改同一块内存。CUDA的原子操作提供了一种机制，使得在这种情况下仍能保证数据的一致性。然而，过度依赖原子操作可能会导致性能下降，因为它们违反了GPU编程的基本原则——并行执行。因此，在设计GPU算法时，应尽量减少原子操作的使用，或者寻找可以避免使用原子操作的算法。 CUDA原子操作的应用：在某些情况下，CUDA原子操作是必要的。例如，在统计或计数问题中，需要多个线程共享一个计数器，并且每个线程都可能需要增加计数器的值。在这种情况下，使用CUDA原子操作可以保证计数器的正确性。另一个例子是图形处理，其中可能需要多个线程同时更新像素的值。使用CUDA原子操作可以避免同时更新导致的数据不一致问题。 ","date":"2023-07-11T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/ba25bc69cbefbfac1287056fee570cee2b6458ff.jpg@1256w_880h_!web-article-pic.avif","permalink":"https://cuterwrite.top/p/cuda-tutorial/","title":"CUDA编程：从基础到应用"},{"content":" Table of Contents generated with DocToc\nSVD与NMF：矩阵分解的两种方法 一、奇异值分解（SVD） 二、非负矩阵分解（NMF） 三、SVD与NMF的比较 四、实战：图像压缩 五、结论 参考资料 SVD与NMF：矩阵分解的两种方法 在数据科学中，矩阵分解技术是一种强大的工具，可以用于各种应用，如推荐系统、图像处理和自然语言处理。在这篇文章中，我们将深入探讨两种流行的矩阵分解技术：奇异值分解（SVD）和非负矩阵分解（NMF）。我们将详细解析它们的理论基础，以及如何在实际问题中应用它们。\n一、奇异值分解（SVD） 奇异值分解是一种在线性代数中常用的矩阵分解方法。对于给定的 $m\\times n$ 矩阵A，我们可以将其分解为三个矩阵的乘积：\n$$ A = U\\Sigma V^T $$\n这里，$U$ 是一个 $m\\times m$ 的正交矩阵，$V$ 是一个 $n\\times n$ 的正交矩阵，$\\Sigma$ 是一个 $m\\times n$ 的对角矩阵。对角线上的元素称为奇异值，它们是 $A^T A$ 的特征值的平方根。它们是按降序排列的，代表了原始矩阵中的“能量”或信息量。。我们可以将奇异值分解看作是一种特征值分解，其中 $U$ 和 $V$ 是特征向量，$\\Sigma$ 是特征值的对角矩阵。\n计算SVD的基本步骤如下：\n构造矩阵A的Gram矩阵：对于给定的 $m\\times n$ 矩阵A，我们可以构造一个 $n\\times n$ 的矩阵 $A^T A$，称为A的Gram矩阵。Gram矩阵是一个对称半正定矩阵，因此它的特征值都是非负的。 计算Gram矩阵的特征值和特征向量：我们可以使用任何标准的特征值分解算法来计算Gram矩阵的特征值和特征向量。这些特征值就是A的奇异值的平方，特征向量则构成了右奇异向量和左奇异向量。我们将特征值按降序排列，将特征向量按相同的顺序排列。 构造奇异值矩阵 $\\Sigma$ ：我将特征值的平方根按照从大到小的顺序排列在对角线上，构成 $m\\times n $ 的对角矩阵 $\\Sigma$ 。 构造左奇异向量矩阵 $U$ 和右奇异向量矩阵 $V$ ：将对应于特征值的特征向量按照特征值的顺序排列，构成 $n\\times n$ 的矩阵 $V$ 和 $m\\times m$ 的矩阵 $U$ 。这些特征向量是标准化的，即它们的长度为1，并且互相正交。 这样，我们就得到了A的奇异值分解。在Python中，我们可以使用NumPy的np.linalg.svd函数来计算SVD，这个函数会自动执行上述步骤，并返回 $ U, \\Sigma, V^T $ 。如下所示：\nimport numpy as np U, S, Vt = np.linalg.svd(A) 需要注意的是，虽然理论上SVD总是存在的，但在实际计算中可能会遇到数值稳定性的问题。此外，对于非常大的矩阵，计算SVD可能会非常耗时。在这些情况下，我们可能需要使用一些更高效的算法或者近似方法，如随机SVD。\nSVD的一个重要应用是在推荐系统中进行矩阵补全。在推荐系统中，我们通常有一个用户-商品评分矩阵，但这个矩阵通常是非常稀疏的，因为大多数用户只评价了少数商品。SVD可以用于预测用户对未评价商品的评分，从而提供个性化的推荐。\n二、非负矩阵分解（NMF） 由于维度的复杂性和维度诅咒，直接处理高维数据需要大量的计算资源。非负矩阵分解（NMF）作为一种降维技术被提出，在图像处理中得到了重要的应用。通过采用NMF，非负的高维矩阵可以被分解成两个非负的低维矩阵，其中一个包括列向量，可以被视为数据空间中的基向量，另一个则包含缩放这些基向量的系数行。此外，NMF也可用于文本数据处理。我们可以检查系数矩阵中的每一列，并确定具有最大系数的行号，其中行号表示原始矩阵中各列的聚类ID。这种聚类特性意味着NMF可以用于数据聚类。\nNMF对矩阵的元素有一个额外的非负约束。对于给定的 $K\\times N$ 非负矩阵 $M\\in R^{K\\times N}$ ，我们可以找到两个非负矩阵 $W$ 和 $H$ ，使得 $M\\approx WH$ 。其中 $W\\in R^{K\\times r}$ 和 $H\\in R^{r\\times N}$ 是两个非负矩阵，即 $W\\geq 0$ 和 $H\\geq 0$ 。矩阵 $W$ 代表捕捉数据特征的基向量，而矩阵 $H$ 是表示每个基向量对重建原始数据的贡献的权重。NMF中的非负约束允许学习整体数据的部分表征，而这种约束在SVD中是不允许的。为了找到 $M\\approx WH$的近似解，定义基于欧氏距离的成本函数来量化近似的质量，即:\n$$ Q=\\Vert M-WH\\Vert^2_F=\\sum_{i,j}(M_{ij}-(WH)_{ij})^2 $$\n由于成本函数 $Q$ 在 $W$ 和 $H$ 中都是非凸的，所以在求解 $Q$ 的最小值过程中找到全局最小值是不现实的。一些数值优化技术，如梯度下降和共轭梯度，可以被用来寻找局部最小值。然而，梯度下降的收敛速度很慢，共轭梯度的实现很复杂。此外，基于梯度的方法对步长的参数设置很敏感，这对现实应用来说并不方便。为此，可以利用 $W$ 和 $H$ 的multiplicative update rules，作为收敛速度和实现复杂性之间的折中方案，具体如下:\n$$ H_{aj} \\leftarrow H_{aj} \\frac{W^T M_{aj}}{W^T W H_{aj}}, W_{ia} \\leftarrow W_{ia} \\frac{M H^T_{ia}}{W H H^T_{ia}} $$\n其中，矩阵 $W$ 和 $H$ 可以被随机初始化，然后通过迭代更新来优化 $Q$ 。这些更新规则可以保证 $Q$ 在每次迭代中都会减少，因此可以保证收敛到局部最小值。\n在Python中，我们可以使用sklearn.decomposition.NMF类来计算NMF。如下所示：\nfrom sklearn.decomposition import NMF model = NMF(n_components=2, init=\u0026#39;random\u0026#39;, random_state=0) W = model.fit_transform(X) H = model.components_ 三、SVD与NMF的比较 虽然SVD和NMF都是矩阵分解技术，但它们有一些重要的区别。\n数据类型和约束：SVD可以应用于任何矩阵，而NMF只能应用于非负矩阵。其次，SVD提供了一种最优的低秩近似，而NMF则没有这种保证。然而，NMF的非负约束使得它的分解更具解释性，这在许多应用中是非常有用的。 分解的解释性：虽然SVD和NMF都可以将原始矩阵分解为一些基本的“构成元素”，但NMF的分解通常更具解释性。这是因为NMF的非负约束使得分解的结果更容易解释和理解。在许多应用中，如主题模型或社区发现，NMF的分解可以直接解释为数据的一些基本模式或特征。 优化和稳定性：SVD的优化问题有闭式解，这意味着我们可以直接计算出最优解。而NMF的优化问题通常需要使用迭代方法来求解，如梯度下降或坐标下降。这使得NMF的计算过程可能更复杂，而且可能需要更多的时间。而且SVD的结果是唯一的（除了奇异向量的符号），而NMF的结果可能依赖于初始化和优化算法。这意味着对同一个数据集，NMF可能会给出不同的结果。 近似质量：SVD提供了一种最优的低秩近似，即它可以找到最接近原始矩阵的低秩矩阵。而NMF则没有这种保证，它的近似质量可能会比SVD差。然而，NMF的非负约束使得它的近似可能更符合实际的需求，尤其是在那些原始数据是非负的情况下。 计算复杂性：SVD和NMF的计算复杂性也有所不同。对于一个 $m\\times n$ 的矩阵，SVD的计算复杂性大约为 $\\mathbf{O}(\\min {m^2n, mn^2})$ ，而NMF的计算复杂性则取决于迭代次数和所选的优化算法。在实践中，NMF通常比SVD更慢，但也有一些高效的NMF算法可以缩短计算时间。 总的来说，SVD和NMF各有优势，选择使用哪一种技术取决于具体的应用和需求。\n四、实战：图像压缩 让我们通过一个实战演示来看看如何使用SVD和NMF进行图像压缩。我们将使用Python的NumPy和scikit-learn库来执行这些任务。\n首先，我们需要导入必要的库，并加载一张图像：\nimport numpy as np from sklearn.decomposition import NMF from PIL import Image # 加载图像 img = Image.open(\u0026#39;image.jpg\u0026#39;) width, height = img.size img = np.array(img) r, g, b = img[:, :, 0], img[:, :, 1], img[:, :, 2] img_matrix = [] img_matrix.extend([r.flatten(), g.flatten(), b.flatten()]) M = np.array(img_matrix).T 然后，我们可以使用NumPy的np.linalg.svd函数来进行SVD，得到 $U, S, V^T$ ：\n# 执行SVD U, s, Vt = np.linalg.svd(M, full_matrices=False) 我们可以选择前 $r$ 个奇异值和对应的 $U$ 和 $V^T$ 的列来进行低秩近似：\nd = 16 U_d = U[:, :d] s_d = s[:d] Vt_d = Vt[:d, :] M_d = U_d @ np.diag(s_d) @ Vt_d r, g, b = M_d[:, 0], M_d[:, 1], M_d[:, 2] img = np.dstack((r, g, b)).reshape(height, width, 3) img[img \u0026lt; 0] = 0 img[img \u0026gt; 255] = 255 img = Image.fromarray(np.uint8(img), mode=\u0026#39;RGB\u0026#39;) img.show() 同样，我们也可以使用scikit-learn的NMF类来进行NMF：\n# 执行NMF model = NMF(n_components=16, init=\u0026#39;random\u0026#39;, random_state=0) W = model.fit_transform(M) H = model.components_ M_d = W @ H r, g, b = M_d[:, 0], M_d[:, 1], M_d[:, 2] img = np.dstack((r, g, b)).reshape(height, width, 3) img[img \u0026lt; 0] = 0 img[img \u0026gt; 255] = 255 img = Image.fromarray(np.uint8(img), mode=\u0026#39;RGB\u0026#39;) img.show() 最后，我们可以比较原始图像和重构图像的差异，以及SVD和NMF的压缩效果。这种压缩方法的优点是可以大大减少存储和传输图像所需的数据量，而且如果选择的秩r足够大，压缩后的图像的质量也可以接受。\n五、结论 总的来说，SVD和NMF都是强大的矩阵分解技术，它们在许多数据科学应用中都有广泛的用途。虽然SVD提供了一种最优的低秩近似，但NMF的非负约束使得它的分解更具解释性。在选择使用哪一种技术时，我们需要考虑我们的具体需求，以及我们的数据是否满足这些技术的要求。\n参考资料 [1] Lee, Daniel, and H. Sebastian Seung. \u0026ldquo;Unsupervised learning by convex and conic coding. \u0026quot; Advances in neural information processing systems 9 (1996).\n[2] Lee, Daniel D., and H. Sebastian Seung. \u0026ldquo;Learning the parts of objects by non-negative matrix factorization.\u0026rdquo; Nature 401.6755 (1999): 788-791.\n[3] Lee, Daniel, and H. Sebastian Seung. \u0026ldquo;Algorithms for non-negative matrix factorization. \u0026quot; Advances in neural information processing systems 13 (2000).\n","date":"2023-07-11T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/65cf6588fa725014c7cd617ccbeb997f27742e49.jpg@1256w_1880h_!web-article-pic.jpg","permalink":"https://cuterwrite.top/p/matrix-factorization/","title":"SVD与NMF：矩阵分解的两种方法"},{"content":" Table of Contents generated with DocToc\n最小反馈弧集合问题 一、引言 二、问题定义 三、解决方案 1. GreedyFAS 2. SortFAS 3. PageRankFAS 四、实际应用 最小反馈弧集合问题 一、引言 在复杂网络分析、社会学、生物信息学等领域，我们经常需要处理的一个问题是如何从一个有向图中移除最少的边，使得图中不再存在环。这个问题被称为最小反馈弧集问题（Minimum Feedback Arc Set，简称MinFAS）。在本文中，我们将详细介绍这个问题的定义、性质，以及一些常见的解决算法。我们还将讨论这个问题在实际应用中的一些例子。\n二、问题定义 首先，我们来详细定义一下最小反馈弧集问题。给定一个有向图G=(V, E)，其中V是顶点集，E是边集。给定有向图G(V,E)，集合F是E的一个子集，若G的生成子图G′(V,E−F)中不包含环，则称F是G的一个反馈弧集合。容易推出：若有向图G包含环，则其每个环至少有一条边在F中。我们将基数最小的反馈弧集合称为最小反馈弧集合。最小反馈弧集合问题就是在给定有向图G的情况下，求解最小反馈弧集合F。\n例如：$ F={(1, 2), (4, 5)} $ 在这个问题中，我们的目标是找到最小的反馈弧集，也就是说，我们希望找到尽可能少的边，使得去掉这些边后图中不再有环。这个问题在许多实际应用中都有重要的意义。例如，在社会网络分析中，我们可以通过这个问题来找出社区内的关键人物；在生物信息学中，我们可以通过这个问题来找出基因调控网络中的关键基因。\n最小反馈弧集问题已经被证明是一个NP难问题。这意味着，我们无法在多项式时间内找到这个问题的精确解（除非P=NP）。然而，尽管这个问题很难，但是我们仍然可以通过一些方法来找到它的近似解。在理论计算机科学中，有一类算法被称为近似算法，它们可以在多项式时间内找到问题的近似解。对于最小反馈弧集问题，我们也可以使用这类算法来求解。在接下来的部分中，我们将介绍一些常见的近似算法。\n三、解决方案 对于最小反馈弧集问题，我们有多种解决方案，其中包括贪心算法（GreedyFAS）、排序算法（SortFAS）和基于PageRank的算法（PageRankFAS）。\n1. GreedyFAS GreedyFAS算法的核心思想在于用贪心法生成一个线性排列，将该线性排列中的后向边集作为结果返回。该算法的伪代码如下图所示： 对任一有向图G，GreedyFAS算法使用的贪心策略为：\n查找源头点（入度为0的点）。若查到源头点则排在序列 $s_1$ 末尾并移除该点，重复直到 $G$ 无源头点。 查找汇集点（出度为0的点）。若查到汇集点则排在序列 $s_2$ 首部并移除该点，重复直到 $G$ 无汇集点。 计算剩余点的 $\\delta$ 值（出度与入度的差值），将 $\\delta$ 值最大的点排在 $s_1$ 末尾并移除该点。 重复上述过程直到 $G$ 不存在任何点。 返回序列 $s_1 s_2$ 。 2. SortFAS SortFAS算法的基本思想是该算法根据序号的自然顺序生成初始最小线性排列问题（LA），不断调整LA使后向边的数量尽可能少。该算法的伪代码如下图所示： 对任一有向图G，SortFAS算法的步骤如下：\n生成初始最小线性排列问题（LA）。 对于LA中的每个序号v，记录全局变量val，初始化为0，表示调整后新增的后向边数。记录v的位置loc。记录最小值min=0 从序号loc-1开始，向前遍历LA得到序号w，若v-\u0026gt;w存在则val\u0026ndash;，否则val++。 如果val小于等于min，则赋值min=val，记录位置loc=w 在位置loc插入序号v 3. PageRankFAS PageRankFAS算法的核心思想在于将原始图的强连通分量转换为线图，然后用PageRank算法评估线图中节点的重要性，然后依次删除线图中PageRank值最高的节点对应的边。该算法的伪代码如下图所示：\n对任一有向图G，PageRankFAS的算法步骤如下：\n检测图是否有环，如果存在环，执行以下循环：\n识别有向图中的强连接分量 $s_i, i=0,1,\\cdots$ 遍历强连通分量 $s_i$ ，对于每个强连通分量 $s_i$ ，执行： 如果 $s-i$ 的大小小于等于1，跳过该强连通分量的处理。 选择 $s_i$ 中的一个随机节点 $v$ ，从 $v$ 开始遍历创建 $s_i$ 的线图 $L(s_i)$ 计算 $L(s_i)$ 的PageRank值。 选择 $L(s_i)$ 中PageRank值最大的节点，找到 $s_i$ 中对应的边 $e$ ，添加到最小反馈弧集。 在 $G$ 中删除边 $e$ 。 如果仍有环，重复执行1和2，直到图不存在环为止。 四、实际应用 最小反馈弧集问题在许多领域都有广泛的应用。例如，在生物信息学中，我们可以通过求解最小反馈弧集问题，来找出基因调控网络中的关键基因。在这种情况下，我们通常将基因调控网络表示为一个有向图，其中的顶点代表基因，边代表基因之间的调控关系。然后，我们可以通过求解最小反馈弧集问题，来找出那些对整个网络有重要影响的基因。\n在社会网络分析中，我们可以通过求解最小反馈弧集问题，来检测社区内的关键人物。在这种情况下，我们通常将社区表示为一个有向图，其中的顶点代表人，边代表人之间的关系。然后，我们可以通过求解最小反馈弧集问题，来找出那些对整个社区有重要影响的人。\n","date":"2023-07-11T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/20230711173143.png","permalink":"https://cuterwrite.top/p/fas/","title":"最小反馈弧集合问题"},{"content":" Table of Contents generated with DocToc\nRDMA: Soft-RoCE环境搭建实验 1. RoCE简介 2. RoCE的协议层次 3. RoCE的优势 4. Soft-RoCE 5. 部署实验 5.1. 实验环境 5.2. 部署RDMA软件栈 5.2.1. 确认当前内核是否支持RXE 5.2.2. 安装用户态动态链接库 5.2.3. 安装iproute2和perftest 5.3. 配置RXE网卡 5.4. 执行perftest测试 RDMA: Soft-RoCE环境搭建实验 1. RoCE简介 RoCE是三大RDMA协议之一，全称为RDMA Over Converged Ethernet，即基于融合以太网的RDMA。它是一种基于传统以太网的部分下层协议，在其基础上实现InfiniBand的部分上层协议。\nRoCE的发展历史如下：\n1999年，由Compaq, Dell, HP, IBM, Intel, Microsoft和Sun公司组成了IBTA组织。愿景是设计一种更高速的新的互联协议规范标准，来应对传统以太网在面对未来计算机行业的发展时可能遇到的瓶颈。\n2000年，IBTA组织设计并发布了Infiniband Architecture Specification 1.0（IB规范）。\n2007年，IETF发布了iWARP（Internet Wide Area RDMA Protocol）的一系列RFC。\n2010年，IBTA发布了RoCE v1规范。\n2014年，IBTA发布了RoCE v2规范。\n2. RoCE的协议层次 首先是二层的以太网链路帧，然后是IP报文头和UDP报文头，最后是各层级协议的校验。而Infiniband传输层报文实际上是UDP层的负载，也就是深蓝色背景的部分。UDP报文头中有一个字段Destination Port Number（目的端口号），对于RoCE v2来说固定是4791，当对端网卡收到报文后，会根据该字段识别是普通的以太网数据包，还是RoCE数据包，或者是其他协议的数据包，然后再进行解析。深蓝色背景的IB传输层部分又分成了IB报头，实际的用户数据（Payload）以及校验部分。\n3. RoCE的优势 为什么我们有了Infiniband协议之后，还要设计RoCE协议呢？最主要的原因还是成本问题：由于Infiniband协议本身定义了一套全新的层次架构，从链路层到传输层，都无法与现有的以太网设备兼容。也就是说，如果某个数据中心因为性能瓶颈，想要把数据交换方式从以太网切换到Infiniband技术，那么需要购买全套的Infiniband设备，包括网卡、线缆、交换机和路由器等等。商用级设备由于对可靠性有比较高的要求，所以这一套下来是非常昂贵的。\n而RoCE协议的出现解决了这一问题，如果用户想要从以太网切换到RoCE，那么只需要购买支持RoCE的网卡就可以了，线缆、交换机和路由器（RoCE v1不支持以太网路由器）等网络设备都是兼容的——因为我们只是在以太网传输层基础上又定义了一套协议而已。\n所以RoCE相比于Infiniband，主要还是省钱，当然性能上相比Infiniband还是有一些损失，毕竟人家是全套重新设计的。\n至于iWARP，相比于RoCE协议栈更复杂，并且由于TCP的限制，只能支持可靠传输，即无法支持UD等传输类型。所以目前iWARP的发展并不如RoCE和Infiniband。\n4. Soft-RoCE 虽然RoCE相比Infiniband具有兼容性优势，价格也便宜，但是实际应用的时候依然需要专用的网卡支持。\nRoCE本身确实可以由软件实现，也就是本节即将介绍的Soft-RoCE，但是商用的时候，几乎不会有人用软件实现的RoCE。RDMA技术本身的一大特点就是“硬件卸载”，即把本来软件（CPU）做的事情放到硬件中实现以达到加速的目的。CPU主要是用来计算的，让它去处理协议封包和解析以及搬运数据，这是对计算资源的浪费。所以RoCE网卡会把TCP/IP协议栈放到硬件中实现以解放CPU，让它去做更重要的事。\n我们说回Soft-RoCE，它由IBM和Mellanox牵头的IBTA RoCE工作组实现。本身的设计初衷有几点：\n降低RoCE部署成本：Soft-RoCE可以使不具备RoCE能力的硬件和支持RoCE的硬件间进行基于IB语义的交流，这样可以免于替换网络中的一些非关键节点的旧型号网卡。\n相比TCP提升性能：虽然软件实现IB传输层带来了一定的开销，但是相比基于Socket-TCP/IP的传统通信方式，Soft-RoCE因为减少了系统调用（只在软件通知硬件下发了新SQ WQE时才会使用系统调用），发送端的零拷贝以及接收端的只需要单次拷贝等原因，仍然带来了性能上的提升。\n便于开发和测试RDMA程序：有了Soft-RoCE，我们基于Verbs API编写的程序，就可以不依赖于硬件执行起来，可以很方便地运行程序。\n实现原理\nSoft-RoCE就是把本来应该卸载到硬件的封包和解析工作，又拿到软件来做。其本身是基于Linux内核的TCP/IP协议栈实现的，网卡本身并不感知收发的数据包是RoCE报文，其驱动程序按照IB规范中的报文格式将用户数据封装成IB传输层报文，然后把报文整体当做数据填入Socket Buffer当中，由网卡进行下一步收发包处理。\n5. 部署实验 5.1. 实验环境 本实验主要使用Ubuntu 20.04 64位作为系统环境，采用2台2核4GB云服务器作为Soft-RoCE的部署环境。\n节点 IP地址 RDMA设备名 node1 172.16.16.10 node1 node2 172.16.16.6 node2 5.2. 部署RDMA软件栈 5.2.1. 确认当前内核是否支持RXE cat /boot/config-$(uname -r) | grep RXE 如果CONFIG_RDMA_RXE的值为y或者m，表示当前的操作系统可以使用RXE。\n5.2.2. 安装用户态动态链接库 sudo apt-get install libibverbs1 ibverbs-utils librdmacm1 libibumad3 ibverbs-providers rdma-core 这几个软件包的作用如下：\n软件包名 主要功能 libibverbs1 ibverbs动态链接库 ibverbs-utils ibverbs示例程序 librdmacm1 rdmacm动态链接库 libibumad3 ibumad动态链接库 ibverbs-providers ibverbs各厂商用户态驱动（包括RXE） rdma-core 文档及用户态配置文件 安装完上述软件之后，可以执行ibv_devices看看有没有报错：\n这是个基于verbs接口编写的小程序，用来获取并打印出当前系统中的RDMA设备列表。\n查看安装的版本：\ndpkg -L libibverbs1 可以看到安装的版本是1.14.19.0\n5.2.3. 安装iproute2和perftest iproute2是用来替代net-tools软件包的，是一组开源的网络工具集合，比如用更强大ip命令替换了以前常用的ifconfig。我们需要其中的rdma工具来对RXE进行配置。一般的操作系统都已经包含了，安装也很简单：\nsudo apt-get install iproute2 perftest是一个基于Verbs接口开发的开源RDMA性能测试工具，可以对支持RDMA技术的节点进行带宽和时延测试。相比于rdma-core自带的示例程序 ，功能更加强大，当然也更复杂。使用如下命令安装：\nsudo apt-get install perftest 5.3. 配置RXE网卡 首先我们需要加载内核驱动，modprobe会自动加载依赖的其他驱动。\nsudo modprobe rdma_rxe 然后进行用户态配置：\nsudo rdma link add rxe_0 type rxe netdev eth0 其中rxe_0是你希望的RDMA的设备名，可任意取名。eth0为Soft-RoCE设备所绑定的网络设备名，也就是ifconfig中看到的网卡名。\n接着我们用rdma工具查看是否添加成功：\nrdma link 再次运行ibv_devices程序，可以看到RXE网卡已经出现在设备列表里。\n也可以运行ibv_devinfo -d node1命令查看虚拟RDMA设备的信息。\n5.4. 执行perftest测试 分别在两端执行以下命令：\nib_send_bw -d node2 以及：\nib_send_bw -d node1 172.16.16.6 ib_send_bw是用来测试SEND操作的带宽的程序（infiniband_send bandwidth），其中 \u0026lt;server_ip\u0026gt; 表示对端的IP\n两端的结果如下，Server端：\nClient端：\n可以看到两端都打印出了一些测试信息以及最后的测试结果，也就是带宽信息。\n","date":"2023-02-11T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/86.png","permalink":"https://cuterwrite.top/p/soft-roce/","title":"RDMA：Soft-RoCE环境搭建实验"},{"content":"Table of Contents generated with DocToc\n基于Flink Native Kubernetes的词频统计实验 1 简介 1.1 实验环境 1.2 集群规划 2 Kubernetes集群部署 3 Flink Native Kubernetes部署 3.1 配置flink用户权限 3.2 创建session cluster 4 编写WordCount程序 5 实验结果 基于Flink Native Kubernetes的词频统计实验 1 简介 1.1 实验环境 本实验主要使用Ubuntu 20.04 64位作为系统环境，采用3台4核8GB云服务器作为Kubernetes集群部署机器，1台4核8GB云服务器作为集群管理工具Kuboard Spary部署机器，并作为NFS Server部署机器。使用的软件如下：\n名称 版本 kuboard spary v1.2.3-amd64 kubernetes v1.25.4 calico v3.23.3 etcd v3.5.5 crictl v1.25.0 crun 1.4.5 krew v0.4.3 runc v1.1.4 cni v1.1.1 nerdctl 1.0.0 coredns v1.8.6 dnsautoscaler 1.8.5 pod_infra 3.7 flink 1.16.0 hadoop 3.2.3 1.2 集群规划 Kuborad Spary 主机名 IP kuborad 192.168.0.15 NFS Server 主机名 IP NFS-server 192.168.0.15 Kubernetes集群规划 主机名 IP 控制节点 etcd节点 工作节点 node1 192.168.0.6 是 是 是 node2 192.168.0.7 是 是 是 node3 192.168.0.14 是 是 是 2 Kubernetes集群部署 这部分内容已经在Spark on K8s实验中给出详细步骤，这里不再重复。 3 Flink Native Kubernetes部署 3.1 配置flink用户权限 创建用户flink并配置权限 kubectl create serviceaccount flink -n bigdata kubectl create clusterrolebinding flink-role-binding-flink \\ --clusterrole=edit \\ --serviceaccount=bigdata:flink 3.2 创建session cluster 在安装了Flink的节点上进入flink根目录，执行以下命令并指定资源：\n./bin/kubernetes-session.sh \\ -Dkubernetes.namespace=bigdata \\ -Dkubernetes.jobmanager.service-account=flink \\ -Dkubernetes.rest-service.exposed.type=NodePort \\ -Dkubernetes.cluster-id=flink-session-cluster \\ -Dtaskmanager.memory.process.size=2048m \\ -Dkubernetes.taskmanager.cpu=1 \\ -Dkubernetes.jobmanager.replicas=1 \\ -Dtaskmanager.numberOfTaskSlots=3 \\ -Dresourcemanager.taskmanager-timeout=3600000 可以看到，控制台提示创建成功，并且提示了Flink Web UI的访问地址为：http://192.168.0.6:32077，可以看到Web UI界面如下：\n继续在flink根目录下执行以下命令，将官方自带的WindowJoin任务提交到session cluster测试部署是否成功：\n./bin/flink run -d \\ --target kubernetes-session \\ -Dkubernetes.namespace=bigdata \\ -Dkubernetes.cluster-id=flink-session-cluster \\ -Dkubernetes.service-account=flink \\ -Dkubernetes.namespace=bigdata \\ -Dkubernetes.taskmanager.cpu=1 \\ examples/streaming/WindowJoin.jar 可以看到WindowJoin.jar已经被提交到session cluster，占用1个Slot，总共Slot数为4\n4 编写WordCount程序 配置POM文件： \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;com.cuterwrite\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;FlinkApp\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;flink.version\u0026gt;1.16.0\u0026lt;/flink.version\u0026gt; \u0026lt;maven.compiler.source\u0026gt;11\u0026lt;/maven.compiler.source\u0026gt; \u0026lt;maven.compiler.target\u0026gt;11\u0026lt;/maven.compiler.target\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!-- Flink dependencies --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.flink\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;flink-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${flink.version}\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.flink\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;flink-streaming-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${flink.version}\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-shade-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.1\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;shade\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;artifactSet\u0026gt; \u0026lt;excludes\u0026gt; \u0026lt;exclude\u0026gt;com.google.code.findbugs:jsr305\u0026lt;/exclude\u0026gt; \u0026lt;/excludes\u0026gt; \u0026lt;/artifactSet\u0026gt; \u0026lt;filters\u0026gt; \u0026lt;filter\u0026gt; \u0026lt;!-- Do not copy the signatures in the META-INF folder. Otherwise, this might cause SecurityExceptions when using the JAR. --\u0026gt; \u0026lt;artifact\u0026gt;*:*\u0026lt;/artifact\u0026gt; \u0026lt;excludes\u0026gt; \u0026lt;exclude\u0026gt;META-INF/*.SF\u0026lt;/exclude\u0026gt; \u0026lt;exclude\u0026gt;META-INF/*.DSA\u0026lt;/exclude\u0026gt; \u0026lt;exclude\u0026gt;META-INF/*.RSA\u0026lt;/exclude\u0026gt; \u0026lt;/excludes\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;/filters\u0026gt; \u0026lt;transformers\u0026gt; \u0026lt;transformer implementation=\u0026#34;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\u0026#34;\u0026gt; \u0026lt;!-- Replace this with the main class of your job --\u0026gt; \u0026lt;mainClass\u0026gt;com.cuterwrite.WordCount\u0026lt;/mainClass\u0026gt; \u0026lt;/transformer\u0026gt; \u0026lt;transformer implementation=\u0026#34;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer\u0026#34;/\u0026gt; \u0026lt;/transformers\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; 编写WordCount.java： package com.cuterwrite; import org.apache.flink.api.common.functions.FlatMapFunction; import org.apache.flink.api.java.tuple.Tuple2; import org.apache.flink.streaming.api.datastream.DataStreamSource; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; import org.apache.flink.streaming.api.functions.sink.SinkFunction; import org.apache.flink.streaming.api.windowing.assigners.TumblingProcessingTimeWindows; import org.apache.flink.streaming.api.windowing.time.Time; import org.apache.flink.util.Collector; import org.slf4j.LoggerFactory; import org.slf4j.Logger; public class WordCount { private static final Logger log = LoggerFactory.getLogger(WordCount.class); public WordCount() {} public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); env.setParallelism(3); // 监听9999端口的socket输入 DataStreamSource\u0026lt;String\u0026gt; text = env.socketTextStream(\u0026#34;192.168.0.6\u0026#34;, 9999); text.flatMap(new FlatMapFunction\u0026lt;String, Tuple2\u0026lt;String, Integer\u0026gt;\u0026gt;() { @Override public void flatMap(String value, Collector\u0026lt;Tuple2\u0026lt;String, Integer\u0026gt;\u0026gt; collector) throws Exception { String[] tokens = value.toLowerCase().split(\u0026#34; \u0026#34;); for (String token : tokens) { collector.collect(new Tuple2\u0026lt;\u0026gt;(token, 1)); } } // 合并相同单词的频数 }) .keyBy(item -\u0026gt; item.f0) .window(TumblingProcessingTimeWindows.of(Time.seconds(5))) .sum(1) .addSink(new SinkFunction\u0026lt;Tuple2\u0026lt;String, Integer\u0026gt;\u0026gt;() { @Override public void invoke(Tuple2\u0026lt;String, Integer\u0026gt; value, Context context) throws Exception { log.info(\u0026#34;单词：\u0026#34; + value.f0 + \u0026#34;,频率：\u0026#34; + value.f1); } }); env.execute(\u0026#34;Word Count\u0026#34;); } } 5 实验结果 提交WordCount程序jar包\n./bin/flink run -d \\ --target kubernetes-session \\ -Dkubernetes.namespace=bigdata \\ -Dkubernetes.cluster-id=flink-session-cluster \\ -Dkubernetes.service-account=flink \\ -Dkubernetes.namespace=bigdata \\ /root/FlinkApp-1.0-SNAPSHOT.jar 查看Flink Web UI：\n使用socket传输字符进行测试：\nnc 192.168.0.6 9999 实验结果：\n","date":"2022-12-23T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/YSFD_P2_50.png","permalink":"https://cuterwrite.top/p/flink-native-k8s/","title":"基于Flink Native Kubernetes的词频统计实验"},{"content":"Table of Contents generated with DocToc\n基于Spark on k8s的词频统计实验 1 简介 1.1 实验环境 1.2 集群规划 2 部署Kubernetes集群 2.1 安装Kuboard-Spray 2.2 加载离线资源包 2.3 安装Kubernetes集群 3 部署Spark on k8s 3.1 制作spark容器镜像 3.2 创建命名空间 3.3 配置spark用户权限 3.4 配置spark历史服务器 4 编写WordCount程序 5 实验结果 基于Spark on k8s的词频统计实验 1 简介 1.1 实验环境 本实验主要使用Ubuntu 20.04 64位作为系统环境，采用6台4核8GB云服务器作为Kubernetes集群部署机器，1台2核4GB云服务器作为集群管理工具Kuboard Spary部署机器，1台2核4GB云服务器作为NFS Server（使用Centos 7.6系统）部署机器。\n使用的软件如下：\n名称 版本 kuboard spary v1.2.3-amd64 kubernetes v1.25.4 calico v3.23.3 etcd v3.5.5 crictl v1.25.0 crun 1.4.5 krew v0.4.3 runc v1.1.4 cni v1.1.1 nerdctl 1.0.0 coredns v1.8.6 dnsautoscaler 1.8.5 pod_infra 3.7 spark 3.3.1 hadoop 3.2.3 1.2 集群规划 Kuborad Spary 主机名 IP kuborad 192.168.0.115 NFS Server 主机名 IP NFS-server 192.168.0.132 Kubernetes集群规划 主机名 IP 控制节点 etcd节点 工作节点 node1 192.168.0.76 是 是 是 node2 192.168.0.213 是 是 是 node3 192.168.0.2 是 是 是 node4 192.168.0.41 否 否 是 node5 192.168.0.73 否 否 是 node6 192.168.0.12 否 否 是 2 部署Kubernetes集群 2.1 安装Kuboard-Spray Kuboard-Spray 是一款可以在图形界面引导下完成 Kubernetes 高可用集群离线安装的工具，开源仓库的地址为 Kuboard-Spray\n在kuborad节点上安装docker-ce\n# 1. 安装必备的系统工具 sudo apt-get remove docker docker-engine docker.io containerd runc; sudo apt-get install apt-transport-https ca-certificates curl gnupg2 software-properties-common; # 2. 安装GPG证书 curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/docker.gpg; # 3. 写入软件源信息 echo \\ \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/docker.gpg] https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/ubuntu \\ $(lsb_release -cs) stable\u0026#34; | sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null # 4. 更新并安装Docker-CE sudo apt-get update; sudo apt-get install docker-ce; # 5. 配置docker镜像加速器(可以在阿里云获取地址) sudo mkdir -p /etc/docker; sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://docker.mirrors.ustc.edu.cn\u0026#34;, \u0026#34;https://cr.console.aliyun.com/\u0026#34; ] } EOF sudo systemctl daemon-reload; sudo systemctl restart docker; 在kuboard节点上执行以下命令：\ndocker run -d \\ --privileged \\ --restart=unless-stopped \\ --name=kuboard-spray \\ -e TZ=Asia/Shanghai \\ -p 80:80/tcp \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v ~/kuboard-spray-data:/data \\ eipwork/kuboard-spray:v1.2.3-amd64 在浏览器打开地址 http://这台机器的IP，输入用户名 admin，默认密码 Kuboard123，即可登录 Kuboard-Spray 界面。\n2.2 加载离线资源包 在 Kuboard-Spray 界面中，导航到 系统设置 \u0026ndash;\u0026gt; 资源包管理 界面，可以看到已经等候您多时的 Kuboard-Spray 离线资源包，如下图所示\n点击 导入 按钮，在界面的引导下完成资源包的加载。\n2.3 安装Kubernetes集群 在 Kuboard-Spray 界面中，导航到 集群管理 界面，点击界面中的 添加集群安装计划 按钮，填写表单如下：\n集群名称： 自定义名称，本文中填写为 kuboard，此名称不可以修改；\n资源包：选择前面步骤中导入的离线资源包。\n点击 确定 按钮后，将进入集群规划页面，在该界面中添加每个集群节点的连接参数并设置节点的角色，如下图所示：\n重要： kuboard-spray 所在机器不能当做 K8S 集群的一个节点，因为安装过程中会重启集群节点的容器引擎，这会导致 kuboard-spray 被重启掉。\n注意：\n最少的节点数量是 1 个； ETCD 节点、控制节点的总数量必须为奇数； 点击上图的 保存 按钮，再点击 执行 按钮，可以启动集群的离线安装过程，安装结果如下：\n3 部署Spark on k8s 3.1 制作spark容器镜像 下载spark-3.3.1-bin-hadoop3\nwget https://mirrors.pku.edu.cn/apache/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz; tar -xzf spark-3.3.1-bin-hadoop.tgz; mv spark-3.3.1-bin-hadoop spark; 修改Dockerfile默认apt源加速\ncd spark/kubernetes/dockerfiles/spark; // 修改Dockerfile内容 // 修改前： sed -i \u0026#39;s/http:\\/\\/deb.\\(.*\\)/https:\\/\\/deb.\\1/g\u0026#39; /etc/apt/sources.list // 修改后： sed -i \u0026#39;s#http://deb.debian.org#https://mirrors.ustc.edu.cn#g\u0026#39; /etc/apt/source.list sed -i \u0026#39;s|security.debian.org/debian-security|mirrors.ustc.edu.cn/debian-security|g\u0026#39; /etc/apt/source.list 构建docker镜像\ncd spark/bin; // -r \u0026lt;repo\u0026gt; -t \u0026lt;tag\u0026gt; ./docker-image-tool.sh -r cuterwrite -t 0.1 build; 推送镜像到阿里云仓库（参考容器镜像服务-\u0026gt;实例列表-\u0026gt;镜像仓库）\ndocker login --username=[阿里云账号] registry.cn-hangzhou.aliyuncs.com; docker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/[repository]:[镜像版本号]; docker push registry.cn-hangzhou.aliyuncs.com/[repository]:[镜像版本号]; 3.2 创建命名空间 访问Kuboard，通常默认用户名为 admin，默认密码为 Kuboard123，访问地址为第一个控制节点的 80 端口（取决于安装时的参数），如下图所示：\n点击进入default集群，在下图所示的页面点击创建spark命名空间：\n3.3 配置spark用户权限 创建用户spark并配置权限\nkubectl create serviceaccount spark kubectl create clusterrolebinding spark-role --clusterrole=edit --serviceaccount=spark:spark --namesparce=spark 3.4 配置spark历史服务器 创建一个名为spark-history-server的deployment，配置如下：\n容器信息：\n名称：spark-history-server\n容器镜像：registry.cn-hangzhou.aliyuncs.com/[用户名]/spark:0.1（需配置仓库仓库名和密码）\n环境变量：SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=hdfs://192.168.0.238:8020/sparkhistory（需提前部署HDFS)\n容器端口：18080，端口名称http\n参数：[\u0026quot;/opt/spark/bin/spark-class\u0026quot;, \u0026ldquo;org.apache.spark.deploy.history.HistoryServer\u0026rdquo;]\n服务信息：\n端口：18080\n协议：TCP\n目标端口：18080\nNodePort：30080\n类型：NodePort\n测试配置是否成功：\n./spark-submit \\ --master k8s://https://127.0.0.1:6443 \\ --deploy-mode cluster \\ --name spark-pi \\ --class org.apache.spark.examples.SparkPi \\ --conf spark.kubernetes.executor.request.cores=1 \\ --conf spark.kubernetes.executor.limit.cores=1 \\ --conf spark.kubernetes.driver.limit.cores=1 \\ --conf spark.kubernetes.driver.request.cores=1 \\ --conf spark.eventLog.enabled=true \\ --conf spark.eventLog.dir=hdfs://192.168.0.238:8020/sparkhistory \\ --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \\ --conf spark.kubernetes.namespace=bigdata \\ --conf spark.executor.instances=2 \\ --conf spark.kubernetes.file.upload.path=/tmp \\ --conf spark.kubernetes.container.pullSecrets=aliyun-repository \\ --conf spark.kubernetes.container.image=registry.cn-hangzhou.aliyuncs.com/cuterwrite/spark:0.1 \\ hdfs://192.168.0.238:8020/user/root/jars/spark-examples_2.12-3.3.1.jar 提交任务成功后可以在Kuboard管理界面看到一个新启动的容器组：\n访问spark历史服务器，可以看到以下记录：\n4 编写WordCount程序 WordCount.java\npackage com.cuterwrite; import org.apache.spark.api.java.function.FlatMapFunction; import org.apache.spark.sql.Dataset; import org.apache.spark.sql.Encoders; import org.apache.spark.sql.Row; import org.apache.spark.sql.SparkSession; import java.util.Arrays; import java.util.Iterator; public class WordCount { public static void main(String[] args) throws Exception { SparkSession spark = SparkSession.builder().appName(\u0026#34;WordCount\u0026#34;).getOrCreate(); Dataset\u0026lt;String\u0026gt; lines = spark.read().textFile(\u0026#34;hdfs://192.168.0.238:8020/input/news.txt\u0026#34;); Dataset\u0026lt;String\u0026gt; words = lines.flatMap(new FlatMapFunction\u0026lt;String, String\u0026gt;() { @Override public Iterator\u0026lt;String\u0026gt; call(String line) throws Exception { return Arrays.asList(line.split(\u0026#34; \u0026#34;)).iterator(); } }, Encoders.STRING()); Dataset\u0026lt;Row\u0026gt; wordCounts = words.groupBy(\u0026#34;value\u0026#34;).count(); wordCounts.write().format(\u0026#34;csv\u0026#34;).save(\u0026#34;hdfs://192.168.0.238:8020/output/word_count_result\u0026#34;); } } 5 实验结果 提交词频统计任务到Kubernetes ./spark-submit \\ --master k8s://https://127.0.0.1:6443 \\ --deploy-mode cluster \\ --name wordcount \\ --class com.cuterwrite.WordCount \\ --conf spark.kubernetes.executor.request.cores=2 \\ --conf spark.kubernetes.executor.limit.cores=2 \\ --conf spark.kubernetes.driver.limit.cores=1 \\ --conf spark.kubernetes.driver.request.cores=1 \\ --conf spark.eventLog.enabled=true \\ --conf spark.eventLog.dir=hdfs://192.168.0.238:8020/sparkhistory \\ --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \\ --conf spark.kubernetes.namespace=bigdata \\ --conf spark.executor.instances=3 \\ --conf spark.kubernetes.file.upload.path=/tmp \\ --conf spark.kubernetes.container.pullSecrets=aliyun-repository \\ --conf spark.kubernetes.container.image=registry.cn-hangzhou.aliyuncs.com/cuterwrite/spark:0.1 \\ hdfs://192.168.0.238:8020/user/root/jars/SparkApp-1.0.jar 执行结果： hdfs dfs -cat output/wordCount/_temporary/0/task_202212221534101760903765384745539_0002_m_000000/* ","date":"2022-12-23T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/92.png","permalink":"https://cuterwrite.top/p/spark-on-k8s/","title":"基于Spark on k8s的词频统计实验"},{"content":" Table of Contents generated with DocToc\nMapReduce实验 1 简介 1.1 实验环境 1.2 集群规划 2 在IDEA中创建项目 3 编写MapReduce应用程序 4 实验结果 MapReduce实验 1 简介 1.1 实验环境 本实验主要使用Ubuntu 20.04 64位作为系统环境，采用3台4核8GB云服务器作为Haddop集群部署机器，使用的软件如下：\n名称 版本 Hadoop 3.2.3 IDEA 2022.2.3 1.2 集群规划 主机名 IP DataNode NameNode JournalNode ZKFC node1 192.168.0.76 是 是 是 是 node2 192.168.0.213 是 是 是 是 node3 192.168.0.2 是 否 是 否 2 在IDEA中创建项目 打开IDEA界面，点击File-\u0026gt;New Project，选择Maven Archetype，创建一个名为MapReduce的Maven项目：\n编写pom.xml文件，内容如下：\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;com.cuterwrite\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;MapReduce\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;maven.compiler.source\u0026gt;11\u0026lt;/maven.compiler.source\u0026gt; \u0026lt;maven.compiler.target\u0026gt;11\u0026lt;/maven.compiler.target\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.hadoop\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hadoop-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.2.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/project\u0026gt; 3 编写MapReduce应用程序 分别编写IntSumReducer.java、TokenizerMapper.java、WordCount.java文件：\npackage com.cuterwrite; import org.apache.hadoop.io.IntWritable; import org.apache.hadoop.io.Text; import org.apache.hadoop.mapreduce.Reducer; import java.io.IOException; import java.util.Iterator; public class IntSumReducer extends Reducer\u0026lt;Text, IntWritable, Text, IntWritable\u0026gt; { private IntWritable result = new IntWritable(); public IntSumReducer() { } public void reduce(Text key, Iterable\u0026lt;IntWritable\u0026gt; values, Reducer\u0026lt;Text, IntWritable, Text, IntWritable\u0026gt;.Context context) throws IOException, InterruptedException { int sum = 0; IntWritable val; for (Iterator\u0026lt;IntWritable\u0026gt; iterator = values.iterator(); iterator.hasNext(); sum += val.get()) { val = (IntWritable)iterator.next(); } this.result.set(sum); context.write(key, this.result); } } package com.cuterwrite; import java.io.IOException; import java.util.StringTokenizer; import org.apache.hadoop.io.IntWritable; import org.apache.hadoop.io.Text; import org.apache.hadoop.mapreduce.Mapper; public class TokenizerMapper extends Mapper\u0026lt;Object, Text, Text, IntWritable\u0026gt; { private static final IntWritable one = new IntWritable(1); private Text word = new Text(); public TokenizerMapper() { } public void map(Object key, Text value, Mapper\u0026lt;Object, Text, Text, IntWritable\u0026gt;.Context context) throws IOException, InterruptedException { StringTokenizer tokenizer = new StringTokenizer(value.toString()); while (tokenizer.hasMoreTokens()) { this.word.set(tokenizer.nextToken()); context.write(this.word, one); } } } package com.cuterwrite; import org.apache.hadoop.conf.Configuration; import org.apache.hadoop.fs.Path; import org.apache.hadoop.io.IntWritable; import org.apache.hadoop.io.Text; import org.apache.hadoop.mapreduce.Job; import org.apache.hadoop.mapreduce.lib.input.FileInputFormat; import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat; public class WordCount { public WordCount() {} public static void main(String[] args) throws Exception { Configuration conf = new Configuration(); conf.set(\u0026#34;fs.defaultFS\u0026#34;, \u0026#34;hdfs://ha-cluster\u0026#34;); conf.set(\u0026#34;fs.hdfs.impl\u0026#34;, \u0026#34;org.apache.hadoop.hdfs.DistributedFileSystem\u0026#34;); String[] filePath = new String[] { \u0026#34;hdfs://ha-cluster/user/root/input/news1.txt\u0026#34;, \u0026#34;hdfs://ha-cluster/user/root/input/news2.txt\u0026#34;, \u0026#34;hdfs://ha-cluster/user/root/input/news3.txt\u0026#34; }; Job job = Job.getInstance(conf, \u0026#34;word count\u0026#34;); job.setJarByClass(WordCount.class); job.setMapperClass(TokenizerMapper.class); job.setCombinerClass(IntSumReducer.class); job.setReducerClass(IntSumReducer.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(IntWritable.class); for (int i = 0; i \u0026lt; filePath.length ; i++) { FileInputFormat.addInputPath(job, new Path(filePath[i])); } String outputPath = \u0026#34;hdfs://ha-cluster/user/root/output/mapreduce\u0026#34;; FileOutputFormat.setOutputPath(job, new Path(outputPath)); System.exit(job.waitForCompletion(true) ? 0 : 1); } } 4 实验结果 将应用程序编译打包成jar包：\nmvn clean install 上传jar包至HDFS中的jars目录下：\nhdfs dfs -put MapReduce-1.0-SNAPSHOT.jar jars 创建input、output目录，上传数据文件至HDFS\nhdfs dfs -mkdir -p input hdfs dfs -mkdir -p output hdfs dfs -put news1.txt news2.txt news3.txt input 运行jar包：\nhadoop jar MapReduce-1.0-SNAPSHOT.jar com.cuterwrite.WordCount 查看执行结果：\nhdfs dfs -cat output/mapreduce/* ","date":"2022-12-22T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/202210221658.png","permalink":"https://cuterwrite.top/p/mapreduce/","title":"MapReduce实验"},{"content":" Zookeeper on k8s部署实验 1 简介 1.1 实验环境 1.2 集群规划 2 创建ConfigMap 2.1 创建zookeeper-environment 2.2 创建zookeeper-setup 3 创建StatefulSet 3.1 创建工作容器 3.2 创建存储挂载 3.3 创建SVC 3.4 设置亲和性 4 部署结果 4.1 集群信息 4.2 节点状态测试 Zookeeper on k8s部署实验 1 简介 1.1 实验环境 已经使用Kuboard Spary搭建好Kubernetes集群和Kuboard，使用的软件如下：\n名称 版本 kuboard spary v1.2.3-amd64 kubernetes v1.25.5 zookeeper 3.8.0 1.2 集群规划 Zookeeper（三台4核8G的Ubuntu20.04服务器） 主机名 IP node1 192.168.0.6 node2 192.168.0.7 node3 192.168.0.14 2 创建ConfigMap 2.1 创建zookeeper-environment 创建一个名为zookeeper-environment的配置字典，包含变量对如下： Key Value ALLOW_ANONYMOUS_LOGIN yes BITNAMI_DEBUG false ZOO_4LW_COMMANDS_WHITELIST srvr, mntr, ruok ZOO_DATA_LOG_DIR ZOO_ENABLE_AUTH no ZOO_INIT_LIMIT 10 ZOO_LOG_LEVEL ERROR ZOO_MAX_CLIENT_CNXNS 60 ZOO_PORT_NUMBER 2181 ZOO_SERVERS zookeeper-statefulset-0.zookeeper-statefulset.bigdata.svc.cluster.local:2888:3888::1 zookeeper-statefulset-1.zookeeper-statefulset.bigdata.svc.cluster.local:2888:3888::2 zookeeper-statefulset-2.zookeeper-statefulset.bigdata.svc.cluster.local:2888:3888::3 ZOO_SYNC_LIMIT 5 ZOO_TICK_TIME 2000 2.2 创建zookeeper-setup 创建一个名为zookeeper-setup的配置字典，Key为setup.sh，value如下：\n#!/bin/bash if [[ -f \u0026#34;/bitnami/zookeeper/data/myid\u0026#34; ]]; then export ZOO_SERVER_ID=\u0026#34;$(cat /bitnami/zookeeper//data/myid)\u0026#34; else HOSTNAME=\u0026#34;$(hostname -s)\u0026#34; if [[ $HOSTNAME =~ (.*)-([0-9]+)$ ]]; then ORD=${BASH_REMATCH[2]} export ZOO_SERVER_ID=\u0026#34;$((ORD + 1 ))\u0026#34; else echo \u0026#34;Failed to get index from hostname $HOST\u0026#34; exit 1 fi fi exec /entrypoint.sh /run.sh 3 创建StatefulSet 创建一个名为zookeeper-statefulset的有状态副本集，设置replica为3 3.1 创建工作容器 容器名称：zookeeper\n容器镜像：bitnami/zookeeper:3.8.0\n命令：/opt/scripts/setup.sh\n环境变量：引用之前创建的配置字典zookeeper-environment\n容器端口：2181\n资源请求限制：\nCPU资源请求：500m\n内存资源请求：500Mi\nCPU资源限制：500m\n内存资源限制：500Mi\n健康检查：\n容器存活探针：\n执行命令：/bin/bash -c 'echo \u0026quot;ruok\u0026quot; | timeout 2 nc -w 2 localhost 2181 | grep imok'\n初始延迟：30秒\n执行探测频率：10秒\n超时时间：5秒\n健康阈值：1秒\n不健康阈值：6秒\n容器就绪探针：与容器存活探针相同\n容器安全上下文：\nrunAsNonRoot：true\n用户：1001\n3.2 创建存储挂载 数据卷：配置字典zookeeper-setup\n挂载路径：/opt/scripts/setup.sh\n子路径：setup.sh\n3.3 创建SVC 服务类型：NodePort\n端口：\n端口名称 port targetPort client 2181 2181 server 2888 2888 leader-election 3888 3888 3.4 设置亲和性 设置Node亲和性（硬策略）\n必须满足标签表达式：app.kubernetes.io/component=zookeeper 设置Pod反亲和性（软策略）\n尽量满足标签表达式\n权重：49\ntogologykey：app.kubernetes.io/name\n表达式：app.kubernetes.io/component=zookeeper\n4 部署结果 4.1 集群信息 4.2 节点状态测试 zkServer.sh status ","date":"2022-12-21T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/typora/202210172323.png","permalink":"https://cuterwrite.top/p/zookeeper-on-k8s/","title":"Zookeeper on k8s部署实验"},{"content":" Table of Contents generated with DocToc\nHadoop3 HA模式三节点高可用集群搭建实验 关于Hadoop3 HA模式 单点故障（SPOF） Zookeeper 实验过程和结果 环境 集群规划 创建hadoop用户 主机名和网络映射配置 安装SSH并配置SSH免密登录 安装Java环境 安装hadoop3 安装Zookeeper 配置环境变量 配置HA模式集群分布式环境 修改文件workers 修改文件core-site.xml 修改文件hdfs-site.xml 修改文件hadoop-env.sh 在所有节点上创建数据文件夹和日志文件夹 在所有节点上分别启动journalnode 格式化namenode节点 分别在namenode节点上启动zkfc 在主节点上启动所有datanode节点 实验结果 实例运行 补充：可选配置 HDFS Web UI配置认证 Hadoop3 HA模式三节点高可用集群搭建实验 关于Hadoop3 HA模式 单点故障（SPOF） 简单来说，单点故障指的是分布式系统过度依赖于某一个节点，以至于只要该节点宕掉，就算整个集群的其它节点是完好的，集群也无法正常工作。而单点故障问题一般出现在集群的元数据存储节点上，这种节点一般一个集群就一个，一旦坏了整个系统就不能正常使用。Hadoop的单点故障出现在namenode上，影响集群不可用主要有以下两种情况：一是namenode节点宕机，将导致集群不可用，重启namenode之后才可使用；二是计划内的namenode节点软件或硬件升级，导致集群短时间内不可用。\n为了避免出现单点故障，Hadoop官方给出了高可用HA方案：可以采取同时启动两个namenode：其中一个工作（active），另一个总是处于后备机（standby）的状态，让它只是单纯地同步活跃机的数据，当活跃机宕掉的时候就可以自动切换过去。这种模式称为HA模式。HA模式下不能用[namenode主机:端口]的模式来访问Hadoop集群，因为namenode主机已经不再是一个固定的IP了，而是采用serviceid的方式来访问，这个serviceid存储在ZooKeeper上。\nZookeeper Zookeeper是一个轻量级的分布式架构集群，为分布式应用提供一致性服务，提供的功能包括：配置维护、域名服务、分布式同步和组服务等。在HA模式中，Zookeeper最大的功能之一是知道某个节点是否宕机了。其原理是：每一个机器在Zookeeper中都有一个会话，如果某个机器宕机了，这个会话就会过期，Zookeeper就能发现该节点已宕机。\n实验过程和结果 环境 本实验使用Ubuntu 18.04 64位作为系统环境，采用3台2核16GB（ MA3.MEDIUM16型号）的腾讯云服务器作为集群部署机器。\n使用的软件如下：\n名称 版本 Hadoop 3.2.3 Zookeeper 3.6.3 JDK 11.0.2 建议：在以下的部署过程中使用root用户可以避免很多权限问题。\n集群规划 主机名 IP Namenode Datanode Zookeeper JournalNode master 172.31.0.12 是 是 是 是 slave1 172.31.0.16 是 是 是 是 slave2 172.31.0.10 否 是 是 是 创建hadoop用户 在终端输出如下命令创建一个名为hadoop的用户。\nsudo useradd -m hadoop -s /bin/bash 接着使用如下命令设置密码，按提示输入两次密码，这里简单设置为hadoop\nsudo passwd hadoop 此外，可以为hadoop用户添加管理员权限，方便后续的部署，避免一些权限问题的出现。\nsudo adduser hadoop sudo 主机名和网络映射配置 为了便于区分master节点和slave节点，可以修改各个节点的主机名。在Ubuntu系统中，我们可以执行以下命令来修改主机名。\nsudo vim /etc/hostname 执行上面命令后，就打开了/etc/hostname这个文件，这个文件记录了主机名。打开这个文件之后，里面只有当前的主机名这一行内容，可以直接删除，并修改为master或slave1、slave2，然后保存退出vim编辑器，这样就完成了主机名的修改，需要重启系统后才能看到主机名的变化。\n然后，在master节点中执行如下命令打开并修改master节点的/etc/hosts文件\nsudo vim /etc/hosts 在hosts文件中增加如下三条IP（局域网IP）和主机名映射关系。\n172.31.0.12 master 172.31.0.16 slave1 172.31.0.10 slave2 需要注意的是，一般hosts文件中只能有一个127.0.0.1，其对应主机名为localhost，如果有多余127.0.0.1映射，应删除，特别是不能存在“127.0.0.1 Master”这样的映射记录。修改后需要重启Linux系统。\n上面完成了master节点的配置，接下来要继续完成对其他slave节点的配置修改。请参照上面的方法，把slave1节点上的“/etc/hostname”文件中的主机名修改为“slave1”，把slave1节点上的“/etc/hostname”文件中的主机名修改为“slave2”同时，修改“/etc/hosts”的内容，在hosts文件中增加如下三条IP和主机名映射关系：\n172.31.0.12 master 172.31.0.16 slave1 172.31.0.10 slave2 修改完成以后，重新启动slave节点的Linux系统。\n这样就完成了master节点和slave节点的配置，然后，需要在各个节点上都执行如下命令，测试是否相互ping得通，如果ping不通，后面就无法顺利配置成功：\nping master -c 3 ping slave1 -c 3 ping slave2 -c 3 例如，在master节点上ping slave1，如果ping通的话，会显示如下图所示的结果：\n安装SSH并配置SSH免密登录 集群模式需要用到SSH登陆，Ubuntu默认已经安装SSH client，此外还需要安装SSH server\nsudo apt-get install openssh-server 安装后，可以使用如下命令登陆本机\nssh localhost 在集群模式中，必须要让master节点可以SSH免密登录到各个slave节点上。首先，生成master节点的公钥，如果之前已经生成过公钥，必须要删除原来生成的公钥，重新生成一次。具体命令如下：\ncd ~/.ssh #如果没有该目录，先执行一次ssh localhost rm ./id_rsa* #删除之前生成的公钥 ssh-keygen -t rsa #执行该命令后一直按回车就可以 为了让master节点能够SSH免密登录本机，需要在master节点上执行如下命令：\ncat ./id_rsa.pub \u0026gt;\u0026gt; ./authorized_keys 完成后可以执行“ssh master”来验证一下，可能会遇到提示信息，输入yes即可，测试成功后执行exit命令返回原来的终端。\n接下来，在master节点上将公钥传输到slave1和slave2节点\nscp ~/.ssh/id_rsa.pub hadoop@slave1:/home/hadoop/ scp ~/.ssh/id_rsa.pub hadoop@slave2:/home/hadoop/ 接着在slave1（slave2）节点上将SSH公钥加入授权\nmkdir ~/.ssh cat ~/id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys rm ~/id_rsa.pub #用完之后可以删除掉 这样，master节点就可以免密登录到各个slave节点上了，例如执行如下命令：\nssh slave1 会显示如下结果，显示已经登录到slave1节点上。\n安装Java环境 Hadoop3需要JDK版本在1.8以上，这里我选择11版本JDK作为Java环境，先执行以下命令下载压缩包。\ncd /usr/local/softwares; sudo wget https://repo.huaweicloud.com/openjdk/11.0.2/openjdk-11.0.2_linux-x64_bin.tar.gz 然后，使用如下命令解压缩：\nsudo tar -xzf openjdk-11.0.2_linux-x64_bin.tar.gz; sudo mv jdk-11.0.2 openjdk; 这时，可以执行以下命令查看是否安装成功\ncd openjdk; ./bin/java --version; 如果返回如下信息，则说明安装成功：\n安装hadoop3 先执行以下命令下载压缩包。\ncd /usr/local/softwares; sudo wget https://mirrors.pku.edu.cn/apache/hadoop/common/hadoop-3.2.3/hadoop-3.2.3.tar.gz 然后，使用如下命令解压缩：\nsudo tar -xzf hadoop-3.2.3.tar.gz; sudo mv hadoop-3.2.3 hadoop 这时，可以执行以下命令查看是否安装成功\ncd hadoop; ./bin/hadoop version 如果返回如下信息，则说明安装成功：\n安装Zookeeper 先执行以下命令下载压缩包。\ncd /usr/local/softwares; sudo wget https://mirrors.pku.edu.cn/apache/zookeeper/stable/apache-zookeeper-3.6.3-bin.tar.gz; 然后，使用如下命令解压缩：\nsudo tar -xzf apache-zookeeper-3.6.3-bin.tar.gz; sudo mv apache-zookeeper-3.6.3-bin zookeeper; 接下来，将Zookeeper中的conf文件夹里的zoo_sample.cfg文件复制一份，改名为zoo.cfg，然后编辑这个文件，其他的部分不用动，需要修改dataDir这一行。dataDir是ZooKeeper的数据文件夹的位置，在我的机器上我用的是/data/zookeeper，你们可以设置成你们的目录。此外，需要在末尾加上所有节点的信息（数字与myid要对应）：\nserver.1=master:2888:3888 server.2=slave1:2888:3888 server.3=slave2:2888:3888 然后再修改bin/zkEnv.sh，添加以下日志输出文件夹配置：\nZOO_LOG_DIR=/data/logs/zookeeper 最后，需要在每一个节点上的dataDir目录下手动创建一个文件，命名为myid，并写入这台服务器的Zookeeper ID。这个ID数字可以自己随便写，取值范围是1~255，在这里我将master、slave1和slave2分别取值为1，2，3。配置完成以上全部后，分别使用zkServer.sh start命令启动集群，ZooKeeper会自动根据配置把所有的节点连接成一个集群。启动后使用jps命令可以查看到QuorumPeerMain进程已经启动成功。\n配置环境变量 配置环境变量后可以在任意目录中直接使用hadoop、hdfs等命令。配置方法也比较简单。首先执行命令：\nsudo vim ~/.bashrc 然后，在该文件最上面的位置加入下面内容：\nexport JAVA_HOME=/usr/local/softwares/openjdk export HADOOP_HOME=/usr/local/softwares/hadoop export HADOOP_PREFIX=$HADOOP_HOME export HADOOP_MAPRED_HOME=$HADOOP_HOME export HADOOP_COMMON_HOME=$HADOOP_HOME export HADOOP_HDFS_HOME=$HADOOP_HOME export YARN_HOME=$HADOOP_HOME export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/natvie export HADOOP_INSTALL=$HADOOP_HOME export ZK_HOME=/usr/local/softwares/zookeeper export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$ZK_HOME/bin 保存后执行如下命令使配置生效：\nsource ~/.bashrc 配置HA模式集群分布式环境 修改文件workers 需要把所有数据节点的主机名写入该文件，每行一个，默认为localhost（即把本机作为数据节点），在本实验中，master和slave1、slave2都充当datanode，所以该文件内容配置如下：\nmaster slave1 slave2 修改文件core-site.xml 在一般集群模式中，fs.defaultFS配置为hdfs://master:9000，即名称节点所在的主机名加上端口号，但需要注意的是，在HA模式下分别有一个active和standby的名称节点，需要将该属性设置为集群id，这里写的ha-cluster需要与hdfs-site.xml中的配置一致，所以将该文件修改为如下内容：\n\u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;fs.defaultFS\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdfs://ha-cluster\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;ha.zookeeper.quorum\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;master:2181,slave1:2181,slave2:2181\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;ha.zookeeper.session-timeout.ms\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;30000\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; 修改文件hdfs-site.xml 对以下属性进行配置：\n\u0026lt;configuration\u0026gt; \u0026lt;!-- 服务ID--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.nameservices\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;ha-cluster\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.ha.namenodes.ha-cluster\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;master,slave1\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- rpc地址--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.rpc-address.ha-cluster.master\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;master:8020\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.rpc-address.ha-cluster.slave1\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;slave1:8020\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- http地址--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.http-address.ha-cluster.master\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;master:9870\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.http-address.ha-cluster.slave1\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;slave1:9870\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- journalnode集群访问地址--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.shared.edits.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;qjournal://master:8485;slave1:8485;slave2:8485/ha-cluster\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- dfs客户端--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.client.failover.proxy.provider.ha-cluster\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- 配置kill方式--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.ha.fencing.methods\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;sshfence\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.ha.fencing.ssh.private-key-files\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;/home/hadoop/.ssh/id_rsa\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- 自动failover机制--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.ha.automatic-failover.enabled\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;true\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;ha.zookeeper.quorum\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;master:2181,slave1:2181,slave2:2181\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- 冗余因子，datanode有3个，所以设置为3--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.replication\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;3\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.name.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:/data/hadoop/hdfs/nn\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.datanode.data.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:/data/hadoop/hdfs/dn\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- 不要加file前缀--\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.journalnode.edits.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;/data/hadoop/hdfs/jn\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; 修改文件hadoop-env.sh 在文件开头添加以下变量\nexport HADOOP_NAMENODE_OPS=\u0026#34; -Xms1024m -Xmx1024m -XX:+UseParallelGC\u0026#34; export HADOOP_DATANODE_OPS=\u0026#34; -Xms1024m -Xmx1024m\u0026#34; export HADOOP_LOG_DIR=/data/logs/hadoop 在所有节点上创建数据文件夹和日志文件夹 sudo mkdir -p /data/hadoop/hdfs/nn; sudo mkdir -p /data/hadoop/hdfs/dn; sudo mkdir -p /data/hadoop/hdfs/jn; sudo mkdir -p /data/zookeeper; sudo chown -R hadoop.hadoop /data/hadoop; sudo chown -R hadoop.hadoop /data/zookeeper; sudo mkdir /data/logs; sudo mkdir /data/logs/hadoop; sudo mkdir /data/logs/zookeeper; sudo chown -R hadoop.hadoop /data/logs 在所有节点上分别启动journalnode hdfs --daemon start journalnode 格式化namenode节点 在第一个namenode上进行格式化并启动hdfs：\nhdfs namenode -format; hdfs --daemon start namenode 在第二个namenode上进行备用初始化\nhdfs namenode -bootstrapStandby 在第一个namenode上进行journalnode的初始化\nhdfs namenode -initializeSharedEdits 分别在namenode节点上启动zkfc hdfs zkfc -formatZK 在主节点上启动所有datanode节点 start-dfs.sh 实验结果 实例运行 首先创建HDFS上的用户目录，命令如下：\nhdfs dfs -mkdir -p /user/hadoop 然后，在HDFS中创建一个input目录，并将“/usr/local/softwares/hadoop/etc/hadoop”目录中的配置文件作为输入文件复制到input目录中，命令如下：\nhdfs dfs -mkdir input; hdfs dfs -put /usr/local/softwares/hadoop/etc/hadoop/*.xml input 接着就可以运行MapReduce作业了，命令如下：\nhadoop jar /usr/local/softwares/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.3.jar grep input output \u0026#39;dfs[a-z.]+\u0026#39; 运行结果如下：\n补充：可选配置 HDFS Web UI配置认证 HDFS带有一个可视化的端口号默认为9870的Web UI界面，这个界面如果没有做防火墙限制的话会暴露在公网上。而该界面又存在着大量的日志和配置信息，直接暴露在公网上不利于系统的安全，所以在这里可以配置一个简单的系统认证功能。步骤如下：\n安装httpd或安装httpd-tools\nsudo apt-get install httpd 安装nginx：这部分内容较多，不是重点，网上有大量的教程，跟着其中一个进行就行。\n通过htpasswd命令生成用户名和密码数据库文件\nhtpasswd -c passwd.db [username] 查看生成的db文件内容\ncat passwd.db 通过nginx代理并设置访问身份验证\n# nginx配置文件 vim nginx.conf server {\r# 使用9871端口替代原有的9870端口\rlisten 9871;\rserver_name localhost;\rlocation / {\rauth_basic \u0026#34;hadoop authentication\u0026#34;;\rauth_basic_user_file /home/hadoop/hadoop/passwd.db\rproxy_pass http://127.0.0.1:9870\r}\r} 重新加载nginx配置\ncd /usr/local/lighthouse/softwares/nginx/sbin ./nginx -s reload 启动nginx\nsystemctl start nginx 到此为止，HDFS Web UI界面认证设置完成，效果如下：.\n","date":"2022-09-22T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/typora/32756284e8854b9ba653bd3632af435d.jpg","permalink":"https://cuterwrite.top/p/hadoop-ha/","title":"Hadoop3 HA模式三节点高可用集群搭建实验"},{"content":" Table of Contents generated with DocToc\n路径规划算法之A* 与D* Lite原理详解 问题描述 基础算法介绍 广度优先搜索 最佳优先算法 Dijkstra算法 A* 算法 A* 算法变种 D* Lite算法 参考文献 路径规划算法之A* 与D* Lite原理详解 问题描述 如何在一个网格地图中找到两点之间的最短路径\n基础算法介绍 如果要在一个网格地图中找到两点之间的最短路径，很容易想到的广度优先算法（Breadth First）、最佳优先算法和Dijkstra算法。\n广度优先搜索 广度优先搜索算法如其名称所示以广度做为优先级进行搜索。\n从起点开始，首先遍历起点周围邻近的点，然后再遍历已经遍历过的点邻近的点，逐步的向外扩散，直到找到终点。\n这种算法就像洪水（Flood fill）一样向外扩张，算法的过程如下图所示：\n广度优先算法的优点是一定可以找到两点间的最优路径，但是代价就是需要搜索的点非常多，速度会比较慢。\n最佳优先算法 在一些情况下，如果我们可以预先计算出每个节点到终点的距离，则我们可以利用这个信息更快的到达终点。\n最佳优先算法和广度优先算法不同，它需要使用一个优先队列，用每个节点到终点的距离作为优先级每次始终选取到终点移动代价最小（离终点最近）的节点作为下一个遍历的节点，直到到达终点。这种算法称之为最佳优先（Best First）算法。和广度优先相比，最佳优先所需要搜索的点要少很多，可以大大加快路径的搜索速度，如下图所示：\n但最佳优先算法的缺点就是，当起点和终点有障碍物时，可能最佳优先算法找到的路径并不是最佳的路径，下图描述了这种情况：\nDijkstra算法 Dijkstra算法是由计算机科学家Edsger W. Dijkstra在1956年提出的\nDijkstra算法用来寻找图形中节点之间的最短路径。\n考虑这样一种场景，在一些情况下，图形中相邻节点之间的移动代价并不相等。例如，游戏中的一幅图，既有平地也有山脉，那么游戏中的角色在平地和山脉中移动的速度通常是不相等的。\n在Dijkstra算法中，需要计算每一个节点距离起点的总移动代价。同时，还需要一个优先队列结构。对于所有待遍历的节点，放入优先队列中会按照代价进行排序。\n在算法运行的过程中，每次都从优先队列中选出代价最小的作为下一个遍历的节点。直到到达终点为止。\n下面对比了不考虑节点移动代价差异的广度优先搜索与考虑移动代价的Dijkstra算法的运算结果：\n当图形为网格图，并且每个节点之间的移动代价是相等的，那么Dijkstra算法将和广度优先算法变得一样。\nA* 算法 A* 算法最初发表于1968年，由Stanford研究院的Peter Hart, Nils Nilsson以及Bertram Raphael发表。它可以被认为是Dijkstra算法的扩展。\n由于借助启发函数的引导，A*算法通常拥有更好的性能。\nA* 算法通过下面这个函数来计算每个节点的优先级。 $$ f(n) = g(n) + h(n) $$ 其中：\nf(n) 是节点n的综合优先级。当我们选择下一个要遍历的节点时，我们总会选取综合优先级最高（值最小）的节点。 g(n) 是节点n距离起点的实际代价。 h(n) 是启发函数，是节点n到终点的估计值 在极端情况下，启发函数始终为0，则将由g(n)g(n)决定节点的优先级，此时算法就退化成了Dijkstra算法。 如果h(n)始终小于等于节点n到终点的代价，则A*算法保证一定能够找到最短路径。但是当h(n)的值越小，算法将遍历越多的节点，也就导致算法越慢。 如果h(n)完全等于节点n到终点的代价，则A*算法将找到最佳路径，并且速度很快。可惜的是，并非所有场景下都能做到这一点。因为在没有达到终点之前，我们很难确切算出距离终点还有多远。 如果h(n)的值比节点n到终点的代价要大，则A*算法不能保证找到最短路径，不过此时会很快。 在另外一个极端情况下，如果h(n)相较于g(n)大很多，则此时只有h(n)产生效果，这也就变成了最佳优先搜索。 由上面这些信息我们可以知道，通过调节启发函数我们可以控制算法的速度和精确度。因为在一些情况，我们可能未必需要最短路径，而是希望能够尽快找到一个路径即可。这也是A*算法比较灵活的地方。\n对于网格形式的图，有以下这些启发函数可以使用：\n如果图形中只允许朝上下左右四个方向移动，则可以使用曼哈顿距离（Manhattan distance）。 如果图形中允许朝八个方向移动，则可以使用对角距离。 如果图形中允许朝任何方向移动，则可以使用欧几里得距离（Euclidean distance）。 A* 算法还需要使用两个集合来表示待遍历的节点，与已经遍历过的节点。\nOpenList：可到达的节点 CloseList：已到达的节点 A* 算法具体的运行过程为：每次从优先队列中选取f(n)值最小（优先级最高）的节点作为下一个待遍历的节点，如果该节点是目标节点，则直接返回，算法结束。如果不是，则遍历其邻居节点，对所有不在CloseList中的、在网格范围内的、非障碍物的节点，计算其中F值、G值和H值，添加到优先队列（OpenList）中和CloseList中。\nA* 算法Java实现如下图所示：\nA* 算法变种 A* 算法有不少的变种，主要有如下算法：\nARA * ：ARA* - Anytime A* with Provable Bounds on Sub-Optimality\nD* ：D* 是Dynamic A* 的简写，其算法和A*类似，不同的是，其代价的计算在算法运行过程中可能会发生变化。\nProject “Fast Replanning （Incremental Heuristic Search）” Real-Time Replanning in Dynamic and Unknown Environments Field D* ： Field D* 扩展了D* 和D* Lite，是一种基于插值（ interpolation-based ）的规划算法，它使用线性插值来有效地生成低成本路径，从而消除不必要的转向。\n在给定线性插值假设的情况下，路径是最优的，并且在实践中非常有效。该算法目前被各种现场机器人系统使用。\n关于Field D* 的详细内容可以看下面这篇论文：\nField D*: An Interpolation-based Path Planner and Replanner D* Lite算法 D* Lite 算法是一种增量启发式搜素算法，由 Sven Koeing 和 Maxim Likhachev 于 2004 年提出，是基于 LPA* 和 Dynamic SWSF-FP 的一种算法。D* Lite 算法可以适用于地图未知、环境随时会发生变化的情况，在遇到新增加的障碍物时，可以利用先前搜索所获得的信息，而不需要完全重新规划路径。\nD* Lite的启发函数与A* 类似，同样有一个启发函数，不过因为 D* Lite 是从终点向起点搜索，所以对应的启发函数 h(n) 也变成了节点 n 到起点的估计值。\nD* Lite中几个概念的定义：\ng(n)：当前节点到终点的实际代价\nh(n)：当前节点到起点的估计值\nrhs（right-hand side)：公式如下\n一个点的 rhs 值是它的父代节点中 g 值加上这两点之间的代价中的最小值，相当于一个点从父代节点到达这个点的最小代价。其实在算法的大部分过程中，g 值和 rhs 值是相等的。\n两个key值：在 A* 算法中，通过 f(n) 的大小来判断一个点的优先级，而在 D* Lite 中，需要通过两个 key 值来判断一个点的优先级，key 值越小优先级越高，先判断第一个 key 值，如果第一个 key 值相等再判断第二个 key 值。公式如下：\n其中 km 的定义为，算法初始化时会先将 km 设置为 0，之后当机器人有检测到地图的变化时，km需要加上上一个起点与当前位置的启发距离，并且把当前所在的点设置为新的起点，即更新起点的位置。\n如果在机器人还没有移动的时候 km 就等于 0，这时算法其实就相当于一个反向从终点往起点方向搜索的 A* 算法了。\n当机器人检测到障碍的变化时会再一次规划路径，这时候的实际起点应该是机器人当前的位置，起点发生了变化，每个点的 h 值也会相应变化，key 值也发生了变化。如果不引入这个参数的话，就需要把优先队列中的全部节点都重新计算一遍 key 值，增加了计算量。引入之后就可以一定程度上保证 key 值的一致性，减少计算量。\n第二 key 值就是 g 值和 rhs 值中的最小值，它的意义在于当两个点的第一个 key 值相等的时候，算法会优先选择距离终点近的点。\n局部一致性：D* Lite 算法中还有一个很重要的概念就是局部一致性，通过一个点的局部一致性来判断当前点是否需要计算。其定义如下：当一个点的 g 值等于 rhs 值时称这个点为局部一致的点，否则称这个点为局部不一致。其中局部不一致的情况还可细分成为局部过一致和局部欠一致：当一个点的 g 值大于 rhs 值时，这个点为局部过一致，通常是有障碍物删除时或者算法第一次搜索路径时；当一个点的 g 值小于 rhs 值时，这个点为局部欠一致，通常是检测到了新增的障碍物。\nD* Lite算法的步骤：\n将当前点设置为起点 将优先队列设置为空队列，将所有节点的g值和rhs值设置为无穷，将终点的rhs值设为0，并且计算它的key值加入到优先队列中。 调用ComputeShortestPath()开始计算它的最短路径 移动到子代中g值加上这两个点之间代价中最小的点。 如果检测到了障碍的变化，根据上一个起点和当前点的启发值，修改k_m的值，并将当前节点设置为新的起点。 对所有两个点之间的代价发生变化的，更新这两个点之间的代价，如果两个点之间的代价变小，说明有障碍物删除，更新它的rhs值，如果代价变大了，说明新增了一个障碍物，需要通过它的子代来更新rhs值。 更新受影响的节点。 计算最短路径。 D* Lite算法Java代码实现还未完成\npython版代码参考：https://github.com/avgaydashenko/d_star\n参考文献 [1]路径规划之A*算法\n[2]路径规划之D* Lite算法详解及实现\n","date":"2021-08-31T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/typora/image-hosting-master/image-hosting-master/store/photo-1563207153-f403bf289096.4ciiq7uwjl40.jfif","permalink":"https://cuterwrite.top/p/route-planning-alogrithm/","title":"路径规划算法之A* 与D* Lite原理详解"},{"content":" Table of Contents generated with DocToc\n聊聊前缀树Trie Trie树简介 Trie树特点 Trie树的插入操作 Trie树的查询操作 Trie树的删除操作 Trie树应用与实现 前缀匹配/自动补全 字符串检索 动态路由 Trie树的局限性 聊聊前缀树Trie Trie树简介 Trie 树，也叫“字典树”。顾名思义，它是一个树形结构。它是一种专门处理字符串匹配的数据结构，用来解决在一组字符串集合中快速查找某个字符串的问题。\n此外 Trie 树也称前缀树（因为某节点的后代存在共同的前缀，比如pan是panda的前缀）。\n它的key都为字符串，能做到高效查询和插入，时间复杂度为O(k)，k为字符串长度，缺点是如果大量字符串没有共同前缀时很耗内存。\n它的核心思想就是通过最大限度地减少无谓的字符串比较，使得查询高效率，即「用空间换时间」，再利用共同前缀来提高查询效率。\nTrie树特点 假设有 5 个字符串，它们分别是：code，cook，five，file，fat。现在需要在里面多次查找某个字符串是否存在。常见的方案有：①如果每次查找，都是拿要查找的字符串跟这 5 个字符串依次进行字符串匹配，时间复杂度为O(n)。②将字符串存入HashSet中，查找的时候时间复杂度为O(1)，但是缺点是空间复杂度高，假如有大量的字符串（比如10亿条）则会浪费大量的空间。\nTrie树则通过空间换时间的方式，将字符串组织成下图的结构：\n通过上图，可以发现 Trie树 的三个特点：\n根节点不包含字符，除根节点外每一个节点都只包含一个字符 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串 每个节点的所有子节点包含的字符都不相同 Trie树的插入操作 Trie树的插入操作很简单，其实就是将单词的每个字母逐一插入 Trie树。插入前先看字母对应的节点是否存在，存在则共享该节点，不存在则创建对应的节点。比如要插入新单词cook，就有下面几步：\n插入第一个字母 c，发现 root 节点下方存在子节点 c，则共享节点 c 插入第二个字母 o，发现 c 节点下方存在子节点 o，则共享节点 o 插入第三个字母 o，发现 o 节点下方不存在子节点 o，则创建子节点 o 插入第三个字母 k，发现 o 节点下方不存在子节点 k，则创建子节点 k 至此，单词 cook 中所有字母已被插入 Trie树 中，然后设置节点 k 中的标志位，标记路径 root-\u0026gt;c-\u0026gt;o-\u0026gt;o-\u0026gt;k这条路径上所有节点的字符可以组成一个单词cook Trie树的查询操作 在 Trie 树中查找一个字符串的时候，比如查找字符串 code，可以将要查找的字符串分割成单个的字符 c，o，d，e，然后从 Trie 树的根节点开始匹配。如图所示，绿色的路径就是在 Trie 树中匹配的路径\nTrie树的删除操作 Trie树的删除操作与二叉树的删除操作有类似的地方，需要考虑删除的节点所处的位置，这里分三种情况进行分析： 删除整个单词（比如hi）\n从根节点开始查找第一个字符h 找到h子节点后，继续查找h的下一个子节点i i是单词hi的标志位，将该标志位去掉 i节点是hi的叶子节点，将其删除 删除后发现h节点为叶子节点，并且不是单词标志位，也将其删除 这样就完成了hi单词的删除操作 删除前缀单词（比如cod）\n这种方式删除比较简单。 只需要将cod单词整个字符串查找完后，d节点因为不是叶子节点，只需将其单词标志去掉即可。\n删除分支单词（比如cook）\n与 删除整个单词 情况类似，区别点在于删除到 cook 的第一个 o 时，该节点为非叶子节点，停止删除，这样就完成cook字符串的删除操作。\nTrie树应用与实现 事实上 Trie树 在日常生活中的使用随处可见，比如这个： 具体来说就是经常用于统计和排序大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是：最大限度地减少无谓的字符串比较，查询效率比哈希表高。\n实现：最简单的字典树\nclass TrieNode { String word; boolean isEnd; TrieNode[] children; public TrieNode() { children = new TrieNode[26]; } } 前缀匹配/自动补全 例如：找出一个字符串集合中所有以 五分钟 开头的字符串。我们只需要用所有字符串构造一个 trie树，然后输出以 五−\u0026gt;分−\u0026gt;钟 开头的路径上的关键字即可。 trie树前缀匹配常用于搜索提示。如当输入一个网址，可以自动搜索出可能的选择。当没有完全匹配的搜索结果，可以返回前缀最相似的可能\n实现：自动补全功能\n（1）先找出匹配词语的节点（可能是中间的路径，不一定是最终节点）\n（2）递归的查询该节点下的所有单词\npublic class Trie { private class TrieNode { String word; boolean isEnd; Map\u0026lt;Character, TrieNode\u0026gt; children; public TrieNode() { children = new HashMap\u0026lt;\u0026gt;(); } } TrieNode root; public Trie() { root = new TrieNode(); } public void insert(String word) { TrieNode node = root; for (char c : word.toCharArray()) { if (!node.children.containsKey(c)) { node.children.put(c, new TrieNode()); } node = node.children.get(c); } node.isEnd = true; node.word = word; } public List\u0026lt;String\u0026gt; autoComplete(TrieNode node, String word) { List\u0026lt;String\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); for (char c : word.toCharArray()) { if (!node.children.containsKey(c)) { node = node.children.get(c); } } helper(node, res); return res; } private void helper(TrieNode node, List\u0026lt;String\u0026gt; words) { if (node.isEnd) { words.add(node.word); } for (Map.Entry\u0026lt;Character, TrieNode\u0026gt; entry : node.children.entrySet()) { helper(entry.getValue(), words); } } } 字符串检索 给出 N 个单词组成的熟词表，以及一篇全用小写英文书写的文章，按最早出现的顺序写出所有不在熟词表中的生词。 检索/查询功能是Trie树最原始的功能。给定一组字符串，查找某个字符串是否出现过，思路就是从根节点开始一个一个字符进行比较：\n如果沿路比较，发现不同的字符，则表示该字符串在集合中不存在。 如果所有的字符全部比较完并且全部相同，还需判断最后一个节点的标志位（标记该节点是否代表一个关键字）。 public class Trie { private class TrieNode { String word; boolean isEnd; Map\u0026lt;Character, TrieNode\u0026gt; children; public TrieNode() { children = new HashMap\u0026lt;\u0026gt;(); } } TrieNode root; public Trie() { root = new TrieNode(); } public void insert(String word) { TrieNode node = root; for (char c : word.toCharArray()) { if (!node.children.containsKey(c)) { node.children.put(c, new TrieNode()); } node = node.children.get(c); } node.isEnd = true; node.word = word; } public boolean search(String word) { TrieNode node = root; for (char c : word.toCharArray()) { if (!node.children.containsKey(c)) { return false; } node = node.children.get(c); } return node.isEnd; } } 动态路由 实现动态路由最常用的数据结构，被称为前缀树(Trie树)。看到名字你大概也能知道前缀树长啥样了：每一个节点的所有的子节点都拥有相同的前缀。这种结构非常适用于路由匹配，比如我们定义了如下路由规则：\n/:lang/doc /:lang/tutorial /:lang/intro /about /p/blog /p/related HTTP请求的路径恰好是由/分隔的多段构成的，因此，每一段可以作为前缀树的一个节点。我们通过树结构查询，如果中间某一层的节点都不满足条件，那么就说明没有匹配到的路由，查询结束。\n接下来我们实现的动态路由具备以下两个功能。\n参数匹配:。例如 /p/:lang/doc，可以匹配 /p/c/doc 和 /p/go/doc。 通配*。例如 /static/*filepath，可以匹配/static/fav.ico，也可以匹配/static/js/jQuery.js，这种模式常用于静态服务器，能够递归地匹配子路径。 实现：动态路由\n（1）由于路由规则允许模糊匹配，匹配子节点时可能还包括了含有模糊字符串的结构，比如插入/:lang/tutorial这个路由pattern后再插入/golang/intro时，虽然golang与:lang并不匹配，但还是需要将intro插入在:lang节点下，而不是再创建一个golang节点，所以仅使用哈希表查找子节点并不合适，需要改用为ArrayList来存TrieNode，使用一个单独的字符串part来保存节点的信息，isWild来判断节点是否是模糊节点。\n（2）插入与查询的逻辑与字符串检索区别不大，关键修改在于：插入时还需要插入part和isWild信息，搜搜时如果碰到了*号开头的节点，需要终止查询，返回该节点。\npublic class Trie { private class TrieNode { String part; String pattern; boolean isWild; boolean isEnd; List\u0026lt;TrieNode\u0026gt; children; public TrieNode() { children = new ArrayList\u0026lt;\u0026gt;(); } public TrieNode(boolean isWild, String part) { this.isWild = isWild; this.part = part; children = new ArrayList\u0026lt;\u0026gt;(); } } private TrieNode root; public Trie() { root = new TrieNode(); } public List\u0026lt;String\u0026gt; parsePattern(String pattern) { String[] parts = pattern.split(\u0026#34;/\u0026#34;); List\u0026lt;String\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); for (String part : parts) { if (part.isEmpty()) { continue; } res.add(part); if (part.charAt(0) == \u0026#39;*\u0026#39;) { break; } } return res; } public TrieNode matchChild(TrieNode node, String part) { for (TrieNode child : node.children) { if ((child.part != null \u0026amp;\u0026amp; child.part.equals(part)) || child.isWild) { return child; } } return null; } public List\u0026lt;TrieNode\u0026gt; matchChildren(TrieNode node, String part) { List\u0026lt;TrieNode\u0026gt; children = new ArrayList\u0026lt;\u0026gt;(); for (TrieNode child : node.children) { if ((child.part != null \u0026amp;\u0026amp; child.part.equals(part)) || child.isWild) { children.add(child); } } return children; } public void insert(String pattern) { List\u0026lt;String\u0026gt; parts = parsePattern(pattern); insert(root, pattern, parts, 0); } private void insert(TrieNode node, String pattern, List\u0026lt;String\u0026gt; parts, int depth) { if (parts.size() == depth) { node.pattern = pattern; node.isEnd = true; return; } String part = parts.get(depth); TrieNode child = matchChild(node, part); if (child == null) { boolean isWild = part.charAt(0) == \u0026#39;:\u0026#39; || part.charAt(0) == \u0026#39;*\u0026#39;; child = new TrieNode(isWild, part); node.children.add(child); } insert(child, pattern, parts, depth + 1); } public TrieNode search(TrieNode node, int depth, List\u0026lt;String\u0026gt; parts) { if ((parts.size() == depth) || (node.part != null \u0026amp;\u0026amp; node.part.startsWith(\u0026#34;*\u0026#34;))) { if (node.isEnd) { return node; } return null; } String part = parts.get(depth); List\u0026lt;TrieNode\u0026gt; children = matchChildren(node, part); for (TrieNode child : children) { TrieNode result = search(child, depth + 1, parts); if (result != null) { return result; } } return null; } public String getPattern(String path) { List\u0026lt;String\u0026gt; searchParts = parsePattern(path); TrieNode node = search(root, 0, searchParts); if (node != null) { return node.pattern; } return null; } } Trie树的局限性 如前文所讲，Trie的核心思想是空间换时间，利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的。 假设字符的种数有m个，有若干个长度为n的字符串构成了一个 Trie树 ，则每个节点的出度为 m（即每个节点的可能子节点数量为m），Trie树 的高度为n。很明显我们浪费了大量的空间来存储字符，此时Trie树的最坏空间复杂度为O(m^n)。也正由于每个节点的出度为m，所以我们能够沿着树的一个个分支高效的向下逐个字符的查询，而不是遍历所有的字符串来查询，此时Trie树的最坏时间复杂度为O(n)。 这正是空间换时间的体现，也是利用公共前缀降低查询时间开销的体现。\n","date":"2021-08-16T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/typora/image-hosting-master/image-hosting-master/store/mountains-6522018__340.3begmxsrjam0.webp","permalink":"https://cuterwrite.top/p/trie/","title":"聊聊前缀树Trie"},{"content":" Table of Contents generated with DocToc\nSpring Cloud OAuth2从零开始实现用户认证和单点登录 OAuth2 是什么 OAuth2的使用场景 OAuth2实现统一认证功能 创建并配置认证服务端auth-server 1、引入需要的Maven包 2、配置bootstrap.yml和Nacos配置 3、配置Spring Security 4、实现UserDetailsService 5、配置OAuth2 6、配置JWTTokenStore 7、启动auth-server Spring Cloud OAuth2从零开始实现用户认证和单点登录 OAuth2 是什么 OAuth2 其实是一个关于授权的网络标准，它制定了设计思路和运行流程，利用这个标准我们其实是可以自己实现 OAuth2 的认证过程的。 spring-cloud-starter-oauth2 是 Spring Cloud 按照 OAuth2 的标准并结合 spring-security 封装好的一个具体实现。\nOAuth 2 有四种授权模式，分别是授权码模式（authorization code）、简化模式（implicit）、密码模式（resource owner password credentials）、客户端模式（client credentials），具体 OAuth2 是什么，可以参考这篇文章（http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html）。\nOAuth2的使用场景 典型的OAuth2使用场景：微信登录、QQ登录、微博登录、Google帐号登录、Github帐号登录等。第一次使用就无需注册，直接通过第三方平台授权登录即可，大大提高了使用效率。此外，服务不需要存储用户的密码，只需要存储认证平台返回的唯一ID和用户信息即可。 不使用OAuth2的场景：用户需要先完成注册，然后用注册号的帐号密码或者用手机验证码登录。 OAuth2实现统一认证功能 创建并配置认证服务端auth-server 认证服务端负责验证帐号、密码、存储Token、检查Token、刷新Token等。\n1、引入需要的Maven包 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-oauth2\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 2、配置bootstrap.yml和Nacos配置 认证服务器采用Nacos Config方案，将配置放在Nacos注册中心上\nbootstrap.yml配置 spring: application: name: auth-server cloud: nacos: config: prefix: auth-server-config server-addr: xxxx file-extension: yaml group: refactored-spring-cloud auth-server-config配置 server: port: 18003 spring: datasource: url: jdbc:mysql://xxxx:3306/spring?useUnicode=true\u0026amp;\u0026amp;characterEncoding=UTF-8\u0026amp;\u0026amp;serverTimezone=Asia/Shanghai username: xxxx password: xxxx jpa: show-sql: true generate-ddl: true database-platform: org.hibernate.dialect.MYSQL5InnoDBDialect database: mysql application: name: auth-server cloud: nacos: discovery: server-addr: xxxx:8848 group: refactored-spring-cloud inetutils: ignored-interfaces: eth.* preferred-networks: xxxx redis: host: xxxx port: 6379 management: endpoint: health: enabled: true dubbo: protocol: name: dubbo port: -1 registry: address: spring-cloud://xxxx consumer: timeout: 3000 3、配置Spring Security public class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Bean public PasswordEncoder passwordEncoder() { return new BCryptPasswordEncoder(); } @Bean @Override public AuthenticationManager authenticationManager() throws Exception { return super.authenticationManager(); } /** * 开放所有接口 */ @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers(\u0026#34;/**\u0026#34;) .permitAll(); } } PasswordEncoder：采用BCrypt加密算法 AuthenticationManager：OAuth2密码模式必须制定的授权管理，用默认的即可 configure：配置拦截器，使用通配符开放所有接口访问权限 4、实现UserDetailsService @Slf4j @Commponent(value = \u0026#34;kiteUserDetailService\u0026#34;) public class KiteUserDetailService implements UserDetailService { @DubboReference IUserService service; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { log.info(\u0026#34;username is: \u0026#34; + username); // 查询用户 if (user == null) { throw new UsernameNotFoundException(\u0026#34;The user is not found\u0026#34;); } else { // 查询角色 List\u0026lt;SysRole\u0026gt; roles = user.getRoles(); List\u0026lt;SimpleGrantedAuthority\u0026gt; authorities = new ArrayList\u0026lt;\u0026gt;(); for (SysRole role : roles) { authorities.add(new SimpleGrantedAuthority(role.getRoleName())); } // 查询密码 String password = user.getPassword(); return new User(username, password, authorities); } } } loadUserByUsername：首先利用用户微服务接口通过username查询用户、角色以及密码，然后返回org.springframework.security.core.userdetails.User即可。 5、配置OAuth2 @Configuration @EnableAuthorizationServer public class OAuth2Config extends AuthorizationServerConfigurerAdapter { @Autowired public PasswordEncoder passwordEncoder; @Autowired public UserDetailsService kiteUserDetailsService; @Autowired private TokenStore jwtTokenStore; @Autowired private JwtAccessTokenConverter jwtAccessTokenConverter; @Autowired private DataSource dataSource; @Override public void configure(final AuthorizationServerEndpointsConfigurer endpoints) throws Exception { // Redis token方式 endpoints.authenticaionManager(authenticationManager) .userDetailsService(kiteUserDetailsService) .accessTokenConverter(jwtAccessTokenConverter) .tokenStore(jwtTokenStore); } @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception { JdbcClientDetailsServiceBuilder builder = clients.jdbc(dataSource); builder.passwordEncoder(passwordEncoder); } @Override public void configure(AuthorizationServerSecurityConfigurer security) throws Exception { security.allowFromAuthenticationForClients(); security.checkTokenAccess(\u0026#34;isAuthenticated\u0026#34;); security.tokenKeyAccess(\u0026#34;isAuthenticated\u0026#34;); } } 有三个configure方法的重写\nAuthorizationServerEndpointConfigurer参数的重写\nauthenticationManager：用于支持password模式 userDetailsService：设置用户验证服务 tokenStore：制定token的存储方式 accessTokenConverter：开启json web token模式 ClientDetailsServiceConfigure参数的重写：采用数据库配置的方式，预先定义好oauth2_client_details表，如下：\n参数说明：\nclientId、client_secret：这两个参数对应请求端定义的 cleint-id 和 client-secret authorized_grant_types：包括authorization_code（授权码模式）、password（密码模式）、implicit（隐式授权类型）、client_credentials、refresh_token这五种中的一种或多种。 access_token_validity：token的有效期 scopes：用来限定客户端访问的权限，只有在scopes定义内的，才可以正常换取token。 create table oauth_client_details ( client_id VARCHAR(256) PRIMARY KEY, resource_ids VARCHAR(256), client_secret VARCHAR(256), scope VARCHAR(256), authorized_grant_types VARCHAR(256), web_server_redirect_uri VARCHAR(256), authorities VARCHAR(256), access_token_validity INTEGER, refresh_token_validity INTEGER, additional_information VARCHAR(4096), autoapprove VARCHAR(256) ); AuthorizationServerSecurityConfigurer参数的重写：限制客户端访问认证接口的权限\nallowFormAuthenticationForClients()：允许客户端访问OAuth2授权接口，否则返回401 checkTokenAccess ：允许已授权用户访问checkToken接口。 tokenKeyAccess：允许已授权用户访问获取token接口。 6、配置JWTTokenStore @Configuration public class JWTTokenStore { @Bean public TokenStore jwtTokenStore() { return new JwtTokenStore(jwtAccessTokenConverter()); } @Bean public JwtAccessTokenConverter jwtAccessTokenConverter() { JwtAccessTokenConverter accessTokenConverter = new JwtAccessTokenConverter(); accessTokenConverter.setSigningKey(\u0026#34;dev\u0026#34;); return accessTokenConverter; } } 7、启动auth-server 现在已经可以访问OAuth2相关的Restful接口：\nPOST /oauth/authorize 授权码模式认证授权接口 GET/POST /oauth/token 获取 token 的接口 POST /oauth/check_token 检查 token 合法性接口 ","date":"2021-07-15T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/typora/image-hosting-master/image-hosting-master/store/image.rglemef8w74.png","permalink":"https://cuterwrite.top/p/oauth2-guide/","title":"Spring Cloud OAuth2从零开始实现用户认证和单点登录"},{"content":" Table of Contents generated with DocToc\n机器学习重要术语词汇表 精确度Accuracy 曲线下面积 (AUC) 二元分类 校准 分类 决定系数 特征工程 F-score 超参数 Label 对数损失 损失函数 平均绝对误差 (MAE) 多类分类 N 元语法 标准化 管道 Precision Recall 正则化 回归 相对绝对误差 相对平方误差 均方误差根 (RMSE) 机器学习重要术语词汇表 精确度Accuracy 在分类中，准确性是正确分类的项数目除以测试集内的项总数。 范围从 0（最不准确）到 1（最准确）。 准确性是模型性能的评估指标之一。 将其与Precision、Recall和F-score结合考虑。\n曲线下面积 (AUC) 二元分类的一项评估指标，即曲线下面积值，它绘制真阳性率（y 轴）与误报率（x 轴）进行对照。 范围从 0.5（最差）到 1（最佳）。 也称为 ROC 曲线下面积。\n二元分类 一个分类任务，其中标签仅为两个类中的一个。\n校准 校准是将原始分数映射到类成员身份的过程，用于二元和多类分类。\n分类 当使用这些数据来预测某一类别，有监督学习任务被称为“分类”。 二分类指的是仅预测两个类别（例如，将图像划分为“猫”或“狗”图片）。 多分类指的是预测多个类别（例如，当将图像划分为特定品种狗的图片）。\n决定系数 回归中的一项评估指标，表明数据与模型的匹配程度。 范围从 0 到 1。 值 0 表示数据是随机的，否则就无法与模型相匹配。 1 表示模型与数据完全匹配。 这通常称 r 平方值。\n特征工程 特征工程是涉及定义一组特征和开发软件以从可用现象数据中生成特征向量（即特征提取）的过程。\nF-score 分类的一项评估指标，用于平衡Precision和Recall\n超参数 机器学习算法的参数。 示例包括在决策林中学习的树的数量，或者梯度下降算法中的步长。 在对模型进行定型之前，先设置超参数 的值，并控制查找预测函数参数的过程，例如，决策树中的比较点或线性回归模型中的权重。\nLabel 使用机器学习模型进行预测的元素。 例如，狗的品种或将来的股票价格。\n对数损失 在分类中，描述分类器准确性的评估指标。 对数损失越小，分类器越准确。\n损失函数 损失函数是指训练标签值与模型所做预测之间的差异。 通过最小化损失函数来估算模型参数。\n可以为不同的训练程序配置不同的损失函数。\n平均绝对误差 (MAE) 回归中的一项评估指标，即所有模型误差的平均值，其中模型误差是预测标签值和正确标签值之间的差距。\n多类分类 一种分类任务，其中标签为三个或三个以上类中的一个。\nN 元语法 文本数据的特征提取方案：N 个单词的任何序列都将转变为特征值\n标准化 标准化是将浮点数据缩放到 0 到 1 之间的值的过程。\n管道 要将模型与数据集相匹配所需的所有操作。 管道由数据导入、转换、特征化和学习步骤组成。 对管道进行定型后，它会转变为模型。\nPrecision 在分类中，Precision是正确预测为属于该类的项目的数量，除以预测为属于该类的项目的总数。\nRecall 在分类中，Recall是正确预测为属于该类的项目的数量，除以实际属于该类的项目的总数。\n正则化 正则化会对过于复杂的线性模型进行惩罚。 正则化有两种类型：\nL1正则化将无意义特征的权重归零。 进行这种正则化之后，所保存模型的大小可能会变小。 L2正则化将无意义特征的权重范围最小化。 这是一种更通用的过程，并且对离群值不太敏感。 回归 有监督学习任务，其中输出是一个实际值，例如，双精度值。 示例包括预测股票价格。\n相对绝对误差 回归中的一项评估指标，即所有绝对误差总和除以正确标签值和所有正确标签值的平均值之间的差值总和。\n相对平方误差 回归中的一项评估指标，即所有绝对平方误差总和除以正确标签值和所有正确标签值的平均值之间的平方差值总和。\n均方误差根 (RMSE) 误差平方平均值的平方根。\n","date":"2021-07-15T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/typora/image-hosting-master/image-hosting-master/store/image.2lqvb7dnlg80.png","permalink":"https://cuterwrite.top/p/machine-learning-terms/","title":"机器学习重要术语词汇表"},{"content":" Table of Contents generated with DocToc\nStream常见用法 1 Stream概述 2 Stream创建 2.1 Collection.stream() 2.2 Arrays.stream(T[] array) 2.3 Stream.of / iterate / generate 3 Stream使用 3.1 Optional 3.2 遍历 forEach/find/match 3.3 筛选 filter 3.4 聚合 max/min/count 3.5 映射 map/flatMap 3.6 规约 reduce 3.7 收集 collect 3.8 分组 groupingBy/partitioningBy 3.9 连接 joining 3.10 排序 sorted Stream常见用法 1 Stream概述 Stream将要处理的元素集合看作一种流，在流的过程中，借助Stream API对流中的元素进行操作，比如：筛选、排序、聚合等。\nStream可以由数组或集合创建，对流的操作分为两种：\n中间操作，每次返回一个新的流，可以有多个。 终端操作，每个流只能进行一次终端操作，终端操作结束后流无法再次使用。终端操作会产生一个新的集合或值。 另外，Stream有几个特性：\nstream不存储数据，而是按照特定的规则对数据进行计算，一般会输出结果。 stream不会改变数据源，通常情况下会产生一个新的集合或一个值。 stream具有延迟执行特性，只有调用终端操作时，中间操作才会执行。 2 Stream创建 2.1 Collection.stream() List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); Stream\u0026lt;Integer\u0026gt; stream = list.stream(); //并行流 Stream\u0026lt;Integer\u0026gt; parallelStream = list.parallelStream(); 2.2 Arrays.stream(T[] array) int[] array = new int[]{1, 2, 3, 4, 5}; IntStream stream = Arrays.stream(array) 2.3 Stream.of / iterate / generate Stream\u0026lt;Integer\u0026gt; stream = Stream.of(1, 2, 3, 4, 5, 6);\r//创建从0开始，间距为3的stream（个数为4）\rStream\u0026lt;Integer\u0026gt; stream2 = Stream.iterate(0, x -\u0026gt; x + 3).limit(4); 3 Stream使用 3.1 Optional Optional类是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。\n3.2 遍历 forEach/find/match 遍历输出符合条件的元素\nlist.stream().filter(x -\u0026gt; x \u0026gt; 6).forEach(System.out::println); 遍历对元素执行某个方法\nlist.stream().forEach(methodName); 匹配一个\nlist.stream().filter(x -\u0026gt; x \u0026gt; 6).findFirst(); 是否包含特定条件的元素\nlist.stream().anyMatch(x -\u0026gt; x \u0026lt; 6); 所有元素满足条件\nlist.stream().allMatch(x -\u0026gt; x == 1); 3.3 筛选 filter 同上，直接在stream对象上使用就行\n3.4 聚合 max/min/count 获取int数组中中的最大值\nArrays.stream(array).max().getAsInt(); 获取Integer列表中的最大值，需要传入一个Comparator对象\nlist.stream().max(Integer::compareTo).get(); 获取String列里中长度最长的元素\nlist.stream().max(Comparator.comparing(String::length)).get(); 获取员工列表工资最高的员工\nlist.stream().max(Comparator.comparing(Person::getSalary)).get(); 计算Integer集合中大于6的元素的个数\nlist.stream().filter(x -\u0026gt; x \u0026gt; 6).count(); 3.5 映射 map/flatMap 映射，可以将一个流的元素按照一定的映射规则映射到另一个流中。分为map和flatMap：\nmap：接收一个函数作为参数，该函数会被应用到每个元素上，并将其映射成一个新的元素。 flatMap：接收一个函数作为参数，将流中的每个值都换成另一个流，然后把所有流连接成一个流。 将字符串数组的元素全部改成大写\nArrays.stream(array).map(String::toUpperCase).collect(Collectors.toList()); 将员工薪资全部增加1000\nlist.stream().map(person -\u0026gt; { person.setSalary(person.getSalary() + 1000); return person; }).collect(Collectors.toList()); 3.6 规约 reduce 将一个流缩减为一个值，能实现集合求和，求乘积和求最值操作等。\n求Integer列表的元素之和，乘积和最大值\nlist.stream().reduce(Integer::sum).get(); list.stream().reduce((x,y) -\u0026gt; x + y).get(); list.stream().reduce((x,y) -\u0026gt; x * y).get(); 3.7 收集 collect 就是把一个流收集起来，最终可以是收集成一个值也可以收集成一个新的集合。\ncollect主要依赖java.util.stream.Collectors类内置的静态方法。\n归集：toList()，toSet()，toMap() 统计：counting、averagingInt、averagingLong、averagingDouble、maxBy、minBy、summingInt、summingLong、summingDouble、sumarizingInt、sumarizingLong、sumarizingDouble 3.8 分组 groupingBy/partitioningBy 将员工按薪资是否高于8000分组\nlist.stream().collect(Collectors.groupingBy(x -\u0026gt; x.getSalary() \u0026gt; 8000)) 将员工按性别分组\nlist.stream().collect(Collectors.groupingBy(Person::getSex)); 3.9 连接 joining 将stream中的元素用特定的连接符（没有的话，则直接连接）连接成一个字符串。\nlist.stream().collect(Collectors.joining(\u0026#34;,\u0026#34;)); 3.10 排序 sorted 按工资升序排序\nlist.stream().sorted(Compartor.comparing(Person::getSalary)); 按工资倒序排序\nlist.stream().sorted(Compartor.comparing(Person::getSalary)).reversed(); 多列排序\nlist.stream().sorted(Compartor.comparing(Person::getSalary).thenComparing(Person::getAge)); ","date":"2021-05-11T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/typora/image-hosting-master/image-hosting-master/20210503/bridge-5621201_1920.6p53ez4buso0.jpg","permalink":"https://cuterwrite.top/p/java-stream/","title":"Java-Stream常见用法"},{"content":" Table of Contents generated with DocToc\nJavaSE知识点笔记 1 数据类型 1.1 基本类型 1.2 包装类型 1.3 缓存池 2 String 2.1 概述 2.2 不可变的优点 2.2.1 可以缓存hash值 2.2.2 String Pool 2.2.3 安全性 2.2.4 线程安全 2.3 String、StringBuilder和StringBuffer 2.3.1 可变性 2.3.2 线程安全 2.4 String Pool 2.5 new String（“abc”） 3 运算 3.1 参数传递 3.2 float与double 3.3 隐式类型转换 4 关键字 4.1 final 4.2 static 5 Object通用方法 6 继承 6.1 访问权限 6.2 抽象类与接口 6.3 super 6.4 重写与重载 7 反射 8 异常 9 泛型、注解、新特性 JavaSE知识点笔记 1 数据类型 1.1 基本类型 byte/8 char/16 short/16 int/32 float/32 long/64 double/64 boolean/~ 1.2 包装类型 基本类型都有对应的包装类型，基本类型与其对应的包装类型之间的赋值使用自动装箱与拆箱完成。\nInteger x = 2; // 装箱 调用了 Integer.valueOf(2) int y = x; // 拆箱 调用了 X.intValue() 1.3 缓存池 new Integer(123) 与 Integer.valueOf(123) 的区别在于：\nnew Integer(123) 每次都会新建一个对象； Integer.valueOf(123) 会使用缓存池中的对象，多次调用会取得同一个对象的引用。 valueOf() 方法的实现比较简单，就是先判断值是否在缓存池中，如果在的话就直接返回缓存池的内容。\n在 Java 8 中，Integer 缓存池的大小默认为 -128~127。\n编译器会在自动装箱过程调用 valueOf() 方法，因此多个值相同且值在缓存池范围内的 Integer 实例使用自动装箱来创建，那么就会引用相同的对象。\n基本类型对应的缓冲池如下：\nboolean values true and false all byte values short values between -128 and 127 int values between -128 and 127 char in the range \\u0000 to \\u007F 2 String 2.1 概述 String 被声明为 final，因此它不可被继承。(Integer 等包装类也不能被继承）\n在 Java 8 中，String 内部使用 char 数组存储数据。\nprivate final char[] value; 在 Java 9 之后，String 类的实现改用 byte 数组存储字符串，同时使用 coder 来标识使用了哪种编码。\nprivate final byte[] value; private final byte coder; value 数组被声明为 final，这意味着 value 数组初始化之后就不能再引用其它数组。并且 String 内部没有改变 value 数组的方法，因此可以保证 String 不可变。\n2.2 不可变的优点 2.2.1 可以缓存hash值 因为 String 的 hash 值经常被使用，例如 String 用做 HashMap 的 key。不可变的特性可以使得 hash 值也不可变，因此只需要进行一次计算。\n2.2.2 String Pool 如果一个 String 对象已经被创建过了，那么就会从 String Pool 中取得引用。只有 String 是不可变的，才可能使用 String Pool。\n2.2.3 安全性 String 经常作为参数，String 不可变性可以保证参数不可变。例如在作为网络连接参数的情况下如果 String 是可变的，那么在网络连接过程中，String 被改变，改变 String 的那一方以为现在连接的是其它主机，而实际情况却不一定是。\n2.2.4 线程安全 String 不可变性天生具备线程安全，可以在多个线程中安全地使用。\n2.3 String、StringBuilder和StringBuffer 2.3.1 可变性 String不可变 StringBuilder和StringBuffer可变 2.3.2 线程安全 String线程安全 StringBuilder线程不安全 StringBuffer线程安全：synchronized机制 2.4 String Pool 字符串常量池（String Pool）保存着所有字符串字面量（literal strings），这些字面量在编译时期就确定。不仅如此，还可以使用 String 的 intern() 方法在运行过程将字符串添加到 String Pool 中。\n当一个字符串调用 intern() 方法时，如果 String Pool 中已经存在一个字符串和该字符串值相等（使用 equals() 方法进行确定），那么就会返回 String Pool 中字符串的引用；否则，就会在 String Pool 中添加一个新的字符串，并返回这个新字符串的引用。\n在 Java 7 之前，String Pool 被放在运行时常量池中，它属于永久代。而在 Java 7，String Pool 被移到堆中。这是因为永久代的空间有限，在大量使用字符串的场景下会导致 OutOfMemoryError 错误。\n2.5 new String（“abc”） 使用这种方式一共会创建两个字符串对象（前提是 String Pool 中还没有 \u0026ldquo;abc\u0026rdquo; 字符串对象）。\n\u0026ldquo;abc\u0026rdquo; 属于字符串字面量，因此编译时期会在 String Pool 中创建一个字符串对象，指向这个 \u0026ldquo;abc\u0026rdquo; 字符串字面量； 而使用 new 的方式会在堆中创建一个字符串对象。 3 运算 3.1 参数传递 Java 的参数是以值传递的形式传入方法中，而不是引用传递。\n3.2 float与double Java 不能隐式执行向下转型，因为这会使得精度降低。\n3.3 隐式类型转换 使用+=和++运算符会执行隐式类型转换，相当于强制类型转换。\n（比如：int转short）\n4 关键字 4.1 final （1）数据\n声明数据为常量，可以是编译时常量，也可以是在运行时被初始化后不能被改变的常量。\n对于基本类型，final 使数值不变； 对于引用类型，final 使引用不变，也就不能引用其它对象，但是被引用的对象本身是可以修改的。 （2）方法\n声明方法不能被子类重写。\nprivate 方法隐式地被指定为 final，如果在子类中定义的方法和基类中的一个 private 方法签名相同，此时子类的方法不是重写基类方法，而是在子类中定义了一个新的方法。\n（3）类\n声明类不允许被继承。\n4.2 static 1. 静态变量\n静态变量：又称为类变量，也就是说这个变量属于类的，类所有的实例都共享静态变量，可以直接通过类名来访问它。静态变量在内存中只存在一份。 实例变量：每创建一个实例就会产生一个实例变量，它与该实例同生共死。 2. 静态方法\n静态方法在类加载的时候就存在了，它不依赖于任何实例。所以静态方法必须有实现，也就是说它不能是抽象方法。\n3. 静态语句块\n静态语句块在类初始化时运行一次。\n4. 静态内部类\n非静态内部类依赖于外部类的实例，也就是说需要先创建外部类实例，才能用这个实例去创建非静态内部类。而静态内部类不需要。\n5. 静态导包\n在使用静态变量和方法时不用再指明 ClassName，从而简化代码，但可读性大大降低。\n6. 初始化顺序\n静态变量和静态语句块优先于实例变量和普通语句块，静态变量和静态语句块的初始化顺序取决于它们在代码中的顺序。\n5 Object通用方法 hashcode equals clone toString getClass finalize notify notifyAll wait 6 继承 6.1 访问权限 private、protected、public，以及default（如果不加访问修饰符，表示包级可见。）\n可以对类或类中的成员（字段和方法）加上访问修饰符。\n类可见表示其它类可以用这个类创建实例对象。 成员可见表示其它类可以用这个类的实例对象访问到该成员； protected 用于修饰成员，表示在继承体系中成员对于子类可见，但是这个访问修饰符对于类没有意义。\n6.2 抽象类与接口 1. 抽象类\n抽象类和抽象方法都使用 abstract 关键字进行声明。如果一个类中包含抽象方法，那么这个类必须声明为抽象类。\n抽象类和普通类最大的区别是，抽象类不能被实例化，只能被继承。\n2. 接口\n接口是抽象类的延伸，在 Java 8 之前，它可以看成是一个完全抽象的类，也就是说它不能有任何的方法实现。\n从 Java 8 开始，接口也可以拥有默认的方法实现，这是因为不支持默认方法的接口的维护成本太高了。在 Java 8 之前，如果一个接口想要添加新的方法，那么要修改所有实现了该接口的类，让它们都实现新增的方法。\n接口的成员（字段 + 方法）默认都是 public 的，并且不允许定义为 private 或者 protected。从 Java 9 开始，允许将方法定义为 private，这样就能定义某些复用的代码又不会把方法暴露出去。\n接口的字段默认都是 static 和 final 的。\n6.3 super 访问父类的构造函数：可以使用 super() 函数访问父类的构造函数，从而委托父类完成一些初始化的工作。应该注意到，子类一定会调用父类的构造函数来完成初始化工作，一般是调用父类的默认构造函数，如果子类需要调用父类其它构造函数，那么就可以使用 super() 函数。 访问父类的成员：如果子类重写了父类的某个方法，可以通过使用 super 关键字来引用父类的方法实现。 6.4 重写与重载 1. 重写（Override）\n存在于继承体系中，指子类实现了一个与父类在方法声明上完全相同的一个方法。\n为了满足里式替换原则，重写有以下三个限制：\n子类方法的访问权限必须大于等于父类方法； 子类方法的返回类型必须是父类方法返回类型或为其子类型。 子类方法抛出的异常类型必须是父类抛出异常类型或为其子类型。 使用 @Override 注解，可以让编译器帮忙检查是否满足上面的三个限制条件。\n2. 重载（Overload）\n存在于同一个类中，指一个方法与已经存在的方法名称上相同，但是参数类型、个数、顺序至少有一个不同。\n应该注意的是，返回值不同，其它都相同不算是重载。\n7 反射 每个类都有一个 Class 对象，包含了与类有关的信息。当编译一个新类时，会产生一个同名的 .class 文件，该文件内容保存着 Class 对象。\n类加载相当于 Class 对象的加载，类在第一次使用时才动态加载到 JVM 中。也可以使用 Class.forName(\u0026quot;com.mysql.jdbc.Driver\u0026quot;) 这种方式来控制类的加载，该方法会返回一个 Class 对象。\n反射可以提供运行时的类信息，并且这个类可以在运行时才加载进来，甚至在编译时期该类的 .class 不存在也可以加载进来。\nClass 和 java.lang.reflect 一起对反射提供了支持，java.lang.reflect 类库主要包含了以下三个类：\nField ：可以使用 get() 和 set() 方法读取和修改 Field 对象关联的字段； Method ：可以使用 invoke() 方法调用与 Method 对象关联的方法； Constructor ：可以用 Constructor 的 newInstance() 创建新的对象。 反射的优点：\n可扩展性 ：应用程序可以利用全限定名创建可扩展对象的实例，来使用来自外部的用户自定义类。 类浏览器和可视化开发环境 ：一个类浏览器需要可以枚举类的成员。可视化开发环境（如 IDE）可以从利用反射中可用的类型信息中受益，以帮助程序员编写正确的代码。 调试器和测试工具 ： 调试器需要能够检查一个类里的私有成员。测试工具可以利用反射来自动地调用类里定义的可被发现的 API 定义，以确保一组测试中有较高的代码覆盖率。 反射的缺点：\n尽管反射非常强大，但也不能滥用。如果一个功能可以不用反射完成，那么最好就不用。在我们使用反射技术时，下面几条内容应该牢记于心。\n性能开销 ：反射涉及了动态类型的解析，所以 JVM 无法对这些代码进行优化。因此，反射操作的效率要比那些非反射操作低得多。我们应该避免在经常被执行的代码或对性能要求很高的程序中使用反射。 安全限制 ：使用反射技术要求程序必须在一个没有安全限制的环境中运行。如果一个程序必须在有安全限制的环境中运行，如 Applet，那么这就是个问题了。 内部暴露 ：由于反射允许代码执行一些在正常情况下不被允许的操作（比如访问私有的属性和方法），所以使用反射可能会导致意料之外的副作用，这可能导致代码功能失调并破坏可移植性。反射代码破坏了抽象性，因此当平台发生改变的时候，代码的行为就有可能也随着变化。 8 异常 Throwable 可以用来表示任何可以作为异常抛出的类，分为两种： Error 和 Exception。其中 Error 用来表示 JVM 无法处理的错误，Exception 分为两种：\n受检异常 ：需要用 try\u0026hellip;catch\u0026hellip; 语句捕获并进行处理，并且可以从异常中恢复； 非受检异常 ：是程序运行时错误，例如除 0 会引发 Arithmetic Exception，此时程序崩溃并且无法恢复。 9 泛型、注解、新特性 略。\n本文转载自：https://github.com/CyC2018/CS-Notes，用于个人复习。\n","date":"2021-05-04T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/typora/image-hosting-master/image-hosting-master/20210503/river-6021951_1920.4hwe8w8ugb20.jpg","permalink":"https://cuterwrite.top/p/java-se/","title":"JavaSE知识点笔记"},{"content":" Table of Contents generated with DocToc\nJava并发知识点笔记 1 使用线程的方法 2 基础线程机制 2.1 Executor 2.2 Daemon 2.3 sleep() 2.4 yield() 3 线程中断 3.1 InterruptedException 3.2 interrupted() 3.3 Executor 的中断操作 4 互斥锁 4.1 synchronized 4.2 ReentrantLock 4.3 比较 4.4 选择 5 线程协作 5.1 join 5.2 wait/notify 5.3 await/signal 6 线程状态 7 JUC包/AQS 7.1 CountDownLatch 7.2 CyclicBarrier 7.3 Semaphore 8 JUC包其它组件 8.1 FutureTask 8.2 BlockingQueue 8.3 ForkJoin 9 内存模型 9.1 主内存与工作内存 9.2 内存间交互操作 9.3 内存模型三大特性 9.3.1. 原子性 9.3.2. 可见性 9.3.3. 有序性 9.4 先行发生原则 10 线程安全策略 10.1 不可变 10.2 互斥同步 10.3 非阻塞同步 10.4 无同步 10.4.1 栈封闭 10.4.2 线程本地存储 10.4.3 可重入代码 11 锁优化 11.1 自旋锁 11.2 锁消除 11.3 锁粗化 11.4 轻量级锁 11.5 偏向锁 Java并发知识点笔记 1 使用线程的方法 实现 Runnable 接口； 实现 Callable 接口； 继承 Thread 类。 2 基础线程机制 2.1 Executor Executor 管理多个异步任务的执行，而无需程序员显式地管理线程的生命周期。这里的异步是指多个任务的执行互不干扰，不需要进行同步操作。\n主要有三种 Executor：\nCachedThreadPool：一个任务创建一个线程； FixedThreadPool：所有任务只能使用固定大小的线程； SingleThreadExecutor：相当于大小为 1 的 FixedThreadPool。 2.2 Daemon 守护线程是程序运行时在后台提供服务的线程，不属于程序中不可或缺的部分。\n当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。\nmain() 属于非守护线程。\n在线程启动之前使用 setDaemon() 方法可以将一个线程设置为守护线程。\n2.3 sleep() Thread.sleep(millisec) 方法会休眠当前正在执行的线程，millisec 单位为毫秒。\nsleep() 可能会抛出 InterruptedException，因为异常不能跨线程传播回 main() 中，因此必须在本地进行处理。线程中抛出的其它异常也同样需要在本地进行处理。\n2.4 yield() 对静态方法 Thread.yield() 的调用声明了当前线程已经完成了生命周期中最重要的部分，可以切换给其它线程来执行。该方法只是对线程调度器的一个建议，而且也只是建议具有相同优先级的其它线程可以运行。\n3 线程中断 一个线程执行完毕之后会自动结束，如果在运行过程中发生异常也会提前结束。\n3.1 InterruptedException 通过调用一个线程的 interrupt() 来中断该线程，如果该线程处于阻塞、限期等待或者无限期等待状态，那么就会抛出 InterruptedException，从而提前结束该线程。但是不能中断 I/O 阻塞和 synchronized 锁阻塞。\n3.2 interrupted() 如果一个线程的 run() 方法执行一个无限循环，并且没有执行 sleep() 等会抛出 InterruptedException 的操作，那么调用线程的 interrupt() 方法就无法使线程提前结束。\n但是调用 interrupt() 方法会设置线程的中断标记，此时调用 interrupted() 方法会返回 true。因此可以在循环体中使用 interrupted() 方法来判断线程是否处于中断状态，从而提前结束线程。\n3.3 Executor 的中断操作 调用 Executor 的 shutdown() 方法会等待线程都执行完毕之后再关闭，但是如果调用的是 shutdownNow() 方法，则相当于调用每个线程的 interrupt() 方法。\n4 互斥锁 Java 提供了两种锁机制来控制多个线程对共享资源的互斥访问，第一个是 JVM 实现的 synchronized，而另一个是 JDK 实现的 ReentrantLock。\n4.1 synchronized 同步代码块：锁对象 同步一个方法：锁对象 同步一个类：锁整个类 同步一个静态方法：锁整个类 4.2 ReentrantLock ReentrantLock 是 java.util.concurrent（J.U.C）包中的锁。\n通过lock和unlock操作\n4.3 比较 1. 锁的实现\nsynchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的。\n2. 性能\n新版本 Java 对 synchronized 进行了很多优化，例如自旋锁等，synchronized 与 ReentrantLock 大致相同。\n3. 等待可中断\n当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。\nReentrantLock 可中断，而 synchronized 不行。\n4. 公平锁\n公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。\nsynchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但是也可以是公平的。\n5. 锁绑定多个条件\n一个 ReentrantLock 可以同时绑定多个 Condition 对象。\n4.4 选择 除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。这是因为 synchronized 是 JVM 实现的一种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。\n5 线程协作 5.1 join 在线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是忙等待，直到目标线程结束。\n5.2 wait/notify 调用 wait() 使得线程等待某个条件满足，线程在等待时会被挂起，当其他线程的运行使得这个条件满足时，其它线程会调用 notify() 或者 notifyAll() 来唤醒挂起的线程。\n它们都属于 Object 的一部分，而不属于 Thread。\n只能用在同步方法或者同步控制块中使用，否则会在运行时抛出 IllegalMonitorStateException。\n使用 wait() 挂起期间，线程会释放锁。这是因为，如果没有释放锁，那么其它线程就无法进入对象的同步方法或者同步控制块中，那么就无法执行 notify() 或者 notifyAll() 来唤醒挂起的线程，造成死锁\nwait() 和 sleep() 的区别\nwait() 是 Object 的方法，而 sleep() 是 Thread 的静态方法； wait() 会释放锁，sleep() 不会。 5.3 await/signal java.util.concurrent 类库中提供了 Condition 类来实现线程之间的协调，可以在 Condition 上调用 await() 方法使线程等待，其它线程调用 signal() 或 signalAll() 方法唤醒等待的线程。\n相比于 wait() 这种等待方式，await() 可以指定等待的条件，因此更加灵活。\n使用 Lock 来获取一个 Condition 对象。\n6 线程状态 new runable blocked waiting timed_waiting terminated 7 JUC包/AQS 7.1 CountDownLatch 用来控制一个或者多个线程等待多个线程。\n维护了一个计数器 cnt，每次调用 countDown() 方法会让计数器的值减 1，减到 0 的时候，那些因为调用 await() 方法而在等待的线程就会被唤醒。\n7.2 CyclicBarrier 用来控制多个线程互相等待，只有当多个线程都到达时，这些线程才会继续执行。\n和 CountdownLatch 相似，都是通过维护计数器来实现的。线程执行 await() 方法之后计数器会减 1，并进行等待，直到计数器为 0，所有调用 await() 方法而在等待的线程才能继续执行。\nCyclicBarrier 和 CountdownLatch 的一个区别是，CyclicBarrier 的计数器通过调用 reset() 方法可以循环使用，所以它才叫做循环屏障。\nCyclicBarrier 有两个构造函数，其中 parties 指示计数器的初始值，barrierAction 在所有线程都到达屏障的时候会执行一次。\n7.3 Semaphore Semaphore 类似于操作系统中的信号量，可以控制对互斥资源的访问线程数。\n8 JUC包其它组件 8.1 FutureTask 在介绍 Callable 时我们知道它可以有返回值，返回值通过 Future\u0026lt;V\u0026gt; 进行封装。FutureTask 实现了 RunnableFuture 接口，该接口继承自 Runnable 和 Future\u0026lt;V\u0026gt; 接口，这使得 FutureTask 既可以当做一个任务执行，也可以有返回值。\nFutureTask 可用于异步获取执行结果或取消执行任务的场景。当一个计算任务需要执行很长时间，那么就可以用 FutureTask 来封装这个任务，主线程在完成自己的任务之后再去获取结果。\n8.2 BlockingQueue java.util.concurrent.BlockingQueue 接口有以下阻塞队列的实现：\nFIFO 队列 ：LinkedBlockingQueue、ArrayBlockingQueue（固定长度） 优先级队列 ：PriorityBlockingQueue 提供了阻塞的 take() 和 put() 方法：如果队列为空 take() 将阻塞，直到队列中有内容；如果队列为满 put() 将阻塞，直到队列有空闲位置。\n8.3 ForkJoin 主要用于并行计算中，和 MapReduce 原理类似，都是把大的计算任务拆分成多个小任务并行计算。\nForkJoinPool 实现了工作窃取算法来提高 CPU 的利用率。每个线程都维护了一个双端队列，用来存储需要执行的任务。工作窃取算法允许空闲的线程从其它线程的双端队列中窃取一个任务来执行。窃取的任务必须是最晚的任务，避免和队列所属线程发生竞争。例如下图中，Thread2 从 Thread1 的队列中拿出最晚的 Task1 任务，Thread1 会拿出 Task2 来执行，这样就避免发生竞争。但是如果队列中只有一个任务时还是会发生竞争。\n9 内存模型 Java 内存模型试图屏蔽各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台下都能达到一致的内存访问效果。\n9.1 主内存与工作内存 处理器上的寄存器的读写的速度比内存快几个数量级，为了解决这种速度矛盾，在它们之间加入了高速缓存。\n加入高速缓存带来了一个新的问题：缓存一致性。如果多个缓存共享同一块主内存区域，那么多个缓存的数据可能会不一致，需要一些协议来解决这个问题。\n所有的变量都存储在主内存中，每个线程还有自己的工作内存，工作内存存储在高速缓存或者寄存器中，保存了该线程使用的变量的主内存副本拷贝。\n线程只能直接操作工作内存中的变量，不同线程之间的变量值传递需要通过主内存来完成。\n9.2 内存间交互操作 Java 内存模型定义了 8 个操作来完成主内存和工作内存的交互操作。\nread：把一个变量的值从主内存传输到工作内存中 load：在 read 之后执行，把 read 得到的值放入工作内存的变量副本中 use：把工作内存中一个变量的值传递给执行引擎 assign：把一个从执行引擎接收到的值赋给工作内存的变量 store：把工作内存的一个变量的值传送到主内存中 write：在 store 之后执行，把 store 得到的值放入主内存的变量中 lock：作用于主内存的变量 unlock 9.3 内存模型三大特性 9.3.1. 原子性 Java 内存模型保证了 read、load、use、assign、store、write、lock 和 unlock 操作具有原子性，例如对一个 int 类型的变量执行 assign 赋值操作，这个操作就是原子性的。但是 Java 内存模型允许虚拟机将没有被 volatile 修饰的 64 位数据（long，double）的读写操作划分为两次 32 位的操作来进行，即 load、store、read 和 write 操作可以不具备原子性。\n有一个错误认识就是，int 等原子性的类型在多线程环境中不会出现线程安全问题。前面的线程不安全示例代码中，cnt 属于 int 类型变量，1000 个线程对它进行自增操作之后，得到的值为 997 而不是 1000。\n为了方便讨论，将内存间的交互操作简化为 3 个：load、assign、store。\n下图演示了两个线程同时对 cnt 进行操作，load、assign、store 这一系列操作整体上看不具备原子性，那么在 T1 修改 cnt 并且还没有将修改后的值写入主内存，T2 依然可以读入旧值。可以看出，这两个线程虽然执行了两次自增运算，但是主内存中 cnt 的值最后为 1 而不是 2。因此对 int 类型读写操作满足原子性只是说明 load、assign、store 这些单个操作具备原子性。\nAtomicInteger 能保证多个线程修改的原子性。\n除了使用原子类之外，也可以使用 synchronized 互斥锁来保证操作的原子性。它对应的内存间交互操作为：lock 和 unlock，在虚拟机实现上对应的字节码指令为 monitorenter 和 monitorexit。\n9.3.2. 可见性 可见性指当一个线程修改了共享变量的值，其它线程能够立即得知这个修改。Java 内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可见性的。\n主要有三种实现可见性的方式：\nvolatile synchronized，对一个变量执行 unlock 操作之前，必须把变量值同步回主内存。 final，被 final 关键字修饰的字段在构造器中一旦初始化完成，并且没有发生 this 逃逸（其它线程通过 this 引用访问到初始化了一半的对象），那么其它线程就能看见 final 字段的值。 对前面的线程不安全示例中的 cnt 变量使用 volatile 修饰，不能解决线程不安全问题，因为 volatile 并不能保证操作的原子性。\n9.3.3. 有序性 有序性是指：在本线程内观察，所有操作都是有序的。在一个线程观察另一个线程，所有操作都是无序的，无序是因为发生了指令重排序。在 Java 内存模型中，允许编译器和处理器对指令进行重排序，重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。\nvolatile 关键字通过添加内存屏障的方式来禁止指令重排，即重排序时不能把后面的指令放到内存屏障之前。\n也可以通过 synchronized 来保证有序性，它保证每个时刻只有一个线程执行同步代码，相当于是让线程顺序执行同步代码。\n9.4 先行发生原则 上面提到了可以用 volatile 和 synchronized 来保证有序性。除此之外，JVM 还规定了先行发生原则，让一个操作无需控制就能先于另一个操作完成。\n单一线程原则：在一个线程内，在程序前面的操作先行发生于后面的操作。 管程锁定规则：一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。 volatile 变量规则：对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作。 线程启动规则：Thread 对象的 start() 方法调用先行发生于此线程的每一个动作。 线程加入规则：Thread 对象的结束先行发生于 join() 方法返回。 线程中断规则：对线程 interrupt() 方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过 interrupted() 方法检测到是否有中断发生。 对象终结规则：一个对象的初始化完成（构造函数执行结束）先行发生于它的 finalize() 方法的开始。 传递性：如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么操作 A 先行发生于操作 C。 10 线程安全策略 10.1 不可变 不可变的类型：\nfinal 关键字修饰的基本数据类型 String 枚举类型 Number 部分子类，如 Long 和 Double 等数值包装类型，BigInteger 和 BigDecimal 等大数据类型。但同为 Number 的原子类 AtomicInteger 和 AtomicLong 则是可变的。 对于集合类型，可以使用 Collections.unmodifiableXXX() 方法来获取一个不可变的集合。\n10.2 互斥同步 synchronized 和 ReentrantLock。\n10.3 非阻塞同步 CAS AtomicInteger ABA问题：如果一个变量初次读取的时候是 A 值，它的值被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。\n解决方法：J.U.C 包提供了一个带有标记的原子引用类 AtomicStampedReference 来解决这个问题，它可以通过控制变量值的版本来保证 CAS 的正确性。大部分情况下 ABA 问题不会影响程序并发的正确性，如果需要解决 ABA 问题，改用传统的互斥同步可能会比原子类更高效。\n10.4 无同步 10.4.1 栈封闭 多个线程访问同一个方法的局部变量时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有的。\n10.4.2 线程本地存储 如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。\n它提供了线程本地变量，也就是如果你创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的一个本地拷贝，多个线程操作这个变量的时候，实际是操作的自己本地内存里面的变量，从而避免了线程安全问题\n每个 Thread 都有一个 ThreadLocal.ThreadLocalMap 对象。\n当调用一个 ThreadLocal 的 set(T value) 方法时，先得到当前线程的 ThreadLocalMap 对象，然后将 ThreadLocal-\u0026gt;value 键值对插入到该 Map 中。\n10.4.3 可重入代码 这种代码也叫做纯代码（Pure Code），可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回后，原来的程序不会出现任何错误。\n可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。\n11 锁优化 11.1 自旋锁 自旋锁的思想是让一个线程在请求一个共享数据的锁时执行忙循环（自旋）一段时间，如果在这段时间内能获得锁，就可以避免进入阻塞状态。\n自旋锁虽然能避免进入阻塞状态从而减少开销，但是它需要进行忙循环操作占用 CPU 时间，它只适用于共享数据的锁定状态很短的场景。\n在 JDK 1.6 中引入了自适应的自旋锁。自适应意味着自旋的次数不再固定了，而是由前一次在同一个锁上的自旋次数及锁的拥有者的状态来决定。\n11.2 锁消除 锁消除是指对于被检测出不可能存在竞争的共享数据的锁进行消除。\n锁消除主要是通过逃逸分析来支持，如果堆上的共享数据不可能逃逸出去被其它线程访问到，那么就可以把它们当成私有数据对待，也就可以将它们的锁进行消除。\n11.3 锁粗化 如果一系列的连续操作都对同一个对象反复加锁和解锁，频繁的加锁操作就会导致性能损耗。\n如果虚拟机探测到由这样的一串零碎的操作都对同一个对象加锁，将会把加锁的范围扩展（粗化）到整个操作序列的外部。\n11.4 轻量级锁 JDK 1.6 引入了偏向锁和轻量级锁，从而让锁拥有了四个状态：无锁状态（unlocked）、偏向锁状态（biasble）、轻量级锁状态（lightweight locked）和重量级锁状态（inflated）。\n轻量级锁是相对于传统的重量级锁而言，它使用 CAS 操作来避免重量级锁使用互斥量的开销。对于绝大部分的锁，在整个同步周期内都是不存在竞争的，因此也就不需要都使用互斥量进行同步，可以先采用 CAS 操作进行同步，如果 CAS 失败了再改用互斥量进行同步。\n11.5 偏向锁 偏向锁的思想是偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要。\n本文转载自：https://github.com/CyC2018/CS-Notes，用于个人复习。\n","date":"2021-05-04T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/typora/image-hosting-master/image-hosting-master/20210503/santorini-1578440_1920.3ldusy6rm1k0.jpg","permalink":"https://cuterwrite.top/p/java-concurrent/","title":"Java并发知识点笔记"},{"content":" Table of Contents generated with DocToc\nJava容器知识点笔记 1 概述 1.1 Collection 1.1.1 Set 1.1.2 List 1.1.3 Queue 2 源码分析 2.1 ArrayList 2.1.1 概述 2.1.2 扩容 2.1.3 删除元素 2.1.4 序列化 2.1.5 Fail-fast 2.2 Vector 2.2.1 同步 2.2.2 扩容 2.2.3 与ArrayList的比较 2.2.4 替代方案 2.3 CopyOnWriteArrayList 2.3.1 读写分离 2.3.2 适用场景 2.4 LinkedList 2.4.1 概述 2.4.2 与ArrayList的比较 2.5 HashMap 2.5.1 概述 2.5.2 拉链法 2.5.3 确认桶下标方法 2.5.4 扩容基本原理 2.5.5 扩容重新计算桶下标 2.5.6 与HashTable对比 2.6 ConcurrentHashMap 2.6.1 存储结构 2.6.2 size操作 2.6.3 jdk8的改动 2.7 LinkedHashMap 2.7.1 存储结构 2.7.2 afterNodeAccess() 2.7.3 afterNodeInsertion() Java容器知识点笔记 1 概述 容器主要包括 Collection 和 Map 两种，Collection 存储着对象的集合，而 Map 存储着键值对（两个对象）的映射表。\n1.1 Collection 1.1.1 Set TreeSet：基于红黑树实现，支持有序性操作，例如根据一个范围查找元素的操作。但是查找效率不如 HashSet，HashSet 查找的时间复杂度为 O(1)，TreeSet 则为 O(logN)。\nHashSet：基于哈希表实现，支持快速查找，但不支持有序性操作。并且失去了元素的插入顺序信息，也就是说使用 Iterator 遍历 HashSet 得到的结果是不确定的。\nLinkedHashSet：具有 HashSet 的查找效率，并且内部使用双向链表维护元素的插入顺序。\n1.1.2 List ArrayList：基于动态数组实现，支持随机访问。\nVector：和 ArrayList 类似，但它是线程安全的。\nLinkedList：基于双向链表实现，只能顺序访问，但是可以快速地在链表中间插入和删除元素。不仅如此，LinkedList 还可以用作栈、队列和双向队列。\n1.1.3 Queue LinkedList：可以用它来实现双向队列。 PriorityQueue：基于堆结构实现，可以用它来实现优先队列。 2 源码分析 2.1 ArrayList 2.1.1 概述 因为 ArrayList 是基于数组实现的，所以支持快速随机访问。RandomAccess 接口标识着该类支持快速随机访问，默认容量为10\ntransient Object[] elementData; private static final int DEFAULT_CAPACITY = 10; 2.1.2 扩容 添加元素时使用 ensureCapacityInternal() 方法来保证容量足够，如果不够时，需要使用 grow() 方法进行扩容，新容量的大小为 oldCapacity + (oldCapacity \u0026gt;\u0026gt; 1)，即 oldCapacity+oldCapacity/2。其中 oldCapacity \u0026raquo; 1 需要取整，所以新容量大约是旧容量的 1.5 倍左右。（oldCapacity 为偶数就是 1.5 倍，为奇数就是 1.5 倍-0.5）\n扩容操作需要调用 Arrays.copyOf() 把原数组整个复制到新数组中，这个操作代价很高，因此最好在创建 ArrayList 对象时就指定大概的容量大小，减少扩容操作的次数。\n2.1.3 删除元素 需要调用 System.arraycopy() 将 index+1 后面的元素都复制到 index 位置上，该操作的时间复杂度为 O(N)，可以看到 ArrayList 删除元素的代价是非常高的。\n2.1.4 序列化 ArrayList 基于数组实现，并且具有动态扩容特性，因此保存元素的数组不一定都会被使用，那么就没必要全部进行序列化。\n保存元素的数组 elementData 使用 transient 修饰，该关键字声明数组默认不会被序列化。\nArrayList 实现了 writeObject() 和 readObject() 来控制只序列化数组中有元素填充那部分内容。\n序列化时需要使用 ObjectOutputStream 的 writeObject() 将对象转换为字节流并输出。而 writeObject() 方法在传入的对象存在 writeObject() 的时候会去反射调用该对象的 writeObject() 来实现序列化。反序列化使用的是 ObjectInputStream 的 readObject() 方法，原理类似。\n2.1.5 Fail-fast modCount 用来记录 ArrayList 结构发生变化的次数。结构发生变化是指添加或者删除至少一个元素的所有操作，或者是调整内部数组的大小，仅仅只是设置元素的值不算结构发生变化。\n在进行序列化或者迭代等操作时，需要比较操作前后 modCount 是否改变，如果改变了需要抛出 ConcurrentModificationException。代码参考上节序列化中的 writeObject() 方法。\n2.2 Vector 2.2.1 同步 它的实现与 ArrayList 类似，但是使用了 synchronized 进行同步。\n2.2.2 扩容 Vector 的构造函数可以传入 capacityIncrement 参数，它的作用是在扩容时使容量 capacity 增长 capacityIncrement。如果这个参数的值小于等于 0，扩容时每次都令 capacity 为原来的两倍。\n调用没有 capacityIncrement 的构造函数时，capacityIncrement 值被设置为 0，也就是说默认情况下 Vector 每次扩容时容量都会翻倍。\n2.2.3 与ArrayList的比较 Vector 是同步的，因此开销就比 ArrayList 要大，访问速度更慢。最好使用 ArrayList 而不是 Vector，因为同步操作完全可以由程序员自己来控制； Vector 每次扩容请求其大小的 2 倍（也可以通过构造函数设置增长的容量），而 ArrayList 是 1.5 倍。 2.2.4 替代方案 可以使用 Collections.synchronizedList(); 得到一个线程安全的 ArrayList。\n也可以使用 concurrent 并发包下的 CopyOnWriteArrayList 类。\n2.3 CopyOnWriteArrayList 2.3.1 读写分离 写操作在一个复制的数组上进行，读操作还是在原始数组中进行，读写分离，互不影响。\n写操作需要加锁，防止并发写入时导致写入数据丢失。\n写操作结束之后需要把原始数组指向新的复制数组。\n2.3.2 适用场景 CopyOnWriteArrayList 在写操作的同时允许读操作，大大提高了读操作的性能，因此很适合读多写少的应用场景。\n但是 CopyOnWriteArrayList 有其缺陷：\n内存占用：在写操作时需要复制一个新的数组，使得内存占用为原来的两倍左右； 数据不一致：读操作不能读取实时性的数据，因为部分写操作的数据还未同步到读数组中。 所以 CopyOnWriteArrayList 不适合内存敏感以及对实时性要求很高的场景。\n2.4 LinkedList 2.4.1 概述 基于双向链表实现，使用 Node 存储链表节点信息。\nprivate static class Node\u0026lt;E\u0026gt; { E item; Node\u0026lt;E\u0026gt; next; Node\u0026lt;E\u0026gt; prev; } 每个链表存储了 first 和 last 指针：\ntransient Node\u0026lt;E\u0026gt; first; transient Node\u0026lt;E\u0026gt; last; 2.4.2 与ArrayList的比较 ArrayList 基于动态数组实现，LinkedList 基于双向链表实现。ArrayList 和 LinkedList 的区别可以归结为数组和链表的区别：\n数组支持随机访问，但插入删除的代价很高，需要移动大量元素； 链表不支持随机访问，但插入删除只需要改变指针。 2.5 HashMap 2.5.1 概述 基于数组+链表+红黑树实现 transient Node\u0026lt;K,V\u0026gt;[] table; 默认容量16，每次扩容为2倍 默认负载因子为0.75 当链表长度大于等于8时，检查table长度是否大于64，如果是则转成红黑树。 基本原理：通过key的hashcode经过扰动处理得到hash值，然后通过(n - 1) \u0026amp; hash判断当前元素存放的位置，如果当前位置存在元素的话，就判断该元素与要存放的元素的hash值以及key是否相同，如果相同则直接覆盖，不相同就用拉链法解决冲突。 2.5.2 拉链法 将链表和数组相结合。也就是说创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可。\n2.5.3 确认桶下标方法 计算key的hash（h = key.hashcode(); h ^ (h \u0026raquo;\u0026gt; 16)） hash \u0026amp; (n - 1) 2.5.4 扩容基本原理 设 HashMap 的 table 长度为 M，需要存储的键值对数量为 N，如果哈希函数满足均匀性的要求，那么每条链表的长度大约为 N/M，因此查找的复杂度为 O(N/M)。\n为了让查找的成本降低，应该使 N/M 尽可能小，因此需要保证 M 尽可能大，也就是说 table 要尽可能大。HashMap 采用动态扩容来根据当前的 N 值来调整 M 值，使得空间效率和时间效率都能得到保证。\n扩容使用 resize() 实现，需要注意的是，扩容操作同样需要把 oldTable 的所有键值对重新插入 newTable 中，因此这一步是很费时的。\n2.5.5 扩容重新计算桶下标 在进行扩容时，需要把键值对重新计算桶下标，从而放到对应的桶上。在前面提到，HashMap 使用 hash%capacity 来确定桶下标。HashMap capacity 为 2 的 n 次方这一特点能够极大降低重新计算桶下标操作的复杂度。\n2.5.6 与HashTable对比 Hashtable 使用 synchronized 来进行同步。 HashMap 可以插入键为 null 的 Entry。 HashMap 的迭代器是 fail-fast 迭代器。 HashMap 不能保证随着时间的推移 Map 中的元素次序是不变的。 2.6 ConcurrentHashMap 2.6.1 存储结构 ConcurrentHashMap 和 HashMap 实现上类似，最主要的差别是 ConcurrentHashMap 采用了分段锁（Segment），每个分段锁维护着几个桶（HashEntry），多个线程可以同时访问不同分段锁上的桶，从而使其并发度更高（并发度就是 Segment 的个数）。\nSegment 继承自 ReentrantLock。\n默认的并发级别为 16，也就是说默认创建 16 个 Segment。\n2.6.2 size操作 每个 Segment 维护了一个 count 变量来统计该 Segment 中的键值对个数。\n在执行 size 操作时，需要遍历所有 Segment 然后把 count 累计起来。\nConcurrentHashMap 在执行 size 操作时先尝试不加锁，如果连续两次不加锁操作得到的结果一致，那么可以认为这个结果是正确的。\n尝试次数使用 RETRIES_BEFORE_LOCK 定义，该值为 2，retries 初始值为 -1，因此尝试次数为 3。\n如果尝试的次数超过 3 次，就需要对每个 Segment 加锁。\n2.6.3 jdk8的改动 JDK 1.7 使用分段锁机制来实现并发更新操作，核心类为 Segment，它继承自重入锁 ReentrantLock，并发度与 Segment 数量相等。\nJDK 1.8 使用了 CAS 操作来支持更高的并发度，在 CAS 操作失败时使用内置锁 synchronized。\n并且 JDK 1.8 的实现也在链表过长时会转换为红黑树。\n2.7 LinkedHashMap 2.7.1 存储结构 继承自 HashMap，因此具有和 HashMap 一样的快速查找特性。\n内部维护了一个双向链表，用来维护插入顺序或者 LRU 顺序。\ntransient LinkedHashMap.Entry\u0026lt;K,V\u0026gt; head; transient LinkedHashMap.Entry\u0026lt;K,V\u0026gt; tail; accessOrder 决定了顺序，默认为 false，此时维护的是插入顺序。\nfinal boolean accessOrder; LinkedHashMap 最重要的是以下用于维护顺序的函数，它们会在 put、get 等方法中调用。\nvoid afterNodeAccess(Node\u0026lt;K,V\u0026gt; p) { } void afterNodeInsertion(boolean evict) { } 2.7.2 afterNodeAccess() 当一个节点被访问时，如果 accessOrder 为 true，则会将该节点移到链表尾部。也就是说指定为 LRU 顺序之后，在每次访问一个节点时，会将这个节点移到链表尾部，保证链表尾部是最近访问的节点，那么链表首部就是最近最久未使用的节点。\n2.7.3 afterNodeInsertion() 在 put 等操作之后执行，当 removeEldestEntry() 方法返回 true 时会移除最晚的节点，也就是链表首部节点 first。\nevict 只有在构建 Map 的时候才为 false，在这里为 true。\n本文转载自：https://github.com/CyC2018/CS-Notes，用于个人复习。\n","date":"2021-05-04T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/typora/image-hosting-master/image-hosting-master/20210503/antarctica-1987579_1920.4sf6q29twew0.jpg","permalink":"https://cuterwrite.top/p/java-collection/","title":"Java容器知识点笔记"},{"content":" Table of Contents generated with DocToc\nJVM知识点笔记 1 运行时数据区域 1.1 程序计数器 1.2 Java虚拟机栈 1.3 本地方法栈 1.4 堆 1.5 方法区 1.6 运行时常量池 1.7 直接内存 2 垃圾收集 2.1 判断一个对象是否可回收 2.1.1 引用计数算法 2.1.2 可达性分析算法 2.1.3 方法区的回收 2.1.4 finalize() 2.2 引用类型 2.2.1 强引用 2.2.2 软引用 2.2.3 弱引用 2.2.4 虚引用 2.3 垃圾收集算法 2.3.1 标记 - 清除 2.3.2 标记-整理 2.3.3 复制 2.3.4 分代收集 2.4 垃圾收集器 3 内存分配与回收策略 3.1 Minor GC和Full GC 3.2 内存分配策略 3.2.1. 对象优先在 Eden 分配 3.2.2. 大对象直接进入老年代 3.2.3. 长期存活的对象进入老年代 3.2.4. 动态对象年龄判定 3.2.5. 空间分配担保 3.3 Full GC触发条件 3.3.1. 调用 System.gc() 3.3.2. 老年代空间不足 3.3.3. 空间分配担保失败 3.3.4. JDK 1.7 及以前的永久代空间不足 3.3.5. Concurrent Mode Failure 4 类加载机制 4.1 类的生命周期 4.2 类加载过程 4.2.1. 加载 4.2.2. 验证 4.2.3. 准备 4.2.4. 解析 4.2.5. 初始化 4.3 类初始化时机 4.3.1. 主动引用 4.3.2. 被动引用 4.4 类与类加载器 4.5 类加载器分类 4.6 双亲委派模型 4.6.1. 工作过程 4.6.2. 好处 4.6.3. 实现 4.7 自定义类加载器实现 JVM知识点笔记 1 运行时数据区域 1.1 程序计数器 记录正在执行的虚拟机字节码指令的地址（如果正在执行的是本地方法则为空）。\n1.2 Java虚拟机栈 每个 Java 方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。\n可以通过 -Xss 这个虚拟机参数来指定每个线程的 Java 虚拟机栈内存大小，在 JDK 1.4 中默认为 256K，而在 JDK 1.5+ 默认为 1M：\n该区域可能抛出以下异常：\n当线程请求的栈深度超过最大值，会抛出 StackOverflowError 异常； 栈进行动态扩展时如果无法申请到足够内存，会抛出 OutOfMemoryError 异常。 1.3 本地方法栈 本地方法栈与 Java 虚拟机栈类似，它们之间的区别只不过是本地方法栈为本地方法服务。\n本地方法一般是用其它语言（C、C++ 或汇编语言等）编写的，并且被编译为基于本机硬件和操作系统的程序，对待这些方法需要特别处理。\n1.4 堆 所有对象都在这里分配内存，是垃圾收集的主要区域（\u0026ldquo;GC 堆\u0026rdquo;）。\n现代的垃圾收集器基本都是采用分代收集算法，其主要的思想是针对不同类型的对象采取不同的垃圾回收算法。可以将堆分成两块：\n新生代（Young Generation） 老年代（Old Generation） 堆不需要连续内存，并且可以动态增加其内存，增加失败会抛出 OutOfMemoryError 异常。\n可以通过 -Xms 和 -Xmx 这两个虚拟机参数来指定一个程序的堆内存大小，第一个参数设置初始值，第二个参数设置最大值。\njava -Xms1M -Xmx2M HackTheJava 1.5 方法区 用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。\n和堆一样不需要连续的内存，并且可以动态扩展，动态扩展失败一样会抛出 OutOfMemoryError 异常。\n对这块区域进行垃圾回收的主要目标是对常量池的回收和对类的卸载，但是一般比较难实现。\nHotSpot 虚拟机把它当成永久代来进行垃圾回收。但很难确定永久代的大小，因为它受到很多因素影响，并且每次 Full GC 之后永久代的大小都会改变，所以经常会抛出 OutOfMemoryError 异常。为了更容易管理方法区，从 JDK 1.8 开始，移除永久代，并把方法区移至元空间，它位于本地内存中，而不是虚拟机内存中。\n方法区是一个 JVM 规范，永久代与元空间都是其一种实现方式。在 JDK 1.8 之后，原来永久代的数据被分到了堆和元空间中。元空间存储类的元信息，静态变量和常量池等放入堆中。\n1.6 运行时常量池 运行时常量池是方法区的一部分。\nClass 文件中的常量池（编译器生成的字面量和符号引用）会在类加载后被放入这个区域。\n除了在编译期生成的常量，还允许动态生成，例如 String 类的 intern()。\n1.7 直接内存 在 JDK 1.4 中新引入了 NIO 类，它可以使用 Native 函数库直接分配堆外内存，然后通过 Java 堆里的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在堆内存和堆外内存来回拷贝数据。\n2 垃圾收集 垃圾收集主要是针对堆和方法区进行。程序计数器、虚拟机栈和本地方法栈这三个区域属于线程私有的，只存在于线程的生命周期内，线程结束之后就会消失，因此不需要对这三个区域进行垃圾回收。\n2.1 判断一个对象是否可回收 2.1.1 引用计数算法 为对象添加一个引用计数器，当对象增加一个引用时计数器加 1，引用失效时计数器减 1。引用计数为 0 的对象可被回收。\n在两个对象出现循环引用的情况下，此时引用计数器永远不为 0，导致无法对它们进行回收。正是因为循环引用的存在，因此 Java 虚拟机不使用引用计数算法。\n2.1.2 可达性分析算法 以 GC Roots 为起始点进行搜索，可达的对象都是存活的，不可达的对象可被回收。\nJava 虚拟机使用该算法来判断对象是否可被回收，GC Roots 一般包含以下内容：\n虚拟机栈中局部变量表中引用的对象 本地方法栈中 JNI 中引用的对象 方法区中类静态属性引用的对象 方法区中的常量引用的对象 2.1.3 方法区的回收 因为方法区主要存放永久代对象，而永久代对象的回收率比新生代低很多，所以在方法区上进行回收性价比不高。\n主要是对常量池的回收和对类的卸载。\n为了避免内存溢出，在大量使用反射和动态代理的场景都需要虚拟机具备类卸载功能。\n类的卸载条件很多，需要满足以下三个条件，并且满足了条件也不一定会被卸载：\n该类所有的实例都已经被回收，此时堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 Class 对象没有在任何地方被引用，也就无法在任何地方通过反射访问该类方法。 2.1.4 finalize() 类似 C++ 的析构函数，用于关闭外部资源。但是 try-finally 等方式可以做得更好，并且该方法运行代价很高，不确定性大，无法保证各个对象的调用顺序，因此最好不要使用。\n当一个对象可被回收时，如果需要执行该对象的 finalize() 方法，那么就有可能在该方法中让对象重新被引用，从而实现自救。自救只能进行一次，如果回收的对象之前调用了 finalize() 方法自救，后面回收时不会再调用该方法。\n2.2 引用类型 无论是通过引用计数算法判断对象的引用数量，还是通过可达性分析算法判断对象是否可达，判定对象是否可被回收都与引用有关。\nJava 提供了四种强度不同的引用类型。\n2.2.1 强引用 被强引用关联的对象不会被回收。\n使用 new 一个新对象的方式来创建强引用。\n2.2.2 软引用 被软引用关联的对象只有在内存不够的情况下才会被回收。\n使用 SoftReference 类来创建软引用。\n2.2.3 弱引用 被弱引用关联的对象一定会被回收，也就是说它只能存活到下一次垃圾回收发生之前。\n使用 WeakReference 类来创建弱引用。\n2.2.4 虚引用 又称为幽灵引用或者幻影引用，一个对象是否有虚引用的存在，不会对其生存时间造成影响，也无法通过虚引用得到一个对象。\n为一个对象设置虚引用的唯一目的是能在这个对象被回收时收到一个系统通知。\n使用 PhantomReference 来创建虚引用。\n2.3 垃圾收集算法 2.3.1 标记 - 清除 在标记阶段，程序会检查每个对象是否为活动对象，如果是活动对象，则程序会在对象头部打上标记。\n在清除阶段，会进行对象回收并取消标志位，另外，还会判断回收后的分块与前一个空闲分块是否连续，若连续，会合并这两个分块。回收对象就是把对象作为分块，连接到被称为 “空闲链表” 的单向链表，之后进行分配时只需要遍历这个空闲链表，就可以找到分块。\n在分配时，程序会搜索空闲链表寻找空间大于等于新对象大小 size 的块 block。如果它找到的块等于 size，会直接返回这个分块；如果找到的块大于 size，会将块分割成大小为 size 与 (block - size) 的两部分，返回大小为 size 的分块，并把大小为 (block - size) 的块返回给空闲链表。\n不足：\n标记和清除过程效率都不高； 会产生大量不连续的内存碎片，导致无法给大对象分配内存。 2.3.2 标记-整理 让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。\n优点:\n不会产生内存碎片 不足:\n需要移动大量对象，处理效率比较低。 2.3.3 复制 将内存划分为大小相等的两块，每次只使用其中一块，当这一块内存用完了就将还存活的对象复制到另一块上面，然后再把使用过的内存空间进行一次清理。\n主要不足是只使用了内存的一半。\n现在的商业虚拟机都采用这种收集算法回收新生代，但是并不是划分为大小相等的两块，而是一块较大的 Eden 空间和两块较小的 Survivor 空间，每次使用 Eden 和其中一块 Survivor。在回收时，将 Eden 和 Survivor 中还存活着的对象全部复制到另一块 Survivor 上，最后清理 Eden 和使用过的那一块 Survivor。\nHotSpot 虚拟机的 Eden 和 Survivor 大小比例默认为 8:1，保证了内存的利用率达到 90%。如果每次回收有多于 10% 的对象存活，那么一块 Survivor 就不够用了，此时需要依赖于老年代进行空间分配担保，也就是借用老年代的空间存储放不下的对象。\n2.3.4 分代收集 现在的商业虚拟机采用分代收集算法，它根据对象存活周期将内存划分为几块，不同块采用适当的收集算法。\n一般将堆分为新生代和老年代。\n新生代使用：复制算法 老年代使用：标记 - 清除 或者 标记 - 整理 算法 2.4 垃圾收集器 以上是 HotSpot 虚拟机中的 7 个垃圾收集器，连线表示垃圾收集器可以配合使用。\n单线程与多线程：单线程指的是垃圾收集器只使用一个线程，而多线程使用多个线程； 串行与并行：串行指的是垃圾收集器与用户程序交替执行，这意味着在执行垃圾收集的时候需要停顿用户程序；并行指的是垃圾收集器和用户程序同时执行。除了 CMS 和 G1 之外，其它垃圾收集器都是以串行的方式执行。 3 内存分配与回收策略 3.1 Minor GC和Full GC Minor GC：回收新生代，因为新生代对象存活时间很短，因此 Minor GC 会频繁执行，执行的速度一般也会比较快。 Full GC：回收老年代和新生代，老年代对象其存活时间长，因此 Full GC 很少执行，执行速度会比 Minor GC 慢很多。 3.2 内存分配策略 3.2.1. 对象优先在 Eden 分配 大多数情况下，对象在新生代 Eden 上分配，当 Eden 空间不够时，发起 Minor GC。\n3.2.2. 大对象直接进入老年代 大对象是指需要连续内存空间的对象，最典型的大对象是那种很长的字符串以及数组。\n经常出现大对象会提前触发垃圾收集以获取足够的连续空间分配给大对象。\n-XX:PretenureSizeThreshold，大于此值的对象直接在老年代分配，避免在 Eden 和 Survivor 之间的大量内存复制。\n3.2.3. 长期存活的对象进入老年代 为对象定义年龄计数器，对象在 Eden 出生并经过 Minor GC 依然存活，将移动到 Survivor 中，年龄就增加 1 岁，增加到一定年龄则移动到老年代中。\n-XX:MaxTenuringThreshold 用来定义年龄的阈值。\n3.2.4. 动态对象年龄判定 虚拟机并不是永远要求对象的年龄必须达到 MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 中相同年龄所有对象大小的总和大于 Survivor 空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代，无需等到 MaxTenuringThreshold 中要求的年龄。\n3.2.5. 空间分配担保 在发生 Minor GC 之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立的话，那么 Minor GC 可以确认是安全的。\n如果不成立的话虚拟机会查看 HandlePromotionFailure 的值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC；如果小于，或者 HandlePromotionFailure 的值不允许冒险，那么就要进行一次 Full GC。\n3.3 Full GC触发条件 对于 Minor GC，其触发条件非常简单，当 Eden 空间满时，就将触发一次 Minor GC。而 Full GC 则相对复杂，有以下条件：\n3.3.1. 调用 System.gc() 只是建议虚拟机执行 Full GC，但是虚拟机不一定真正去执行。不建议使用这种方式，而是让虚拟机管理内存。\n3.3.2. 老年代空间不足 老年代空间不足的常见场景为前文所讲的大对象直接进入老年代、长期存活的对象进入老年代等。\n为了避免以上原因引起的 Full GC，应当尽量不要创建过大的对象以及数组。除此之外，可以通过 -Xmn 虚拟机参数调大新生代的大小，让对象尽量在新生代被回收掉，不进入老年代。还可以通过 -XX:MaxTenuringThreshold 调大对象进入老年代的年龄，让对象在新生代多存活一段时间。\n3.3.3. 空间分配担保失败 使用复制算法的 Minor GC 需要老年代的内存空间作担保，如果担保失败会执行一次 Full GC。具体内容请参考上面的第 5 小节。\n3.3.4. JDK 1.7 及以前的永久代空间不足 在 JDK 1.7 及以前，HotSpot 虚拟机中的方法区是用永久代实现的，永久代中存放的为一些 Class 的信息、常量、静态变量等数据。\n当系统中要加载的类、反射的类和调用的方法较多时，永久代可能会被占满，在未配置为采用 CMS GC 的情况下也会执行 Full GC。如果经过 Full GC 仍然回收不了，那么虚拟机会抛出 java.lang.OutOfMemoryError。\n为避免以上原因引起的 Full GC，可采用的方法为增大永久代空间或转为使用 CMS GC。\n3.3.5. Concurrent Mode Failure 执行 CMS GC 的过程中同时有对象要放入老年代，而此时老年代空间不足（可能是 GC 过程中浮动垃圾过多导致暂时性的空间不足），便会报 Concurrent Mode Failure 错误，并触发 Full GC。\n4 类加载机制 类是在运行期间第一次使用时动态加载的，而不是一次性加载所有类。因为如果一次性加载，那么会占用很多的内存。\n4.1 类的生命周期 包括以下 7 个阶段：\n加载（Loading） 验证（Verification） 准备（Preparation） 解析（Resolution） 初始化（Initialization） 使用（Using） 卸载（Unloading） 4.2 类加载过程 包含了加载、验证、准备、解析和初始化这 5 个阶段。\n4.2.1. 加载 加载是类加载的一个阶段，注意不要混淆。\n加载过程完成以下三件事：\n通过类的完全限定名称获取定义该类的二进制字节流。 将该字节流表示的静态存储结构转换为方法区的运行时存储结构。 在内存中生成一个代表该类的 Class 对象，作为方法区中该类各种数据的访问入口。 其中二进制字节流可以从以下方式中获取：\n从 ZIP 包读取，成为 JAR、EAR、WAR 格式的基础。 从网络中获取，最典型的应用是 Applet。 运行时计算生成，例如动态代理技术，在 java.lang.reflect.Proxy 使用 ProxyGenerator.generateProxyClass 的代理类的二进制字节流。 由其他文件生成，例如由 JSP 文件生成对应的 Class 类。 4.2.2. 验证 确保 Class 文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。\n4.2.3. 准备 类变量是被 static 修饰的变量，准备阶段为类变量分配内存并设置初始值，使用的是方法区的内存。\n实例变量不会在这阶段分配内存，它会在对象实例化时随着对象一起被分配在堆中。应该注意到，实例化不是类加载的一个过程，类加载发生在所有实例化操作之前，并且类加载只进行一次，实例化可以进行多次。\n初始值一般为 0 值，例如下面的类变量 value 被初始化为 0 而不是 123。\npublic static int value = 123; 如果类变量是常量，那么它将初始化为表达式所定义的值而不是 0。例如下面的常量 value 被初始化为 123 而不是 0。\npublic static final int value = 123; 4.2.4. 解析 将常量池的符号引用替换为直接引用的过程。\n其中解析过程在某些情况下可以在初始化阶段之后再开始，这是为了支持 Java 的动态绑定。\n4.2.5. 初始化 初始化阶段才真正开始执行类中定义的 Java 程序代码。初始化阶段是虚拟机执行类构造器 \u0026lt;clinit\u0026gt;() 方法的过程。在准备阶段，类变量已经赋过一次系统要求的初始值，而在初始化阶段，根据程序员通过程序制定的主观计划去初始化类变量和其它资源。\n\u0026lt;clinit\u0026gt;() 是由编译器自动收集类中所有类变量的赋值动作和静态语句块中的语句合并产生的，编译器收集的顺序由语句在源文件中出现的顺序决定。特别注意的是，静态语句块只能访问到定义在它之前的类变量，定义在它之后的类变量只能赋值，不能访问。例如以下代码：\npublic class Test { static { i = 0; // 给变量赋值可以正常编译通过 System.out.print(i); // 这句编译器会提示“非法向前引用” } static int i = 1; } 由于父类的 \u0026lt;clinit\u0026gt;() 方法先执行，也就意味着父类中定义的静态语句块的执行要优先于子类。例如以下代码：\nstatic class Parent { public static int A = 1; static { A = 2; } } static class Sub extends Parent { public static int B = A; } public static void main(String[] args) { System.out.println(Sub.B); // 2 } 接口中不可以使用静态语句块，但仍然有类变量初始化的赋值操作，因此接口与类一样都会生成 \u0026lt;clinit\u0026gt;() 方法。但接口与类不同的是，执行接口的 \u0026lt;clinit\u0026gt;() 方法不需要先执行父接口的 \u0026lt;clinit\u0026gt;() 方法。只有当父接口中定义的变量使用时，父接口才会初始化。另外，接口的实现类在初始化时也一样不会执行接口的 \u0026lt;clinit\u0026gt;() 方法。\n虚拟机会保证一个类的 \u0026lt;clinit\u0026gt;() 方法在多线程环境下被正确的加锁和同步，如果多个线程同时初始化一个类，只会有一个线程执行这个类的 \u0026lt;clinit\u0026gt;() 方法，其它线程都会阻塞等待，直到活动线程执行 \u0026lt;clinit\u0026gt;() 方法完毕。如果在一个类的 \u0026lt;clinit\u0026gt;() 方法中有耗时的操作，就可能造成多个线程阻塞，在实际过程中此种阻塞很隐蔽。\n4.3 类初始化时机 4.3.1. 主动引用 虚拟机规范中并没有强制约束何时进行加载，但是规范严格规定了有且只有下列五种情况必须对类进行初始化（加载、验证、准备都会随之发生）：\n遇到 new、getstatic、putstatic、invokestatic 这四条字节码指令时，如果类没有进行过初始化，则必须先触发其初始化。最常见的生成这 4 条指令的场景是：使用 new 关键字实例化对象的时候；读取或设置一个类的静态字段（被 final 修饰、已在编译期把结果放入常量池的静态字段除外）的时候；以及调用一个类的静态方法的时候。\n使用 java.lang.reflect 包的方法对类进行反射调用的时候，如果类没有进行初始化，则需要先触发其初始化。\n当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。\n当虚拟机启动时，用户需要指定一个要执行的主类（包含 main() 方法的那个类），虚拟机会先初始化这个主类；\n当使用 JDK 1.7 的动态语言支持时，如果一个 java.lang.invoke.MethodHandle 实例最后的解析结果为 REF_getStatic, REF_putStatic, REF_invokeStatic 的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化；\n4.3.2. 被动引用 以上 5 种场景中的行为称为对一个类进行主动引用。除此之外，所有引用类的方式都不会触发初始化，称为被动引用。被动引用的常见例子包括：\n通过子类引用父类的静态字段，不会导致子类初始化。 System.out.println(SubClass.value); // value 字段在 SuperClass 中定义 通过数组定义来引用类，不会触发此类的初始化。该过程会对数组类进行初始化，数组类是一个由虚拟机自动生成的、直接继承自 Object 的子类，其中包含了数组的属性和方法。 SuperClass[] sca = new SuperClass[10]; 常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。 System.out.println(ConstClass.HELLOWORLD); 4.4 类与类加载器 两个类相等，需要类本身相等，并且使用同一个类加载器进行加载。这是因为每一个类加载器都拥有一个独立的类名称空间。\n这里的相等，包括类的 Class 对象的 equals() 方法、isAssignableFrom() 方法、isInstance() 方法的返回结果为 true，也包括使用 instanceof 关键字做对象所属关系判定结果为 true。\n4.5 类加载器分类 从 Java 虚拟机的角度来讲，只存在以下两种不同的类加载器：\n启动类加载器（Bootstrap ClassLoader），使用 C++ 实现，是虚拟机自身的一部分；\n所有其它类的加载器，使用 Java 实现，独立于虚拟机，继承自抽象类 java.lang.ClassLoader。\n从 Java 开发人员的角度看，类加载器可以划分得更细致一些：\n启动类加载器（Bootstrap ClassLoader）此类加载器负责将存放在 \u0026lt;JRE_HOME\u0026gt;\\lib 目录中的，或者被 -Xbootclasspath 参数所指定的路径中的，并且是虚拟机识别的（仅按照文件名识别，如 rt.jar，名字不符合的类库即使放在 lib 目录中也不会被加载）类库加载到虚拟机内存中。启动类加载器无法被 Java 程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给启动类加载器，直接使用 null 代替即可。\n扩展类加载器（Extension ClassLoader）这个类加载器是由 ExtClassLoader（sun.misc.Launcher$ExtClassLoader）实现的。它负责将 \u0026lt;JAVA_HOME\u0026gt;/lib/ext 或者被 java.ext.dir 系统变量所指定路径中的所有类库加载到内存中，开发者可以直接使用扩展类加载器。\n应用程序类加载器（Application ClassLoader）这个类加载器是由 AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的。由于这个类加载器是 ClassLoader 中的 getSystemClassLoader() 方法的返回值，因此一般称为系统类加载器。它负责加载用户类路径（ClassPath）上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。\n4.6 双亲委派模型 应用程序是由三种类加载器互相配合从而实现类加载，除此之外还可以加入自己定义的类加载器。\n下图展示了类加载器之间的层次关系，称为双亲委派模型（Parents Delegation Model）。该模型要求除了顶层的启动类加载器外，其它的类加载器都要有自己的父类加载器。这里的父子关系一般通过组合关系（Composition）来实现，而不是继承关系（Inheritance）。\n4.6.1. 工作过程 一个类加载器首先将类加载请求转发到父类加载器，只有当父类加载器无法完成时才尝试自己加载。\n4.6.2. 好处 使得 Java 类随着它的类加载器一起具有一种带有优先级的层次关系，从而使得基础类得到统一。\n例如 java.lang.Object 存放在 rt.jar 中，如果编写另外一个 java.lang.Object 并放到 ClassPath 中，程序可以编译通过。由于双亲委派模型的存在，所以在 rt.jar 中的 Object 比在 ClassPath 中的 Object 优先级更高，这是因为 rt.jar 中的 Object 使用的是启动类加载器，而 ClassPath 中的 Object 使用的是应用程序类加载器。rt.jar 中的 Object 优先级更高，那么程序中所有的 Object 都是这个 Object。\n4.6.3. 实现 以下是抽象类 java.lang.ClassLoader 的代码片段，其中的 loadClass() 方法运行过程如下：先检查类是否已经加载过，如果没有则让父类加载器去加载。当父类加载器加载失败时抛出 ClassNotFoundException，此时尝试自己去加载。\npublic abstract class ClassLoader { // The parent class loader for delegation private final ClassLoader parent; public Class\u0026lt;?\u0026gt; loadClass(String name) throws ClassNotFoundException { return loadClass(name, false); } protected Class\u0026lt;?\u0026gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { synchronized (getClassLoadingLock(name)) { // First, check if the class has already been loaded Class\u0026lt;?\u0026gt; c = findLoadedClass(name); if (c == null) { try { if (parent != null) { c = parent.loadClass(name, false); } else { c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found // from the non-null parent class loader } if (c == null) { // If still not found, then invoke findClass in order // to find the class. c = findClass(name); } } if (resolve) { resolveClass(c); } return c; } } protected Class\u0026lt;?\u0026gt; findClass(String name) throws ClassNotFoundException { throw new ClassNotFoundException(name); } } 4.7 自定义类加载器实现 以下代码中的 FileSystemClassLoader 是自定义类加载器，继承自 java.lang.ClassLoader，用于加载文件系统上的类。它首先根据类的全名在文件系统上查找类的字节代码文件（.class 文件），然后读取该文件内容，最后通过 defineClass() 方法来把这些字节代码转换成 java.lang.Class 类的实例。\njava.lang.ClassLoader 的 loadClass() 实现了双亲委派模型的逻辑，自定义类加载器一般不去重写它，但是需要重写 findClass() 方法。\n本文转载自：https://github.com/CyC2018/CS-Notes，用于个人复习。\n","date":"2021-05-04T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/typora/image-hosting-master/image-hosting-master/20210503/naples-122698_1920.2vb750rs8te0.jpg","permalink":"https://cuterwrite.top/p/jvm/","title":"JVM知识点笔记"},{"content":" Table of Contents generated with DocToc\nSocket与IO模型 1 IO模型 1.1 阻塞式IO 1.2 非阻塞式IO 1.3 IO复用 1.4 信号驱动IO 1.5 异步IO 1.6 IO模型对比 2 IO复用 2.1 select 2.2 poll 2.3 epoll 2.4 LT与ET 2.5 select、poll、epoll对比 Socket与IO模型 1 IO模型 1.1 阻塞式IO 应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回。\n应该注意到，在阻塞的过程中，其它应用进程还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其它应用进程还可以执行，所以不消耗 CPU 时间，这种模型的 CPU 利用率会比较高。\n1.2 非阻塞式IO 应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询（polling）。\n由于 CPU 要处理更多的系统调用，因此这种模型的 CPU 利用率比较低。\n1.3 IO复用 使用 select 或者 poll 等待数据，并且可以等待多个套接字中的任何一个变为可读。这一过程会被阻塞，当某一个套接字可读时返回，之后再使用 recvfrom 把数据从内核复制到进程中。\n它可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O。\n如果一个 Web 服务器没有 I/O 复用，那么每一个 Socket 连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。\n1.4 信号驱动IO 应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。\n相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。\n1.5 异步IO 应用进程执行 aio_read 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。\n异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O。\n1.6 IO模型对比 同步IO：将数据从内核缓冲区复制到应用进程缓冲区的阶段（第二阶段），应用进程会阻塞。 异步IO：第二阶段应用进程不会阻塞。 同步IO包括：BIO、NIO、IO复用和信号驱动IO，它们的区别在第一阶段\nBIO会直接阻塞应用进程，直到数据从内核缓冲区复制到应用进程缓冲区。\nNIO采用轮询方式判断IO是否完成，避免阻塞。\n信号驱动IO采用SIGIO信号方式，避免阻塞\nIO多路复用使用select/poll/epoll等待描述符成为就绪状态，避免阻塞。\n其中，NIO、信号驱动IO和异步IO在第一阶段不会阻塞。\n2 IO复用 2.1 select select 允许应用程序监视一组文件描述符，等待一个或者多个描述符成为就绪状态，从而完成 I/O 操作。\n缺点：\n单个进程所打开的FD是有限制的，通过FD_SETSIZE设置，默认1024 每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大 对socket扫描时是线性扫描（对所有的fds遍历扫描），采用轮询的方法，效率较低（高并发时） 2.2 poll poll与select相比，只是没有fd的限制，其它基本一样\n缺点：\n每次调用poll，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大 对socket扫描时是线性扫描，采用轮询的方法，效率较低（高并发时） 2.3 epoll select 和 poll 速度都比较慢，每次调用都需要将全部描述符从应用进程缓冲区复制到内核缓冲区。\nepoll 只需要将描述符从进程缓冲区向内核缓冲区拷贝一次，并且进程不需要通过轮询来获得事件完成的描述符。\n缺点：epoll只能工作在linux下\n2.4 LT与ET LT：LT模式下，只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作。 ET：ET模式下，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论fd中是否还有数据可读。所以在ET模式下，read一个fd的时候一定要把它的buffer读完，或者遇到EAGAIN错误。 2.5 select、poll、epoll对比 select poll epoll 数据结构 bitmap 数组 红黑树 最大连接数 1024 无上限 无上限 fd拷贝 每次调用select拷贝 每次调用poll拷贝 fd首次调用epoll_ctl拷贝，每次调用epoll_wait不拷贝 工作效率 轮询：O(n) 轮询：O(n) 回调：O(1) 本文转载自：https://github.com/CyC2018/CS-Notes，用于个人复习。\n","date":"2021-05-04T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/typora/image-hosting-master/image-hosting-master/20210503/cheetah-3749168_1920.4pgxzkp625g0.jpg","permalink":"https://cuterwrite.top/p/io-model/","title":"Socket与IO模型"},{"content":" Table of Contents generated with DocToc\n一、数据库系统原理 1 事务 1.1 概念 1.2 ACID 1.3 AUTOCOMMIT 2 并发一致性问题 2.1 丢失修改 2.2 读脏数据 2.3 不可重复读 2.4 幻影读 3 封锁 3.1 封锁粒度 3.2 封锁类型 3.2.1 读写锁 3.2.2 意向锁 3.3 封锁协议 3.3.1 三级封锁协议 3.3.2 二段锁协议 3.4 MySQL隐式与显示锁定 4 隔离级别 4.1 未提交读 4.2 提交读 4.3 可重复读 4.4 可串行化 5 多版本并发控制 5.1 基本思想 5.2 版本号 5.3 Undo日志 5.4 ReadView 5.5 快照读与当前读 5.5.1 快照读 5.5.2 当前读 6 Next-Key Locks 6.1 Record Locks 6.2 Gap Locks 6.3 Next-Key Locks 二、MySQL 1 索引 1.1 B+树原理 1.1.1 数据结构 1.1.2. 操作 1.1.3 与红黑树的比较 1.2 MySQL索引 1.2.1 B+树索引 1.2.2 哈希索引 1.2.3 全文索引 1.2.4 空间数据索引 1.3 索引优化 1.3.1. 独立的列 1.3.2. 多列索引 1.3.3. 索引列的顺序 1.3.4. 前缀索引 1.3.5. 覆盖索引 1.4 索引的优点 1.5 索引的使用条件 1.6 MySQL里的索引类型 1.7 聚簇索引和非聚簇索引 1.8 回表查询 2 查询性能优化 2.1 Explain 2.2 优化数据访问 2.2.1 减少请求的数据量 2.2.2 减少扫描的行数 2.3 重构查询方式 2.3.1 切分大查询 2.3.2 分解大连接查询 3 存储引擎 3.1 InnoDB 3.2 MyISAM 3.3 区别 4 数据类型 5 分表 5.1 水平切分 5.2 垂直切分 5.3 Sharding 策略 5.4 Sharding 存在的问题 5.4.1. 事务问题 5.4.2. 连接 5.4.3. ID 唯一性 6 复制 6.1 主从复制 6.2 读写分离 三、Redis 1 概述 2 数据类型 3 数据结构 3.1 字典 3.2 跳跃表 4 使用场景 4.1 计数器 4.2 缓存 4.3 查找表 4.4 消息队列 4.5 会话缓存 4.6 分布式锁 4.7 其他 5 键的过期时间 6 数据淘汰策略 7 持久化 7.1 RDB 7.2 AOF 8 事务 9 事件 9.1 文件事件 9.2 时间事件 9.3 事件的调度与执行 10 复制 10.1 连接过程 10.2 主从链 11 哨兵 12 分片 13 IO多路复用 13.1 什么是IO多路复用 13.2 为什么需要IO多路复用 13.3 IO多路复用的实现方式 13.4 select缺点 13.5 poll与select对比 13.6 poll缺点 13.7 epoll缺点 13.8 epoll的应用 13.9 select/poll/epoll之间的区别 13.10 epoll LT和ET模式的区别 一、数据库系统原理 1 事务 1.1 概念 事务指的是满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。\n1.2 ACID 原子性\n事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。\n回滚可以用回滚日志（Undo Log）来实现，回滚日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。\n一致性\n数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对同一个数据的读取结果都是相同的。\n隔离性\n一个事务所做的修改在最终提交以前，对其它事务是不可见的。\n持久性\n一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。系统发生崩溃可以用重做日志（Redo Log）进行恢复，从而实现持久性。与回滚日志记录数据的逻辑修改不同，重做日志记录的是数据页的物理修改。\n原因：\n只有满足一致性，事务的执行结果才是正确的。\n在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。\n在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。\n事务满足持久化是为了能应对系统崩溃的情况。\n1.3 AUTOCOMMIT MySQL 默认采用自动提交模式。也就是说，如果不显式使用START TRANSACTION语句来开始一个事务，那么每个查询操作都会被当做一个事务并自动提交。\n2 并发一致性问题 2.1 丢失修改 丢失修改指一个事务的更新操作被另外一个事务的更新操作替换。一般在现实生活中常会遇到，例如：T1 和 T2 两个事务都对一个数据进行修改，T1 先修改并提交生效，T2 随后修改，T2 的修改覆盖了 T1 的修改。\n2.2 读脏数据 读脏数据指在不同的事务下，当前事务可以读到另外事务未提交的数据。例如：T1 修改一个数据但未提交，T2 随后读取这个数据。如果 T1 撤销了这次修改，那么 T2 读取的数据是脏数据。\n2.3 不可重复读 不可重复读指在一个事务内多次读取同一数据集合。在这一事务还未结束前，另一事务也访问了该同一数据集合并做了修改，由于第二个事务的修改，第一次事务的两次读取的数据可能不一致。例如：T2 读取一个数据，T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。\n2.4 幻影读 幻读本质上也属于不可重复读的情况，T1 读取某个范围的数据，T2 在这个范围内插入新的数据，T1 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。\n3 封锁 3.1 封锁粒度 MySQL 中提供了两种封锁粒度：行级锁以及表级锁。\n应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。\n但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。因此封锁粒度越小，系统开销就越大。\n在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。\n3.2 封锁类型 3.2.1 读写锁 互斥锁（Exclusive），简写为 X 锁，又称写锁。 共享锁（Shared），简写为 S 锁，又称读锁。 有以下两个规定：\n一个事务对数据对象 A 加了 X 锁，就可以对 A 进行读取和更新。加锁期间其它事务不能对 A 加任何锁。 一个事务对数据对象 A 加了 S 锁，可以对 A 进行读取操作，但是不能进行更新操作。加锁期间其它事务能对 A 加 S 锁，但是不能加 X 锁。 锁的兼容关系如下：\n3.2.2 意向锁 使用意向锁（Intention Locks）可以更容易地支持多粒度封锁。\n在存在行级锁和表级锁的情况下，事务 T 想要对表 A 加 X 锁，就需要先检测是否有其它事务对表 A 或者表 A 中的任意一行加了锁，那么就需要对表 A 的每一行都检测一次，这是非常耗时的。\n意向锁在原来的 X/S 锁之上引入了 IX/IS，IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。有以下两个规定：\n一个事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁； 一个事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。 通过引入意向锁，事务 T 想要对表 A 加 X 锁，只需要先检测是否有其它事务对表 A 加了 X/IX/S/IS 锁，如果加了就表示有其它事务正在使用这个表或者表中某一行的锁，因此事务 T 加 X 锁失败。\n各种锁的兼容关系如下：\n解释如下：\n任意 IS/IX 锁之间都是兼容的，因为它们只表示想要对表加锁，而不是真正加锁； 这里兼容关系针对的是表级锁，而表级的 IX 锁和行级的 X 锁兼容，两个事务可以对两个数据行加 X 锁。（事务 T1 想要对数据行 R1 加 X 锁，事务 T2 想要对同一个表的数据行 R2 加 X 锁，两个事务都需要对该表加 IX 锁，但是 IX 锁是兼容的，并且 IX 锁与行级的 X 锁也是兼容的，因此两个事务都能加锁成功，对同一个表中的两个数据行做修改。） 3.3 封锁协议 3.3.1 三级封锁协议 一级封锁协议：事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。可以解决丢失修改问题，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。 二级封锁协议：在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。可以解决读脏数据问题，因为如果一个事务在对数据 A 进行修改，根据 1 级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据。 三级封锁协议：在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。可以解决不可重复读的问题，因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变。 3.3.2 二段锁协议 加锁和解锁分为两个阶段进行。\n可串行化调度是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。串行执行的事务互不干扰，不会出现并发一致性问题。\n事务遵循两段锁协议是保证可串行化调度的充分条件。例如以下操作满足两段锁协议，它是可串行化调度。\n3.4 MySQL隐式与显示锁定 MySQL 的 InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。\nInnoDB 也可以使用特定的语句进行显示锁定：\nSELECT ... LOCK In SHARE MODE; SELECT ... FOR UPDATE; 4 隔离级别 4.1 未提交读 事务中的修改，即使没有提交，对其它事务也是可见的。\n4.2 提交读 一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。\n4.3 可重复读 保证在同一个事务中多次读取同一数据的结果是一样的。\n4.4 可串行化 强制事务串行执行，这样多个事务互不干扰，不会出现并发一致性问题。\n该隔离级别需要加锁实现，因为要使用加锁机制保证同一时间只有一个事务执行，也就是保证事务串行执行。\n5 多版本并发控制 多版本并发控制（Multi-Version Concurrency Control, MVCC）是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。而未提交读隔离级别总是读取最新的数据行，要求很低，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。\n5.1 基本思想 在封锁一节中提到，加锁能解决多个事务同时执行时出现的并发一致性问题。在实际场景中读操作往往多于写操作，因此又引入了读写锁来避免不必要的加锁操作，例如读和读没有互斥关系。读写锁中读和写操作仍然是互斥的，而 MVCC 利用了多版本的思想，写操作更新最新的版本快照，而读操作去读旧版本快照，没有互斥关系，这一点和 CopyOnWrite 类似。\n在 MVCC 中事务的修改操作（DELETE、INSERT、UPDATE）会为数据行新增一个版本快照。\n脏读和不可重复读最根本的原因是事务读取到其它事务未提交的修改。在事务进行读取操作时，为了解决脏读和不可重复读问题，MVCC 规定只能读取已经提交的快照。当然一个事务可以读取自身未提交的快照，这不算是脏读。\n5.2 版本号 系统版本号 SYS_ID：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。 事务版本号 TRX_ID ：事务开始时的系统版本号。 5.3 Undo日志 MVCC 的多版本指的是多个版本的快照，快照存储在 Undo 日志中，该日志通过回滚指针 ROLL_PTR 把一个数据行的所有快照连接起来。\n例如在 MySQL 创建一个表 t，包含主键 id 和一个字段 x。我们先插入一个数据行，然后对该数据行执行两次更新操作。\nINSERT INTO t(id, x) VALUES(1, \u0026#34;a\u0026#34;); UPDATE t SET x=\u0026#34;b\u0026#34; WHERE id=1; UPDATE t SET x=\u0026#34;c\u0026#34; WHERE id=1; 因为没有使用 START TRANSACTION 将上面的操作当成一个事务来执行，根据 MySQL 的 AUTOCOMMIT 机制，每个操作都会被当成一个事务来执行，所以上面的操作总共涉及到三个事务。快照中除了记录事务版本号 TRX_ID 和操作之外，还记录了一个 bit 的 DEL 字段，用于标记是否被删除。\nINSERT、UPDATE、DELETE 操作会创建一个日志，并将事务版本号 TRX_ID 写入。DELETE 可以看成是一个特殊的 UPDATE，还会额外将 DEL 字段设置为 1。\n5.4 ReadView MVCC 维护了一个 ReadView 结构，主要包含了当前系统未提交的事务列表 TRX_IDs {TRX_ID_1, TRX_ID_2, \u0026hellip;}，还有该列表的最小值 TRX_ID_MIN 和 TRX_ID_MAX。\n在进行 SELECT 操作时，根据数据行快照的 TRX_ID 与 TRX_ID_MIN 和 TRX_ID_MAX 之间的关系，从而判断数据行快照是否可以使用：\nTRX_ID \u0026lt; TRX_ID_MIN，表示该数据行快照时在当前所有未提交事务之前进行更改的，因此可以使用。\nTRX_ID \u0026gt; TRX_ID_MAX，表示该数据行快照是在事务启动之后被更改的，因此不可使用。\nTRX_ID_MIN \u0026lt;= TRX_ID \u0026lt;= TRX_ID_MAX，需要根据隔离级别再进行判断：\n提交读：如果 TRX_ID 在 TRX_IDs 列表中，表示该数据行快照对应的事务还未提交，则该快照不可使用。否则表示已经提交，可以使用。 可重复读：都不可以使用。因为如果可以使用的话，那么其它事务也可以读到这个数据行快照并进行修改，那么当前事务再去读这个数据行得到的值就会发生改变，也就是出现了不可重复读问题。 在数据行快照不可使用的情况下，需要沿着 Undo Log 的回滚指针 ROLL_PTR 找到下一个快照，再进行上面的判断。\n5.5 快照读与当前读 5.5.1 快照读 MVCC 的 SELECT 操作是快照中的数据，不需要进行加锁操作。\n5.5.2 当前读 MVCC 其它会对数据库进行修改的操作（INSERT、UPDATE、DELETE）需要进行加锁操作，从而读取最新的数据。可以看到 MVCC 并不是完全不用加锁，而只是避免了 SELECT 的加锁操作。\n6 Next-Key Locks Next-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。\nMVCC 不能解决幻影读问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读（REPEATABLE READ）隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。\n6.1 Record Locks 锁定一个记录上的索引，而不是记录本身。\n如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。\n6.2 Gap Locks 锁定索引之间的间隙，但是不包含索引本身。\n6.3 Next-Key Locks 它是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。它锁定一个前开后闭区间。\n二、MySQL 1 索引 1.1 B+树原理 1.1.1 数据结构 B Tree 指的是 Balance Tree，也就是平衡树。平衡树是一颗查找树，并且所有叶子节点位于同一层。\nB+ Tree 是基于 B Tree 和叶子节点顺序访问指针进行实现，它具有 B Tree 的平衡性，并且通过顺序访问指针来提高区间查询的性能。\n在 B+ Tree 中，一个节点中的 key 从左到右非递减排列，如果某个指针的左右相邻 key 分别是 keyi 和 keyi+1，且不为 null，则该指针指向节点的所有 key 大于等于 keyi 且小于等于 keyi+1。\n1.1.2. 操作 进行查找操作时，首先在根节点进行二分查找，找到一个 key 所在的指针，然后递归地在指针所指向的节点进行查找。直到查找到叶子节点，然后在叶子节点上进行二分查找，找出 key 所对应的 data。\n插入删除操作会破坏平衡树的平衡性，因此在进行插入删除操作之后，需要对树进行分裂、合并、旋转等操作来维护平衡性。\n1.1.3 与红黑树的比较 红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用 B+ Tree 作为索引结构，这是因为使用 B+ 树访问磁盘数据有更高的性能。\n（一）B+ 树有更低的树高\n平衡树的树高 O(h)=O(logdN)，其中 d 为每个节点的出度。红黑树的出度为 2，而 B+ Tree 的出度一般都非常大，所以红黑树的树高 h 很明显比 B+ Tree 大非常多。\n（二）磁盘访问原理\n操作系统一般将内存和磁盘分割成固定大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I/O 就能完全载入一个节点。\n如果数据不在同一个磁盘块上，那么通常需要移动制动手臂进行寻道，而制动手臂因为其物理结构导致了移动效率低下，从而增加磁盘数据读取时间。B+ 树相对于红黑树有更低的树高，进行寻道的次数与树高成正比，在同一个磁盘块上进行访问只需要很短的磁盘旋转时间，所以 B+ 树更适合磁盘数据的读取。\n（三）磁盘预读特性\n为了减少磁盘 I/O 操作，磁盘往往不是严格按需读取，而是每次都会预读。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，并且只需要很短的磁盘旋转时间，速度会非常快。并且可以利用预读特性，相邻的节点也能够被预先载入。\n1.2 MySQL索引 1.2.1 B+树索引 是大多数 MySQL 存储引擎的默认索引类型。\n因为不再需要进行全表扫描，只需要对树进行搜索即可，所以查找速度快很多。\n因为 B+ Tree 的有序性，所以除了用于查找，还可以用于排序和分组。\n可以指定多个列作为索引列，多个索引列共同组成键。\n适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。\nInnoDB 的 B+Tree 索引分为主索引和辅助索引。主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。\n辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。\n1.2.2 哈希索引 哈希索引能以 O(1) 时间进行查找，但是失去了有序性：\n无法用于排序与分组； 只支持精确查找，无法用于部分查找和范围查找。 InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。\n1.2.3 全文索引 MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。\n查找条件使用 MATCH AGAINST，而不是普通的 WHERE。\n全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。\nInnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。\n1.2.4 空间数据索引 MyISAM 存储引擎支持空间数据索引（R-Tree），可以用于地理数据存储。空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。\n必须使用 GIS 相关的函数来维护数据。\n1.3 索引优化 1.3.1. 独立的列 在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。\n例如下面的查询不能使用 actor_id 列的索引：\nSELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5; 1.3.2. 多列索引 在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把 actor_id 和 film_id 设置为多列索引。\nSELECT film_id, actor_ id FROM sakila.film_actor WHERE actor_id = 1 AND film_id = 1; 1.3.3. 索引列的顺序 让选择性最强的索引列放在前面。\n索引的选择性是指：不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，每个记录的区分度越高，查询效率也越高。\n例如下面显示的结果中 customer_id 的选择性比 staff_id 更高，因此最好把 customer_id 列放在多列索引的前面。\nSELECT COUNT(DISTINCT staff_id)/COUNT(*) AS staff_id_selectivity, COUNT(DISTINCT customer_id)/COUNT(*) AS customer_id_selectivity, COUNT(*) FROM payment; staff_id_selectivity: 0.0001 customer_id_selectivity: 0.0373 COUNT(*): 16049 1.3.4. 前缀索引 对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。\n前缀长度的选取需要根据索引选择性来确定。\n1.3.5. 覆盖索引 索引包含所有需要查询的字段的值。\n具有以下优点：\n索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。 一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用（通常比较费时）。 对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。 1.4 索引的优点 大大减少了服务器需要扫描的数据行数。 帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，不需要排序和分组，也就不需要创建临时表）。 将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。 1.5 索引的使用条件 对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效； 对于中到大型的表，索引就非常有效； 但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。 1.6 MySQL里的索引类型 普通索引 唯一索引 主键索引 组合索引 全文索引 1.7 聚簇索引和非聚簇索引 聚簇索引也叫簇类索引，是一种对磁盘上实际数据重新组织以按指定的一个或多个列的值排序。（聚簇索引就是主键的一种术语） 非聚簇索引，叶级页指向表中的记录，记录的物理顺序与逻辑顺序没有必然的联系。 或者：\n聚簇索引：规定存储在磁盘上的数据是连续的，这个连续是指物理顺序就是连续的。 非聚簇索引：既然聚簇索引是连续的，那非聚簇索引就是不连续的。索引的存储和数据的存储是分离的，也就是说找到了索引但没找到数据，需要根据索引上的值(主键)再次回表查询,非聚簇索引也叫做辅助索引。 举例：\n第一种，直接根据主键查询获取所有字段数据，此时主键是聚簇索引，因为主键对应的索引叶子节点存储了id=1的所有字段的值。\nselect * from student where id = 1 第二种，根据编号查询编号和名称，编号本身是一个唯一索引，但查询的列包含了学生编号和学生名称，当命中编号索引时，该索引的节点的数据存储的是主键ID，需要根据主键ID重新查询一次，所以这种查询下no不是聚簇索引\nselect no,name from student where no = \u0026#39;test\u0026#39; 第三种，我们根据编号查询编号（有人会问知道编号了还要查询？要，你可能需要验证该编号在数据库中是否存在），这种查询命中编号索引时，直接返回编号，因为所需要的数据就是该索引，不需要回表查询，这种场景下no是聚簇索引\nselect no from student where no = \u0026#39;test\u0026#39; 总结\n主键一定是聚簇索引，MySQL的InnoDB中一定有主键，即便研发人员不手动设置，则会使用unique索引，没有unique索引，则会使用数据库内部的一个行的id来当作主键索引,其它普通索引需要区分SQL场景，当SQL查询的列就是索引本身时，我们称这种场景下该普通索引也可以叫做聚簇索引，MyisAM引擎没有聚簇索引。\n1.8 回表查询 要说回表查询，先要从InnoDB的索引实现说起。InnoDB有两大类索引，一类是聚集索引(Clustered Index)，一类是非聚簇索引(Secondary Index)。\nInnoDB的聚集索引：InnoDB聚集索引的叶子节点存储行记录，因此InnoDB必须要有且只有一个聚集索引。\n1.如果表定义了PK(Primary Key，主键)，那么PK就是聚集索引。\n2.如果表没有定义PK，则第一个NOT NULL UNIQUE的列就是聚集索引。\n3.否则InnoDB会另外创建一个隐藏的ROWID作为聚集索引。\n这种机制使得基于PK的查询速度非常快，因为直接定位的行记录。\nInnoDB的普通索引：InnoDB普通索引的叶子节点存储主键ID(MyISAM则是存储的行记录头指针)。\n回表查询：先通过非聚簇索引查询主键ID，再通过主键ID查询数据。\n2 查询性能优化 2.1 Explain Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。\n比较重要的字段有：\nselect_type : 查询类型，有简单查询、联合查询、子查询等 key : 使用的索引 rows : 扫描的行数 2.2 优化数据访问 2.2.1 减少请求的数据量 只返回必要的列：最好不要使用 SELECT * 语句。 只返回必要的行：使用 LIMIT 语句来限制返回的数据。 缓存重复查询的数据：使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。 2.2.2 减少扫描的行数 最有效的方式是使用索引来覆盖查询。\n2.3 重构查询方式 2.3.1 切分大查询 一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。\n2.3.2 分解大连接查询 将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处有：\n让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。 分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。 减少锁竞争； 在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。 查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。 3 存储引擎 3.1 InnoDB 是 MySQL 默认的事务型存储引擎，只有在需要它不支持的特性时，才考虑使用其它存储引擎。\n实现了四个标准的隔离级别，默认级别是可重复读（REPEATABLE READ）。在可重复读隔离级别下，通过多版本并发控制（MVCC）+ Next-Key Locking 防止幻影读。\n主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。\n内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。\n支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。\n3.2 MyISAM 设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。\n提供了大量的特性，包括压缩表、空间数据索引等。\n不支持事务。\n不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入（CONCURRENT INSERT）。\n可以手工或者自动执行检查和修复操作，但是和事务恢复以及崩溃恢复不同，可能导致一些数据丢失，而且修复操作是非常慢的。\n如果指定了 DELAY_KEY_WRITE 选项，在每次修改执行完成时，不会立即将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作。\n3.3 区别 事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。\n并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。\n外键：InnoDB 支持外键。\n备份：InnoDB 支持在线热备份。\n崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。\n其它特性：MyISAM 支持压缩表和空间数据索引。\n4 数据类型 整型：tinyint、smallint、mediumint、int、bigint 浮点数：float、double、decimal 字符串：char、varchar 时间和日期：datetime、timestamp 5 分表 5.1 水平切分 水平切分又称为 Sharding，它是将同一个表中的记录拆分到多个结构相同的表中。\n当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓存单个数据库的压力。\n5.2 垂直切分 垂直切分是将一张表按列切分成多个表，通常是按照列的关系密集程度进行切分，也可以利用垂直切分将经常被使用的列和不经常被使用的列切分到不同的表中。\n在数据库的层面使用垂直切分将按数据库中表的密集程度部署到不同的库中，例如将原来的电商数据库垂直切分成商品数据库、用户数据库等。\n5.3 Sharding 策略 哈希取模：hash(key) % N； 范围：可以是 ID 范围也可以是时间范围； 映射表：使用单独的一个数据库来存储映射关系。 5.4 Sharding 存在的问题 5.4.1. 事务问题 使用分布式事务来解决，比如 XA 接口。\n5.4.2. 连接 可以将原来的连接分解成多个单表查询，然后在用户程序中进行连接。\n5.4.3. ID 唯一性 使用全局唯一 ID（GUID） 为每个分片指定一个 ID 范围 分布式 ID 生成器 (如 Twitter 的 Snowflake 算法) 6 复制 6.1 主从复制 主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。\nbinlog 线程 ：负责将主服务器上的数据更改写入二进制日志（Binary log）中。 I/O 线程 ：负责从主服务器上读取二进制日志，并写入从服务器的中继日志（Relay log）。 SQL 线程 ：负责读取中继日志，解析出主服务器已经执行的数据更改并在从服务器中重放（Replay）。 6.2 读写分离 主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。\n读写分离能提高性能的原因在于：\n主从服务器负责各自的读和写，极大程度缓解了锁的争用； 从服务器可以使用 MyISAM，提升查询性能以及节约系统开销； 增加冗余，提高可用性。 读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。\n三、Redis 1 概述 Redis 是速度非常快的非关系型（NoSQL）内存键值数据库，可以存储键和五种不同类型的值之间的映射。\n键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。\nRedis 支持很多特性，例如将内存中的数据持久化到硬盘中，使用复制来扩展读性能，使用分片来扩展写性能。\n2 数据类型 数据类型 可以存储的值 操作 STRING 字符串、整数或者浮点数 对整个字符串或者字符串的其中一部分执行操作\u0026lt;/br\u0026gt; 对整数和浮点数执行自增或者自减操作 LIST 列表 从两端压入或者弹出元素 \u0026lt;/br\u0026gt; 对单个或者多个元素进行修剪，\u0026lt;/br\u0026gt; 只保留一个范围内的元素 SET 无序集合 添加、获取、移除单个元素\u0026lt;/br\u0026gt; 检查一个元素是否存在于集合中\u0026lt;/br\u0026gt; 计算交集、并集、差集\u0026lt;/br\u0026gt; 从集合里面随机获取元素 HASH 包含键值对的无序散列表 添加、获取、移除单个键值对\u0026lt;/br\u0026gt; 获取所有键值对\u0026lt;/br\u0026gt; 检查某个键是否存在 ZSET 有序集合 添加、获取、删除元素\u0026lt;/br\u0026gt; 根据分值范围或者成员来获取元素\u0026lt;/br\u0026gt; 计算一个键的排名 3 数据结构 3.1 字典 dictht 是一个散列表结构，使用拉链法解决哈希冲突。\n3.2 跳跃表 是有序集合的底层实现之一。\n跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。\n在查找时，从上层指针开始查找，找到对应的区间之后再到下一层去查找。下图演示了查找 22 的过程。\n与红黑树等平衡树相比，跳跃表具有以下优点：\n插入速度非常快速，因为不需要进行旋转等操作来维护平衡性； 更容易实现； 支持无锁操作。 4 使用场景 4.1 计数器 可以对 String 进行自增自减运算，从而实现计数器功能。\nRedis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。\n4.2 缓存 将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。\n4.3 查找表 例如 DNS 记录就很适合使用 Redis 进行存储。\n查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。\n4.4 消息队列 List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息\n不过最好使用 Kafka、RabbitMQ 等消息中间件。\n4.5 会话缓存 可以使用 Redis 来统一存储多台应用服务器的会话信息。\n当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。\n4.6 分布式锁 在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。\n可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。\n4.7 其他 Set 可以实现交集、并集等操作，从而实现共同好友等功能。\nZSet 可以实现有序性操作，从而实现排行榜等功能。\n5 键的过期时间 Redis 可以为每个键设置过期时间，当键过期时，会自动删除该键。\n对于散列表这种容器，只能为整个键设置过期时间（整个散列表），而不能为键里面的单个元素设置过期时间。\n6 数据淘汰策略 可以设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略。\nRedis 具体有 6 种淘汰策略：\n策略 描述 volatile-lru 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 volatile-ttl 从已设置过期时间的数据集中挑选将要过期的数据淘汰 volatile-random 从已设置过期时间的数据集中任意选择数据淘汰 allkeys-lru 从所有数据集中挑选最近最少使用的数据淘汰 allkeys-random 从所有数据集中任意选择数据进行淘汰 noeviction 禁止驱逐数据 作为内存数据库，出于对性能和内存消耗的考虑，Redis 的淘汰算法实际实现上并非针对所有 key，而是抽样一小部分并且从中选出被淘汰的 key。\n使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用 allkeys-lru 淘汰策略，将最近最少使用的数据淘汰。\nRedis 4.0 引入了 volatile-lfu 和 allkeys-lfu 淘汰策略，LFU 策略通过统计访问频率，将访问频率最少的键值对淘汰。\n7 持久化 Redis 是内存型数据库，为了保证数据在断电后不会丢失，需要将内存中的数据持久化到硬盘上。\n7.1 RDB 将某个时间点的所有数据都存放到硬盘上。\n可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。\n如果系统发生故障，将会丢失最后一次创建快照之后的数据。\n如果数据量很大，保存快照的时间会很长。\n7.2 AOF 将写命令添加到 AOF 文件（Append Only File）的末尾。\n使用 AOF 持久化需要设置同步选项，从而确保写命令同步到磁盘文件上的时机。这是因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，然后由操作系统决定什么时候同步到磁盘。有以下同步选项：\n选项 同步频率 always 每个写命令都同步 everysec 每秒同步一次 no 让操作系统来决定何时同步 always 选项会严重减低服务器的性能； everysec 选项比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器性能几乎没有任何影响； no 选项并不能给服务器性能带来多大的提升，而且也会增加系统崩溃时数据丢失的数量。 随着服务器写请求的增多，AOF 文件会越来越大。Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。\n8 事务 一个事务包含了多个命令，服务器在执行事务期间，不会改去执行其它客户端的命令请求。\n事务中的多个命令被一次性发送给服务器，而不是一条一条发送，这种方式被称为流水线，它可以减少客户端与服务器之间的网络通信次数从而提升性能。\nRedis 最简单的事务实现方式是使用 MULTI 和 EXEC 命令将事务操作包围起来。\n9 事件 Redis 服务器是一个事件驱动程序。\n9.1 文件事件 服务器通过套接字与客户端或者其它服务器进行通信，文件事件就是对套接字操作的抽象。\nRedis 基于 Reactor 模式开发了自己的网络事件处理器，使用 I/O 多路复用程序来同时监听多个套接字，并将到达的事件传送给文件事件分派器，分派器会根据套接字产生的事件类型调用相应的事件处理器。\n9.2 时间事件 服务器有一些操作需要在给定的时间点执行，时间事件是对这类定时操作的抽象。\n时间事件又分为：\n定时事件：是让一段程序在指定的时间之内执行一次； 周期性事件：是让一段程序每隔指定时间就执行一次。 Redis 将所有时间事件都放在一个无序链表中，通过遍历整个链表查找出已到达的时间事件，并调用相应的事件处理器。\n9.3 事件的调度与执行 服务器需要不断监听文件事件的套接字才能得到待处理的文件事件，但是不能一直监听，否则时间事件无法在规定的时间内执行，因此监听时间应该根据距离现在最近的时间事件来决定。\n从事件处理的角度来看，服务器运行流程如下：\n10 复制 通过使用 slaveof host port 命令来让一个服务器成为另一个服务器的从服务器。\n一个从服务器只能有一个主服务器，并且不支持主主复制。\n10.1 连接过程 主服务器创建快照文件，发送给从服务器，并在发送期间使用缓冲区记录执行的写命令。快照文件发送完毕之后，开始向从服务器发送存储在缓冲区中的写命令；\n从服务器丢弃所有旧数据，载入主服务器发来的快照文件，之后从服务器开始接受主服务器发来的写命令；\n主服务器每执行一次写命令，就向从服务器发送相同的写命令。\n10.2 主从链 随着负载不断上升，主服务器可能无法很快地更新所有从服务器，或者重新连接和重新同步从服务器将导致系统超载。为了解决这个问题，可以创建一个中间层来分担主服务器的复制工作。中间层的服务器是最上层服务器的从服务器，又是最下层服务器的主服务器。\n11 哨兵 Sentinel（哨兵）可以监听集群中的服务器，并在主服务器进入下线状态时，自动从从服务器中选举出新的主服务器。\n12 分片 分片是将数据划分为多个部分的方法，可以将数据存储到多台机器里面，这种方法在解决某些问题时可以获得线性级别的性能提升。\n假设有 4 个 Redis 实例 R0，R1，R2，R3，还有很多表示用户的键 user:1，user:2，\u0026hellip; ，有不同的方式来选择一个指定的键存储在哪个实例中。\n最简单的方式是范围分片，例如用户 id 从 0~1000 的存储到实例 R0 中，用户 id 从 1001~2000 的存储到实例 R1 中，等等。但是这样需要维护一张映射范围表，维护操作代价很高。 还有一种方式是哈希分片，使用 CRC32 哈希函数将键转换为一个数字，再对实例数量求模就能知道应该存储的实例。 根据执行分片的位置，可以分为三种分片方式：\n客户端分片：客户端使用一致性哈希等算法决定键应当分布到哪个节点。 代理分片：将客户端请求发送到代理上，由代理转发请求到正确的节点上。 服务器分片：Redis Cluster。 13 IO多路复用 13.1 什么是IO多路复用 IO多路复用是一种同步IO模型，实现一个线程可以监视多个文件句柄；一旦某个文件句柄就绪，就能够通知应用程序进行相应的读写操作；没有文件句柄就绪时会阻塞应用程序，交出cpu。多路是指网络连接，复用指的是同一个线程\n13.2 为什么需要IO多路复用 解决BIO和NIO的问题。\nBIO：服务端采用单线程，当accept一个请求后，在recv或send调用阻塞时，将无法accept其他请求（必须等上一个请求处recv或send完），无法处理并发。\n当服务器端采用多线程，当accept一个请求后，开启线程进行recv，可以完成并发处理，但随着请求数增加需要增加系统线程，大量的线程占用很大的内存空间，并且线程切换会带来很大的开销，10000个线程真正发生读写事件的线程数不会超过20%，每次accept都开一个线程也是一种资源浪费\nNIO：服务器端当accept一个请求后，加入fds集合，每次轮询一遍fds集合recv(非阻塞)数据，没有数据则立即返回错误，每次轮询所有fd（包括没有发生读写事件的fd）会很浪费cpu\nIO多路复用：服务器端采用单线程通过select/epoll等系统调用获取fd列表，遍历有事件的fd进行accept/recv/send，使其能支持更多的并发连接请求\n13.3 IO多路复用的实现方式 select poll epoll 13.4 select缺点 单个进程所打开的FD是有限制的，通过FD_SETSIZE设置，默认1024 每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大 对socket扫描时是线性扫描（对所有的fds遍历扫描），采用轮询的方法，效率较低（高并发时） 13.5 poll与select对比 poll与select相比，只是没有fd的限制，其它基本一样\n13.6 poll缺点 每次调用poll，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大 对socket扫描时是线性扫描，采用轮询的方法，效率较低（高并发时） 13.7 epoll缺点 epoll只能工作在linux下\n13.8 epoll的应用 Redis nginx 13.9 select/poll/epoll之间的区别 select poll epoll 数据结构 bitmap 数组 红黑树 最大连接数 1024 无上限 无上限 fd拷贝 每次调用select拷贝 每次调用poll拷贝 fd首次调用epoll_ctl拷贝，每次调用epoll_wait不拷贝 工作效率 轮询：O(n) 轮询：O(n) 回调：O(1) 13.10 epoll LT和ET模式的区别 epoll有EPOLLLT和EPOLLET两种触发模式，LT是默认的模式，ET是“高速”模式。\nLT模式下，只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作 ET模式下，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论fd中是否还有数据可读。所以在ET模式下，read一个fd的时候一定要把它的buffer读完，或者遇到EAGAIN错误 本文转载自：https://github.com/CyC2018/CS-Notes，用于个人复习。\n","date":"2021-05-04T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/typora/image-hosting-master/image-hosting-master/20210503/windmills-5614160_1920.7f194ofsigg0.jpg","permalink":"https://cuterwrite.top/p/database-system/","title":"计算机基础知识点总结（数据库系统 + MySQL + Redis）"},{"content":" Table of Contents generated with DocToc\nArrayList源码分析 1 简介 1.1 ArrayList和Vector的区别 1.2 ArrayList和LinkedList的区别 2 核心源码分析 2.1 属性 2.2 构造函数 2.3 扩容机制 2.3.1 add方法 2.3.2 ensureCapacityInternal方法 2.3.3 ensureExplicitCapacity 2.3.4 grow方法 2.3.5 hugeCapacity方法 2.4 拷贝机制 2.5 ensureCapacity方法 ArrayList源码分析 1 简介 底层：Object[]，容量能动态增长。在添加大量元素前，会先调用ensureCapacity来增加ArrayList的容量，可以减少递增再分配的次数。\nArrayList继承了AbstractList，实现了List，RandomAccess，Cloneable，Serializable等接口。\nRandomAccess：标志接口，接口体是空的，只是用来表明ArrayList是支持快速随机访问的。 Cloneable：能被克隆 Serializable：可序列化 1.1 ArrayList和Vector的区别 底层都是Object[]，但是ArrayList线程不安全，Vector线程安全。\n1.2 ArrayList和LinkedList的区别 线程安全：ArrayList和LinkedList都是线程不安全的。 底层数据结构：ArrayList是Object[]，LinkedList底层是双向链表。 插入和删除：ArrayList插入和删除元素的时间复杂度受元素位置的影响，为O(n - i)；LinkedList的插入和删除元素的时间复杂度不受插入元素位置的影响，都近似于O(1)，但如果在指定位置插入和删除，需要先移动到指定位置再执行操作，时间复杂度近似于O(n)。 是否支持快速随机访问：ArrayList支持，LinkedList不支持。 内存空间占用：ArrayList需要在列表末尾预留一定的容量空间，LinkedList的每一个元素都需要多消耗pre和next指针的空间。 2 核心源码分析 2.1 属性 默认初始容量大小\nprivate static final int DEFAULT_CAPACITY = 10; 元素个数\nprivate int size; 存放数据的数组\ntransient Object[] elementData 空数组\nprivate static final Object[] EMPTY_ELEMENTDATA = {}; 用于默认大小实例的共享空数组实例\nprivate static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {} 2.2 构造函数 无参\npublic ArrayList(){ this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; } 注意：以无参数构造方法创建 ArrayList 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量扩为 10。（用了懒汉式的单例设计模式）\n指定容量\npublic ArrayList(int initialCapacity){ if (initialCapacity \u0026gt; 0){ this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0){ this.elementData = EMPTY_ELEMENTDATA; } else { //抛出异常 } } 指定collection\npublic ArrayList(Collection\u0026lt;? extends E\u0026gt; c){ elementData = c.toArray(); if ((size = elementData.length) != 0){ if (elementData.getClass() != Object[].class){ elementData = Arrays.copyOf(elementData, size, Object[].class); } } else { this.elementData = EMPTY_ELEMENTDATA; } } 2.3 扩容机制 2.3.1 add方法 2.3.2 ensureCapacityInternal方法 2.3.3 ensureExplicitCapacity 2.3.4 grow方法 2.3.5 hugeCapacity方法 2.4 拷贝机制 2.5 ensureCapacity方法 ","date":"2021-04-29T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/typora/image-hosting-master/image-hosting-master/20210503/man-5640540_1920.5mr5hqwq7xc0.jpg","permalink":"https://cuterwrite.top/p/arraylist-source-code/","title":"ArrayList源码分析"},{"content":"实用工具和网址 万能工具箱 CyberChef：https://gchq.github.io/CyberChef/\n小白工具盒：https://www.ooopn.com/\n在线画图工具 ProcessOn：https://www.processon.com/ Figma：https://www.figma.com/ 在线解编码工具 BASE64：https://base64.supfree.net/ MD5：https://www.zxgj.cn/g/md5 AES/DES：http://www.fly63.com/tool/cipher/ JWT：http://jwt.calebb.net/ ASCII：https://www.matools.com/code-convert-ascii Unicode：https://www.zxgj.cn/g/unicode UTF8：https://www.zxgj.cn/g/utf8 字符串：https://www.zxgj.cn/g/enstring URL：http://tool.chinaz.com/tools/urlencode.aspx?jdfwkey=lbixzl 在线转换工具 在线ACSII对照表：http://www.fly63.com/tool/ascii/ 通用进制转换工具：https://www.zxgj.cn/g/jinzhi 在线浮点数十进制转换：http://www.binaryconvert.com/ RGB：https://www.zxgj.cn/g/yansezhi 时间戳：https://www.zxgj.cn/g/unix 计量单位换算：http://www.fly63.com/tool/unitable/ 在线JSON解析：http://www.json.cn/ 在线JS代码格式化工具：https://prettier.io/playground/ SQL压缩/格式化工具：https://www.zxgj.cn/g/sqlformat JSON和YAML在线转换：http://www.fly63.com/tool/jsonyaml/ JSON和XML在线转换:https://www.zxgj.cn/g/jsonxml 人民币大小写转换：http://www.fly63.com/tool/renmingbi/ 正则表达式工具 正则表达式调试工具：https://regexr.com/ 正则表达式可视化工具：https://jex.im/regulex/ 网络工具 IP地址归属地查询：https://www.ip138.com/ IP地址查询：https://www.ipip.net/ip.html/ HTTP在线接口测试工具：http://www.fly63.com/php/http/ 在线编译运行工具 C#在线编译运行（不支持input）：https://rextester.com/ C/C++在线编译：https://www.onlinegdb.com/ 在线编译工具套装：https://c.runoob.com/ 在线生成器 UUID：https://www.zxgj.cn/g/uuid 随机数：https://www.zxgj.cn/g/suijishu 其它常用开发工具 在线Nginx配置工具：https://nginxconfig.io/ 在线对比工具：http://www.fly63.com/tool/textdiff/ 在线Chrome浏览器插件：https://www.crx4chrome.com/ 变量命名神器：https://unbug.github.io/codelf/ 文本处理工具大全：https://gitee.com/wwwlib/funNLP?_from=gitee_search#https://github.com/wainshine/Company-Names-Corpus 在线素材网站 阿里巴巴矢量图标库：https://www.iconfont.cn/ SimpleIcons：https://simpleicons.org/ SkillIcons: https://skillicons.dev/ 表情包在线网站：https://fabiaoqing.com/ 极简壁纸：https://bz.zzzmh.cn/ Wallpaper Abyss壁纸：https://wall.alphacoders.com Pixabay图片素材库：https://pixabay.com/zh Unsplash图片素材库：https://unsplash.com Pexels图片素材库：http://www.pexels.com PH图片素材库：https://pxhere.com/ NASA图片素材库：https://images.nasa.gov 设计制作类工具 在线PS：https://www.uupoop.com/ 中国色彩：http://zhongguose.com/ 在线音频剪辑：https://www.weixinsyt.com/ 在线视频剪辑：https://www.kapwing.com/ LOGO在线制作：https://www.uugai.com/ 艺术字体在线生成：https://www.qt86.com/ 在线表格转换工具：https://tableconvert.com/ 在线海报设计工具：https://www.designcap.com/ 图片智能放大工具：https://bigjpg.com/ 二维码美化器：https://mh.cli.im/ 在线代码截图工具：https://carbon.now.sh/ 在线抠图工具：https://www.remove.bg/zh ICO图标在线生成：http://www.fly63.com/php/ico/ SVG转PNG：http://www.fly63.com/tool/svg2img/ 视频转GIF：http://www.fly63.com/tool/giftxt/ 二维码在线生成：http://www.fly63.com/tool/ewm/ 二维码在线解码：http://www.fly63.com/php/decoder/ 写作辅助工具 在线字数统计：https://www.eteste.com/ mdnice markdown排版工具：https://mdnice.com/ mdmall markdown排版工具：https://md.aclickall.com/ markdown目录生成器：https://ecotrust-canada.github.io/markdown-toc/ 在线图床（基于github）：https://picx.xpoet.cn/ 图壳图床：https://imgkr.com/ 免费图床：https://sm.ms/ 在线短链接工具：https://urlify.cn/ 在线文本替换：http://www.fly63.com/tool/textreplace/ 表格生成器：https://www.tablesgenerator.com/ 更优雅的Github 徽章与标签生成器：https://shields.io/\n贡献者头像生成器：https://contrib.rocks/\n更多：[GitHub - abhisheknaiidu/awesome-github-profile-readme: 😎 A curated list of awesome GitHub Profile READMEs 📝](https://github.com/abhisheknaiidu/awesome-github-profile-readme#tools)\n在线办公工具 pdf在线处理工具1：https://smallpdf.com/cn/pdf-tools pdf在线处理工具2：https://tools.pdf24.org/zh/ 在线多媒体转换：https://cn.office-converter.com/ 在线文字识别工具：https://ocr.wdku.net/ 在线文件压缩工具：https://docsmall.com/ 官方文档 Git：https://www.liaoxuefeng.com/wiki/896043488029600/900375748016320 SVM：http://svnbook.red-bean.com/nightly/zh/index.html Nginx中文文档：https://www.nginx.cn/doc/index.html Mybatis中文文档：https://mybatis.org/mybatis-3/zh/index.html 微信小程序官方文档：https://developers.weixin.qq.com/miniprogram/dev/framework/ NodeJs中文文档：http://nodejs.cn/learn Golang标准库：https://studygolang.com/pkgdoc Java 8官方文档：https://docs.oracle.com/javase/8/docs.api/index.html Maven官方文档：http://maven.apache.org/guides/ Spring Boot官方文档：https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/ RabbitMq官方文档：https://www.rabbitmq.com/documentation.html Dubbo中文文档：https://dubbo.apache.org/zh/docs/ Netty官方文档：https://netty.io/wiki/index.html ElasticSearch官方文档：https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html Spring Cloud官方文档：https://spring.io/projects/spring-cloud Docker官方文档：https://docs.docker.com/get-started/ K8S中文文档：https://kubernetes.io/zh/docs/home/ Vue.js中文文档：https://cn.vuejs.org/v2/guide/ React.js官方文档：https://reactjs.org/docs/getting-started.html Jenkins中文文档：https://www.jenkins.io/zh/doc/ Ant design官方文档：https://www.antdv.com/docs/vue/introduce-cn/ Hutool：https://www.hutool.cn/ Flink中文文档：https://flink-learning.org.cn/ 厦门大学大数据实验室：http://dblab.xmu.edu.cn/blog/ Flutter中文文档：https://flutter.cn/docs/development/tools/sdk/releases Neo4j官方文档：https://neo4j.com/docs/ Cypher：https://neo4j.com/docs/cypher-manual/ Python API：https://neo4j.com/docs/python-manual/current/ Python指南： Python最佳实践：https://pythonguidecn.readthedocs.io/zh/latest/ Python3-cookbook：https://python3-cookbook.readthedocs.io/zh_CN/latest/ Go语言指南： The way to Go：https://github.com/unknwon/the-way-to-go_ZH_CN/blob/master/eBook/directory.md Go web编程：https://github.com/astaxie/build-web-application-with-golang/blob/master/zh/SUMMARY.md 7 days golang：https://geektutu.com/post/gee.html Go 高级编程：https://chai2010.cn/advanced-go-programming-book/ Go By Example：https://gobyexample-cn.github.io/ 清华大学人工智能技术系列报告：https://reports.aminer.cn/ Spark中文文档v2.0.0：http://spark.apachecn.org/#/ 流媒体下载工具 Hotbox：https://www.hotbox.fun/ 算法学习 leetcode：https://leetcode-cn.com/problemset/all/ nowcoder：https://www.nowcoder.com labuladong的算法小抄：https://labuladong.gitbook.io/algo/ Mysql索引背后的数据结构及算法原理：http://blog.codinglabs.org/articles/theory-of-mysql-index.html 代码例子速查 代码速查表：https://devhints.io/react Go by example: https://gobyexample-cn.github.io/ 计算机在线实验平台 databrick（在线spark集群资源）：https://community.cloud.databricks.com/ 谷歌colab（在线jupyter）：https://colab.research.google.com/notebooks/welcome.ipynb 腾讯云cloudstudio（在线vs theia）：https://coding.net/products/cloudstudio 计算机课程学习 CS自学指南：https://csdiy.wiki/ PythonPark：https://hub.fastgit.org/Jack-Cherish/PythonPark ucore os实验指导书：https://chyyuu.gitbooks.io/ucore_os_docs/content/ 学习CSS布局：https://zh.learnlayout.com/index.html 常用镜像站 阿里云镜像站：https://developer.aliyun.com/mirror\n北京大学镜像站：https://mirrors.pku.edu.cn/Mirrors\n清华大学镜像站：https://mirrors.tuna.tsinghua.edu.cn/\n常用电子资源检索网站 zhelper：https://docs.zhelper.net/search/\n书享家：https://www.shuxiangjia.cn/\n中文书专用鸠摩搜书：https://www.jiumodiary.com/\n书籍知识库（Wall）：https://www.zhishikoo.com/\n苦瓜书盘：http://www.kgbook.com/\nZ-lib：https://zh.bookshome.net/\nCCF图书馆：https://dl.ccf.org.cn\n美团技术团队：https://tech.meituan.com/\n","date":"2021-04-29T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/typora/image-hosting-master/image-hosting-master/20210503/sky-5375005_1920.4x9nxtuuftk0.jpg","permalink":"https://cuterwrite.top/p/useful-tool/","title":"实用工具和网址"},{"content":" Table of Contents generated with DocToc\nHashMap源码分析 1 属性 2 构造方法 3 增加元素 4 读取元素 5 删除元素 6 底层数据结构分析 6.1 JDK1.8之前 6.2 JDK1.8之后 HashMap源码分析 1 属性 初始化容量\nstatic final int DEFAULT_INITIAL_CAPACITY = 1 \u0026lt;\u0026lt; 4; 最大容量\nstatic final int MAXIMUM_CAPACITY = 1 \u0026lt;\u0026lt; 30; 负载因子\nstatic final float DEFAULT_LOAD_FACTOR = 0.75f; 红黑树阈值\nstatic final int TREEIFY_THRESHOLD = 8; 链表阈值\nstatic final int UNTREEIFY_THRESHOLD = 6; 红黑树桶阈值\nstatic final int MIN_TREEIFY_CAPACITY = 64; table数组，用来初始化\ntransient Node\u0026lt;K,V\u0026gt;[] table; entrySet存放缓存\ntransient Set\u0026lt;Map.Entry\u0026lt;K,V\u0026gt;\u0026gt; entrySet; 桶的数量\ntransient int size 修改次数\ntransient int modCount; 阈值\nint threshold 负载因子\nfloat loadFactor 2 构造方法 HashMap()\npublic HashMap(){ this.loadFactor = DEFAULT_LOAD_FACTOR; } HashMap(int initialCapacity)\npublic HashMap(int initialCapacity){ this(int initialCapacity, DEFAULT_LOAD_FACTOR); } HashMap(int initialCapacity, float loadFactor )\npublic HashMap(int initialCapacity, float loadFactor){ if (initialCapacity \u0026lt; 0){ //抛出数值异常 } if (initialCapacity \u0026gt; MAXIMUM_CAPACITY){ initialCapacity = MAXIMUM_CAPACITY; } if (loadFactor \u0026lt;= 0 || Float.isNaN(loadFactor)){ //抛出数值异常 } this.loadFactor = loadFactor; //tableSizeFor，大于等于当前值的下一个2的幂，比如输入17，返回32 this.threshold = tableSizeFor(initialCapacity); } 3 增加元素 put方法分析\npublic V put(K key, V value){ return putVal(hash(key), key, value, false, true); } hash方法分析\nstatic int hash(Object key){ int h; //key为空返回0，先计算key的hashcode，然后与h无符号右移16位后的二进制进行异或 return key == null ? 0 : (h = key.hashCode() ^ (h \u0026gt;\u0026gt;\u0026gt; 16)); } putVal方法分析\nfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict){ Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; p; int n, i; /* * 如果table是否等于空或者等于0，如果是则进行初始化 */ if ((tab = table) == null || (n = tab.length) == 0){ n = (tab = resize()).length(); } /* * 哈希取模，i = (n - 1) \u0026amp; hash，对值的位置进行确定 * 也是capacity为2的幂的原因，与运算效率高于% * capacity为2的幂次时，(n - 1) \u0026amp; hash = hash % n * 如果tab[i] = null，新增一个元素 */ if ((p = tab[i = (n - 1) \u0026amp; hash]) == null){ tab[i] = newNode(hash, key, value, null); } else { //说明该位置有值了 Node\u0026lt;K,V\u0026gt; e; K k; if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.eqauls(k)))){ //key值存在，无论链表还是红黑树都需要替换 e = p; } else if (p instanceof TreeNode){ //如果是红黑树 e = ((TreeNode\u0026lt;K,V\u0026gt;)p).putTreeVal(this, tab, hash, key, value); } else { /* * 链表，遍历到最后节点然后插入； */ for (int binCount = 0; ;binCount++){ if ((e = p.next) == null){ p.next = newNode(hash, key, value, null); //大于红黑树阈值，转换红黑树 if (binCount \u0026gt;= TREEIFY_THRESHOLD - 1){ treeifyBin(tab, hash); } break; } if (e.hash \u0026amp;\u0026amp; hahs \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))){ break; } p = e; } } /* * 如果链表中重复就直接替换 */ if (e != null){ V oldValue = e.value; if (!onlyIfAbsent || oldValue == null){ e.value = value; } afterNodeAccess(e); return oldValue; } } //记录修改次数 modCount++; //如果超过threshold，调用resize if (++size \u0026gt; threshold){ resize(); } afterNodeInsertion(evict); return null; } 如果定位到的数组位置没有元素，直接插入。 如果定位到的数组位置有元素，就要和插入的key比较，key相同则直接覆盖，如果不相同，则判断p是否是TreeNode，如果是则调用e=((TreeNode\u0026lt;K,V)p).putTreeVal(this, tab, hash, key, value)将元素添加进入。如果不是则遍历链表插入到链表尾部。 resize方法分析\nfinal Node\u0026lt;k,V\u0026gt;[] resize(){ Node\u0026lt;K,V\u0026gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap \u0026gt; 0){ if (oldCap \u0026gt;= MAXIMUM_CAPACITY){ threshold = Integer.MAX_VALUE; return oldTab; } else if ((newCap = oldCap \u0026lt;\u0026lt; 1) \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; oldCap \u0026gt;= DEFAULT_INITIAL_CAPACITY){ //threshold加倍 newThr = oldThr \u0026lt;\u0026lt; 1; } } else if (oldThr \u0026gt; 0){ newCap = oldThr; } else { //默认Capacity和threshold，分别为16和12 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } if (newThr == 0){ float ft = (float)newCap * loadFactor; newThr = (newCap \u0026lt; MAXIMUN_CAPACITY \u0026amp;\u0026amp; ft \u0026lt; (float)MAXIMUM_CAPACITY ? (int) ft : Integer.MAX_VALUE); } threshold = newThr; Node\u0026lt;K,V\u0026gt;[] newTab = (Node\u0026lt;K,V\u0026gt;[])new Node[newCap]; table = newTab; if (oldTab != null){ /* * 省略，拷贝旧的hash桶到newTab */ } } 4 读取元素 get方法分析\npublic V get(Object key){ Node\u0026lt;K,V\u0026gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; } getNode方法分析\nfinal Node\u0026lt;K,V\u0026gt; getNode(int hash, Object key){ Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; first, e; int n; K k; //table有元素 if ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp; (first = tab[(n - 1) \u0026amp; hash]) != null){ //从第一个node开始 if (first.hash = hash \u0026amp;\u0026amp; ((k = first.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))){ return first; } //first的下一个node if ((e = first.next) != null){ //若是红黑树，调用红黑树查找方法 if (first instanceof TreeNode){ return ((TreeNode\u0026lt;K,V\u0026gt;)first).getTreeNode(hash, key); } //否则遍历链表查找 do { if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))){ return e; } } while ((e = e.next) != null); } } //table没元素了，直接返回null return null; } 5 删除元素 remove方法分析\npublic V remove(Object key){ Node\u0026lt;K,V\u0026gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; } removeNode方法分析\nfinal Node\u0026lt;K,V\u0026gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable){ Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; p; int n, index; if ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp; (p = tab[index = (n - 1) \u0026amp; hash]) != null){ Node\u0026lt;K,V\u0026gt; node = null; Node\u0026lt;K,V\u0026gt; e; K k; V v; if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))){ node = p; } else if ((e = p.next) != null){ //如果是红黑树，调用红黑树查找方法 if (p instanceof TreeNode){ node = ((TreeNode\u0026lt;K,V\u0026gt;)p).getTreeNode(hash,key); } else { //否则，迭代链表 do{ if (e.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))){ node = e; break; } p = e; } while ((e = e.next) != null); } } //找到节点了 if (node != null \u0026amp;\u0026amp; (!matchValue || (v = node.value) == value || (value != null \u0026amp;\u0026amp; value.equals(v)))){ //调用红黑树删除节点的方法 if (node instanceof TreeNode){ ((TreeNode\u0026lt;K,V\u0026gt;)node).removeTreeNode(this, tab, movable); } else if (node == p){ //是链表头部 tab[index] = node.next; } else { p.next = node.next; } //修改次数 modCount++; size--; afterNodeRemoval(node); return node; } } return null; } 6 底层数据结构分析 6.1 JDK1.8之前 底层：数组加链表\n基本原理：通过key的hashcode经过扰动处理得到hash值，然后通过(n - 1) \u0026amp; hash判断当前元素存放的位置，如果当前位置存在元素的话，就判断该元素与要存放的元素的hash值以及key是否相同，如果相同则直接覆盖，不相同就用拉链法解决冲突。\n扰动函数：hash方法，目的是防止一些实现比较差的hashcode方法，减少碰撞。\nhash方法：\nstatic int hash(int h){ h ^= (h \u0026gt;\u0026gt;\u0026gt; 20) ^ (h \u0026gt;\u0026gt;\u0026gt; 12); return h ^ (h \u0026gt;\u0026gt;\u0026gt; 7) ^ (h \u0026gt;\u0026gt;\u0026gt; 4); } 性能较于1.8差，扰动次数为4\n拉链法：将链表和数组结合，也就是创建一个链表数组Node\u0026lt;K,V\u0026gt;[]，如果遇到哈希冲突，则将冲突的值加到链表中即可。\n6.2 JDK1.8之后 底层：数组加链表加红黑树 基本原理：当链表长度大于阈值8时，会调用treeifyBin方法，根据HashMap数组决定是否转化成红黑树，只有当数组长度大于或者等于64时，才会执行转换红黑树的操作，减减少搜索时间。否则只会进行resize()方法对数组进行扩容。 ","date":"2021-04-27T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/typora/image-hosting-master/image-hosting-master/20210503/mountains-6207115_1920.6ff92y51zus0.jpg","permalink":"https://cuterwrite.top/p/hashmap/","title":"HashMap源码分析"},{"content":" Table of Contents generated with DocToc\n前端开发知识点-基础篇 1 Cookie、Session、SessionStorage和LocalStorage 2 Http和Https的区别 3 Http2.0的特性 4 OSI七层模型 5 TCP和UDP的区别 6 TCP三次握手和四次挥手 7 HTTP状态码 8 HTTP缓存机制 9 XSS攻击和CSRF攻击 10 HTTP常见请求头 11 HTTP常见请求方法 12 输入URL到显示页面的过程 13 Websocket 14 BOM对象 15 CORS跨域请求的方式 16 CSS盒模型 17 link标签和import标签的区别 18 transition和animation的区别 19 Flex布局 20 BFC 21 块元素和行元素 22 HTML5和CSS3的新元素 23 重绘和重排 24 闭包 25 类的创建和继承 26 promise、generator、async/await 27 事件流 28 事件委托（代理） 29 事件循环 30 图片懒加载和预加载 31 new操作符 32 bind、apply、call的区别 33 节流和防抖 34 深拷贝 35 对象属性改变监听-Proxy 36 变量提升和暂时性死区 37 箭头函数 38 原型链 39 ES6新特性 40 垂直居中的方法 41 前端性能优化 42 get和post的区别 43 web worker 44 浮动清除 45 CSS选择器 前端开发知识点-基础篇 1 Cookie、Session、SessionStorage和LocalStorage Cookie：服务器提供的一种用于维护会话状态信息的数据，通过服务器发送到浏览器，浏览器保存在本地的一种纯文本文件，当下一次有同源的请求时，将保存的Cookie数据添加到请求头部，发送给服务端。可以用来实现记录用户登录状态等功能。\nSession：服务器为了保存用户状态而创建的一个特殊的对象。在浏览器第一次访问服务器时，服务器会创建一个session对象,该对象有一个唯一的id,即sessionid，服务器会把sessionid以cookie的形式发送给浏览器,当浏览器再次访问服务器时,会携带cookie在请求头,可以通过cookie中的sessionid来访问session对象，可以实现在http无状态基础上实现用户状态管理。\nCookie的特点：\nCookie数据存放在客户端上。 Cookie是非安全的，由于存在本地，有被盗取的可能。 Cookie保存的数据不能超过4K。 Cookie始终在同源的HTTP请求中携带。 如何设置Cookie：\n服务端：使用Set-Cookie的响应头部，包含5个属性值expires、 domain、path、secure和httponly，分别代表过期时间、域名、路径、安全传输、是否禁用客户端js脚本访问。 客户端：通过JS脚本，例如document.cookie Cookie和Session和区别：\nCookie存放在客户端，Session存放在服务端。 Cookie是非安全的，考虑安全应该使用Session 访问增多时，服务器压力比较大，考虑使用Cookie 单个Cookie保存的数据不能超过4K Cookie、SessionStorage和LocalStorage的区别：\nCookie始终在同源的HTTP请求中携带。（即使不需要） Cookie可以限制可访问的path 存储大小：Cookie存放数据不能超过4k，WebStorage可以达到5M或更大。 有效期不同：SessionStorage只在当前浏览器窗口关闭前有效，LocalStorage始终有效，用作持久化，Cookie在设置的过期时间之前一直有效。 Cookie常用场景：\n保持用户登录状态 跟踪用户行为，记录用户选项 2 Http和Https的区别 HTTPS基本原理：客户端使用HTTPS URL访问服务端，要去服务端建立SSL连接，服务端接收到客户端请求后，会将网站的证书（携带公钥）返回给客户端，客户端和服务端开始协商SSL连接的安全等级，也就是加密等级，然后两者通过协商一致的安全等级，建立会话密钥，然后客户端通过网站的公钥来加密会话密钥，传给网站，服务端通过自己的私钥解密出会话密钥，通过会话密钥加密与客户端的通信。\n安全性：HTTPS是安全超文本协议，在HTTP基础上有更强的安全性，简单来说，HTTPS是使用了TLS/SSL加密的HTTP协议。 申请证书：HTTPS需要使用CA证书。 传输协议：HTTP以明文形式传输数据，HTTPS以加密形式传输数据。 端口号不同：一般来说，HTTP协议的端口为80，HTTPS的端口为443 连接方式：HTTP的连接简单，是无状态的，HTTPS在HTTP的基础上使用了SSL协议进行加密传输。 3 Http2.0的特性 提升了访问速度 允许多路复用：允许同时通过单一的HTTP/2连接发送多重请求-响应信息。 二进制分帧：将所有的传输数据分割为更小的数据帧，并对它们进行二进制编码。 首部压缩 服务器端推送 4 OSI七层模型 应用层：文件传输，常用协议HTTP、STMP、FTP 表示层：数据格式化、代码转换、数据加密 会话层：建立和解除会话 传输层：提供端对端的接口，TCP/UDP 网络层：为数据包选择路由，IP/ICMP 数据链路层：传输带有地址的帧。 物理层：二进制的数据形式在物理媒体上传输数据。 5 TCP和UDP的区别 TCP是面向连接的，UDP是无连接的，即发送数据前不需要先建立连接。 TCP提供可靠的服务，无差错、不丢失、不重复、按序到达，UDP尽最大努力交付。（大数据量使用TCP） TCP面向字节流，UDP面向报文。（UDP无拥塞控制，可能出现丢包） TCP只能1对1，UDP支持1对1和1对多。 TCP首部较大为20字节，UDP只有8字节。 6 TCP三次握手和四次挥手 TCP三次握手：（A为客户端，B为服务端）\nB处于监听，A向B发送连接请求报文SYN=1，ACK=0，选择一个初始的序号x B收到连接请求报文，如果同意连接，则向A发送连接确认报文SYN=1，ACK=1，确认号ack=x+1，选择初始序号y A收到B的连接确认报文，向B发送确认报文ACK=1，确认号ack=y+1，序号为x+1 B收到A的确认，连接建立。 三次握手的原因\n第三次握手防止失效的连接请求到达服务器，让服务器错误打开连接。客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务端返回的确认，导致：客户端超时重传重新建立连接，这时就会出现2个SYN连接。如果有第三次握手，客户端会忽略服务端之后发送的对滞留连接请求的确认，不进行第三次握手，因此就不会打开连接。\nTCP四次挥手：\nA发送连接释放报文FIN=1，序号为u B收到后发出确认ACK=1, ack=x+1, 序号为v，此时TCP属于半关闭状态，A不能发数据，B能发数据。 B不需要连接时，发送连接释放报文FIN=1，ACK=1，ack=u+1，序号为w A收到后发出确认ACK=1，ack=w+1，序号为u+1，进入TIME-WAIT状态，等待2MSL（最大报文存存活时间）后释放连接。 B收到A的确认后释放连接。 7 HTTP状态码 状态码按第一个数字分类，1表示信息，2表示成功，3表示重定向，4表示客户端错误，5表示服务端错误。\n常见状态码：101切换协议、200成功、301永久重定向、302临时重定向、304未修改、400请求无效、401未认证、403拒绝执行、404未找到资源\n200和304的区别：\n200是请求成功，一般用于GET和POST 304是未修改，所请求的资源未修改，服务器返回此状态码时，不会返回任何资源，客户端通过缓存访问资源（协商缓存）。 8 HTTP缓存机制 强缓存：返回状态码为200，不会向服务端发送请求，直接从缓存取资源。相关字段有pragma、expires、cache-control（cache-control优先级更高，pragma优先级最高）。 协商缓存：返回状态码为304，会向服务端发送请求，通过服务器告知缓存是否可用。相关字段有Last-Modified/If-Modified-Since，Etag/If-None-Match 缓存流程：\n缓存是否过期：未过期，则从缓存读取（强缓存），否则下一步。 Etag值：True，向服务端发送带If-None-Match的请求，否则继续判断Last-Modified Last-Modified为True，向服务端发送带If-Modified-Since的请求，否则正式发送请求，相应后缓存协商。。（无缓存） 服务器根据If-None-Match和If-Modified-Since决策返回200还是304，304则从缓存读取（协商缓存），200则走正常请求。 9 XSS攻击和CSRF攻击 XSS攻击：跨站脚本攻击，盗取Cookie，在返回的HTML中嵌入js脚本，防范方法：用户输入检查（过滤特殊字符等）、设置set-cookie的httponly属性。\nCSRF攻击：跨站请求伪造，利用Cookie，以用户的名义发送恶意请求。防范方法：验证码、检查HTTPS头部的referer、使用token。\n10 HTTP常见请求头 可以划分为：通用首部、请求首部、相应首部和实体首部\n通用首部：\nAccept：可接受的响应内容类型 Accept-Encoding：可接受的响应内容编码形式 Accept-Language：可接受的响应语言列表 Cache-Control：是否使用强缓存 Pragma：一般来说指，是否使用强缓存 Connection：连接类型（keep-alive） User-Agent：浏览器的身份标识字符串 Content-Length：8进制标识的请求体的长度。 Content-Type：请求体的MIME类型，用于POST和GET Host：服务器的域名及监听端口号，80则可以省略 请求首部：\ncookie Etag/If-None-Match Last-Modified/if-Modified-Since等 响应首部：\nset-cookie等 11 HTTP常见请求方法 get：请求资源 head：请求header post：建立或修改资源。 put：取代资源 delete：删除指定资源 connect： options：允许客户端查看服务端的性能 trace：回显服务器收到的请求，用于测试和诊断 patch：对put的补充，对已有资源局部更新。 12 输入URL到显示页面的过程 首先需要找到这个url域名的服务器ip，首先会寻找缓存中的记录，如果没有则查找本地的hosts文件是否有记录，如果没有则进行下一步。 DNS解析：首先，客户端通过发送DHCP请求报文获取网关路由器的IP地址，然后通过ARP协议获取网关路由器的MAC地址，接着向网关路由器发送DNS查询报文，到达DNS服务器后，在DNS数据库中查询域名解析后的IP地址。 浏览器根据得到的IP地址及相应的端口号，构造一个HTTP请求报文，并将这个HTTP请求封装在一个TCP包中，依次经过传输层、网络层、数据链路层、物理层到达服务端，服务端解析这个请求来作出响应给浏览器。 浏览器解析响应内容并渲染页面，结束连接。（DOM树和CSSOM树） 13 Websocket WebSocket是HTML5中的协议，支持持久连续，http协议不支持持久性连接。Http1.0和HTTP1.1都不支持持久性的链接，HTTP1.1中的keep-alive，将多个http请求合并为1个。\nHTTP的生命周期通过Request来界定，也就是Request一个Response，那么在Http1.0协议中，这次Http请求就结束了。在Http1.1中进行了改进，有一个connection：Keep-alive，也就是说，在一个Http连接中，可以发送多个Request，接收多个Response。但是必须记住，在Http中一个Request只能对应有一个Response，而且这个Response是被动的，不能主动发起。\nWebSocket是基于Http协议的，或者说借用了Http协议来完成一部分握手，在握手阶段与Http是相同的。有2个相关的请求头，upgrade，connection。\nupgrade:websocket\nconnection:upgrade\n14 BOM对象 浏览器对象，location、history和navigator\n常用属性和方法：\nhistory：go、back、forward navigator：userAgent、cookieEnabled location： get类型：href、search、hash、host、hostname、pathname、port、protocal set类型：assgin（设置url）、replace（设置url，并且在history中移除）、reload 15 CORS跨域请求的方式 cors：跨域资源共享，客服了AJAX只能同源使用的限制。\n只要同时满足以下两大条件，就属于简单请求\n请求方法为head、get、post之一 请求头只有：Accepet、Accpet-Language、Content-Language、Last-Event-ID、Content-Type这五种，并且Content-type只有application/x-www-form-unlencoded、multipart/form-data、text/plain这三种。 对于简单请求，浏览器直接发出CORS请求，在请求头加上Origin字段，用来说明来自哪个源，服务器根据这个值决定是否同意此次请求，同意则返回响应，响应头多出几个字段（以Access-Control-开头），否则返回一个正常的HTTP响应，但请求头不包含Access-Control-Allow-Origin字段，抛出一个错误。\nwithCredentials属性\nCORS请求默认不发送Cookie和HTTP认证信息，如果需要发送，一方面需要服务器同意，指定Access-Control-Allow-Credentials为True，另一方面ajax请求要设置withCredentials属性为true。此外，如果要发送Cookie，Access-Control-Allow-Origin就不能设置为星号，必须指定明确的、与明确网页一致的域名。同时，Cookie依然遵循同源政策。\n预检请求\n对于复杂请求的CORS请求，会在正式通信前，增加一次HTTP查询请求，称为预检请求，浏览器先询问服务器，如果同意才会发出正式的XMLHttpRequest请求，否则就报错。\n预检请求用的请求方法为OPTIONS，请求头有Origin、Access-Control-Request-Method、Access-Control-Request-Headers这三个字段。\n一旦服务器通过了预检请求，以后每次浏览器正常的CORS请求，都跟正常请求一样，会有一个OrIgin请求头字段，服务器响应请求头会带有Access-Control-Allow-Origin。\n16 CSS盒模型 标准盒模型：box-sizing：content-box；width=content IE盒模型：box-sizing：border-box；width=content+border+padding box-sizing：padding-box；width=content+padding 17 link标签和import标签的区别 link属于html标签，@import是css提供的。 加载时机：页面加载时，link会同时加载，而@import引用的css会等到页面加载结束后加载。 兼容性：@import只有IE5以上才支持。 优先级：link大于@import 18 transition和animation的区别 大部分属性相同，都是随时间改变元素的属性值。 transition需要触发一个事件才能改变属性，而animation不需要触发任何事件。 transition为2帧，animation可以一帧一帧。 19 Flex布局 弹性布局，用来为盒状模型提供最大的灵活性。\n划分：容器属性和元素属性\n容器属性：\nflex-direction：主轴方向 flex-wrap：换行规则 flew-flow：上面两者结合。 justify-content：主轴对齐方式 align-items：交叉轴对齐方式 元素属性：\norder：排列顺序 flex-glow：放大比例 flex-shrink：缩小比例 flex-basis：占据空间 flex：上面三者的缩写 align-self：允许元素与其它项目的对齐方式不一样，默认auto，继承父元素的align-item 20 BFC BFC：块级格式化上下文，用于清除浮动，防止margin重叠等\nBFC是页面上的一个独立容器，子元素不会影响到外面，计算BFC的高度时，浮动元素也会参与计算。\n会生成BFC的元素：\nfloat不为none的元素 position为fixed和absolute的元素 display为inline-block、table-cell、table-caption、flex、inline-flex的元素。 overflow不为visible的元素 21 块元素和行元素 块元素：独占一行，并且有自动填满父元素，可以设置margin和padding以及高度和宽度 行元素：不会独占一行，width和height会失效，并且在垂直方向的padding和margin会失效。 22 HTML5和CSS3的新元素 HTML5新增元素： 新标签：8个语义标签（header、section、footer、aside、nav、main、article、figure）、mark高亮、progress进度、新表单控件(calendar、data、time、email、url、search)、新的input类型（color、date、datetime、datetime-local、email） canvas绘图，支持内联SVG，支持MathML 多媒体：audio、video、source、embed track 本地离线存储：manifest配置文件 web存储：localStorage、SessionStorage 其它：web worker、websocket CSS3新元素 边框： border-radius、box-shadow 背景：background-size、background-origin 文本效果：text-shadow、word-wrap、word-break等 2D/3D转换：transform 动画：animation 23 重绘和重排 DOM的变化影响到了预算内宿的几何属性比如宽高，浏览器重新计算元素的几何属性，其他元素的几何属性也会受到影响，浏览器需要重新构造渲染树，这个过程称之为重排，浏览器将受到影响的部分重新绘制在屏幕上的过程称为重绘。\n重绘和重排的原因：\n添加或删除可见的DOM元素 元素尺寸位置的改变 浏览器页面初始化 浏览器窗口大小发生改变。 重排一定导致重绘，重绘不一定导致重排。\n减少重排，提高性能的方法：\n元素的多次样式修改合并成一次修改。 如需进行对DOM节点进行多次操作，先将其脱离文本流之后再进行多次操作。 table布局的渲染与普通DOM节点的操作相比，性能消耗更大，如果可以，尽量减少table布局的使用。 缓存常用的布局信息。 24 闭包 闭包：当一个嵌套的内部函数引用了外部函数的变量或者函数时，外部函数在执行时就产生了闭包。\n典型的闭包：\n将函数作为灵一个函数的返回值 将函数作为实参传给另一个函数调用 闭包特点：函数嵌套函数，内部函数引用外部函数的变量。\n闭包的作用：\n延长外部函数局部变量的生命周期，可以用于实现计数器。 可以形成变量的局部作用域，实现函数封装。 闭包的缺点：函数定义的变量和数据会一直存在内存函数中，不会被及时释放，容易导致内存泄漏。\n25 类的创建和继承 类的创建：new一个function，在这个function中的prototype里面添加属性和方法\nfunction Animal(name){ this.name = name || \u0026#39;Animal\u0026#39;; //实例方法 this.sleep = function(){ console.log(this.name + \u0026#34;正在睡觉!\u0026#34;); } //原型方法 Animal.prototype.eat = function(food){ console.log(this.name + \u0026#34;正在吃\u0026#34; + food); }; } 类的继承：4种方式\n原型链继承（new一个空对象，空对象指向Animal，缺点是无法多继承）\nfunction Cat(){ Cat.prototype = new Animal(); Cat.prototype.name = \u0026#39;Cat\u0026#39;; } 构造继承（使用父亲的构造函数来增强子类实例，等于复制父亲的实例属性）\nfunction Cat(name){ Animal.call(this); this.name = name || \u0026#39;Tom\u0026#39;; } 优点：可以多继承\n缺点：只能继承实例属性和方法\n实例集成和拷贝继承：\n实例继承：为父亲实例添加新特性，作为子类实例返回 拷贝继承：拷贝父亲元素上的属性和方法 组合继承：构造继承和原型链继承的组合\nfunction Cat(name){ Animal.call(this); this.name = name || \u0026#39;Tom\u0026#39;; } Cat.prototype = new Animal(); Cat.prototype.constructor = Cat; 通过调用父类构造，继承父亲的属性并保留传参的优点，然后通过将父亲实例作为子类原型，实现函数复用。\n特点：可以继承实例属性，也可以继承原型属性\n缺点：调用了两次父类构造函数，生成了两份实例\n寄生组合继承：通过寄生方式，砍掉父亲的实例属性\nfunction Cat(name){ Animal.call(this); this.name = name || \u0026#39;Tom\u0026#39;; } var Super = function(){}; Super.prototype = Animal.prototype; Cat.prototype = new Super(); 最常用的方法：\nCat.prototype = Object.create(Animal.prototype); 26 promise、generator、async/await promise：CommonJS工作组提出的一种规范，目的是为异步编程提供统一接口。每一个异步任务返回一个Promise对象，该对象有一个then方法，允许指定回调函数。有三个状态：等待（pending）、已完成（resolved，又称fulfilled）、已拒绝（rejected）。promise必须实现then方法（可以说，then就是promise的核心），而且then必须返回一个promise，同一个promise的then可以调用多次，并且回调的执行顺序跟它们被定义时的顺序一致。then方法接受两个参数，第一个参数是成功时的回调，在promise由“等待”态转换到“完成”态时调用，另一个是失败时的回调，在promise由“等待”态转换到“拒绝”态时调用。同时，then可以接受另一个promise传入，也接受一个“类then”的对象或方法，即thenable对象。\n使用举例：\nfunc(){ return new Promise((resolve,reject)=\u0026gt;{ work().then(res=\u0026gt;{ this.data = res.data; resolve(); }).catch(error=\u0026gt;{ reject(error); }) }) } promise的用处\n解决了回调函数的回调地狱问题，有时候我们的请求需要上一个请求返回的结果，会造成相互间回调函数的嵌套，使得代码的可读性和维护性很低。 让代码变得扁平，可读性更好，then返回一个promise，可以把then串起来，then返回的promise装载了由调用返回的值。 在异步回调中，函数的执行栈与原函数分离开，导致外部无法抓住异常。在promise中我们可以使用reject捕获失败情况，和catch捕获执行异常。 promise只不过是一种更良好的编程风格。 promise的缺点：\n不设置回调函数，promise内部抛出的错误，无法返回到外部。 处于pending状态时，无法得知进展到哪一个阶段。 async和await：\nasync函数返回一个promise对象，在没有await的情况下执行async函数，它会立即返回一个promise对象，并且，绝对不会注意后面语句的执行，await关键字只能用在aync定义的函数内； await 可以用于等待一个 async 函数的返回值，如果它等到的是一个 Promise 对象，await 就忙起来了，它会阻塞后面的代码，等着 Promise 对象 resolve，然后得到 resolve 的值，作为 await 表达式的运算结果。async/await使得异步代码看起来像同步代码，使代码简洁，可读性更好，避免嵌套。 27 事件流 事件流：从页面接受事件的顺序，DOM2级事件流包括下面几个阶段\n事件捕获阶段 处于目标阶段 事件冒泡阶段 addEventListener：DOM2级事件新增的指定事件处理程序的操作，这个方法接受三个参数，要处理的事件名，作为事件处理程序的函数和一个布尔值（true则在捕获阶段调用事件处理程序，否则在冒泡阶段调用）。IE只支持事件冒泡。\naddEventListener示例：\nvar op = document.getElementById(\u0026#34;id\u0026#34;); op.addEventListener(\u0026#39;click\u0026#39;, function(e){ //do something }, false); 28 事件委托（代理） 事件委托：事件委托指的是，不在事件的发生地（直接dom）上设置监听函数，而是在其父元素上设置监听函数，通过事件冒泡，父元素可以监听到子元素上事件的触发，通过判断事件发生元素DOM的类型，来做出不同的响应。\n举例：最经典的就是ul和li标签的事件监听，比如我们在添加事件时候，采用事件委托机制，不会在li标签上直接添加，而是在ul父元素上添加。\n优点：比较合适动态元素的绑定，新添加的子元素也会有监听函数，也可以有事件触发机制。\n29 事件循环 事务队列中，在每一次事件循环中，宏任务只会提取一个执行，而微任务会一直提取，直到微任务队列为空为止。\n也就是说如果某个微任务任务被推入到执行中，那么当主线程任务执行完成后，会循环调用该队列任务中的下一个任务来执行，直到该任务队列到最后一个任务为止。而事件循环每次只会入栈一个宏任务,主线程执行完成该任务后又会检查微任务队列并完成里面的所有任务后再执行宏任务队列的任务。\n宏任务：setTimeOut、setInterval、setImmediate、IO、UI渲染、主JS、requestAnimationFrame等。\n微任务：process.nextTick、promise.then()，Object.observe()等\n30 图片懒加载和预加载 懒加载：迟缓加载甚至不加载。（减少服务器的压力）\n实现方法：图片地址不放在src，而是放在其它属性，页面加载后，根据scrollTop判断图片是否在用户视野内，如果在，则将data-original属性中的值放在src。在滚动事件中重复判断图片是否进入视野。 预加载：提前加载图片，当用户需要查看时直接从本地缓存中渲染。（会增大服务器的压力）\nCSS实现：background：url()\nJS实现：\nconst img = new Image(); img.src = \u0026#39;xxx\u0026#39;; 31 new操作符 new操作符新建了一个空对象，这个对象原型指向构造函数的prototype，执行构造函数后返回这个对象\n实现一个new的方法：\nfunction Animal(){...} //var a = new Animal(); function myNew(){ let obj = {} let Constructor = [].shifit.apply(arguments); //绑定原型 obj.__proto__ = Constructor.prototype; //调用构造函数 let res = Constructor.apply(obj, arguments); return typeof res === \u0026#39;object\u0026#39; ? res : obj; } 32 bind、apply、call的区别 apply和call用来改变函数的this指向，它们两个函数的第一个参数都是一样的，表示要改变指向的那个对象，第二个参数，apply中是数组，而call是arg1,arg2\u0026hellip;的形式。 bind改变this作用域会返回一个新的函数，这个函数不会立即执行。 33 节流和防抖 防抖：持续拖动滚动条，只要不停止触发，就永远不会有输出。短时间内触发的事件，在某个时间期限内，函数只执行一次。\nfunction debounce(func, wait){ var timeout; return function(){ clearTimeout(timeout); timeout = setTimeout(func,wait); } } 节流：持续拖动滚动条，每间隔一段时间，就会输出反馈。相当于技能冷却，执行之后，函数会失效一段时间，冷却之后，又会恢复，设置一个状态位，判断是否处于工作状态。（在防抖基础上，到达指定事件必须输出）\nfunction throttle(func, wait, mustRun){ var timeout, start = new Data(); return function(){ var context = this, args = arguments; var cur = new Data(); clearTimeout(timeout); if (cur - start \u0026gt;= mustRun){ func.apply(context, args); start = cur; } else { timeout = setTimeout(func, wait); } } } 34 深拷贝 简单深拷贝：JSON序列化和反序列化\nfunction deepCopy(obj){ let __obj = JSON.stringify(obj); return JSON.parse(_obj); } 递归方法：\nfunction deepCopy(obj){ let res; if (typeof obj === \u0026#39;Object\u0026#39;){ if (Array.isArray(obj)){ res = [] for (let i in obj){ res.push(deepCopy(obj[i])) } } else if (obj == null){ res = null; } else if (obj.constructor === \u0026#39;RegExp\u0026#39;){ res = obj; } else { res = {} for (let i in obj){ res[i] = deepCopy(obj[i]) } } } else { res = obj; } return res; } 35 对象属性改变监听-Proxy 示例\nvar user = new Proxy({}, { set:function(target,key,value,receiver){ } }) 36 变量提升和暂时性死区 变量提升：var定义变量，变量可以在声明前使用，值为undefined；let不会出现这个情况。\n暂时性死区TDZ：只要一进入当前作用域，所要使用的变量就已经存在了，但是不可获取，只有等待变量声明的那一行代码出现，才可以获取和使用该变量。\n只要块级作用域内存在let和const命令，它所声明的变量就会绑定这个区域，不再受外部影响。\n37 箭头函数 基本语法\nlet func = value=\u0026gt;value; //aka let func = function(value){ return value; }; 与普通函数的区别\n箭头函数没有this，如果普通函数包含箭头函数，那么this访问的就是最近一层普通函数的this 箭头函数是匿名函数，不能作为构造函数，不能使用new 箭头函数没有自己的arguments参数，虽然有name属性但是是空字符串，用\u0026hellip;扩展运算符。 箭头函数通过call()或apply()方法调用一个函数时，只传入了一个参数，对this并没有影响。 箭头函数没有原型属性prototype 38 原型链 原型：prototype，是一个对象，作用是共享属性和方法\n原型链：原型与原型层层连接的过程即为原型链\n假设B继承了A，b是B的实例，那么就有以下关系：\n（1）\nb.__proto__ = B.prototype （2）B.prototype.constructor = B，A.prototype.constructor = A\n（3）\nB.__proto__ = A （4）\nB.prototype.__proto__ = A.prototype 39 ES6新特性 let（解决了变量提升）、 const常量，块级作用域（暂时性死区）。 模板字符串：“xxx${}” 箭头函数 对象，数组解构赋值 for in和for of class类 extend类继承 40 垂直居中的方法 margin：auto，left、right、top、bottom全设为0 display：flex，align-items:center，justify-content:center; 41 前端性能优化 降低请求量：合并资源、减少HTTP请求数、minify/gzip压缩，webP，懒加载 加快请求速度：预解析DNS、减少域名数、并行加载、CDN分发 缓存：HTTP协议缓存请求、离线缓存manifest、离线数据缓存localStorage 渲染：JS/CSS优化，加载顺序，服务端渲染，pipeline 42 get和post的区别 get参数通过url传递，post放在request body中 get请求在url中传递的参数有长度限制，post没有 get参数暴露在url，不安全。 get请求只能进行url编码，post支持多种编码方式 get请求浏览器会主动缓存。 get请求参数会被完整保留在浏览历史记录。 get用来获取资源，post用来增加或更新资源。 43 web worker 在HTML页面中，如果在执行脚本时，页面的状态是不可响应的，直到脚本执行完成后，页面才变成可响应。web worker是运行在后台的js，独立于其他脚本，不会影响页面你的性能。并且通过postMessage将结果回传到主线程。这样在进行复杂操作的时候，就不会阻塞主线程了。\n如何创建web worker：\n检测浏览器对于web worker的支持性\n创建web worker文件（js，回传函数等）\n创建web worker对象\n44 浮动清除 overflow:hidden/auto 给浮动的元素的容器添加浮动 45 CSS选择器 ID选择器、Class选择器、标签选择器、伪元素选择器、伪类选择器\n优先级：\n引入了同类的选择器：排在后面的样式属性优先 引入了不同的选择器：id\u0026gt;class\u0026gt;标签 ","date":"2021-04-27T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/typora/image-hosting-master/image-hosting-master/20210503/lake-5538757_1920.2fnhpht9u2vw.jpg","permalink":"https://cuterwrite.top/p/web-development-1/","title":"前端开发知识点复习-基础篇"},{"content":" Table of Contents generated with DocToc\n一、操作系统 1、进程与线程的区别 2、进程间的通信的几种方式 3、线程同步的方式 4、进程同步的方式 5、死锁 5.1、死锁的定义 5.2、死锁必要条件 5.3、死锁处理 6、进程的状态 7、进程调度算法 8、虚拟内存 9、页面置换算法 10、分页与分段的区别 二、计算机网络 1、计算机网络体系结构 1.1、五层协议 1.2、OSI七层协议 2、UDP和TCP的特点 3、UDP首部格式 4、TCP首部格式 5、TCP三次握手 6、TCP四次挥手 7、TCP可靠传输 8、TCP滑动窗口 9、TCP 流量控制 10、TCP 拥塞控制 11、域名系统 12、FTP协议 13、DHCP协议 14、SSH协议 15、SMTP协议 16、Web页面请求过程 16.1. DHCP 配置主机信息 16.2. ARP 解析 MAC 地址 16.3. DNS 解析域名 16.4. HTTP 请求页面 一、操作系统 1、进程与线程的区别 进程是对运行时程序的封装，是系统进行资源调度和分配的的基本单位，实现了操作系统的并发；\n线程是进程的子任务，是CPU调度和分派的基本单位，用于保证程序的 实时性，实现进程内部的并发；\n一个程序至少有一个进程，一个进程至少有一个线程，线程依赖于进程而存在；\n进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。\n2、进程间的通信的几种方式 管道（pipe）及命名管道（named pipe）：管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信； 信号（signal）：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生； 消息队列：消息队列是消息的链接表，它克服了上两种通信方式中信号量有限的缺点，具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息； 共享内存：可以说这是最有用的进程间通信方式。它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等； 信号量：主要作为进程之间及同一种进程的不同线程之间得同步和互斥手段； 套接字：这是一种更为一般得进程间通信机制，它可用于网络中不同机器之间的进程间通信，应用非常广泛。 3、线程同步的方式 互斥量 Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问 信号量 Semphare：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量 事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作 4、进程同步的方式 临界区：对临界资源进行访问的那段代码称为临界区。为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。 同步与互斥 信号量 管程：有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。管程引入了 条件变量 以及相关的操作：wait() 和 signal() 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。 5、死锁 5.1、死锁的定义 在两个或者多个并发进程中，如果每个进程持有某种资源而又等待其它进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。通俗的讲，就是两个或多个进程无限期的阻塞、相互等待的一种状态。\n5.2、死锁必要条件 互斥：每个资源要么已经分配给了一个进程，要么就是可用的。 占有和等待：已经得到了某个资源的进程可以再请求新的资源。 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。 5.3、死锁处理 鸵鸟策略：把头埋在沙子里，假装根本没发生问题。因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。\n死锁检测与死锁恢复：不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。\n每种类型一个资源的死锁检测：通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。 每种类型多个资源的死锁检测：每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。 寻找一个没有标记的进程 Pi，它所请求的资源小于等于 A。 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。 如果没有这样一个进程，算法终止。 死锁恢复：在程序运行之前预防发生死锁。\n破坏互斥条件 破坏占有和等待条件 破坏不可抢占条件 破坏环路等待条件 死锁避免：在程序运行时避免发生死锁。\n安全状态：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。\n银行家算法：检查一个状态是否安全的算法如下：\n查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。 重复以上两步，直到所有进程都标记为终止，则状态是安全的。 如果一个状态不是安全的，需要拒绝进入这个状态。\n6、进程的状态 ready running waiting 只有ready和running可以相互转换，其它都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。 阻塞状态是缺少需要的资源从running状态转换而来，但是该资源不包括CPU时间，缺少CPU时间会从running变成ready。 7、进程调度算法 先来先服务 first-come first-serverd（FCFS）：非抢占式的调度算法，按照请求的顺序进行调度。有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。 短作业优先 shortest job first（SJF）：非抢占式的调度算法，按估计运行时间最短的顺序进行调度。长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。 最短剩余时间优先 shortest remaining time next（SRTN）：最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。 时间片轮转：将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。 优先级调度：每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。 多级反馈队列：可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。 8、虚拟内存 虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。\n为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。\n9、页面置换算法 OPT LRU LFU FIFO 10、分页与分段的区别 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。\n地址空间的维度：分页是一维地址空间，分段是二维的。\n大小是否可以改变：页的大小不可变，段的大小可以动态改变。\n出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。\n二、计算机网络 1、计算机网络体系结构 1.1、五层协议 应用层 运输层 网络层 数据链路层 物理层 1.2、OSI七层协议 应用层：为特定应用程序提供数据传输服务 表示层：数据压缩、加密以及数据描述 会话层：建立和管理回话 运输层：提供的是进程间的通用数据传输服务。 网络层：为主机间提供数据传输服务 数据链路层：主机之间可以有很多链路，链路层协议就是为同一链路的节点提供服务。数据链路层把网络层传来的分组封装成帧。 物理层：尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异。 2、UDP和TCP的特点 用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。 传输控制协议 TCP（Transmission Control Protocol）是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。 3、UDP首部格式 首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。\n4、TCP首部格式 序号 ：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。 确认号 ：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。 数据偏移 ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。 确认 ACK ：当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。 同步 SYN ：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。 终止 FIN ：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。 窗口 ：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。 5、TCP三次握手 假设 A 为客户端，B 为服务器端。\n首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。 A 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。 B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。 A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。 B 收到 A 的确认后，连接建立。 三次握手的原因\n第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。\n客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。\n6、TCP四次挥手 以下描述不讨论序号和确认号，因为序号和确认号的规则比较简单。并且不讨论 ACK，因为 ACK 在连接建立之后都为 1。\nA 发送连接释放报文，FIN=1。\nB 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。\n当 B 不再需要连接时，发送连接释放报文，FIN=1。\nA 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接。\nB 收到 A 的确认后释放连接。\n四次挥手的原因\n客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。\nTIME_WAIT\n客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由：\n确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。 7、TCP可靠传输 TCP 使用超时重传来实现可靠传输：如果一个已经发送的报文段在超时时间内没有收到确认，那么就重传这个报文段。\n8、TCP滑动窗口 窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。\n发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。\n接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。\n9、TCP 流量控制 流量控制是为了控制发送方发送速率，保证接收方来得及接收。\n接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。\n10、TCP 拥塞控制 如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。\nTCP 主要通过四个算法来进行拥塞控制：慢开始、拥塞避免、快重传、快恢复。\n发送方需要维护一个叫做拥塞窗口（cwnd）的状态变量，注意拥塞窗口与发送方窗口的区别：拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口。\n为了便于讨论，做如下假设：\n接收方有足够大的接收缓存，因此不会发生流量控制； 虽然 TCP 的窗口基于字节，但是这里设窗口的大小单位为报文段。 1、慢开始与拥塞避免\n发送的最初执行慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 \u0026hellip;\n注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh，当 cwnd \u0026gt;= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。\n如果出现了超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始。\n2、快重传与快恢复\n在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。\n在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M2，则 M3 丢失，立即重传 M3。\n在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。\n慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。\n11、域名系统 DNS 是一个分布式数据库，提供了主机名和 IP 地址之间相互转换的服务。这里的分布式数据库是指，每个站点只保留它自己的那部分数据。\n域名具有层次结构，从上到下依次为：根域名、顶级域名、二级域名。\nDNS 可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。大多数情况下 DNS 使用 UDP 进行传输，这就要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。在两种情况下会使用 TCP 进行传输：\n如果返回的响应超过的 512 字节（UDP 最大只支持 512 字节的数据）。 区域传送（区域传送是主域名服务器向辅助域名服务器传送变化的那部分数据）。 12、FTP协议 FTP 使用 TCP 进行连接，它需要两个连接来传送一个文件：\n控制连接：服务器打开端口号 21 等待客户端的连接，客户端主动建立连接后，使用这个连接将客户端的命令传送给服务器，并传回服务器的应答。 数据连接：用来传送一个文件数据。 根据数据连接是否是服务器端主动建立，FTP 有主动和被动两种模式：\n主动模式：服务器端主动建立数据连接，其中服务器端的端口号为 20，客户端的端口号随机，但是必须大于 1024，因为 0~1023 是熟知端口号。 被动模式：客户端主动建立数据连接，其中客户端的端口号由客户端自己指定，服务器端的端口号随机。 主动模式要求客户端开放端口号给服务器端，需要去配置客户端的防火墙。被动模式只需要服务器端开放端口号即可，无需客户端配置防火墙。但是被动模式会导致服务器端的安全性减弱，因为开放了过多的端口号。\n13、DHCP协议 DHCP (Dynamic Host Configuration Protocol) 提供了即插即用的连网方式，用户不再需要手动配置 IP 地址等信息。\nDHCP 配置的内容不仅是 IP 地址，还包括子网掩码、网关 IP 地址。\nDHCP 工作过程如下：\n客户端发送 Discover 报文，该报文的目的地址为 255.255.255.255:67，源地址为 0.0.0.0:68，被放入 UDP 中，该报文被广播到同一个子网的所有主机上。如果客户端和 DHCP 服务器不在同一个子网，就需要使用中继代理。 DHCP 服务器收到 Discover 报文之后，发送 Offer 报文给客户端，该报文包含了客户端所需要的信息。因为客户端可能收到多个 DHCP 服务器提供的信息，因此客户端需要进行选择。 如果客户端选择了某个 DHCP 服务器提供的信息，那么就发送 Request 报文给该 DHCP 服务器。 DHCP 服务器发送 Ack 报文，表示客户端此时可以使用提供给它的信息。 14、SSH协议 TELNET 用于登录到远程主机上，并且远程主机上的输出也会返回。\nTELNET 可以适应许多计算机和操作系统的差异，例如不同操作系统系统的换行符定义。\n15、SMTP协议 一个电子邮件系统由三部分组成：用户代理、邮件服务器以及邮件协议。\n邮件协议包含发送协议和读取协议，发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。\nSMTP 只能发送 ASCII 码，而互联网邮件扩充 MIME 可以发送二进制文件。MIME 并没有改动或者取代 SMTP，而是增加邮件主体的结构，定义了非 ASCII 码的编码规则。\nPOP3 的特点是只要用户从服务器上读取了邮件，就把该邮件删除。但最新版本的 POP3 可以不删除邮件。\nIMAP 协议中客户端和服务器上的邮件保持同步，如果不手动删除邮件，那么服务器上的邮件也不会被删除。IMAP 这种做法可以让用户随时随地去访问服务器上的邮件。\n16、Web页面请求过程 16.1. DHCP 配置主机信息 假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。 主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。 该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。 该数据报则被放置在 MAC 帧中，该帧具有目的地址 FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:FF，将广播到与交换机连接的所有设备。 连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。 该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。 主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。 16.2. ARP 解析 MAC 地址 主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。\n主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。\n该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。\n该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。\nDHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。\n主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址（FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。\n网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。\n16.3. DNS 解析域名 知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。\n网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。\n因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。\n到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。\n找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。\n16.4. HTTP 请求页面 有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。 在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。 HTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。 连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。 HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。 浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。 本文转载自：https://github.com/CyC2018/CS-Notes，用于个人复习。\n","date":"2021-04-22T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/typora/image-hosting-master/image-hosting-master/20210503/rocky-coast-5059912_1920.5upaeily96k0.jpg","permalink":"https://cuterwrite.top/p/interview-help/","title":"计算机基础知识点总结（操作系统+计算机网络）"},{"content":" Table of Contents generated with DocToc\n1、命令返回值 2、多数据库 3、命令大全 1、通用命令 keys pattern exists key del key type key 2、字符串类型 简介 set key value / get key incr key incrby key increment decr key decrby key decrement incrbyfloat key increment append key value strlen key mget key / mset key1 value1 \u0026hellip; 位操作 使用场景 3、hash类型 简介 hset key field value hget key field hmset key field value hmget key field hgetall key hexists key field hsetnx key field value hincrby key field increment hdel key field 其他命令 使用场景 4、list类型 简介 lpush key value1\u0026hellip; rpush key value1\u0026hellip; lpop key rpop key llen key lrange key start stop lrem key count value lindex key index lset key index value ltrim key start end linsert key before|after pivot value rpoplpush source destination 使用场景 5、set类型 简介 sadd key member srem key member smembers sismember key member sdiff key1 key2 \u0026hellip; sinter key1 key2\u0026hellip; sunion key1 key2\u0026hellip; scard key sdiffstore/sinterstore/sunionstore destination key1 key2\u0026hellip; srandmember key count spop 使用场景 6、zset类型 简介 zadd key score member zscore key member zrange key start stop [withscores] zrangebyscore key min max [withscores] limit offset count zrevrangebyscore key max min [withscores] limit offset count zincrby key increment member zcard key zcount key min max zrem key member1 \u0026hellip; zremrangebyranke key start stop zremrangebyscore key min max zrank key member zrevrank key member 1、命令返回值 状态回复 OK：成功 PONG：响应PING 错误回复：命令不存在或者命令格式有误 Error Unknown command 整数回复： INCR命令：返回递增后的键值 DBSIZE命令：返回键的数量 字符串回复： 请求键的值或者请求一个其他类型键中的某个元素 多行字符串回复： 请求非字符串类型键的元素列表 Keys (Pattern)：返回数据库中符合指定规则的键名 2、多数据库 一个Redis实例提供了多个用来存储数据的字典，客户端可以指定数据存储在哪个字典中。 数据库默认从0开始递增命名，默认支持16个数据库（DB0，DB1，\u0026hellip;，DB15） 不支持自定义数据库名字，也不支持单独设置访问密码 3、命令大全 1、通用命令 keys pattern 获得符合规则的键名列表，支持？、*、[]、\\x四种通配符\nkeys命令会遍历所有键，不建议在生产环境中使用 命令不区分大小写 exists key 如果键存在返回1，否则返回0 del key 删除一个或多个键，返回删除的键的个数 type key 获得键值的数据类型 2、字符串类型 简介 字符串类型是Redis中最基本的数据类型，它能存储任何形式的字符串，包括二进制数据，可以存储邮箱、JSON、或者一张图片，允许存储的最大容量是512MB set key value / get key 赋值与取值 incr key 递增数字，让当前键值递增，并返回递增后的值 如果key不存在时会默认键值为0 incrby key increment 增加指定的整数 decr key 同上 decrby key decrement 同上 incrbyfloat key increment 增加指定浮点数 append key value 尾部追加 strlen key 字符串长度 mget key / mset key1 value1 \u0026hellip; 同时获取/设置多个键值 位操作 getbit key offset setbit key offset value bitcount key bittop 使用场景 文章访问量统计：为每篇文章使用一个名为post:文h章ID:page.view的键来记录文章的访问量，每次访问文章的时候使用incr命令。（键命名建议：“对象类型：对象ID：对象属性”） 生成自增ID：对于每一类对象使用名为对象类型：count的键来存储当前类型对象的数量（如users:count），每次新增一个对象时都使用incr命令，返回值就是该新增对象的ID。 存储文章数据：JSON存储 3、hash类型 简介 散列类型适合存储对象：使用对象类别和ID构成键名，使用字段表示属性，字段值则存储属性值。一个键最多存2^32 - 1个元素 hset key field value hset car price 500 hget key field hget car price hmset key field value hmget key field hgetall key hexists key field hsetnx key field value 当字段不存在时赋值\n原子操作，线程安全\nhincrby key field increment hdel key field 其他命令 hkeys hvals hlen 使用场景 存储文章数据 存储文章缩略名：使用slug.to.id的键来存储文章缩略名和ID之间的映射关系。这样就可以用hexists判断缩略名是否存在，使用hget命令来获取缩略名对应的文章ID 4、list类型 简介 可以存储一个有序的字符串列表，常用操作是向列表两端添加元素 底层：双向链表，添加复杂度O（1） 适用场景：只关心最新的内容 一个键最多存2^32 - 1个元素 lpush key value1\u0026hellip; rpush key value1\u0026hellip; lpop key rpop key llen key lrange key start stop 获取列表片段（两边都是闭区间） 支持负索引（与python类似） 0，-1会返回所有元素 start \u0026gt; stop：返回空 stop \u0026gt; len：返回start,start + len lrem key count value 删除列表中前count个值为value的元素，返回值是实际删除的元素个数 count\u0026gt;0时，从列表左边开始删除 count\u0026lt;0时，从列表右边开始删除 count=0时，删除所有 lindex key index 索引取值，支持负数 lset key index value 索引赋值 ltrim key start end 删除指定索引外的全部值 linsert key before|after pivot value 首先查找pivot，然后插入其前面或后面 rpoplpush source destination 将一个元素转到另一个列表 使用场景 存储文章ID列表 存储评论列表 5、set类型 简介 无序、唯一 最多2^32 - 1个元素 常用操作：插入、删除、判断某个元素是否存在、交集、并集、差集 sadd key member srem key member smembers 返回所有元素 sismember key member 判断元素是否在集合中\nO（1）\nsdiff key1 key2 \u0026hellip; 求差集（ key1 - key2） sinter key1 key2\u0026hellip; 求交集 sunion key1 key2\u0026hellip; 求并集 scard key 获取元素个数 sdiffstore/sinterstore/sunionstore destination key1 key2\u0026hellip; 存储集合操作的结果 srandmember key count count\u0026gt;0时，获取不重复的随机count个元素 count\u0026lt;0时，获取可能重复的随机count个元素 spop 随机选择一个元素弹出 使用场景 存储文章标签 通过标签搜索文章 6、zset类型 简介 有序 唯一 可以获取某一范围的袁旭 底层：散列表和跳表，读取速度为O(logn) zadd key score member 支持整数、双精度浮点数，甚至-inf和+inf 可以修改score zscore key member zrange key start stop [withscores] 获得排名在某个范围的元素\n可以添加分数\n复杂度为O(logn + m)\nzrangebyscore key min max [withscores] limit offset count 获得指定分数范围的元素，两边是闭区间 支持inf 数字前添加左圆括号表示开区间 可以用limit限制返回的个数 zrevrangebyscore key max min [withscores] limit offset count 同上，改成降序 zincrby key increment member 增加某个元素的分数 zcard key 元素数量 zcount key min max 分数范围内个数 zrem key member1 \u0026hellip; zremrangebyranke key start stop 根据排名范围删除元素 zremrangebyscore key min max 根据分数范围删除元素 zrank key member 获取元素排名 zrevrank key member 降序排名 ","date":"2021-04-07T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/typora/image-hosting-master/image-hosting-master/20210503/groningen-5372387_1920.jhh1ofhqnjs.jpg","permalink":"https://cuterwrite.top/p/redis-1/","title":"Redis入门"},{"content":" Table of Contents generated with DocToc\nSpring Cloud alibaba笔记 SOA与微服务的区别： Spring Cloud Alibaba与Spring Cloud Netflix的对比 什么是Spring Boot？ IOC/DI（控制反转与依赖注入） Spring发展过程 自动装配的实现 手写实现一个Starter 1 Starter的功能 2 Starter的命名规范 3 实现基于Redis的Starter Apache Dubbo Zookeeper Dubbo集成Zookeeper 1 需要解决的问题 2 实现步骤 3 原理 4 实战Dubbo Spring Cloud Dubbo的高级应用 1 集群容错 2 负载均衡 3 服务降级 主机绑定规则 Dubbo源码分析 1 核心点 2 生成IDE工程的命令 3 SPI(Service Provider Interface) 4 Dubbo中的SPI思想 5 Dubbo中的SPI原理 6 自适应扩展点 7 Protocol自适应扩展点源码 8 IOC 9 AOP 10 Dubbo集成Spring机制（略） 什么是Nacos？ 1 关键特性 2 Nacos集群 搭建Nacos注册中心的注意点 Nacos实现原理 1 模块组成 2 注册中心的原理 3 Nacos源码（略） Nacos实现统一配置管理 1 Nacos集成Spring Boot 2 Nacos集成Spring Cloud 3 动态更新配置 4 基于DataID配置yaml的文件扩展名 5 不同环境的配置切换 6 自定义Namespace和Group Nacos Config实现原理（略） Spring Cloud加载配置的原理（略） Nacos源码（略） Sentinel限流及熔断 1 服务限流的作用及实现 2 服务熔断和降级 3 Sentinel的特性 4 Sentinel的组成： 5 Sentinel基本应用： 6 Sentinel资源保护规则 1 QPS流量控制行为 7 Sentinel实现服务熔断 Sentinel集成Spring Cloud 基于Sentinel Dashboard来实现流控配置 Sentinel自定义URL限流异常 Sentinel对URL资源清洗 Sentinel集成Nacos实现动态流控规则 Sentinel集成Nacos实现规则同步 1 Sentinel Dashboard源码修改： 2 Sentinel Dashboard规则同步 Sentinel集成Dubbo实现限流 * 1 Dubbo服务接入Sentinel Dashboard 2 Dubbo服务限流规则 Sentinel热点限流 1 热点参数限流的使用 2 @SentinelResource 3 热点参数规则说明 Sentinel的工作原理（略） Spring Cloud Sentinel工作原理（略） Sentinel核心源码分析（略） 1 限流的源码实现 2 实时指标数据统计 3 服务降级的实现原理 什么是分布式事务？ 1 分布式事务问题的理论模型 1 X/Open分布式模型 2 两阶段提交协议 3 三阶段提交协议 4 CAP定理和BASE理论 2 分布式事务问题的常见解决方案 1 TCC补偿性方案 2 基于可靠性消息的最终一致性方案 3 最大努力通知型 3 分布式事务框架Seata 1 AT模式 2 Saga模式 Spring Cloud alibaba笔记 SOA与微服务的区别： SOA关注的是服务的重用性及解决信息孤岛问题 微服务关注的是解耦，虽然解耦和可重用性从特定的角度来看是一样的，但本质上是有区别的，解耦是降低业务之间的耦合度，而重用性关注的是服务的复用。 微服务会更多地关注在DevOps的持续交付上，因为服务粒度细化之后使得开发运维变得更加重要，因此微服务与容器化技术的结合更加紧密。 Spring Cloud Alibaba与Spring Cloud Netflix的对比 Alibaba开源组件在没有织入Spring Cloud生态之前，已经在各大公司广泛应用，所以容易实现技术整合及迁移。 Alibaba开源组件在服务治理上和处理高并发的能力上有天然的优势。 什么是Spring Boot？ 帮助开发者快速构建一个基于Spring Framework及Spring生态体系的应用解决方案，也是对于“约定优于配置”理念的最佳实践。\nIOC/DI（控制反转与依赖注入） IOC：把对象的生命周期托管到Spring容器中，而反转是指对象的获取方式被反转了。 当使用IOC容器之后，客户端类不需要通过new来创建这些对象，而是直接从IOC容器中获得。早期的Spring中，主要通过XML的方式来定义Bean，Spring会解析XML文件，把定义的Bean转载到IOC容器中。 DI：IOC容器在运行期间，动态地把某种依赖关系注入组件中。 DI的三种方法：接口注入、构造方法注入、setter方法注入；目前是基于注解的形式：有@Autowired、@Inject和@Resource Spring发展过程 J2EE的EJB时代 Spring XML配置文件时代 JavaConfig的无配置化注入时代 Spring Boot时代：约定优于配置，核心为： Starter组件：开箱即用 自动装配：自动根据上下文完成Bean的装配 Actuator：应用监控 Spring Boot CLI：脚手架 自动装配的实现 实现原理：@EnableAutoConfiguration，这个注解的声明在启动类注解@SpringBootApplication内。进一步又涉及到@Enable注解（本质上是对@Configuration和@Bean的封装）；使用Enable注解后，Spring会解析到@Import导入的配置类，从而根据这个配置类中的描述来实现Bean的装配。\n例子：可以直接使用@Autowired来注入RedisTemplate实例。\nEnableAutoConfiguration的原理\n@Import：导入一个AutoConfigurationImportSelector类。\n@AutoConfigurationPackage：把使用了该注解的类所在的类所在的包及子包下所有组件扫描到Spring IoC容器中\nAutoConfigurationImportSelector：是ImportSelector的实现类，只有一个selectImports抽象方法，并且返回一个String数组，在这个数组中可以指定需要装配到IOC容器的类，当@Import中导入一个ImportSelectord的实现类后，会把该实现类中返回的Class名称都装载到IOC容器中。\nImportSelector与@Configuration的区别：前者可以实现批量装配，并且还可以通过逻辑处理来实现Bean的选择性装配，也就是根据上下文来决定哪些类能够被IOC容器初始化。\n自动装配原理总结：\n通过@Import(AutoConfigurationImportSelector)实现配置类的导入 AutoConfigurationImportSelector类实现了ImportSelector接口，重写了方法selectImports，用于实现选择性批量配置类的装配。 通过Spring提供的SpringFactoriesLoader机制，扫描classpath路径下的META-INF/spring.factories，读取需要实现自动装配的配置类。 通过条件筛选的方式，把不符合条件的配置类移除，最终完成自动装配。 @Conditional条件装配\n是Spring Framework提供的一个核心注解，这个注解的作用是提供自动装配的条件约束，一般与@Configuration和**@Bean**配合使用。\n简单来说，Spring在解析@Configuration配置类时，如果该配置类增加了@Conditional注解，那么就会根据该注解配置的条件来决定是否要实现Bean的装配。\n@Configuration public class ConditionConfig { @Bean @Conditional(GpCondition.class) public ThirdClass thirdClass() { return new ThirdClass(); } } 表示：如果GpCondition类中的matches返回true，则装载ThirdClass这个类。\n@Conditional在Spring Boot中的扩展\n常用装配注解：\n@ConditionalOnBean\n@ConditionalOnMissingBean\n@ConditionalOnResource\n@ConditionalOnProperties\nspring-autoconfigure-metadata\n用于实现批量自动装配条件配置，作用和@Conditional一致，只是把这些条件配置放在了配置文件中。\n两个条件：\n（1）配置文件的路径和名称必须是/META-INF/spring-autoconfigure-metadata.properties\n（2）配置文件中key的配置格式：自动配置类的类全路径名.条件=值\n好处：有效降低Spring Boot的启动时间，通过这种过滤方式可以减少配置类的加载数量，因为这个过滤发生在配置类的装载之前，所以它可以降低Spring Boot启动时装载Bean的耗时。\n手写实现一个Starter 1 Starter的功能 涉及相关组件的Jar包依赖 自动实现Bean的装配 自动声明并且加载application.properties文件中的属性配置。 2 Starter的命名规范 Starter的命名主要分为官方命名和自定义组件命名两类，这种命名格式不是强制性的，也是一种约定俗成的方式。\n官方命名格式：spring-boot-starter-模块名称 自定义命名格式：模块名称-spring-boot-starter 3 实现基于Redis的Starter 创建一个工程，命名为redis-spring-boot-starter 添加Jar包依赖 定义属性类，实现在application.properties中配置Redis的连接参数，使用@ConfigurationProperties，把当前类中的属性和配置文件中的配置进行绑定，并且规定前缀。 定义需要自动装配的配置类，主要就是把RedissonClient装配到IOC容器中。 Apache Dubbo 什么是Dubbo：一个分布式服务框架，主要实现多个系统之间的高性能、透明化调用，简单来说就是一个RPC框架，但是和普通的RPC框架不同，它提供了服务治理功能，比如服务注册、监控、路由、容错等。\n服务提供者开发流程：\n创建一个普通的Maven工程provider，并创建两个模块：api和provider，其中provider是一个Spring Boot工程 在api模块中定义接口，并且通过mvn install安装到本地仓库 在provider模块的pom文件中引入api和dubbo组件。 在provider中实现接口，并且使用@DubboService注解发布服务 在application.properties文件（或yml）中添加Dubbo服务的配置信息，包括application.name、protocal.name、protocol.port和registry.address 启动Spring Boot 服务调用者的开发流程：\n创建一个Spring Boot项目consumer，添加Jar包依赖（Dubbo和api） 在application.properties中配置dubbo.application.name 使用@DubboReference注解获取一个远程代理对象。 Zookeeper Zookeeper是一个高性能的分布式协调中间件，基于Java编写。\nZookeeper的数据结构：数据模型和分布式文件系统类似，是一种层次化的属性结构，区别是：Zookeeper的数据是结构化存储的，并没有在物理上体现出文件和目录。Zookeeper树中的每个节点被称为Znode，Znode维护了一个stat状态信息，其中包含数据变化的时间和版本等。并且每个Znode可以设置一个value值，Zookeeper并不用于通用的数据库或者大容量的对象存储，它只是管理和协调有关的数据，所以value的数据大小不建议设置得非常大，否则会带来更大的网络开销。Zookeeper上的每一个节点的数据都是允许读和写的，读表示指定获得Znode上的value数据，写表示修改Znode上的value数据。另外，节点的创建规则和文件系统中文件的创建规则类似，必须按照层次创建。例如：创建/node/node1/node1-1，先要创建/node/node1这两个层次节点。\nZookeeper的特性：Znode在被创建后，需要指定节点的类型，节点类型分为：\nWatcher机制：\nZnode的订阅/通知机制：当Znode节点状态发生变化时或者Zookeeper客户端连接状态发生变化时，会触发事件通知。这个机制在服务注册与发现中，针对服务调用者及时感知到服务提供者的变化提供了非常好的解决方案。\nZookeeper提供的Java API中，提供了三种机制来针对Znode进行注册监听，分别是：\n常用应用场景分析\n分布式锁：（1）多线程中Synchronized和Lock用于解决共享资源访问的数据安全性问题，但范围是线程级别的。（2）在分布式架构中，多个进程对同一个共享资源的访问，也存在数据安全性问题，因此也需要使用锁的形式来解决这类问题，而解决分布式环境下多进程对于共享资源访问带来的安全性问题的方案就是使用分布式锁。锁的本质是排他性，也就是避免同一时刻多个进程同时访问某一个共享资源。（3）如果使用Zookeeper实现分布式锁来达到排他性的目的，只需要用到节点的特性：临时节点，以及同级节点的唯一性。（4）具体实现：a.获得锁的过程：所有客户端可以去Zookeeper服务器上/Exclusive_Locks节点下创建一个临时节点/lock。Zookeeper基于同级节点的唯一性，会保证所有客户端中只有一个客户端能创建成功，创建成功的客户端获得了排它锁，没有获得锁的客户端就需要通过Watcher机制监听/Exclusive_Locks节点下子节点的变更事件，用于实时监听/lock节点的变化情况以作出反应。 b.释放锁的过程：①获得锁的客户端因为异常断开了和服务端的连接，临时节点会自动删除。②获得锁的客户端执行完业务逻辑后，主动删除创建的lock节点。 Master选举：分布式系统中的集群模式，某一机器宕机后，其他节点会接替故障节点继续工作。（1）Zookeeper有两种方式来实现Master选举的场景。假设集群中有3个节点，需要选举出Master，那么三个节点同时去Zookeeper服务器上创建一个临时节点/master-election，由于节点的唯一性，只会有一个客户端创建成功，创建成功就称为Master。同时，其他没有创建成功的客户端，针对该节点注册Watcher事件，监控master，一旦/master-election节点被删除，其他客户端重新发起master选举。（2）方法二：利用临时有序节点的特性来实现。所有参与选举的节点在/master节点下创建一个临时有序节点，编号最小的节点表示master，后续的节点监听上一个节点的删除事件，用于触发重新选举。 Dubbo集成Zookeeper 1 需要解决的问题 服务动态上下线感知：服务调用者要感知到服务提供者上下线的变化。 负载均衡 2 实现步骤 在provider模块中添加Zookeeper相关依赖 修改application.properties配置文件，修改dubbo的registry-addr为zookeeper服务器的地址，表示当前Dubbo服务需要注册到Zookeeper上。 consumer只需要修改application.properties，设置dubbo的registry-addr即可 3 原理 Dubbo服务注册到Zookeeper上之后，可以在Zookeeper服务器上看到图下所示的树形结构。\n其中URL是临时节点，其他皆为持久化节点，如果注册该节点的服务器下线了，那么这个服务器的URL地址就会被移除。\n当Dubbo服务消费者启动时，会对/providers下的子节点注册Watcher监听，这样就可以感知到服务提供方的上下线变化，从而防止请求发送到已经下线的服务器造成访问失败。同时，服务消费者会在/consumers下写入自己的URL，这样可以在监控平台上看到某个Dubbo服务正在被哪些服务调用。最重要的是，如果服务消费者需要调用一个服务，那么它会先去/providers路径下获得所有该服务的提供方URL列表，然后通过负载均衡算法计算出一个地址进行远程访问。\n此外，Dubbo还可以针对不同的情况实现以下功能：\n基于临时节点的特性，当服务器宕机或者下线时，注册中心会自动删除该服务提供者的信息。 注册中心重启时，Dubbo能自动恢复注册数据及订阅请求。 为了保证节点操作的安全性，Zookeeper提供了ACL权限控制，在Dubbo中可以通过register.username和password来设置节点的验证信息。 注册中心默认的根节点为/dubbo，如果需要针对不同环境设置不同的根节点，可以使用registry.group修改根节点名称。 4 实战Dubbo Spring Cloud 创建service-provider工程，创建两个子模块api和provider，前者为maven工程，后者为Spring Boot工程 在api中声明接口，并执行mvn install 在provider中添加api、Spring Boot、Spring Cloud和Spring Cloud Alibaba相关组件的依赖。（包括spring-cloud-starter、spring-cloud-starter-dubbo、api、discovery） 在父pom中显示声明dependencyManagement配置版本。 在provider中创建接口的实现类，并且声明@DubboService 在application.properties中配置Dubbo相关信息。 启动provider服务。 创建consumer，依赖与provider类似，同样在application.properties中配置Dubbo相关信息。注意：dubbo-cloud-subscribed-services表示服务调用者订阅的服务提供方的应用名称列表，如果有多个应用名称，可以通过\u0026quot;,\u0026ldquo;分开，默认值为“*” 使用@DubboReference消费服务，启动即可。 Dubbo的高级应用 1 集群容错 Dubbo默认提供6种容错模式，默认为Failover Cluster，此外可以根据实际需求自行扩展。\n配置方式：在@DubboService中增加参数cluster=\u0026ldquo;failfast\u0026quot;即可。 推荐：查询语句容错策略建议使用默认的Failover Cluster，而增删改操作建议使用Failfast Cluster或者使用Failover Cluster(retries=0)，防止出现数据重复添加等其他问题！建议在设计接口的时候把查询接口方法单独做成一个接口提供查询。 2 负载均衡 Dubbo提供了4种负载均衡策略，默认为random，也可以自行扩展（基于SPI机制）。\n3 服务降级 服务降级是一种系统保护策略，当服务器访问压力较大时，可以根据当前业务情况对不重要的服务进行降级，以保证核心业务的正常运行。所谓的降级，就是把一些非必要的功能在流量较大的时间段暂时关闭，比如在双十一大促时，淘宝会把查看历史订单、商品评论等功能关闭。\n降级的分类：\n是否自动化：人工降级、自动降级 功能划分：读服务降级和写服务降级 自动降级更多来自于系统出现某些异常时自动触发“兜底的流畅”，比如：\n故障降级：调用的远程服务挂了，网络故障或者RPC服务返回异常。这类情况在业务情况下可以通过设置兜底数据响应给客户端。 限流降级：为了保护系统不被压垮，在系统中会针对核心业务进行限流，当请求流量达到阈值时，后续的请求会被拦截。 Dubbo提供了一种Mock配置来实现服务降级，也就是当服务提供方出现网络异常无法访问时，客户端不抛出异常，步骤如下：\n在consumer中创建MockService，这个类只需要实现降级的接口即可，重写接口中的抽象方法实现本地数据的返回。 在@DubboReference中增加mock参数，制定MockService的位置。 在不启动Dubbo服务或者服务端的返回值超过默认的超时时间时，得到的数据就是MockService中的数据。 主机绑定规则 主机绑定表示的是Dubbo服务对外发布的IP地址，默认情况下Dubbo会按照以下顺序来查找并绑定主机IP地址。\n查找环境变量DUBBO_IP_TO_BIND属性配置的IP地址。\n查找dubbo.protocol.host属性的IP地址，默认是空，如果没有配置或者IP地址不合法则继续查找。\n通过LocalHost.getHostAddress获取本机IP地址，获取失败则继续。\n如果配置了注册中心的地址，则使用Socket通信连接到注册中心的地址后，使用for循环通过socket.getLocalAddress().getHostAddress()扫描各个网卡来获取网卡IP的地址。\n建议：通过dubbo.protocal.host设置主机地址，防止注册错误的IP地址，使服务消费者无法调用。\ndocker部署解决方案：使用\u0026ndash;net=host绑定网络，然后配置application.yml\n配置inetutils下的两个参数\nDubbo源码分析 1 核心点 SPI机制 自适应扩展点 IOC和AOP Dubbo如何与Spring集成。 2 生成IDE工程的命令 mvn idea:idea mvn eclipse:eclipse 3 SPI(Service Provider Interface) 自适应扩展点：AdaptiveExtension 指定名称扩展点：Extension(name) 激活扩展点：ActivateExtension(url,key) SPI是JDK内置的一种服务提供发现机制，主要用于服务的扩展实现。SPI机制在很多场景中都有运用，比如数据库连接，JDK提供了Driver接口，这个驱动类由不同的数据库厂商来实现，然后JDK利用SPI机制从classpath下找到相应的驱动来获得指定数据库的连接。这种插拔式的扩展加载方式，也同样遵循一定的协议约定，比如所有的扩展点必须要放在resources/META-INF/services目录下，SPI机制会默认扫描这个路径下的属性文件以完成加载。\n4 Dubbo中的SPI思想 Dubbo或者SpringFactoriesLoader并没有使用JDK内置的SPI机制，只是利用了SPI的思想。Dubbo SPI的相关逻辑被封装在了ExtensionLoader类中，通过ExtensionLoader我们可以加载指定的实现类。\nDubbo的SPI扩展有两个规则：\n和JDK内置的SPI一样，需要在resources目录下创建任一目录结构：META-INF/dubbo、META-INF/dubbp/internal、META-INF/services，在对应的目录下创建以接口全路径名命名的文件，Dubbo会去三个目录下加载相应扩展点。 文件内容和JDK内置的SPI不一样，内容是key-value形式的数据，key是一个字符串，value是一个对应扩展点的实现，这样的方式可以按照需要加载指定的实现类。 实现步骤如下：\n在一个依赖了Dubbo框架的工程中，创建一个扩展点及一个实现。其中，扩展点需要声明@SPI注解。 在resources/META-INF/dubbo目录下创建以SPI接口命名的文件 使用ExtensionLoader.getExtensionLoader.getExtension(key)获得指定名称的扩展点实现。 5 Dubbo中的SPI原理 （1）ExtensionLoader.getExtensionLoader：这个方法用于返回一个ExtensionLoader实例，逻辑如下：\n先从缓存中获取与扩展类对应的ExtensionLoader 缓存未命中，则创建一个新的实例，保存到eEXTENXION_LOADERS集合中缓存起来。 在ExtensionLoader构造方法中，初始化一个objectFactory （2）getExtension：这个方法用于根据指定名称获取对应的扩展点并返回。\nname用于参数的判断，如果name=\u0026ldquo;true\u0026rdquo;，则返回一个默认的扩展实现。 创建一个Holder对象，用户缓存该扩展点的实例。 如果缓存中不存在，则通过createExtension(name)创建一个扩展点。 （3）createExtension()：去指定的路径下查找name对应的扩展点的实现。\n通过getExtensionClasses().get(name)获取一个扩展类 通过反射实例化之后缓存到EXTENSION_INSTANCES集合中。 injectExtension实例依赖注入 把扩展类对象通过Wrapper进行包装。 （4）getExtensionClasses()\n从缓存中换取已经被加载的扩展类 如果缓存未命中，则调用loadExtensionClasses加载扩展类。 （5）loadExtensionClasses()\n通过cacheDefaultExtensionName方法获取当且扩展接口的默认扩展对象，并且缓存。 调用loadDirectory方法加载指定文件目录下的配置文件。 （6）cacheDefaultExtensionName()\n获得指定扩展接口的@SPI注解 得到@SPI注解中的名字，保存到cacheDefaultName属性中。 6 自适应扩展点 Adaptive Extension：能够根据上下文动态匹配一个扩展类，使用方式如下：\nExtensionLoader.getExtensionLoader(class).getAdaptiveExtension(); 自适应扩展点通过@Adaptive注解声明，有两种使用方式\n（1）@Adaptive注解定义在类上面，表示当前类为自适应扩展点。\n（2）@Adaptive注解定义上方法层面，会通过动态代理的方式生成一个动态字节码，进行自适应匹配。\n7 Protocol自适应扩展点源码 ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); 首先是getExtensionLoader：\n（1）从缓存中获取自适应扩展点实例。\n（2）如果缓存未命中，则通过createAdaptiveExtension创建自适应扩展点。\n然后是createAdaptiveExtension：\n（1）getAdaptiveExtensionClass：获取一个自适应扩展类的实例。\n（2）injectExtension完成依赖注入。\n接着是getAdaptiveExtensionClass：\n（1）通过getExtensionClasses方法加载当前传入类型的所有扩展点，缓存在一个集合中。\n（2）如果cachedAdaptiveClass为空，则调用createAdaptiveExtensionClass进行创建。\n8 IOC 上文中的injectExtension就是依赖注入的实现，整体逻辑为：\n（1）遍历被加载的扩展类中的所有set方法。\n（2）得到set方法中的参数类型，如果参数类型是对象类型，则获得这个set方法中的属性名称。\n（3）使用自适应扩展点加载该属性名称对应的扩展类。\n（4）调用set完成赋值。\n简单来说，injectExtension方法的主要功能是，如果当前加载的扩展类中存在一个成员对象，并且为它提供了set方法，那么就会通过自适应扩展点进行加载并赋值。\n9 AOP 面向切面编程，意图是把业务逻辑和功能逻辑分离，然后在运行期间或者类加载期间进行织入，可以降低代码的复杂性，以及提高重用性。\ninstance = injectExtension((T)WrapperClass.getConstructor(type).newInstance(instance)); 这段代码分别用到了依赖注入和AOP，AOP体现在基于Wrapper装饰器类实现对原有的扩展类instance进行包装。\n10 Dubbo集成Spring机制（略） p89\n什么是Nacos？ Nacos致力于解决微服务中的统一配置、服务注册与发现等问题。它提供了一组简单易用的特性集，帮助开发者快速实现动态服务发现、服务配置、服务元数据以及流量管理。\n1 关键特性 服务发现和服务健康监测\nNacos基于DNS和基于RPC的服务发现。服务提供者通过原生SDK、OpenAPI或一个独立的Agent TODO注册Service后，服务消费者可以使用DNS或HTTP\u0026amp;API查找和发现服务。\nNacos提供对服务的实时的健康检查，阻止向不健康的主机或服务实例发送请求。Nacos支持传输层（PING或TCP）和应用层（如HTTP、MYSQL、用户自定义）的健康检查。对于复杂的云环境和网络拓扑环境（如VPC、边缘网络等）服务的健康检查，Nacos提供了agent上报和服务端主动监测两种健康检查模式。Nacos还提供了统一的健康检查仪表盘。\n动态配置服务\n业务服务一般都会维护一个本地配置文件，然后把一些常量配置到这个文件中。这种方式在某些场景会存在某些问题，比如配置变更时需要重新部署应用。而动态配置服务可以以中心化、外部化和动态化的方式管理所有环境的应用配置和服务配置。\n动态DNS服务\n支持权重路由，让开发者更容易实现中间层负载均衡、更灵活的路由策略、流量控制，以及数据中心内网的简单DNS服务。\n服务及其元数据管理\n2 Nacos集群 包含一个Leader节点和多个Follower节点。\n数据一致性算法采用的Raft（Etcd、Redis哨兵选举也是这个算法）\n3个或3个以上Nacos节点才能构成集群。\n搭建Nacos注册中心的注意点 dubbo.scan.base-packages功能等同于@DubboComponentScan dubbo.registry.address：Dubbo服务注册中心的配置地址，它的值spring-cloud://url表示挂载到Spring Cloud注册中心，不配置的话会提示没有配置注册中心的错误。 spring.cloud.nacos.discovery.server-addr：Nacos服务注册中心的地址。 Nacos实现原理 1 模块组成 Provider App Consumer App Name Server Nacos Server Nacos Console 整体来说，服务提供者通过Virtual IP访问Nacos Server高可用集群，基于Open API完成服务的注册和服务的查询。Nacos Server本身可以支持主备模式，所以底层会采用数据一致性算法来完成主从节点的整体同步。服务消费者也是如此。\n2 注册中心的原理 服务注册的功能主要体现在：\n服务实例在启动时注册到服务注册表，并在关闭时注销。（Open API） 服务消费者查询服务注册表，获得可用实例。 服务注册中心需要调用服务实例的健康检查API来验证它是否能够处理请求。（心跳机制） 3 Nacos源码（略） 服务注册 服务地址的获取 服务地址变化的感知 Nacos实现统一配置管理 各个应用自己独立维护本地配置方式的不足：\n1 Nacos集成Spring Boot 在application.properties中配置nacos.config.server-addr 创建NacosConfigController，用于从Nacos Server动态读取配置。 @NacosPropertiesSource：用于加载dataId为example的配置源，autoRefreshed表示开启自动更新。 @NacosValue：设置属性的值，其中info表示key，而Local Hello World表示默认值。也就是说如果key不存在，则使用默认值。这是一种高可用的策略。 2 Nacos集成Spring Cloud spring.cloud.nacos.config.prefix表示Nacos配置中心上的DataID的前缀。 spring.cloud.nacos.config.server-addr表示Nacos配置中心的地址。 在Nacos Console创建配置 在启动类中，读取配置中心的数据。 注意坑：配置文件必须用bootstrap.yml这个名称，因为bootstrap加载顺序优于application，因为需要在bootstrap配置文件中添加连接到配置中心的配置属性来加载外部配置中心的配置信息。 3 动态更新配置 通过一个while循环不断读取info属性，当info属性发生变化时，控制台可以监听到。\n4 基于DataID配置yaml的文件扩展名 DataID默认规则是${prefix}-${spring.profile.active}.${file-extension}\n在默认情况下，会去Nacos服务器上加载DataID以${spring.application.name}.${file-extension:properties}为前缀的基础配置。例如：在不通过spring.cloud.nacos.config.prefix指定DataID时，会默认读取DataID为nacos-config-demo.properties的配置信息。 如果明确指定了spring.cloud.nacos.config.prefix，则会加载DataID为指定值的配置。 spring.profile.active表示多环境支持。 在实际应用中，如果使用YAML格式配置，则需要声明spring.cloud.nacos.config.file-extension=yaml\n5 不同环境的配置切换 Spring Boot多环境支持配置步骤如下：\n在resource目录下根据不同环境创建不同的配置： application-dev.properties application-test.properties application-prod.properties 定义一个application.properties默认配置，在该配置中通过spring.profile.active=${env}来指定使用哪个环境的配置，如果${env}的值为prod，表示使用prod环境。 也可以通过设置 VM Options=-Dspring.profiles.active=prod来指定。 Nacos Config配置步骤如下：\n在bootstrap.properties中声明spring.profiles.active=prod 在Nacos控制台新增DataID为nacos-config-demo-prod.properties的配置项。 6 自定义Namespace和Group Namespace：解决多环境及多租户数据的隔离问题。 使用：在bootstrap.properties里指定spring.cloud.nacos.config.namespace Group：用于分组管理Data ID 使用：在bootstrap.properties里指定spring.cloud.nacos.config.group Nacos Config实现原理（略） 获取配置 监听配置 发布配置 删除配置 分为两类：配置的CRUD和配置的动态监听\nSpring Cloud加载配置的原理（略） Nacos源码（略） Sentinel限流及熔断 1 服务限流的作用及实现 主要作用：损失一部分用户的可用性，为大部分用户提供稳定可靠的服务。\n计算器算法：在制定周期内累加访问次数，当访问次数达到阈值时，触发限流策略。\n滑动窗口算法：源于TCP拥塞控制，原理是在固定窗口中分割出多个小时间窗口，分别在每个小时间窗口中记录访问次数，然后根据时间将窗口往前滑动并删除过期的小时间窗口。最终只需要统计滑动窗口范围内所有小时间窗口总的计数即可。（Sentinel的原理）\n令牌桶算法：每一个请求，都需要从令牌桶中获取一个令牌，如果没有获得令牌，则触发限流策略。\n特性：短时间内新增的流量系统能够正常处理。\n漏桶限流算法：用于控制数据注入网络的速度，平滑网络上的突发流量。\n2 服务熔断和降级 在微服务架构中，由于服务拆分粒度较细，会出现请求链路较长的情况，用户发起一个请求操作，需要调用多个微服务才能完成。\n雪崩效应：某个服务因为网络延迟或者请求超时等原因不可用时，就会导致当前请求阻塞，一旦某个链路上被依赖的服务不可用，很可能出现请求堆积而产生雪崩。\n所以，服务熔断就是用来解决这个问题的方案，它指的是当某个服务提供者无法正常为服务调用者提供服务时，为了防止整个系统出现雪崩效应，暂时将出现故障的接口隔离出来，断绝与外部接口的联系，当触发熔断后，后续一段时间内该服务调用者的请求都会直接失败，直至目标服务恢复正常。\n3 Sentinel的特性 丰富的应用场景：秒杀、消息削峰填谷、集群流量控制等。 实时监控 开源生态支持 SPI扩展点支持 4 Sentinel的组成： 核心库（Java客户端）：不依赖任何框架与库，能够运行于所有Java运行时环境。 控制台（Dashboard） 5 Sentinel基本应用： 步骤如下：\n（1）定义资源：限流保护的最基本元素，比如一个方法。\n（2）定义限流规则\n（3）检验规则是否生效\n限流规则：通过initFlowRules方法设置\ngrade：限流阈值类型，有QPS模式和并发线程数模式。 count：限流阈值 resource：设置需要保护的资源 6 Sentinel资源保护规则 Sentinel支持多种保护规则：流量控制规则、熔断降级规则、系统保护规则、来源访问控制规则、热点参数规则。\n限流规则：先通过FlowRules来定义限流规则，然后通过FlowRuleManager.loadRules来加载规则列表。 1 QPS流量控制行为 通过controlBehavior设置，包含：\n直接拒接 Warm UP，冷启动 匀速排队 冷启动 + 匀速排队 7 Sentinel实现服务熔断 通过DegradeRule实现：\ngrade：熔断策略，支持秒级RT、秒级异常比例、分钟异常数。默认是秒级RT。 timeWindow：熔断降级的时间窗口，单位为s。也就是出发熔断降级之后多长时间内自动熔断。 rtSlowRequestAmount：在RT模式下，1s内持续多少个请求的平均RT超出阈值后出发熔断，默认值是5 minRequestAmout：触发的异常熔断最小请求数，请求数小于该值时即使异常比例超出阈值也不会触发熔断，默认值是5. 三种熔断策略：\n平均响应时间RT：如果1s内持续进来5个请求，对应的平均响应时间都超过了阈值(count，单位为ms)，那么在接下来的时间窗口内，对这个方法的调用都会自动熔断，抛出DegradeException 异常比例 最近一分钟异常数：如果timeWindow小于60s，则结束熔断状态后仍然可能再进入熔断状态。 Sentinel集成Spring Cloud 步骤如下：\n创建项目，集成Spring Cloud依赖。\n添加Sentinel依赖。\n创建一个REST接口，并且通过@SentinelResource配置限流保护资源。\n在上述代码中，配置限流资源有几种情况\nSentinel starter在默认情况下会为所有的HTTP服务提供限流埋点，所以如果只想对HTTP服务进行限流，只需添加依赖即可。 如果想要对特定的方法进行限流或降级，则需要通过@SentinelResource注解来定义资源。 可以通过SphU.entry()方法来配置资源。 手动配置流控规则，可以借助Sentinel的InitFunc SPI扩展接口来实现，只需要实现自己的InitFunc接口，并在init方法中编写规则加载的逻辑即可。\n基于Sentinel Dashboard来实现流控配置 步骤如下：\n启动Sentinel Dashboard\n在application.yml中增加以下配置\n提供一个REST接口\n进入Sentinel Dashboard中配置流控规则。\n访问簇点链路，找到资源名称。\n单机流控按钮设置流控规则\n注意sentinel的坑：\nSentinel自定义URL限流异常 默认情况下，URL触发限流后会返回Blocked by Sentinel字符串\n在实际应用中，大都采用JSON格式，所以如果希望修改触发限流之后的返回结果形式，则可以通过自定义限流异常来处理，实现UrlBlockHandler并且重写blocked方法。\n还有一种场景，当触发限流后，希望跳转到一个降级页面，可以通过下面这个配置来实现。\nspring.cloud.sentinel.servlet.block-page={url}\nSentinel对URL资源清洗 Sentinel中HTTP服务的限流默认由Sentinel-Web-Servlet包中的CommonFilter来实现，这个Filter会把每个不同的URL都作为不同的资源来处理。\n举例：\n限流统计不准确，实际需求是控制clean方法总的QPS，结果统计的是每个URL的QPS 导致Sentinel中资源数量过多，默认资源数量阈值为6000，对于多出的资源规则将不会生效。 针对这个问题可以通过URLCleaner接口来实现资源清洗，也就是对于/clean/{id}这个URL，我们可以统一归集到/clean/*资源下，具体代码如下：\nSentinel集成Nacos实现动态流控规则 Sentinel的理念是只需要开发者关注资源的定义，默认会对资源进行流控。当然我们还需要自定义流控规则，前面有两种方式：\n通过FlowRuleManager.loadRules(List rules)手动加载流控规则 在Sentinel Dashboard上针对资源动态创建流控规则。 针对第一种方式，如果接入Sentinel Dashboard，那么同样支持动态修改流控规则。但是，这里会存在一个问题，基于Sentinel Dashboard所配置的流控规则，都是保存在内存中的，一旦应用重启，这些规则都会被清除。为了解决这个问题，Sentinel提供了动态数据源支持。\n目前，Sentinel支持Consul、Zookeeper、Redis、Nacos、Apollo、etcd等数据源的扩展，我们使用Nacos的方式来扩展。\n步骤如下：\n添加Nacos数据源依赖包\n创建一个REST接口用于测试。\n在application.yml中添加数据源配置。\n配置说明：\nrule-type：flow、degrade、param-flow、gw-flow等\ndata-type：Spring Cloud Alibaba提供了JSON和XML两种格式。如果需要自定义，则可以将值配置为custom，并配置converter-class指向converter类。\n登录Nacos控制台，创建流控配置规则，配置信息如下：\n最后，登录Sentinel Dashboard，找到执行项目名称菜单下的“流控规则”，就可以看到在Nacos上所配置的流控规则已经被加载了。\n当在Nacos控制台修改流控规则后，可以同步在Sentinel Dashboard上看到流控规则的变化。\n注意：在Sentinel Dashboard上修改无法同步到Nacos上。 强烈建议：不要在Nacos上修改流控规则，因为这种修改的危险系数很高。这就意味着流控规则的管理应该集中在Sentinel Dashboard上，所以我们需要实现Sentinel Dashboard来动态维护规则并同步到Nacos上，目前官方还没有提供支持，但可以自己实现。\n这里有一个坑：出现了空指针异常org.springframework.beans.factory.BeanCreationException: Error creating bean with name \u0026lsquo;ds1-sentinel-nacos-datasource\u0026rsquo;: FactoryBean threw exception on object creation; nested exception is java.lang.NullPointerException，出现原因是Spring-Cloud-Alibaba与Sentinel的版本对应不上，解决办法是把Spring Cloud Alibaba的版本升到2.2.5.RELEASE即可。\nSentinel集成Nacos实现规则同步 Sentinel Dashboard的“流控规则”下的所有操作，都会调用Sentinel源码中的FlowControllerV1类，这个类包含流控规则本地化的CRUD\n另外，在com.alibaba.csp.sentinel.dashboard.controller.v2包下存在一个FlowControllerV2类，这个类同样提供流控规则的CRUD，和V1版本不同的是，它可以实现指定数据源的规则拉取和同步。\nFlowControllerV2依赖以下两个非常重要的类\nDynamicRuleProvider：动态规则的拉取，从指定数据源中获取流控规则后在Sentinel Dashboard中展示。 DynamicRulePublisher：动态规则的发布，将在Sentinel Dashboard中修改的规则同步到指定数据源中。 这里我们扩展这两个类，然后集成Nacos来实现Sentinel Dashboard规则的同步。\n1 Sentinel Dashboard源码修改： 具体步骤如下：\n打开sentinel-dashboard工程，在pom.xml中把sentinel-datasource-nacos依赖的scope注释掉。\n修改resouces/app/scripts/directives/sidebar/sidebar.html文件下的代码，将dashboard.flowV1改成dashboard.flow\n修改之后，会调用FlowControllerV2中的接口。\n在com.alibaba.csp.sentinel.dashboard.rule包中创建一个nacos包，并创建一个类用来加载外部化配置。\n创建一个Nacos配置类NacosConfiguration\n注入Converter转换器，将FlowRuleEntity转化为FlowRule，以及反向转化。 注入Nacos配置服务ConfigService 创建一个常量类NacosConstants，分别表示默认的GROUP_ID和DATA_ID的后缀。\n实现动态从Nacos配置中心获取流控规则。\n创建一个流控规则发布类，在Sentinel Dashboard上修改完配置后，需要调用该发布方法将数据持久化到Nacos中。\n修改FlowControllerV2类，将上面配置的两个类注入进来，表示规则的拉取和规则的发布统一用我们前面自定义的两个实例。\n在application.properties文件中添加nacos服务端的配置信息。\n将代码打包成一个fat jar\n详见https://blog.csdn.net/weixin_42073629/article/details/107117433 或者test包中的nacos代码\n2 Sentinel Dashboard规则同步 应用程序需要修改的地方比较少，只需注意配置文件中data-id的命名要以-sentinel-flow结尾即可。\nSentinel集成Dubbo实现限流 Sentinel提供了与Dubbo整合的模块Sentinel Apache Dubbo Adapter，可以针对服务提供者和服务消费者进行流控，在使用的时候，只需要添加以下依赖。\n添加后该依赖后，Dubbo服务中的接口和方法（包括服务端和消费端）就会成为Sentinel中的资源，只需针对指定资源配置流控规则就可以实现Sentinel流控功能。\nSentinel Apache Dubbo Adapter实现限流的核心原理是基于Dubbo的SPI机制实现Filter扩展，Dubbo的Filter机制是专门为服务提供者和服务消费者调用过程进行拦截设计的，每次执行远程方法，该拦截都会被执行。\n同时，Sentinel Apache Dubbo Adapter还可以自定义开启或者关闭某个Filter的功能，下面表示关闭消费端的过滤器。\n1 Dubbo服务接入Sentinel Dashboard 引入sentinel-transport-simple-http依赖\n添加启动参数\n登录Sentinel Dashboard之后，进入“簇点链路”，就可以看到资源信息。\n需要注意的是，限流可以通过服务接口或服务方法设置\n服务接口：resourceName为接口的全限定名（包+接口名） 服务方法：resourceName为接口全限定名：方法名（包+接口名:方法名） 2 Dubbo服务限流规则 两种方式\nSentinel Dashboard FlowRuleManager.loadRules(List rules) Sentinel Apache Dubbo Adapter组件中没有实现规则持久化，因此有以下步骤来支持：\n在dubbo服务中添加sentinel-datasource-nacos依赖 通过Sentinel提供的InitFunc扩展点，实现Nacos数据源的配置 访问Sentinel Dashboard，在针对某个资源创建流控规则时，这个规则会同步保存到Nacos的配置中心，而当Nacos配置中心发生变化时，会触发事件机制通知Dubbo应用重新加载流控规则。 Sentinel热点限流 热点数据表示经常访问的数据，在有限场景中我们希望针对这些访问频次非常高的数据进行限流，比如针对一段时间内频繁访问的用户ID地址进行限流，或者针对频繁访问的某个用户ID进行限流。\nSentinel提供了热点参数限流的规则，它是一种特殊的限流，在普通限流的基础上对同一个受保护的资源区根据请求中的参数分别处理，该策略只对包含热点参数的资源调用生效。热点限流在以下场景使用较多：\n服务网关层：例如防止网络爬虫和恶意攻击，一种常用方法就是限制爬虫的IP地址。 写数据的服务：例如业务系统提供写数据的服务，数据会写入数据库之类的存储系统。存储系统的底层会加锁写磁盘上的文件，部分存储系统会将某一类数据写入同一个文件中。如果底层写同一文件，会出现抢占锁的情况，导致出现大量超时和失败。出现这种情况时一般有两种解决方法：修改存储设计、对热点参数限流。 Sentinel通过LRU策略结合滑动窗口机制来实现热点参数的统计，其中LRU策略可以统计单位时间内最常访问的热点数据，滑动窗口机制可以协助统计每个参数的QPS。\n1 热点参数限流的使用 引用热点参数限流依赖包sentinel-parameter-flow-control 接下来创建一个REST接口，并定义限流埋点，此处针对参数ID配置热点限流规则。 针对不同的热点参数，需要通过SphU.entry(resourceName,EntryType.IN,1,id)方法设置，其最后一个参数是一个数组，有多个热点参数就按照次序依次传入，该配置表示后续会针对该参数进行热点限流。 通过ParamFlowRuleManager.loadRules加载热点参数规则。 2 @SentinelResource 如果是通过@SentinelResource注解来定义资源，当注解所配置得方法上有参数时，Sentinel会把这些参数传入SphU.entry中\n3 热点参数规则说明 durationInSec：统计窗口时间长度，单位为s maxQueueingTimeMS：最长排队等待时长，只有当流控为controlBehavior设置为匀速排队模式时生效。 paramIdx：热点参数的索引，属于必填项，对应的是SphU.entry中的参数索引位置。 paramFlowItemList：针对指定参数值单独设置限流阈值，不受count阈值的限制。 Sentinel的工作原理（略） 工作流程：由各个Slot插槽组成（责任链模式） p229 Spring Cloud Sentinel工作原理（略） starter自动装配 p232 Sentinel核心源码分析（略） sentinel-adapter sentinel-core sentinel-dashboard sentinel-demo sentinel-extension sentinel-transport 1 限流的源码实现 2 实时指标数据统计 3 服务降级的实现原理 什么是分布式事务？ 事务：作为单个逻辑工作单元执行的多个数据库操作，要么同时成功，要么同时失败，必须满足ACID特性。（单库多表）\n在微服务架构下，随着业务服务的拆分及数据库的拆分，举例说，订单和库存分别拆分成两个独立的数据库，当客户端发起一个下单操作，需要在订单服务对应的数据库创建订单，同时基于RPC通信调用库存服务完成商品库存的扣减。\n这样，原来的单库事务操作就变成了多个数据库的事务操作 =\u0026gt; 数据不一致问题。\n1 分布式事务问题的理论模型 核心原因：存储资源的分布性\n在实际应用中，应该尽可能从设计层面去避免分布式事务的问题。\n1 X/Open分布式模型 X/Open DTP是X/Open这个组织定义的一套分布式事务的标准。这个标准提出了两阶段提交（2PC，2-phase-commit）来保证分布式事务的完整性。X/Open DTP包含以下三种角色。\nAP：Application RM：Resource Manager TM：Transaction Manager 如果TM需要能够管理多个数据库的事务，则实现步骤如下：\n配置TM，把多个RM注册到TM，相当于TM注册RM作为数据源。 AP从TM管理的RM中获取连接，如果RM是数据库则获取JDBC连接。 AP向TM发起一个全局事务，生成全局事务ID（XID），XID会通知各个RM。 AP通过第二步获得的连接直接操作RM完成数据库操作。这时，AP在每次操作会把XID传递给RM。 AP结束全局事务，TM会通知各个RM全局事务结束。 根据各个RM的事务执行结果，执行提交或者回滚操作。 其中，TM和多个RM之间的事务控制，是基于XA协议来完成的。目前Oracle、MySQL、DB2都实现了XA接口，因此都能作为RM。\n2 两阶段提交协议 第一阶段：事务的准备阶段\n第二阶段：事务的提交或回滚阶段\n这两个阶段都是由事务管理器发起的，流程如下：\n准备阶段：TM通知RM准备分支事务，记录事务日志，并告知TM的准备结果。 提交/回滚阶段：如果所有的RM在准备阶段都明确返回成功，TM向所有RM发起提交指令完成数据的变更；反之，则TM向所有RM发送回滚指令。 然而，它并不是完美的，也有缺点：\n同步阻塞：所有RM都是事务阻塞型的，对于任何一次指令都必须要有明确的响应才能进行下一步，否则会处于阻塞状态。 过于保守：任何一个节点失败都会导致数据回滚。 TM的单点故障：如果TM在第二阶段故障，则所有RM会一直处于锁定状态。 “脑裂”导致数据不一致问题：在第二阶段中，TM向所有RM发送commit请求后，发生局部网络异常导致只有一部分RM接受到commit，剩余未收到请求的则没提交，导致数据出现不一致问题。 3 三阶段提交协议 利用超时机制解决了同步阻塞的问题\nCanCommit（询问阶段）：TM向RM发送事务执行请求，询问是否可以完成指令，参与者只需回答是或者不是即可，不需要做真正的事务操作，这个阶段会有超时中止机制。 PreCommit（准备阶段）：TM根据RM的反馈结果决定是否继续，如果在询问阶段所有RM都能执行操作，则TM向所有RM发送PreCommit请求，RM收到请求后写redo和undo日志，执行事务操作但是不提交事务，然后返回ACK响应等待TM的下一步通知。如果询问阶段任意参与者返回不能执行操作的结果，则TM发送事务中断请求。 DoCommit（提交或回滚阶段）：根据上一步骤的执行结果，如果每个RM都返回成功，则TM发送事务提交指令，反之则中止。 三阶段提交协议与二阶段提交协议的区别\n增加了一个CanCommit阶段，可以尽早发现无法执行操作而中止后续的行为。 在准备阶段之后，TM和RM都引入超时机制，一旦超时，TM和RM会继续提交事务，并且认为处于成功状态，因为这种情况下事务默认为成功的可能性比较大。 实际上，一旦超时，在三阶段提交协议下仍然可能出现数据不一致的问题，当然概率是比较小的。另外，最大的好处是基于超时机制来避免资源的永久锁定。\n4 CAP定理和BASE理论 XA协议：二阶段提交和三阶段提交，数据一致性强，但可用性低。\nCAP定理：布鲁尔定理，指在分布式系统中不可能同时满足一致性C、可用性A、分区容错性P，最多同时满足两个。\nC：数据在多个副本中要保持强一致 A：系统对外提供的服务必须一直处于可用状态。 P：在分布式系统中遇到任何网络分区故障，系统仍然能够正常对外提供服务。 在分布式系统中，要么满足CP，要么满足AP，不可能实现CAP或者CA，因为网络通信不是绝对可靠的。\nAP：放弃强一致性，实现最终的一致。（很多互联网公司的主要选择） CP：放弃高可用性，实现强一致性。（2PC和3PC，存在问题：用户完成一个操作可能会等待较长的时间，用户体验差） BASE理论：由于CAP中CA不可兼得衍生出来的一种新的思想。核心思想是：牺牲数据的强一致性来获得高可用性，有三个特性：\nBasically Avaliable（基本可用）：分布式系统出现故障时，允许损失一部分功能的可用性，保证核心功能的可用。 Soft State（软状态）：允许系统中的数据存在中间状态，这个状态不影响系统的可用性，也就是允许系统中不同节点的数据副本之间的同步存在延时。 Eventually Consistent（最终一致性）：中间状态的数据在经过一段时间之后，会达到一个最终的数据一致性。 2 分布式事务问题的常见解决方案 1 TCC补偿性方案 TCC（Try-Confirm-Cancel）是一种比较成熟的分布式数据一致性解决方案，它实际上是把一个完整的业务拆分为如下三个步骤\nTry：这个阶段主要是对数据的校验或者资源的预留。 Confirm：确定真正执行的任务，只操作Try阶段预留的资源。 Cancel：取消执行，释放Try阶段预留的资源。 本质：二阶段提交的思想，第一阶段通过Try准备，第二阶段通过Confirm/Cancel\n2 基于可靠性消息的最终一致性方案 基于可靠性消息的最终一致性方案是互联网公司比较常用的分布式数据一致性解决方案，它主要利用消息中间件（Kafka、RocketMQ或RabbitMQ）的可靠性机制来实现数据一致性的投递。\n总结：消费者没有向消息中间件服务器发送确认之前，这个消息会被重复投递，确保消息的可靠性消费。\n3 最大努力通知型 与基于可靠性消息的最终一致性方案实现类似，是一种比较简单的柔性事务解决方案。\n如果没有返回一个消息确认时，则不断进行重试，直到收到一个消息确认或者达到最大重试次数。\n3 分布式事务框架Seata 提供了AT、TCC、Saga和XA四种事务模式。\n1 AT模式 Seata最主推的分布式事务解决方案，基于XA演进而来，分为TM、RM和TC，TC作为Seata的服务器独立部署。\n2 Saga模式 又称长事务解决方案，主要描述的是在没有2PC的情况下如何解决分布式事务问题。其核心思想是：把一个业务流程中的长事务拆分为多个本地短事务，业务流程中的每个参与者都提交真实提交给本地段事务，当其中一个参与者失败，则通过补偿机制补偿前面已经成功的参与者。\n两种补偿恢复方式：\n向后恢复：如果任一子事务失败，则撤销执行结果。 向前恢复：不进行补偿，而是对失败的事务进行redo，这种方式比较适合于事务必须要执行成功的场景。 优点：\n一阶段直接提交本地事务 没有锁等待，性能较高 在事件驱动的模式下，短事务可以异步执行。 补偿机制的实现比较简单。 缺点：不提供原子性和隔离性支持\n协调模式：\n事件/编排式 命令/协同式 ","date":"2021-04-07T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/typora/image-hosting-master/image-hosting-master/20210503/dolomites-5076492_1920.5srkr3iefto0.jpg","permalink":"https://cuterwrite.top/p/spring-cloud-alibaba-1/","title":"Spring Cloud Alibaba笔记"}]