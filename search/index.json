[{"content":"RDMA 之 Memory Region 本文欢迎非商业转载，转载请注明出处。\n声明：仅用于收藏，便于阅读\n― Savir, 知乎专栏：6. RDMA 之 Memory Region 我们假设一种场景，同时也顺便温习一下 RDMA WRITE 操作的流程：\n如下图所示，A 节点想要通过 IB 协议向 B 节点的内存中写入一段数据，上层应用给本节点的 RDMA 网卡下发了一个 WQE，WQE 中包含了源内存地址、目的内存地址、数据长度和秘钥等信息，然后硬件会从内存中取出数据，组包发送到对端网卡。B 节点的网卡收到数据后，解析到其中的目的内存地址，把数据写入到本节点的内存中。\n那么问题来了，APP 提供的地址都是虚拟地址（Virtual Address，下文称 VA），经过 MMU 的转换才能得到真实的物理地址（Physical Address，下文称 PA），我们的RDMA 网卡是如何得到 PA 从而去内存中拿到数据的呢？就算网卡知道上哪去取数据，如果用户恶意指定了一个非法的 VA，那网卡岂不是有可能被“指使”去读写关键内存？\n为了解决上面的问题，IB 协议提出了 MR 的概念。\nMR 是什么 MR 全称为 Memory Region，指的是由 RDMA 软件层在内存中规划出的一片区域，用于存放收发的数据。IB 协议中，用户在申请完用于存放数据的内存区域之后，都需要通过调用 IB 框架提供的 API 注册 MR，才能让 RDMA 网卡访问这片内存区域。由下图可以看到，MR 就是一片特殊的内存而已：\n在对 IB 协议进行相关描述时，我们通常称 RDMA 硬件为HCA（Host Channel Adapter， 宿主通道适配器），IB 协议中对其的定义是“处理器和 I/O 单元中能够产生和消耗数据包的 IB 设备”，为了与协议保持一致，我们在包括本文及之后的文章中都称硬件部分为 HCA。\n为什么要注册 MR 下面我们来看一下 MR 是如何解决本文开篇提出的两个问题的：\n1. 注册 MR 以实现虚拟地址与物理地址转换 我们都知道 APP 只能看到虚拟地址，而且会在 WQE 中直接把 VA 传递给 HCA（既包括本端的源 VA，也包括对端的目的 VA）。现在的 CPU 都有 MMU 和页表这一“利器”来进行 VA 和 PA 之间的转换，而 HCA 要么直接连接到总线上，要么通过 IOMMU/SMMU 做地址转换后连接到总线上，它是“看不懂”APP 提供的 VA 所对应的真实物理内存地址的。\n所以注册 MR 的过程中，硬件会在内存中创建并填写一个 VA to PA 的映射表，这样需要的时候就能通过查表把 VA 转换成 PA 了。我们还是提供一个具体的例子来讲一下这个过程：\n现在假设左边的节点向右边的节点发起了 RDMA WRITE 操作，即直接向右节点的内存区域中写入数据。假设图中两端都已经完成了注册 MR 的动作，MR 即对应图中的“数据 Buffer”，同时也创建好了 VA-\u0026gt;PA 的映射表。\n首先本端 APP 会下发一个 WQE 给 HCA，告知 HCA，用于存放待发送数据的本地 Buffer 的虚拟地址，以及即将写入的对端数据 Buffer 的虚拟地址。 本端 HCA 查询 VA-\u0026gt;PA 映射表，得知待发数据的物理地址，然后从内存中拿到数据，组装数据包并发送出去。 对端 HCA 收到了数据包，从中解析出了目的 VA。 对端 HCA 通过存储在本地内存中的 VA-\u0026gt;PA 映射表，查到真实的物理地址，核对权限无误后，将数据存放到内存中。 再次强调一下，对于右侧节点来说，无论是地址转换还是写入内存，完全不用其 CPU 的参与。\n2. MR 可以控制 HCA 访问内存的权限 因为 HCA 访问的内存地址来自于用户，如果用户传入了一个非法的地址（比如系统内存或者其他进程使用的内存），HCA 对其进行读写可能造成信息泄露或者内存覆盖。所以我们需要一种机制来确保 HCA 只能访问已被授权的、安全的内存地址。IB 协议中，APP 在为数据交互做准备的阶段，需要执行注册 MR 的动作。\n而用户注册 MR 的动作会产生两把钥匙——L_KEY（Local Key）和 R_KEY（Remote Key），说是钥匙，它们的实体其实就是一串序列而已。它们将分别用于保障对于本端和远端内存区域的访问权限。下面两张图分别是描述 L_Key 和 R_Key 的作用的示意图：\nL_Key R_Key 这里大家可能会有疑问，本端是如何知道对端节点的可用 VA 和对应的 R_Key 的？其实两端的节点在真正的 RDMA 通信之前，都会通过某些方式先建立一条链路（可能是 Socket 连接，也可能是 CM 连接）并通过这条链路交换一些 RDMA 通信所必须的信息（VA，Key，QPN 等），我们称这一过程叫做“建链”和“握手”。我将在后面的文章中详细介绍。\n除了上面两个点之外，注册 MR 还有个重要的作用：\n3. MR 可以避免换页 因为物理内存是有限的，所以操作系统通过换页机制来暂时把某个进程不用的内存内容保存到硬盘中。当该进程需要使用时，再通过缺页中断把硬盘中的内容搬移回内存，这一过程几乎必然导致 VA-PA 的映射关系发生改变。\n由于 HCA 经常会绕过 CPU 对用户提供的 VA 所指向的物理内存区域进行读写，如果前后的 VA-PA 映射关系发生改变，那么我们在前文提到的 VA-\u0026gt;PA 映射表将失去意义，HCA 将无法找到正确的物理地址。\n为了防止换页所导致的 VA-PA 映射关系发生改变，注册 MR 时会 \u0026ldquo;Pin\u0026rdquo; 住这块内存（亦称“锁页”），即锁定 VA-PA 的映射关系。也就是说，MR 这块内存区域会长期存在于物理内存中不被换页，直到完成通信之后，用户主动注销这片 MR。\n好了，至此我们介绍完了 MR 的概念和作用，下一篇文章我将给大家介绍一下 PD（Protection Domain，保护域）的概念。\n代码示例 下面是一个简单的 RDMA 程序，展示了如何注册 MR：\n#include \u0026lt;infiniband/verbs.h\u0026gt;\rint main() {\r// 省略初始化过程...\rstruct ibv_mr *mr;\rmr = ibv_reg_mr(pd, buf, 1024, IBV_ACCESS_LOCAL_WRITE |\rIBV_ACCESS_REMOTE_WRITE);\r// 获取 L_Key 和 R_Key\ruint32_t lkey = mr-\u0026gt;lkey;\ruint32_t rkey = mr-\u0026gt;rkey;\r// 省略其它代码...\r}\r","date":"2024-04-03T16:17:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/8fa232626b76940fddc8cc52a49c49e9195413-2024-04-04.webp","permalink":"https://cuterwrite.top/p/rdma-mr/","title":"RDMA 之 Memory Region"},{"content":"记录：安装 Intel® OneAPI-2024.0 Intel one API 由两个部分组成，前者为基础 Base Toolkit ，后者必须依赖前者，Intel one API HPC Toolkit，也就是要前后依次安装。\nBase Toolkit Base Toolkit 是 Intel 的一个 API 基础工具包包括以下库和其他库\nIntel® oneAPI DPC++/C++ Compiler\rIntel® DPC++ Compatibility Tool\rIntel® oneAPI DPC++ Library\rIntel® oneAPI Math Kernel Library\rIntel® oneAPI Threading Building Blocks\rIntel® oneAPI Collective Communications Library\rIntel® oneAPI Data Analytics Library\rIntel® oneAPI Deep Neural Networks Library\rIntel® Integrated Performance Primitives\rIntel® VTune™ Profiler\rIntel® Advisor\rIntel® Distribution for GDB*\rIntel® Distribution for Python* (separate download required)\rIntel® FPGA Add-on for oneAPI Base Toolkit (separate download required)\rBase Toolkit 安装 下载安装包 $ wget https://registrationcenter-download.intel.com/akdlm/IRC_NAS/163da6e4-56eb-4948-aba3-debcec61c064/l_BaseKit_p_2024.0.1.46_offline.sh\r安装 $ chmod +x l_BaseKit_p_2024.0.1.46_offline.sh\r$ sudo ./l_BaseKit_p_2024.0.1.46_offline.sh\r如果自定义安装在用户目录，就不需要 root 权限 ./l_BaseKit_p_2024.0.1.46_offline.sh\r然后将启动一个图形安装界面，继续操作：\n（1）选择 Accept \u0026amp; customize （2）选择安装的组件 （3）选择安装的路径 （4）选择 Next （5）选择 2 然后开始安装 接下来等待安装完成即可。\nHPC Toolkit 运行基于 Base Toolkit ，这个必须作为后者安装\nIntel® Fortran Compiler\rIntel® Fortran Compiler Classic\rIntel® Inspector\rIntel® MPI Library\rIntel® Trace Analyzer and Collector\rHPC Toolkit 安装 下载安装包 $ wget https://registrationcenter-download.intel.com/akdlm/IRC_NAS/67c08c98-f311-4068-8b85-15d79c4f277a/l_HPCKit_p_2024.0.1.38_offline.sh\r安装 $ chmod +x l_HPCKit_p_2024.0.1.38_offline.sh\r$ sudo ./l_HPCKit_p_2024.0.1.38_offline.sh\r如果自定义安装在用户目录，就不需要 root 权限 ./l_HPCKit_p_2024.0.1.38_offline.sh\r必须安装的库文件： Intel® MPI Library Intel® Fortran Compiler (Beta) \u0026amp; Intel® Fortran Compiler Classic Intel® oneAPI DPC++/C++ Compiler \u0026amp; Intel® C++ Compiler Classic\n安装过程与 Base Toolkit 类似，不再赘述。\n环境配置 安装完成后，需要配置环境变量，以便在终端中使用 Intel® oneAPI 工具。\n在 HPC 环境中，使用 modulefile 来管理环境变量，可以使用 module 命令来加载环境变量。\n以下是参考的 modulefile 文件，可以根据自己的安装路径进行修改。\n#%Module1.0#####################################################################\r##\r## modules modulefile\r##\rproc ModulesHelp { } {\rglobal version prefix\rputs stderr \u0026quot;\\tmodules - loads the modules software \u0026amp; application environment\u0026quot;\rputs stderr \u0026quot;\\n\\tThis adds $prefix/* to several of the\u0026quot;\rputs stderr \u0026quot;\\tenvironment variables.\u0026quot;\rputs stderr \u0026quot;\\n\\tVersion $version\\n\u0026quot;\r}\rmodule-whatis\t\u0026quot;loads intel/oneapi2024.0\u0026quot;\r# for Tcl script use only\rset\tversion\toneapi2024.0\rset\tprefix\t/opt/software/intel/oneapi2024.0\rconflict\tintel\rprepend-path\tTBBROOT\t${prefix}/tbb/2021.11/env/..\rprepend-path\tDAALROOT\t${prefix}/cdal/2024.0\rprepend-path\tDPCT_BUNDLE_ROOT\t${prefix}/dpcpp-ct/2024.0\rprepend-path\tINSPECTOR_2023_DIR\t${prefix}/inspector/2024.0\rprepend-path\tONEAPI_ROOT\t${prefix}\rprepend-path\tPKG_CONFIG_PATH\t${prefix}/vtune/2024.0/include/pkgconfig/lib64:${prefix}/tbb/2021.11/env/../lib/pkgconfig:${prefix}/mpi/2021.11/lib/pkgconfig:${prefix}/mkl/2024.0/lib/pkgconfig:${prefix}/ippcp/2021.9/lib/pkgconfig:${prefix}/inspector/2024.0/include/pkgconfig/lib64:${prefix}/dpl/2022.3/lib/pkgconfig:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/../lib/pkgconfig:${prefix}/cdal/2024.0/lib/pkgconfig:${prefix}/compiler/2024.0/lib/pkgconfig:${prefix}/ccl/2021.11/lib/pkgconfig:${prefix}/advisor/2024.0/include/pkgconfig/lib64:\r#prepend-path\tPKG_CONFIG_PATH\t${prefix}/vtune/2024.0/include/pkgconfig/lib64:${prefix}/tbb/2021.11/env/../lib/pkgconfig:${prefix}/mkl/2024.0/lib/pkgconfig:${prefix}/ippcp/2021.9/lib/pkgconfig:${prefix}/inspector/2024.0/include/pkgconfig/lib64:${prefix}/dpl/2022.3/lib/pkgconfig:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/../lib/pkgconfig:${prefix}/cdal/2024.0/lib/pkgconfig:${prefix}/compiler/2024.0/lib/pkgconfig:${prefix}/ccl/2021.11/lib/pkgconfig:${prefix}/advisor/2024.0/include/pkgconfig/lib64:\rprepend-path\tVT_MPI\timpi4\rprepend-path\tACL_BOARD_VENDOR_PATH\t/opt/Intel/OpenCLFPGA/oneAPI/Boards\rprepend-path\tFPGA_VARS_DIR\t${prefix}/compiler/2024.0/lib/oclfpga\rprepend-path\tCCL_ROOT\t${prefix}/ccl/2021.11\rprepend-path\tVT_ADD_LIBS\t\u0026quot;-ldwarf -lelf -lvtunwind -lm -lpthread\u0026quot;\rprepend-path\tI_MPI_ROOT\t${prefix}/mpi/2021.11\rprepend-path\tFI_PROVIDER_PATH\t${prefix}/mpi/2021.11//libfabric/lib/prov:/usr/lib/x86_64-linux-gnu/libfabric\rprepend-path\tDNNLROOT\t${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp\rprepend-path\tDIAGUTIL_PATH\t${prefix}/vtune/2024.0/sys_check/vtune_sys_check.py:${prefix}/dpcpp-ct/2024.0/sys_check/sys_check.sh:${prefix}/debugger/2024.0/sys_check/debugger_sys_check.py:${prefix}/compiler/2024.0/sys_check/sys_check.sh:${prefix}/advisor/2024.0/sys_check/advisor_sys_check.py:\rprepend-path\tCCL_CONFIGURATION\tcpu_gpu_dpcpp\rprepend-path\tDPL_ROOT\t${prefix}/dpl/2022.3\rprepend-path\tMANPATH\t${prefix}/mpi/2021.11/man:${prefix}/itac/2022.0/man:${prefix}/debugger/2024.0/documentation/man:${prefix}/compiler/2024.0/documentation/en/man/common:::\r#prepend-path\tMANPATH\t${prefix}/itac/2022.0/man:${prefix}/debugger/2024.0/documentation/man:${prefix}/compiler/2024.0/documentation/en/man/common:::\rprepend-path\tGDB_INFO\t${prefix}/debugger/2024.0/documentation/info/\rprepend-path\tSETVARS_COMPLETED\t1\rprepend-path\tAPM\t${prefix}/advisor/2024.0/perfmodels\rprepend-path\tCMAKE_PREFIX_PATH\t${prefix}/tbb/2021.11/env/..:${prefix}/ipp/2021.10/lib/cmake/ipp:${prefix}/ipp/2021.10/lib/cmake/ipp:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/../lib/cmake:${prefix}/cdal/2024.0:${prefix}/compiler/2024.0/IntelDPCPP:${prefix}/ccl/2021.11/lib/cmake/oneCCL\rprepend-path\tVTUNE_PROFILER_2023_DIR\t${prefix}/vtune/2024.0\rprepend-path\tCMPLR_ROOT\t${prefix}/compiler/2024.0\rprepend-path\tADVISOR_2023_DIR\t${prefix}/advisor/2024.0\rprepend-path\tFPGA_VARS_ARGS\t\u0026quot;\u0026quot;\rprepend-path\tINFOPATH\t${prefix}/debugger/2024.0/gdb/intel64/lib\rprepend-path\tIPPROOT\t${prefix}/ipp/2021.10\rprepend-path\tIPP_TARGET_ARCH\tintel64\rprepend-path\tPYTHONPATH\t${prefix}/advisor/2024.0/pythonapi\rprepend-path\tVT_ROOT\t${prefix}/itac/2022.0\rprepend-path\tDALROOT\t${prefix}/cdal/2024.0\rprepend-path\tLIBRARY_PATH\t${prefix}/tbb/2021.11/env/../lib/intel64/gcc4.8:${prefix}/mpi/2021.11//libfabric/lib:${prefix}/mpi/2021.11//lib/release:${prefix}/mpi/2021.11//lib:${prefix}/mkl/2024.0/lib/intel64:${prefix}/ipp/2021.10/lib/intel64:${prefix}/ippcp/2021.9/lib/intel64:${prefix}/ipp/2021.10/lib/intel64:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/lib:${prefix}/cdal/2024.0/lib/intel64:${prefix}/compiler/2024.0/compiler/lib/intel64_lin:${prefix}/compiler/2024.0/lib:${prefix}/ccl/2021.11/lib/cpu_gpu_dpcpp\r#prepend-path\tLIBRARY_PATH\t${prefix}/tbb/2021.11/env/../lib/intel64/gcc4.8:${prefix}/mkl/2024.0/lib/intel64:${prefix}/ipp/2021.10/lib/intel64:${prefix}/ippcp/2021.9/lib/intel64:${prefix}/ipp/2021.10/lib/intel64:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/lib:${prefix}/cdal/2024.0/lib/intel64:${prefix}/compiler/2024.0/compiler/lib/intel64_lin:${prefix}/compiler/2024.0/lib:${prefix}/ccl/2021.11/lib/cpu_gpu_dpcpp\rprepend-path\tDAL_MAJOR_BINARY\t1\rprepend-path\tIPPCRYPTOROOT\t${prefix}/ippcp/2021.9\rprepend-path\tIPPCP_TARGET_ARCH\tintel64\rprepend-path\tOCL_ICD_FILENAMES\tlibintelocl_emu.so:libalteracl.so:${prefix}/compiler/2024.0/lib/x64/libintelocl.so\rprepend-path\tCLASSPATH\t${prefix}/mpi/2021.11//lib/mpi.jar:${prefix}/cdal/2024.0/lib/onedal.jar\r#prepend-path\tCLASSPATH\t${prefix}/cdal/2024.0/lib/onedal.jar\rprepend-path\tINTELFPGAOCLSDKROOT\t${prefix}/compiler/2024.0/lib/oclfpga\rprepend-path\tLD_LIBRARY_PATH\t${prefix}/tbb/2021.11/env/../lib/intel64/gcc4.8:${prefix}/mpi/2021.11//libfabric/lib:${prefix}/mpi/2021.11//lib/release:${prefix}/mpi/2021.11//lib:${prefix}/mkl/2024.0/lib/intel64:${prefix}/itac/2022.0/slib:${prefix}/ipp/2021.10/lib/intel64:${prefix}/ippcp/2021.9/lib/intel64:${prefix}/ipp/2021.10/lib/intel64:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/lib:${prefix}/debugger/2024.0/gdb/intel64/lib:${prefix}/debugger/2024.0/libipt/intel64/lib:${prefix}/debugger/2024.0/dep/lib:${prefix}/cdal/2024.0/lib/intel64:${prefix}/compiler/2024.0/lib:${prefix}/compiler/2024.0/lib/x64:${prefix}/compiler/2024.0/lib/oclfpga/host/linux64/lib:${prefix}/compiler/2024.0/compiler/lib/intel64_lin:${prefix}/ccl/2021.11/lib/cpu_gpu_dpcpp:${prefix}/compiler/2024.0/compiler/lib/intel64_lin:${prefix}/ccl/2021.11/lib/cpu_gpu_dpcpp\r#prepend-path\tLD_LIBRARY_PATH\t${prefix}/tbb/2021.11/env/../lib/intel64/gcc4.8:${prefix}/mkl/2024.0/lib/intel64:${prefix}/itac/2022.0/slib:${prefix}/ipp/2021.10/lib/intel64:${prefix}/ippcp/2021.9/lib/intel64:${prefix}/ipp/2021.10/lib/intel64:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/lib:${prefix}/debugger/2024.0/gdb/intel64/lib:${prefix}/debugger/2024.0/libipt/intel64/lib:${prefix}/debugger/2024.0/dep/lib:${prefix}/cdal/2024.0/lib/intel64:${prefix}/compiler/2024.0/lib:${prefix}/compiler/2024.0/lib/x64:${prefix}/compiler/2024.0/lib/oclfpga/host/linux64/lib:${prefix}/compiler/2024.0/compiler/lib/intel64_lin:${prefix}/ccl/2021.11/lib/cpu_gpu_dpcpp:${prefix}/compiler/2024.0/compiler/lib/intel64_lin:${prefix}/ccl/2021.11/lib/cpu_gpu_dpcpp\rprepend-path\tVT_LIB_DIR\t${prefix}/itac/2022.0/lib\rprepend-path\tVTUNE_PROFILER_DIR\t${prefix}/vtune/2024.0\rprepend-path\tVT_SLIB_DIR\t${prefix}/itac/2022.0/slib\rprepend-path\tMKLROOT\t${prefix}/mkl/2024.0\rprepend-path\tDAL_MINOR_BINARY\t1\rprepend-path\tNLSPATH\t${prefix}/mkl/2024.0/lib/intel64/locale/%l_%t/%N:${prefix}/compiler/2024.0/compiler/lib/intel64_lin/locale/%l_%t/%N\rprepend-path\tPATH\t${prefix}/vtune/2024.0/bin64:${prefix}/mpi/2021.11//libfabric/bin:${prefix}/mpi/2021.11//bin:${prefix}/mkl/2024.0/bin/intel64:${prefix}/itac/2022.0/bin:${prefix}/inspector/2024.0/bin64:${prefix}/dpcpp-ct/2024.0/bin:${prefix}/dev-utilities/2024.0/bin:${prefix}/debugger/2024.0/gdb/intel64/bin:${prefix}/compiler/2024.0/lib/oclfpga/bin:${prefix}/compiler/2024.0/bin/intel64:${prefix}/compiler/2024.0/bin:${prefix}/advisor/2024.0/bin64\r#prepend-path\tPATH\t${prefix}/vtune/2024.0/bin64:${prefix}/mkl/2024.0/bin/intel64:${prefix}/itac/2022.0/bin:${prefix}/inspector/2024.0/bin64:${prefix}/dpcpp-ct/2024.0/bin:${prefix}/dev-utilities/2024.0/bin:${prefix}/debugger/2024.0/gdb/intel64/bin:${prefix}/compiler/2024.0/lib/oclfpga/bin:${prefix}/compiler/2024.0/bin/intel64:${prefix}/compiler/2024.0/bin:${prefix}/advisor/2024.0/bin64\rprepend-path\tINTEL_PYTHONHOME\t${prefix}/debugger/2024.0/dep\rprepend-path\tINTEL_LICENSE_FILE\t/opt/intel/licenses:/root/intel/licenses\rprepend-path\tCPATH\t${prefix}/tbb/2021.11/env/../include:${prefix}/mpi/2021.11//include:${prefix}/mkl/2024.0/include:${prefix}/ipp/2021.10/include:${prefix}/ippcp/2021.9/include:${prefix}/ipp/2021.10/include:${prefix}/dpl/2022.3/linux/include:${prefix}/dpcpp-ct/2024.0/include:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/include:${prefix}/dev-utilities/2024.0/include:${prefix}/cdal/2024.0/include:${prefix}/compiler/2024.0/lib/oclfpga/include:${prefix}/ccl/2021.11/include/cpu_gpu_dpcpp\r#prepend-path\tCPATH\t${prefix}/tbb/2021.11/env/../include:${prefix}/mkl/2024.0/include:${prefix}/ipp/2021.10/include:${prefix}/ippcp/2021.9/include:${prefix}/ipp/2021.10/include:${prefix}/dpl/2022.3/linux/include:${prefix}/dpcpp-ct/2024.0/include:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/include:${prefix}/dev-utilities/2024.0/include:${prefix}/cdal/2024.0/include:${prefix}/compiler/2024.0/lib/oclfpga/include:${prefix}/ccl/2021.11/include/cpu_gpu_dpcpp\r运行测试 通过 module load 命令加载环境变量\n$ module load intel/oneapi2024.0\r测试是否安装成功\n$ icx -v\r如果输出版本信息，则安装成功。\nIntel(R) oneAPI DPC++/C++ Compiler 2024.0.2 (2024.0.2.20231213)\rTarget: x86_64-unknown-linux-gnu\rThread model: posix\rInstalledDir: /opt/software/intel/oneapi2024.0/compiler/2024.0/bin/compiler\rConfiguration file: /opt/software/intel/oneapi2024.0/compiler/2024.0/bin/compiler/../icx.cfg\rFound candidate GCC installation: /opt/rh/devtoolset-11/root/usr/lib/gcc/x86_64-redhat-linux/11\rSelected GCC installation: /opt/rh/devtoolset-11/root/usr/lib/gcc/x86_64-redhat-linux/11\rCandidate multilib: .;@m64\rCandidate multilib: 32;@m32\rSelected multilib: .;@m64\r继续测试 MPI\n$ mpirun --version\r如果输出版本信息，则安装成功。\nIntel(R) MPI Library for Linux* OS, Version 2021.11 Build 20231005 (id: 74c4a23)\rCopyright 2003-2023, Intel Corporation.\ricx 说明 Intel® oneAPI DPC++/C++ Compiler (icx) is Intel nextgen compiler based on Clang /LLVM technology plus Intel proprietary optimizations and code generation.\n― Intel®, Intel® C/C\u0026#43;\u0026#43; Compilers Complete Adoption of LLVM icx 是基于 Clang /LLVM 技术的 Intel 下一代编译器，加上 Intel 专有的优化和代码生成。\nLLVM 帮助实现了为英特尔架构提供更加优秀的 C/C++编译器这一目标。最新的英特尔 C/C++编译器使用 LLVM 架构，可提供更快的编译时间、更好的优化、增强的标准支持以及对 GPU 和 FPGA 负载转移（offloading）的支持。\n采用 LLVM 的好处 LLVM 开源项目是模块化和可重用的编译器和一系列工具链技术的集合，整个项目支持多种处理器架构和编程语言。Clang 开源项目提供了一个 C/C++前端，为 LLVM 项目支持了最新的语言标准。包括 Clang 在内，LLVM 是由一个庞大且非常活跃的开发社区维护的。\n采用 LLVM 的好处有很多，第一条要说的是更快的构建时间。众所周知，Clang 是很快的！我们使用英特尔 oneAPI 2021.3 工具包中的英特尔 C/C++编译器时，测得构建时间减少了 14％。除了减少构建时间外，采用 Clang 使我们可以从社区支持最新 C++语言标准的一系列成果中受益，并贡献成果来反哺社区。\n英特尔为开源项目提供贡献和支持的历史颇为悠久，其中向 LLVM 做出贡献就有十年时间了。我们今天的主动合作行为包括了优化报告补充、扩大的浮点模型支持，以及向量增强。英特尔直接对 LLVM 项目做出贡献，也有一个临时区域（英特尔 LLVM 技术项目），针对 SYCL 支持。\n在英特尔架构上，英特尔 C/C++编译器预期能提供比基础 Clang+LLVM 编译器更高的性能。接下来英特尔 C/C++编译器都会是采用了 LLVM 开源基础架构的版本（icx）。我们会继续之前的长期努力，持续为 Clang 和 LLVM 项目做出贡献，包括为它们提供优化。并非所有的优化技术都会被上游采纳，有时是因为它们太新了，有时因为它们过于针对英特尔架构。这是可以预料的，并且与其他已经采用 LLVM 的编译器是同样的情况。\n英特尔 C/C++编译器一直都在提供最优秀的性能。经典版本的英特尔 C/C++编译器取得了对 GCC 18％的优势，而基于 LLVM 的英特尔 C/C++编译器取得了 41％的优势。\n","date":"2024-03-08T14:39:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/crop_62cf8bae89f60c3522eb45af53a53f4b195413-2024-03-09.webp","permalink":"https://cuterwrite.top/p/intel-oneapi/","title":"记录：安装 Intel® OneAPI-2024.0"},{"content":"笔记：Pure: 改进消息传递以更好地利用节点内的共享内存 引用出处 James Psota and Armando Solar-Lezama. 2024. Pure: Evolving Message Passing To Better Leverage Shared Memory Within Nodes. In Proceedings of the 29th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming (PPoPP \u0026lsquo;24). Association for Computing Machinery, New York, NY, USA, 133–146. https://doi.org/10.1145/3627535.3638503\r关键词 并行编程模型 分布式运行时系统 基于任务的并行模型 并发数据结构 无锁数据结构 摘要 Pure 是一种新的编程模型和运行时系统，旨在在基于消息传递接口（增强使用任务利用空闲核心能力）的环境中充分利用节点内部的共享内存。Pure 通过两种方式利用共享内存：(1) 允许 rank 在等待消息到达时从彼此那里窃取工作；(2) 利用高效无锁的数据结构实现节点内各进程间高性能的消息传递和集合操作。研究者通过 micro benchmark 测试评估了 Pure 的关键消息传递和集合特性，并展示了在 CoMD 分子动力学和 miniAMR 自适应网格细化应用中，当扩展到 4096 个 rank 时，Pure 可实现高达 2.1x 的应用加速。\n1. 引言 在过去的几十年里，高性能计算领域经历了从大型向量计算机到由单处理器构成的集群的转变，这些集群通过网络互连。MPI 成为了分布式内存系统上并行编程的事实标准。随着硬件的进步，多核集群的出现使得节点内的核心能够共享内存并通过网络进行通信，这促使社区不断寻求新的范式，以更有效地利用现代集群资源。目前主要的策略有两种：一种是维持统一的 MPI 编程方法，通过改进 MPI 运行时系统来更好地利用共享内存；另一种是采用 MPI+X 等混合编程模式，在节点内部采用共享内存并行性，而在节点之间继续使用 MPI。然而，这些方法要么可能受到 MPI 标准对接口行为规定的限制，无法最大化性能；要么给程序员带来了管理两种编程模型的挑战。\n社区已经尝试了许多其他方法，其中包括 PGAS 模型，它提供了一种集群范围内的共享内存抽象，以及 Legion 、Chapel 和 X10 等隐式并行编程语言，这些语言提供了高级抽象，并尝试自动高效地协调应用程序。尽管取得了一定的进展，许多现代 HPC 应用仍然依赖于 MPI。MPC 和 AMPI 也尝试通过将线程作为 MPI Rank 来利用内部的共享内存，以提高性能。\n然而，仅使用 MPI 的方法往往比混合编程方法表现更佳。这可能是因为接口的局限性和无法充分利用节点内的共享内存，导致 MPI 未能充分发挥其潜在性能。因此，本文提出的 Pure 系统基于 MPI-everywhere 方法构建，打破了一些 MPI 的传统假设，更有效地利用了共享内存，同时避免了对现有程序进行重大重构的需求。Pure 采用了与 MPI 类似的编程模型，从而能够利用 HPC 社区现有的 MPI 知识和应用程序基础。\nPure 的设计灵感源自 MPI，其核心编程模型是基于消息传递的，并可选择性地整合任务并行性。与 MPI 不同，Pure 摒弃了使用进程级别的 rank 和对旧版语言的支持限制，转而采用线程作为 rank 的实现，而非传统的进程。这种转变使得 Pure 能够高效地采用轻量级的无锁同步机制，实现同一节点内各线程间的协调。利用这种线程化的 rank 架构，Pure 构建了高效的节点内集体操作功能，并通过无锁算法来优化这些操作的性能。此外，Pure 支持将应用程序中的一部分并行代码块以标准的 C++ lambda 表达式的形式运行，这些表达式能够被当前拥有 rank 的线程以及其他空闲的 rank 自动且并发地执行，而这一切的操作都由 Pure Runtime 运行时系统自动进行调度。\n论文提出的优化策略涵盖了以下几点：\n一种无锁消息传递方法，适用于小消息和大数据消息的传输。 无锁数据结构，用于高效实现集合通信算法。 一个无锁任务调度器，允许空闲线程高效地从其他线程中“窃取”工作负载。 作者采用了标准的 C++ 库来确保 Pure 的广泛兼容性，并证明了 Pure 相较于经过高度优化的 MPI 基准测试，在性能上有显著提升。此外，作者还展示了 Pure 编程模型在语义上与 MPI 非常相似，这意味着从现有应用程序迁移到 Pure 是直接且简便的，这一点通过源码到源码的转换工具 mpi2pure 得到了进一步的证明。总体而言，论文的主要贡献可以总结为以下几点：\n提出了一种新的编程模型和运行时系统，该系统有效地结合了消息传递和任务并行性，并且利用了标准 C++ 的特性来实现。 展示了现代 C++ 如何支持更加灵活的并行运行时系统接口。 描述了一个设计精良的无锁、多线程和分布式运行时系统，该系统在节点内部相比 MPI 显示出了显著的速度提升。 证明了通过仅对现有的 MPI 应用程序进行最小的源代码修改，就能在 micro benchmark 测试和三个实际应用中实现与最先进的 MPI 实现相比的显著性能提升。 2. Pure 使用示例 本节通过一个简单的 1-D Stencil 算法示例来阐释 Pure 的使用方法。该示例虽然简单，但能够清晰展示 Pure 的核心概念及其与 MPI 的相似之处，为开发者编写更复杂的应用程序奠定了基础。\n在 MPI 版本的实现代码 rand_stencil_mpi 中，计算工作主要集中在函数 random_work 中执行。简单来说，rand_stencil_mpi 函数首先会进入一个循环，迭代次数为 iters ，在数组 a 的每个元素上计算 random_work 。值得注意的是，random_work 执行的时间长度是可变且未知的，因此会引入负载不平衡。此外，random_work 不会修改数组 a 的内容，而是接着通过对相邻元素求平均值更新数组 a 。最后，程序利用 MPI_Send 和 MPI_Recv 交换 temp 数组的首尾元素，以便计算数组 a 的首尾元素。由于 random_work 所需时间长短不一，某些处理单元会提前完成任务，有时会在等待发送方较慢的 MPI_Recv 调用时陷入阻塞状态。\n示例 1：1-D Stencil with Random Work, MPI Version\nvoid rand_stencil_mpi(double* const a, size_t arr_sz, size_t iters, int my_rank,\rint n_ranks) {\rdouble temp[arr_sz];\rfor (auto it = 0; it \u0026lt; iters; ++it) {\rfor (auto i = 0; i \u0026lt; arr_sz; ++i) {\rtemp[i] = random_work(a[i]);\r}\rfor (auto i = 1; i \u0026lt; arr_sz - 1; ++i) {\ra[i] = (temp[i - 1] + temp[i] + temp[i + 1]) / 3.0;\r}\rif (my_rank \u0026gt; 0) {\rMPI_Send(\u0026amp;temp[0], 1, MPI_DOUBLE, my_rank - 1, 0, MPI_COMM_WORLD);\rdouble neighbor_hi_val;\rMPI_Recv(\u0026amp;neighbor_hi_val, 1, MPI_DOUBLE, my_rank - 1, 0, MPI_COMM_WORLD,\rMPI_STATUS_IGNORE);\ra[0] = (neighbor_hi_val + temp[0] + temp[1]) / 3.0;\r} // ends if not first rank\rif (my_rank \u0026lt; n_ranks - 1) {\rMPI_Send(\u0026amp;temp[arr_sz - 1], 1, MPI_DOUBLE, my_rank + 1, 0,\rMPI_COMM_WORLD);\rdouble neighbor_lo_val;\rMPI_Recv(\u0026amp;neighbor_lo_val, 1, MPI_DOUBLE, my_rank + 1, 0, MPI_COMM_WORLD,\rMPI_STATUS_IGNORE);\ra[arr_sz - 1] =\r(temp[arr_sz - 2] + temp[arr_sz - 1] + neighbor_lo_val) / 3.0;\r} // ends if not last rank\r} // ends for all iterations\r}\r示例 2 则展示了实现同样功能的 Pure 版本。其中存在一些关键差异。首先，消息调用函数接口不同，使用的是相应的 Pure 消息传递函数 pure_send_msg 和 pure_recv_msg ，而非 MPI 调用，但参数实质上与 MPI 对应函数基本相同。Pure 的消息传递语义类似于 MPI：发送端缓冲区被复制到接收端缓冲区。实现区别主要在于：Pure 在节点内部采用了轻量级的消息传递方法，从而在节点内的消息传递比 MPI 的延迟更低。\n示例 2：Pure 版本\nvoid rand_stencil_pure(double* a, const int arr_sz, const int n_iter,\rconst int my_rank, const int n_ranks) {\rdouble temp[arr_sz];\rPureTask rand_work_task = [a, temp, arr_sz, my_rank](\rchunk_id_t start_chunk, chunk_id_t end_chunk,\rstd::optinal\u0026lt;void\u0026gt; cont_params) {\rauto [min_idx, max_idx] =\rpure_aligned_idx_range\u0026lt;double\u0026gt;(arr_sz, start_chunk, end_chunk);\rfor (auto i = min_idx; i \u0026lt; max_idx; i++) {\rtemp[i] = random_work(a[i]);\r}\r}; // ends definding the Pure Task for rand_work_task\rfor (auto it = 0; it \u0026lt; n_iter; it++) {\rrand_work_task.execute(); // execute all chunks of rank_work_task\rfor (auto i = 1; i \u0026lt; arr_sz - 1; ++i) {\ra[i] = (temp[i - 1] + temp[i] + temp[i + 1]) / 3.0;\r}\rif (my_rank \u0026gt; 0) {\rpure_send_msg(\u0026amp;temp[0], 1, MPI_DOUBLE, my_rank - 1, 0, PURE_COMM_WORLD);\rdouble neighbor_hi_val;\rpure_recv_msg(\u0026amp;neighbor_hi_val, 1, MPI_DOUBLE, my_rank - 1, 0,\rPURE_COMM_WORLD);\ra[0] = (neighbor_hi_val + temp[0] + temp[1]) / 3.0;\r} // ends if not first rank\rif (my_rank \u0026lt; n_ranks - 1) {\rpure_send_msg(\u0026amp;temp[arr_sz - 1], 1, MPI_DOUBLE, my_rank + 1, 0,\rPURE_COMM_WORLD);\rdouble neighbor_lo_val;\rpure_recv_msg(\u0026amp;neighbor_lo_val, 1, MPI_DOUBLE, my_rank + 1, 0,\rPURE_COMM_WORLD);\ra[arr_sz - 1] =\r(temp[arr_sz - 2] + temp[arr_sz - 1] + neighbor_lo_val) / 3.0;\r} // ends if not last rank\r} // ends definding the Pure Task for rand_work_task\r}\r更重要的差异在于 Pure 中增加的 Pure Task ，用带有一组特定参数定义的 lambda 表达式，其利用 lambda 的捕获参数特性，允许外部于 lambda 体内的变量以值或引用形式被捕获并在 lambda 执行时使用。Pure Task 可以被视为由 Pure Runtime 运行时系统负责执行应用程序代码片段，可以通过多线程并发执行。因此，Pure 任务应结构化为类似数据并行的形式。此外，Pure Task 需要由程序员保证线程安全。\n在以上 Pure 实现中，程序员可以利用 chunk ranges 来描述并发性。这些子范围或 chunk 是通过 start_chunk 和 end_chunk 参数传递给 Pure Task 的，而它们是由 Pure Runtime 运行时系统提供。Pure Runtime 运行时系统负责确保所有工作顺利完成。由于可能涉及到不同的多个线程，Pure Runtime 运行时系统会通过追踪哪些 chunk 已分配和完成来实现这一点。\n其次，程序员需要将 Pure Runtime 运行时系统提供的 start_chunk 和 end_chunk 参数映射到与应用计算相关的具体内容上。在这里，代码使用了 pure_aligned_idx_range 辅助函数将其转化为循环索引子范围。这个辅助函数考虑到了缓存行，所以有利于避免伪共享问题。\n由于 random_work 可能导致负载分布不均，某些 rank 可能会在等待消息时处于空闲状态。Pure 的任务调度器会自动利用这些空闲的 rank，以执行同一节点内其他待处理的 Pure 任务块。以下图中在同一节点内的三个 rank 为例：rank 0 正在执行一个被划分为 6 个 chunks 的 Pure Task，而 rank 1 和 rank 2 因为接收消息而阻塞。\n示例 Pure 代码的时间线示意图 从图中可以清晰地看到以下执行流程：\nrank 0 开始处理第一个 chunk（chunk 0） 。 同时，rank 1 窃取并行执行第二个 chunk（chunk 1）。 任务调度器随后为 rank 0 分配第三个 chunk（chunk 2），为 rank 1 分配第四个 chunk（chunk 3）。 rank 2 尝试窃取一个任务，并成功执行第五个 chunk（chunk 4）。由于 random_work 的执行随机性，chunk 2 和 chunk 4 可能是耗时较长的任务。 rank 0 完成 chunk 5 的处理，这是一个较小的任务块，它在 rank 2 完成 chunk 4 之前就已经结束了。 任务调度器确保在所有 chunks 完成之前，rank 0 不会结束执行。实际上，rank 0 要等到 chunk 4 完成后才能继续。 在 rank 1 和 rank 2 等待消息的过程中，它们会尝试从其他任何可用的 rank 中窃取更多的 chunks。 得益于 lambda 表达式的变量捕获功能，不同 rank 之间可以高效地共享上下文信息。 实验结果显示，在单节点上配置 32 个 rank 的 Pure 版本因为更快的消息传递和 Pure Task 的并行执行，相比于 MPI 版本，Pure 版本实现了 10% 的性能提升。在负载分布不均的情境下，Pure 的加速比甚至超过了 200%。这些性能提升的程度虽然受到负载不平衡的影响，但在实际应用场景中，Pure 仍展现出了显著的性能改进。这归功于 Pure Runtime 运行时系统的能力，它能够自动检测并高效利用未被充分利用的计算资源。\n3. 编程模型 Pure 的编程模型核心是“消息传递结合可选的任务并行性”。在语义上，Pure 的消息传递和集合通信操作与 MPI 等同，差异主要体现在语法上的一些细节。\n尽管 Pure 在节点内部采用线程，但其 rank 命名空间在整个集群中保持非层级结构。在 Pure 程序的执行周期内，rank 的数量保持不变。\nPure 应用程序采用 C++ 编写，并通过 SPMD（单程序多数据）模式运行，实现了内部的多线程化。在同一个节点上，所有的 rank 都是通过内核线程实现的。\n需要注意的是，Pure 应用程序并不支持全局变量。因此，开发者应当移除全局变量或者使用 thread_local 关键字来限制变量的作用域，确保线程之间的安全性。\n对于存在负载不均衡问题的应用程序，开发者可以在满足以下特定条件的程序部分使用 Pure Task：\n计算密集型的热点区域。 可以并发执行的任务。 消息传递和集合通信操作 在 Pure 中，pure_send_msg 和 pure_recv_msg 函数在功能上与 MPI 的 MPI_Send 和 MPI_Recv 相对应，同时 Pure 也提供了相应的非阻塞版本。\nPure Runtime 运行时系统确保所有消息都会被送达，并且按照发送的顺序进行交付。Pure 还实现了一系列的集合通信操作，包括：\nReduce All-Reduce Barrier Broadcast 此外，Pure 引入了通信子（communication subgroup）的概念，允许开发者通过 pure_comm_split 函数将一个通信子集进一步细分为更小的子集。\n为了使用 Pure，应用程序需要采用现代 C++ 标准进行编写，推荐使用 std=c++11 或更高版本进行编译。Pure 提供了一个基于 Make 的构建系统，它会自动配置合适的编译器选项，并链接到 Pure Runtime 运行时系统（libpure），同时定义了一系列用于调试和性能分析的 target。\nPure Task Pure Task 允许开发者定义应用程序中的计算部分，并将其分解为可并行执行的 chunks。这些 chunks 可以由 Pure Runtime 运行时系统自动并发执行。\n然而，Pure Task 不是必需的，只有在任务可以划分为多个小块，并且这样做有助于缓解负载不均衡问题时，才推荐使用 Pure Task。\nPure Task 通过 C++ Lambda 表达式实现，并在拥有该任务的 rank 调用 execute 方法时同步执行。每个 rank 同一时间只能执行一个 Pure Task。Lambda 表达式的变量捕获功能使得不同 rank 在执行不同 chunks 时能够高效共享上下文信息。通常，一个 Pure Task 在应用程序的运行过程中会被定义一次，然后在每个时间步或其他迭代中多次执行。\n定义 Pure Task 时，需要指定 chunk 的数量和额外的应用程序参数。任务之间应避免相互依赖，不过因为它们会在 execute 调用期间完全执行，所以它们不会与任务外部的代码发生冲突。\nPure Task 包含一个 execute 方法，该方法接受一个 optional\u0026lt;void*\u0026gt; 类型的参数 per_exe_args ，用于每次执行任务时传递额外的参数。这在任务主体的输入值在连续执行中发生变化时非常有用。例如，开发者可以将指向局部结构体的指针传递给 execute 方法。\nPure Task 的前两个参数 start_chunk 和 end_chunk 是无符号整数，用于指定要执行的 chunk 范围。这些 chunk 由 Pure Runtime 运行时系统分配，确保每个 chunk 只被执行一次，即使它们可能并发执行。\nPure Task 使用 chunk 范围为调度器提供了灵活性，允许一次性分配多个 chunks。chunks 的数量由 Pure 任务调度器决定，但不会超过在 Makefile 文件中预定义的 PURE_MAX_TASK_CHUNKS 。\n目前，Pure Task 的接口需要手动将 chunk 编号映射到数组索引，这在处理多维数组时可能比较繁琐。因此，未来的工作目标是扩展接口，提供类似于 TBB 的 parallel_for 那样更简洁、更高级的接口。\n最后，开发者需要确保 Pure Task 内部的实现是线程安全的，以避免同一任务的多个并发执行的 chunks 之间的相互竞争。例如，在 CoMD 分子动力学 Benchmark 中，需要处理多个线程同时写入同一内存位置的问题，这时可以使用 std::atomic 数组来替代普通 int 数组。\n4. 运行时系统 Pure 运行时系统是一个多线程和分布式运行时的动态库，用于支持 Pure 应用程序的开发。开发者在使用时需要包含 pure.h 头文件，并使用 C++17 标准进行编译，同时链接到 libpure 库。Pure 运行时系统能够自动地在计算和通信操作之间寻找并利用重叠执行的机会，尤其是在通信延迟较高的情况下。\nPure 运行时系统的主要职能包括：\n初始化并配置必要的进程和线程，启动应用程序。 管理节点内部的 rank 间通信和集合操作。 管理内部的内存缓冲区和数据结构。 如果应用程序中定义了 Pure Task，运行时系统还需负责这些任务的调度和执行。 Rank 初始化与映射 Pure 中的 rank 实现为 MPI 进程的内核线程。在多节点应用中，Pure 运行 MPI 来处理跨节点通信，而在单节点应用中则不使用 MPI，尽管如此，Pure 应用程序并不直接调用 MPI 函数。通过 Makefile 配置，Pure 程序可以在一个节点或 NUMA 节点上启动一个 MPI 进程，并根据每个节点或 NUMA 节点的核心数来创建相应数量的线程。对于应用程序开发者而言，他们只需了解非层次化的 rank 命名空间，而节点、线程、MPI 进程和通信延迟等底层概念都被抽象化，对开发者透明。\nPure 支持灵活的 rank 到节点的映射策略，并且默认采用 SMP 风格的分配策略。同时，Pure 也支持自定义的 rank 映射，包括使用 CrayPAT 的 rank 重排文件。虽然这些硬件相关的细节对开发者来说是不可见的，但 Pure 内部会利用这些信息来优化关键功能。\n在 Pure 应用程序启动时，不会直接执行应用程序的原始 main 函数。相反，底层的 MPI 程序会调用 Pure 运行时系统中定义的 main 函数，该函数负责初始化 Pure 的核心数据结构，然后创建并绑定线程，每个线程执行一个 original_main 函数，这是从应用程序代码中的原始 main 函数重命名而来的版本。应用程序执行完毕后，original_main 函数返回到 Pure 运行时系统，后者负责完成 MPI 的清理和终止过程。\nSpin-Steal Waiting Loop (SSW-Loop) 当 Pure 的 rank 遇到阻塞事件，如等待消息到达，它将执行一个称为 自旋、窃取等待循环（SSW-Loop） 的机制，而不是简单地进入空闲状态。在此循环中，rank 会检查是否满足阻塞条件，例如是否有消息到达，如果没有，它会尝试从其他 rank 窃取任务。如果一个阻塞的 rank 能够协助其进程中正在并发执行的其他线程完成任务，它就会参与这种协助工作。\n由于线程是绑定到特定的 CPU 的，并且每个 rank 只运行一个应用程序，Pure 选择让 rank 主动自旋等待，而不是放弃 CPU。SSW-Loop 让计算中的 rank 具有“多态性”：它既可以作为主程序的计算节点，也可以协助其他 rank 执行窃取到的任务块，然后再返回检查自身的阻塞事件。\nPure 遵循优先处理当前 rank 拥有的窃取任务负载的策略，坚持任务负载优先的调度原则。\n与那些使用辅助线程来实现工作负载窃取或通信的系统不同，Pure 的特点是允许应用级别的计算节点直接进行任务窃取操作。\n实现说明 Pure 是使用 C++17 标准库编写的。Pure 运行时系统由大约 21,000 行源代码构成，而 Pure 工具则包含了约 14,000 行源代码。Pure 已在多种环境下进行测试，包括笔记本电脑和集群，其运行仅需要一个支持 C++17 的编译器、类 Unix 操作系统以及 MPI 环境。Pure 的源代码可以在 GitHub 上公开获取，链接为： https://github.com/psota/pure\r。\n点对点通信 Pure 提供了阻塞和非阻塞的点对点消息传递功能，其语义与 MPI 的消息传递相一致。\nPure 内部采用三种不同的策略来进行消息传递，选择哪种策略取决于消息的大小以及发送方和接收方是否位于同一节点。\nPure 在整个程序的生命周期中分配并复用一个持久的 Channel 对象，该对象存储于运行时系统中。内部的 Channel Manager 负责将消息参数映射到合适的数据结构，并根据需要创建这些结构。\nPure 消息传递策略 短消息（小于 8KB）： 采用无锁循环队列（PureBufferQueue，PBQ），具有 acquire-release 内存语义。发送线程在有可用空间时将消息复制到 PBQ，接收线程则在消息准备好时将其取出。 在短消息传递中，拷贝的开销相对较小，这样可以让发送方调用返回后立即执行执行其它有用的工作。 发送和接收线程都使用 SSW-Loop 进行等待，以尽可能地实现计算与通信的重叠执行。 所有消息的 slot 存储在一个连续的缓冲区中，通过指针算术确保每个 slot 与缓存行边界对齐，避免发送和接收线程之间的伪共享。 大消息（大于等于 8KB）： 类似于 PBQ 的策略，但使用直接从发送方到接收方的单次内存拷贝，灵感来自 MPI 的 rendezvous 模式。 使用无锁的固定大小循环缓冲区来存储接收方的接收调用参数。 发送方通过 SSW-Loop 等待元数据队列项，然后将消息内容直接复制到接收方的缓冲区。发送方通过在无锁队列中插入传输的字节数来通知接收方传输已完成。 跨节点消息 透明地使用 MPI 接口进行消息传递。 在 Pure 初始化期间，使用分布式一致性算法创建 thread-rank-process-node 映射数据结构，将 Pure rank 映射到 MPI rank。 为了确保在接收节点上正确的接收线程能够接收到消息，在 MPI_TAG 中编码发送和接收线程的 ID，解决多线程路由问题。 集合通信 Pure 的集体通信操作在语义上与 MPI 相同，但在节点内部通过自下而上构建的数据结构来实现，这在单节点和多节点基准测试中都显示出了显著的性能提升，即使在跨节点通信时仍然依赖于 MPI 的集合操作。\nPure 采用一个领导者线程来协调集体通信过程，其他线程则协助进行计算并按需调用 MPI 集合函数。\nPure 使用静态领导者选举方法，这比基于比较和交换的“首先进入”方法更为高效。 以下仅以 All-Reduce 为例子，其它集合通信操作思想类似。\n对于小数据的 All-Reduce 操作，Pure 设计了名为 Sequenced Per-Thread Dropbox (SPTD) 的并发数据结构，提供了一种高效的无锁机制，用于在领导线程和其他非领导线程之间对偶同步和可选共享数据。\nSequenced Per-Thread Dropbox (SPTD) 该方法借鉴了 flat-combinding 技术，将通信器中的线程 0 作为领导者线程。\n对于大小不超过 2KB 的小数组： 非领导者线程首先将数据复制到 SPTD，然后与领导者线程同步，表明输入数据已就绪（使用原子序列号而非共享原子计数器）。 领导者线程执行所有输入数组的逐元素 Reduce 操作。 每个节点的领导者线程使用 MPI_Allreduce 对局部 Reduce 结果进行全局 Reduce。 领导者线程同步，非领导者线程将最终的 Reduce 结果复制到私有缓冲区。 所有线程在等待时执行 SSW-Loop。 对于超过 2KB 的大数组，Reduce 计算可能成为性能瓶颈，因此需要所有线程并发执行 Reduce 计算，并通过共享内存直接从每个线程的缓冲区中读取或写入数据。 Reduce 工作被划分为大小相等的块，避免伪共享并实现向量化计算。 线程使用 SPTD 报告准备状态，并通过原子序列号标记计算完成。 领导者线程调用 MPI_Allreduce 执行跨节点的 All-Reduce 操作，并通过另一个原子序列号传播最终结果。 任务调度器 Pure 运行时系统精心设计了一个任务调度器，它在共享内存中维护了一个名为 active_tasks 的数组。这个数组存储了一系列原子指针，每个指针对应于一个正在执行的任务，并且为系统中的每个节点和每个 rank 分配了一个条目。这些条目最初被设置为 nullptr，表示任务尚未分配。\n当一个任务被创建并准备执行时，系统会为其初始化状态，并通过原子操作更新 active_tasks 数组中相应的条目，以反映该任务已被分配。这个更新过程确保了任务的执行状态对系统中的所有线程都是可见的，从而使得任务可以被其他线程“窃取”。\n在任务的执行过程中，拥有任务的 rank 会开始执行一系列的 chunk，这些是任务的细分工作单元。同时，其他线程会在它们的 SSL-Loop 期间不断检查 active_tasks 数组，通过原子加载操作来寻找可执行的非空任务。\n任务的执行是由两个原子整数 curr_chunk 和 chunks_done 来协调的。拥有任务的 rank（owner rank）和可能的窃取者 rank（thief ranks）都会运行相同的并发执行函数。窃取者线程会执行一个 chunk 后返回，而拥有者线程则持续执行直到所有 chunk 完成。通过使用 fetch_add 操作，线程可以确定自己应该执行哪个 chunk，如果 curr_chunk 的值已经超过了总的 chunk 数量，线程则会停止执行。\n每当一个 chunk 被成功完成后，线程会原子性地增加 chunks_done 的值。拥有者线程会更新其本地存储，以避免缓存未命中。最终，拥有者 rank 会等待，直到所有的 chunk 都执行完毕，确保任务的完整执行。\n值得注意的是，任务的 chunk 与应用程序的 rank 是在同一硬件线程上执行的。在 Pure 应用中，每个硬件线程都被分配给一个特定的 rank。尽管目前 Pure 还没有利用硬件加速器（如 GPU）来加速任务执行，但设计者相信 Pure 的架构完全有能力支持这种加速。\nPure 的任务调度器提供了多种执行模式和窃取算法，以适应不同的执行需求。例如，作者实现了单 chunk 执行模式和一种引导式自调度模式，后者是一种工作划分算法，它优先分配较大的工作块，然后是较小的工作块。此外，调度器还包括 NUMA 感知窃取模式，它优先从同一 NUMA 节点上的线程窃取任务，以及一种“黏性”窃取模式，允许窃取者线程返回它们最近窃取且仍在活跃状态的任务。这些特性共同确保了任务调度的高效性和灵活性。\n评估 在伯克利 NERSC 的 Cori HPC 集群上进行了 Pure 的性能评估。该集群包含 2388 个节点，每个节点配置有 2 个插槽、16 个核心和 128GB 内存，通过 Cray Aires 进行节点间互联。实验配置启用了超线程，并采用 256 位向量宽度。每个节点上运行 2 个进程，共 32 个线程。评估使用 Intel 编译器，并将 Cray MPICH 作为性能基线。\nNAS DT 基准测试结果 仅通过优化消息传递机制，Pure 取得了 11% 至 25% 的性能加速。 引入 Pure Tasks 后，性能加速比提升至 1.7 倍至 2.6 倍。 辅助线程能小幅提高性能，不过仅限于剩余未使用的 CPU 核心才能使用。在这里，除了 80 个 rank 的情况下空闲了 24 个核心，其它情况下都充分利用了 CPU 核心。 CoMD 和 miniAMR 基准测试 -在 CoMD 分子动力学应用中，Pure 在所有 rank 数下的性能均优于仅使用 MPI 及 MPI+OpenMP 的性能，分别实现了 7% 至 25% 以及 35% 至 50% 的加速比，即使在没有负载不均衡的情况下。\n在 miniAMR 自适应网格细化应用中，Pure 至少实现了 20%，最多 50% 的性能加速。 集合通信性能 Pure 在集合通信操作中的性能表现突出，这些操作的内部优化机制和数据结构设计使得 Pure 在处理大规模并行计算任务时展现出显著的效率和优势。 相关工作 类别 相关工作 Pure 的优势 MPI 1. 利用多核节点内的共享内存提升性能；2. XPMEM 显著增强节点内通信效率；3. ch4 网络库优化了 MPI 的共享内存通信；4. 改进了 MPI 的集合通信算法；5. DMAPP 库针对特定集合通信进行了优化，但限制较多；6. 解决了大规模全对全集合通信的挑战；7. 单边消息 API 实现了解耦；8. 优化了数据移动与进程同步 1. Pure 在所有集合通信和负载大小上均展现出卓越的性能；2. 提供了高级的通信计算重叠机制，超越了传统的单边消息 API MPI 多线程 1. 支持 MPI_THREAD_MULTIPLE 模式下的 rank 内多线程； 2. 多数 MPI 实现通过全局锁实现线程安全，导致性能瓶颈；3. MPI 4.0 引入 MPI+X 方法增强多线程支持；4. 引入了 MPI Fine-points 和 Endpoints 概念以支持线程 1. Pure 重视多线程代码中的 MPI 调用，强调其重要性；2. 提供了一种统一的编程模型，简化了并行任务的引入 AMPI 1. 基于 Charm++ 的 MPI 兼容库；2. 提供高级并行编程抽象；3. 通过最小化代码更改实现性能提升 1. Pure 在实际测试中表现优于 AMIP，得益于其优化的消息传递和集合通信，以及更精细和低开销的负载均衡策略；2. 相较于 AMIP SMP 基于线程的模型，Pure 提供了更高效的并行处理 PGAS 语言和并行框架 1. PGAS 语言提供了全局内存地址空间的抽象；2. Chapel 和 X10 扩展了 PGAS 方法，支持本地和远程异步任务；3. HPX 为现代 C++标准增加了分布式操作支持；4. Legion 作为数据中心并行编程系统；5. Kokkos, STAPL, BCL 等框架提供了应用程序与硬件间的抽象层 1. 类似于 Pure，PGAS 模型采用 SPMD 风格，通过局部性引用提高性能；2. 这些框架虽然利用了现代 C++特性，但通常需要对现有应用程序进行大量重写，而 Pure 则提供了更为直接的优化路径 总结 数十年来，由于其相对的简单性和性能优势，消息传递一直被视为并行编程的标准模型。然而，本文表明，消息传递与共享内存并非不可兼容。实际上，通过设计合适的库，可以在不牺牲大多数消息传递优点的前提下充分利用共享内存。\n","date":"2024-03-03T01:16:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/crop_e9af4c445d695be5002248c7c814c67d195413-2024-03-04.webp","permalink":"https://cuterwrite.top/p/pure/","title":"笔记：Pure - 改进消息传递以更好地利用节点内的共享内存"},{"content":"科研图表绘制 前置知识 位图 又称为点阵图像、像素图或栅格图像，由像素点组成。这些点可以进行不同的排列和染色以构成图像。\n位图特点：\n位图图像善于重现颜色的细微层次，能够制作出色彩和亮度变化丰富的图像，颜色逼真，文件庞大，不能随意缩放； 图像尺寸越大，文件也就越大；图像色彩越丰富，文件也就越大。 打印和输出的精度是有限的； 位图的文件格式：比如.tiff、.bmp、.gif、.jpg、.png、.psd 等。 常用的位图编辑软件：Photoshop 等。 矢量图 矢量又称为“向量”，矢量图像中的图形元素（点和线段）称为对象，每个对象都是一个单独的个体，它具有大小、方向、轮廓、颜色和屏幕位置等属性。简单地说，矢量图形软件就是用数学的方法来绘制矩形等基本形状的。\n矢量图特点：\n可以无限放大，同时又不用担心失真； 矢量图可以轻松地转化为位图，而位图转化为矢量图就需要通过图像临摹之类的方式，但完美转成矢量图还是有些难度。 矢量图的文件格式 ：比如 Adobe Illustrator 的.AI、.EPS、.SVG，.PDF，AutoCAD 的.dwg 和.dxf，windows 标准图元文件*.wmf 和增强型图元文件*.emf 等。 常用的矢量图编辑软件：Illustrator、CorelDraw、AutoCAD 等。 像素、DPI 与打印尺寸之间的关系 图像分辨率，像素数和打印尺寸在数学上的关系为：像素=分辨率（DPI）× 打印尺寸（以英寸为单位）。\n其中，DPI 为每平方英寸像素数目，也就是图像细节程度的度量。理解了上述概念我们就可以通过上述概念推测出图像的尺寸大小，比如说，我想打印一副 8 英寸 * 10 英寸，300DPI 的图片，那么怎样设置图像的像素长宽度呢？你只要简单地把这两者相乘就可以了，$8 \\times 300=2400$ ，$10 \\times 300=3000$ ，所以这幅图像的像素尺寸就是 $2400 \\times 3000$ 。\n杂志要求 这里以著名出版商艾斯维尔（Elsevier）的要求\r为例：\nTARGET SIZE Image Width Pixels at 300 dpi Pixels at 500 dpi Pixels at 1000 dpi Minimal size 30 mm (85 pt) 354 591 1181 Single column 90 mm (255 pt) 1063 1772 3543 1.5 column 140 mm (397 pt) 1654 2756 5512 Double column (full width) 190 mm (539 pt) 2244 3740 7480 通过学习上面图像尺寸的内容我们可以知道打印尺寸与像素和 dpi 之间的关系。例如，表格中红色要求图像最小尺寸为 $30 \\mathrm{mm}$ ，我们可以通过公式验证一下在 300dpi 分辨率下 354 像素宽打印出来的尺寸是不是 $30 \\mathrm{mm}$ ：$354 \\div 300 \\times 2.54 \\times 10 = 29.97 \\mathrm{mm}$ ， 最后相乘的两个数据是把英寸换算成毫米，正好是 $30 \\mathrm{mm}$ 。所以知道了上述关系我们就可以利用 Photoshop 来编辑我们的图片了；\n例如一张图片，来自于 Mapman，用 Photoshop 打开，显示尺寸如下：\n由于图片尺寸太大，宽度 $124.99 \\mathrm{cm}$ ，而且分辨率是 $72$ ，不符合杂志要求。这里利用上面学到的知识在不损失图片像素的情况下调整一下图片尺寸；\n现在我们要把图片宽度调整到双栏的尺寸也就是 $19\\mathrm{cm}$ ；通过公式：像素=分辨率（DPI）× 打印尺寸（以英寸为单位）\n在像素不变的情况下，我们要提高分辨率，来缩小图片的打印尺寸，根据比例计算应该提高到多少 dpi： $124.99 \\div 19 \\times 72=473.6 \\mathrm{dpi}$ ；\n所以修改宽度和分辨率这两个数值就可以了，而且图片的像素数是不变的，达到了无损改变图片的大小；而且 473dpi 大于最小的 300dpi。\nMatplotlib Python 库 作为 Python 生态中最基础且最广泛使用的数据可视化库，Matplotlib 提供了丰富的 2D 和 3D 图形绘制能力，尤其适合制作线图、柱状图、散点图等常见科研图表，并能高度定制化输出样式以符合各类学术期刊的标准。\n它可以用来绘制各种静态，动态，交互式的图表。我们可以使用该工具将很多数据通过图表的形式更直观的呈现出来，包括绘制线图、散点图、等高线图、条形图、柱状图、3D 图形、甚至是图形动画等等。\nMatplitlib Cheat Sheet Seaborn Python 库 构建于 Matplotlib 之上，Seaborn 进一步强化了统计图表的功能，它内置了许多高级统计图表样式，如热力图、箱型图和时间序列分析图表，使复杂数据关系的展现更为直观易读。既然是基于 matplotlib，所以 seaborn 的很多图表接口和参数设置与其很是接近，使得作图更加方便快捷。即便是没有什么基础的人，也能通过极简的代码，做出具有分析价值而又十分美观的图形。\nSeaborn Cheat Sheet 优秀教程：数据可视化，Seaborn 画图原来这么好看\rVisio 矢量图软件（框架流程绘制与算法结构） 对于非数据密集型但逻辑严密的图表设计，如实验流程图、系统架构图或算法流程图，Microsoft Visio 凭借其强大的矢量编辑能力和海量预设模板，成为了构建清晰、规范流程图的理想选择。\nOrigin 矢量图软件（数学分析与函数绘制） Origin 是由 OriginLab 公司开发的一个科学绘图、数据分析软件，支持在 Microsoft Windows 下运行。Origin 支持各种各样的 2D/3D 图形。Origin 中的数据分析功能包括统计，信号处理，曲线拟合以及峰值分析。Origin 中的曲线拟合是采用基于 Levernberg-Marquardt 算法（LMA）的非线性最小二乘法拟合。Origin 强大的数据导入功能，支持多种格式的数据，包括 ASCII、Excel、NI TDM、DIADem、NetCDF、SPC 等等。图形输出格式多样，例如 JPEG，GIF，EPS，TIFF 等。内置的查询工具可通过 ADO 访问数据库数据。\n在物理、化学、生物等领域享有盛誉，Origin 专为科研数据分析打造，以其强大的数学分析和函数绘制能力著称，特别适用于绘制精密的信号曲线、频谱分析图和其他复杂科研图形。\nAI（Adobe Illustrator）矢量图软件 作为行业标准级矢量图形处理软件，Illustrator 不仅适用于高精度的出版级图表设计，还能创建高质量的科学插图，确保在任何尺寸下都能保持清晰细腻的效果。它是一种应用于出版、多媒体和在线图像的工业标准矢量插画的软件。该软件主要应用于印刷出版、海报书籍排版、专业插画、多媒体图像处理和互联网页面的制作等，也可以为线稿提供较高的精度和控制，适合生产任何小型设计到大型的复杂项目。\n在图表绘制中，主要应用在：直接绘图-计科和控制类的用的很少，有生化环材方向的同学利用 AI 实现细胞结构，心室高亮等操作；整合之前导出的单个矢量图；将非矢量图转化为矢量图\nInkscape 矢量图软件 AI 的平替版，优点在于开源免费。 作为开源界的矢量图形编辑器翘楚，Inkscape 提供了一套完整的 SVG 编辑工具，科研人员可以免费使用它来创作复杂的矢量图表，并确保跨平台兼容性和无损缩放性。官方中文地址：Inkscape\r详细介绍：Inkscape - 免费开源、跨平台的矢量图形设计软件，代替 Adobe Illustrator (AI) 和 CorelDRAW\r推荐视频教程：\n","date":"2024-02-27T00:14:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/crop_ee40c9cb9e33ffe888365e66e0a104dc195413-2024-02-28.webp","permalink":"https://cuterwrite.top/p/science-plot/","title":"科研图表绘制"},{"content":"RDMA 基本服务类型 本文欢迎非商业转载，转载请注明出处。\n声明：仅用于收藏，便于阅读\n― Savir, 知乎专栏：5. RDMA 基本服务类型 我们在 “3. RDMA 基本元素”\r一文中提到过，RDMA 的基本通信单元是 QP，而基于 QP 的通信模型有很多种，我们在 RDMA 领域称其为“服务类型”。IB 协议中通过“可靠”和“连接”两个维度来描述一种服务类型。\n可靠 通信中的可靠性指的是通过一些机制保证发出去的数据包都能够被正常接收。IB 协议中是这样描述可靠服务的：\nReliable Service provides a guarantee that messages are delivered from a requester to a responder at most once, in order and without corruption.\n即“可靠服务在发送和接受者之间保证了信息最多只会传递一次，并且能够保证其按照发送顺序完整的被接收”。\nIB 通过以下三个机制来保证可靠性：\n应答机制 假设 A 给 B 发了一个数据包，A 怎样才能知道 B 收到了呢，自然是 B 回复一个“我收到了”消息给 A。在通信领域我们一般称这个回复为应答包或者 ACK（Acknowledge）。在 IB 协议的可靠服务类型中，使用了应答机制来保证数据包被对方收到。IB 的可靠服务类型中，接收方不是每一个包都必须回复，也可以一次回复多个包的 ACK，以后我们再展开讨论。\n数据校验机制 这个比较好理解，发端会对 Header 和 Payload（有效载荷，也就是真正要收发的数据）通过一定的算法得到一个校验值放到数据包的末尾。对端收到数据包后，也会用相同的算法计算出校验值，然后与数据包中的校验值比对，如果不一致，说明数据中包含错误（一般是链路问题导致的），那么接收端就会丢弃这个数据包。IB 协议使用的 CRC 校验，本文对 CRC 不做展开介绍。\n保序机制 保序指的是，保证先被发送到物理链路上的数据包一定要先于后发送的数据包被接收方收到。有一些业务对数据包的先后顺序是有严格要求的，比如语音或者视频。IB 协议中有 PSN（Packet Sequence Number，包序号）的概念，即每个包都有一个递增的编号。PSN 可以用来检测是否丢包，比如收端收到了 1，但是在没收到 2 的情况下就收到了 3，那么其就会认为传输过程中发生了错误，之后会回复一个 NAK 给发端，让其重发丢失的包。\n不可靠服务，没有上述这些机制来保证数据包被正确的接收，属于“发出去就行，我不关心有没有被收到”的服务类型。\n连接与数据报 连接（Connection） 在这里指的是一个抽象的逻辑概念，需要区别于物理连接，熟悉 Socket 的读者一定对这个其不陌生。连接是一条通信的“管道”，一旦管道建立好了，管道这端发出的数据一定会沿着这条管道到达另一端。\n对于“连接”或者说“面向连接”的定义有很多种，有的侧重于保证消息顺序，有的侧重于消息的传递路径唯一，有的强调需要软硬件开销来维护连接，有的还和可靠性的概念有交集。本专栏既然是介绍 RDMA 技术，那么我们就看一下 IB 协议 3.2.2 节中对其的描述：\nIBA supports both connection oriented and datagram service. For connected service, each QP is associated with exactly one remote consumer. In this case the QP context is configured with the identity of the remote consumer’s queue pair. \u0026hellip; During the communication establishment process, this and other information is exchanged between the two nodes.\n即“IBA 支持基于连接和数据报的服务。对于基于连接的服务来说，每个 QP 都和另一个远端节点相关联。在这种情况下，QP Context 中包含有远端节点的 QP 信息。在建立通信的过程中，两个节点会交换包括稍后用于通信的 QP 在内的对端信息\u0026quot;。\n上面这端描述中的 Context 一般被翻译成上下文，QP Context（简称 QPC）可以简单理解为是记录一个 QP 相关信息的表格。我们知道 QP 是两个队列，除了这两个队列之外，我们还需要把关于 QP 的信息记录到一张表里面，这些信息可能包括队列的深度，队列的编号等等，后面我们会展开讲。\n可能还是有点抽象，我们用图说话：\nA、B 和 A、C 节点的网卡在物理上是连接在一起的，A 上面的 QP2 和 B 上面的 QP7、A 上面的 QP4 和 B 上面的 QP2 建立了逻辑上的连接，或者说“绑定到了一起”。在连接服务类型中的每个 QP，都和唯一的另一个 QP 建立了连接，也就是说 QP 下发的每个 WQE 的目的地都是唯一的。拿上图来说，对于 A 的 QP2 下发的每个 WQE，硬件都可以通过 QPC 得知其目的为 B 的 QP7，就会把组装好的数据包发送给 B，然后 B 会根据 QP7 下发的 RQ WQE 来存放数据；同理，对于 A 的 QP4 下发的每个 WQE，A 的硬件都知道应该把数据发给 Node C 的 QP2。\n“连接”是如何维护的呢？其实就是在 QPC 里面的一个记录而已。如果 A 的 QP2 想断开与 B 的 QP7 的“连接”然后与其他 QP 相“连接”，只需要修改 QPC 就可以了。两个节点在建立连接的过程中，会交换稍后用于数据交互的 QP Number，然后分别记录在 QPC 中。\n数据报（Datagram） 与连接相反，发端和收端间不需要“建立管道”的步骤，只要发端到收端物理上是可以到达的，那么我就可能从任何路径发给任意的收端节点。IB 协议对其的定义是这样的：\nFor datagram service, a QP is not tied to a single remote consumer, but rather information in the WQE identifies the destination. A communication setup process similar to the connection setup process needs to occur with each destination to exchange that information.\n即“对于数据报服务来说，QP 不会跟一个唯一的远端节点绑定，而是通过 WQE 来指定目的节点。和连接类型的服务一样，建立通信的过程也需要两端交换对端信息，但是数据报服务对于每个目的节点都需要执行一次这个交换过程。”\n我们举个例子：\n在数据报类型的 QP 的 Context 中，不包含对端信息，即每个 QP 不跟另一个 QP 绑定。QP 下发给硬件的每个 WQE 都可能指向不同的目的地。比如节点 A 的 QP2 下发的第一个 WQE，指示给节点 C 的 QP3 发数据；而下一个 WQE，可以指示硬件发给节点 B 的 QP7。\n与连接服务类型一样，本端 QP 可以和哪个对端 QP 发送数据，是在准备阶段提前通过某些方式相互告知的。这也是上文“数据报服务对于每个目的节点都需要执行一次这个交换过程”的含义。\n服务类型 上面介绍的两个维度两两组合就形成了 IB 的四种基本服务类型：\n可靠(Reliable) 不可靠(Unreliable) 连接(Connection) RC（Reliable Connection） UC（Unreliable Connection） 数据报(Datagram) RD（Reliable Datagram） UD（Unreliable Datagram） RC 和 UD 是应用最多也是最基础的两种服务类型，我们可以将他们分别类比成 TCP/IP 协议栈传输层的 TCP 和 UDP。\nRC 用于对数据完整性和可靠性要求较高的场景，跟 TCP 一样，因为需要各种机制来保证可靠，所以开销自然会大一些。另外由于 RC 服务类型和每个节点间需要各自维护一个 QP，假设有 N 个节点要相互通信，那么至少需要 N * (N - 1) 个 QP，而 QP 和 QPC 本身是需要占用网卡资源或者内存的，当节点数很多时，存储资源消耗将会非常大。\nUD 硬件开销小并且节省存储资源，比如 N 个节点需要相互通信，只需要创建 N 个 QP 就可以了，但是可靠性跟 UDP 一样没法保证。用户如果想基于 UD 服务类型实现可靠性，那么需要自己基于 IB 传输层实现应用层的可靠传输机制。\n除此之外，还有 RD 和 UC 类型，以及 XRC（Extended Reliable Connection），SRD（Scalable Reliable Datagram）等更复杂的服务类型，我们将在协议解析部分对其进行详细的描述。\n更多关于 QP 类型选择的信息可以参考 RDMAmojo 上的Which Queue Pair type to use?\r这篇文章，感谢 @sinkinben\r同学在评论区指路。\n代码示例 在 RDMA 编程中，我们可以通过 ibv_create_qp 函数来创建 QP，其中的 struct ibv_qp_init_attr 结构体中的 qp_type 字段就是用来指定 QP 的服务类型的。下面是一个简单的示例代码：\nstruct ibv_qp_init_attr qp_init_attr;\rqp_init_attr.qp_type = IBV_QPT_RC; // RC 类型\rqp_init_attr.sq_sig_all = 1; // 1 表示 SQ 中的每个 WQE 都需要对应的接收一个 CQE\rqp_init_attr.send_cq = cq; // 发送 CQ\rqp_init_attr.recv_cq = cq; // 接收 CQ\rqp_init_attr.cap.max_send_wr = 1024; // SQ 的深度\rstruct ibv_qp *qp = ibv_create_qp(pd, \u0026amp;qp_init_attr);\r","date":"2024-02-25T22:04:01Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/f71da3ec40dd74648e15471d47ba3b84195413_crop-2024-02-26.webp","permalink":"https://cuterwrite.top/p/rdma-service-types/","title":"RDMA 基本服务类型"},{"content":"RDMA 操作类型 本文欢迎非商业转载，转载请注明出处。\n声明：仅用于收藏，便于阅读\n― Savir, 知乎专栏：4. RDMA 操作类型 前面几篇涉及 RDMA 的通信流程时一直在讲 SEND-RECV，然而它其实称不上是“RDMA”，只是一种加入了 0 拷贝和协议栈卸载的传统收发模型的“升级版”，这种操作类型没有完全发挥 RDMA 技术全部实力，常用于两端交换控制信息等场景。当涉及大量数据的收发时，更多使用的是两种 RDMA 独有的操作：WRITE 和 READ。\n我们先来复习下双端操作——SEND 和 RECV，然后再对比介绍单端操作——WRITE 和 READ。\nSEND \u0026amp; RECV SEND 和 RECV 是两种不同的操作类型，但是因为如果一端进行 SEND 操作，对端必须进行 RECV 操作，所以通常都把他们放到一起描述。\n为什么称之为“双端操作”？因为完成一次通信过程需要两端 CPU 的参与，并且收端需要提前显式的下发 WQE。下图是一次 SEND-RECV 操作的过程示意图。原图来自于[1]，我做了一些修改。\n上一篇我们讲过，上层应用通过 WQE（WR）来给硬件下任务。在 SEND-RECV 操作中，不止发送端需要下发 WQE，接收端也需要下发 WQE 来告诉硬件收到的数据需要放到哪个地址。发送端并不知道发送的数据会放到哪里，每次发送数据，接收端都要提前准备好接收 Buffer，而接收端 CPU 自然会感知这一过程。\n为了下文对比 SEND/RECV 与 WRITE/READ 的异同，我们将上一篇的 SEND-RECV 流程中补充内存读写这一环节，即下图中的步骤④——发送端硬件根据 WQE 从内存中取出数据封装成可在链路上传输数据包和步骤⑦——接收端硬件将数据包解析后根据 WQE 将数据放到指定内存区域，其他步骤不再赘述。另外再次强调一下，收发端的步骤未必是图中这个顺序，比如步骤⑧⑪⑫和步骤⑨⑩的先后顺序就是不一定的。\n下面将介绍 WRITE 操作，对比之后相信大家可以理解的更好。\nWRITE WRITE 全称是 RDMA WRITE 操作，是本端主动写入远端内存的行为，除了准备阶段，远端 CPU 不需要参与，也不感知何时有数据写入、数据在何时接收完毕。所以这是一种单端操作。\n通过下图我们对比一下 WRITE 和 SEND-RECV 操作的差异，本端在准备阶段通过数据交互，获取了对端某一片可用的内存的地址和“钥匙” ，相当于获得了这片远端内存的读写权限。拿到权限之后，本端就可以像访问自己的内存一样直接对这一远端内存区域进行读写，这也是 RDMA——远程直接地址访问的内涵所在。\nWRITE/READ 操作中的目的地址和钥匙是如何获取的呢？通常可以通过我们刚刚讲过的 SEND-RECV 操作来完成，因为拿到钥匙这个过程总归是要由远端内存的控制者——CPU 允许的。虽然准备工作还比较复杂， 但是一旦完成准备工作，RDMA 就可以发挥其优势，对大量数据进行读写。一旦远端的 CPU 把内存授权给本端使用，它便不再会参与数据收发的过程，这就解放了远端 CPU，也降低了通信的时延。\n需要注意的是，本端是通过虚拟地址来读写远端内存的，上层应用可以非常方便的对其进行操作。实际的虚拟地址—物理地址的转换是由 RDMA 网卡完成的。具体是如何转换的，将在后面的文章介绍。\n忽略准备阶段 key 和 addr 的获取过程，下面我们描述一次 WRITE 操作的流程，此后我们不再将本端和对端称为“发送”和“接收”端，而是改为“请求”和“响应”端，这样对于描述 WRITE 和 READ 操作都更恰当一些，也不容易产生歧义。\n请求端 APP 以 WQE（WR）的形式下发一次 WRITE 任务。 请求端硬件从 SQ 中取出 WQE，解析信息。 请求端网卡根据 WQE 中的虚拟地址，转换得到物理地址，然后从内存中拿到待发送数据，组装数据包。 请求端网卡将数据包通过物理链路发送给响应端网卡。 响应端收到数据包，解析目的虚拟地址，转换成本地物理地址，解析数据，将数据放置到指定内存区域。 响应端回复 ACK 报文给请求端。 请求端网卡收到 ACK 后，生成 CQE，放置到 CQ 中。 请求端 APP 取得任务完成信息。 注：严谨地说，第 6 步回复 ACK 之时，RDMA 网卡只能保证数据包中的 Payload 已经被”暂存“了下来，但不能保证一定已经把数据放到目的内存里面了。不过这一点不影响我们对整理流程的理解，感谢@nekomii 同学的提醒。\nIB Spec. 9.7.5.1.6 ACKNOWLEDGE MESSAGE SCHEDULING 原文：”For SEND or RDMA WRITE requests, an ACK may be scheduled before data is actually written into the responder’s memory. The ACK simply indicates that the data has successfully reached the fault domain of the responding node. That is, the data has been received by the channel adapter and the channel adapter will write that data to the memory system of the responding node, or the responding application will at least be informed of the failure.“\nREAD 顾名思义，READ 跟 WRITE 是相反的过程，是本端主动读取远端内存的行为。同 WRITE 一样，远端 CPU 不需要参与，也不感知数据在内存中被读取的过程。\n获取 key 和虚拟地址的流程也跟 WRITE 没有区别，需要注意的是 \u0026ldquo;读”这个动作所请求的数据，是在对端回复的报文中携带的。\n下面描述一次 READ 操作的流程，注意跟 WRITE 只是方向和步骤顺序的差别。\n请求端 APP 以 WQE 的形式下发一次 READ 任务。 请求端网卡从 SQ 中取出 WQE，解析信息。 请求端网卡将 READ 请求包通过物理链路发送给响应端网卡。 响应端收到数据包，解析目的虚拟地址，转换成本地物理地址，解析数据，从指定内存区域取出数据。 响应端硬件将数据组装成回复数据包发送到物理链路。 请求端硬件收到数据包，解析提取出数据后放到 READ WQE 指定的内存区域中。 请求端网卡生成 CQE，放置到 CQ 中。 请求端 APP 取得任务完成信息。 总结 我们忽略各种细节进行抽象，RDMA WRITE 和 READ 操作就是在利用网卡完成下面左图的内存拷贝操作而已，只不过复制的过程是由 RDMA 网卡通过网络链路完成的；而本地内存拷贝则如下面右图所示由 CPU 通过总线完成的：\nRDMA 标准定义上述几种操作的时候使用的单词是非常贴切的，“收”和“发”是需要有对端主动参与的语义 ，而‘读“和”写“更像是本端对一个没有主动性的对端进行操作的语义。\n通过对比 SEND/RECV 和 WRITE/READ 操作，我们可以发现传输数据时不需要响应端 CPU 参与的 WRITE/READ 有更大的优势，缺点就是请求端需要在准备阶段获得响应端的一段内存的读写权限。但是实际数据传输时，这个准备阶段的功率和时间损耗都是可以忽略不计的，所以 RDMA WRITE/READ 才是大量传输数据时所应用的操作类型，SEND/RECV 通常只是用来传输一些控制信息。\n除了本文介绍的几种操作之外，还有 ATOMIC 等更复杂一些的操作类型，将在后面的协议解读部分详细分析。本篇就到这里，下一篇将介绍 RDMA 基本服务类型。\n代码示例 本文中的操作类型都是通过 WQE 来下发的，下面是一个简单的例子，展示了如何使用 libibverbs 来创建一个 QP，然后通过 WQE 来下发一个 WRITE 操作。\n#include \u0026lt;infiniband/verbs.h\u0026gt;\r#include \u0026lt;stdio.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\r#include \u0026lt;string.h\u0026gt;\rint main() {\rstruct ibv_device **dev_list = ibv_get_device_list(NULL);\rstruct ibv_context *ctx = ibv_open_device(dev_list[0]);\rstruct ibv_pd *pd = ibv_alloc_pd(ctx);\rstruct ibv_cq *cq = ibv_create_cq(ctx, 10, NULL, NULL, 0);\rstruct ibv_qp *qp;\rstruct ibv_qp_init_attr qp_init_attr = {\r.send_cq = cq,\r.recv_cq = cq,\r.qp_type = IBV_QPT_RC,\r};\rqp = ibv_create_qp(pd, \u0026amp;qp_init_attr);\rstruct ibv_mr *mr;\rchar *buf = malloc(1024);\rmr = ibv_reg_mr(pd, buf, 1024, IBV_ACCESS_LOCAL_WRITE | IBV_ACCESS_REMOTE_WRITE);\rstruct ibv_sge sge = {\r.addr = (uintptr_t)buf,\r.length = 1024,\r.lkey = mr-\u0026gt;lkey,\r};\rstruct ibv_send_wr wr = {\r.wr_id = 1,\r.sg_list = \u0026amp;sge,\r.num_sge = 1,\r.opcode = IBV_WR_RDMA_WRITE,\r.send_flags = IBV_SEND_SIGNALED,\r};\rstruct ibv_send_wr *bad_wr;\ribv_post_send(qp, \u0026amp;wr, \u0026amp;bad_wr);\rreturn 0;\r}\r参考资料 [1] part1-OFA_Training_Sept_2016.pdf\n","date":"2024-02-24T03:09:01Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/bcb5351691a864a6827138cf4c2e0642195413_crop-2024-02-25.webp","permalink":"https://cuterwrite.top/p/rdma-op/","title":"RDMA 操作类型"},{"content":"搭建玄铁 900 系列工具链与 xuantie-qemu 环境 一、搭建平台 Linux 发行版：CentOS Linux release 7.6.1810 (Core) 内核版本：3.10.0-957.el7.x86_64 $ cat /etc/centos-release\rCentOS Linux release 7.6.1810 (Core)\r$ uname -r\r3.10.0-957.el7.x86_64\r二、搭建玄铁 900 系列工具链环境 1. 下载玄铁 900 系列工具链 首先，我们需要下载适用于 RISC-V 架构的 Xuantie GNU 工具链。前往玄铁官网\r获取最新版本的预编译包，并根据你的操作系统进行安装。在 Linux 系统中，通常解压后通过添加 bin 路径到 $PATH 环境变量即可。\n工具链安装包由于执行平台和目标程序平台的不同分为不同的版本，如 Xuantie--elf--x86_64-V*-.tar.gz 是 64 位 linux 平台的 riscv 裸程序工具链套件。具体分类如下：\n根据执行平台 x86_64：64 位 linux 平台 i386：32 位 linux 平台 mingw：Windows Mingw 平台 根据目标程序平台 elf：裸程序编译套件 linux：linux 应用程序编译套件 这里我们下载最新的版本为 2.8.1 的适用于 64 位 linux 平台的 linux 应用程序编译套件，即 Xuantie-900-gcc-linux-5.10.4-glibc-x86_64 。\nwget https://occ-oss-prod.oss-cn-hangzhou.aliyuncs.com/resource//1705395627867/Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.1-20240115.tar.gz\rtar -xzvf Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.1-20240115.tar.gz\rsudo mv Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.1-20240115 /opt\rexport PATH=/opt/Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.1-20240115/bin:$PATH\r2. 验证工具链安装 $ riscv64-unknown-linux-gnu-gcc -v\rUsing built-in specs.\rCOLLECT_GCC=riscv64-unknown-linux-gnu-gcc\rCOLLECT_LTO_WRAPPER=/opt/Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.0/bin/../libexec/gcc/riscv64-unknown-linux-gnu/10.4.0/lto-wrapper\rTarget: riscv64-unknown-linux-gnu\rConfigured with: /mnt/ssd/jenkins_iotsw/slave/workspace/Toolchain/build-gnu-riscv_4/./source/riscv/riscv-gcc/configure --target=riscv64-unknown-linux-gnu --with-gmp=/mnt/ssd/jenkins_iotsw/slave/workspace/Toolchain/build-gnu-riscv_4/build-gcc-riscv64-unknown-linux-gnu/build-Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.0/lib-for-gcc-x86_64-linux --with-mpfr=/mnt/ssd/jenkins_iotsw/slave/workspace/Toolchain/build-gnu-riscv_4/build-gcc-riscv64-unknown-linux-gnu/build-Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.0/lib-for-gcc-x86_64-linux --with-mpc=/mnt/ssd/jenkins_iotsw/slave/workspace/Toolchain/build-gnu-riscv_4/build-gcc-riscv64-unknown-linux-gnu/build-Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.0/lib-for-gcc-x86_64-linux --with-libexpat-prefix=/mnt/ssd/jenkins_iotsw/slave/workspace/Toolchain/build-gnu-riscv_4/build-gcc-riscv64-unknown-linux-gnu/build-Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.0/lib-for-gcc-x86_64-linux --with-libmpfr-prefix=/mnt/ssd/jenkins_iotsw/slave/workspace/Toolchain/build-gnu-riscv_4/build-gcc-riscv64-unknown-linux-gnu/build-Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.0/lib-for-gcc-x86_64-linux --with-pkgversion='Xuantie-900 linux-5.10.4 glibc gcc Toolchain V2.8.0 B-20231018' CXXFLAGS='-g -O2 -DTHEAD_VERSION_NUMBER=2.8.0 ' --prefix=/mnt/ssd/jenkins_iotsw/slave/workspace/Toolchain/build-gnu-riscv_4/build-gcc-riscv64-unknown-linux-gnu/Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.0 --with-sysroot=/mnt/ssd/jenkins_iotsw/slave/workspace/Toolchain/build-gnu-riscv_4/build-gcc-riscv64-unknown-linux-gnu/Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.0/sysroot --with-system-zlib --enable-shared --enable-tls --enable-languages=c,c++,fortran --disable-libmudflap --disable-libssp --disable-libquadmath --enable-libsanitizer --disable-nls --disable-bootstrap --src=/mnt/ssd/jenkins_iotsw/slave/workspace/Toolchain/build-gnu-riscv_4/./source/riscv/riscv-gcc --enable-multilib --with-abi=lp64d --with-arch=rv64gc_zfh_xtheadc 'CFLAGS_FOR_TARGET=-O2 -mcmodel=medany' 'CXXFLAGS_FOR_TARGET=-O2 -mcmodel=medany'\rThread model: posix\rSupported LTO compression algorithms: zlib\rgcc version 10.4.0 (Xuantie-900 linux-5.10.4 glibc gcc Toolchain V2.8.0 B-20231018)\r可以看到输出了 gcc 的版本信息，说明工具链安装成功。\n三、搭建 xuantie-qemu 环境 1. 前提条件 在安装 xuantie-qemu 之前，需要确保系统含有以下工具或库。\ngcc 编译器 automake autoconf libtool glib2 库 其它\u0026hellip;.. 通过以下命令安装上述工具或库。\nsudo yum update -y\rsudo yum install -y autoconf automake libtool make gcc gcc-c++ gawk bison flex texinfo gperf patchutils bc \\\rzlib-devel mpfr-devel gmp-devel curl-devel expat-devel git \\\rglib2-devel libfdt-devel pixman-devel ncurses-devel ncurses-compat-libs\r如果是 Ubuntu/Dedian 系统，可以使用以下命令安装。\nsudo apt-get update\rsudo apt-get install -y autoconf automake autotools-dev curl libmpc-dev libmpfr-dev libgmp-dev \\\rgawk build-essential bison flex texinfo gperf libtool patchutils bc \\\rzlib1g-dev libexpat-dev git \\\rlibglib2.0-dev libfdt-dev libpixman-1-dev \\\rlibncurses5-dev libncursesw5-dev\r2. 下载并安装 xuantie-qemu 访问 Xuantie QEMU 官方仓库\r，获取适用于玄铁 900 系列芯片的 xuantie-qemu 源代码，然后按照常规步骤编译安装：\ngit clone https://github.com/T-head-Semi/qemu.git\rgit checkout xuantie-qemu-6.1.0\r3. 编译安装 xuantie-qemu cd qemu\rmkdir build\rcd build\r../configure --target-list=riscv64-softmmu,riscv64-linux-user --prefix=/opt/qemu/6.1.0-xuantie\rmake -j $(nproc)\rsudo make install\rexport PATH=/opt/qemu/6.1.0-xuantie/bin:$PATH\r4. 验证 xuantie-qemu 安装 安装完毕后如果执行如下命令后能够查看到 qemu 的具体版本，则说明安装成功\n$ qemu-riscv64 --version\rqemu-riscv64 version 6.0.94 (v6.1.0-12-g03813c9)\rCopyright (c) 2003-2021 Fabrice Bellard and the QEMU Project developers\r编写一段 C 语言程序，如下所示：\n#include \u0026lt;stdio.h\u0026gt;\rint main() {\rprintf(\u0026quot;Hello RISC-V \\n\u0026quot;);\rreturn 0;\r}\r使用 Xuantie 900 系列工具链编译该程序，并使用用户模式的 xuantie-qemu 运行程序。\n$ riscv64-unknown-linux-gnu-gcc -static -o hello hello.c\r$ qemu-riscv64 ./hello\rHello RISC-V\r再写一段 RVV 向量化的 C 语言程序，如下所示：\nRVV 向量化 C 语言程序\r#include \u0026lt;riscv_vector.h\u0026gt;\r#include \u0026lt;stdio.h\u0026gt;\r#define N 15\rfloat vsum(float* v, int n) {\rvfloat32m1_t vs, vv, vtmp;\rfloat s = 0.0;\rint i;\rint vlmax;\rvlmax = vsetvlmax_e32m1();\rprintf(\u0026quot;vlmax:%d\\n\u0026quot;, vlmax);\rvs = vfmv_v_f_f32m1(0.0, vlmax);\rvtmp = vfmv_v_f_f32m1(0.0, vlmax);\rfor (i = 0; i \u0026lt; n - vlmax; i += vlmax) {\rvv = vle32_v_f32m1(\u0026amp;v[i], vlmax);\rvtmp = vfadd_vv_f32m1(vtmp, vv, vlmax);\r}\rvs = vfredusum_vs_f32m1_f32m1(vs, vtmp, vs, vlmax);\rs = vfmv_f_s_f32m1_f32(vs);\rfor (; i \u0026lt; n; i++) {\rs += v[i];\r}\rreturn s;\r}\rfloat vsum1(float* v, int n) {\rvfloat32m1_t vs, vv;\rfloat s;\rint i;\rint vl, vlmax;\rvlmax = vsetvlmax_e32m1();\rvs = vfmv_v_f_f32m1(0.0, vlmax);\rfor (i = 0; n \u0026gt; 0; i += vl, n -= vl) {\rvl = vsetvl_e32m1(n);\rprintf(\u0026quot;vl:%d\\n\u0026quot;, vl);\rvv = vle32_v_f32m1(\u0026amp;v[i], vl);\rvs = vfredusum_vs_f32m1_f32m1(vs, vv, vs, vl);\r}\rs = vfmv_f_s_f32m1_f32(vs);\rreturn s;\r}\rfloat vsum2(float* v, int n) {\rvfloat32m2_t vv;\rvfloat32m1_t vs;\rfloat s;\rint i;\rint vl, vlmax;\rvlmax = vsetvlmax_e32m1();\rvs = vfmv_v_f_f32m1(0.0, vlmax);\rfor (i = 0; n \u0026gt; 0; i += vl, n -= vl) {\rvl = vsetvl_e32m2(n);\rprintf(\u0026quot;vl:%d\\n\u0026quot;, vl);\rvv = vle32_v_f32m2(\u0026amp;v[i], vl);\rvs = vfredusum_vs_f32m2_f32m1(vs, vv, vs, vl);\r}\rs = vfmv_f_s_f32m1_f32(vs);\rreturn s;\r}\rint main() {\rint i;\rfloat v[N], sum = 0.0;\rprintf(\u0026quot;Hello RISC-V!\\n\u0026quot;);\rfor (i = 0; i \u0026lt; N; i++) {\rv[i] = i;\r}\rsum = vsum(v, N);\rprintf(\u0026quot;%f\\n\u0026quot;, sum);\rreturn 0;\r}\r编译并运行该程序（这时需要指定 -cpu ，否则会报非法指定的异常，即 Illegal instruction (core dumped)）：\n$ riscv64-unknown-linux-gnu-gcc -static -O3 -march=rv64imafdcv0p7_zfh_xtheadc -o test_vec test_vec.c\r$ qemu-riscv64 -cpu c920 ./test_vec\rHello RISC-V!\rvlmax:4\r105.000000\r四、在 QEMU 上运行 RISC-V 64 位 Linux 系统 1. 制作内核 1.1 下载内核源码 $ wget https://mirrors.edge.kernel.org/pub/linux/kernel/v5.x/linux-5.10.42.tar.gz\r$ tar -xzvf linux-5.10.42.tar.gz\r下载后进入内核源码目录\n$ cd linux-5.10.42\r1.2 配置和编译内核 $ make ARCH=riscv CROSS_COMPILE=riscv64-unknown-linux-gnu- defconfig\r$ make ARCH=riscv CROSS_COMPILE=riscv64-unknown-linux-gnu- -j $(nproc)\r...\rAR drivers/built-in.a\rGEN .version\rCHK include/generated/compile.h\rLD vmlinux.o\rMODPOST vmlinux.symvers\rMODINFO modules.builtin.modinfo\rGEN modules.builtin\rLD .tmp_vmlinux.kallsyms1\rKSYMS .tmp_vmlinux.kallsyms1.S\rAS .tmp_vmlinux.kallsyms1.S\rLD .tmp_vmlinux.kallsyms2\rKSYMS .tmp_vmlinux.kallsyms2.S\rAS .tmp_vmlinux.kallsyms2.S\rLD vmlinux\rSYSMAP System.map\rMODPOST modules-only.symvers\rGEN Module.symvers\rCC [M] fs/efivarfs/efivarfs.mod.o\rOBJCOPY arch/riscv/boot/Image\rGZIP arch/riscv/boot/Image.gz\rLD [M] fs/efivarfs/efivarfs.ko\rKernel: arch/riscv/boot/Image.gz is ready\r2. 制作 rootfs 2.1 下载 busybox 源码 $ wget https://busybox.net/downloads/busybox-1.33.1.tar.bz2\r下载完后进入 busybox 源码目录\ncd busybox-1.33.1\r2.2 配置 busybox $ make ARCH=riscv CROSS_COMPILE=riscv64-unknown-linux-gnu- defconfig\r$ make ARCH=riscv CROSS_COMPILE=riscv64-unknown-linux-gnu- menuconfig\r打开配置菜单后进入第一行的 \u0026ldquo;Settings\u0026rdquo;，在 \u0026ldquo;Build Options\u0026rdquo; 节中，选中 “Build static binary (no shared libs)”，设置好后退出保存配置。\n检查 .config 文件中是否有 CONFIG_STATIC=y ，如果没有则手动添加。\n2.3 编译和安装 busybox $ make ARCH=riscv CROSS_COMPILE=riscv64-unknown-linux-gnu- -j $(nproc)\r$ make ARCH=riscv CROSS_COMPILE=riscv64-unknown-linux-gnu- install\r此时源码目录 busyboxsource 下会新出现一个 _install 目录 ，可以看到生成的东西。\n$ ls _install\rbin linuxrc sbin usr\r进入 _install 目录，创建以下目录\n$ cd _install\r$ mkdir proc sys dev etc etc/init.d\r$ ls\rbin dev etc linuxrc proc sbin sys usr\r然后另外再新建一个最简单的 init 的 RC 文件：\n$ cd etc/init.d/\r$ touch rcS\r$ vim rcS\r编辑该文件内容为：\n#!/bin/sh\rmount -t proc none /proc\rmount -t sysfs none /sys\r/sbin/mdev -s\r然后修改 rcS 文件权限，加上可执行权限\n$ chmod +x rcS\r2.4 制作文件系统 继续在 _install 目录下执行如下命令：\n$ find -print0 | cpio -0oH newc | gzip -9 \u0026gt; ../rootfs.img\r3276 blocks\r3. 启动运行 创建一个新的目录，将编译好的内核 Image 和制作好的 rootfs.img 移动到该目录下。\n$ mkdir riscv64-linux\r$ cd riscv64-linux\r$ cp ../linux-5.10.42/arch/riscv/boot/Image .\r$ cp ../busybox-1.33.1/rootfs.img .\r执行如下命令：\n$ qemu-system-riscv64 \\\r-nographic -machine virt \\\r-kernel Image \\\r-initrd rootfs.img \\\r-append \u0026quot;root=/dev/ram rdinit=/sbin/init\u0026quot;\r将显示 Linux Kernel 启动流程：\n点击展开\rOpenSBI v0.9\r____ _____ ____ _____\r/ __ \\ / ____| _ \\_ _|\r| | | |_ __ ___ _ __ | (___ | |_) || |\r| | | | '_ \\ / _ \\ '_ \\ \\___ \\| _ \u0026lt; | |\r| |__| | |_) | __/ | | |____) | |_) || |_\r\\____/| .__/ \\___|_| |_|_____/|____/_____|\r| |\r|_|\rPlatform Name : riscv-virtio,qemu\rPlatform Features : timer,mfdeleg\rPlatform HART Count : 1\rFirmware Base : 0x80000000\rFirmware Size : 100 KB\rRuntime SBI Version : 0.2\rDomain0 Name : root\rDomain0 Boot HART : 0\rDomain0 HARTs : 0*\rDomain0 Region00 : 0x0000000080000000-0x000000008001ffff ()\rDomain0 Region01 : 0x0000000000000000-0xffffffffffffffff (R,W,X)\rDomain0 Next Address : 0x0000000080200000\rDomain0 Next Arg1 : 0x0000000087000000\rDomain0 Next Mode : S-mode\rDomain0 SysReset : yes\rBoot HART ID : 0\rBoot HART Domain : root\rBoot HART ISA : rv64imafdcvsu\rBoot HART Features : scounteren,mcounteren,time\rBoot HART PMP Count : 16\rBoot HART PMP Granularity : 4\rBoot HART PMP Address Bits: 54\rBoot HART MHPM Count : 0\rBoot HART MHPM Count : 0\rBoot HART MIDELEG : 0x0000000000000222\rBoot HART MEDELEG : 0x000000000000b109\r[ 0.000000] Linux version 5.10.42 (root@centos) (riscv64-unknown-linux-gnu-gcc (Xuantie-900 linux-5.10.4 glibc gcc Toolchain V2.8.0 B-20231018) 10.4.0, GNU ld (GNU Binutils) 2.35) #1 SMP Wed Feb 21 02:07:46 CST 2024\r[ 0.000000] OF: fdt: Ignoring memory range 0x80000000 - 0x80200000\r[ 0.000000] efi: UEFI not found.\r[ 0.000000] Initial ramdisk at: 0x(____ptrval____) (1085440 bytes)\r[ 0.000000] Zone ranges:\r[ 0.000000] DMA32 [mem 0x0000000080200000-0x0000000087ffffff]\r[ 0.000000] Normal empty\r[ 0.000000] Movable zone start for each node\r[ 0.000000] Early memory node ranges\r[ 0.000000] node 0: [mem 0x0000000080200000-0x0000000087ffffff]\r[ 0.000000] Initmem setup node 0 [mem 0x0000000080200000-0x0000000087ffffff]\r[ 0.000000] software IO TLB: Cannot allocate buffer\r[ 0.000000] SBI specification v0.2 detected\r[ 0.000000] SBI implementation ID=0x1 Version=0x9\r[ 0.000000] SBI v0.2 TIME extension detected\r[ 0.000000] SBI v0.2 IPI extension detected\r[ 0.000000] SBI v0.2 RFENCE extension detected\r[ 0.000000] SBI v0.2 HSM extension detected\r[ 0.000000] riscv: ISA extensions acdfimsuv\r[ 0.000000] riscv: ELF capabilities acdfim\r[ 0.000000] percpu: Embedded 17 pages/cpu s32360 r8192 d29080 u69632\r[ 0.000000] Built 1 zonelists, mobility grouping on. Total pages: 31815\r[ 0.000000] Kernel command line: root=/dev/ram rdinit=/sbin/init\r[ 0.000000] Dentry cache hash table entries: 16384 (order: 5, 131072 bytes, linear)\r[ 0.000000] Inode-cache hash table entries: 8192 (order: 4, 65536 bytes, linear)\r[ 0.000000] Sorting __ex_table...\r[ 0.000000] mem auto-init: stack:off, heap alloc:off, heap free:off\r[ 0.000000] Memory: 108240K/129024K available (7084K kernel code, 3993K rwdata, 4096K rodata, 223K init, 342K bss, 20784K reserved, 0K cma-reserved)\r[ 0.000000] Virtual kernel memory layout:\r[ 0.000000] fixmap : 0xffffffcefee00000 - 0xffffffceff000000 (2048 kB)\r[ 0.000000] pci io : 0xffffffceff000000 - 0xffffffcf00000000 ( 16 MB)\r[ 0.000000] vmemmap : 0xffffffcf00000000 - 0xffffffcfffffffff (4095 MB)\r[ 0.000000] vmalloc : 0xffffffd000000000 - 0xffffffdfffffffff (65535 MB)\r[ 0.000000] lowmem : 0xffffffe000000000 - 0xffffffe007e00000 ( 126 MB)\r[ 0.000000] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=1, Nodes=1\r[ 0.000000] rcu: Hierarchical RCU implementation.\r[ 0.000000] rcu: RCU restricting CPUs from NR_CPUS=8 to nr_cpu_ids=1.\r[ 0.000000] rcu: RCU debug extended QS entry/exit.\r[ 0.000000] Tracing variant of Tasks RCU enabled.\r[ 0.000000] rcu: RCU calculated value of scheduler-enlistment delay is 25 jiffies.\r[ 0.000000] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=1\r[ 0.000000] NR_IRQS: 64, nr_irqs: 64, preallocated irqs: 0\r[ 0.000000] riscv-intc: 64 local interrupts mapped\r[ 0.000000] plic: plic@c000000: mapped 53 interrupts with 1 handlers for 2 contexts.\r[ 0.000000] random: get_random_bytes called from start_kernel+0x31a/0x48c with crng_init=0\r[ 0.000000] riscv_timer_init_dt: Registering clocksource cpuid [0] hartid [0]\r[ 0.000000] clocksource: riscv_clocksource: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns\r[ 0.000150] sched_clock: 64 bits at 10MHz, resolution 100ns, wraps every 4398046511100ns\r[ 0.003557] Console: colour dummy device 80x25\r[ 0.008887] printk: console [tty0] enabled\r[ 0.012368] Calibrating delay loop (skipped), value calculated using timer frequency.. 20.00 BogoMIPS (lpj=40000)\r[ 0.012666] pid_max: default: 32768 minimum: 301\r[ 0.014227] Mount-cache hash table entries: 512 (order: 0, 4096 bytes, linear)\r[ 0.014306] Mountpoint-cache hash table entries: 512 (order: 0, 4096 bytes, linear)\r[ 0.040922] rcu: Hierarchical SRCU implementation.\r[ 0.042741] EFI services will not be available.\r[ 0.044926] smp: Bringing up secondary CPUs ...\r[ 0.045062] smp: Brought up 1 node, 1 CPU\r[ 0.054128] devtmpfs: initialized\r[ 0.061463] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 7645041785100000 ns\r[ 0.061753] futex hash table entries: 256 (order: 2, 16384 bytes, linear)\r[ 0.067460] NET: Registered protocol family 16\r[ 0.131233] vgaarb: loaded\r[ 0.132530] SCSI subsystem initialized\r[ 0.134485] usbcore: registered new interface driver usbfs\r[ 0.134834] usbcore: registered new interface driver hub\r[ 0.135035] usbcore: registered new device driver usb\r[ 0.150024] clocksource: Switched to clocksource riscv_clocksource\r[ 0.167109] NET: Registered protocol family 2\r[ 0.168330] IP idents hash table entries: 2048 (order: 2, 16384 bytes, linear)\r[ 0.172076] tcp_listen_portaddr_hash hash table entries: 128 (order: 0, 5120 bytes, linear)\r[ 0.172242] TCP established hash table entries: 1024 (order: 1, 8192 bytes, linear)\r[ 0.172480] TCP bind hash table entries: 1024 (order: 3, 32768 bytes, linear)\r[ 0.172690] TCP: Hash tables configured (established 1024 bind 1024)\r[ 0.173861] UDP hash table entries: 256 (order: 2, 24576 bytes, linear)\r[ 0.174481] UDP-Lite hash table entries: 256 (order: 2, 24576 bytes, linear)\r[ 0.175963] NET: Registered protocol family 1\r[ 0.179024] RPC: Registered named UNIX socket transport module.\r[ 0.179111] RPC: Registered udp transport module.\r[ 0.179150] RPC: Registered tcp transport module.\r[ 0.179186] RPC: Registered tcp NFSv4.1 backchannel transport module.\r[ 0.179332] PCI: CLS 0 bytes, default 64\r[ 0.182716] Unpacking initramfs...\r[ 0.263706] Freeing initrd memory: 1056K\r[ 0.265678] workingset: timestamp_bits=62 max_order=15 bucket_order=0\r[ 0.281052] NFS: Registering the id_resolver key type\r[ 0.282003] Key type id_resolver registered\r[ 0.282074] Key type id_legacy registered\r[ 0.282505] nfs4filelayout_init: NFSv4 File Layout Driver Registering...\r[ 0.282631] nfs4flexfilelayout_init: NFSv4 Flexfile Layout Driver Registering...\r[ 0.283481] 9p: Installing v9fs 9p2000 file system support\r[ 0.284918] NET: Registered protocol family 38\r[ 0.285416] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 251)\r[ 0.285593] io scheduler mq-deadline registered\r[ 0.285692] io scheduler kyber registered\r[ 0.295484] pci-host-generic 30000000.pci: host bridge /soc/pci@30000000 ranges:\r[ 0.296336] pci-host-generic 30000000.pci: IO 0x0003000000..0x000300ffff -\u0026gt; 0x0000000000\r[ 0.296861] pci-host-generic 30000000.pci: MEM 0x0040000000..0x007fffffff -\u0026gt; 0x0040000000\r[ 0.296961] pci-host-generic 30000000.pci: MEM 0x0400000000..0x07ffffffff -\u0026gt; 0x0400000000\r[ 0.299940] pci-host-generic 30000000.pci: ECAM at [mem 0x30000000-0x3fffffff] for [bus 00-ff]\r[ 0.301083] pci-host-generic 30000000.pci: PCI host bridge to bus 0000:00\r[ 0.301328] pci_bus 0000:00: root bus resource [bus 00-ff]\r[ 0.301486] pci_bus 0000:00: root bus resource [io 0x0000-0xffff]\r[ 0.301528] pci_bus 0000:00: root bus resource [mem 0x40000000-0x7fffffff]\r[ 0.301568] pci_bus 0000:00: root bus resource [mem 0x400000000-0x7ffffffff]\r[ 0.302864] pci 0000:00:00.0: [1b36:0008] type 00 class 0x060000\r[ 0.377412] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled\r[ 0.389894] 10000000.uart: ttyS0 at MMIO 0x10000000 (irq = 2, base_baud = 230400) is a 16550A\r[ 0.428017] printk: console [ttyS0] enabled\r[ 0.430410] [drm] radeon kernel modesetting enabled.\r[ 0.457312] loop: module loaded\r[ 0.460726] libphy: Fixed MDIO Bus: probed\r[ 0.464996] e1000e: Intel(R) PRO/1000 Network Driver\r[ 0.465383] e1000e: Copyright(c) 1999 - 2015 Intel Corporation.\r[ 0.466272] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver\r[ 0.466724] ehci-pci: EHCI PCI platform driver\r[ 0.467203] ehci-platform: EHCI generic platform driver\r[ 0.467683] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver\r[ 0.468129] ohci-pci: OHCI PCI platform driver\r[ 0.468593] ohci-platform: OHCI generic platform driver\r[ 0.469968] usbcore: registered new interface driver uas\r[ 0.470477] usbcore: registered new interface driver usb-storage\r[ 0.471603] mousedev: PS/2 mouse device common for all mice\r[ 0.475055] goldfish_rtc 101000.rtc: registered as rtc0\r[ 0.476070] goldfish_rtc 101000.rtc: setting system clock to 2024-02-20T19:37:51 UTC (1708457871)\r[ 0.478889] syscon-poweroff soc:poweroff: pm_power_off already claimed (____ptrval____) sbi_shutdown\r[ 0.479494] syscon-poweroff: probe of soc:poweroff failed with error -16\r[ 0.480977] usbcore: registered new interface driver usbhid\r[ 0.481324] usbhid: USB HID core driver\r[ 0.483516] NET: Registered protocol family 10\r[ 0.491589] Segment Routing with IPv6\r[ 0.492256] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver\r[ 0.495528] NET: Registered protocol family 17\r[ 0.497086] 9pnet: Installing 9P2000 support\r[ 0.497667] Key type dns_resolver registered\r[ 0.498706] debug_vm_pgtable: [debug_vm_pgtable ]: Validating architecture page table helpers\r[ 0.533266] Freeing unused kernel memory: 220K\r[ 0.539682] Run /sbin/init as init process\rPlease press Enter to activate this console.\r见到 \u0026quot;Please press Enter to activate this console.\u0026quot; 提示后直接回车，无需密码就进入系统了。\n执行几个常用命令测试一下，都能正常工作：\n/ # ls\rbin etc proc sbin usr\rdev linuxrc root sys\r/ # pwd\r/\r/ # cd bin\r/bin #\r/ # ls\rarch dumpkmap kill netstat setarch\rash echo link nice setpriv\rbase32 ed linux32 nuke setserial\rbase64 egrep linux64 pidof sh\rbusybox false ln ping sleep\rcat fatattr login ping6 stat\rchattr fdflush ls pipe_progress stty\rchgrp fgrep lsattr printenv su\rchmod fsync lzop ps sync\rchown getopt makemime pwd tar\rconspy grep mkdir reformime touch\rcp gunzip mknod resume true\rcpio gzip mktemp rev umount\rcttyhack hostname more rm uname\rdate hush mount rmdir usleep\rdd ionice mountpoint rpm vi\rdf iostat mpstat run-parts watch\rdmesg ipcalc mt scriptreplay zcat\rdnsdomainname kbd_mode mv sed\r/bin #\r退出 QEMU 的方法是按下 Ctrl + A ，松开后再按下 x 键即可退出 QEMU 。\n如果想要往 QEMU 里面传输文件，可以使用挂载的方式，如下所示：\n$ mkdir rootfs\r$ sudo mount -o loop rootfs.img rootfs\r$ cp [-r] [file] ./rootfs/\r$ sudo umount rootfs\r五、总结 至此，我们已经成功搭建了玄铁 900 系列的工具链环境以及 xuantie-qemu 仿真环境，这为后续的开发、编译、链接以及运行和调试基于玄铁 900 系列芯片的 RISC-V 应用程序奠定了基础。\n","date":"2024-02-20T01:51:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/59aa9fecb7e1a3a2b2c88811e6360647195413.jpg@1256w_774h_!web-article-pic-2024-02-20.webp","permalink":"https://cuterwrite.top/p/thead-tools/","title":"搭建玄铁 900 系列工具链与 xuantie-qemu 环境"},{"content":"OpenMP 简介 简介 什么是 OpenMP？ OpenMP（Open Multi-Processing）是一种广泛应用的多线程并行编程模型，它为共享内存系统上的并行计算提供了丰富的指令集和 API。起源于 1997 年，OpenMP 由多个领先硬件和软件供应商共同制定标准，旨在简化并行程序的设计与实现过程，以充分利用现代多核处理器的计算能力。\nOpenMP 支持多种编程语言，包括 C、C++ 以及 Fortran 等，并通过在源代码中插入特定的编译指示（pragma），使得开发者能够轻松地将串行代码转化为高效的并行代码。其主要优势在于其简洁性和易用性，允许程序员使用熟悉的编程语言和开发环境，同时提供良好的可移植性和扩展性。\nOpenMP 由非营利性组织管理，由多家软硬件厂家参与，包括 Arm，IBM，Intel，AMD，NVIDIA，Cray，Oracle 等。\n历史版本 在 官网页面\r可以查询到 OpenMP 的历史版本和发布日期。 版本 发布日期 Fortran 1.0 October 1997 C/C++ 1.0 October 1998 C/C++ 2.0 March 2002 OpenMP 2.5 May 2005 OpenMP 3.0 May 2008 OpenMP 3.1 July 2011 OpenMP 4.0 July 2013 OpenMP 4.5 November 2015 OpenMP 5.0 November 2018 OpenMP 5.1 November 2020 OpenMP 5.2 November 2021 基础知识 技术框架 OpenMP 技术框架 OpenMP Runtime Library 是 OpenMP 规范中定义的一组函数和运行时支持结构，它是 OpenMP 并行编程框架的关键组成部分。这个库在编译器的支持下与用户程序链接，在程序执行时负责管理线程的创建、同步、调度以及数据共享等任务。它实现了 OpenMP 编译指导所指示的所有并行化机制。\nOpenMP Runtime Library 包括了如下功能：\n线程管理（创建、销毁、同步） = 工作共享（动态工作分配给各个线程） = 任务调度 = 同步原语（如 barriers, locks, atomic operations） = 动态调整线程数量 内存模型支持（数据环境变量、private, shared, reduction 变量等） Compiler Directives 编译指导是以 #pragma omp 开头的预处理器指令，程序员在源代码中插入这些指令来指导编译器如何将串行程序转换为并行程序。例如，使用 #pragma omp parallel 指令定义一个并行区域，编译器会在此区域内生成多线程执行逻辑。\nEnvironment Variables 环境变量是 OpenMP 运行时库的一部分，它们用于控制运行时行为，例如线程数量、调度策略等。\nOpenMP Library 是一组函数库，包括了一些用于线程同步、原子操作、锁、并行循环等的函数。这些函数可以在用户程序中直接调用，以实现更细粒度的并行化。\n总的来说，OpenMP 技术框架包括了编译器指导、运行时库、环境变量和函数库等多个组成部分，它们共同构成了一个完整的并行编程环境，共同协作以支持在共享内存系统上的并行编程。\n执行模型：Fork-Join Model OpenMP 的执行模型采用的是 Fork-Join 机制，这是一种用于并行编程中的同步原语模型。在该模型下，程序执行遵循以下步骤：\nFork（派生）阶段： 程序开始时以单个主线程执行，当遇到 OpenMP 编译指导（pragma）指示的并行区域时，主线程会通过 Runtime Library 创建一个或多个工作线程（worker threads）。这些工作线程是对主线程的派生，每个线程负责执行并行区域内的部分任务。并行区域可以是循环、段（sections）、单一任务或其他可并行化的代码块。\nParallel Execution（并行执行）阶段： 创建出的工作线程独立并发地执行分配给它们的任务，并且能够访问共享的数据结构。OpenMP 提供了一套丰富的指令来管理数据的同步和通信，确保在多线程环境下的正确性和一致性。\nJoin（合并）阶段： 当所有工作线程完成其在并行区域内的任务后，它们会自动或者通过显式同步指令（如 omp barrier ）汇聚到 join 点。在此阶段，所有线程等待直至所有其他线程都到达了同步点，随后 join 操作发生。这意味着主线程和其他工作线程重新同步，恢复为串行执行模式或继续执行后续的非并行代码。\nSynchronization and Data Consistency（同步与数据一致性）： Fork-Join 模型确保了在并行执行过程中，通过适当的锁机制、原子操作和同步原语保证了对共享资源的互斥访问以及数据的一致性。\n总结来说，OpenMP 的 Fork-Join 执行模型是一种基于动态线程创建和同步的并行处理框架，它允许开发者方便地将串行代码转化为并行执行的代码片段，同时简化了并行编程中常见的复杂性，如线程管理和数据同步问题。\n线程与进程 进程\n每个进程都有自己独立的地址空间 CPU 在进程间切换时需要进行上下文切换 线程\n一个进程下的线程共享相同的地址空间 CPU 在线程之间切换开销较小 操作系统的线程设计\n现代操作系统如 Linux、Windows 等都支持一个进程下有多个线程。 线程是操作系统调度的基本单位，进程是资源分配的基本单位。 操作系统的线程设计 线程的硬件调度 硬件调度机制与操作系统协同，负责将线程智能地映射至可用的 CPU 物理核心上执行。 因此，在多线程应用中，当活跃线程数超过了实际 CPU 物理核心的数量时，操作系统将不得不进行密集的上下文切换，以确保多个线程在有限的核心资源上交替运行，这种线程竞争过载的现象会导致整体性能瓶颈和效率下降。 超线程技术（Hyper-Threading） 通过在单个物理 CPU 核心上虚拟化出额外的逻辑处理单元，当前通常配置为每个物理核心承载两个逻辑核心。这些逻辑核心能够并行执行独立的任务流，尽管它们共享同一物理核心的基础计算资源，如执行引擎、缓存和其他底层硬件结构。通过这种方式，超线程旨在提高资源利用率和并发处理能力，尤其是在存在大量并行任务且其对计算资源需求相对较小的情况下，可以有效提升系统的总体吞吐量。然而，在某些高度依赖单一核心性能或内存带宽的应用场景下，如部分对 CPU 敏感的游戏或特定类型的数据密集型运算，增加逻辑核心可能并不一定能带来显著的性能提升。 硬件的内存模型 在现代多核处理器体系结构中，每个 CPU 核心为了进一步提升数据访问速度，在与主存之间设计有多级缓存层次结构。最靠近 CPU 核心的是 L1 缓存，通常其后是 L2 缓存，部分高端架构还包含 L3 缓存，这些高速缓存层级存储容量逐层增大，但访问延迟逐层增加。 L1 和 L2 缓存通常是与特定 CPU 核心紧密耦合且私有的，这意味着每个核心拥有自己的独立缓存空间，以降低数据访问冲突并提高缓存命中率。L1 缓存由于距离计算单元最近，其访问速度最快，但容量最小；而 L2 缓存作为 L1 缓存的有效补充，具有相对较大的容量。 为确保在多核环境中不同 CPU 核心的缓存中对共享数据的一致性，硬件和操作系统共同实现了缓存一致性协议（如 MESI 协议）。这种机制允许系统自动维护一个全局一致的数据视图，即使数据在多个核心的缓存中存在副本也能保证它们同步更新，这一特性在某些架构中被称作 ccNUMA（cache-coherent non-uniform memory access） ，即缓存一致性非统一内存访问。 然而，这种缓存一致性管理也带来了一些挑战，其中之一就是“伪共享”(False Sharing)问题。当不同的线程修改位于同一缓存行内的各自独立变量时，尽管这些变量本身并无关联，但由于它们物理上相邻而被存储在同一缓存行内，因此任何针对其中一个变量的写操作都会导致整个缓存行失效并在所有核心间重新同步。这会引发不必要的缓存无效化与重新填充操作，从而显著降低性能。解决伪共享问题通常需要精心设计数据布局或利用缓存行对齐等技术手段来避免无关数据之间的争用。 典型的现代 CPU 内存结构 线程亲和性和线程绑定 线程亲和性（Thread Affinity）是指操作系统或应用程序控制特定线程与处理器核心之间关联的能力。在多核或多处理器系统中，线程亲和性允许程序员或调度器决定将某个线程固定在特定的 CPU 核心上运行，而不是让操作系统自由地在所有可用的核心间进行动态调度。这种机制有助于减少上下文切换开销，提高缓存命中率，并且对于需要保持数据局部性的并行计算任务特别有益。 线程绑定（Thread Pinning）是实现线程亲和性的具体技术手段，它指明了将特定线程与特定硬件资源（如 CPU 核心或 NUMA 节点）之间的强制关联。通过线程绑定，可以确保指定的线程始终在其分配的核心上执行，避免被操作系统迁移到其他核心，从而优化性能、减少延迟并解决伪共享等问题。在 OpenMP 等并行编程模型中，可以通过相关的环境变量或编译指导来设置线程绑定策略，以适应不同的并行计算需求和硬件特性。 同一个插槽上的 CPU 对 L3 缓存的访问延迟是一致的，但不同插槽上的 CPU 对 L3 缓存的访问延迟是不一致的。因此，线程绑定的目的是为了减少线程在不同 CPU 之间的迁移，从而减少访存延迟。 线程亲和性和线程绑定 OpenMP 支持控制线程的绑定 环境变量 OMP_PROC_BIND 或从句 proc_bind(master|close|spread) 控制线程绑定与否，以及线程对于绑定单元（称为 place）分布 OpenMP 编程 安装 对于 Linux 系统，GCC 是常用的编译器，现代版本的 GCC 一般已默认支持 OpenMP。例如在 Ubuntu 20.04 LTS 上，可以通过以下命令安装含有 OpenMP 的 build-essential 包：\n$ sudo apt-get update\r$ sudo apt-get install -y build-essential\r查看 OpenMP 版本 $ echo |cpp -fopenmp -dM |grep -i open\r#define _OPENMP 201511\r编译使用 直接在编译语句中添加 -fopenmp 选项即可开启 OpenMP 支持。 g++ -O2 -std=c++17 -fopenmp hello.cpp -o hello\r如果使用 CMake 构建项目, 加入 -Wunknown-pragmas 选项可以在编译时报告未处理的 #pragma 指令。 find_package(OpenMP REQUIRED)\radd_compile_options(-Wunknown-pragmas)\radd_executable(hello hello.cpp)\rtarget_link_libraries(hello PRIVATE OpenMP::OpenMP_CXX)\rHello World! 第一个 OpenMP 程序 #include \u0026lt;omp.h\u0026gt;\r#include \u0026lt;stdio.h\u0026gt;\rint main() {\r#pragma omp parallel num_threads(8)\r{\rint id = omp_get_thread_num();\rint num_threads = omp_get_num_threads();\rprintf(\u0026quot;Hello World from thread %d of %d \\n\u0026quot;, id, num_threads);\r}\rreturn 0;\r}\r运行结果 $ gcc -fopenmp hello.c -o hello\r$ ./hello\rHello World from thread 7 of 8\rHello World from thread 6 of 8\rHello World from thread 0 of 8\rHello World from thread 3 of 8\rHello World from thread 1 of 8\rHello World from thread 2 of 8\rHello World from thread 5 of 8\rHello World from thread 4 of 8\r同一类 openmp 制导语句称为一种构造(construct) 形式为 #pragma omp \u0026lt;directive name\u0026gt; \u0026lt;clause\u0026gt; 使用 {} 包裹的代码块称为并行区域(parallel region) 线程数设置 优先级由低到高 什么都不做，系统选择运行线程数 设置环境变量 export OMP_NUM_THREADS=4 代码中使用库函数 void omp_set_num_threads(int) 通过制导语句 num_threads(4) if 从句判断串行还是并行执行 常用库函数 设置并行区运行线程数：void omp_set_num_threads(int) 获取并行区运行线程数：int omp_get_num_threads() 获取当前线程编号：int omp_get_thread_num() 获得 OpenMP Wall Clock 时间（单位：秒）：double omp_get_wtime() 获得时间精度：double omp_get_wtick() Parallel 构造 支持的从句\nif(scalar_expression)：如果 scalar_expression 为真，则并行执行，否则串行执行。 num_threads(integer_expression)：指定并行区域中的线程数。 default(shared|none)：指定变量的默认共享性。 shared：所有变量默认为共享。 none：无默认变量类型，每个变量都需要显式声明共享或私有。 shared(list)：指定共享变量列表。 共享变量在内存中只有一份，所有线程都可以访问。 请保证共享变量访问不会冲突。 不特别指定并行区变量默认为 shared。 private(list)：指定私有变量列表。 私有变量在每个线程中都有一份独立的拷贝。 变量需要 重新初始化。 firstprivate(list)：指定首次私有变量列表。 同 private 对变量根据主线程中的数据进行初始化。 示例 1： no clause、private、firstprivate\nint results[4];\rint cnt;\rcnt = 1;\r#pragma omp parallel num_threads(4)\r{\rint tid = omp_get_thread_num();\rfor (int i = 0; i \u0026lt; 4; i++) {\rcnt += 1;\r}\rresults[tid] = cnt;\r}\rprintf(\u0026quot;no clause: \u0026quot;);\rfor (int i = 0; i \u0026lt; 4; i++) {\rprintf(\u0026quot;%d \u0026quot;, results[i]);\r}\rprintf(\u0026quot;\\n\u0026quot;);\rcnt = 1;\r#pragma omp parallel num_threads(4) private(cnt)\r{\rint tid = omp_get_thread_num();\rfor (int i = 0; i \u0026lt; 4; i++) {\rcnt += 1;\r}\rresults[tid] = cnt;\r}\rprintf(\u0026quot;private(not init): \u0026quot;);\rfor (int i = 0; i \u0026lt; 4; i++) {\rprintf(\u0026quot;%d \u0026quot;, results[i]);\r}\rprintf(\u0026quot;\\n\u0026quot;);\rcnt = 1;\r#pragma omp parallel num_threads(4) firstprivate(cnt)\r{\rint tid = omp_get_thread_num();\rfor (int i = 0; i \u0026lt; 4; i++) {\rcnt += 1;\r}\rresults[tid] = cnt;\r}\rprintf(\u0026quot;firstprivate: \u0026quot;);\rfor (int i = 0; i \u0026lt; 4; i++) {\rprintf(\u0026quot;%d \u0026quot;, results[i]);\r}\rprintf(\u0026quot;\\n\u0026quot;);\r打印结果 no clause: 5 9 13 17\rprivate(not init): 4 1572916964 1572916964 1572916964\rfirstprivate: 5 5 5 5\rFor 构造 最常用的并行化构造之一 示例 2：并行化 for 循环\n#pragma omp parallel num_threads(8)\r{\rint tid = omp_get_thread_num();\rint num_threads = omp_get_num_threads();\r#pragma omp for\rfor (int i = 0; i \u0026lt; num_threads; i++) {\r#pragma omp ordered\rprintf(\u0026quot;Hello from thread %d of %d \\n\u0026quot;, tid, num_threads);\r}\r}\r打印结果 Hello from thread 0 of 8\rHello from thread 1 of 8\rHello from thread 2 of 8\rHello from thread 3 of 8\rHello from thread 4 of 8\rHello from thread 5 of 8\rHello from thread 6 of 8\rHello from thread 7 of 8\r在并行区内对 for 循环进行线程划分，且 for 循环满足格式要求 init-expr:需要是 var=lb 形式，类型也有限制 test-expr:限制为 var relational-opb 或者 b relational-op var incr-expr:仅限加减法 Parallel for 构造 常常将 parallel 和 for 结合使用，合并为 parallel for 制导语句 parallel for parallel for if ✅ ❌ ✅ num_threads ✅ ❌ ✅ default ✅ ❌ ✅ copyin ✅ ❌ ✅ private ✅ ✅ ✅ firstprivate ✅ ✅ ✅ shared ✅ ✅ ✅ reduction ✅ ✅ ✅ lastprivate ❌ ✅ ✅ schedule ❌ ✅ ✅ ordered ❌ ✅ ✅ collapse ❌ ✅ ✅ nowait ❌ ✅ ❌ lastprivate(list)\n同 private 执行完 for 循环后，将最后一个线程的值赋给主线程的变量。 nowait：取消代码块结束时的栅栏同步(barrier)\ncollapse(n)：应用于 n 重循环，合并(展开)循环\n注意循环之间是否有数据依赖 ordered：声明有潜在的顺序执行部分\n使用 #pragma omp ordered 标记顺序执行代码(搭配使用) ordered 区内的语句任意时刻仅由最多一个线程执行 shedule(type[,chunk])\ntype：指定循环迭代的调度策略 static：静态调度，chunk 大小固定（默认 n/p ） dynamic：动态调度，chunk 大小固定（默认为 1） guided：引导调度，chunk 大小动态调整 runtime：由系统环境变量 OMP_SCHEDULE 指定 auto：自动调度 chunk：指定每个线程获取的迭代次数 特殊的数据从句：Reduction 在 OpenMP 中，reduction 是一种并行编程技术，用于解决多线程环境下的数据竞争问题，特别是在计算全局变量的累加或类似操作时。当多个线程需要同时修改同一个共享变量，并且这些修改可以通过某种二元运算符（如加法、乘法等）将所有线程的结果合并成一个最终结果时，可以使用 reduction 子句。\n具体来说，reducton 的执行过程为：\nfork 线程并分配任务 每一个线程定义一个私有变量 omp_priv 同 private。 各个线程执行计算 所有 omp_priv 和 omp_in 一起顺序进行 reduction，写回原变量。 相比之下，atomic 是 OpenMP 提供的另一种同步机制，它确保对单个内存位置的访问在多线程环境中是原子性的，即一次只允许一个线程对该内存位置进行读取或写入操作。通过 #pragma omp atomic 指令，可以保证一条简单的赋值语句（或某些特定类型的读改写操作）在并发环境下不会发生数据竞争。\n示例 3：Reduction\nint sum = 0;\rdouble start = omp_get_wtime();\r#pragma omp parallel for num_threads(8) reduction(+ : sum)\rfor (int i = 0; i \u0026lt; 100000; i++) {\rsum += i;\r}\rprintf(\u0026quot;sum = %d\\n\u0026quot;, sum);\rprintf(\u0026quot;Reduction time: %.5lf s\\n\u0026quot;, omp_get_wtime() - start);\r// no reduction\rsum = 0;\rstart = omp_get_wtime();\r#pragma omp parallel for num_threads(8)\rfor (int i = 0; i \u0026lt; 100000; i++) {\r#pragma omp atomic\rsum += i;\r}\rprintf(\u0026quot;sum = %d\\n\u0026quot;, sum);\rprintf(\u0026quot;Atomic time: %.5lf s\\n\u0026quot;, omp_get_wtime() - start);\rreturn 0;\r打印结果 sum = 704982704\rReduction time: 0.00062 s\rsum = 704982704\rAtomic time: 0.01021 s\r两者结果相同，但是 reduction 的执行时间更短，这是因为 reduction 通过为每个线程分配一个私有副本，线程可以在其私有空间内自由地执行归约操作，而不需要在更新全局结果时与其他线程争夺锁资源，加上高效的数据合并方法等。 OpenMP reducton operation 同步构造 Sections 构造 将并行区的代码块划分为多个 section 分配执行。 可以搭配 parallel 合成为 parallel sections 构造。 每个 section 由一个线程执行 线程数大于 section 数目：部分线程空闲 线程数小于 section 数目：部分线程分配多个 section 示例代码： #pragma omp sections\r{\r#pragma omp section\rmethod1();\r#pragma omp section\rmethod2();\r}\rBarrier 构造 在特定位置进行栅栏同步 在存在数据依赖的情况下，可以使用 barrier 保证数据的一致性 Barrier 同步示意图 Single 构造 用于标记只有一个线程执行的代码块，带有隐式的 barrier 同步，可以使用 nowait 取消隐式的 barrier 同步。 pragma single Atomic 构造 用于保证对共享变量的原子操作，避免数据竞争。 False Sharing 伪共享简单来说就是指多个线程同时访问同一缓存行的不同部分，导致缓存行的无效化和重新填充，从而降低了程序的性能。 不同核心对同一 Cache line 的同时读写会造成严重的冲突，导致改级缓存失效。 False Sharing 问题 在 OpenMP 中，解决伪共享的方法主要有： 数据结构对齐 ：通过使用编译器提供的对齐指令或关键字确保相关变量分别处于不同的缓存行中。例如，在 C++中可以使用 alignas 关键字来指定变量的内存对齐方式，确保每个线程的数据独立位于不同的缓存行。 增大缓存行之间的间距 ：在相邻变量之间插入足够的填充空间，使得它们不会出现在同一个缓存行内。 避免无意义的竞争 ：设计算法和数据结构以减少不必要的共享数据访问。如果可能，尽量让线程操作各自独立的数据段。 自定义内存分配 ：使用特殊的内存分配函数，确保分配的连续内存区域对齐到缓存行边界，这样分配给不同线程的数据就不会落在同一缓存行上。 在某些情况下，可以利用特定平台提供的硬件特性或者编译器支持的扩展，比如 Intel 的 __declspec(align(#)) 属性（对于 MSVC）或者 __attribute__((aligned(#)))（对于 GCC/Clang）。 也可以通过控制变量的作用域或者利用动态创建私有副本等技术来间接避免伪共享问题。 任务构造 除了 Fork-Join 模型外，OpenMP 还支持任务并行模型，通过 task 制导语句来实现。 即动态地管理线程池和任务池，线程池中的线程可以动态地获取任务池中的任务进行执行，从而实现任务的并行执行。 示例 4：任务并行\n#include \u0026lt;iostream\u0026gt;\r#include \u0026lt;omp.h\u0026gt;\r#include \u0026lt;unistd.h\u0026gt;\r#include \u0026lt;iomanip\u0026gt;\rvoid big_task(int i) {\rsleep(10);\r}\rvoid small_task(int i) {\rsleep(1);\r}\rint main() {\rint ntasks = 8;\rdouble start = omp_get_wtime();\r#pragma omp parallel\r{\r#pragma omp single\r{\rstd::cout \u0026lt;\u0026lt; \u0026quot;Task 0 Created\u0026quot; \u0026lt;\u0026lt; std::endl;\r#pragma omp task\rbig_task(0);\rstd::cout \u0026lt;\u0026lt; \u0026quot;Task 1 Created\u0026quot; \u0026lt;\u0026lt; std::endl;\r#pragma omp task\rbig_task(1);\rfor (int i = 2; i \u0026lt; ntasks; i++) {\rstd::cout \u0026lt;\u0026lt; \u0026quot;Task \u0026quot; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026quot; Created\u0026quot; \u0026lt;\u0026lt; std::endl;\r#pragma omp task\rsmall_task(i);\r}\r}\r#pragma omp taskwait\r}\rstd::cout \u0026lt;\u0026lt; \u0026quot;All tasks finished\u0026quot; \u0026lt;\u0026lt; std::endl;\rstd::cout \u0026lt;\u0026lt; \u0026quot;Time: \u0026quot; \u0026lt;\u0026lt; std::fixed \u0026lt;\u0026lt; std::setprecision(2) \u0026lt;\u0026lt; omp_get_wtime() - start \u0026lt;\u0026lt; \u0026quot;s\u0026quot; \u0026lt;\u0026lt; std::endl;\rreturn 0;\r}\r运行结果 $ g++ -fopenmp task.cpp -o task\r$ ./task\rTask 0 Created\rTask 1 Created\rTask 2 Created\rTask 3 Created\rTask 4 Created\rTask 5 Created\rTask 6 Created\rTask 7 Created\rAll tasks finished\rTime: 10.00s\r这段代码中，我们使用了 #pragma omp task 制导语句来创建任务，任务的执行由线程池中的线程动态获取并执行。在任务创建后，我们使用 #pragma omp taskwait 来等待所有任务执行完毕。达到了一个异步执行的效果。 向量化：SIMD 构造 SIMD（Single Instruction, Multiple Data）是一种并行计算模式，它通过一条指令同时对多个数据进行操作，从而实现高效的数据并行计算。 在 OpenMP 中，可以使用 #pragma omp simd 制导语句来实现向量化并行计算。 aligned 用于列出内存对齐的指针 safelen 用于标记循环展开时的数据依赖 linear 用于标记循环变量的线性关系 编译器例如 gcc 也自带向量化功能，一般使用以下编译选项 -O3 -ffast-math -fivopts -march=native -fopt-info-vec -fopt-info-vec-missed ","date":"2024-02-19T01:36:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/c17b7451a44c1d4370d5ba2b966298ea195413_crop-2024-02-19.webp","permalink":"https://cuterwrite.top/p/openmp-intro/","title":"OpenMP 简介"},{"content":"RDMA 基本元素 本文欢迎非商业转载，转载请注明出处。\n声明：仅用于收藏，便于阅读\n― Savir, 知乎专栏：3. RDMA 基本元素 RDMA 技术中经常使用缩略语，很容易让刚接触的人一头雾水，本篇的目的是讲解 RDMA 中最基本的元素及其含义。\n我将常见的缩略语对照表写在前面，阅读的时候如果忘记了可以翻到前面查阅。\nWQ Work Queue 简称 WQ，是 RDMA 技术中最重要的概念之一。WQ 是一个储存工作请求的队列，为了讲清楚 WQ 是什么，我们先介绍这个队列中的元素 WQE（Work Queue Element，工作队列元素）。\nWQE WQE 可以认为是一种“任务说明”，这个工作请求是软件下发给硬件的，这份说明中包含了软件所希望硬件去做的任务以及有关这个任务的详细信息。比如，某一份任务是这样的：“我想把位于地址 0x12345678 的长度为 10 字节的数据发送给对面的节点”，硬件接到任务之后，就会通过 DMA 去内存中取数据，组装数据包，然后发送。\nWQE 的含义应该比较明确了，那么我们最开始提到的 WQ 是什么呢？它就是用来存放“任务书”的“文件夹”，WQ 里面可以容纳很多 WQE。有数据结构基础的读者应该都了解，队列是一种先进先出的数据结构，在计算机系统中非常常见，我们可以用下图表示上文中描述的 WQ 和 WQE 的关系：\nWQ 这个队列总是由软件向其中增加 WQE（入队），硬件从中取出 WQE，这就是软件给硬件“下发任务”的过程。为什么用队列而不是栈？因为进行“存”和“取“操作的分别是软件和硬件，并且需要保证用户的请求按照顺序被处理在 RDMA 技术中，所有的通信请求都要按照上图这种方式告知硬件，这种方式常被称为“Post”。\nQP Queue Pair 简称 QP，就是“一对”WQ 的意思。\nSQ 和 RQ 任何通信过程都要有收发两端，QP 就是一个发送工作队列和一个接受工作队列的组合，这两个队列分别称为 SQ（Send Queue）和 RQ（Receive Queue）。我们再把上面的图丰富一下，左边是发送端，右边是接收端：\nWQ 怎么不见了？SQ 和 RQ 都是 WQ，WQ 只是表示一种可以存储 WQE 的单元，SQ 和 RQ 才是实例。\nSQ 专门用来存放发送任务，RQ 专门用来存放接收任务。在一次 SEND-RECV 流程中，发送端需要把表示一次发送任务的 WQE 放到 SQ 里面。同样的，接收端软件需要给硬件下发一个表示接收任务的 WQE，这样硬件才知道收到数据之后放到内存中的哪个位置。上文我们提到的 Post 操作，对于 SQ 来说称为 Post Send，对于 RQ 来说称为 Post Receive。\n需要注意的是，在 RDMA 技术中通信的基本单元是 QP，而不是节点。如下图所示，对于每个节点来说，每个进程都可以使用若干个 QP，而每个本地 QP 可以“关联”一个远端的 QP。我们用“节点 A 给节点 B 发送数据”并不足以完整的描述一次 RDMA 通信，而应该是类似于“节点 A 上的 QP3 给节点 C 上的 QP4 发送数据”。\n每个节点的每个 QP 都有一个唯一的编号，称为 QPN（Queue Pair Number），通过 QPN 可以唯一确定一个节点上的 QP。\nSRQ Shared Receive Queue 简称 SRQ，意为共享接收队列。概念很好理解，就是一种几个 QP 共享同一个 RQ 时，我们称其为 SRQ。以后我们会了解到，使用 RQ 的情况要远远小于使用 SQ，而每个队列都是要消耗内存资源的。当我们需要使用大量的 QP 时，可以通过 SRQ 来节省内存。如下图所示，QP2~QP4 一起使用同一个 RQ：\nCQ Completion Queue 简称 CQ，意为完成队列。跟 WQ 一样，我们先介绍 CQ 这个队列当中的元素——CQE（Completion Queue Element）。可以认为 CQE 跟 WQE 是相反的概念，如果 WQE 是软件下发给硬件的“任务书”的话，那么 CQE 就是硬件完成任务之后返回给软件的“任务报告”。CQE 中描述了某个任务是被正确无误的执行，还是遇到了错误，如果遇到了错误，那么错误的原因是什么。\n而 CQ 就是承载 CQE 的容器——一个先进先出的队列。我们把表示 WQ 和 WQE 关系的图倒过来画，就得到了 CQ 和 CQE 的关系：\n每个 CQE 都包含某个 WQE 的完成信息，他们的关系如下图所示：\n下面我们把 CQ 和 WQ（QP）放在一起，看一下一次 SEND-RECV 操作中，软硬件的互动（图中序号顺序不表示实际时序）：\n2022/5/23：下图及后面的列表顺序有修改，将原来第 2 条的“接收端硬件从 RQ 中拿到任务书，准备接收数据”移动到“接收端收到数据，进行校验后回复 ACK 报文给发送端”之后，并且修改了描述，现在为第 6 条。\n这里我犯了错误的点是 RQ 和 SQ 不同，是一个“被动接收”的过程，只有收到 Send 报文（或者带立即数的 Write 报文）时硬件才会消耗 RQ WQE。感谢 @连接改变世界 的指正。\n接收端 APP 以 WQE 的形式下发一次 RECV 任务到 RQ。 发送端 APP 以 WQE 的形式下发一次 SEND 任务到 SQ。 发送端硬件从 SQ 中拿到任务书，从内存中拿到待发送数据，组装数据包。 发送端网卡将数据包通过物理链路发送给接收端网卡。 接收端收到数据，进行校验后回复 ACK 报文给发送端。 接收端硬件从 RQ 中取出一个任务书（WQE）。 接收端硬件将数据放到 WQE 中指定的位置，然后生成“任务报告”CQE，放置到 CQ 中。 接收端 APP 取得任务完成信息。 发送端网卡收到 ACK 后，生成 CQE，放置到 CQ 中。 发送端 APP 取得任务完成信息。 NOTE: 需要注意的一点是，上图中的例子是可靠服务类型的交互流程，如果是不可靠服务，那么不会有步骤 5 的 ACK 回复，而且步骤 9 以及之后的步骤会在步骤 5 之后立即触发。关于服务类型以及可靠与不可靠，我们将在《RDMA 基本服务类型》一文中讲解。\n至此，通过 WQ 和 CQ 这两种媒介，两端软硬件共同完成了一次收发过程。\nWR 和 WC 说完了几个 Queue 之后，其实还有两个文章开头提到的概念没有解释，那就是 WR 和 WC（不是 Water Closet 的缩写）。\nWR 全称为 Work Request，意为工作请求；WC 全称 Work Completion，意为工作完成。这两者其实是 WQE 和 CQE 在用户层的“映射”。因为 APP 是通过调用协议栈接口来完成 RDMA 通信的，WQE 和 CQE 本身并不对用户可见，是驱动中的概念。用户真正通过 API 下发的是 WR，收到的是 WC。\nWR/WC 和 WQE/CQE 是相同的概念在不同层次的实体，他们都是“任务书”和“任务报告”。于是我们把前文的两个图又加了点内容：\n代码示例 最后，下面是一个简单的例子，展示了如何使用 libibverbs 来创建一个 QP，然后通过这个 QP 来发送一次数据。这是一个非常简单的例子，只是为了让读者对上文中的概念有一个直观的认识。\n#include \u0026lt;infiniband/verbs.h\u0026gt;\rint main() {\rstruct ibv_context *ctx;\rstruct ibv_pd *pd;\rstruct ibv_cq *cq;\rstruct ibv_qp *qp;\rstruct ibv_mr *mr;\rstruct ibv_sge sge;\rstruct ibv_send_wr wr;\rstruct ibv_send_wr *bad_wr;\rstruct ibv_wc wc;\rctx = ibv_open_device();\rpd = ibv_alloc_pd(ctx);\rcq = ibv_create_cq(ctx, 100, NULL, NULL, 0);\rqp = ibv_create_qp(pd, NULL, NULL);\rmr = ibv_reg_mr(pd, buf, size, IBV_ACCESS_LOCAL_WRITE | IBV_ACCESS_REMOTE_WRITE);\rsge.addr = (uintptr_t)buf;\rsge.length = size;\rsge.lkey = mr-\u0026gt;lkey;\rwr.wr_id = 1;\rwr.sg_list = \u0026amp;sge;\rwr.num_sge = 1;\rwr.opcode = IBV_WR_SEND;\rwr.send_flags = IBV_SEND_SIGNALED;\rwr.next = NULL;\ribv_post_send(qp, \u0026amp;wr, \u0026amp;bad_wr);\ribv_poll_cq(cq, 1, \u0026amp;wc);\rreturn 0;\r}\r总结 好了，我们用 IB 协议[1]3.2.1 中的 Figure 11 这张图总结一下本篇文章的内容：\n用户态的 WR，由驱动转化成了 WQE 填写到了 WQ 中，WQ 可以是负责发送的 SQ，也可以是负责接收的 RQ。硬件会从各个 WQ 中取出 WQE，并根据 WQE 中的要求完成发送或者接收任务。任务完成后，会给这个任务生成一个 CQE 填写到 CQ 中。驱动会从 CQ 中取出 CQE，并转换成 WC 返回给用户。\n基础概念就介绍到这里，下一篇将介绍 RDMA 的几种常见操作类型。\n参考文献 [1]《IB Specification Vol 1-Release-1.3-2015-03-03》\n","date":"2024-02-02T01:01:01Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/73c30b990886bf6988c97858a3e16011195413_crop-2024-02-04.webp","permalink":"https://cuterwrite.top/p/rdma-element/","title":"RDMA 基本元素"},{"content":"比较基于传统以太网与 RDMA 技术的通信 本文欢迎非商业转载，转载请注明出处。\n声明：仅用于收藏，便于阅读\n― Savir, 知乎专栏：2. 比较基于传统以太网与 RDMA 技术的通信 本篇的目的是通过对比一次典型的基于 TCP/IP 协议栈的以太网和 RDMA 通信的过程，直观的展示 RDMA 技术相比传统以太网的优势，尽量不涉及协议和软件实现细节。\n假设本端的某个应用想把自己内存中的数据复制到对端某个应用可以访问的内存中（或者通俗的讲，本端要给对端发送数据），我们来看一下以太网和 RDMA 的 SEND-RECV 语义都做了哪些操作。\n传统以太网 在描述通信过程时的软硬件关系时，我们通常将模型划分为用户层 Userspace，内核 Kernel 以及硬件 Hardware。Userspace 和 Kernel 实际上使用的是同一块物理内存，但是处于安全考虑，Linux 将内存划分为用户空间和内核空间。用户层没有权限访问和修改内核空间的内存内容，只能通过系统调用陷入内核态，Linux 的内存管理机制比较复杂，本文不展开讨论。\n一次典型的基于传统以太网的通信过程的可以如下图所示进行分层：\n一次收-发过程的步骤如下：\n发送端和接收端通过 Socket 库提供的接口建立链接（就是在两个节点间建立了一条逻辑上的道路，数据可以沿这条道路从一端发送到另一端）并分别在内存中申请好发送和接收 Buffer。 发送端 APP 通过 Socket 接口陷入内核态，待发送数据经过 TCP/IP 协议栈的一层层封装，最后被 CPU 复制到 Socket Buffer 中。 发送端通过网卡驱动，告知网卡可以发送数据了，网卡将通过 DMA 从 Buffer 中复制封装好的数据包到内部缓存中，然后将其发送到物理链路。 接收端网卡收到数据包后，将数据包放到接收 Buffer 中，然后 CPU 将通过内核中的 TCP/IP 协议栈对报文进行层层解析，取出有效的数据。 接收端 APP 通过 Socket 接口陷入内核态，CPU 将数据从内核空间复制到用户空间。 这个模型的数据流向大致是像上图这个样子，数据首先需要从用户空间复制一份到内核空间，这一次复制由 CPU 完成，将数据块从用户空间复制到内核空间的 Socket Buffer 中。内核中软件 TCP/IP 协议栈给数据添加各层头部和校验信息。最后网卡会通过 DMA 从内存中复制数据，并通过物理链路发送给对端的网卡。\n而对端是完全相反的过程：硬件将数据包 DMA 拷贝到内存中，然后 CPU 会对数据包进行逐层解析和校验，最后将数据复制到用户空间。\n上述过程中的关键点是需要 CPU 参与的把数据从用户空间拷贝到内核空间，以及同样需要 CPU 全程参与的数据包组装和解析，数据量大的情况下，这将对 CPU 将造成很大的负担。\n下面我们看一下 RDMA 是如何将 CPU“解放”出来的。\nRDMA 同样是一端发送，一端接收的场景，我们将 RDMA 的分层模型分成两部分“控制通路”和“数据通路”，控制通路需要进入内核态准备通信所需的内存资源，而数据通路指的是实际数据交互过程中的流程。这一过程的分层关系如下图所示：\n同 Socket 一样，我们简单描述下通信的过程：\n发送端和接收端分别通过控制通路陷入内核态创建好通信所需要的内存资源。 在数据通路上，接收端 APP 通知硬件准备接收数据，告诉硬件将接收到的数据放在哪片内存中。 在数据通路上，发送端 APP 通知硬件发送数据，告诉硬件待发送数据位于哪片内存中。 发送端 RDMA 网卡从内存中搬移数据，组装报文发送给对端。 对端收到报文，对其进行解析并通过 DMA 将有效载荷写入内存。然后以某种方式通知上层 APP，告知其数据已接收并妥善存放到指定位置。 这一过程中的数据流向大致如上图所示。通过和 Socket 的对比，我们可以明显看到，数据收发绕过了内核并且数据交换过程并不需要 CPU 参与，报文的组装和解析是由硬件完成的。\n通过上面的对比，我们可以明显的体会到 RDMA 的优势，既将 CPU 从数据包封装和解析中解放出来，又减少了 CPU 拷贝数据的功率和时间损耗。需要注意的是，本文只描述了 SEND-RECV 流程，而 RDMA 技术所独有的，效率更高的 WRITE/READ 语义将在后续文章中介绍。\n下一篇我们将介绍一些 RDMA 技术中的重要且基本的概念。\n","date":"2024-02-01T02:01:01Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/cropped_2024010202-2024-02-03.webp","permalink":"https://cuterwrite.top/p/ethernet-vs-rdma/","title":"比较基于传统以太网与 RDMA 技术的通信"},{"content":"编译安装 UCX 1.15.0 与 OpenMPI 5.0.0：详尽指南 一、环境准备 首先，请确保您的系统满足以下基本要求：\n操作系统：支持 Linux（如 Ubuntu 20.04 LTS）或其他类 Unix 操作系统。 开发工具包：安装必要的构建工具和库，例如 build-essential ，libnuma-dev ，pkg-config 等。 内核版本：对于最佳性能，建议使用最新稳定版内核。 需要支持 RDMA 的硬件环境或虚拟环境。 sudo apt-get update\rsudo apt-get install -y build-essential libnuma-dev pkg-config\r二、编译安装 UCX 1.15.0 下载 UCX 源码包： wget https://github.com/openucx/ucx/releases/download/v1.15.0/ucx-1.15.0.tar.gz\rtar -xzvf ucx-1.15.0.tar.gz\rcd ucx-1.15.0\r配置 UCX 编译选项： mkdir build \u0026amp;\u0026amp; cd build\r../configure --prefix=/root/software/ucx/1.5.0\r您可以根据实际需求添加更多配置选项，比如指定特定的网卡类型或者启用特定的功能。\n编译并安装： make -j 8\rmake install\rUCX 架构说明 UCX 1.15.0 的架构如下图所示： 组件 角色 说明 UCP Protocol 实现高级抽象，如标记匹配、流、连接协商和建立、多轨以及处理不同的内存类型。 UCT Transport 实现低级通信原语，如活动消息、远程内存访问和原子操作。 UCM Memory 通用的数据结构、算法和系统实用程序的集合。 UCP Protocol 截获内存注册缓存使用的内存分配和释放事件。 三、编译安装 OpenMPI 5.0.0 下载 OpenMPI 源码包： wget https://download.open-mpi.org/release/open-mpi/v5.0/openmpi-5.0.0.tar.gz\rtar -xzvf openmpi-5.0.0.tar.gz\rcd openmpi-5.0.0\r配置 OpenMPI 编译选项，指定使用 UCX 作为传输层： mkdir build \u0026amp;\u0026amp; cd build\r../configure --without-hcoll \\\r--enable-python-bindings \\\r--enable-mpirun-prefix-by-default \\\r--prefix=/root/software/openmpi/5.0.0-ucx-1.15.0 \\\r--with-ucx=/root/software/ucx/1.15.0 \\\r--enable-mca-no-build=btl-uct\r对于 OpenMPI 4.0 及更高版本，btl_uct 组件可能存在编译错误。该组件对于使用 UCX 来说并不重要；因此可以通过 --enable-mca-no-build=btl-uct 禁用： --enable-python-bindings 选项用于启用 Python 绑定。 --enable-mpirun-prefix-by-default 选项用于在使用 mpirun 启动 MPI 程序时自动添加 --prefix 选项。 --without-hcoll 选项用于禁用 HCOLL 组件。不设置编译时会报错 cannot find -lnuma 与 cannot find -ludev 的错误。 最后配置选项如下：\n编译并安装： make -j 8\rmake install\r四、验证安装与设置环境变量 安装完成后，可以通过运行简单的 MPI 程序来验证 UCX 和 OpenMPI 是否成功集成：\nmpirun -np 2 --mca pml ucx --mca btl ^vader,tcp,openib,uct -x UCX_NET_DEVICES=mlx5_0:1 hostname\r（如果在 root 上运行则需要加上 --allow-run-as-root 选项，如果有 RDMA 设备可以设置 -x UCX_NET_DEVICES ）\n如果需要结合 Slurm 使用，可以参考 Launching with Slurm\r。\n其中一种方式就是，先通过 salloc 分配资源，然后在分配的资源上运行 mpirun 命令。此时 --hostfile 、 --host 、 -n 等是不需要设置的，例如：\nsalloc -n 2\rmpirun --mca pml ucx --mca btl ^vader,tcp,openib,uct -x UCX_NET_DEVICES=mlx5_0:1 hostname\r如果一切正常，您会看到两台主机名的输出。为了方便使用，可以将 OpenMPI 的 bin 目录等添加到系统 PATH 环境变量中：\nvim ~/.bashrc\rexport PATH=/root/software/openmpi/5.0.0-ucx-1.15.0/bin:$PATH\rexport LD_LIBRARY_PATH=/root/software/openmpi/5.0.0-ucx-1.15.0/lib:$LD_LIBRARY_PATH\rexport CPATH=/root/software/openmpi/5.0.0-ucx-1.15.0/include:$CPATH\rexport MANPATH=/root/software/openmpi/5.0.0-ucx-1.15.0/share/man:$MANPATH\rsource ~/.bashrc\r五、UCX 性能测试 发送方：\nucx_perftest -c 0 -d mlx5_0:1\r接收方：\nucx_perftest -c 1 -d mlx5_0:1 \u0026lt;server_hostname\u0026gt; -t tag_lat\r总之，通过以上步骤，我们已经成功地从源代码编译并安装了 UCX 1.15.0 和 OpenMPI 5.0.0，并将其整合为一个高效稳定的高性能计算环境。在实际应用中，可以根据具体需求进一步优化配置以获得更优性能。\n","date":"2024-02-01T01:01:01Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/cropped_2024010204-2024-02-03.webp","permalink":"https://cuterwrite.top/p/openmpi-with-ucx/","title":"编译安装 UCX 1.15.0 与 OpenMPI 5.0.0：详尽指南"},{"content":"GCC-13.2.0 编译安装 GCC 13.1 已被发布为 GCC 13 的第一个稳定版本，作为 GNU 编译器集合的年度功能发布。\nGCC 13.1 是一个重大更新，为那些对一些老式编程感兴趣的人添加了 Modula-2 语言前端，虽然有新的 GCC Rust gccrs 代码，但它在 v13.1 中被禁用。在这个版本，GCC 的静态分析器继续改进，有更多的 C23 和 C++23 功能，并支持许多新的 x86_64/RISC-V/AArch64 处理器。\nGCC 13.1 还提供了对 Ryzen 7000 系列和 EPYC 9004 系列处理器的初始 AMD Zen 4(Znver4)支持，OpenMP 卸载改进，支持以 JSON 为基础的 SARIF 格式发出诊断程序，Ada 2022 附加功能，各种新的 C/C++警告，支持 AMD 本能 MI200 系列用于 AMDGCN 后端，Ampere-1A 支持，Neoverse-V2/Cortex-X3/Cortex-X1C/Cortex-A715 支持，以及许多新的 Intel CPU 支持。GCC 13 增加了针对 Raptor Lake, Meteor Lake, Sierra Forest, Grand Ridge, Emerald Rapids 以及 Granite Rapids 的英特尔 CPU Target，以及相关的新英特尔 CPU 指令集扩展，如 AMX-FP16、AVX-IFMA、AVX-VNNI-INT8、AVX-NE-CONVERT、RAO-INT 和 AMX-Complex。\n为了体验 C++20 的新功能，GCC 13.1 也是一个很好的选择，因为它包括对 C++20 的许多新功能的支持。截止到本文撰写时，GCC-13.2 也已发布，所以我直接选择了最新的版本。\n下载 GCC-13.2.0 源码 下载地址：Index of /gcc/releases/gcc-13.2.0\r下载与解压 GCC-13.2.0 源码\nwget https://mirror.koddos.net/gcc/releases/gcc-13.2.0/gcc-13.2.0.tar.gz\rtar -xzvf gcc-13.2.0.tar.gz\rcd gcc-13.2.0\r开始编译 编译命令： ./contrib/download_prerequisites\rmkdir build \u0026amp;\u0026amp; cd build\r../configure --prefix=/root/software/gcc-13.2.0 \\\r--with-pkgversion='glibc gcc V13.2.0' \\\r--enable-checking=release \\\r--enable-languages=c,c++ \\\r--disable-multilib \\\r--enable-bootstrap \\\r--enable-threads=posix \\\r--with-system-zlib \\\r--with-gmp=$GMP_HOME \\\r--with-mpfr=$MPFR_HOME \\\r--with-mpc=$MPC_HOME \\\rmake -j$(nproc)\rmake install\r设置环境变量 # gcc-13.0.2.env\rexport GCC13_HOME=/root/software/gcc-13.2.0\rexport PATH=$GCC13_HOME/bin:$PATH\rexport LD_LIBRARY_PATH=$GCC13_HOME/lib64:$LD_LIBRARY_PATH\rexport LD_LIBRARY_PATH=$GCC13_HOME/lib:$LD_LIBRARY_PATH\rexport LD_LIBRARY_PATH=$GCC13_HOME/libexec:$LD_LIBRARY_PATH\rexport CPATH=$GCC13_HOME/include:$CPATH\rexport INCLUDE=$GCC13_HOME/include:$CPATH\rexport CC=$GCC13_HOME/bin/gcc\rexport CXX=$GCC13_HOME/bin/g++\rexport FC=$GCC13_HOME/bin/gfortran\rexport F77=$GCC13_HOME/bin/gfortran\rexport F90=$GCC13_HOME/bin/gfortran\rexport F95=$GCC13_HOME/bin/gfortran\r命令行测试 $ gcc -v\r输出结果为：\nUsing built-in specs.\rCOLLECT_GCC=gcc\rCOLLECT_LTO_WRAPPER=/root/software/gcc-13.2.0/libexec/gcc/x86_64-pc-linux-gnu/13.2.0/lto-wrapper\rTarget: x86_64-pc-linux-gnu\rConfigured with: ../configure --prefix=/root/software/gcc-13.2.0 --with-pkgversion='glibc gcc V13.2.0' --enable-checking=release --enable-languages=c,c++,fortran --enable-threads=posix --enable-bootstrap --disable-multilib --with-system-zlib --with-gmp=/root/software/gmp/6.2.1 --with-mpfr=/root/software/mpfr/4.1.0 --with-mpc=/root/software/mpc/1.2.1\rThread model: posix\rSupported LTO compression algorithms: zlib\rgcc version 13.2.0 (glibc gcc V13.2.0)\r即为编译安装成功。\nC++ 20 主要新特性 C++ 20 的主要新特性如下： Concepts（概念）：概念是对模板参数的类型约束，它们使得模板代码更加清晰和易于理解。概念允许开发者定义一个接口，模板参数必须满足这个接口才能被接受。 Ranges（范围库）：这是对标准模板库（STL）的一个重大扩展，它引入了“范围”概念，以支持更加声明式的数据处理方式。 Spaceship Operator(三路比较运算符)：\u0026lt;=\u0026gt;被称为三路比较运算符，它可以一次性比较两个值，返回它们的相对顺序（小于、等于、大于）。 Modules (模块)：模块旨在替代传统的头文件和源文件分离方式，提供一种新的编译单元，可以显著改善编译时间和代码组织。 Coroutines (协程)：协程是一种轻量级的线程，它可以在不同的执行点之间切换，而不是在函数调用之间切换。协程是一种用于编写异步代码的新方法，它允许函数在不同的时间点暂停和恢复执行，而不需要回调函数或复杂的状态机。 constexpr 改进：C++20 大大扩展了可以在编译时计算的代码的范围，包括允许 virtual 函数、try 和 catch 块在 constexpr 函数中使用。 初始化器列表的 std::to_array ：这允许将初始化器列表转换为 std::array ，从而提供了一种类型安全的方式来处理固定大小的数组。 模板语法的简化：typename 和 class 在模板参数中可以互换使用，简化了模板的语法。 新的标准属性：引入了多个新的属性，如 [[likely]] 和 [[unlikely]] ，用于向编译器提供分支预测的提示。 新的标准库组件：例如 std::span ，它提供了一个视图，可以表示数组或其他连续序列的一部分，而不需要复制数据。 新的同步库：例如 std::latch 和 std::barrier ，为多线程编程提供了新的同步原语。 std::format：这是一个新的格式化库，它提供了一种类型安全的方式来格式化字符串。 其它等等 C++ 23 主要新特性 C++ 23 的主要新特性如下： Lambada 修复省略参数括号 () 的问题。 更改 lambda 尾部返回类型的作用域。 让支持函数的 attributes 都支持 lambda。这个功能其实很多编译器早已支持。 编译期计算：主要修复一些 bug 和继续完善编译期计算的能力。 Deducing this : Deducing this 是 C++23 中最重要的特性之一。它其实就是提供一种将非静态成员函数的“隐式对象参数”变为“显式对象参数”的方法。 Deducing this 的主要动机是消除成员函数修饰所带来的冗余。 多维数组： 支持多维下标运算符，即 operator[a, b, c, …]。 标准库引入 std::mdspan。 标准库： 增强 std::string 和 std::string_view 增强 std::optional std::flat_map 和 std::flat_set， 替代 std::map 和 std::set。 std::stacktrace：用于 exception 捕获后，展开调用栈，方便调试。将 stacktrace 引入标准库，可以看作是对 C++ 异常处理能力的加强。 std::excepted：对 C++ 通过返回值进行错误处理的能力加强。和 std::optional 差不多，但是 std::optional 只能表示正常值和空值（std::nullopt）。而 std::expected 则可以表示一个期望的值和一个错误的值，相当于两个成员的 std::variant，但是 std::excepted 的接口使用起来更方便。 std::unreachable()：给编译器的优化提示，告诉编译器这个地方是不可到达的。如果 std::unreachable() 被调用，其结果是 undefined behavior。 其它： 静态 operator() 和 静态 operator[] 假定表达式 [[assume(expr)]] size_t 字面量 Corutines 协程示例 #include \u0026lt;coroutine\u0026gt;\r#include \u0026lt;iostream\u0026gt;\r#include \u0026lt;optional\u0026gt;\rtemplate\u0026lt;typename T\u0026gt;\rstruct Generator {\rstruct promise_type;\rusing handle_type = std::coroutine_handle\u0026lt;promise_type\u0026gt;;\rstruct promise_type {\rstd::optional\u0026lt;T\u0026gt; current_value;\rstatic auto get_return_object_on_allocation_failure() { return Generator{nullptr}; }\rauto get_return_object() { return Generator{handle_type::from_promise(*this)}; }\rauto initial_suspend() { return std::suspend_always{}; }\rauto final_suspend() noexcept { return std::suspend_always{}; }\rvoid unhandled_exception() { std::exit(1); }\rtemplate\u0026lt;typename U\u0026gt;\rauto yield_value(U\u0026amp;\u0026amp; value) {\rcurrent_value = std::forward\u0026lt;U\u0026gt;(value);\rreturn std::suspend_always{};\r}\rvoid return_void() {}\r};\rhandle_type coro;\rGenerator(handle_type h): coro(h) {}\rGenerator(Generator const\u0026amp;) = delete;\rGenerator(Generator\u0026amp;\u0026amp; o) : coro(o.coro) { o.coro = nullptr; }\r~Generator() { if (coro) coro.destroy(); }\rT next() {\rif (coro) {\rcoro.resume();\rif (coro.done()) {\rcoro.promise().current_value.reset();\r}\rreturn *coro.promise().current_value;\r}\rreturn T{};\r}\r};\rGenerator\u0026lt;int\u0026gt; generateNumbers(int start, int end) {\rfor (int i = start; i \u0026lt;= end; ++i) {\rco_yield i;\r}\r}\rint main() {\rauto numbers = generateNumbers(1, 5);\rfor (int i = 1; i \u0026lt;= 5; ++i) {\rstd::cout \u0026lt;\u0026lt; numbers.next() \u0026lt;\u0026lt; std::endl;\r}\rreturn 0;\r}\r编译命令：\ng++ -o coroutines coroutines.cpp -std=c++20 -fcoroutines -O3\r运行结果:\n./coroutines\r1\r2\r3\r4\r5\rDeducing this 示例 #include \u0026lt;iostream\u0026gt;\rstruct Test {\rtemplate \u0026lt;typename Self\u0026gt;\rvoid explicitCall(this Self\u0026amp;\u0026amp; self, const std::string\u0026amp; text) {\rstd::cout \u0026lt;\u0026lt; text \u0026lt;\u0026lt; \u0026quot;: \u0026quot;;\rstd::forward\u0026lt;Self\u0026gt;(self).implicitCall();\rstd::cout \u0026lt;\u0026lt; '\\n';\r}\rvoid implicitCall() \u0026amp; {\rstd::cout \u0026lt;\u0026lt; \u0026quot;non const lvalue\u0026quot;;\r}\rvoid implicitCall() const\u0026amp; {\rstd::cout \u0026lt;\u0026lt; \u0026quot;const lvalue\u0026quot;;\r}\rvoid implicitCall() \u0026amp;\u0026amp; {\rstd::cout \u0026lt;\u0026lt; \u0026quot;non const rvalue\u0026quot;;\r}\rvoid implicitCall() const\u0026amp;\u0026amp; {\rstd::cout \u0026lt;\u0026lt; \u0026quot;const rvalue\u0026quot;;\r}\r};\rint main() {\rstd::cout \u0026lt;\u0026lt; '\\n';\rTest test;\rconst Test constTest;\rtest.explicitCall(\u0026quot;test\u0026quot;);\rconstTest.explicitCall(\u0026quot;constTest\u0026quot;);\rstd::move(test).explicitCall(\u0026quot;std::move(test)\u0026quot;);\rstd::move(constTest).explicitCall(\u0026quot;std::move(consTest)\u0026quot;);\rstd::cout \u0026lt;\u0026lt; '\\n';\r}\r","date":"2024-01-30T11:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/cropped-2024-01-30.webp","permalink":"https://cuterwrite.top/p/gcc-13-source-install/","title":"GCC-13.2.0 编译安装"},{"content":"RDMA 概述 本文欢迎非商业转载，转载请注明出处。\n声明：仅用于收藏，便于阅读\n― Savir, 知乎专栏：1. RDMA 概述 本想完全靠自己的语言完成这篇概述，然而开篇并没有想象当中的好写，看样子从宏观上概括一个技术比从微观上探究细枝末节要困难不少。本文是以前人们对 RDMA 技术的介绍为主，加入了一些自己的理解。随着本专栏内容的增加，本篇概述也会更新和逐渐完善。\n什么是 DMA DMA 全称为 Direct Memory Access，即直接内存访问。意思是外设对内存的读写过程可以不用 CPU 参与而直接进行。我们先来看一下没有 DMA 的时候：\n无 DMA 控制器时 I/O 设备和内存间的数据路径 假设 I/O 设备为一个普通网卡，为了从内存拿到需要发送的数据，然后组装数据包发送到物理链路上，网卡需要通过总线告知 CPU 自己的数据请求。然后 CPU 将会把内存缓冲区中的数据复制到自己内部的寄存器中，再复制到 I/O 设备的存储空间中。如果数据量比较大，那么很长一段时间内 CPU 都会忙于搬移数据，而无法投入到其他工作中去。\nCPU 的最主要工作是计算，而不是进行数据复制，这种工作属于白白浪费了它的计算能力。为了给 CPU“减负”，让它投入到更有意义的工作中去，后来人们设计了 DMA 机制：\n有 DMA 控制器时 I/O 设备和内存间的数据路径 可以看到总线上又挂了一个 DMA 控制器，它是专门用来读写内存的设备。有了它以后，当我们的网卡想要从内存中拷贝数据时，除了一些必要的控制命令外，整个数据复制过程都是由 DMA 控制器完成的。过程跟 CPU 复制是一样的，只不过这次是把内存中的数据通过总线复制到 DMA 控制器内部的寄存器中，再复制到 I/O 设备的存储空间中。CPU 除了关注一下这个过程的开始和结束以外，其他时间可以去做其他事情。\nDMA 控制器一般是和 I/O 设备在一起的，也就是说一块网卡中既有负责数据收发的模块，也有 DMA 模块。\n什么是 RDMA RDMA（ Remote Direct Memory Access ）意为远程直接地址访问，通过 RDMA，本端节点可以“直接”访问远端节点的内存。所谓直接，指的是可以像访问本地内存一样，绕过传统以太网复杂的 TCP/IP 网络协议栈读写远端内存，而这个过程对端是不感知的，而且这个读写过程的大部分工作是由硬件而不是软件完成的。\n为了能够直观的理解这一过程，请看下面两个图（图中箭头仅做示意，不表示实际逻辑或物理关系）：\n传统网络中，“节点 A 给节点 B 发消息”实际上做的是“把节点 A 内存中的一段数据，通过网络链路搬移到节点 B 的内存中”，而这一过程无论是发端还是收段，都需要 CPU 的指挥和控制，包括网卡的控制，中断的处理，报文的封装和解析等等。\n上图中左边的节点在内存用户空间中的数据，需要经过 CPU 拷贝到内核空间的缓冲区中，然后才可以被网卡访问，这期间数据会经过软件实现的 TCP/IP 协议栈，加上各层头部和校验码，比如 TCP 头，IP 头等。网卡通过 DMA 拷贝内核中的数据到网卡内部的缓冲区中，进行处理后通过物理链路发送给对端。\n对端收到数据后，会进行相反的过程：从网卡内部存储空间，将数据通过 DMA 拷贝到内存内核空间的缓冲区中，然后 CPU 会通过 TCP/IP 协议栈对其进行解析，将数据取出来拷贝到用户空间中。\n可以看到，即使有了 DMA 技术，上述过程还是对 CPU 有较强的依赖。\n而使用了 RDMA 技术之后，这一过程可以简单的表示成下面的示意图：\n同样是把本端内存中的一段数据，复制到对端内存中，在使用了 RDMA 技术时，两端的 CPU 几乎不用参与数据传输过程（只参与控制面）。本端的网卡直接从内存的用户空间 DMA 拷贝数据到内部存储空间，然后硬件进行各层报文的组装后，通过物理链路发送到对端网卡。对端的 RDMA 网卡收到数据后，剥离各层报文头和校验码，通过 DMA 将数据直接拷贝到用户空间内存中。\nRDMA 的优势 RDMA 主要应用在高性能计算（HPC）领域和大型数据中心当中，并且设备相对普通以太网卡要昂贵不少（比如 Mellanox 公司的 Connext-X 5 100Gb PCIe 网卡市价在 4000 元以上）。由于使用场景和价格的原因，RDMA 与普通开发者和消费者的距离较远，目前主要是一些大型互联网企业在部署和使用。\nRDMA 技术为什么可以应用在上述场景中呢？这就涉及到它的以下几个特点：\n0 拷贝：指的是不需要在用户空间和内核空间中来回复制数据。 由于 Linux 等操作系统将内存划分为用户空间和内核空间，在传统的 Socket 通信流程中 CPU 需要多次把数据在内存中来回拷贝。而通过 RDMA 技术，我们可以直接访问远端已经注册的内存区域。\n关于 0 拷贝可以参考这篇文章：浅谈 Linux 下的零拷贝机制\r内核 Bypass：指的是 IO（数据）流程可以绕过内核，即在用户层就可以把数据准备好并通知硬件准备发送和接收。避免了系统调用和上下文切换的开销。 上图（原图[1]\r）可以很好的解释“0 拷贝”和“内核 Bypass”的含义。上下两部分分别是基于 Socket 的和基于 RDMA 的一次收-发流程，左右分别为两个节点。可以明显的看到 Socket 流程中在软件中多了一次拷贝动作。而 RDMA 绕过了内核同时也减少了内存拷贝，数据可以直接在用户层和硬件间传递。\nCPU 卸载：指的是可以在远端节点 CPU 不参与通信的情况下（当然要持有访问远端某段内存的“钥匙”才行）对内存进行读写，这实际上是 把报文封装和解析放到硬件中做了。而传统的以太网通信，双方 CPU 都必须参与各层报文的解析，如果数据量大且交互频繁，对 CPU 来讲将是一笔不小的开销，而这些被占用的 CPU 计算资源本可以做一些更有价值的工作。 通信领域两大出场率最高的性能指标就是“带宽”和“时延”。简单的说，所谓带宽指的是指单位时间内能够传输的数据量，而时延指的是数据从本端发出到被对端接收所耗费的时间。因为上述几个特点，相比于传统以太网，RDMA 技术同时做到了更高带宽和更低时延，所以其在带宽敏感的场景——比如海量数据的交互，时延敏感——比如多个计算节点间的数据同步的场景下得以发挥其作用。\n协议 RDMA 本身指的是一种技术，具体协议层面，包含 Infiniband（IB），RDMA over Converged Ethernet（RoCE）和 internet Wide Area RDMA Protocol（iWARP）。三种协议都符合 RDMA 标准，使用相同的上层接口，在不同层次上有一些差别。\n上图[2]g\r对于几种常见的 RDMA 技术的协议层次做了非常清晰的对比\nInfiniband 2000 年由 IBTA（InfiniBand Trade Association）提出的 IB 协议是当之无愧的核心，其规定了一整套完整的链路层到传输层（非传统 OSI 七层模型的传输层，而是位于其之上）规范，但是其无法兼容现有以太网，除了需要支持 IB 的网卡之外，企业如果想部署的话还要重新购买配套的交换设备。\nRoCE RoCE 从英文全称就可以看出它是基于以太网链路层的协议，v1 版本网络层仍然使用了 IB 规范，而 v2 使用了 UDP+IP 作为网络层，使得数据包也可以被路由。RoCE 可以被认为是 IB 的“低成本解决方案”，将 IB 的报文封装成以太网包进行收发。由于 RoCE v2 可以使用以太网的交换设备，所以现在在企业中应用也比较多，但是相同场景下相比 IB 性能要有一些损失。\niWARP iWARP 协议是 IETF 基于 TCP 提出的，因为 TCP 是面向连接的可靠协议，这使得 iWARP 在面对有损网络场景（可以理解为网络环境中可能经常出现丢包）时相比于 RoCE v2 和 IB 具有更好的可靠性，在大规模组网时也有明显的优势。但是大量的 TCP 连接会耗费很多的内存资源，另外 TCP 复杂的流控等机制会导致性能问题，所以从性能上看 iWARP 要比 UDP 的 RoCE v2 和 IB 差。\n需要注意的是，虽然有软件实现的 RoCE 和 iWARP 协议，但是真正商用时上述几种协议都需要专门的硬件（网卡）支持。\niWARP 本身不是由 Infiniband 直接发展而来的，但是它继承了一些 Infiniband 技术的设计思想。这三种协议的关系如下图所示：\n玩家 标准/生态组织 提到 IB 协议，就不得不提到两大组织——IBTA 和 OFA。\nIBTA[3]\r成立于 1999 年，负责制定和维护 Infiniband 协议标准。IBTA 独立于各个厂商，通过赞助技术活动和推动资源共享来将整个行业整合在一起，并且通过线上交流、营销和线下活动等方式积极推广 IB 和 RoCE。\nIBTA 会对商用的 IB 和 RoCE 设备进行协议标准符合性和互操作性测试及认证，由很多大型的 IT 厂商组成的委员会领导，其主要成员包括博通，HPE，IBM，英特尔，Mellanox 和微软等，华为也是 IBTA 的会员。\nOFA[4]\r成立于 2004 年的非盈利组织，负责开发、测试、认证、支持和分发独立于厂商的开源跨平台 infiniband 协议栈，2010 年开始支持 RoCE。其对用于支撑 RDMA/Kernel bypass 应用的 OFED（OpenFabrics Enterprise Distribution）软件栈负责，保证其与主流软硬件的兼容性和易用性。OFED 软件栈包括驱动、内核、中间件和 API。\n上述两个组织是配合关系，IBTA 主要负责开发、维护和增强 Infiniband 协议标准；OFA 负责开发和维护 Infiniband 协议和上层应用 API。\n开发社区 Linux 社区 Linux 内核的 RDMA 子系统还算比较活跃，经常会讨论一些协议细节，对框架的修改比较频繁，另外包括华为和 Mellanox 在内的一些厂商也会经常对驱动代码进行修改。\n邮件订阅：http://vger.kernel.org/vger-lists.html#linux-rdma\r代码位于内核 drivers/infiniband/目录下，包括框架核心代码和各厂商的驱动代码。\n代码仓：https://git.kernel.org/pub/scm/linux/kernel/git/rdma/rdma.git/\rRDMA 社区 对于上层用户，IB 提供了一套与 Socket 套接字类似的接口——libibverbs，前文所述三种协议都可以使用。参考着协议、API 文档和示例程序很容易就可以写一个 Demo 出来。本专栏中的 RDMA 社区专指其用户态社区，在 github 上其仓库的名字为 linux-rdma。\n主要包含两个子仓库：\nrdma-core 用户态核心代码，API，文档以及各个厂商的用户态驱动。\nperftest 一个功能强大的用于测试 RDMA 性能的工具。 代码仓：https://github.com/linux-rdma/\rUCX[5]\rUCX 是一个建立在 RDMA 等技术之上的用于数据处理和高性能计算的通信框架，RDMA 是其底层核心之一。我们可以将其理解为是位于应用和 RDMA API 之间的中间件，向上层用户又封装了一层更易开发的接口。\n笔者对其并不了解太多，只知道业界有一些企业在基于 UCX 开发应用。\n代码仓：https://github.com/openucx/ucx\r硬件厂商 设计和生产 IB 相关硬件的厂商有不少，包括 Mellanox、华为、收购了 Qlogic 的 IB 技术的 Intel，博通、Marvell，富士通等等，这里就不逐个展开了，仅简单提一下 Mellanox 和华为。\nMellanox IB 领域的领头羊，协议标准制定、软硬件开发和生态建设都能看到 Mellanox 的身影，其在社区和标准制定上上拥有最大的话语权。目前最新一代的网卡是支持 200Gb/s 的 ConnextX-6 系列。\n华为 去年初推出的鲲鹏 920 芯片已经支持 100Gb/s 的 RoCE 协议，技术上在国内处于领先地位。但是软硬件和影响力方面距离 Mellanox 还有比较长的路要走，相信华为能够早日赶上老大哥的步伐。\n用户 微软、IBM 和国内的阿里、京东都正在使用 RDMA，另外还有很多大型 IT 公司在做初步的开发和测试。在数据中心和高性能计算场景下，RDMA 代替传统网络是大势所趋。笔者对于市场接触不多，所以并不能提供更详细的应用情况。\n下一篇将用比较直观的方式比较一次典型的基于 Socket 的传统以太网和 RDMA 通信过程。\n","date":"2024-01-01T01:01:01Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/crop_65b36f302c1d3715061e824224dcc9ca195413.jpg@1256w_1806h_!web-article-pic-2024-01-14.webp","permalink":"https://cuterwrite.top/p/rdma-overview/","title":"RDMA 概述"},{"content":"在 HPC 上运行 Apache Spark 一、概述 Apache Spark\r是一个多语言引擎，用于在单节点机器或集群上执行数据工程、数据科学和机器学习任务。本文将为您提供在高性能计算（HPC）集群系统上运行多节点 Spark 集群的指南，并展示一个使用 PySpark 的作业示例。\n二、开始 1. 下载 OpenJDK-11.0.2 从 OpenJDK 官方网站\r下载 OpenJDK-11.0.2。选择 Linux 的对应版本并下载。解压下载的文件并将其放置在 ${HOME}/software/openjdk 中并重命名为 11.0.2 。\n2. 下载 Spark-3.4.2 从 Apache Spark 下载页面\r下载 Spark 。本文使用的是 Spark-3.4.2，但本指南应该也适用于更新的版本。解压下载的文件并将目录重命名为 3.4.2，放置在 ${HOME}/software/spark 文件夹中。\n3. 配置 modulefile 在自定义目录中安装软件后，需要将软件的可执行文件路径等添加到相应的环境变量中才能使用。module 是一款环境变量管理工具，通过 module 实现软件环境变量的管理，快速加载和切换软件环境。集群中安装了一些常用的软件和库，可以通过 module 进行加载使用。\n在这里，我们需要编写 modulefile 来管理自己的 JDK 和 Spark 软件环境，以便快速加载 Java 和 Spark 环境。\n在 ${HOME}/modulefiles/openjdk 中创建名为 11.0.2 的文本文件，内容为： #%Module1.0\r##\r## openjdk modulefile\r##\rproc ModulesHelp { } {\rputs stderr \u0026quot;This module sets up the environment for OpenJdk 11.0.2 \\n\u0026quot;\r}\rmodule-whatis \u0026quot;For more information, \\$ module help openjdk/11.0.2\\n\u0026quot;\rconflict openjdk\r# 注意！这里需要进行修改\rset root \u0026lt;PATH/WHERE/OPENJDK/DIRECTORY/IS\u0026gt;\rprepend-path PATH ${root}/bin\r在 ${HOME}/modulefiles/spark 中创建名为 3.4.2 的文本文件， 内容为： #%Module1.0\r##\r## spark modulefile\r##\rproc ModulesHelp { } {\rglobal version\rputs stderr \u0026quot;This module loads Apache Spark environment variables and updates the PATH.\u0026quot;\rputs stderr \u0026quot; \u0026quot;\rputs stderr \u0026quot;Version: $version\u0026quot;\r}\rmodule-whatis \u0026quot;Loads Apache Spark environment variables and updates the PATH. \\n For more information, \\$ module help spark/3.4.2 .\\n\u0026quot;\rconflict spark\r# Set the version and installation path\rset version 3.4.2\r# 注意！这里需要进行修改\rset root \u0026lt;PATH/WHERE/SPARK/DIRECTORY/IS\u0026gt;\r# Set the environment variables\rsetenv SPARK_HOME ${root}\rsetenv SPARK_CONF_DIR ${root}/conf\rsetenv PYSPARK_PYTHON python3\r# Update the PATH\rprepend-path PATH ${root}/bin\rprepend-path PATH ${root}/sbin\r# Update the CLASSPATH\rprepend-path CLASSPATH ${root}/jars/*\r4. 使用 pip 安装 pyspark 库 创建虚拟 Conda 环境 pyspark conda create -n pyspark python=3.10\r安装 pyspark conda activate pyspark\rpip install pyspark\r5. 编写环境加载脚本 set-spark-env.sh 在 ${HOME}/scripts 目录下编写 set-spark-env.sh 脚本文件： #!/bin/bash\rsource /etc/profile\r# 注意！这里需要修改为你的 Conda 的安装路径\rexport CONDA_PATH=\u0026lt;PATH/WHERE/CONDA/DIRECTORY/IS\u0026gt;\rexport PATH=$CONDA_PATH/bin:$PATH\rexport MODULEPATH=${HOME}/modulefiles:$MODULEPATH\rsource activate\rconda activate pyspark\rmodule load openjdk\rmodule load spark\r6. 编写 sbatch 脚本 为了启动 Spark 集群，我们使用以下 Slurm 脚本来请求计算节点。Slurm 脚本请求四个节点，并生成一个 master 节点和三个 worker 节点的 Spark 集群。可以通过更改 Slurm 脚本中的 -N 选项的值来增加或减少工作节点的数量。 #!/bin/bash\r#SBATCH --export=ALL\r#SBATCH --mem=0\r#SBATCH -p C28M250G\r#SBATCH -t 1:00:00\r#SBATCH -N 4\r#SBATCH -J spark_test\r#SBATCH -o o.spark_test\r#SBATCH -e e.spark_test\rsource ~/scripts/set-spark-env.sh\rworkdir=`pwd`\rnodes=($(scontrol show hostnames ${SLURM_JOB_NODELIST} | sort | uniq ))\rnumnodes=${#nodes[@]}\rlast=$(( $numnodes - 1 ))\rexport SCRATCH=${workdir}/scratch\rmaster=${nodes[0]}\rmasterurl=\u0026quot;spark://${master}:7077\u0026quot;\rssh ${nodes[0]} \u0026quot;source ~/scripts/set-spark-env.sh; start-master.sh\u0026quot;\rfor i in $( seq 1 $last )\rdo\rssh ${nodes[$i]} \u0026quot;source ~/scripts/set-spark-env.sh; start-worker.sh ${masterurl}\u0026quot;\rdone\rssh ${nodes[0]} \u0026quot;cd ${workdir}; source ~/scripts/set-spark-env.sh; /usr/bin/time -v spark-submit --deploy-mode client --executor-cores 28 --executor-memory 240G --conf spark.standalone.submit.waitAppCompletion=true --master $masterurl spark_test.py\u0026quot;\rwait\recho 'end'\rexit\r该 Slurm 脚本会提交一个用于测试的 python 脚本（ spark_test.py ），内容如下。此脚本运行 PySpark 代码来测试 Spark 集群。复制下面的内容，并将其保存在 sbatch 脚本所在目录中的 spark_test.py 文件。你也可以更改 spark_test.py 文件的路径，但必须适当地更新 Slurm 脚本。 #spark_test.py\rimport random\rfrom pyspark.sql import SparkSession\rimport pyspark.sql.functions as F\rspark = SparkSession.builder.appName('Test-app').getOrCreate()\r#Generate sample dataset\rcola_list = ['2022-01-01', '2022-01-02', '2022-01-03' ]\rcolb_list = ['CSC', 'PHY', 'MAT', 'ENG', 'CHE', 'ENV', 'BIO', 'PHRM']\rcolc_list = [100, 200, 300, 400, 500, 600, 700, 800, 900]\r# declaring a random.seed value to generate same data in every run\rrandom.seed(1)\rsample_data = []\rfor idx in range(1000):\rsample_data.append([random.choice(cola_list), random.choice(colb_list), random.choice(colc_list)])\rcolumns= [\u0026quot;date\u0026quot;, \u0026quot;org\u0026quot;, \u0026quot;value\u0026quot;]\r#creating a Spark dataframe\rdf = spark.createDataFrame(data = sample_data, schema = columns)\rres = (df.groupBy('date','org')\r.agg(F.count('value').alias('count_value')))\rres.show()\r如果启动了 Spark 集群并且 spark-test.py 成功执行，那么日志文件 o.spark_test 中的输出应该如下： starting org.apache.spark.deploy.master.Master, logging to ...\rstarting org.apache.spark.deploy.worker.Worker, logging to ...\rstarting org.apache.spark.deploy.worker.Worker, logging to ...\rstarting org.apache.spark.deploy.worker.Worker, logging to ...\r+----------+----+-----------+\r| date| org|count_value|\r+----------+----+-----------+\r|2022-01-03| BIO| 37|\r|2022-01-02| ENV| 53|\r|2022-01-03| CHE| 39|\r|2022-01-03| PHY| 46|\r|2022-01-01| CSC| 45|\r|2022-01-03| CSC| 48|\r|2022-01-01| BIO| 39|\r|2022-01-01| MAT| 42|\r|2022-01-02| CHE| 44|\r|2022-01-03| ENV| 33|\r|2022-01-01| ENG| 33|\r|2022-01-02| ENG| 28|\r|2022-01-01| ENV| 33|\r|2022-01-02| CSC| 45|\r|2022-01-02| MAT| 51|\r|2022-01-01| PHY| 38|\r|2022-01-01|PHRM| 40|\r|2022-01-03|PHRM| 42|\r|2022-01-02|PHRM| 43|\r|2022-01-03| ENG| 56|\r+----------+----+-----------+\ronly showing top 20 rows\rend\rSpark 还提供了一个 web UI 来监控集群，您可以通过将 master 节点端口转发到本地机器来在本地机器上访问它。 例如，如果 master 节点在 cpu1 上运行，则可以在本地计算机终端上运行以下代码。 ssh -t -t \u0026lt;USERNAME\u0026gt;@\u0026lt;LOGIN_NODE_IP\u0026gt; -L 8080:localhost:8080 \\\r-i \u0026lt;PRIVATE_KEY_LOCATION\u0026gt; ssh cpu1 -L 8080:127.0.0.1:8080\r然后就可以在本地机器上的 Web 浏览器上使用地址 http://localhost:8080/\r访问 Spark Web UI。 三、总结 在本文中，我们介绍了如何在 HPC 集群上部署和运行 Apache Spark 集群。通过遵循本指南中的步骤，你应该能够成功地在 HPC 环境中运行 Spark 作业。请注意，根据你的具体 HPC 环境和配置，可能需要进行一些调整。\nSpark 官方文档\r是一个非常有用的工具，通过它可以帮助你找到 Spark 的具体说明并解决问题。所以实际遇到问题时要多使用它。\n","date":"2023-12-30T01:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/crop_afb480a4096d16305dc5696f8072d0c0195413.jpg@1256w_2094h_!web-article-pic-2023-12-30.webp","permalink":"https://cuterwrite.top/p/run-spark-on-hpc/","title":"在 HPC 上运行 Apache Spark"},{"content":"一、引言 随着图片格式的不断发展，AVIF 和 HEIC 这两种高效的图片格式逐渐受到了开发者的关注。AVIF（AV1 Image File Format）是一种基于 AV1 视频编码的图像格式，具有高压缩率和高质量的特点。HEIC（High Efficiency Image Format）是一种基于 HEVC（High Efficiency Video Coding）编码的图像格式，同样具有高压缩率和高质量的优势。为了方便处理这两种格式的图片，我们可以使用 Pillow-AVIF-Plugin 和 Pillow-HEIC 库。\n二、安装 首先，我们需要安装 Pillow 库，它是一个强大的 Python 图像处理库。使用以下命令安装：\npip install pillow\r接下来，安装 Pillow-AVIF-Plugin 和 Pillow-HEIC 库：\npip install pillow-avif-plugin\rpip install pillow-heic\r三、使用方法 1. 处理 AVIF 图片 使用 Pillow-AVIF-Plugin 处理 AVIF 图片非常简单。首先，导入所需的库：\nfrom PIL import Image\rimport pillow_avif\r然后，使用 Image.open() 方法打开 AVIF 图片：\nimage = Image.open('example.avif')\r接下来，可以对图片进行各种操作，例如调整大小、旋转等。也可以使用以下方法将图片保存为其他格式（例如 PNG ）：\nwith Image.open(file_path) as im:\rpng_file_path = os.path.splitext(file_path)[0] + \u0026quot;.png\u0026quot;\rim.save(png_file_path, format=\u0026quot;PNG\u0026quot;)\ros.remove(file_path)\r2. 处理 HEIC 图片 处理 HEIC 图片的方法与处理 AVIF 图片类似。首先，导入所需的库：\nfrom PIL import Image\rfrom pillow_heif import register_heif_opener\rregister_heif_opener()\r然后，使用 Image.open() 方法打开 HEIC 图片：\nimage = Image.open('example.heic')\r接下来，可以对图片进行各种操作，例如调整大小、旋转等。也可以使用以下方法将图片保存为其他格式（例如 PNG ）：\nwith Image.open(file_path) as im:\rpng_file_path = os.path.splitext(file_path)[0] + \u0026quot;.png\u0026quot;\rim.save(png_file_path, format=\u0026quot;PNG\u0026quot;)\ros.remove(file_path)\r四、结论 通过使用 Pillow-AVIF-Plugin 和 Pillow-HEIC 库，我们可以轻松地处理 AVIF 和 HEIC 格式的图片。这两个库为开发者提供了简单易用的接口，使得在实际项目中处理这些高效的图片格式变得更加方便。希望本文能对你有所帮助。\n","date":"2023-12-21T11:45:14Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/4674616682ccadfd81f2dc86c6241f23195413.jpg@1256w_704h_!web-article-pic-2023-12-22-2023-12-31.webp","permalink":"https://cuterwrite.top/p/processing-avif-heic-images-pillow-plugins/","title":"使用 Pillow + Plugin 处理 AVIF 和 HEIC 图片"},{"content":"Ring buffer 详解 一、概述 ring buffer 称作 环形缓冲区 ，也称作环形队列（circular queue），是一种用于表示一个固定尺寸、头尾相连的缓冲区的数据结构，适合缓存数据流。如下为 环形缓冲区（ring buffer） 的概念示意图。\n在任务间的通信、串口数据收发、log 缓存、网卡处理网络数据包、音频/视频流处理中均有 环形缓冲区（ring buffer） 的应用。在 RT-Thread 的 ringbuffer.c 和 ringbuffer.h 文件中，Linux 内核文件 kfifo.h 和 kfifo.c 中也有 环形缓冲区（ring buffer） 的代码实现。\n环形缓冲区的一些使用特点如下：\n当一个数据元素被读取出后，其余数据元素不需要移动其存储位置； 适合于事先明确了缓冲区的最大容量的情形。缓冲区的容量（长度）一般固定，可以用一个静态数组来充当缓冲区，无需重复申请内存； 如果缓冲区的大小需要经常调整，就不适合用环形缓冲区，因为在扩展缓冲区大小时，需要搬移其中的数据，这种场合使用链表更加合适； 因为缓冲区成头尾相连的环形，写操作可能会覆盖未及时读取的数据，有的场景允许这种情况发生，有的场景又严格限制这种情况发生。选择何种策略和具体应用场景相关。 二、原理 由于计算机内存是线性地址空间，因此 环形缓冲区（ring buffer） 需要特别的算法设计才可以从逻辑上实现。\n1. 一个简单例子 先不要想 环形缓冲区（ring buffer） 的具体实现细节，来看一个简单的例子。如下是一个空间大小为 7 的环形缓冲区，其中底部的单线箭头表示头尾相连形成一个环形地址空间：\n假设 1 被写入圆形缓冲区的中心（在环形缓冲区中，最初的写入位置在哪里是无关紧要的）：\n再 写入两个 元素，分别是 2 和 3 ，这两个元素被追加到 1 之后：\n如果 读出两个 元素，那么环形缓冲区中最老的两个元素将被读出（先进先出原则）。在本例中 1 和 2 被读出，缓冲区中剩下 3 ：\n紧接着，向缓冲区中 写入六个 元素 4、5、6、7、8、9 ，这时缓冲区会被装满：\n如果缓冲区是满的，又要写入新的数据，这时有两种策略：一种是覆盖掉最老的数据，也就是将老数据丢掉；另一种是返回错误码或者抛出异常。来看策略一，例如，这时写入两个元素 A 和 B ，就会覆盖掉 3 和 4 ：\n再看，这时如果读出两个元素，就不是 3 和 4 而是 5 和 6（ 5 和 6 这时最老），3 和 4 已经被 A 和 B 覆盖掉。\n通过这个简单的例子，可以总结出要实现 环形缓冲区（ring buffer） 需要注意到几个问题点：\n在缓冲区满的时候写数据，有两种策略可以使用：第一覆盖掉老数据；第二抛出异常； 读数据时，一定要读出缓冲区中最老的数据（缓冲区中数据满足 FIFO 特性）； 怎样来判断缓冲区是满的； 如何实现一个线性地址空间的循环读写。 2. 具体操作 一般的，对一个环形缓冲区进行读写操作，最少需要 4 个信息：\n在内存中的实际 开始位置 （例如：一片内存的头指针，数组的第一个元素指针）； 在内存中的实际 结束位置 （也可以是缓冲区实际空间大小，结合开始位置，可以算出结束位置）； 在缓冲区中进行写操作时的 写索引 值； 在缓冲区中进行读操作时的 读索引 值。 缓冲区开始位置 和 缓冲区结束位置（或空间大小） 实际上定义了环形缓冲区的实际逻辑空间和大小。 读索引 和 写索引 标记了缓冲区进行读操作和写操作时的具体位置。\n具体来说，读写逻辑如下：\n当环形缓冲区为空时，读索引和写索引指向相同的位置（因为是环形缓冲区，可以出现在任何位置）； 当向缓冲区写入一个元素时，元素被写入 写索引 当前所指向位置，然后写索引加 1，指向下一个位置； 当从缓冲区读出一个元素时，在 读索引 当前所指向位置的元素被读出，然后读索引加 1，指向下一个位置； 当缓冲区满时，写索引和读索引指向相同的位置（和缓冲区为空时一样）。 2.1 在缓冲区满的时候写数据，有两种策略可以使用 缓冲区变满在 环形缓冲区（ring buffer） 中会实际发生，一般会有两种处理策略，第一覆盖掉老数据；第二抛出“异常”。这两种策略该如何选择要结合具体的应用场景。如音/视频流中，丢掉一些数据不要紧，可以选择第一种策略；在任务间通信的时候，要严格保证数据正确传输，这个时候就要选择第二种策略。\n2.2 读数据时，一定要读出缓冲区中最老的数据 环形缓冲区（ring buffer） 也是 FIFO 类型的数据结构，需要满足先进先出的原则。写就相当于进，读就相当于出。所以读数据时，一定要保证读最老的数据。一般的情况下不会有问题，但有一种场景需要小心： 当缓冲区是满的时候，继续写入元素（覆盖），除了写索引要变，读索引也要跟着变，保证读索引一定是指向缓冲区中最老的元素 。\n2.3 怎样来判断缓冲区是满的 判断缓冲区是满还是空，在环形缓冲区（ring buffer）中是一个重点问题，在维基百科\r中，讲解了五种判断方法，感兴趣可以看一下。在平衡各方优缺点后，本节重点讲解 镜像指示位 方法，在 linux 和 RT-Thread 实现的环形缓冲区中，也都是用的该策略（或者说是该策略的扩展）。\n镜像指示位：缓冲区的长度如果是 n ，逻辑地址空间则为 0 至 n-1 ；那么，规定 n 至 2n-1 为镜像逻辑地址空间。本策略规定读写指针的地址空间为 0 至 2n-1 ，其中低半部分对应于常规的逻辑地址空间，高半部分对应于镜像逻辑地址空间。当指针值大于等于 2n 时，使其折返（wrapped）到 ptr-2n。使用一位表示写指针或读指针是否进入了虚拟的镜像存储区：置位表示进入，不置位表示没进入还在基本存储区。\n在读写指针的值相同情况下，如果二者的指示位相同，说明缓冲区为空；如果二者的指示位不同，说明缓冲区为满。\n这种方法优点是测试缓冲区满/空很简单；不需要做取余数操作；读写线程可以分别设计专用算法策略，能实现精致的并发控制。\n缺点是读写指针各需要额外的一位作为指示位。\n如果缓冲区长度是 2 的幂，则本方法可以省略镜像指示位。如果读写指针的值相等，则缓冲区为空；如果读写指针相差 n ，则缓冲区为满，这可以用条件表达式（写指针 == (读指针 异或 缓冲区长度)）来判断。—— 维基百科\n上面是维基百科中对 镜像指示位 的整体描述，但是单凭上面这一个描述，去理解 镜像指示位 方法还是有一定困难，下面来进行一些讨论。\n上面描述中提到了 读/写指针 的概念，注意这个读/写指针和上文提到的 读索引 和 写索引 不是一回事。读写指针的范围是 $[0, 2n-1]$ ，而 读索引 和 写索引 的范围是 $[0, n - 1]$ ，其必须和缓冲区的实际逻辑空间一致。但是 读/写指针 和 读索引 和 写索引 有一个转换关系：\n$$ 读索引 = 读指针 \\bmod 缓冲区长度 \\\\ 写索引 = 写指针 \\bmod 缓冲区长度 $$\n但是如果缓冲区长度是 2 的幂，那么求余运算可以等价的转换为如下的 按位与 运算：\n$$ 读索引 = 读指针 \\\u0026amp; (缓冲区长度 - 1) \\\\ 写索引 = 写指针 \\\u0026amp; (缓冲区长度 - 1) $$\n按位与的运算效率要比求余运算高的多，在 linux 内核中将缓冲区长度扩展为 2 的幂长度随处可见，都是为了用按位与操作代替求余操作。为了判断缓冲区是否为空或者满，镜像指示位策略引入了两个布尔变量（指示位），来分别标记读指针或写指针是否进入了镜像区间 $[n, 2n-1]$ ，在读写指针的值相同情况下，如果二者的指示位相同，说明缓冲区 为空 ；如果二者的指示位不同，说明缓冲区 为满 。但如果缓冲区的长度是 2 的幂，则可以省略镜像指示位。如果读写指针的值相等，则缓冲区为空；如果读写指针相差 n ，则缓冲区为满。\n2.4 如何实现一个线性地址空间的循环读写 理解了 2.3 节的描述，再来理解用一个线性地址空间来实现循环读写就比较容易。如一个环形缓冲区的长度为 七 ，则其读写索引的区间为 $[0, 6]$ 。当写索引的值为 6 ，再向缓冲区中写入一个元素时，写索引应该要回到缓冲区的起始索引位置 0 ，读索引在碰到这种情况也是类似处理。总结为一句话就是，当写索引或读索引已经到了环形缓冲区的结束位置时，进行下一步操作时，其应该要回到环形缓冲区的开始位置。\n三、实现 对于环形缓冲区的代码实现，本文会分析 RT-Thread 的 ringbuffer.c 和 ringbuffer.h 文件，Linux 内核中的 kfifo.h 和 kfifo.c 文件。\n1. RT-Thread 中实现的 ring buffer 下面分析 RT-Thread 的 ring buffer 实现，主要会讨论 环形缓冲区结构体 、 缓冲区初始化操作 、写操作 、 读操作 、判断缓冲区是否为空或满 。\n1.1 环形缓冲区结构体 RT-Thread 中定义了结构体 rt_ringbuffer ，其中 buffer_ptr 、 buffer_size 、 read_index 、 write_index 和之前介绍的 4 个信息是完全对应的。为了判断缓冲区是空还是满，还定义了两个布尔型变量 read_mirror 和 write_mirror ，其是通过位域的定义方式来实现。\nstruct rt_ringbuffer\r{\rrt_uint8_t *buffer_ptr;\rrt_uint16_t read_mirror : 1;\rrt_uint16_t read_index : 15;\rrt_uint16_t write_mirror : 1;\rrt_uint16_t write_index : 15;\rrt_int16_t buffer_size;\r};\r1.2 缓冲区初始化操作 初始化操作 rt_ringbuffer_init 很容易理解，就是将申请好的内存地址赋值给环形缓冲区，缓冲区实际逻辑大小也传入进去。read_index 、write_index 、read_mirror 和 write_mirror 全部初始化为零。\nvoid rt_ringbuffer_init(struct rt_ringbuffer *rb,\rrt_uint8_t *pool,\rrt_int16_t size)\r{\rRT_ASSERT(rb != RT_NULL);\rRT_ASSERT(size \u0026gt; 0);\r/* initialize read and write index */\rrb-\u0026gt;read_mirror = rb-\u0026gt;read_index = 0;\rrb-\u0026gt;write_mirror = rb-\u0026gt;write_index = 0;\r/* set buffer pool and size */\rrb-\u0026gt;buffer_ptr = pool;\rrb-\u0026gt;buffer_size = RT_ALIGN_DOWN(size, RT_ALIGN_SIZE);\r}\r1.3 写操作和读操作 写操作有两个接口 rt_ringbuffer_put 和 rt_ringbuffer_put_force ，当缓冲区满的时候，前一个不会写入，后一个会强制写入（覆盖）；读操作有一个接口 rt_ringbuffer_get 。\n这里先说明一下， RT-Thread 的 ring buffer 实现虽然借鉴了上一章讲的 镜像指示位 策略，但其并没有使用读写指针，而是直接用的 写索引 和 读索引 ，也就是说结构体中的 read_index 和 write_index 就是写索引和读索引，无需进行转换，直接可以用来操作缓冲区。这一点和 linux 的实现方式不同，在下面的 linux 章节中会看到。但 read_mirror 和 write_mirror 是和 镜像指示位策略 中讲的一样，用来标记是否进入了镜像区间。\n先来看 rt_ringbuffer_put 的实现，该函数的返回值是实际写入大小，就是如果传入的 length 大于缓冲区的剩余空间，则 length 只有部分会被写入缓冲区。\n当 if (rb-\u0026gt;buffer_size - rb-\u0026gt;write_index \u0026gt; length) 为真时，就是说从 写索引 到缓冲区结束位置这一段空间能容纳全部所写入数据。写索引无需回环。对应的代码就是 rt_memcpy(\u0026amp;rb-\u0026gt;buffer_ptr[rb-\u0026gt;write_index], ptr, length); 。 当 if (rb-\u0026gt;buffer_size - rb-\u0026gt;write_index \u0026gt; length) 为假时，就是说从 写索引 到缓冲区结束位置这一段空间无法全部容纳所写入数据，写索引需要回环到缓冲区开头，写入剩下的数据。对应代码就是 rt_memcpy(\u0026amp;rb-\u0026gt;buffer_ptr[rb-\u0026gt;write_index],\u0026amp;ptr[0],rb-\u0026gt;buffer_size - rb-\u0026gt;write_index); 和 rt_memcpy(\u0026amp;rb-\u0026gt;buffer_ptr[0],\u0026amp;ptr[rb-\u0026gt;buffer_size - rb-\u0026gt;write_index],length - (rb-\u0026gt;buffer_size - rb-\u0026gt;write_index)); 。因为写索引已经回环了，所以要将 write_mirror 做一下取反操作：rb-\u0026gt;write_mirror = ~rb-\u0026gt;write_mirror; 。 写操作接口 rt_ringbuffer_put_force 和上面介绍的基本一样，其实就是多了当传入的 length 大于缓冲区的剩余空间时，会将已有的元素覆盖掉。如果发生了元素覆盖，那缓冲区一定会变满，read_index 和 write_index 会相等，对应语句 if (length \u0026gt; space_length) rb-\u0026gt;read_index = rb-\u0026gt;write_index; 。因为会操作 read_index 元素，也要考虑其是否发生了回环，发生了回环后 read_mirror 需要取反，对应语句 rb-\u0026gt;read_mirror = ~rb-\u0026gt;read_mirror;。\n读接口 rt_ringbuffer_get 和写接口的操作逻辑基本一致，也是通过条件 if (rb-\u0026gt;buffer_size - rb-\u0026gt;write_index \u0026gt; length) 将读操作分成了两种情形，过程和写操作接口 rt_ringbuffer_put 没有差异。\n/**\r* @brief Put a block of data into the ring buffer. If the capacity of ring buffer is insufficient, it will discard out-of-range data.\r*\r* @param rb A pointer to the ring buffer object.\r* @param ptr A pointer to the data buffer.\r* @param length The size of data in bytes.\r*\r* @return Return the data size we put into the ring buffer.\r*/\rrt_size_t rt_ringbuffer_put(struct rt_ringbuffer *rb,\rconst rt_uint8_t *ptr,\rrt_uint16_t length)\r{\rrt_uint16_t size;\rRT_ASSERT(rb != RT_NULL);\r/* whether has enough space */\rsize = rt_ringbuffer_space_len(rb);\r/* no space */\rif (size == 0)\rreturn 0;\r/* drop some data */\rif (size \u0026lt; length)\rlength = size;\rif (rb-\u0026gt;buffer_size - rb-\u0026gt;write_index \u0026gt; length)\r{\r/* read_index - write_index = empty space */\rrt_memcpy(\u0026amp;rb-\u0026gt;buffer_ptr[rb-\u0026gt;write_index], ptr, length);\r/* this should not cause overflow because there is enough space for\r* length of data in current mirror */\rrb-\u0026gt;write_index += length;\rreturn length;\r}\rrt_memcpy(\u0026amp;rb-\u0026gt;buffer_ptr[rb-\u0026gt;write_index],\r\u0026amp;ptr[0],\rrb-\u0026gt;buffer_size - rb-\u0026gt;write_index);\rrt_memcpy(\u0026amp;rb-\u0026gt;buffer_ptr[0],\r\u0026amp;ptr[rb-\u0026gt;buffer_size - rb-\u0026gt;write_index],\rlength - (rb-\u0026gt;buffer_size - rb-\u0026gt;write_index));\r/* we are going into the other side of the mirror */\rrb-\u0026gt;write_mirror = ~rb-\u0026gt;write_mirror;\rrb-\u0026gt;write_index = length - (rb-\u0026gt;buffer_size - rb-\u0026gt;write_index);\rreturn length;\r}\rRTM_EXPORT(rt_ringbuffer_put);\r/**\r* @brief Put a block of data into the ring buffer. If the capacity of ring buffer is insufficient, it will overwrite the existing data in the ring buffer.\r*\r* @param rb A pointer to the ring buffer object.\r* @param ptr A pointer to the data buffer.\r* @param length The size of data in bytes.\r*\r* @return Return the data size we put into the ring buffer.\r*/\rrt_size_t rt_ringbuffer_put_force(struct rt_ringbuffer *rb,\rconst rt_uint8_t *ptr,\rrt_uint16_t length)\r{\rrt_uint16_t space_length;\rRT_ASSERT(rb != RT_NULL);\rspace_length = rt_ringbuffer_space_len(rb);\rif (length \u0026gt; rb-\u0026gt;buffer_size)\r{\rptr = \u0026amp;ptr[length - rb-\u0026gt;buffer_size];\rlength = rb-\u0026gt;buffer_size;\r}\rif (rb-\u0026gt;buffer_size - rb-\u0026gt;write_index \u0026gt; length)\r{\r/* read_index - write_index = empty space */\rrt_memcpy(\u0026amp;rb-\u0026gt;buffer_ptr[rb-\u0026gt;write_index], ptr, length);\r/* this should not cause overflow because there is enough space for\r* length of data in current mirror */\rrb-\u0026gt;write_index += length;\rif (length \u0026gt; space_length)\rrb-\u0026gt;read_index = rb-\u0026gt;write_index;\rreturn length;\r}\rrt_memcpy(\u0026amp;rb-\u0026gt;buffer_ptr[rb-\u0026gt;write_index],\r\u0026amp;ptr[0],\rrb-\u0026gt;buffer_size - rb-\u0026gt;write_index);\rrt_memcpy(\u0026amp;rb-\u0026gt;buffer_ptr[0],\r\u0026amp;ptr[rb-\u0026gt;buffer_size - rb-\u0026gt;write_index],\rlength - (rb-\u0026gt;buffer_size - rb-\u0026gt;write_index));\r/* we are going into the other side of the mirror */\rrb-\u0026gt;write_mirror = ~rb-\u0026gt;write_mirror;\rrb-\u0026gt;write_index = length - (rb-\u0026gt;buffer_size - rb-\u0026gt;write_index);\rif (length \u0026gt; space_length)\r{\rif (rb-\u0026gt;write_index \u0026lt;= rb-\u0026gt;read_index)\rrb-\u0026gt;read_mirror = ~rb-\u0026gt;read_mirror;\rrb-\u0026gt;read_index = rb-\u0026gt;write_index;\r}\rreturn length;\r}\rRTM_EXPORT(rt_ringbuffer_put_force);\r/**\r* @brief Get data from the ring buffer.\r*\r* @param rb A pointer to the ring buffer.\r* @param ptr A pointer to the data buffer.\r* @param length The size of the data we want to read from the ring buffer.\r*\r* @return Return the data size we read from the ring buffer.\r*/\rrt_size_t rt_ringbuffer_get(struct rt_ringbuffer *rb,\rrt_uint8_t *ptr,\rrt_uint16_t length)\r{\rrt_size_t size;\rRT_ASSERT(rb != RT_NULL);\r/* whether has enough data */\rsize = rt_ringbuffer_data_len(rb);\r/* no data */\rif (size == 0)\rreturn 0;\r/* less data */\rif (size \u0026lt; length)\rlength = size;\rif (rb-\u0026gt;buffer_size - rb-\u0026gt;read_index \u0026gt; length)\r{\r/* copy all of data */\rrt_memcpy(ptr, \u0026amp;rb-\u0026gt;buffer_ptr[rb-\u0026gt;read_index], length);\r/* this should not cause overflow because there is enough space for\r* length of data in current mirror */\rrb-\u0026gt;read_index += length;\rreturn length;\r}\rrt_memcpy(\u0026amp;ptr[0],\r\u0026amp;rb-\u0026gt;buffer_ptr[rb-\u0026gt;read_index],\rrb-\u0026gt;buffer_size - rb-\u0026gt;read_index);\rrt_memcpy(\u0026amp;ptr[rb-\u0026gt;buffer_size - rb-\u0026gt;read_index],\r\u0026amp;rb-\u0026gt;buffer_ptr[0],\rlength - (rb-\u0026gt;buffer_size - rb-\u0026gt;read_index));\r/* we are going into the other side of the mirror */\rrb-\u0026gt;read_mirror = ~rb-\u0026gt;read_mirror;\rrb-\u0026gt;read_index = length - (rb-\u0026gt;buffer_size - rb-\u0026gt;read_index);\rreturn length;\r}\rRTM_EXPORT(rt_ringbuffer_get);\r1.4 判断缓冲区是否为空或满 判断缓冲区是否为空或满，通过函数 rt_ringbuffer_status 来实现。其逻辑是：在读写指针的值相同情况下，如果二者的指示位相同，说明缓冲区 为空 ；如果二者的指示位不同，说明缓冲区 为满 。注意这里的读写指针已经在读写( rt_ringbuffer_get 和 rt_ringbuffer_put )过程中转换为了读写索引。\nrt_inline enum rt_ringbuffer_state rt_ringbuffer_status(struct rt_ringbuffer *rb)\r{\rif (rb-\u0026gt;read_index == rb-\u0026gt;write_index)\r{\rif (rb-\u0026gt;read_mirror == rb-\u0026gt;write_mirror)\rreturn RT_RINGBUFFER_EMPTY;\relse\rreturn RT_RINGBUFFER_FULL;\r}\rreturn RT_RINGBUFFER_HALFFULL;\r}\r小结 在多线程中，对同一个环形缓冲区进行读写操作时，需要加上锁，不然存在访问不安全问题； 当只有一个读线程和一个写线程（单生产者单消费者模型）时，用 rt_ringbuffer_put 和 rt_ringbuffer_get 进行读写操作缓冲区是线程安全的，无需加锁；但是 rt_ringbuffer_put_force 不行，因为其可能对 读写索引 都进行操作的场景，这个时候再进行 rt_ringbuffer_get 读操作，就是不安全访问； 读写指针已经在读写( rt_ringbuffer_get 和 rt_ringbuffer_put )过程中转换为了读写索引。所以 read_index(读索引)和 write_index (写索引)可以直接用来操作缓冲区，无需转换； read_index 和 write_index 的大小区间为$[0, n-1]$ ， $n$ 为缓冲区大小； RT-Thread 的环形缓冲区不需要 buffer 大小为 2 的幂 。 2. Linux 中实现的 ring buffer 在 linux 内核中， kfifo 就是 ring buffer 的经典实现方式，本文将介绍 linux 2.6 版本中的 ring buffer 实现方式，主要介绍 缓冲区结构体 、 缓冲区初始化 、 读操作 、 写操作 、 判断缓冲区是否为空或满 。\n2.1 缓冲区结构体 kfifo 的 ring buffer 结构体定义如下，其中 buffer、size、in、out 环形缓冲区 4 个信息是一一对应的。但其中 in 、 out 分别是 写指针 和 读指针 ，而不是 写索引 和 读索引 。参数 lock 是自旋锁，在多进程/线程对同一个环形缓冲区进行读写操作时，需要进行锁保护。和 RT-Thread 对比，可以看到其并没有读写的 镜像指示位 。\nstruct kfifo {\runsigned char *buffer; /* the buffer holding the data */\runsigned int size; /* the size of the allocated buffer */\runsigned int in; /* data is added at offset (in % size) */\runsigned int out; /* data is extracted from off. (out % size) */\rspinlock_t *lock; /* protects concurrent modifications */\r};\r2.2 缓冲区初始化 在 kfifo 的初始化 kfifo_init 中可以看出，其会对所传入的 size 大小进行扩展，使其满足 size 为 2 的幂 。这样就可以使用性质： 如果缓冲区的长度是 2 的幂 ，则可以省略镜像指示位。如果读写指针的值相等，则缓冲区为空；如果读写指针相差 n(缓冲区大小)，则缓冲区为满 。所以在传入 buffer 的 size 大小时，最好开始就将其确定为 2 的幂 。\nstruct kfifo *kfifo_init(unsigned char *buffer, unsigned int size,\rint gfp_mask, spinlock_t *lock)\r{\rstruct kfifo *fifo;\r/* size must be a power of 2 */\rBUG_ON(size \u0026amp; (size - 1));\rfifo = kmalloc(sizeof(struct kfifo), gfp_mask);\rif (!fifo)\rreturn ERR_PTR(-ENOMEM);\rfifo-\u0026gt;buffer = buffer;\rfifo-\u0026gt;size = size;\rfifo-\u0026gt;in = fifo-\u0026gt;out = 0;\rfifo-\u0026gt;lock = lock;\rreturn fifo;\r}\r2.3 读操作和写操作 可以看到 kfifo 对读操作和写操作的实现非常简洁。在进行读操作和写操作时，其充分利用了无符号整型的性质。在 __kfifo_put (写操作)和 __kfifo_get (读操作)时， in (写指针)和 out (读指针)都是正向增加的，当达到最大值时，产生溢出，使得从 0 开始，进行循环使用。 in(写指针) 和 out(读指针) 会恒定的保持如下关系：\n读指针 + 缓冲区已存储数据长度 = 写指针 其中读指针是 out ，写指针是 in 。 out(读指针) 永远不会超过 in(写指针) 的大小，最多两者相等，相等就是缓冲区为空的时候。\n先看 __kfifo_put 的源码。 len = min(len, fifo-\u0026gt;size - fifo-\u0026gt;in + fifo-\u0026gt;out); 中表达的意思就是实际写入的长度一定要小于缓冲区的可用空间大小，防止发生覆盖已有元素的场景。来看这一句 l = min(len, fifo-\u0026gt;size - (fifo-\u0026gt;in \u0026amp; (fifo-\u0026gt;size - 1))); ，其中 (fifo-\u0026gt;in \u0026amp; (fifo-\u0026gt;size - 1)) 就是将 in(写指针) 转换为写索引，整体表达的意思是从 写索引 到缓冲区结束位置这一段所能写入数据的大小，这一段写入操作的代码为 memcpy(fifo-\u0026gt;buffer + (fifo-\u0026gt;in \u0026amp; (fifo-\u0026gt;size - 1)), buffer, l); 。如果这一段还不够，需要折返到缓冲区的开始位置，将剩下的部分写入到缓冲区中，其代码为 memcpy(fifo-\u0026gt;buffer, buffer + l, len - l); 。而且 $len \u0026gt;= l$, 当 $len=l$ 就说明第一段已经可以容纳所写入大小，缓冲区无需折返，第二个 memcpy 拷贝了零个字节，相当于什么也没有发生。\n再看 __kfifo_get 的源码。其思路基本和 __kfifo_put 一致，了解了上面的转换关系，就比较好理解：\n/*\r* __kfifo_put - puts some data into the FIFO, no locking version\r* @fifo: the fifo to be used.\r* @buffer: the data to be added.\r* @len: the length of the data to be added.\r*\r* This function copies at most 'len' bytes from the 'buffer' into\r* the FIFO depending on the free space, and returns the number of\r* bytes copied.\r*\r* Note that with only one concurrent reader and one concurrent\r* writer, you don't need extra locking to use these functions.\r*/\runsigned int __kfifo_put(struct kfifo *fifo,\runsigned char *buffer, unsigned int len)\r{\runsigned int l;\rlen = min(len, fifo-\u0026gt;size - fifo-\u0026gt;in + fifo-\u0026gt;out);\r/* first put the data starting from fifo-\u0026gt;in to buffer end */\rl = min(len, fifo-\u0026gt;size - (fifo-\u0026gt;in \u0026amp; (fifo-\u0026gt;size - 1)));\rmemcpy(fifo-\u0026gt;buffer + (fifo-\u0026gt;in \u0026amp; (fifo-\u0026gt;size - 1)), buffer, l);\r/* then put the rest (if any) at the beginning of the buffer */\rmemcpy(fifo-\u0026gt;buffer, buffer + l, len - l);\rfifo-\u0026gt;in += len;\rreturn len;\r}\rEXPORT_SYMBOL(__kfifo_put);\runsigned int __kfifo_get(struct kfifo *fifo,\runsigned char *buffer, unsigned int len)\r{\runsigned int l;\rlen = min(len, fifo-\u0026gt;in - fifo-\u0026gt;out);\r/* first get the data from fifo-\u0026gt;out until the end of the buffer */\rl = min(len, fifo-\u0026gt;size - (fifo-\u0026gt;out \u0026amp; (fifo-\u0026gt;size - 1)));\rmemcpy(buffer, fifo-\u0026gt;buffer + (fifo-\u0026gt;out \u0026amp; (fifo-\u0026gt;size - 1)), l);\r/* then get the rest (if any) from the beginning of the buffer */\rmemcpy(buffer + l, fifo-\u0026gt;buffer, len - l);\rfifo-\u0026gt;out += len;\rreturn len;\r}\rEXPORT_SYMBOL(__kfifo_get);\r2.4 判断缓冲区是否为空或满 kfifo 中没有专门的函数判断缓冲区是否为空或满，但可以通过 __kfifo_len 函数获取 缓冲区已存储数据长度 。如果其值等于零就说明缓冲区为空，如果其值等于缓冲区大小，就说明缓冲区满。\nstatic inline unsigned int __kfifo_len(struct kfifo *fifo)\r{\rreturn fifo-\u0026gt;in - fifo-\u0026gt;out;\r}\r小结 linux 中环形缓冲区（ring buffer）的实现，其实是对 镜像指示位 策略的扩展，读指针和写指针区间范围不再局限在镜像区间 $[0, 2n-1]$ ，而是整个 unsigned int 大小的空间，对于 32 位机器，读指针和写指针的区间范围是 $[0, 2^{32} - 1]$ ; 进行扩展后，还能维持如下的关系，是因为缓冲区大小 n 会被扩展为 2 的幂 ，那么 $2^32$ 肯定是 $n$ 扩展后的整数倍，所以还是能够满足如下关系； 读索引 = 读指针 \u0026amp; (缓冲区长度 - 1) 写索引 = 写指针 \u0026amp; (缓冲区长度 - 1) 读索引和写索引的区间范围仍然是 $[0, n-1]$ ， $n$ 为缓冲区大小； 在多进程/线程中，对同一个环形缓冲区进行读写操作时，需要加上锁，不然存在访问不安全问题； 当只有一个读进程/线程和一个写进程/线程时，无需加锁，也能保证访问安全。 3. 5.17+版本的 Linux 中实现的 ring buffer 在 linux5.17+ 版本中的 kfifo.c 和 kfifo.h 中，其源码实现已经和 linux 2.6 版本有很大的不同，但是最新版本的 ring buffer 核心思想和 linux 2.6 版本并没有不同。\nkfifo.h 文件中定义的 ring buffer 结构体，其中 in 、 out 依然是 写指针 和 读指针 ，mask 是缓冲区大小减 1（做\u0026amp;操作，更方便的将读写指针转换为 读写索引 ）， esize 缓冲区单个存储元素的字节大小(在 linux 2.6 版本中，一个元素就是一个字节大小，最新版本将其进行了扩展)， data 缓冲区的逻辑起始地址（指针类型不再是字节）。其它的 初始化接口 、 读接口 、 写接口 、 判断缓冲区是否为空或满接口逻辑 和 linux 2.6 大致差不多，可以对照源码看一下。\nstruct __kfifo {\runsigned int in;\runsigned int out;\runsigned int mask;\runsigned int esize;\rvoid *data;\r};\r四、总结 环形缓冲区（ring buffer）适合于事先明确了缓冲区的最大容量的情形。缓冲区的容量（长度）一般固定，可以用一个静态数组来充当缓冲区，无需重复申请内存； 如果缓冲区的大小需要经常调整，就不适合用环形缓存区，因为在扩展缓冲区大小时，需要搬移其中的数据，这种场合使用链表更加合适； 因为缓冲区成头尾相连的环形，写操作可能会覆盖未及时读取的数据，有的场景允许这种情况发生，有的场景又严格限制这种情况发生。选择何种策略和具体应用场景相关； 环形缓冲区（ring buffer）特别适合于通信双方循环发送数据的场景； 镜像指示位是一种高效判断缓冲区是否为空或满的策略，在 RT-Thread 和 linux 中都使用了该策略（或者是该策略的扩展），其能够保证在只有一个读线程（或进程）和一个写线程（或进程）中无需锁也能做到线程安全； 注意区分写指针和写索引，读指针和读索引，最终对缓冲区进行操作还是需要写索引和读索引； 如果自己嵌入式项目中需要使用环形缓冲区（ring buffer），可以借鉴 linux 2.6 版本的 kfifo 实现，很容易改写，而且非常高效。 五、参考资料 环形缓冲区\rring buffer，一篇文章讲透它？\r","date":"2023-12-02T02:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/9fd865ce11924381a127462463ae2234-2023-12-02.webp","permalink":"https://cuterwrite.top/p/ring-buffer/","title":"Ring buffer 详解"},{"content":"性能刺客之伪共享 一、前言 在多核并发编程中，如果将互斥锁的争用比作 性能杀手 的话，那么伪共享则相当于 性能刺客。杀手 与 刺客 的区别在于杀手是可见的，遇到杀手时我们可以选择战斗、逃跑、绕路、求饶等多种手段去应付，但 刺客 却不同， 刺客 永远隐藏在暗处，伺机给你致命一击，防不胜防。具体到我们的并发编程中，遇到锁争用影响并发性能情况时，我们可以采取多种措施（如缩短临界区，原子操作等等）去提高程序性能，但是伪共享却是我们从所写代码中看不出任何蛛丝马迹的，发现不了问题也就无法解决问题，从而导致伪共享在暗处严重拖累程序的并发性能，但我们却束手无策。\n二、缓存行 为了进行下面的讨论，我们需要首先熟悉缓存行的概念，学过操作系统课程存储结构这部分内容的同学应该对存储器层次结构的金字塔模型印象深刻，金字塔从上往下代表存储介质的成本降低、容量变大，从下往上则代表存取速度的提高。位于金字塔模型最上层的是 CPU 中的寄存器，其次是 CPU 缓存（L1，L2，L3），再往下是内存，最底层是磁盘，操作系统采用这种存储层次模型主要是为了解决 CPU 的高速与内存磁盘低速之间的矛盾，CPU 将最近使用的数据预先读取到 Cache 中，下次再访问同样数据的时候，可以直接从速度比较快的 CPU 缓存中读取，避免从内存或磁盘读取拖慢整体速度。\nCPU 缓存的最小单位就是缓存行，缓存行大小依据架构不同有不同大小，最常见的有 64Byte 和 32Byte ，CPU 缓存从内存取数据时以缓存行为单位进行，每一次都取需要读取数据所在的整个缓存行，即使相邻的数据没有被用到也会被缓存到 CPU 缓存中。\n三、缓存一致性 在单核 CPU 情况下，上述方法可以正常工作，可以确保缓存到 CPU 缓存中的数据永远是 干净 的，因为不会有其他 CPU 去更改内存中的数据，但是在多核 CPU 下，情况就变得更加复杂一些。多 CPU 中，每个 CPU 都有自己的私有缓存（可能共享 L3 缓存），当一个 CPU1 对 Cache 中缓存数据进行操作时，如果 CPU2 在此之前更改了该数据，则 CPU1 中的数据就不再是 干净 的，即应该是失效数据，缓存一致性就是为了保证多 CPU 之间的缓存一致。\nLinux 系统中采用 MESI 协议处理缓存一致性，所谓 MESI 即是指 CPU 缓存的四种状态：\nM（修改，Modified）：本地处理器已经修改缓存行，即是脏行，它的内容与内存中的内容不一样，并且此 cache 只有本地一个拷贝(专有)； E（专有，Exclusive）：缓存行内容和内存中的一样，而且其它处理器都没有这行数据； S（共享，Shared）：缓存行内容和内存中的一样, 有可能其它处理器也存在此缓存行的拷贝； I（无效，Invalid）：缓存行失效, 不能使用。 每个 CPU 缓存行都在四个状态之间互相转换，以此决定 CPU 缓存是否失效，比如 CPU1 对一个缓存行执行了写入操作，则此操作会导致其他 CPU 的该缓存行进入 Invalid 无效状态， CPU 需要使用该缓存行的时候需要从内存中重新读取。由此就解决了多 CPU 之间的缓存一致性问题。\n四、伪共享 何谓伪共享？上面我们提过 CPU 的缓存是 以缓存行为单位 进行的，即除了本身所需读写的数据之外还会缓存与该数据在同一缓存行的数据，假设缓存行大小是 32 字节，内存中有 abcdefgh 八个 int 型数据，当 CPU 读取 d 这个数据时， CPU 会将 abcdefgh 八个 int 数据组成一个缓存行加入到 CPU 缓存中。假设计算机有两个 CPU：CPU1 和 CPU2 ， CPU1 只对 a 这个数据进行频繁读写， CPU2 只对 b 这个数据进行频繁读写，按理说这两个 CPU 读写数据没有任何关联，也就不会产生任何竞争，不会有性能问题，但是由于 CPU 缓存是以缓存行为单位进行存取的，也是以缓存行为单位失效的，即使 CPU1 只更改了缓存行中 a 数据，也会导致 CPU2 中该缓存行完全失效，同理，CPU2 对 b 的改动也会导致 CPU1 中该缓存行失效，由此引发了该缓存行在两个 CPU 之间 乒乓 ，缓存行频繁失效，最终导致程序性能下降，这就是伪共享。\n下面是维基百科的定义：\nIn computer science, false sharing is a performance-degrading usage pattern that can arise in systems with distributed, coherent caches at the size of the smallest resource block managed by the caching mechanism. When a system participant attempts to periodically access data that is not being altered by another party, but that data shares a cache block with data that is being altered, the caching protocol may force the first participant to reload the whole cache block despite a lack of logical necessity. The caching system is unaware of activity within this block and forces the first participant to bear the caching system overhead required by true shared access of a resource.\n在计算机科学中，伪共享是一种性能降低的使用模式，可能出现在具有分布式、一致性缓存的系统中，缓存大小为缓存机制管理的最小资源块。当一个系统参与者试图定期访问未被其他方修改的数据，但该数据与正在被修改的数据共享一个缓存块时，缓存协议可能会强制第一个参与者重新加载整个缓存块，尽管在逻辑上没有必要。 缓存系统无法感知这个块内的活动，并强制第一个参与者承担由真正共享资源访问所需的缓存系统开销。\n五、如何避免伪共享 避免伪共享主要有以下两种方式：\n缓存行填充（Padding）：为了避免伪共享就需要将可能造成伪共享的多个变量处于不同的缓存行中，可以采用在变量后面填充字节的方式达到该目的。 使用某些语言或编译器中强制变量对齐，将变量都对齐到缓存行大小，避免伪共享发生。 六、获取缓存行大小 在 C++11 中，可以使用 std::hardware_destructive_interference_size 和 std::hardware_constructive_interference_size 获取缓存行大小，前者获取的是缓存行大小，后者获取的是缓存行大小的两倍，即 2 * std::hardware_destructive_interference_size。\n在 C 语言中，可以读取 coherency_line_size 文件获取缓存行大小，该文件位于 /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size ，该文件中存储的是缓存行大小的字节数，可以使用 cat 命令查看。也可以通过 long cache_line_size = sysconf(_SC_LEVEL1_DCACHE_LINESIZE) 的方式获取。\n七、通过对齐解决伪共享 C 语言中可以使用 posix_memalign 函数来实现对齐，该函数的声明如下：\nint posix_memalign(void **memptr, size_t alignment, size_t size);\r总结 一般伪共享都很隐蔽，很难被发现，当伪共享真正构成性能瓶颈的时候，我们有必要去努力找到并解决它，但是在大部分对性能追求没有那么高的应用中，伪共享的存在对程序的危害很小，有时并不值得耗费精力和额外的内存空间（缓存行填充）去查找系统存在的伪共享。还是那句我们一直以来应该遵循的原则 “不要过度优化，不要提前优化。” 。\n参考资料 C++性能榨汁机之伪共享\r","date":"2023-12-02T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/6c3f8961290e41f894f5a1cbb768aba9-2023-12-02.webp","permalink":"https://cuterwrite.top/p/false-sharing/","title":"性能刺客之伪共享"},{"content":"离子通道与 Hudgkin-Huxley 模型 从生物物理学的角度来看，动作电位是通过细胞膜中离子通道的电流的结果。在对乌贼的巨型轴突进行的一系列广泛实验中，霍奇金和胡克斯利成功地测量了这些电流，并以微分方程的方式描述了它们的动力学。在转向 Hudgkin-Huxley 方程之前，我们需要补充一些关于离子通道平衡电位的额外知识。\n一、平衡电位（Equilibrium Potential） 神经元和其他细胞一样，被一个膜所包围，该膜将细胞的内部与细胞外空间分开。细胞内的离子浓度与周围液体中的离子浓度不同。浓度的差异产生了一个电位，在神经元动力学中起着重要作用。该小节将对平衡电位给出一个直观的解释。\n1. Nernst 电位（Nernst Potential） 根据热力学理论，分子处于能量状态的概率与 Boltzmann 因子成正比，即 $p \\propto \\exp \\left( -E/kT \\right )$，其中 $E$ 是分子的能量，$k$ 是 Boltzmann 常数，$T$ 是温度。现在考虑带有电荷 $q$ 的正离子在静电场中。它们在位置 $x$ 的能量为 $E=q u(x)$，其中 $u(x)$ 是 $x$ 处的电势。因此，正离子在位置 $x$ 附近的概率为 $p(x) \\propto \\exp \\left[ -q u(x)/kT \\right ] $。对于带有正电荷 $q\u0026gt;0$ 的离子，离子密度在电位低的区域更高。我们用 $n(x)$ 表示点 $x$ 处的离子密度。则点 $x_1$ 处和点 $x_2$ 处的密度之间的关系为：\n$$ \\frac{n(x_1)}{n(x_2)} = \\exp \\left [ -\\frac{qu(x_1)-qu(x_2)}{kT} \\right ] \\tag{1.1} $$\n因此，电位差 $\\Delta u = u(x_1) − u(x_2)$ 引起了离子密度的差异。\n图 1.1： (a)在热平衡状态下，电场中的正离子分布为：高能态的离子较少，低能态的离子较多。因此，电压差会产生浓度梯度。(b) 类似地，离子浓度的差异会产生电势差。神经元内部的浓度与周围的浓度不同。由此产生的电位称为 **Nernst 电位** 。实线表示细胞膜。离子可以通过间隙传递。 由于这是关于平衡状态的陈述，反过来也是成立的。离子密度的差异会产生电势差 $\\Delta u$ 。我们考虑两个离子浓度分别为 $n_1$ 和 $n_2$ 的区域；参见图 1.1(b)。通过求解公式 (1.1) 得到 $\\Delta u$，我们发现，在平衡状态下，浓度差异会产生一个电压。\n$$ \\Delta u = \\frac{kT}{q} \\ln \\frac{n_1}{n_2} \\tag{1.2} $$\n该电压又被称为 Nernst 电位（Hille, 2001）。\n2. 反转电位（Reversal Potential） 细胞膜由一层薄的脂质双层组成，几乎是一个完美的电绝缘体。然而，在细胞膜中嵌入了特定的蛋白质，它们作为离子门控通道。第一种类型的门控通道是离子泵，第二种是离子通道。离子泵能够主动地将离子从一侧运输到另一侧。因此，细胞内液体中的离子浓度与周围环境不同。例如，哺乳动物神经元内的钠浓度（约为 $10 mM$ ）低于细胞外液体中的钠浓度（约为 $145 mM$ ）。另一方面，细胞内的钾浓度（约为 $140 mM$ ）高于周围环境中的钾浓度（约为 $5 mM$ ）。对于霍奇金和哈克斯利研究的鱿鱼巨大轴突，这些数字略有不同，但基本思想是相同的：细胞外的钠离子比细胞内多，而钾离子则相反。\n让我们暂时专注于钠离子。在平衡状态下，浓度差引起了约为 $+67 mV$ 的 Nernst 电位 $E_{Na}$ 。也就是说，在平衡状态下，细胞内部相对于周围环境具有正电势。细胞内部和周围液体通过离子通道相互联系，钠离子可以从膜的一侧通过到另一侧。如果电压差 $\\Delta u$ 小于 Nernst 电势 $E_{Na^{+}}$ 的值，更多的 $Na^+$ 离子会流入细胞，以减小浓度差异。如果电压大于 Nernst 电势，离子会从细胞流出。因此，当电压 $\\Delta u$ 通过 $E_{Na}$ 时，电流的方向会反转。因此，$E_{Na}$ 被称为反转电位。\n继续看钾离子，正如上面提到的，钾离子在细胞内的浓度（约为 $140 mM$ ）比细胞外液体（约为 $5 mM$ ）高。钾离子具有单个正电荷 $q = 1.6 × 10^{-19} C$ 。应用 Nernst 公式（1.2），其中玻尔兹曼常数 $k = 1.4 × 10^{-23} J/K$ ，在室温下得到 $E_K ≈ -83 mV$ 。因此，钾离子 $K^{+} 的反转电势是负的。\n到目前为止，我们考虑了钠或钾的存在。在真实的细胞中，这些和其他离子类型同时存在，并对跨膜电压做出贡献。实验发现，细胞膜的静息电位约为 $u_{rest} ≈ 65 mV$ 。由于 $E_K \u0026lt; u_{rest} \u0026lt; E_{Na}$ ，钾离子在静息电位下从细胞流出，而钠离子则流入细胞。在稳态下，主动离子泵平衡这种流动，并通过通道运输与通过通道的离子数量相同的离子返回。$u_{rest}$ 的值由通道中离子流动（膜的渗透性）和主动离子转运（维持浓度差的离子泵的效率）之间的动态平衡决定。\n二、Hudgkin-Huxley 模型 霍奇金和哈克斯利（1952）对乌贼的巨型轴突进行了实验，发现了三种不同类型的离子电流，即钠、钾和主要由氯离子组成的泄漏电流。特定的电压依赖性离子通道，一个用于钠，另一个用于钾，控制这些离子通过细胞膜的流动。泄漏电流负责其他未明确描述的通道类型。\n1. 模型定义（Model Definition） 图 2.1： Hodgkin-Huxley 模型示意图。 Hodgkin-Huxley 模型可以通过图 2.1 来理解。半透膜细胞膜将细胞内部与细胞外液体隔开，并起到电容器的作用。如果将输入电流 $I(t)$ 注入细胞，它可能会在电容器上增加进一步的电荷，或者通过细胞膜中的通道泄漏。\n图 2.1 中的每种通道类型都由一个电阻器表示。非特异通道具有泄漏电阻 $R$ ，钠通道具有电阻 $R_{Na}$ ，钾通道具有电阻 $R_K$ 。电阻器图中的对角箭头表示电阻值不固定，而是根据离子通道是否打开或关闭而变化。\n由于通过细胞膜的主动离子转运，细胞内的离子浓度与细胞外液体不同。由离子浓度差产生的 Nernst 电位在图 2.1 中由电池表示。由于每种离子类型的 Nernst 电位不同，分别为钠、钾和非特异第三通道设置了单独的电池，其电池电压分别为 $E_{Na}$ 、$E_K$ 和 $E_L$ 。\n现在让我们将上述电路图转化为数学方程。膜上电荷的守恒意味着施加的电流 $I(t)$ 可以分为充电电流 $I_C$ ，用于充电电容器 $C$ ，以及通过离子通道的其他电流 $I_k$ 。因此，可以写成以下方程：\n$$ I(t) = I_C(t) + \\sum_{k} I_k(t) \\tag{2.1} $$\n在标准的 Hodgkin-Huxley 模型中，只有三种类型的通道：一个带有 $Na$ 索引的钠通道，一个带有 $K$ 索引的钾通道，以及一个具有电阻 $R$ 的非特异泄漏通道。根据电容的定义 $C = q / u$ ，可以得到充电电流 $I_C = C\\frac{du}{dt}$ 。因此，方程 (2.1) 可以写成：\n$$ C \\frac{du}{dt} = I(t) - \\sum_{k} I_k(t) \\tag{2.2} $$\n在生物学术语中，$u$ 是膜上的电压，$\\sum_{k} I_k(t)$ 是通过细胞膜的离子电流之和。\n如上所述，Hodgkin-Huxley 模型描述了三种类型的通道。所有通道可以通过它们的电阻或等效地通过它们的电导来表征。泄漏通道由电压无关的电导 $g_L=1/R$ 来描述。由于 $u$ 是细胞膜上的总电压，$E_L$ 是电池的电压，在图 2.1 中泄漏电阻器的电压为 $u - E_L$ 。根据欧姆定律，我们得到泄漏电流 $I_L = g_L (u - E_L)$ 。\n其他离子通道的数学模型类似，只是它们的电导是电压和时间依赖的。如果所有通道都打开，它们分别以最大电导率 $g_{Na}$ 或 $g_K$ 发射电流。然而，通常情况下，一些通道被阻断。霍奇金和哈克斯利的突破是，他们成功地测量了通道的有效电阻如何随着时间和电压的变化而变化。此外，他们还提出了对其观察结果的数学描述。具体来说，他们引入了额外的门控变量 $m$ , $n$ 和 $h$ 来模拟模拟通道在给定时间点开放的概率。例如，钠通道的有效电导被建模为 $1 / R_{Na} = g_{Na} \\cdot m^3 h$ ，其中 $m$ 描述通道的激活（开放），$h$ 描述通道的失活（阻塞）。钾的电导率为 $1 / R_K = g_K \\cdot n^4$ ，其中 $n$ 描述通道的激活。\n总的来说，霍奇金和哈克斯利将公式 (2.2) 右边的三个离子电流写成：\n$$ \\sum_{k} I_k(t) = g_{Na} \\cdot m^3 h \\cdot (u - E_{Na}) + g_K \\cdot n^4 \\cdot (u - E_K) + g_L \\cdot (u - E_L) \\tag{2.3} $$\n其中参数 $E_{Na}$ , $E_K$ , 和 $E_L$ 是反转电位。\n三个门控变量 $m$ , $n$ 和 $h$ 根据以下形式的微分方程变化：\n$$ \\dot{x}=-\\frac{1}{\\tau_x (u)}\\left [ x-x_0(u)\\right ] \\tag{2.4} $$\n其中，$\\dot{x} = \\frac{dx}{dt}$ ，其中 $x$ 表示 $m$, $n$ 或者 $h$ 。公式 （2.4） 的解释很简单：对于一个固定的电压 $u$ ，变量 $x$ 以时间常数 $\\tau_x(u)$ 逼近目标值 $x_0(u)$ 。目标值 $x_0(u)$ 和时间常数 $\\tau_x(u)$ 对电压的依赖关系分别如图 2.2 (a), (b) 所示。\n图 2.2 ： Hodgkin-Huxley 模型。(a) 门控变量 $m$, $n$, $h$ 的平衡函数。(b)与电压有关的时间常数，静息电位为 $u=-65mV$ （箭头），参数由表 2.1 给出。 表 2.1 ：在大脑皮层上的锥体神经元上拟合的 Hodgkin-Huxley 方程的参数。$n$ 和 $m$ 的参数由 Zach Mainen（Mainen et al., 1995）根据 Huguenard 等人（1988）报告的实验进行拟合，$h$ 的参数由 Richard Naud 根据 Hamill 等人（1991）报告的实验进行拟合。电压以 $mV$ 为单位，膜电容为 $C = 1 \\mu F/ cm^2$ 。 图 2.2 中绘制的函数形式，以及公式（2.3）中的最大电导和反转电位，是霍奇金和哈克斯利根据经验推导出来的。\n实验者通过向细胞注入适当的电流来保持细胞膜上的电压在所需的值上。在实验中，假设实验者在 $t\u0026lt;t_0$ 时将细胞保持在静息电位 $u_0 =-65mV$ ，并且在 $t=t_0$ 时将电压切换到一个新值 $u_1$ 。对于 $t \u0026gt; t_0$ ，通过对微分方程（2.4）进行积分，可以得到以下动力学方程：\n$$ \\begin{aligned} \u0026amp; m(t)=m_0(u_1) + [m_0(u_0)-m_0(u_1)] \\exp \\left[ -\\frac{t-t_0}{\\tau_m(u_1)} \\right ] ,\\\\ \u0026amp; h(t)=h_0(u_1) + [h_0(u_0)-h_0(u_1)] \\exp \\left[ -\\frac{t-t_0}{\\tau_h(u_1)} \\right ] , \\end{aligned} \\tag{2.5} $$\n其中 $m(t)$ 和 $h(t)$ 分别表示钠通道和钾通道的激活和失活状态。基于给定的函数 $m_0(u)$ 、$h_0(u)$ 、$\\tau_m(u)$ 和 $\\tau_h(u)$ 的模型，可以预测在 $t \u0026gt; t_0$ 时电压变化引起的钠电流 $I_{Na}(t)=g_{Na} [m(t)^3] h(t) (u_1 - E_{Na})$ 和钾电流 $I_K(t)=g_K [n(t)^4] (u_1 - E_K)$ 。\n而 $n(t)$ 的表达式为：\n$$ n(t)=n_0(u_1) + [n_0(u_0)-n_0(u_1)] \\exp \\left[ -\\frac{t-t_0}{\\tau_n(u_1)} \\right ] \\tag{2.6} $$\n图 2.3 ：Hodgkin 和 Huxley 绘制的钾离子电导率变化原始测量曲线和公式拟合曲线。施加 $25 mV$ 的电压切换后，回到静息电位后，钾的电导率（圆圈）的测量时间过程。拟合实线是基于公式（2.6）的。 霍奇金和哈克斯利使用方程（2.4）和（2.5）反过来进行研究。他们在使用适当的药物阻断钠通道后，施加电压变化并测量钾电流的时间变化。将记录的电流除以驱动电位 $(u_1 - E_K)$ 可以得到时间相关的电导率 $g_K [ n(t)^4]$ (图 2.3 ）。使用方程（2.6），霍奇金和哈克斯利推导出了钾通道的 $n_0(u_1)$ 和 $τ_n(u_1)$ 的值，以及 $n^4(t)$ 中的指数 4。通过对不同的 $u_1$ 值重复实验，可以得到 $n_0(u)$ 和 $τ_n(u)$ 的实验曲线。\n变量 $m$ 被称为激活变量。为了理解这个术语，我们注意到从图 2.2 可以看出，在神经元的静息电位 $u = -65 mV$ 时，$m_0(u)$ 的值接近于零。因此，在静息状态下，通过通道的钠电流 $I_{Na} = g_{Na} m^3 h(u - E_{Na})$ 为零。换句话说，钠通道是关闭的。\n当膜电位显著增加超过静息电位时，门控变量 $m$ 增加到其新值 $m_0(u)$ 。只要 $h$ 不变，钠电流就会增加，门打开。因此，变量 $m$ “激活”了通道。如果在电压恢复到静息状态后，$m$ 衰减回零，就被称为“去激活”。类似地，关于失活变量 $h$ 的术语也是类似的。在静息状态下，$h$ 有一个较大的正值。如果电压增加到超过 $-40 mV$ 的值，$h$ 接近一个接近静息状态的新值 $h_0(u)$ 。因此，通道通过一个由 $\\tau_h(u)$ 给出的时间常数“失活”（阻塞）。如果电压返回到零，$h$ 增加，使得通道经历“去失活”。这听起来像是一种棘手的词汇，但事实证明，将一个去激活的通道（$m$ 接近零，$h$ 接近 1）与一个失活的通道（$h$ 接近零）区分开来是有用的。\n2. 随机通道的打开（Stochastic Channel Opening） 首先，离子通道的数量在一个细胞膜上是有限的，而且每个离子通道的开启和关闭是随机的。因此，当实验者记录通过细胞膜的电流时，他不会发现测量变量随时间平滑可靠地演变，而是会发现电流高度波动，每次重复实验时看起来都不同。这就是离子通道的随机性（如图 2.4 所示）。\n图 2.4 ： 随机通道激活现象。在实验中，当施加一个电压阶跃到细胞膜上时，通过细胞膜的电流会呈现阶梯状变化，并且在每次试验中都有所不同（如顶部的连续轨迹所示）。对多次试验进行平均后，得到的结果是底部的轨迹。 然而，Hodgkin-Huxley 模型是用确定性方程描述离子通道的开启和关闭的。这些方程涉及的变量包括 $m$ ，$h$ 和 $n$ ，它们对应的是通过一个假设的、包含无限数量离子通道的极大细胞膜的电流密度，或者说是通过一小片细胞膜的电流，但是这个电流是在多次重复同一实验后得到的平均值。这就是 $Hodgkin-Huxley$ 模型的局限性，因为它忽略了离子通道的随机性。不过可以通过向模型中添加适当的噪声来包含随机性。这种噪声可以模拟离子通道开启和关闭的随机性，从而使模型更准确地描述神经元的动力学行为。\n使用以电压为自变量的转换速率 $\\alpha$ 和 $\\beta$ 来描述每种通道类型的激活和失活动力学，公式如下：\n$$ \\begin{aligned} \\dot{m}= \u0026amp;\\alpha_m (u) (1-m) - \\beta_m (u) m ,\\\\ \\dot{n}= \u0026amp;\\alpha_n (u) (1-n) - \\beta_n (u) n ,\\\\ \\dot{h}= \u0026amp;\\alpha_h (u) (1-h) - \\beta_h (u) h , \\\\ \\end{aligned} \\tag{2.7} $$\n公式 （2.4）和 （2.7）是等价的。逼近值 $x_0(u)$ 和时间常数 $\\tau_x(u)$ 由变换 $x_0(u)=\\alpha_x(u)/[\\alpha_x(u)+\\beta_x(u)]$ 和 $\\tau_x(u)=1/[\\alpha_x(u)+\\beta_x(u)]$ 给出。表 2.1 中的第二个表格给出了各种以 $u$ 为自变量的经验拟合函数 $\\alpha$ 和 $\\beta$ ，用于生成图 2.2 中的曲线。\n方程（2.7）是化学中常用的方程，用于描述具有速率常数 $α$ 和 $β$ 的激活过程的随机动力学。我们可以将这个过程解释为具有电压依赖的转换速率的两个状态之间的分子开关。例如，激活变量 $n$ 可以解释为找到一个开放的钾通道的概率。因此，在一个具有 $K$ 个离子通道的细胞膜中，预计有 $k \\approx (1 - n)K$ 个通道是关闭的。我们可以将 $\\alpha_n(u) \\Delta t$ 解释为在短时间区间 $\\Delta t$ 内，暂时关闭的通道中有一个切换到开放状态的概率。\n3. Hudgkin-Huxley 模型的动力学（Dynamics of Hudgkin-Huxley Model） 不同类型的输入被依次考虑，包括脉冲输入、恒定输入、阶跃电流输入和时间依赖输入。选择这些输入场景是为了直观理解 Hodgkin-Huxley 模型的动力学特性。Hodgkin-Huxley 模型最重要的特性是能够产生动作电位。在图 2.5(a) 中，一个持续 $1ms$ 的短脉冲电流在 $t=1ms$ 时施加，引发了一个动作电位。这个脉冲的幅度接近 $100mV$ ，半峰宽约为 $2.5ms$ 。在动作电位之后，膜电位下降到静息电位以下，再慢慢回到静息电位值 $-65mV$ 。\n图 2.5 ： (a)动作电位。Hodgkin-Huxley 模型受到 $t=1ms$ 和 $t=2ms$ 之间的短而强的电流脉冲的刺激。对于 $t\u0026gt;2ms$ 的膜电位 $u(t)$ 的时间变化显示了动作电位（正峰值），随后是相对不应期，此时电位低于静息电位 $u_{rest}$（虚线）。右侧面板显示了 $t=2ms$ 和 $t=5ms$ 之间动作电位的放大视图。（b）门控变量 $m，h，n$ 的变化揭示了动作电位是如何通过钠通道和钾通道介导的。（c）钠电流 $I_{Na}$ 取决于变量 $m$ 和 $h$ ，在动作电位的上升阶段有一个脉冲。钾电流 $I_K$ 受变量 $n$ 控制，并与 $I_{Na}$ 相比有一定的延迟开始。 脉冲产生过程中离子通道的动力学（Ion channel dynamics during spike generation） 为了理解动作电位生成的生物物理学基础，我们回到图 2.2(a) 。我们发现 $m_0$ 和 $n_0$ 随着 $u$ 的增加而增加，而 $h_0$ 则减少。因此，如果某些外部输入导致膜电压上升，由于 $m$ 的增加，钠通道的电导增加。结果，正钠离子流入细胞，进一步提高膜电位。如果这种正反馈足够大，就会引发动作电位。当膜电位接近钠电流的反转电位 $E_{Na}$ 时，这种爆发性增加自然停止。 在高 $u$ 值下，由于因子 $h$ 的作用，钠电导缓慢关闭。如图 2.2(b) 所示，时间常数 $\\tau_h$ 始终大于 $\\tau_m$ 。因此，使通道失活的变量 $h$ 对电压增加的反应比激活通道的变量 $m$ 慢。在类似的较慢时间尺度上，钾电流在图 2.5(c) 中开始。由于它是向外的电流，它降低了电位。钠和钾电流的整体效应是一个短暂的动作电位，随后是负超调；(负超调，又被称为超极化脉冲后电位，是由于 $h$ 变量引起的钠通道的缓慢去失活过程所导致）。\nHudgkin-Huxley 模型的动力学覆盖的知识比较多，主要概念如下：\n平均发射率与增益函数（Mean Firing Rate and Gain Function） 时间依赖的输入刺激 （Stimulations by Time-Dependent Input） 发射阈值（Firing Threshold） 不应性（Refractoriness） 阻尼振荡与瞬时脉冲（Damped Oscillations and transient spiking） 这里就不继续介绍了，有兴趣的可以参考原文。\n参考文献 [1] Gerstner, Wulfram, Werner M. Kistler, Richard Naud, and Liam Paninski. Neuronal dynamics: from single neurons to networks and models of cognition. Cambridge university press, 2014. ","date":"2023-11-02T00:55:55Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/20231102162211-2023-11-02.webp","permalink":"https://cuterwrite.top/p/ion-channels-and-hudgkin-huxley/","title":"离子通道与 Hudgkin-Huxley 模型"},{"content":"脉冲神经网络入门：神经元与数学 一、神经元系统的结构 生物神经元是一种高度特化的细胞，其结构和功能包含很多因素，其中神经元的几何形态特征和电学物理特性是两个重要方面。几何形态特征主要指神经元的空间结构，而电学物理特性包含神经元不同的动作点位发放模式。生物神经系统内有两类细胞：神经元细胞和神经胶质细胞，前者担负着信息处理的主要任务，而后者对前者起支持作用。神经元细胞的几何形态结构和电学物理特性是生物神经系统进行信息处理的基础。所谓的神经胶质细胞，它们是脑组织能量供应和结构稳定所需要的。由于胶质细胞不直接参与信息处理，本文将不再进一步讨论它们。本文还将忽略一些罕见的神经元亚型，如哺乳动物视网膜上的非脉冲神经元。本文只专注于脉冲神经元。\n1. 理想的脉冲神经元 (ideal spike neuron) 一个典型的神经元可以分为三个功能不同的部分，称为树突（dendrite）、细胞体（soma）和轴突（axon）。\n图 1.1：(a) Ramón y Cajal 于 1899 年绘制的神经元示意图。树突、体细胞和轴突可以被清楚地区分出来。图片显示了一个神经元动作电位的例子。动作电位是一个持续时间为 $1ms$ 的短电压脉冲，振幅约为 $100mv$ 。(b) 从突触前神经元 $j$ 到突触后神经元 $i$ 的信号传输。突触由虚线圈标记。右下端的轴突通向其它神经元。 树突：指从神经元细胞体内向外伸出的许多较短的分支，它们充当着神经元的输入端，接收来自其它神经元的神经冲动并传递给细胞体； 细胞体：神经元的核心，由细胞核、细胞质和细胞膜等组成，负责处理接收到的信号； 轴突：指由神经元细胞体向外伸出的一条最长的分支，它是管状纤维组织，充当神经元的输出端，再轴突末端有很多神经末梢，它们向外发出神经冲动。 神经元的轴突末梢经过多次分支，最后每一个小支的末端膨大呈杯状或球状，称为突触小体。这些突触小体可以与多个神经元的细胞体或树突相接触，形成神经元之间连接的突触（synapse）。通常把发送神经元成为突触前神经元（presynaptic neuron），把接收神经元称为突触后神经元（postsynaptic neuron）。\n2. 脉冲序列 (spike train) 生物神经系统在内外刺激作用下，使得神经元按照一定的时间间隔产生一系列的活动电位，称为脉冲序列 (spike train)。神经元信号由短的电脉冲组成，可以通过在神经元的体部或靠近体部或轴突的位置放置一个精细的电极来观察，如下图所示，脉冲（或活动电位），其振幅为 100 毫伏，通常持续时间为 1~2 ms。脉冲的形式不会因为活动电位沿轴突传播而改变。神经元发送的单个活动电位或脉冲是信号传递的基本单元，因为所有脉冲的波形都是相似的，所以活动电位的形状不会携带任何信息，而传递有用神经信息的是脉冲的发放时间和频率。\n图 1.2：动作电位是刻板事件。在最大电压时间内排列的膜电位记录显示动作电位形状的变化很小。 脉冲序列中的活动电位通常是很好地分开的。即使有非常强的输入，也不可能在第一次脉冲期间紧接着激发第二次脉冲。两个脉冲之间的最小距离定义了神经元的绝对不应期（absolute refractory period）—— 大致在活动电位的复极化阶段（repolarization phase），无论用任何强的刺激都不能再引起活动电位。\n3. 突触 (synapse) 突触前神经元的轴突与突触后细胞的树突（或体细胞）接触的部位是突触。脊椎动物大脑中最常见的突触类型是化学突触。在化学突触处，轴突终端非常接近突触后神经元，在突触前和突触后细胞膜之间只留下一个微小的间隙。这就是所谓的突触间隙（synaptic cleft）。当一个活动电位到达突触时，它触发了一个复杂的生化处理步骤链，导致神经递质从突触前末端释放到突触间隙中。一旦递质分子到达突触后一侧，它们将被突触后细胞膜上的专门受体检测到，并导致（直接或通过生化信号链）打开特定通道，导致细胞外液体中的离子流入细胞。离子的涌入反过来又改变了突触后部位的膜电位，因此，最后，化学信号被转化为电反应。从突触前神经元传入的脉冲信号引起突触后神经元膜电位发生的变化称为突触后电位（postsynaptic potential）。\n除了化学突触之外，神经元还可以通过电突触连接，称为间隙连接（gap junctions）。特化膜蛋白在两个神经元之间形成直接的电连接。关于间隙连接的功能方面当前所知不多，但它们被认为参与了神经元的同步。\n二、神经动力学的要素 脉冲对突触后神经元的影响可以用细胞内电极来记录，该电极测量细胞内部和其周围环境之间的电位差 $u(t)$ 。这个电位差被称为膜电位。在没有任何输入的情况下，神经元处于静息状态，对应一个恒定的膜电位 $u_{rest}$，称为静息电位（resting potential），一般在 $-80\\sim -40mV$ （当以细胞外的电位为 0 ）。当神经元受到外界刺激，突触后电位的总和超过某一阈值时，神经元产生一个不衰减的沿神经纤维传递的神经冲动，即活动电位或脉冲。活动电位的动态变化过程包含一个迅速的去极化正向电位变化和缓慢的复极化负向电位变化。活动电位的另一特征是电位的极性在峰电位顶端倒转，细胞内由静息时的负电位变为正电位，这一过程称为超射。神经元活动电位的产生会导致局部的兴奋性发生一系列的变化。大致在活动电位的复极化阶段（repolarization phase），无论用任何强的刺激都不能再引起活动电位，这个阶段称为绝对不应期（absolute refractory period）；在随后的短时间内，活动电位进入超极化阶段（hyperpolarization phase），用比原来强的刺激方能引起活动电位，而且反应幅度还会小一些，这个阶段称为相对不应期（relative refractory period）。神经元对信号的传递方式在很大程度上与神经元的电学特性有关。\n图 2.1：膜电位在绝对不应期和相对不应期的变化。在绝对不应期，神经元不能再次激发。在相对不应期，神经元可以激发，但需要更强的刺激。 1. 突触后电位（postsynaptic potential） 从突触前神经元传入的脉冲信号引起突触后神经元膜电位发生的变化称为突触后电位（postsynaptic potential），具有局部电位的性质。一个神经元通常有许多突触，其中有些是兴奋性的，有些是抑制性的。对于从突触前神经元传来的多个脉冲，由于突触类型的不同，突触后电位可分为兴奋性和抑制性两类。兴奋性突触使突触后神经元的膜去极化，产生正的突触后电位，称为兴奋性突触后电位（excitatory postsynaptic potential，EPSP）。EPSP 在传入脉冲到达突触后神经元 $0.3\\sim 0.5ms$ 之后产生，它有一个较快的上升过程和缓慢的指数衰减过程，电位总共持续 $10\\sim 20ms$ 。抑制性突触使突触后神经元的膜超极化，产生负的突触后电位，称为抑制性突触后电位（inhibitory postsynapticpotential，IPSP），IPSP 到达峰值时间和 EPSP 相似。\n图 2.2：(a)兴奋性突触后电位（EPSP）; (b)抑制性突触后电位（IPSP）。 用数学术语规范化，那么研究神经元 $i$ 的膜电位随时间变化的函数 $u_i(t)$ 。在输入脉冲到达之前，有 $u_i(t)=u_{rest}\\ (t=0)$ 。对于 $t\u0026gt;0$ ，在电极上看到神经元 $i$ 的反应如下：\n$$ u_i(t)-u_{rest}=: \\varepsilon_{ij}(t) \\tag{2.1} $$\n2. 发射阈值与活动电位（firing threshold and action potential） 考虑两个突触前神经元 $j=1,2$ ，它们都向突触后神经元 $i$ 发送脉冲。神经元 $j=1$ 在时刻 $t_1^{(1)}, t_2^{(2)}, \\cdots$ 发送脉冲，神经元 $j=2$ 也在时刻 $t_1^{(1)}, t_2^{(2)}, \\cdots$ 发送脉冲。每个脉冲分别引起一个突触后电位 $\\varepsilon_{i1}$ 或 $\\varepsilon_{i2}$ 。只要只有少数的输入脉冲，电位的总变化大小约是各个 PSP 的总和：\n$$ u_i(t)=\\sum_{j}\\sum_{f} \\varepsilon_{ij}(t-t_j^{f}) + u_{rest} \\tag{2.2} $$\n即，膜电位对输入脉冲的反应是线性的。\n另一方面，如果在很短的时间间隔内有太多的输入脉冲到达，线性就会被打破。一旦膜电位达到一个临界值 $\\vartheta$ ，它的曲线就会显示出与 PSP 的简单求和完全不同的行为：膜电位表现出类似脉冲的偏移，振幅约为 $100 mV$ 。这个短电压脉冲将沿着神经元轴突与其他神经元的突触传播。在脉冲之后，膜电位并不直接回到静止电位，而是在许多神经元类型中通过低于静止值的超极化阶段。\n单个 EPSP 的振幅在 $1 mV$ 的范围内。脉冲初始临界值比静息电位高约 $20$ 至 $30 mV$ 。因此在大多数神经元中，如下图所示的四个脉冲是不足以触发一个活动电位的。相反地，需要大约 $20\\sim 50$ 个突触前脉冲在很短的时间窗口内到达才能触发一个突触后活动电位。这个时间窗口称为发射阈值（firing threshold），它是神经元的一个重要参数。\n图 2.3：来自第二个突触前神经元 $j=2$ 的输入脉冲在来自神经元 $j=1$ 的尖峰后不久到达，导致第二个突触后电位增加到了第一个上。 三、Integrade-and-fire 模型 神经元动力学可以被视为一个整合的过程，与出发活动电位超过某个临界电压的机制相结合。事实上，在实验中，发射时间通常被定义为膜电位从下往上达到某个阈值的时刻。为了建立一个神经元动力学的现实模型，我们通过阈值 $\\vartheta$ 来描述神经元的发射阈值。如果电压 $u_i(t)$ （包含所有输入的总效应）从下往上到达 $\\vartheta$ ，我们就说神经元会发射一个脉冲。跨越阈值的时刻定义了发射时间 $t_i^f$ 。\n该模型利用了一个事实，即一个而给定的神经元的活动电位总是具有大致相同的形式。如果一个活动电位的形状总是相同的，那么这个形状就不能用来传递信息；相反，信息包含在脉冲的存在或不存在中。因此活动电位被简化为“发生在一个精确的时刻的事件”。\n将活动电位描述为事件的神经元模型被称为 Intergrate-and-fire 模型。该模型没有尝试描述活动电位的形状。Integrade-and-fire 模型有两个独立的组成部分，都是定义其动力学所必须的：\n描述膜电位 $u_i(t)$ 变化的方程； 产生脉冲的机制。 在下文中将介绍最简单的 Intergrade-and-fire 类模型：Leaky Integrade-and-fire 模型，该模型有两个独立的组成部分：\n描述膜电位变化的线性微分方程； 脉冲发射的阈值。 1. 输入的整合（input integration） 变量 $u_i$ 描述了神经元 $i$ 的膜电位的瞬时值。在没有任何输入的情况下，电位处于静息值 $u_{rest}$ 。如果实验者向神经元 $i$ 注入电流 $I(t)$ ，或神经元 $i$ 接收其它神经元的突触输入，电位 $u_i$ 将被偏离其静止值。\n为了得到一个将瞬时电压 $u_i(t) - u_{rest}$ 与输入电流 $I(t)$ 联系起来的方程，我们使用电学理论中的基本定律。一个神经元被细胞膜所包围，这是一个相当好的绝缘体。如果一个短的电流脉冲 $I(t)$ 被注入到神经元中，额外的电荷 $q=\\int I(t\u0026rsquo;)\\ dt\u0026rsquo;$ 必须去到某个地方：给细胞膜充电（如下图所示）。因此，细胞膜的作用就相当于一个容量为 $C$ 的电容器。因为绝缘体并不完美，电荷会随着时间的推移慢慢通过细胞膜泄露。因此，细胞膜可以用一个有限的泄露电阻 $R$ 表示。\n图 3.1：神经元的电学特性：被动膜。(a)由细胞膜（大圈）包围的神经元接收一个（正）输入电流 $I(t)$ ，增加细胞内的电荷。细胞膜的作用就像一个与电阻并联的电容器，与电位为 $u_{rest}$ 的电池并联。(b)细胞膜对具有平滑电压轨迹的阶梯电流的反应。 代表 Leaky Integrate-and-fire 模型的基本电路由一个电容 $C$ 和一个由电流 $I(t)$ 驱动的电阻 $R$ 并联组成。如果驱动电流 $I(t)$ 为零，则电容器两端的电压由电池电压 $u_{rest}$ 给出。\n为了分析电路，我们使用电流守恒定律，将驱动电流分成两部分。\n$$ I(t) = I_{R} + I_{C}. \\tag{3.1} $$\n第一个是通过线性电阻 $R$ 的阻性电流 $I_R$ ，根据欧姆定律可以计算出 $I_R=\\frac{u_R}{R}$，其中 $u_R=u-u_{rest}$ 是电阻两端的电压。第二个分量 $I_C$ 给电容器 $C$ 充电。根据电容的定义 $C=\\frac{q}{u}$ ，其中 $q$ 为电荷，$u$ 为电压，我们可以得出电容电流 $I_C=\\frac{dq}{dt}=C \\frac{du}{dt}$ ，即：\n$$ I(t)=\\frac{u(t)-u_{rest}}{R}+C \\frac{du}{dt}. \\tag{3.2} $$\n等式两边乘以 $R$ ，并引入时间常数 $\\tau_{m}=RC$ ， 则标准形式为：\n$$ \\tau_m \\frac{du}{dt} = -[u(t)-u_{rest}]+RI(t). \\tag{3.3} $$\n其中，$u$ 是膜电位，$\\tau_m$ 是神经元的膜时间常数。\n图 3.2：被动膜上的短脉冲和总充电量。由短电流脉冲 $I(t)$ 驱动的漏电整合器的电压响应振幅（底部）（顶部）只取决于总电荷 $q = \\int I(t) \\\\ dt$ ，而不取决于电流脉冲的高度。 从数学的角度来看，公式 (3.3) 是一个线性微分方程。从电气工程师的角度来看，它是一个漏电整合器或 $RC$ 电路的方程，其中电阻 $R$ 和电容 $C$ 是平行排列的。从神经科学家的角度来看，它被称为被动膜的方程。\n方程 (3.3) 的解是什么？我们假设，无论出于什么原因，在时刻 $t=0$ 时，膜电位的值为 $u_{rest} + \\Delta u$ 。在 $t\u0026gt;0$ 时，输入电流 $I(t)$ 将消失变为零。直观地讲，我们期望，如果我们等待足够长的时间，膜电位会放松到静息电位 $u_{rest}$ 。事实上，具有初始条件 $u(t_0)=u_{rest} + \\Delta u$ 的方程 (3.3) 的解是：\n$$ u(t)-u_{rest}=\\Delta u \\exp \\left ( -\\frac{t-t_0}{\\tau_m} \\right)\\ \\mathrm{for}\\ t\u0026gt;0. \\tag{3.4} $$\n因此，在没有输入的情况下，膜电位以指数形式衰减静息电位。膜时间常数 $\\tau_m=RC$ 是衰减的特征时间。对于一个典型的神经元来说，它在 $10ms$ 的范围内，因此与 $1ms$ 数量级的脉冲持续时间相比相当长。解 (3.4) 的有效性可以通过在方程两边取导数来检查。由于它是没有输入时的解，它又被称为自由解（free solution）。\n2. 脉冲输入（pulse input） 在我们继续定义 Intergrate-and-Fire 模型及其变体之前，让我们研究一下由公式 (3.3) 定义的被动膜的动力学。假设被动膜受到恒定输入电流 $I(t)=I_0$ 的刺激。该电流从 $t=0$ 开始，持续到 $t=Delta$ 。为了简单起见，我们假设 $t=0$ 时，膜电位为 $u_{rest}$ 。\n第一步，我们计算一下膜电位的时间过程。膜电位的轨迹可以通过整合方程 (3.3) 和初始条件 $u(t_0)=u_{rest}$ 得到，即 $0 \u0026lt; t \u0026lt; \\Delta$ 时的解为：\n$$ u(t) = u_{rest} + RI_0 \\left [ 1 - \\exp \\left ( -\\frac{t}{\\tau_m} \\right ) \\right ]. \\tag{3.5} $$\n如果输入电流从未停止，膜电位 (3.5) 将在 $t\\rightarrow \\infty$ 时接近渐进值 $u(\\infty)=u_{rest}+RI_0$ 。一旦达到稳定状态，电容器上的电荷就不再变化。然后，所有的输入电流必须流经电阻。因此，电阻处的稳态电压是 $RI_0$ ，所哟膜的总电压是 $u_{rest}+RI_0$ 。\n3. 脉冲发射阈值（spike firing threshold） 发射时间指的是一个给定的神经元发射动作电位 $t^f$ 的时刻。Leaky Integrate-and-Fire(LIF) 模型中的发射时间 $t^f$ 是由一个阈值标准定义的：\n$$ t^f\\ : \\quad u(t^f) = \\vartheta. \\tag{3.6} $$\n图 3.3：Integrate-and-Fire 模型。(a)由恒定输入电流 $I_0=1.5$ 驱动的 Integrate-and-fire 神经元的膜电位的事件过程。电压 $\\Delta u(t)=u-u_{rest}$ 被阈值 $\\vartheta$ 归一化。输入电流的单位将被选择，以便 $I_0=1$ 能对应达到 $t\\rightarrow \\infty$ 的阈值曲线。在一个脉冲过后，电位被重置为 $u_{\\tau} = u_{rest}$ 。(b)对随时间变化的输入电流的电压反应。 虽然脉冲的形式没有被明确描述。然而注意到，在发射时间 $t^f$ 之后，电位立即被重置为一个新的值 $u_r \u0026lt; \\vartheta$。\n$$ \\lim_{\\delta \\rightarrow 0; \\delta \u0026gt; 0} u(t^f + \\delta) = u_r. \\tag{3.7} $$\n对于 $t\u0026gt;t^f$，动力学再次由 (3.3) 给出，直到发生下一个阈值跨越。联立 (3.3) 和 (3.7)，我们可以定义 Leak Integrate-and-Fire(LIF) 模型（Stein, 1967）。图 3.3 显示了由恒定电流 $I_0$ 驱动的 LIF 模型的电压曲线。\n对于神经元 $i$ 的发射时间，我们定义 $t_i^f$ ，其中 $f=1,2,\\cdots $ 是脉冲的标签。从形式上看，我们可以将神经元的脉冲序列表示为发射时间的序列：\n$$ S_i(t) = \\sum_{f} \\delta (t-t_i^f). \\tag{3.8} $$\n其中，$\\delta(x)$ 是 Dirac $\\delta$ 函数：\n$$ \\delta(x)=\\begin{cases} 0,\u0026amp;x = 0 \\\\ \\int_{-\\infty}^{\\infty} \\delta(x) dx = 1,\u0026amp; x \\neq 0 \\end{cases} \\tag{3.9} $$\n四、LIF 模型的局限性 LIF 模型是高度简化的，忽略了神经元动力学的许多细节。尤其是，可能来自突触前神经元或者电流注入的输入被线性整合，与突触后神经元的状态无关：\n$$ \\tau_m \\frac{du}{dt} = -[u(t)-u_{rest}]+RI(t). \\tag{4.1} $$\n其中，$I(t)$ 是输入电流。此外，在每个输出脉冲之后，膜电位被重置。\n$$ \\mathrm{if}\\ u(t)=\\vartheta \\quad\\mathrm{then} \\ \\lim_{\\delta \\rightarrow 0; \\delta \u0026gt; 0} u(t+\\delta) = u_r. \\tag{4.2} $$\n这样就不会保留对以前脉冲的记忆。现在，让我们列出到目前位置讨论的简化模型的主要局限性。\n1. 适应、爆发和抑制性反弹（adaptation, bursting and inhibitory rebound） 通过细胞内电极注入电流。在一个标准的实验方案中，我们可以施加一个刺激电流，在时间 $t_0$ 从一个电流值 $I_1$ 切换到一个新的电流值 $I_2$ 。假设 $I_1=0$ ，这样神经元在 $t\u0026lt;t_0$ 时是静息状态的。如果电流 $I_2$ 足够大，它将引起 $t\u0026gt;t_0$ 的脉冲。大多数神经元会对当前阶跃做出反应，产生一列脉冲，脉冲之间的间隔会连续增加，直到达到周期性发射的稳定状态。\n图 4.1：对当前阶跃的反应。在(a)(c)中，电流在 $t=t_0$ 时从 $I_1=0$ 切换到 $I_2\u0026gt;0$ 。fast-spiking neuron(a)在没有适应的情况下具有较短的脉冲间隔，而 regularly firing neuron(c)表现出适应性，可以看到脉冲间隔时间的增加。(b)中显示了一个 stuttering neuron(指发生语言或运动障碍的神经元，这种神经元在传递信号时可能会出现中断、重复或不协调的行为，导致口吃或肌肉抽动等症状)的例子。许多神经元在抑制性电流 $I_1 \u0026lt;0$ 被关闭后发出一个抑制性反弹脉冲(d)。 图 4.1(c)中这种具有适应性的神经元被称为 regularly firing neuron。适应是一个缓慢的过程，在几个脉冲上积累起来。由于标准的 LIF 模型在每次脉冲后将电位重置位相同的值并重新启动整合过程，因此在最近的脉冲之后不会保留任何记忆。因此，LIF 神经元不具有适应性。\n第二类神经元为 fast-spiking neuron。这些神经元不显示适应性，因此可以用 LIF 模型来近似。许多抑制性神经元是 fast-spiking neuron。\n除了 regularly firing neuron 和 fast-spiking neuron 外，还有 bursting neuron 和 stuttering neuron。这些神经元对恒定刺激的反应是一连串的脉冲，这些脉冲周期性地爆发或非周期性地被相当长的间隔打断。\n另一个经常观察到的行为是抑制后的反弹。考虑到一个 $I_1\u0026lt;0$ 和 $I_2=0$ 的阶梯电流，即：在一个时间 $t_0$ 从一个抑制性电流 $I_1$ 切换到零电流。在这种情况下，许多神经元会在 $t\u0026gt;t_0$ 时发出一个或多个抑制性反弹脉冲，甚至抑制的释放也能出发动作电位。这种行为在图 4.1(d) 中显示。\n2. 分流抑制和反转电位（shunting inhibition and reversal potential） 在显示中，神经元被嵌入在一个大型网络中，并接受来自许多其它神经元的输入。假设一个来自突触前神经元 $j$ 的脉冲在时间 $t_j^f$ 被发送到突触后神经元 $i$ 的突触。突触后电位是脉冲到达突触后产生的，其形状和振幅不取决于突触后神经元 $i$ 的状态。这当然是一种简化，现实中的情况要复杂一些。\n图 4.2：突触后电位的形状取决于去极化的瞬间水平。(a)当神经元处于静息状态时，在时间 $t^f$ 到达的抑制性突触的突触前脉冲对膜电位几乎没有影响，但如果膜电位 $u$ 高于静息电位，则影响很大。如果膜在抑制性突触的反转电位以下超极化，对突触前输入的反应就会改变符号。(b)兴奋性突触的脉冲引起突触后电位，其振幅仅略微取决于瞬间电压 $u$ 。对于大的去极化，振幅会饱和并且变小。 在图 4.2 中示意性地勾勒了一个实验，其中神经元由恒定电流 $I_0$ 驱动。假设 $I_0$ 太弱，无法引起发射，因此，在一定的静息时间后，膜电位会稳定在一个恒定值 $u_0$ 。在 $t=t^f$ 时，其中一个突触前神经元发出一个脉冲，这样，不久之后动作电位就会到达突触，并且提供突触后神经元的额外刺激。更精确的说，脉冲在突触后神经元产生一个电流脉冲（突触后电流，PSC），其振幅为：\n$$ PSC \\propto [u_0-E_{syn}] \\tag{4.3} $$\n其中，$u_0$ 是膜电位，$E_{syn}$ 是突触的反转电位。由于电流输入的振幅取决于 $u_0$ ，突触后电位的反应也是如此。\n突触后反应对神经元瞬间状态的依赖性在抑制性突触中最为明显。抑制性突触 $E_{syn}$ 的反转电位更低，但通常接近静息电位。因此，如果神经元处于精细状态，输入脉冲对膜电位几乎没有任何影响。然而，如果膜是去极化的，同样的输入脉冲会引起更大的抑制性突触后电位；如果膜已经超极化，输入脉冲甚至可以产生去极化的效果。\n虽然抑制性输入通常对膜电位只有很小的影响，但细胞膜的局部电导率可以大大增加。突触通常位于树突树的体部或轴上。由于它们的策略位置，少数抑制性输入脉冲可以“冲刷”树突树从从数百个兴奋性突触收集的整合输入。这种现象被称为分流抑制（shunting inhibition）。\n兴奋性突触的反转电位通常明显高于静息电位。如果膜去极化， $u_0 \\gg u_rest$ ，兴奋性突触后电位的振幅就会降低，但其效果并不像抑制那样明显。对于非常高的去极化水平，可以观察到 EPSPs 的饱和。\n3. 脉冲后的电导率变化（conductance changes after spikes） 突触后电位的形状不仅取决于去极化的程度，而且更广泛地取决于神经元的内部状态，例如，相对于以前动作电位的时间。假设在时间 $t^f_i$ 产生了动作电位，突触前的脉冲在突触 $j$ 的时间 $t^f_j \u0026gt; t^f_i$ 到达。如果突触前脉冲在突触后动作电位期间或之后不久到达，它的影响不大，因为参与发射动作电位的一些离子通道依然是开放的。如果输入脉冲到达地更晚，它就会产生一个通常大小的突触后电位。\n4. 空间结构（spatial structure） 突触后电位的形式也取决于突触在树突树上的位置。位于远离体细胞的突触引起的突触后电位通常比位于体细胞附近的突触引起的突触后电位小。如果几个输入在几毫秒内出现在同一个树突分支上，第一个输入将引起膜电位的局部变化，影响对稍晚到达的输入脉冲的反应幅度。这可能会导致饱和，或者在所谓的“活性”电流的情况下，导致反应的增强。而在 LIF 模型中，不同突触前脉冲之间这种非线性相互作用被忽略了。\n图 4.3：突触后电位的形状（虚线）取决于自神经元 $i$ 的最后一次输出脉冲以来所经过的时间 $t-t^f_i$。 突触后的尖峰在时间 $t^f_i$ 被触发。突触前的脉冲在突触后神经元的尖峰后不久到达 $t^f_j$ ，其振幅比后来到达的脉冲小得多。 五、LIF 模型的启示 LIF 模型是一个极其简化的神经元模型。它忽略了神经科学家在研究活脑或脑组织切片中的神经元时观察到的许多特征。因此，问题出现了：我们应该从这样一个模型中期待什么？显然，我们不能指望它能解释神经元的完整生物化学和生物物理学。我们也不期望它能解释由树突树上某些 \u0026ldquo;热点 \u0026ldquo;的活性电流引起的高度非线性的相互作用。然而，当涉及到产生脉冲时，即在时间上精确计时的事件时，LIF 模型是十分精确的。因此，它有可能成为神经元中脉冲产生的有效模型，或者更准确地说，能成为细胞体中脉冲产生的有效模型。\n从脉冲生成模型中预测真实神经元脉冲的时间趋势是合理的。实验者使用第一个电极将随时间变化的输入电流 $I(t)$ 注入皮质神经元的细胞体中。通过一个独立的第二电极，实验者测量神经元体部的电压。毫不奇怪，电压轨迹不时地包含尖锐的电脉冲。这些是动作电位或脉冲。\n数学神经科学家现在把实验者使用的输入电流的时间过程 $I(t)$ 与神经元膜电位的时间过程一起，调整一个 LIF 模型的参数，使该模型在输入电流相同的情况下，在时间上产生与真实神经元大致相同的脉冲。这需要一些参数调整，但似乎是可行的。然而，更难解决的相关问题是，神经元模型现在是否可以用来预测真实神经元在新的随时间变化的输入电流下的发射时间，而这种新的输入电流在参数优化过程中并未使用。\n如上所述，神经元不仅在每次放电后表现出不稳定，而且还表现出在数百毫秒内积累起来的适应能力。简单的 LIF 模型并不能很好地预测真实神经元的脉冲时间。然而，如果在神经元模型中加入适应性(和不稳定因素)，预测结果就会出奇地好。增加适应性的一种直接方法是使神经元模型的放电阈值动态：在每个脉冲之后，将阈值 $\\vartheta$ 增加一个增量 $\\theta$ ，使得静息期间，阈值接近其固定值 $θ_0$ 。我们可以使用 Dirac $\\delta$ 函数来表示这种动态阈值：\n$$ \\tau_{adapt} \\frac{d\\vartheta}{dt} = -[\\vartheta(t)-\\vartheta_0] + \\theta \\sum_{f} \\delta(t-t_i^f). \\tag{5.1} $$\n其中，$\\tau_{adapt}$ 为适应时间常数（~几百毫秒），$t^f=t^{(1)}, t^{(2)}, t^{(3)}, \\cdots$ 是神经元的发射时间。\n图 5.1： 广义 LIF 模型与真实实验测量的对比。由波动电流驱动的真实神经元中记录的电压曲线（粗黑线）被叠加在由相同电流驱动的广义 LIF 模型（细线）上。除了少数额外或遗漏的脉冲（箭头），平均脉冲时间也得到了很好的预测。 从图 5.1 中可以看出，具有动态阈值的 LIF 模型的预测结果与真实神经元的电压曲线非常吻合。\n一旦我们确定了好的候选神经元模型，我们将可以尝试用这些模型构建大的神经元网络，并进一步尝试理解神经元网络所使用的动态和计算原理以及潜在的神经编码。虽然这并不意味着理解了整个大脑，但经过良好测试的简化神经元模型中理解大量神经元群体的原理是朝着这个方向迈出的第一步，也是重要的一步。\n总结 神经元信号由短电压脉冲组成，称为动作电位或者脉冲。这些脉冲沿着轴突行进，并被分配到几个突触后神经元，在那里它们又引起突触后电位。如果一个突触后神经元在一个短时间窗口内从多个突触前神经元那收集到足够多的脉冲，它的膜电位可能会达到一个临界值，然后发射出一个脉冲。我们说，神经元已经“发射”了一个脉冲。这个脉冲是神经元的输出信号，反过来又被传输到其它神经元。\n一个比较简单的脉冲神经元模型是 LIF 模型。该模型用一个线性微分方程描述了输入电流如何被整合并转化为膜电位 $u(t)$ 。这里的输入可以是实验者注入孤立神经元的输入电流，也可以是由大型高度连接网络中其它神经元到达的脉冲引起的突触输入电流。其次，如果膜电位到达阈值 $\\vartheta$ ，LIF 神经元会产生一个输出脉冲。最后，在脉冲发射后，线性整合过程被重置，膜电位被重置为一个新的值 $u_r$ 。这个过程被称为膜电位的重置。\nLIF 模型并没有考虑持久的适应性，然而，如果 LIF 模型的电压动态地通过适应机制得到增强，那么它可以成为准确预测皮层神经元脉冲时间的有力工具。\n","date":"2023-11-01T00:55:55Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/2bb88c98-90f9-4308-abcf-493b7e507baa-2023-09-12.webp","permalink":"https://cuterwrite.top/p/introduction-neuron-math/","title":"脉冲神经网络入门：神经元与数学"},{"content":"NEST on HPC 安装教程 1. 安装 MiniConda3 从 Miniconda3 官方网站\r下载 Miniconda3_py39_23.5.2 。\nwget https://repo.anaconda.com/miniconda/Miniconda3-py39_23.5.2-0-Linux-x86_64.sh\r执行 Miniconda3-py39_23.5.2-0-Linux-x86_64.sh ，按照提示安装 Miniconda3。（安装在 $HOME/software/miniconda3/23.5.2 目录下）\n然后，设置 Miniconda3 环境变量。\nexport PATH=$HOME/software/miniconda3/23.5.2/bin:$PATH\r2. 安装 Boost 从 Boost 官方网站\r下载 Boost。\nwget https://boostorg.jfrog.io/artifactory/main/release/1.77.0/source/boost_1_77_0.tar.gz\rtar -zxvf boost_1_77_0.tar.gz\rcd boost_1_77_0\r在 Boost 根目录下执行以下命令安装 Boost：\nmodule load gcc/8.4.0\r./bootstrap.sh --prefix=$HOME/software/boost/1.77.0-gcc-8.4.0 \\\rCC=gcc CXX=g++ FC=gfortran CFLAGS='-O3' CXXFLAGS='-O3' FCFLAGS='-O3'\r配置环境变量：\nexport BOOST_ROOT=$HOME/software/boost/1.77.0-gcc-8.4.0\rexport LD_LIBRARY_PATH=$BOOST_ROOT/lib:$LD_LIBRARY_PATH\rexport LIBRARY_PATH=$BOOST_ROOT/lib:$LIBRARY_PATH\rexport CMAKE_PREFIX_PATH=$BOOST_ROOT/lib/cmake:$CMAKE_PREFIX_PATH\rexport CPATH=$BOOST_ROOT/include:$CPATH\rexport LD_RUN_PATH=$BOOST_ROOT/lib:$LD_RUN_PATH\r3. 安装 GNU Scientific Library 从 GNU Scientific Library 镜像站\r下载 GSL。\nwget https://mirror.ibcp.fr/pub/gnu/gsl/gsl-latest.tar.gz\rtar -zxvf gsl-latest.tar.gz\r在 GSL 根目录执行以下命令安装 GSL：\nmodule load gcc/8.4.0\r./configure --prefix=$HOME/software/gsl/2.7.1-gcc-8.4.0 \\\rCC=gcc CXX=g++ FC=gfortran CFLAGS='-O3' CXXFLAGS='-O3' FCFLAGS='-O3'\rmake install\r配置环境变量：\nexport GSL_ROOT=$HOME/software/gsl/2.7.1-gcc-8.4.0\rexport LD_LIBRARY_PATH=$GSL_ROOT/lib:$LD_LIBRARY_PATH\rexport PATH=$GSL_ROOT/bin:$PATH\rexport CPATH=$GSL_ROOT/include:$CPATH\rexport LIBRARY_PATH=$GSL_ROOT/lib:$LIBRARY_PATH\rexport LD_RUN_PATH=$GSL_ROOT/lib:$LD_RUN_PATH\r4. 安装 NEST 使用 Miniconda3 创建一个虚拟环境。\nsource activate\rconda create -n nest python=3.9\rconda activate nest\r使用 pip 安装 numpy, scipy, cython==0.29.36\npip install numpy scipy cython==0.29.36\r从 NEST github 仓库\r下载 NEST 3.4。\nwget https://github.com/nest/nest-simulator/archive/refs/tags/v3.4.tar.gz\rtar -zxvf v3.4.tar.gz\r在 nest-simulator-3.4 目录下执行:\nmodule load gcc/8.4.0\rmodule load mvaapich2/2.3.7-gcc-8.4.0\rcmake -DCMAKE_C_COMPILER=mpicc \\\r-DCMAKE_CXX_COMPILER=mpicxx \\\r-Dwith-mpi=`which mpiexec` \\\r-DCMAKE_C_FLAGS='-O3 -fPIC' \\\r-DCMAKE_CXX_FLAGS='-O3' \\\r-Dwith-boost=$HOME/software/boost/1.77.0-gcc-8.4.0 \\\r-DGSL_INCLUDE_DIR=$HOME/software/gsl/2.7.1-gcc-8.4.0/include \\\r-DGSL_LIBRARY=$HOME/software/gsl/2.7.1-gcc-8.4.0/lib/libgsl.a \\\r-DGSL_CBLAS_LIBRARY=$HOME/software/gsl/2.7.1-gcc-8.4.0/lib/libgslcblas.a \\\r-DCMAKE_INSTALL_PREFIX:PATH=$HOME/software/nest-simulator/3.4-gcc-8.4.0 .\r配置环境变量：\nexport NEST_ROOT=$HOME/software/nest-simulator/3.4-gcc-8.4.0\rexport LIBRARY_PATH=$NEST_ROOT/lib:$LIBRARY_PATH\rexport LD_LIBRARY_PATH=$NEST_ROOT/lib:$LD_LIBRARY_PATH\r5. 运行 hpc_benchmark 测试 运行 NEST 前需要配置 nest 环境：\nsource $HOME/software/nest-simulator/3.4-gcc-8.4.0/bin/nest_vars.sh\r接着找到 hpc_benchmark.py 目录，该文件位于 $HOME/software/nest-simulator/3.4-gcc-8.4.0/share/doc/nest/examples/hpc_benchmark.py。修改其中的 params 以并行运行更大的模型。\n修改 nvp 为所需 MPI 进程数 × 每进程线程数，如 2 MPI 进程 × 14 线程 = 28 设置合适的 scale ，如 10 。更大的需要更多 nvp 。 params = {\r'nvp': 28, # total number of virtual processes\r'scale': 10., # scaling factor of the network size\r# others...\r}\r在 hpc_benchmark.py 目录下执行：\nexport OMP_NUM_THREADS=14\rmpiexec -N 1 -n 2 -p \u0026lt;partition_name\u0026gt; --export=all python3 hpc_benchmark.py\r其中 -N 指定节点数，-n 指定 MPI 进程数，-p 指定分区名，如 compute，\u0026ndash;export=all 用于将环境变量导出到 MPI 进程中。\n总结 本文介绍了在高性能计算机上安装 NEST-3.4 的方法。\n参考资料 NEST 官方文档\r","date":"2023-10-30T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/20231031002508-2023-10-31.webp","permalink":"https://cuterwrite.top/p/nest-on-hpe-install/","title":"NEST on HPC 安装教程"},{"content":"CUDA 基础：内存访问模式 大多数设备端数据访问都是从全局内存开始的，并且多数 GPU 应用程序容易受内存带宽的限制。因此，最大限度地利用全局内存带宽是调控核函数性能的基本。如果不能正确地调控全局内存的使用，其他优化方案很可能也收效甚微。\n为了在读写数据时达到最佳的性能，内存访问操作必须满足一定的条件。CUDA 执行模型的显著特征之一就是指令必须以线程束为单位进行发布和执行。存储操作也是同样。在执行内存指令时，线程束中的每个线程都提供了一个正在加载或存储的内存地址。在线程束的 32 个线程中，每个线程都提出了一个包含请求地址的单一内存访问请求，它并由一个或多个设备内存传输提供服务。根据线程束中内存地址的分布，内存访问可以被分成不同的模式。\n一、对齐与合并访问 全局内存通过缓存实现加载和存储的过程如下图所示：\n全局内存是一个逻辑内存空间，用户可以通过核函数访问它。所有应用程序数据最初存在于 DRAM 上，即物理设备内存中。核函数的内存请求通常是在 DRAM 设备和片上内存间以 128 字节或 32 字节内存事务来实现。\n所有对全局内存的访问都会通过二级缓存，也有许多访问会通过一级缓存，这取决于访问类型和 GPU 架构。如果这两级缓存都被用到，那么内存访问是由一个 128 字节的内存事务实现的。如果只使用二级缓存，那么这个内存访问是由一个 32 字节的内存事务来实现的。对全局内存缓存其架构，如果允许使用一级缓存，那么可以在编译时选择启用或禁用一级缓存。\n一行一级缓存是 128 字节，它映射到设备内存中一个 128 字节 的对齐段。如果线程束中的每个线程请求一个 4 字节的值，那么每次请求就会获取 128 字节的数据，这恰好与缓存行和设备内存段的大小相契合。\n因此在优化应用程序时，需要注意设备内存访问的两个特性：\n对齐内存访问 合并内存访问 我们把一次内存请求：也就是从核函数发起请求，到硬件响应返回数据这个过程称为一个内存事务（加载和存储都行）。\n当一个内存事务的首个访问地址是缓存粒度（32 或 128 字节）的偶数倍的时候：比如二级缓存 32 字节的偶数倍 64，128 字节的偶数倍 256 的时候，这个时候被称为对齐内存访问，非对齐访问就是除上述的其他情况，非对齐的内存访问会造成带宽浪费。\n当一个线程束内的线程访问的内存都在一个内存块里的时候，就会出现合并访问。\n对齐合并访问的状态是理想化的，也是最高速的访问方式，当线程束内的所有线程访问的数据在一个内存块，并且数据是从内存块的首地址开始被需要的，那么对齐合并访问出现了。为了最大化全局内存访问的理想状态，尽量将线程束访问内存组织成对齐合并的方式，这样的效率是最高的。下面看一个例子。\n一个线程束加载数据，使用一级缓存，并且这个事务所请求的所有数据在一个 128 字节的对齐的地址段上，如下图所示：\n上面蓝色表示全局内存，下面橙色是线程束要的数据，绿色就是对齐的地址段。\n而如果一个事务加载的数据分布在不一个对齐的地址段上，就会有以下两种情况：\n连续的，但是不在一个对齐的段上，比如，请求访问的数据分布在内存地址 1~128 ，那么 0~127 和 128~255 这两段数据要传递两次到 SM 。 不连续的，也不在一个对齐的段上，比如，请求访问的数据分布在内存地址 0~63 和 128~191 上，明显这也需要两次加载。 上图就是典型的一个线程束，数据分散开了，thread 0 的请求在 128 之前，后面还有请求在 256 之后，所以需要三个内存事务，而利用率，也就是从主存取回来的数据被使用到的比例，只有 $\\frac{128}{128 \\times 3}$ 的比例。这个比例低会造成带宽的浪费，最极端的表现，就是如果每个线程的请求都在不同的段，也就是一个 128 字节的事务只有 1 个字节是有用的，那么利用率只有 $\\frac{1}{128}$ 。\n这里总结一下内存事务的优化关键：用最少的事务次数满足最多的内存请求。事务数量和吞吐量的需求随设备的计算能力变化。\n二、全局内存读取 在 SM 中，数据通过以下 3 种缓存 / 缓冲路径进行传输，具体使用何种方式取决于引用了哪种类型的设备内存：\n一级和二级缓存 常量缓存 只读缓存 一 / 二级缓存是默认路径。想要通过其它两种路径传输数据需要应用程序显式说明，但想要提升性能还要取决于使用地访问模式。全局内存加载操作是否会通过一级缓存取决于两个因素：\n设备的计算能力：比较老的设备可能没有一级缓存 编译器选项 在 Fermi GPU 和 Kepler K40 及以后的 GPU （计算能力为 3.5 及以上）中，可以通过编译器标志启用或禁用全局内存负载的一级缓存。默认情况下，在 Fermi 设备上对于全局内存加载可以使用一级缓存，在 K40 及以上 GPU 中禁用。以下标志通知编译器禁用一级缓存：\n-Xptxas -dlcm=cg\r如果一级缓存被禁用，所有对全局内存的加载请求将直接进入到二级缓存；如果二级缓存缺失，则由 DRAM 完成请求。每一次内存事务可由一个、两个或四个部分执行，每个部分有 32 个字节。一级缓存也可以使用下列标识符直接启用:\n-Xptxas -dlcm=ca\r设置这个标志后，全局内存加载请求首先尝试通过一级缓存。如果一级缓存缺失，该请求转向二级缓存。如果二级缓存缺失，则请求由 DRAM 完成。在这种模式下，一个内存加载请求由一个 128 字节的设备内存事务实现。\n在 Kepler K10、K20 和 K20X GPU 中一级缓存不用来缓存全局内存加载。一级缓存专门用于缓存寄存器溢出到本地内存中的数据。\n内存加载可以分为两类：\n缓存加载 没有缓存的加载 内存访问有以下特点：\n是否使用缓存：一级缓存是否介入加载过程 对齐与非对齐的：如果访问的第一个地址是 32 的倍数 合并与非合并，访问连续数据块则是合并的 1. 缓存加载 下面是使用一级缓存的加载过程\n对齐合并的访问，总线利用率 $100\\%$ 对齐的，但是不是连续的，每个线程访问的数据都在一个块内，但是位置是交叉的，总线利用率 $100\\%$ 连续非对齐的，线程束请求一个连续的非对齐的，32 个 4 字节数据，那么会出现，数据横跨两个块，但是没有对齐，当启用一级缓存的时候，就要两个 128 字节的事务来完成，总线利用率为 $50\\%$ 线程束所有线程请求同一个地址，那么肯定落在一个缓存行范围内，那么如果按照请求的是 4 字节数据来说，总线利用率是 $\\frac{4}{128}=3.125\\% $ 比较坏的情况，前面提到过最坏的，就是每个线程束内的线程请求的都是不同的缓存行内，这里比较坏的情况就是，所有数据分布在 $N$ 个缓存行，其中 $1\\leq N \\leq 32$ ，那么请求 32 个 4 字节的数据，就需要 $N$ 个事务来完成，总线利用率也是 $\\frac{1}{N}$ CPU 和 GPU 的一级缓存有显著的差异， GPU 的一级缓存可以通过编译选项等控制，CPU 不可以，而且 CPU 的一级缓存是的替换算法是有使用频率和时间局部性的， GPU 则没有。\n2. 没有缓存的加载 没有缓存的加载是指的没有通过一级缓存，二级缓存则是不得不经过的。\n当不使用一级缓存的时候，内存事务的粒度变为 32 字节，更细粒度的加载可以为非对齐或非合并的内存访问带来更好的总线利用率。\n对齐合并访问 128 字节，不用说，还是最理想的情况，使用 4 个段，总线利用率 $100\\%$ 对齐不连续访问 128 字节，都在四个段内，且互不相同，这样的总线利用率也是 $100\\%$ 连续不对齐，一个段 32 字节，所以，一个连续的 128 字节的请求，即使不对齐，最多也不会超过五个段，总线利用率至少为 $\\frac{4}{5}=80\\%$ 所有线程访问一个 4 字节的数据，那么此时的总线利用率是 $\\frac{4}{32} = 12.5\\%$ ，在这种情况下，非缓存加载性能也是优于缓存加载的性能。 最坏的情况：所有目标数据分散在内存的各个角落，那么需要 $N$ 个内存段，由于请求的 128 个字节最多落在 $N$ 个 32 字节的内存分段内而不是 $N$ 个 128 字节的缓存行内，所以相比于缓存加载，即便是最坏的情况也有所改善。需要注意这里比较的前提是$N$ 不变，然而在实际情况下，当使用大粒度的缓存行时，$N$ 有可能会减少。 3. 只读缓存 只读缓存最初是预留给纹理内存加载用的。对计算能力为 3.5 及以上的 GPU 来说，只读缓存也支持使用全局内存加载代替一级缓存。\n只读缓存的加载粒度是 32 个字节。通常，对分散读取来说，这些更细粒度的加载要优于一级缓存。\n有两种方式可以指导内存通过只读缓存进行读取:\n使用函数 __ldg 在间接引用的指针上使用修饰符 例如：\n__global__ void copyKernel(float *in, float *out)\r{\rint idx = blockDim * blockIdx.x + threadIdx.x;\rout[idx] = __ldg(\u0026amp;in[idx]);\r}\r然后就能强制使用只读缓存了。\n也可以将常量 restrict 修饰符应用到指针上。这些修饰符帮助 nvcc 编译器识别无别名指针(即专门用来访问特定数组的指针)。nvcc 将自动通过只读缓存指导无别名指针的加载。\n__global__ void copyKernel(int * __restrict__ out, const int* __restrict__ in)\r{\rint idx = blockDim * blockIdx.x + threadIdx.x;\rout[idx] = in[idx];\r}\r三、全局内存写入 内存的存储操作相对简单。一级缓存不能用在 Fermi 或 Kepler GPU 上进行存储操作，在发送到设备内存之间存储操作只通过二级缓存。存储操作在 32 个字节段的粒度上被执行。内存事务可以同时被分为一段、两段或四段。例如，如果两个地址同属于一个 128 字节区域，但是不属于一个对齐的 64 字节区域，则会执行一个四段事务（也就是说，执行一个四段事务比执行两个一段事务效果更好）。\n对齐的，访问一个连续的 128 字节范围。存储操作使用一个四段事务完成： 分散在一个 192 字节的范围内，不连续，使用 3 个一段事务完成： 对齐的，在一个 64 字节的范围内，使用一个两段事务完成： 非对齐写入示例与读取情况类似，且更简单，因为始终不经过一级缓存，这里就略过了。 四、结构体数组与数组结构体 数组结构体（AoS）和结构体数组（SoA）是 C 语言中常见的两种数组组织方式。当存储结构化数据集时，它们代表了可以采用的两种强大的数据组织方式（结构体和数组）。\n下面是存储成对的浮点数据数据集的例子。首先，考虑这些成对数据元素集如何使用 AoS 方法进行存储。如下定义一个结构体，命名为 innerStruct ：\nstruct innerStruct\r{\rfloat x;\rfloat y;\r};\r然后，按照下面的方法定义这些结构体数组。这是利用 AoS 方式来组织数据的。它存储的是空间上相邻的数据，这在 CPU 上会有良好的缓存局部性。\nstruct innerStruct myAoS[N];\r接下来，考虑使用 SoA 方法来存储数据：\nstruct innerArray\r{\rfloat x[N];\rfloat y[N];\r};\r这里，在原结构体中每个字段的所有值都被分到各自的数组中。这不仅能将相邻数据点紧密存储起来，也能将跨数组的独立数据点存储起来。可以使用如下结构体定义一个变量：\nstruct innerArray mySoA;\r下图说明了 AoS 和 SoA 方法的内存布局。用 AoS 模式在 GPU 上存储示例数据并执行一个只有 $x$ 字段的应用程序，将导致 $50\\%$ 的带宽损失，因为 $y$ 值在每 32 个字节段或 128 个字节缓存行上隐式地被加载。 AoS 格式也在不需要的 $y$ 值上浪费了二级缓存空间。\n用 SoA 模式存储数据充分利用了 GPU 的内存带宽。由于没有相同字段元素的交叉存取， GPU 上的 SoA 布局提供了合并内存访问，并且可以对全局内存实现更高效的利用。\n当 32 个线程同时访问的时候， SoA 的访问就是连续的，而 AoS 则是不连续的。\n对比 AoS 和 SoA 的内存布局，我们能得到下面结论：\n并行编程范式，尤其是 SIMD（单指令多数据）对 SoA 更友好。 CUDA 中普遍倾向于 SoA 因为这种内存访问可以有效地合并。 五、性能调整 优化设备内存带宽利用率有两个目标：\n对齐及合并内存访问，以减少带宽的浪费 足够的并发内存操作，以隐藏内存延迟 实现并发内存访问量最大化是通过以下方式得到的：\n增加每个线程中执行独立内存操作的数量 对核函数启动的执行配置进行试验，已充分体现每个 SM 的并行性 按照这个思路对程序进行优化，则有两种方法：展开技术和增大并行性。\n1. 展开技术 包含了内存操作的展开循环增加了更独立的内存操作。考虑如下 readOffsetUnroll4 核函数，每个线程都执行 4 个独立的内存操作。因为每个加载过程都是独立的，所以可以调用更多的并发内存访问：\n__global__ void readOffsetUnroll4(float *A, float *B, float *C, const int n, int offset)\r{\runsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\runsigned int k = i + offset;\rif (k + 3 * blockDim.x \u0026lt; n)\r{\rC[i] = A[k];\rC[i + blockDim.x] = A[k + blockDim.x] + B[k + blockDim.x];\rC[i + 2 * blockDim.x] = A[k + 2 * blockDim.x] + B[k + 2 * blockDim.x];\rC[i + 3 * blockDim.x] = A[k + 3 * blockDim.x] + B[k + 3 * blockDim.x];\r}\r}\r启用一级缓存编译选项：\nnvcc -O3 readSegmentUnroll.cu -o readSegmentUnroll -Xptxas -dlcm=ca\r结果表明，展开技术对性能有非常好的影响，甚至比地址对齐还要好。对于 I/O 密集型的核函数，充分说明内存访问并行有很高的优先级。\n2. 增大并行性 可以通过调整块的大小来实现并行性调整：\n线程块最内层维度的大小对性能起着关键的作用 在所有其它情况下，线程块的数量越多，一般性能越高。因此，增大并行性仍然是性能优化的一个重要因素。 参考资料 [1] CUDA C 编程权威指南，机械工业出版社，（美）程润伟（John Cheng） 等著\n","date":"2023-09-04T00:55:55Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/14ce26d6f495200cea2cfa76fefadf88eaab94e5.jpg@1256w_754h_!web-article-pic-2023-09-04.webp","permalink":"https://cuterwrite.top/p/cuda-base-memory-access-mode/","title":"CUDA 基础：内存访问模式"},{"content":"CUDA 基础：内存管理 CUDA 编程的内存管理与 C 语言的类似，需要程序员显式地管理主机和设备之间的数据移动。随着 CUDA 版本的升级，NVIDIA 正系统地实现主机和设备内存空间的统一，但对于大多数应用程序来说，仍需要手动移动数据。本文重点在于如何使用 CUDA 函数来显式地管理内存和数据移动。\n分配和释放设备内存 在主机和设备之间传输数据 为了达到最优性能，CUDA 提供了在主机端准备设备内存的函备内存的函数，并且显式地向设备传输数据和从设备中获取数据。\n一、内存分配和释放 CUDA 编程模型假设了一个包含一个主机和一个设备的异构系统，每一个异构系统都有自己独立的内存空间。核函数在设备内存空间中运行，CUDA 运行时提供函数以分配和释放设备内存。用户可以在主机上使下列函数分配全局内存：\ncudaError_t cudaMalloc(void **devPtr, size_t size);\r这个函数在设备上分配了 count 字节的全局内存，并用 devptr 指针返回该内存的地址。所分配的内存支持任何变量类型，包括整型、浮点类型变量、布尔类型等。如果 cudaMalloc 函数执行失败则返回 cudaErrorMemoryAllocation 。在已分配的全局内存中的值不会被清除。用户需要用从主机上传输的数据来填充所分配的全局内存，或用下列函数将其初始化：\ncudaError_t cudaMemset(void *devPtr, int value, size_t count);\r这个函数用存储在变量 value 中的值来填充从设备内存地址 devPtr 处开始的 count 字节。\n一旦一个应用程序不再使用已分配的全局内存，那么可以以下代码释放该内存空间：\ncudaError_t cudaFree(void *devPtr);\r这个函数释放了 devPtr 指向的全局内存，该内存必须在此前使用了一个设备分配函数（如 cudaMalloc）来进行分配。否则，它将返回一个错误 cudaErrorInvalidDevicePointer 。如果地址空间已经被释放，那么 cudaFree 也返回一个错误。\n设备内存的分配和释放操作成本较高，所以应用程序应重利用设备内存，以减少对整体性能的影响。\n二、内存传输 一旦分配好了全局内存，就可以使用下列函数从主机向设备传输数据：\ncudaError_t cudaMemcpy(void *dst, const void *src, size_t count, cudaMemcpyKind kind);\r这个函数从内存位置 src 复制了 count 字节到内存位置 dst 。变量 kind 指定了复制的方向，可以有下列取值：\ncudaMemcpyHostToHost：从主机内存复制到主机内存 cudaMemcpyHostToDevice：从主机内存复制到设备内存 cudaMemcpyDeviceToHost：从设备内存复制到主机内存 cudaMemcpyDeviceToDevice：从设备内存复制到设备内存 如果指针 dst 和 src 与 kind 指定的复制方向不一致，那么 cudaMemcpy 的行为就是未定义行为。这个函数在大多数情况下都是同步的。\n下图为 CPU 内存和 GPU 内存间的连接性能。从图中可以看到 GPU 芯片和板载 GDDR5 GPU 内存之间的理论峰值带宽非常高，对于 Fermi C2050 GPU 来说为 144GB/s 。CPU 和 GPU 之间通过 PCIe Gen2 总线相连，这种连接的理论带宽要低得多，为 8GB/s（ PCIe Gen3 总线最大理论限制值是 16GB/s）。这种差距意味着如果管理不当的话，主机和设备间的数据传输会降低应用程序的整体性能。因此，CUDA 编程的一个基本原则应是尽可能地减少主机与设备之间的传输。\n三、固定内存 分配的主机内存默认是 pageable（可分页），它的意思也就是因页面错误导致的操作，该操作按照操作系统的要求将主机虚拟内存上的数据移动到不同的物理位置。虚拟内存给人一种比实际可用内存大得多的假象，就如同一级缓存好像比实际可用的片上内存大得多一样。\nGPU 不能在可分页主机内存上安全地访问数据，因为当主机操作系统在物理位置上移动该数据时，它无法控制。当从可分页主机内存传输数据到设备内存时，CUDA 驱动程序首先分配临时页面锁定的或固定的主机内存，将主机源数据复制到固定内存中，然后从固定内存传输数据给设备内存，如下图左边部分所示：\n左边是正常分配内存，传输过程是：锁页-复制到固定内存-复制到设备\n右边是分配时就是固定内存，直接传输到设备上。\n下面函数用来分配固定内存：\ncudaError_t cudaMallocHost(void ** devPtr,size_t count);\r这个函数分配了 count 字节的主机内存，这些内存是页面锁定的并且对设备来说是可访问的。由于固定内存能被设备直接访问，所以它能用比可分页内存高得多的带宽进行读写。然而，分配过多的固定内存可能会降低主机系统的性能，因为它减少了用于存储虚拟内存数据的可分页内存的数量，其中分页内存对主机系统是可用的。\n固定的主机内存释放使用：\ncudaError_t cudaFreeHost(void * devPtr);\r总的来说，固定内存的释放和分配成本比可分页内存要高很多，但是传输速度更快，所以对于大规模数据，固定内存效率更高。应该尽量使用流来使内存传输和计算之间同时进行。\n四、零拷贝内存 通常来说，主机不能直接访问设备变量，同时设备也不能直接访问主机变量。但有一个例外：零拷贝内存。主机和设备都可以访问零拷贝内存。\nGPU 线程可以直接访问零拷贝内存。在 CUDA 核函数中使用零拷贝内存有以下几个优势。\n当设备内存不足时可利用主机内存 避免主机和设备间的显式数据传输 提高 PCIe 传输率 当使用零拷贝内存来共享主机和设备间的数据时，用户必须同步主机和设备间的内存访问，同时更改主机和设备的零拷贝内存中的数据将导致不可预知的后果。\n零拷贝内存是固定内存，不可分页，该内存映射到设备地址空间中。用户可以通过下列函数创建零拷贝内存：\ncudaError_t cudaHostAlloc(void ** pHost,size_t count,unsigned int flags)\r最后一个标志参数，可以选择以下值：\ncudaHostAllocDefalt：和 cudaMallocHost 函数一致 cudaHostAllocPortable：返回能被所有 CUDA 上下文使用的固定内存 cudaHostAllocMapped：产生零拷贝内存，可以实现主机写入和设备读取被映射到设备地址空间中的主机内存 cudaHostAllocWriteCombined：返回写结合内存，在某些设备上这种内存传输效率更高 注意，零拷贝内存虽然不需要显式的传递到设备上，但是设备还不能通过 pHost 直接访问对应的内存地址，设备需要访问主机上的零拷贝内存，需要先获得另一个地址，这个地址帮助设备访问到主机对应的内存，方法是：\ncudaError_t cudaHostGetDevicePointer(void ** pDevice,void * pHost,unsigned int flags)\rpDevice 就是设备上访问主机零拷贝内存的指针了，此处 flags 必须设置为 0 。\n在进行频繁的读写操作时，使用零拷贝内存作为设备内存的补充将显著降低性能。因为每一次映射到内存的传输必须经过 PCIe 总线。与全局内存相比，延迟也显著增加。\n注意不要过度使用零拷贝内存。由于其延迟较高，从零拷贝内存中读取设备核函数可能很慢。\n五、统一虚拟寻址 计算能力为 2.0 及以上版本的设备支持一种特殊的寻址方式，称为统一虚拟寻址（UVA）。UVA，在 CUDA 4.0 中被引入，支持 64 位 Linux 系统。有了 UVA，主机内存和设备内存可以共享同一个虚拟地址空间，如下图所示：\nUVA 之前，我们要管理所有的设备和主机内存，尤其是它们的指针，零拷贝内存尤其麻烦。有了 UVA，由指针指向的内存空间对应用程序代码来说是透明的。\n通过 UVA，由 cudaHostAlloc 分配的固定主机内存具有相同的主机和设备指针。因此，可以将返回的指针直接传递给核函数。\n前面的零拷贝内存，可以知道以下几个方面：\n分配映射的固定主机内存 使用 CUDA 运行时函数获取映射到固定内存的设备指针 将设备指针传递给核函数 有了 UVA ，可以不用上面的那个获得设备上访问零拷贝内存的函数了：\ncudaError_t cudaHostGetDevicePointer(void ** pDevice, void * pHost, unsigned flags);\r因为 UVA 之后，主机和设备的指针都是一样的，所以可以直接传递给核函数了。\n六、统一内存寻址 在 CUDA 6.0 中，引入了统一内存寻址这一新特性，它用于简化 CUDA 编程模型中的内存管理。统一内存中创建了一个托管内存池，内存池中已分配的空间可以用相同的内存地址（即指针）在 CPU 和 GPU 上进行访问。底层系统在统一内存空间中自动在主机和设备之间进行数据传输。这种数据传输对应用程序是透明的，这大大简化了程序代码。\n统一内存寻址依赖于 UVA 的支持，但它们是完全不同的技术。 UVA 为系统中的所有处理器提供了一个单一的虚拟内存地址空间。但是， UVA 不会自动将数据从一个物理位置转移到另一个位置，这是统一内存寻址的一个特有功能。\n统一内存寻址提供了一个单指针到数据模型，在概念上它类似于零拷贝内存。但是零拷贝内存在主机内存中进行分配，因此，由于受到在 PCIe 总线上访问零拷贝内存的影响，核函数的性能将具有较高的延迟。另一方面，统一内存寻址将内存和执行空间分离，因此可以根据需要将数据透明地传输到主机或设备上，以提升局部性和性能。\n托管内存指的是由底层系统自动分配的统一内存，未托管内存就是用户自己分配的内存，这时候对于核函数，可以传递给它两种类型的内存，已托管和未托管内存，可以同时传递。\n托管内存可以是静态的，也可以是动态的，添加 managed 关键字修饰托管内存变量。静态声明的托管内存作用域是文件，这一点可以注意一下。\n托管内存分配方式：\ncudaError_t cudaMallocManaged(void ** devPtr, size_t size, unsigned int flags);\r这个函数分配 size 字节的托管内存，并用 devPtr 返回一个指针。该指针在所有设备和主机上都是有效的。使用托管内存的程序行为与使用未托管内存的程序副本行为在功能上是一致的。但是，使用托管内存的程序可以利用自动数据传输和重复指针消除功能。\n在 CUDA 6.0 中，设备代码不能调用 cudaMallocManaged 函数。所有的托管内存必须在主机端动态声明或者在全局范围内静态声明。\n参考资料 [1] CUDA C 编程权威指南，机械工业出版社，（美）程润伟（John Cheng） 等著\n","date":"2023-09-02T05:55:55Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/fb80f7f3a9a0e016420a324823ef950b9847fb8d.jpg@1256w_2128h_!web-article-pic-2023-09-02.webp","permalink":"https://cuterwrite.top/p/cuda-base-memory-manage/","title":"CUDA 基础：内存管理"},{"content":"CUDA 基础：内存模型概述 内存的访问和管理是所有编程语言的重要部分。在现代加速器中，内存管理对高性能计算有着很大的影响。\n因为多数工作负载被加载和存储数据的速度所限制，所以有大量低延迟、高带宽的内存对性能是十分有利的。然而，大容量、高性能的内存造价高且不容易生产。因此，在现有的硬件存储子系统下，必须依靠内存模型获得最佳的延迟和带宽。CUDA 内存模型结合了主机和设备的内存系统，展现了完整的内存层次结构，能显式地控制数据布局以优化性能。\n一、内存层次结构的优点 程序具有局部性特点，包括：\n时间局部性：如果一个数据被访问，那么它在不久的将来也会被访问。 空间局部性：如果一个数据被访问，那么它附近的数据也会被访问。 现代计算机的内存结构主要如下：\n一个内存层次结构由具有不同延迟、带宽和容量的多级内存组成。通常，随着从处理器到内存延迟的增加，内存的容量也在增加。\nCPU 和 GPU 的主存都采用的是 DRAM（动态随机存取存储器），而低延迟内存（如 CPU 一级缓存）使用的则是 SRAM（静态随机存取存储器）。内存层次结构中最大且最慢的级别通常使用磁盘或闪存驱动来实现。在这种内存层次结构中，当数据被处理器频繁使用时，该数据保存在低延迟、低容量的存储器中；而当该数据被存储起来以备后用时，数据就存储在高延迟、大容量的存储器中。这种内存层次结构符合大内存低延迟的设想。\nGPU 和 CPU 的内存设计有相似的准则和模型。但它们的主要区别是，CUDA 编程模型能将内存层次结构更好地呈现给用户，能让我们显式地控制它的行为。\n二、CUDA 内存模型 对于程序员来说，一般有两种类型的存储器：\n可编程的：你需要显式地控制哪些数据存放在可编程内存中 不可编程的：你不能决定数据的存放位置，程序将自动生成存放位置以获得良好的性能 CPU 内存结构中，一级二级缓存都是不可编程（完全不可控制）的存储设备。另一方面，CUDA 内存模型相对于 CPU 来说更为丰富，提出了多种可编程内存的类型：\n寄存器 共享内存 本地内存 常量内存 纹理内存 全局内存 下图所示为这些内存空间的层次结构，每种都有不同的作用域、生命周期和缓存行为。一个核函数中的线程都有自己私有的本地内存。一个线程块有自己的共享内存，对同一线程块中所有线程都可见，其内容持续线程块的整个生命周期。所有线程都可以访问全局内存。所有线程都能访问的只读内存空间有：常量内存空间和纹理内存空间。全局内存、常量内存和纹理内存空间有不同的用途。纹理内存为各种数据布局提供了不同的寻址模式和滤波模式。对于一个应用程序来说， 全局内存、常量内存和纹理内存中的内容具有相同的生命周期。\n1. 寄存器 寄存器无论是在 CPU 还是在 GPU 都是速度最快的内存空间，但是和 CPU 不同的是 GPU 的寄存器储量要多一些，而且当我们在核函数内不加修饰的声明一个变量，此变量就存储在寄存器中，但是 CPU 运行的程序有些不同，只有当前在计算的变量存储在寄存器中，其余在主存中，使用时传输至寄存器。在核函数声明的数组中，如果用于引用该数组的索引是常量且能在编译时确定，那么该数组也存储在寄存器中。\n寄存器变量对于每个线程来说都是私有的，一个核函数通常使用寄存器来保存需要频繁访问的线程私有变量。寄存器变量与核函数的生命周期相同。一旦核函数执行完毕，就不能对寄存器变量进行访问了。\n寄存器是 SM 中的稀缺资源，Fermi 架构中每个线程最多 63 个寄存器。Kepler 结构扩展到 255 个 寄存器，一个线程如果使用更少的寄存器，那么就会有更多的常驻线程块，SM 上并发的线程块越多，效率越高，性能和使用率也就越高。\n那么问题就来了，如果一个线程里面的变量太多，以至于寄存器完全不够呢？这时候寄存器发生溢出，本地内存就会过来帮忙存储多出来的变量，这种情况会对效率产生非常负面的影响，所以，不到万不得已，一定要避免此种情况发生。\n为了避免寄存器溢出，可以在核函数的代码中配置额外的信息来辅助编译器优化，比如：\n__global__ void\r__lauch_bounds__(maxThreadaPerBlock, minBlocksPerMultiprocessor)\rkernel(...) {\r/* kernel code */\r}\r这里面在核函数定义前加了一个 关键字 lauch_bounds ，然后它后面对应了两个变量：\nmaxThreadaPerBlock：线程块内包含的最大线程数，线程块由核函数来启动 minBlocksPerMultiprocessor：可选参数，每个 SM 中预期的最小的常驻内存块参数。注意，对于一定的核函数，优化的启动边界会因为不同的结构而不同 也可以在编译选项中加入 -maxrregcount=32 来指定每个线程使用的最大寄存器数。 2. 本地内存 核函数中符合存储在寄存器中但不能进入被该核函数分配的寄存器空间中的变量将溢出到本地内存中。编译器可能存放到本地内存中的变量有：\n在编译时使用未知索引引用的本地数组 可能会占用大量寄存器空间的较大本地结构体或数组 任何不满足核函数寄存器限定条件的变量 本地内存实质上是和全局内存一样在同一块存储区域当中的，其访问特点——高延迟，低带宽。对于计算能力 2.0 以上的设备，本地内存存储在每个 SM 的一级缓存，或者设备的二级缓存上。\n3. 共享内存 在核函数中使用 __shared__ 修饰符修饰的变量存放在共享内存中。\n因为共享内存是片上内存，所以与本地内存或全局内存相比，它具有更高的带宽和更低的延迟。它的使用类似于 CPU 一级缓存，但它是可编程的。\n每一个 SM 都有一定数量的由线程块分配的共享内存。因此，必须非常小心不要过度使用共享内存，否则将在不经意间限制活跃线程束的数量。\n共享内存在核函数的范围内声明，其生命周期伴随着整个线程块。当一个线程块执行结束后，其分配的共享内存将被释放并重新分配给其他线程块。\n共享内存是线程之间相互通信的基本方式。因为共享内存是块内线程可见的，所以就有竞争问题的存在，也可以通过共享内存进行通信，当然，为了避免内存竞争，可以使用同步语句：\n__syncthreads();\r此语句相当于在线程块执行时各个线程的一个障碍点，当块内所有线程都执行到本障碍点的时候才能进行下一步的计算，这样可以设计出避免内存竞争的共享内存使用程序。但是，该语句频繁使用会影响内核执行效率。SM 中的一级缓存和共享内存都使用 64KB 的片上内存，它通过静态划分，但在运行时可以通过如下指令进行动态配置：\ncudaError_t cudaFuncSetCacheConfig ( const void* func, cudaFuncCache cacheConfig )\r这个函数在每个核函数的基础上配置了片上内存划分，为 func 指定的核函数设置了配置。支持的缓存配置如下：\ncudaFuncCachePreferNone // 无参考值，默认设置\rcudaFuncCachePreferShared // 48k 共享内存，16k 一级缓存\rcudaFuncCachePreferL1 // 48k 一级缓存，16k 共享内存\rcudaFuncCachePreferEqual // 32k 一级缓存，32k 共享内存\rFermi 架构支持前三种，后面的设备都支持。\n4. 常量内存 常量内存驻留在设备内存中，每个 SM 都有专用的常量内存缓存，常量内存使用 __constant__ 修饰符修饰。\n常量变量必须在全局空间内和所有核函数之外进行声明。对于所有计算能力的设备，都只可以声明 64kB 的常量内存，常量内存是静态声明的，并对同一编译单元中的所有核函数可见。\n核函数只能从常量内存中读取数据（只读）。因此，常量内存必须在主机端使用下面的函数来初始化：\ncudaError_t cudaMemcpyToSymbol ( const void* symbol, const void* src, size_t count, size_t offset = 0, cudaMemcpyKind kind = cudaMemcpyHostToDevice )\r这个函数将 count 个字节从 src 指向的内存复制到 symbol 指向的内存中，这个变量存放在设备的全局内存或常量内存中。在大多数情况下这个函数是同步的。\n线程束中的所有线程从相同的内存地址中读取数据时，常量内存表现最好。举个例子，数学公式中的系数就是一个很好的使用常量内存的例子，因为一个线程束中所有的线程使用相同的系数来对不同数据进行相同的计算。如果线程束里每个线程都从不同的地址空间读取数据，并且只读一次，那么常量内存中就不是最佳选择，因为每从一个常量内存中读取一次数据，都会广播给线程束里的所有线程。\n5. 纹理内存 纹理内存驻留在设备内存中，并在每个 SM 的只读缓存中缓存。纹理内存是一种通过指定的只读缓存访问的全局内存。只读缓存包括硬件滤波的支持，它可以将浮点插入作为读过程的一部分来执行。纹理内存是对二维空间局部性的优化所以线程束里使用纹理内存访问二维数据的线程可以达到最优性能。对于一些应用程序来说，这是理想的内存，并由于缓存和滤波硬件的支持所以有较好的性能优势。然而对于另一些应用程序来说，与全局内存相比，使用纹理内存更慢。\n总的来说纹理内存设计目的应该是为了 GPU 本职工作显示设计的，但是对于某些特定的程序可能效果更好，比如需要滤波的程序，可以直接通过硬件完成。\n6. 全局内存 全局内存是 GPU 中最大、延迟最高并且最常使用的内存。 global 指的是其作用域和生命周期。它的声明可以在任何 SM 设备上被访问到，并且贯穿应用程序的整个生命周期。一个全局内存变量可以被静态声明或动态声明。可以使用 __device__ 修饰符在设备代码中静态地声明一个变量。\n默认通过 cudaMalloc 声明的所有在 GPU 上访问的内存都是全局内存，也就是没有对内存进行任何优化。因为全局内存的性质，当有多个核函数同时执行的时候，如果使用到了同一全局变量，应注意内存竞争。\n全局内存访问是对齐，也就是一次要读取指定大小 $(32，64，128)$ 整数倍字节的内存，所以当线程束执行内存加载/存储时，需要满足的传输数量通常取决与以下两个因素：\n跨线程的内存地址分布 内存事务的对齐方式 在一般情况下，用来满足内存请求的事务越多，未使用的字节被传输回的可能性就越高，这就造成了数据吞吐率的降低。\n对于一个给定的线程束内存请求，事务数量和数据吞吐率是由设备的计算能力来确定的。对于计算能力为 1.0 和 1.1 的设备，全局内存访问的要求是非常严格的。对于计算能力高于 1.1 的设备，由于内存事务被缓存，所以要求较为宽松。缓存的内存事务利用数据局部性来提高数据吞吐率。\n7. GPU 缓存 与 CPU 缓存类似， GPU 缓存是不可编程的内存。在 GPU 上有 4 种缓存：\n一级缓存 二级缓存 只读常量缓存 只读纹理缓存 每个 SM 都有一个一级缓存，所有的 SM 共享一个二级缓存。一级和二级缓存都被用来在存储本地内存和全局内存中的数据，也包括寄存器溢出的部分。对 Fermi GPU 和 Kepler K40 或其后发布的 GPU 来说，CUDA 允许我们配置读操作的数据是使用一级和二级缓存，还是只使用二级缓存。\n在 CPU 上，内存的加载和存储都可以被缓存。但是，在 GPU 上只有内存加载操作可以被缓存，内存存储操作不能被缓存。\n每个 SM 也有一个只读常量缓存和只读纹理缓存，它们用于在设备内存中提高来自于各自内存空间内的读取性能。\n8. CUDA 变量声明总结 用表格进行总结：\n修饰符 变量名 存储器 作用域 生命周期 无 float var 寄存器 线程 线程 无 float var[100] 本地 线程 线程 __shared__ float var* 共享内存 块 块 __device__ float var* 全局内存 全局 应用程序 __constant__ float var* 常量内存 全局 应用程序 设备存储器的重要特征：\n存储器 片上/片外 缓存 存取 范围 生命周期 寄存器 片上 n/a R/W 一个线程 线程 本地 片外 1.0 以上有 R/W 一个线程 线程 共享 片上 n/a R/W 块内所有线程 块 全局 片外 1.0 以上有 R/W 所有线程+主机 主机配置 常量 片外 有 R 所有线程+主机 主机配置 纹理 片外 有 R 所有线程+主机 主机配置 9. 静态全局内存 CPU 内存有动态分配和静态分配两种类型，从内存位置来说，动态分配在堆上进行，静态分配在站上进行，在代码上的表现是一个需要 new，malloc 等类似的函数动态分配空间，并用 delete 和 free 来释放。在 CUDA 中也有类似的动态静态之分，需要 cudaMalloc 的就是动态分配，静态分配与动态分配相同是，也需要显式的将内存 copy 到设备端。下面代码是一个静态分配的例子：\n#include \u0026lt;cuda_runtime.h\u0026gt;\r#include \u0026quot;dbg.h\u0026quot;\r__device__ float devData;\r__global__ void checkGlobalVariable()\r{\rprintf(\u0026quot;Device: the value of devData is %f\\n\u0026quot;, devData);\rdevData += 2.0f;\r}\rint main(int argc, char **argv)\r{\rfloat value = 3.14f;\rCHECK(cudaMemcpyToSymbol(devData, \u0026amp;value, sizeof(float)));\rprintf(\u0026quot;Host: copied %f to the global variable\\n\u0026quot;, value);\rcheckGlobalVariable\u0026lt;\u0026lt;\u0026lt;1, 1\u0026gt;\u0026gt;\u0026gt;();\rCHECK(cudaMemcpyFromSymbol(\u0026amp;value, devData, sizeof(float)));\rprintf(\u0026quot;Host: the value changed by the kernel to %f\\n\u0026quot;, value);\rCHECK(cudaDeviceReset());\rreturn EXIT_SUCCESS;\r}\r运行结果为：\nHost: copied 3.140000 to the global variable\rDevice: the value of devData is 3.140000\rHost: the value changed by the kernel to 5.140000\r唯一要注意的就是这一句：\ncudaMemcpyToSymbol(devData,\u0026amp;value,sizeof(float));\r设备上的变量定义和主机变量定义的不同，设备变量在代码中定义的时候其实就是一个指针，这个指针指向何处，主机端是不知道的，指向的内容也不知道，想知道指向的内容，唯一的办法还是通过显式的办法即 cudaMemcpyToSymbol 传输过来。\n此外还需要注意的是：\n在主机端，devData 只是一个标识符，不是设备全局内存的变量地址 在核函数中，devData 就是一个全局内存中的变量。主机代码不能直接访问设备变量，设备也不能访问主机变量，这就是 CUDA 编程与 CPU 多核最大的不同之处 一方面，是无法使用 cudaMemcpy 来给静态变量赋值的，除非：\nfloat *dptr = NULL;\rcudaGetSymbolAddress((void**)\u0026amp;dptr,devData);\rcudaMemcpy(dptr, \u0026amp;value, sizeof(float), cudaMemcpyHostToDevice);\r另一方面，主机端不可以对设备变量进行取地址操作，该操作是非法的。想要得到 devData 的地址可以用下面方法：\nfloat *dptr = NULL;\rcudaGetSymbolAddress((void**)\u0026amp;dptr, devData);\r当然也有一个例外，可以直接从主机引用 GPU 内存——CUDA 固定内存。\nCUDA 运行时 API 能访问主机和设备变量，但这取决于你给正确的函数是否提供了正确的参数，使用运行时 API ，如果参数填错，尤其是主机和设备上的指针，结果是无法预测的。\n参考资料 [1] CUDA C 编程权威指南，机械工业出版社，（美）程润伟（John Cheng） 等著\n","date":"2023-09-01T04:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/47a9b8a012cf3a3f552c9aba3aeaa93fe669cf70.jpg@1256w_970h_!web-article-pic-2023-09-01.webp","permalink":"https://cuterwrite.top/p/cuda-base-memory-model/","title":"CUDA 基础：内存模型概述"},{"content":"CUDA 基础：线程束执行的本质 1. 线程束和线程块 线程束是 SM 中基本的执行单元，当一个线程块的网格被启动后，网格中的线程块分布在 SM 中。一旦线程块被调度在一个 SM 上，线程块中的线程会被进一步划分为线程束。一个线程束由 32 个连续的线程组成（目前的 GPU 都是 32 个线程，但不保证未来是 32 个），在一个线程束中，所有的线程按照单指令多线程（SIMT）方式执行；也就是说，所有线程都执行相同的指令，每个线程在私有数据上进行操作。下图展示了线程块的逻辑视图和硬件视图之间的关系：\n然而，从硬件的角度来看，所有的线程都被组织成了一维的，线程块可以被配置为一维、二维、三维的。在一个块中，每个线程都有唯一的 ID 。对于一维的线程块，唯一的线程 ID 被存储在 CUDA 的内置变量 threadIdx.x 中，并且，threadIdx.x 中拥有连续值得线程被分组到线程束中。例如，一个有 128 个线程的一维线程块被组织到 4 个线程束里，如下所示：\nwarp0: thread 0, .........., thread 31\rwarp1: thread 32, ........., thread 63\rwarp2: thread 64, ........., thread 95\rwarp3: thread 96, ........., thread 127\r线程块是一个逻辑产物，因为在计算机里，内存总是一维线性存在的，所以执行起来也是一维的访问线程块中的线程，但是我们在写程序的时候却可以以二维三维的方式进行，原因是方便我们写程序，比如处理图像或者三维的数据，三维块就会变得很直接，很方便。\n在块中，每个线程有唯一的编号（可能是个三维的编号），threadIdx 网格中，每个线程块也有唯一的编号(可能是个三维的编号)，blockIdx 那么每个线程就有在网格中的唯一编号。 用 $x$ 维度作为最内层的维度， $y$ 维度作为第二个维度， $z$ 维度作为最外层的维度，则二维或三维线程块的逻辑布局可以转化为一维物理布局。例如，对于一个给定的二维线程块，在一个块中每个线程的独特标识符都可以用内置变量 threadIdx 和 blockDim 来计算：\ntid = threadIdx.x + threadIdx.y * blockDim.x;\r对于一个三维线程块，可以用下面的方式计算：\ntid = threadIdx.x + threadIdx.y * blockDim.x + threadIdx.z * blockDim.x * blockDim.y;\r在 C 语言中，假设三维数组 t 保存了所有的线程，那么 (threadIdx.x, threadIdx.y, threadIdx.z) 就相当于：\nt[z][y][x];\r一个线程块的线程束的数量可以根据下式确定：\n$$ \\mathrm{WarpsPerBlock} = \\left \\lceil \\frac{\\mathrm{threadsPerBlock}}{\\mathrm{warpSize}} \\right \\rceil $$\n因此，硬件总是给一个线程块分配一定数量的线程束。线程束不会在不同的线程块之间分离。如果线程块的大小不是线程束大小的偶数倍，那么在最后的线程束里有些线程就不会活跃。比如说一个在 $x$ 轴中有 40 个线程、在 $y$ 轴中有 2 个线程的二维线程块。从应用程序的角度来看，在一个二维网格中共有 80 个线程。\n硬件为这个线程块配置了 3 个线程束，使总共 96 个硬件线程去支持 80 个软件线程。注意，最后半个线程束是不活跃的。即使这些线程未被使用，它们仍然消耗 SM 的资源，如寄存器。\n从逻辑角度来看： 线程块是线程的集合，它们可以组织为一维、二维或三维布局。\n从硬件角度来看： 线程块是一维线程束的集合。在线程块中线程被组织成一维布局，每 32 个连续线程组成一个线程束。\n2. 线程束分化 控制流是高级编程语言的基本构造中的一种。GPU 支持传统的、C 风格的、显式的控制流结构，例如，if···then···else、for 和 while。\nCPU 拥有复杂的硬件以执行分支预测，也就是在每个条件检查中预测应用程序的控制流会使用哪个分支。如果预测正确，CPU 中的分支只需付出很小的性能代价。如果预测不正确，CPU 可能会停止运行很多个周期，因为指令流水线被清空了。我们不必完全理解为什么 CPU 擅长处理复杂的控制流。这个解释只是作为对比的背景。当我们的程序包含大量的分支判断时，从程序角度来说，程序的逻辑是很复杂的，因为一个分支就会有两条路可以走，如果有 10 个分支，那么一共有 1024 条路走，CPU 采用流水线化作业，如果每次等到分支执行完再执行下面的指令会造成很大的延迟，所以现在处理器都采用分支预测技术，而 CPU 的这项技术相对于 GPU 来说高级了不止一点点，而这也是 GPU 与 CPU 的不同，设计初衷就是为了解决不同的问题。CPU 适合逻辑复杂计算量不大的程序，比如操作系统，控制系统，GPU 适合大量计算简单逻辑的任务，所以被用来算数。\nGPU 是相对简单的设备，它没有复杂的分支预测机制。一个线程束中的所有线程在同周期中必须执行相同的指令，如果一个线程执行一条指令，那么线程束中的所有线程都必须执行该指令。如果在同一线程束中的线程使用不同的路径通过同一个应用程序，这可能会产生问题。例如，思考下面的语句:\nif (cond) {\r...\r} else {\r...\r}\r假设在一个线程束中有 16 个线程执行这段代码，cond 为 true，但对于其他 16 个来说 cond 为 false 。一半的线程束需要执行 if 语句块中的指令，而另一半需要执行 else 语句块中的指令。在同一线程束中的线程执行不同的指令，被称为线程束分化。我们已经知道，在一个线程束中所有线程在每个周期中必须执行相同的指令，所以线程束分化似乎会产生一个悖论。\n如果一个线程束中的线程产生分化，线程束将连续执行每一个分支路径，而禁用不执行这一路径的线程。线程束分化会导致性能明显地下降。在前面的例子中可以看到，线程中并行线程的数量减少了一半: 只有 16 个线程同时活跃地执行，而其他 16 个被禁用了。条件分支越多，并行性削弱越严重。此外，线程束分化只发生在同一个线程束中。在不同的线程束中，不同的条件值不会引起线程束分化。\n执行过程如下：\n因为线程束分化导致的性能下降就应该用线程束的方法解决，根本思路是避免同一个线程束内的线程分化，而让我们能控制线程束内线程行为的原因是线程块中线程分配到线程束是有规律的而不是随机的。这就使得我们根据线程编号来设计分支是可以的，补充说明下，当一个线程束中所有的线程都执行 if 或者，都执行 else 时，不存在性能下降；只有当线程束内有分歧产生分支的时候，性能才会急剧下降。\n线程束内的线程是可以被我们控制的，那么我们就把都执行 if 的线程塞到一个线程束中，或者让一个线程束中的线程都执行 if ，另外线程都执行 else 的这种方式可以将效率提高很多。\n举以下一个低效的核函数为例：\n__global__ void mathKernel1(float *c) {\rint tid = blockIdx.x * blockDim.x + threadIdx.x;\rfloat a, b;\ra = b = 0.0f;\rif (tid % 2 == 0) {\ra = 100.0f;\r} else {\rb = 200.0f;\r}\rc[tid] = a + b;\r}\r这种情况下，线程束内的线程会产生分化，因为线程束内的线程会有一半执行 if ，另一半执行 else ，这样就会导致性能下降。我们可以通过下面的方式来优化：\n__global__ void mathKernel2(float *c) {\rint tid = blockIdx.x * blockDim.x + threadIdx.x;\rfloat a, b;\ra = b = 0.0f;\rif ((tid / warpSize) % 2 == 0) {\ra = 100.0f;\r} else {\rb = 200.0f;\r}\rc[tid] = a + b;\r}\r假设只配置一个大小为 64 的一维线程块，那么只有 2 个线程束，第一个线程束内的线程编号 tid 从 0 到 31， tid / warpSize 都等于 0，那么都执行 if 语句；第二个线程束内的线程编号 tid 从 32 到 63， tid / warpSize 都等于 1，那么都执行 else 语句。这样就避免了线程束内的线程分化，效率较高。\n在 CUDA 中，对线程束分化的评价指标为分支效率 (branch efficiency)，它是一个 0 到 100 之间的百分比，表示线程束中的线程在同一周期中执行的分支指令的百分比。分支效率越高，性能越好。分支效率的计算公式如下：\n$$ \\mathrm{branch\\ efficiency} = \\frac{\\mathrm{branches - divergent\\ branches}}{\\mathrm{branches}} $$\n以上线程束分化例子的完整代码如下：\n线程束分化示例\rCUDA 编程 DEMO：线程束分化 Cuda\r编译命令为：（强制 CUDA 编译器不利用分支预测去优化内核，使用 Tesla T4 GPU）\nnvcc -g -G -arch=sm_75 -o simpleDivergence simpleDivergence.cu\r运行结果为：\n代码中的 Warmup 部分是提前启动一次 GPU，因为第一次启动 GPU 时会比第二次速度慢一些，具体原因未知，可以去查一下 CUDA 的相关技术文档了解内容。我们可以通过 Nvidia Nsight Compute 来查看分支效率（旧版的 nvprof 被弃用了，metrics 参数对应的修改可以参考 CUDA 编程性能分析工具 nvprof/ncu \u0026ndash;metrics 参数含义\r，而且运行 ncu 时候必须使用 root 权限），结果如下所示：\n[58735] simpleDivergence@127.0.0.1\rwarmingup(float *) (1, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\rSection: Command line profiler metrics\r---------------------------------------------------- ----------- ------------\rMetric Name Metric Unit Metric Value\r---------------------------------------------------- ----------- ------------\rsmsp_sass_average_branch_targets_threads_uniform.pct 100.00%\r---------------------------------------------------- ----------- ------------\rmathKernel1(float *) (1, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\rSection: Command line profiler metrics\r---------------------------------------------------- ----------- ------------\rMetric Name Metric Unit Metric Value\r---------------------------------------------------- ----------- ------------\rsmsp_sass_average_branch_targets_threads_uniform.pct 83.33%\r---------------------------------------------------- ----------- ------------\rmathKernel2(float *) (1, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\rSection: Command line profiler metrics\r---------------------------------------------------- ----------- ------------\rMetric Name Metric Unit Metric Value\r---------------------------------------------------- ----------- ------------\rsmsp_sass_average_branch_targets_threads_uniform.pct 100.00%\r---------------------------------------------------- ----------- ------------\rmathKernel3(float *) (1, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\rSection: Command line profiler metrics\r---------------------------------------------------- ----------- ------------\rMetric Name Metric Unit Metric Value\r---------------------------------------------------- ----------- ------------\rsmsp_sass_average_branch_targets_threads_uniform.pct 71.43%\r---------------------------------------------------- ----------- ------------\rmathKernel4(float *) (1, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\rSection: Command line profiler metrics\r---------------------------------------------------- ----------- ------------\rMetric Name Metric Unit Metric Value\r---------------------------------------------------- ----------- ------------\rsmsp_sass_average_branch_targets_threads_uniform.pct 100.00%\r---------------------------------------------------- ----------- ------------\rCUDA 的 nvcc 编译器仍然是在 mathKernel1 和 mathKernel3 上执行有限的优化，以保证分支效率在 50% 以上。注意，mathKernel2 不报告分支分化的唯一原因是它的分支粒度是线程束大小的倍数。此外，把 mathKernel1 中的 if\u0026hellip;else 语句分离为 mathKernel3 的多个 if 语句，可以使分支分化的数量翻倍。\n3. 资源分配 前面提到，每个 SM 上执行的基本单位是线程束，也就是说，单指令通过指令调度器广播给某线程束的全部线程，这些线程同一时刻执行同一命令，当然也有分支情况，也有很多线程束没执行，那么这些没执行的线程束情况又如何呢？可以将这些没执行的线程束分为两类：一类是已经激活的，也就是说这类线程束其实已经在 SM 上准备就绪了，只是没轮到它执行，这时候它的状态为阻塞，另一类是可能分配到 SM 了，但是还没上片，这类就称之为未激活线程束。而每个 SM 上有多少个线程束处于激活状态，取决于以下资源：\n程序计数器 寄存器 共享内存 线程束一旦被激活来到片上，那么它就不会再离开 SM 直到执行结束。\n每个 SM 都有 32 位的寄存器组，每个架构寄存器的数量不一样，其存储于寄存器文件中，为每个线程进行分配，同时，固定数量的共享内存，在线程块之间分配。\n一个 SM 上被分配多少个线程块和线程束取决于 SM 中可用的寄存器和共享内存，以及内核需要的寄存器和共享内存大小。 当 kernel 占用的资源较少，那么更多的线程处于活跃状态，相反则线程越少。\n寄存器资源的分配 共享内存的分配 上面讲的主要是线程束，如果从逻辑上来看线程块的话，可用资源的分配也会影响常驻线程块的数量。特别是当 SM 内的资源没办法处理一个完整块，那么程序将无法启动。\n以下是资源列表：\n当寄存器和共享内存分配给了线程块，这个线程块处于活跃状态，所包含的线程束称为活跃线程束。活跃的线程束又分为三类：\n选定的线程束 阻塞的线程束 符合条件的线程束 当 SM 要执行某个线程束的时候，执行的这个线程束叫做选定的线程束，准备要执行的叫符合条件的线程束，如果线程束不符合条件还没准备好就是阻塞的线程束。 满足下面的要求，线程束才算是符合条件的：\n32 个 CUDA 核心可以用于执行 执行所需要的资源全部就位 Kepler 活跃的线程束数量从开始到结束不得大于 64，可以等于。任何周期选定的线程束小于等于 4 。由于计算资源是在线程束之间分配的，且线程束的整个生命周期都在片上，所以线程束的上下文切换是非常快速的。下一节将说明如何通过大量的活跃的线程束切换来隐藏延迟。\n4. 延迟隐藏 SM 依赖线程级并行，以最大化功能单元的利用率，因此，利用率与常驻线程束的数量直接相关。在指令发出和完成之间的时钟周期被定义为指令延迟。当每个时钟周期中所有的线程调度器都有一个符合条件的线程束时，可以达到计算资源的完全利用。这就可以保证，通过在其他常驻线程束中发布其他指令，可以隐藏每个指令的延迟。\n与在 CPU 上用 C 语言编程相比，延迟隐藏在 CUDA 编程中尤为重要。CPU 核心是为同时最小化延迟一个或两个线程而设计的，而 GPU 则是为处理大量并发和轻量级线程以最大化吞吐量而设计的。GPU 的指令延迟被其他线程束的计算隐藏。\n考虑到指令延迟，指令可以被分为两种基本类型：\n算术指令 内存指令 算术指令延迟是一个算术操作从开始到它产生输出之间的时间。内存指令延迟是指发送出的加载或存储操作和数据到达目的地之间的时间。对于每种情况，相应的延迟大约为：\n算术操作为 10～20 个周期 全局内存访问为 400～800 个周期 下图是阻塞线程束到可选线程束的过程逻辑图：\n其中线程束 0 （Warp 0） 阻塞两段时间后恢复可选模式，但是在这段等待时间中，SM 没有闲置。那么至少需要多少线程，线程束来保证最小化延迟呢？可以根据利特尔法则（Little\u0026rsquo;s Law）提供一个合理的近似值。它起源于队列理论中的一个定理，也可以用于 GPU 中：\n$$ \\mathrm{所需线程束}=\\mathrm{延迟}\\times \\mathrm{吞吐量} $$\n注意带宽和吞吐量的区别，带宽一般指的是理论峰值，最大每个时钟周期能执行多少个指令，吞吐量是指实际操作过程中每分钟处理多少个指令。简单来说，带宽通常是指理论峰值，而吞吐量是指已达到的值。\n这个可以想象成一个瀑布，像这样，绿箭头是线程束，只要线程束足够多，吞吐量是不会降低的：\n假设在 kernel 里一条指令的平均延迟是 5 个周期。为了保持在每个周期内执行 6 个线程束的吞吐量，则至少需要 30 个未完成的线程束。\n对于算术运算来说，其所需的并行可以表示成隐藏算术延迟所需要的操作数量。下面的表格出了 Fermi 和 Kepler 设备所需的操作数量。示例中的算术运算是一个 32 位的浮点数乘加运算 (a + b $\\times$ c)，表示在每个 SM 中每个时钟周期内的操作数量。吞吐量因不同的算术指令而不同。\n吞吐量由 SM 中每个周期内的操作数量确定，而执行一条指令的一个线程束对应 32 个操作。因此，为保持计算资源的充分利用，对于 Fermi GPU 而言，每个 SM 中所需的线程束数量通过计算为 $640 \\div 32 = 20 $ 个线程束。因此，算术运算所需的并行可以用操作的数量或线程束的数量来表示。这个简单的单位转换表明，有两种方法可以提高并行：\n指令级并行（ILP）：一个线程中有很多独立的指令 线程级并行（TLP）：很多并发地符合条件的线程 同样，与指令周期隐藏延迟类似，内存隐藏延迟是靠内存读取的并发操作来完成的，需要注意的是，指令隐藏的关键目的是使用全部的计算资源，而内存读取的延迟隐藏是为了使用全部的内存带宽，内存延迟的时候，计算资源正在被别的线程束使用，所以我们不考虑内存读取延迟的时候计算资源在做了什么，我们的根本目的是把计算资源，内存读取的带宽资源全部使用满，这样就能达到理论的最大效率。同样下表根据利特尔法则给出了需要多少线程束来最小化内存读取延迟，不过这里有个单位换算过程，机器的性能指标内存读取速度给出的是 GB/s 的单位，而我们需要的是每个时钟周期读取字节数，所以要用这个速度除以频率，例如 Tesla C2070 的内存带宽是 144 GB/s，转化成时钟周期： $\\frac{144\\mathrm{GB/s}}{1.566 \\mathrm{GHz}}=92\\mathrm{B/t}$，这样就能得到单位时间周期的内存带宽了。即下表的数据：\n需要说明的是这个速度不是单个 SM 的而是整个 GPU 设备的。Fermi 需要并行的读取 74KB 的数据才能让 GPU 带宽满载，如果每个线程读取 4 个字节，我们大约需要 18500 个线程，大约 579 个线程束才能达到这个峰值。\n所以，延迟的隐藏取决于活动的线程束的数量，数量越多，隐藏得越好，但是线程束的数量又受到上面的说的资源影响。所以这里就需要寻找最优的执行配置来达到最优的延迟隐藏。\n那么我们怎么样确定一个线程束的下界呢，使得当高于这个数字时 SM 的延迟能充分的隐藏，其实这个公式很简单，也很好理解，就是 SM 的计算核心数乘以单条指令的延迟，比如 32 个单精度浮点计算器，每次计算延迟 20 个时钟周期，那么我需要最少 $32 \\times 20 =640$ 个线程使设备处于忙碌状态。然而，这只是一个下边界。\n5. 占用率 在每个 CUDA 核心里指令是顺序执行的。当一个线程束阻塞时，SM 切换执行其他符合条件的线程束。理想情况下，我们想要有足够的线程束占用设备的核心。占用率是每个 SM 中活跃的线程束占最大线程束数量的比值。即：\n$$ \\mathrm{Occupancy} = \\frac{\\mathrm{Active\\ Warps}}{\\mathrm{Max\\ Warps}} $$\n通过以下代码可以查询设备的最大线程束数量：\nint dev = 0;\rcudaDeviceProp deviceProp;\rCHECK(cudaGetDeviceProperties(\u0026amp;deviceProp, dev));\rlog_info(\u0026quot;Device %d: %s\u0026quot;, dev, deviceProp.name);\rlog_info(\u0026quot;Number of SMs: %d\u0026quot;, deviceProp.multiProcessorCount);\rlog_info(\u0026quot;Total amount of constant memory: %4.2f KB\u0026quot;, deviceProp.totalConstMem / 1024.0);\rlog_info(\u0026quot;Total amount of shared memory per block: %4.2f KB\u0026quot;,\rdeviceProp.sharedMemPerBlock / 1024.0);\rlog_info(\u0026quot;Total number of registers available per block: %d\u0026quot;, deviceProp.regsPerBlock);\rlog_info(\u0026quot;Warp size: %d\u0026quot;, deviceProp.warpSize);\rlog_info(\u0026quot;Maximum number of threads per block: %d\u0026quot;, deviceProp.maxThreadsPerBlock);\rlog_info(\u0026quot;Maximum number of threads per multiprocessor: %d\u0026quot;,\rdeviceProp.maxThreadsPerMultiProcessor);\rlog_info(\u0026quot;Maximum number of warps per multiprocessor: %d\u0026quot;,\rdeviceProp.maxThreadsPerMultiProcessor / 32);\rreturn 0;\r输出结果为：\n可以看到 RTX4090 最大 64 个线程束每个 SM。\n内核使用寄存器的数量会影响 SM 内线程束的数量，nvcc 的编译选项也有手动控制寄存器的使用。也可以通过调整线程块内线程的多少来提高占用率，当然要合理不能太极端：\n小的线程块：每个线程块中线程太少，会在所有资源没用完就达到了线程束的最大要求 大的线程块：每个线程块中太多线程，会导致每个 SM 中每个线程可用的硬件资源较少。 一个确定网格和线程块大小的基本准则如下：\n保持每个块中线程数量是线程束大小（32）的倍数 避免块太小：每个块至少要有 128 或 256 个线程 根据内核资源的需求调整块大小 块的数量要远远多于 SM 的数量，从而在设备中可以显示有足够的并行 通过实验得到最佳执行配置和资源使用情况 尽管在每种情况下会遇到不同的硬件限制，但它们都会导致计算资源未被充分利用，阻碍隐藏指令和内存延迟的并行的建立。占用率唯一注重的是在每个 SM 中并发线程或线程束的数量。然而，充分的占用率不是性能优化的唯一目标。内核一旦达到一定级别的占用率，进一步增加占用率可能不会改进性能。为了提高性能，可以调整很多其他因素。\n6. 同步 栅栏同步是一个原语，它在许多并行编程语言中都很常见。在 CUDA 中，同步可以在两个级别执行：\n线程块内同步 系统级别 块级别的就是同一个块内的线程会同时停止在某个设定的位置，用\n__syncthreads();\r这个函数完成，这个函数只能同步同一个块内的线程，不能同步不同块内的线程，想要同步不同块内的线程，就只能让核函数执行完成，控制程序交换主机，这种方式来同步所有线程。当__syncthreads 被调用时，在同一个线程块中每个线程都必须等待直至该线程块中所有其他线程都已经达到这个同步点。线程产生的所有全局内存和共享内存访问，将会在栅栏后对线程块中所有其他的线程可见。该函数可以协调同一个块中线程之间的通信，但它强制线程束空闲，从而可能对性能产生负面影响。\n在不同的块之间没有线程同步。块间同步，唯一安全的方法是在每个内核执行结束端使用全局同步点；也就是说，在全局同步之后，终止当前的核函数，开始执行新的核函数。\n不同块中的线程不允许相互同步，因此 GPU 可以以任意顺序执行块。这使得 CUDA 程序在大规模并行 GPU 上是可扩展的。\n7. 可扩展性 对于任何并行应用程序而言，可扩展性是一个理想的特性。可扩展性意味着为并行应用程序提供了额外的硬件资源，相对于增加的资源，并行应用程序会产生加速。例如，若一个 CUDA 程序在两个 SM 中是可扩展的，则与在一个 SM 中运行相比，在两个 SM 中运行会使运行时间减半。一个可扩展的并行程序可以高效地使用所有的计算资源以提高性能。可扩展性意味着增加的计算核心可以提高性能。串行代码本身是不可扩展的，因为在成千上万的内核上运行一个串行单线程应用程序，对性能是没有影响的。并行代码有可扩展的潜能，但真正的可扩展性取决于算法设计和硬件特性。\n能够在可变数量的计算核心上执行相同的应用程序代码的能力被称为透明可扩展性。一个透明的可扩展平台拓宽了现有应用程序的应用范围，并减少了开发人员的负担，因为它们可以避免新的或不同的硬件产生的变化。可扩展性比效率更重要。一个可扩展但效率很低的系统可以通过简单添加硬件核心来处理更大的工作负载。一个效率很高但不可扩展的系统可能很快会达到可实现性能的上限。\nCUDA 内核启动时，线程块分布在多个 SM 中。网格中的线程块以并行或连续或任意的顺序被执行。这种独立性使得 CUDA 程序在任意数量的计算核心间可以扩展。\n下图展示了 CUDA 架构可扩展性的一个例子。左侧的 GPU 有两个 SM， 可以同时执行两个块；右侧的 GPU 有 4 个 SM ，可以同时执行 4 个块。不修改任何代码，一个应用程序可以在不同的 GPU 配置上运行，并且所需的执行时间根据可用的资源而改变。\n参考资料 [1] CUDA C 编程权威指南，机械工业出版社，（美）程润伟（John Cheng） 等著\n","date":"2023-08-31T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/20230831184001-2023-08-31.webp","permalink":"https://cuterwrite.top/p/cuda-base-warp/","title":"CUDA 基础：线程束执行的本质"},{"content":"SSE 与 AVE 向量化编程 一、 向量化编程简介 近年来，CPU 已经达到了一些物理和功率限制，因此在 GHz 方面，CPU 速度并没有显著提高。随着计算需求的不断增加，CPU 设计人员决定用三种解决方案来解决这个问题：\n增加更多核心。通过这种方式，操作系统可以在不同的内核之间分配正在运行的应用程序。此外，程序还可以创建多个线程来最大化核心使用率 将向量化操作应用到每个核心。该解决方案允许 CPU 对数据向量执行相同的指令。这只能在应用程序级别完成 多条指令的无序执行。如果现代 CPU 是独立的，那么它们最多可以同时执行四条指令。 向量寄存器始于 1997 年的 MMX 指令集。MMX 指令集具有 80 位的寄存器。之后发布了 SSE 指令集（从 SSE1 到 SEE4.2 有多个版本），具有 128 位寄存器。2011 年，英特尔发布了采用 AVX 指令集（256 位寄存器）的 Sandy Bridge 架构。2016 年，首款 AVX-512 CPU 发布，采用 512 位寄存器（最多 16x 32 位浮点矢量）。\n本文将重点介绍 SSE 和 AVX 指令集，因为它们通常出现在最近的处理器中。AVX-512 不在讨论范围内，但只需将 256 位寄存器更改为 512 位对应寄存器(ZMM 寄存器)，即可将本文中的所有示例应用于 AVX-512。\n1. SSE/AVE 寄存器 SSE 和 AVX 各有 16 个寄存器。在 SSE 中，它们被称为 XMM0-XMM15，而在 AVX 中，它们被称为 YMM0-YMM15。XMM 寄存器长度为 128 位，而 YMM 为 256 位。\nSSE 增加了三个类型定义： __m128 、 __m128d 和 __m128i 。分别为浮点型、双精度型(D)和整型(I)。\nAVE 增加了三个类型定义： __m256 、 __m256d 和 __m256i 。分别为浮点型、双精度型(D)和整型(I)。\nXMM 和 YMM 是重叠的：XMM 寄存器被视为相应 YMM 寄存器的下半部分。这可能会在混合使用 SSE 和 AVX 代码时带来一些性能问题。\n浮点数据类型（如__m128、__m128d、__m256 和__m256d）在 GCC 编译器中被视为具有相同数据结构的类型。因此，GCC 允许以数组的形式访问这些数据类型的组件。即：下面代码是合法的。\n__m256 myvar = _mm256_set1_ps(6.665f); // Set all vector values to a single float\rmyvar[0] = 2.22f; // This is valid in GCC compiler\rfloat f = (3.4f + myvar[0]) * myvar[7]; // This is valid in GCC compiler\r例如，对于__m128 类型的变量，可以通过索引来访问其中的四个单精度浮点数组件。对于__m128d 类型的变量，可以通过索引来访问其中的两个双精度浮点数组件。类似地，对于__m256 和__m256d 类型的变量，可以通过索引来访问其中的八个单精度浮点数或四个双精度浮点数组件。\n而在 GCC 编译器中，__m128i 和__m256i 是用于处理整数向量的数据类型。它们被定义为联合体（union），可以表示不同长度的整数向量。然而，由于联合体的特性，访问其中的具体数据成员可能会有一些困难。为了从整数向量中提取单个数据值，可以使用 _mm_extract_epiXX() 函数。这些函数允许从整数向量中提取指定位置的数据值，并将其作为标量返回。 _mm_extract_epiXX() 函数中的 XX 表示整数向量的位宽，例如， _mm_extract_epi32() 用于从 32 位整数向量中提取单个 32 位整数值。\n2. AVE 操作例子 执行 AVX 指令的过程如下：\n所有操作同时进行。就性能而言，在 AVX 中对浮点数执行单个 Add 的消耗与在 AVX 中对 8 个浮点数执行 VAdd 的消耗近似。在Agner Fog\u0026rsquo;s instruction tables\r中，可以获得更多有关指令延迟和吞吐量的信息。在 Sandy Bridge 架构上，VADDPS/D 的延迟为 3，吞吐量为 1，就像 FADD(P) 一样。\n3. 先决条件 SSE/AVX 需要目标机器具备相应的硬件支持。因此，为了确保程序在目标机器上能够正常运行，需要满足这些指令集扩展的先决条件。本文中的示例代码为了简化构建过程并确保程序在当前机器上正常运行，使用-march=native 编译选项。这个选项会自动检测当前机器的 CPU 能力，并使用相应的指令集扩展。这样可以充分利用目标机器的硬件能力，提高程序的性能和效率。\n注意：编译后的二进制文件在没有 AVX 功能的计算机上将失败。如果需要适应不同 CPU 的二进制代码，则需要利用 CPU Flag 并调用不同的函数，或者针对不同的指令集生成不同的二进制代码。\n由于操作系统、编译器和 CPU 都必须允许 SSE/AVX 扩展。我们可以运行以下脚本来检测系统功能：\n#!/bin/bash\r#CPU flag detection\recho -e \u0026quot;\\e[32m\u0026gt;\u0026gt;\u0026gt; Getting CPU flag capabilities and number of cores\\e[0m\u0026quot;\rcat /proc/cpuinfo | egrep \u0026quot;(flags|model name|vendor)\u0026quot; | sort | uniq -c\r#Compiler capabilities. -march=native is required!\recho -e \u0026quot;\\e[32m\u0026gt;\u0026gt;\u0026gt; Getting GCC capabilities\\e[0m\u0026quot;\rgcc -march=native -dM -E - \u0026lt; /dev/null | egrep \u0026quot;SSE|AVX\u0026quot; | sort\r#OS kernel version\recho -e \u0026quot;\\e[32m\u0026gt;\u0026gt;\u0026gt; Getting OS Kernel Version\\e[0m\u0026quot;\runame -a\r在 CPU Flag 中，我们可以看到 SSE 和 AVX 的支持。我们将搜索 avx 标志。这表明 CPU 兼容 AVX。如果有 avx2，则表示 CPU 允许 AVX2 扩展。AVX 足以支持 8x32 位浮点矢量。AVX2 为整数增加了 256 位向量（例如 8x32 位整数）。尽管如此，256 位整数向量的执行速度似乎与两个 128 位向量相同，因此与 SSE 128 位整数向量相比，性能并没有显著提高。\n在 GCC 的输出中，我们可以看到 #define __AVX__ 1 等。这表明 GCC 允许使用 AVX 指令集扩展。\n记住始终使用 -march=native 或 -mavx， 如果运行 GCC 时没有使用正确的 march，就不会得到 AVX 标志！ 默认的 GCC 参数是通用的，如果没有该标记，即使 CPU 支持 AVX，也无法启用 AVX。\n最后，我们需要再次检查 Linux 内核是否为 2.6.30 或更高版本。理想的内核是 4.4.0 或更高版本。\n有了所有这些先决条件，我们就可以开始编写第一个 AVX 向量程序了。\n二、自动向量化 1. GCC 自动向量化 flag GCC 是一种高级编译器，使用优化标志 -O3 或 -ftree-vectorize 时，编译器会搜索循环向量化（需要指定-mavx flag）。在源代码保持不变的情况下，GCC 编译出来的代码会完全不同。\n除非启用某些标志，否则 GCC 不会记录任何有关自动向量化的内容。如果需要自动向量化结果的详细信息，可以使用以下编译器 flag\n-fopt-info-vec 或 -fopt-info-vec-optimized：编译器将记录哪些循环（按行号）正在进行向量化优化。 -fopt-info-vec-missed：关于未被向量化的循环的详细信息，以及许多其他详细信息。 -fopt-info-vec-note：关于所有循环和正在进行的优化的详细信息。 -fopt-info-vec-all：所有以上的选项放在一起。 注意：还有类似的 -fopt-info-[options]-optimized 标志用于其他编译器优化，如内联： -fopt-info-inline-optimized\n在以下示例中，我们将使用 -O3 和 -fopt-info-vec-optimized 启用 GCC 自动向量化。当然也可以更改编译器标志以查看不同的日志记录选项。\n// autovector.cpp\r// compile: g++ -fopt-info-vec-optimized -o autovector autovector.cpp\r#pragma GCC optimize(\u0026quot;O3\u0026quot;, \u0026quot;unroll-loops\u0026quot;, \u0026quot;omit-frame-pointer\u0026quot;, \u0026quot;inline\u0026quot;) // 优化选项\r#pragma GCC option(\u0026quot;arch=native\u0026quot;, \u0026quot;tune=native\u0026quot;, \u0026quot;no-zero-upper\u0026quot;) // 启用 AVX\r#pragma GCC target(\u0026quot;avx\u0026quot;) // 启用 AVX\r#include \u0026lt;bits/stdc++.h\u0026gt;\r#include \u0026lt;x86intrin.h\u0026gt; // AVX/SSE 指令集\rint main()\r{\rconst int N = 200000;\rconst int numTests = 10000;\rfloat a[N], b[N], c[N], result[N];\rauto start = std::chrono::high_resolution_clock::now();\r// 数据初始化\rfor (int i = 0; i \u0026lt; N; ++i)\r{\ra[i] = ((float)i) + 0.1335f;\rb[i] = 1.50f * ((float)i) + 0.9383f;\rc[i] = 0.33f * ((float)i) + 0.1172f;\r}\rfor (int i = 0; i \u0026lt; numTests; ++i)\r{\rfor (int j = 0; j \u0026lt; N; ++j)\r{\rresult[j] = a[j] + b[j] - c[j] + 3 * (float)i;\r}\r}\rauto end = std::chrono::high_resolution_clock::now();\rauto duration = std::chrono::duration_cast\u0026lt;std::chrono::microseconds\u0026gt;(end - start).count();\rassert(result[2] == (2.0f + 0.1335f) + (1.50f * 2.0f + 0.9383f) - (0.33f * 2.0f + 0.1172f) +\r3 * (float)(numTests - 1));\rstd::cout \u0026lt;\u0026lt; \u0026quot;CG\u0026gt; message -channel \\\u0026quot;results\\\u0026quot; Time used: \u0026quot; \u0026lt;\u0026lt; duration\r\u0026lt;\u0026lt; \u0026quot;s, N * numTests=\u0026quot; \u0026lt;\u0026lt; (N * numTests) \u0026lt;\u0026lt; std::endl;\rreturn 0;\r}\r如果一切正常，将看到编译器测试结果：\nautovector.cpp:15:23: optimized: loop vectorized using 32 byte vectors\r将编译选项更改为 -fopt-info-vec-all，可以看到更多的信息，包括向量化的循环的行号。 在 autovector.cpp 第 1 行，将 O3 改为 O2 , 然后重新运行。将不会看到 loop vectorized ，而且非向量化编译会比向量化编译慢。 2. 循环向量化的要求 并非所有循环都能进行向量化。要进行向量化，对循环有一些严格的要求。\n一旦循环开始，循环计数就不能改变。这意味着，循环的终点可以是一个动态变量，可以随意增加或减少其值，但一旦循环开始，它就必须保持不变。 使用 break 或 continue 句子会有一些限制。有时编译器会很聪明地让它起作用，但在某些情况下，循环不会被向量化。 在循环内调用外部函数有一些限制 循环不应该有数据依赖关系。 条件句 (if/Else) 可以在不改变控制流的情况下使用，并且只用于有条件地将 A 或 B 值加载到 C 变量中。选择 A 或 B 是在编译器中使用掩码完成的，因此它同时计算分支 A 和 B ，而 C 将存储一个或另一个值： if ( s \u0026gt;= 0 ) {\rx[i] = (-b[i]+s)/(2.0f*a[i]);\ry[i] = (-b[i]-s)/(2.0f*a[i]);\r}\relse {\rx[i] = 0.0f;\ry[i] = 0.0f;\r}\r这是一个可向量循环。控制流从未改变，x[i] 和 y[i] 值总是设置为其中一个或另一个值。\n有关自动向量化的更多信息，请阅读Intel C++编译器的矢量化\r。该文档虽然面向 Intel 编译器，但它提供了有关自动向量化的有趣而完整的信息。\n自动向量化的好处是，它是自动完成的。编译器会尝试向量化循环，开发人员不需要做任何事情。但是有时(尤其是在高性能计算应用中)需要微调循环和向量化，通过使用手动 AVX 向量化来确保最大吞吐量。\n三、SSE/AVX 的使用 支持 SSE/AVX 的 CPU 具有用于操作 XMM 和 YMM 寄存器的汇编指令。但在大多数编译器中，通过使用内置函数简化了这一过程，因此开发人员不需要直接使用汇编。\n1. 内置函数 编译器将汇编指令封装为函数，使用它们就像调用带有正确参数的函数一样简单。有时，如果 CPU 不支持指令集，些内置函数就会被模拟。\nSSE/AVX 内置函数使用以下命名约定：\n_\u0026lt;vector_size\u0026gt;_\u0026lt;intrin_op\u0026gt;_\u0026lt;suffix\u0026gt;\r\u0026lt;vector_size\u0026gt; 是指向量的大小。对于 128 位的 SSE， 它为 mm，对于 256 位的 AVX/AVX2，它为 mm256，对于 512 位的 AVX512， 它为 mm512 。 \u0026lt;intrin_op\u0026gt; 是指内置函数的名称，例如 add 或 sub，mul 等 。 \u0026lt;suffix\u0026gt; 是指内置函数的参数类型，例如 ps 表示 float ，pd 表示 double ，epi8 表示 int8_t，epi32 表示 int32_t , epu16 表示 uint16_t 等。 你可以在Intel Intrinsics Guide\r中找到所有内置函数，它是 SSE/AVX 中提供的任何内置函数的完整参考。此外，还有一份 x86 内置函数 Cheet Sheet\r，但由于内容更为复杂，阅读起来比较困难。\n2. SSE/AVX 没有提供的内置函数 缺少整数除法：由于某些原因，SSE 和 AVX 缺少整数除法运算符。有一些方法可以克服这一点：\n在线性代码中通过计算除法来完成操作。首先，从向量中取出单个数据，然后进行除法运算，最后将结果再次存储回向量中。然而，这种方法速度较慢。 将整数向量转换为浮点数，将它们相除，然后再次转换为整数。 对于编译时的已知除数，有一些魔法数（magic number）可以将常量除法转换为乘法运算。可以参考libdivide\r。 对于 2 的幂除法，使用位移操作。除以整数 2 等于右移。只有当所有向量都被相同的 2 的幂整除时，才能进行右移操作。不过对有符号数进行右移时要注意！需要使用符号位移。 缺少三角函数：内置函数中没有三角函数。可能的解决办法是用线性代码计算（对每个向量值逐一计算），或创建近似函数。泰勒级数和 Remez 近似函数的效果很好。\n缺少随机数生成器：此外，没有随机数生成器。但是从线性版本重新创建一个好的伪随机生成器是很简单的。只需确定伪随机数生成器中使用的位即可。填充向量首选 32 位或 64 位 RNG。\n3. 性能损失 数据对齐： 旧的 CPU 架构不能使用向量化，除非数据在内存中与向量大小一致。其他一些 CPU 可以使用未对齐的数据，但性能会有所损失。在最近的处理器中，这种影响似乎可以忽略不计。但为了安全起见，如果不增加过多的开销，对齐数据可能是个好主意。有关数据对齐的资料，可参考Data alignment for speed: myth or reality?\r在 GCC 中，可以使用以下变量属性进行数据对齐： __attribute__((aligned(16)))、__attribute__((aligned(32))) 最简单的变量对齐声明：#define ALIGN __attribute__((aligned(32))) SSE/AVX 转换损失： 将传统的 SSE 库与新的 AVX 架构混合使用还有一个大问题。由于 XMM 和 YMM 共享低 128 位，在 AVX 和 SSE 之间转换可能导致高 128 位出现未定义的值。为了解决这个问题，编译器需要保存高 128 位，清除它，执行旧的 SSE 操作，然后恢复旧值。但是这显著增加了 AVX 操作的开销，导致性能下降。\n注意：这个问题并不意味着不能同时使用__m128 和__m256 而不影响性能。AVX 有一个针对__m128 的新指令集，带有 VEX 前缀。这些新的 VEX 指令与__M256 指令相结合没有任何问题。当非 VEX __m128 指令与 __m256 指令结合使用时，就会产生转换代价。当使用旧的 SSE 库链接到新的启用 AVX 的程序时，就会发生这种情况。\n为了避免转换损失，编译器可以使用 -mvzeroupper 参数自动添加对 VZEROUPPER (清除高 128 位)或 VZEROALL（清除所有 YMM 寄存器）的调用，程序员也可以手动添加。如果不使用外部 SSE 库，且确定所有代码都启用了 VEX 并在编译时启用了 AVX 扩展，则可以使用 -mvzeroupper 参数指示编译器避免添加 VZEROUPPER 调用： -mno-vzeroupper。更多关于 SSE/AVX 转换损失的资料，可参考Avoiding AVX-SSE Transition Penalties\r和 Why is this SSE code 6 times slower without VZEROUPPER on Skylake?\r。\n数据移动成本：在 AVX 寄存器中来回移动数据的成本很高。在某些情况下，如果有一些数据存储在线性结构中，那么将这些数据发送到 AVX 向量、执行一些操作并恢复这些数据的成本要比简单地执行线性计算高。因此，开发时必须考虑到数据加载和卸载的开销。请记住，在某些情况下，这将成为性能瓶颈。\n4. AVX 使用例子：计算平方根 下面程序是对浮点数的 SQRT 计算进行向量化，显式使用 __m256 数据类型来存储浮点数，从而减少数据加载的开销。 // vectorized_sqrt.cpp\r// compile: g++ -o vectorized_sqrt vectorized_sqrt.cpp\r#pragma GCC optimize(\u0026quot;O3\u0026quot;, \u0026quot;unroll-loops\u0026quot;, \u0026quot;omit-frame-pointer\u0026quot;, \u0026quot;inline\u0026quot;) // 优化选项\r#pragma GCC option(\u0026quot;arch=native\u0026quot;, \u0026quot;tune=native\u0026quot;, \u0026quot;no-zero-upper\u0026quot;) // 启用 AVX\r#pragma GCC target(\u0026quot;avx\u0026quot;) // 启用 AVX\r#include \u0026lt;bits/stdc++.h\u0026gt;\r#include \u0026lt;x86intrin.h\u0026gt; // AVX/SSE 指令集\rconst int N = 64000000;\rconst int V = N / 8;\rfloat linear[N];\r// 禁用自动向量化\r__attribute__((optimize(\u0026quot;no-tree-vectorize\u0026quot;))) inline void normal_sqrt()\r{\rfor (int i = 0; i \u0026lt; N; ++i)\r{\rlinear[i] = sqrtf(linear[i]);\r}\r}\r__m256 ALIGN vectorized[V];\rinline void avx_sqrt()\r{\rfor (int i = 0; i \u0026lt; V; ++i)\r{\rvectorized[i] = _mm256_sqrt_ps(vectorized[i]);\r}\r}\r#define TIME \\\rstd::chrono::duration_cast\u0026lt;std::chrono::duration\u0026lt;double\u0026gt;\u0026gt;( \\\rstd::chrono::high_resolution_clock::now() - now) \\\r.count()\rint main(int argc, char **argv)\r{\r// 数据初始化\rfor (int i = 0; i \u0026lt; N; ++i)\r{\rlinear[i] = ((float)i) + 0.1335f;\r}\rfor (int i = 0; i \u0026lt; V; ++i)\r{\rfor (int v = 0; v \u0026lt; 8; ++v)\r{\rvectorized[i][v] = ((float)(i * 8 + v)) + 0.1335f;\r}\r}\r// normal_sqrt benchmark\rauto now = std::chrono::high_resolution_clock::now();\rfor (int i = 0; i \u0026lt; 20; ++i)\r{\rnormal_sqrt();\r}\rauto linear_time = TIME;\rstd::cerr \u0026lt;\u0026lt; \u0026quot;Normal sqrtf: \u0026quot; \u0026lt;\u0026lt; linear_time \u0026lt;\u0026lt; std::endl;\r// AVX sqrt benchmark\rnow = std::chrono::high_resolution_clock::now();\rfor (int i = 0; i \u0026lt; 20; ++i)\r{\ravx_sqrt();\r}\rauto avx_time = TIME;\rstd::cerr \u0026lt;\u0026lt; \u0026quot;AVX sqrtf: \u0026quot; \u0026lt;\u0026lt; avx_time \u0026lt;\u0026lt; std::endl;\r// Check Values\rfor (int i = 0; i \u0026lt; V; ++i)\r{\rfor (int v = 0; v \u0026lt; 8; ++v)\r{\rif (abs(linear[i * 8 + v] - vectorized[i][v]) \u0026gt; 0.00001f)\r{\rstd::cerr \u0026lt;\u0026lt; \u0026quot;Error: AVX sqrtf is not equal to normal sqrtf!\u0026quot; \u0026lt;\u0026lt; std::endl;\rstd::cerr \u0026lt;\u0026lt; \u0026quot;linear[\u0026quot; \u0026lt;\u0026lt; i * 8 + v \u0026lt;\u0026lt; \u0026quot;] = \u0026quot; \u0026lt;\u0026lt; linear[i * 8 + v] \u0026lt;\u0026lt; std::endl;\rstd::cerr \u0026lt;\u0026lt; \u0026quot;vectorized[\u0026quot; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026quot;][\u0026quot; \u0026lt;\u0026lt; v \u0026lt;\u0026lt; \u0026quot;] = \u0026quot; \u0026lt;\u0026lt; vectorized[i][v]\r\u0026lt;\u0026lt; std::endl;\rreturn -1;\r}\r}\r}\rstd::cout \u0026lt;\u0026lt; \u0026quot;Linear to AVX improvement : \u0026quot; \u0026lt;\u0026lt; (linear_time / avx_time * 100) \u0026lt;\u0026lt; \u0026quot;%\u0026quot;\r\u0026lt;\u0026lt; std::endl;\rreturn 0;\r}\r可能会看到 600% 或更高的性能提升。也就是说，一旦加载了数据，AVX 的运行速度将是普通 sqrtf 的 7 倍。理论极限是 800%，但很少能达到。一般来说可以预期平均提高 300% 到 600%。运行结果如下： Normal sqrtf: 1.51901\rAVX sqrtf: 0.374871\rLinear to AVX improvement : 405.209%\r可以看到：运行速度提高了 405%。 四、C++中的 SSE/AVX 框架 1. 内置函数的复杂性 直接使用内置函数会使代码编写和维护变得复杂。问题在于内置函数名很长，比如算术运算用函数符号书写：add(a,b) 而不是 a + b。导致下面的代码很难阅读：\nx = _mm256_div_ps(_mm256_add_ps(b, _mm256_sqrt_ps(_mm256_sub_ps(_mm256_mul_ps(b, b),\r_mm256_mul_ps(_mm256_mul_ps(a, c),\r_mm256_set1_ps(4.0f))))) , _mm256_mul_ps(a,_mm256_set1_ps(2.0f)));\r而以下封装版本的可读性非常好：\nx = (b + sqrt(b * b - a * c * 4.0f)) / (a * 2.0f);\r2. 用于 SIMD 计算的 C++框架 现有的一些框架在新的类中封装了向量数据类型。然后，它们重载算术、逻辑和赋值运算符，以简化计算。其中，可以使用这两个框架：\nAgner Fog\u0026rsquo;s C++ vector class library\r： 内容完整，定期更新。而且还包含了三角函数。 Unified Multicore Environment\r：一个较新的库 xsimd Wrapper\r：一个比较好用的 C++ Wrapper。 不过，这些库的体积都比较大，在代码大小有限（小于 100kb）的情况下，可以使用以下简单的封装版本，只需要关注一两种类型。\nSIMD-Framework\rVector wrappers that are reduced in size, just focused on one or two types (for example, __m256 8x float and __m128i 8x short, to work with a vector size of 8, both on floats and on integers). C\u0026#43;\u0026#43;\r除了内置函数，该封装版本还封装了一些特殊的函数： Blend-based functions：blend 是根据掩码有条件地加载向量值的过程，这类函数用于混合两个向量的函数。 if_select(mask,value_true,value_false) ：根据掩码对向量进行有条件加载。如果掩码为真，则返回 value_true，否则返回 value_false。 if_add(mask,value,add_when_true) ：条件加法。返回 value + (mask? add_when_true:0) ，对于每个向量分量。 if_sub, if_mul, if_div ：与 if_add 类似，只是算术运算方式不同。 Horizontal functions：Horizontal 表示这些函数通过计算某些逻辑值或算术值，在单个向量变量内运行。 horizontal_or(mask) ：如果掩码中的任何向量分量为 true。返回布尔值。 horizontal_add(vector) ：返回向量的所有分量的总和。返回值是一个数字(浮点型、双精度型或整型，具体取决于向量类型)。 五、Masking 与 Conditional Load 1. 向量中的掩码 掩码是向量之间逻辑运算的结果。它与布尔运算有许多相似之处（它们是对单个数字或其他布尔运算的逻辑运算结果），但在内部，每个掩码组件必须全部为 0 位或全部为 1 位。\n让我们比较具有大于运算符的两个 AVX 浮点向量：\n输入是两个带有浮点分量的向量。逻辑运算的输出也是一个带浮点分量的向量，但其值的位数被设置为全 0 或全 1。全 1 表示 \u0026ldquo;真\u0026rdquo;，全 0 表示 \u0026ldquo;假\u0026rdquo;。对于浮点数，全 1 的值打印为-nan，对于整数，则打印为-1。存储的实际值并不重要。我们只需要知道它保存的是真值和假值。\n逻辑运算符的结果(\u0026gt;、\u0026lt;、==、\u0026amp;\u0026amp;、||等：以逻辑\u0026amp;\u0026amp;运算符为例：\nvector \u0026amp;\u0026amp; vector = mask mask \u0026amp;\u0026amp; mask == mask vector \u0026amp;\u0026amp; mask == ????? 最后一种情况，可能会有意想不到的结果，这就像试图做 3 \u0026gt; false，也许在 C++ 中这是可行的，但在逻辑意义上这是不正确的。\n注意：与布尔运算不同，并非零以外的任何数字都是 TRUE。只有所有位都设置为 1 的矢量成分才被视为 TRUE。不要使用其他值作为掩码。否则会失败，或得到意想不到的结果。\n2. 条件加载 掩码可用于有条件地将值加载到向量中。比如可以使用掩码来有条件地控制值向量的加载：if_select(mask,value_true,value_false) 可以表示为：\n当掩码设置为 FALSE 时，数据从 value_false 向量加载；当设置为 TRUE 时，数据从 value_true 向量加载。这个概念简单而有效。 代码示例 1：使用掩码和 SIMD-Framework 中的 v8f.h 实现条件加载。（主要使用 if_select(mask,value_true,value_false) 方法，该函数是 _mm256_blendv_ps 的封装）\n#pragma GCC optimize(\u0026quot;O3\u0026quot;, \u0026quot;unroll-loops\u0026quot;, \u0026quot;omit-frame-pointer\u0026quot;, \u0026quot;inline\u0026quot;)\r#pragma GCC option(\u0026quot;arch=native\u0026quot;, \u0026quot;tune=native\u0026quot;, \u0026quot;no-zeroupper\u0026quot;)\r#pragma GCC target(\u0026quot;avx\u0026quot;)\r#include \u0026lt;bits/stdc++.h\u0026gt;\r#include \u0026lt;x86intrin.h\u0026gt;\r#include \u0026quot;v8f.h\u0026quot;\rusing namespace std;\rinline v8f testConditions(const v8f \u0026amp;value)\r{\rreturn if_select(value \u0026gt; 3.0f || (value \u0026lt;= -3.7f \u0026amp;\u0026amp; value \u0026gt; -15.0f), sqrt(2.0f * value + 1.5f),\r(-2.0f * value - 8.7f));\r}\rinline bool validate(const v8f \u0026amp;test, const v8f \u0026amp;vector)\r{\rfor (int j = 0; j \u0026lt; 8; ++j)\r{\rfloat value = test[j];\rfloat expected;\rif (value \u0026gt; 3.0f || (value \u0026lt;= -3.7f \u0026amp;\u0026amp; value \u0026gt; -15.0f))\r{\rexpected = sqrt(2.0f * value + 1.5f);\r}\relse\r{\rexpected = (-2.0f * value - 8.7f);\r}\rif (abs(expected - vector[j]) \u0026gt; 0.00001f)\r{\rcout \u0026lt;\u0026lt; \u0026quot;Assert Error:\u0026quot; \u0026lt;\u0026lt; expected \u0026lt;\u0026lt; \u0026quot; \u0026quot; \u0026lt;\u0026lt; vector[j] \u0026lt;\u0026lt; endl;\rreturn false;\r}\r}\rreturn true;\r}\rint main()\r{\rint validTests = 0;\rint TotalTests = 1000;\rfor (int i = 0; i \u0026lt; TotalTests; ++i)\r{\rfloat offset = -500.0f + (1000.0f * i) / TotalTests;\rv8f test(1.4f, 3.3f, -12.5f, -33.4f, 7.9f, -70.2f, 15.1f, 22.6f);\rtest += offset;\rv8f result = testConditions(test);\rif (validate(test, result))\r{\r++validTests;\r}\r}\rcout \u0026lt;\u0026lt; \u0026quot;Valid Tests:\u0026quot; \u0026lt;\u0026lt; validTests \u0026lt;\u0026lt; \u0026quot;/\u0026quot; \u0026lt;\u0026lt; TotalTests \u0026lt;\u0026lt; \u0026quot; (\u0026quot;\r\u0026lt;\u0026lt; (100 * validTests / TotalTests) \u0026lt;\u0026lt; \u0026quot;%)\u0026quot; \u0026lt;\u0026lt; endl;\rif (validTests != TotalTests)\r{\rreturn -1;\r}\rreturn 0;\r}\r3. 性能 使用掩码的条件加载不是真正的分支，因此它们不会有误预测，并且 CPU 可以更好地利用无序执行。但这是有代价的。因为它们是无分支的，并且所有条件执行都是通过掩码操作完成的，所以总是计算和执行这两个分支。如果要对 value_false 进行非常复杂的计算，那么即使只有 0.00001% 的时间会发生，也会一直进行计算。如果代码中有些部分很少需要，但计算成本很高，这可能会导致性能问题。在下一章数据流控制中，可以通过控制数据流的方法，根据某些条件提前退出循环。\n六、数据流控制 1. 共享数据流问题 在线性编程中，创建条件分支 if、switch、continue 和 break 来控制数据流没有任何问题。你只需创建一个无限循环，并在条件满足时跳出循环即可。但是一个向量不仅有一个条件结果，而且同时有 N 个条件结果。向量的一部分可以准备退出循环(因为向量数据已达到退出条件)，但其余数据在退出之前仍有活动工作要做。\n如果向量分量已经计算完成，请冻结它以避免对其进行任何进一步的计算。具体做法是在任何数值赋值中屏蔽已完成的分量。未完成的向量分量会不断更新，但已完成的分量不会。因此，如果我有一个 8x 浮点矢量，而分量 0、1、4 和 7 已达到结束状态，我就需要在每次数据加载时加上一个掩码[false,false,true,true,false,true,false]\n2. 避免执行计算开销很大的分支 要节省 CPU 时间，最简单的方法是检查掩码内的所有值是否相同，要么全部为 \u0026ldquo;true\u0026rdquo;，要么全部为 \u0026ldquo;false\u0026rdquo;。当掩码内的所有值都相同时，我们就得到了一个简单的布尔值，要么为真，要么为假。这可以用来跳过部分代码，或使用普通的条件分支：if、switch、continue 和 break 等。\n在 SIMD-Framework 中，使用的是 horizontal_or(mask)函数（封装了_xxx_testz_xx）。该函数检查掩码内是否有任何值为真，如果存在真值则返回 true，否则返回 false。\n代码示例 2：使用 horizontal_or(mask) 函数判断掩码内是否有任何值为真，减少分支计算\nv8f result(0.0f);\rfor (int i = 0; i \u0026lt; 2000; i++)\r{\rv8f test(1.4f, 3.3f, -12.5f, -33.4f, 7.9f, -70.2f, 15.1f, 22.6f);\rtest += ((float)i) / 100.0f;\rif (horizontal_or(test \u0026gt;= 38.0f))\r{\rresult += if_select(test \u0026gt;= 38.0f, slowFunction(i), test);\r}\relse\r{\r// 全为 false，不需要执行 slowFunction，直接加上 test 向量即可\rresult += test;\r}\r}\r通过使用 horizontal_or ，还可以提前跳出循环。自动向量化无法实现这种优化，但手动向量化可以，而且是首选。 代码示例 3：使用 horizontal_or 提前跳出循环，该程序需要同时进行 8 次并行模拟，以 200 个回合为限，计算最大连击得分。一旦在任何一次并行模拟中得分超过 1700 分，就结束模拟，并返回最大得分（一个浮点数值，不是包含所有得分的整个向量，只是最大值）和获得该得分的回合。\n#pragma GCC optimize(\u0026quot;O3\u0026quot;, \u0026quot;unroll-loops\u0026quot;, \u0026quot;omit-frame-pointer\u0026quot;, \u0026quot;inline\u0026quot;)\r#pragma GCC option(\u0026quot;arch=native\u0026quot;, \u0026quot;tune=native\u0026quot;, \u0026quot;no-zeroupper\u0026quot;)\r#pragma GCC target(\u0026quot;avx\u0026quot;)\r#include \u0026lt;bits/stdc++.h\u0026gt;\r#include \u0026lt;x86intrin.h\u0026gt;\r#include \u0026quot;v8f.h\u0026quot;\rusing namespace std;\rint validateResult(const int \u0026amp;turn, const float \u0026amp;bestScore)\r{\rcout \u0026lt;\u0026lt; \u0026quot;Turn:\u0026quot; \u0026lt;\u0026lt; turn \u0026lt;\u0026lt; \u0026quot; bestScore:\u0026quot; \u0026lt;\u0026lt; std::setprecision(10) \u0026lt;\u0026lt; bestScore \u0026lt;\u0026lt; endl;\rif (turn != 133)\r{\rcout \u0026lt;\u0026lt; \u0026quot;ERROR, Expected turn exit at 133 != \u0026quot; \u0026lt;\u0026lt; turn \u0026lt;\u0026lt; endl;\rreturn -1;\r}\rif (bestScore != 1707.318481f)\r{\rcout \u0026lt;\u0026lt; \u0026quot;ERROR, Expected a bestScore of 1707.318481f != \u0026quot; \u0026lt;\u0026lt; std::setprecision(10)\r\u0026lt;\u0026lt; bestScore \u0026lt;\u0026lt; endl;\rreturn -1;\r}\rreturn 0;\r}\rint main()\r{\rint turn = 0;\rv8f Scores(1.0f, 3.0f, 7.0f, 13.4f, 22.7f, 0.01f, 4.556f, 9.7f);\rfor (turn = 0; turn \u0026lt; 200; ++turn)\r{\rScores += ((float)(turn) / 15.0f);\rif (turn == 40)\r{\rScores *= Scores / 15.0f + 2.0f;\r}\rif (turn == 70)\r{\rScores += if_select(Scores \u0026lt; 430.0f, 850.0f, 120.0f);\r}\r// 利用 horizontal_or 提前退出循环\rif (horizontal_or(Scores \u0026gt;= 1700.0f))\r{\rbreak;\r}\r}\rcout \u0026lt;\u0026lt; \u0026quot;Scores: \u0026quot; \u0026lt;\u0026lt; Scores \u0026lt;\u0026lt; endl;\rfloat bestScore = 0.0f;\r// 遍历获取最大分量\rfor (int i = 0; i \u0026lt; 8; i++)\r{\rfloat score = get(Scores, i);\rif (bestScore \u0026lt; score)\r{\rbestScore = score;\r}\r}\rreturn validateResult(turn, bestScore);\r}\r七、数据对齐 数据对齐是一种强制编译器在特定字节边界的内存中创建数据对象的方法。这样做的目的是为了提高从处理器加载和存储数据的效率。无需赘述，当数据可以在特定字节边界的内存地址之间移动时，处理器就可以高效地移动数据。对于支持英特尔® AVX-512 指令的英特尔® 处理器来说，当数据起始地址位于 64 字节边界时，内存移动效果最佳。因此，需要强制编译器创建起始地址为 64 字节模的数据对象。\n除了在对齐边界上创建数据（使基指针对齐）外，编译器还能在已知数据访问（包括基指针和索引）对齐 64 字节时执行优化。在通常情况下，如果没有用户的帮助，编译器并不知道循环内部的数据是对齐的。这可能迫使编译器在生成代码时采取保守做法，从而影响性能。因此还必须通过编译指示(C/C++)或指令(Fortran)、选项(如 Fortran 中的-Align array64byte)以及子句/属性的组合来通知编译器进行对齐，以便英特尔编译器能够生成最佳代码。\n总而言之，需要两个步骤：\n数据对齐 在性能关键区域(使用数据的区域)中使用 pragma/directives/clauses 来告诉编译器内存访问是对齐的 1. 数据对齐 调整数据以提高应用性能非常重要。这通常意味着两点：\n在为数组（或指针）分配空间时对齐基指针 确保每个向量化循环（对于每个线程）的起始索引具有良好的对齐属性 对齐静态数组（基指针）\n静态数组的对齐十分简单，不过在 Windows 上与 Linux 上的声明有所区别，以 64 字节边界上静态声明 1000 元素单精度浮点数组为例 在 Windows 上，使用 __declspec(align(64)) 修饰符： __declspec(align(64)) float a[1000];\r在 Linux 上，使用 __attribute__((aligned(64))) 修饰符： float a[1000] __attribute__((aligned(64)));\r对齐动态数据\n动态数据的对齐相对复杂，需要使用特殊的内存分配函数，如 _mm_malloc 和 _mm_free 来替代 malloc 和 free 函数。其中，这些函数的第二个参数是对齐参数（以字节为单位），比如 mm_malloc(p, 64) 返回的数据将是 64 字节对齐的。 对于动态分配的 C/C++ 数组，仅仅在创建时使用 mm_malloc 对齐数据是不够的（这是一个必要条件），还需要在相关循环之前添加一个__assume_aligned(a, 64) 形式的子句。如果没有这一步，编译器将无法检测使用此类数组进行访问时的最佳对齐方式。\n在 C++17 中，还可以使用 std::aligned_alloc 函数来分配对齐的内存，但是这个函数只能在 C++17 中使用，而且只能在 Linux 上使用。使用方式如下： float *a = std::static_cast\u0026lt;float *\u0026gt;std::aligned_alloc(64, 1000 * sizeof(float));\r// 使用完毕后，需要释放内存\rstd::free(a);\r对齐循环索引\n对于内存访问形式为 a[i+n1] 的循环，必须满足特定的对齐要求。具体来说，用户必须确保 （i-loop 的下界 + n1）是 16 的倍数（假设数据类型为 float）。\n此外，除非在编译时信息可以在静态情况下获得（例如访问形式为 x[i] ，并且所有线程的循环下界都是常数 0，或者在循环内部存在形式为 b[i+16*k] 的访问），用户还必须通知编译器关于这个对齐要求。否则，这一步还需要在循环前添加一个 __assume(n1%16==0) 或者 #pragma vector aligned 的语句（ 仅限于 Windows 平台 ）。以下是一个不满足数据对齐要求的例子：\n#define N 1000\rfloat a[N] __attribute__((aligned(64)));\rvoid process_array()\r{\rfor (int i = 0; i \u0026lt; N; i++)\r{\rfloat result = a[i + 4]; // 访问 a[i+n1]，其中 n1 = 4\r// 其它计算操作...\r}\r}\r如果我们要确保内存访问的性能最佳，我们需要确保 i 和 n1 的组合是对齐的，以便在向量化指令集中能够更有效地执行。在上面的代码中，循环的下界是 i 的初始值 0 ，所以 (0 + 4) 不是 16 的倍数。为了满足对齐要求，我们需要进行调整，并且通知编译器这个对齐属性。 #define N 1000\rfloat a[N] __attribute__((aligned(64)));\rvoid process_array(int n1)\r{\rfor (int i = 0; i \u0026lt; N; i += 16) // 调整循环的步长。\r{\r__assume((n1 % 16) == 0);\rfloat result = a[i + n1]; // 访问 a[i+n1]\r// 其它计算操作...\r}\r}\r2. 通知编译器数据对齐 既然已经对齐了数据，那么在程序中实际使用数据时，就有必要告知编译器这些数据是对齐的。例如，将数据作为参数传递给性能关键的函数或子程序时，编译器如何知道参数是对齐的还是未对齐的？例如，数据通常在一个源文件中声明，但在许多其他源文件中使用。因此，这一信息必须由用户提供，因为编译器往往没有关于参数的信息。\n有两种方法可以告知编译器数据对齐情况。 一种方法是使用 OpenMP SIMD ALIGNED 子句通知编译器在使用数据时的数据对齐情况。另一种方法则是使用英特尔专有子句在代码中指定数据对齐方式。\n编译器要为 i 循环内的（浮点数组）内存访问（如 a[i+n1] 和 X[i]）生成对齐的加载/存储，就必须知道：\n基数指针（a 和 X）已对齐。对于静态数组，可以使用上面讨论的技术实现对齐，例如使用 __declspec(align(64)) 。对于动态分配的数组，仅仅在创建时使用 mm_malloc 或 aligned_alloc 对齐数据是不够的，还需要如下所示的子句 __assume_aligned(a, 64) 。 编译器必须知道（i-loop 的下界 + n1）是 16 的倍数（假设数据类型为 float）。如果循环下界为 0 ，那么所需的信息就是 n1 是 16 的倍数。一种方法是添加一个 __assume(n1%16==0) 形式的子句。 代码示例 4： 在 Windows 上使用 __assume_aligned 和 __assume 指令来告知编译器数据对齐情况。\n// compile options: -O3 -xcore-avx512 -qopt-report-phase=vec -qopt-report=5 -qopt-report-file=stdout -restrict -c\r// 该编译指令将生成一个名为 stdout 的文件，其中包含有关向量化的信息。\r// restrict 关键字：提示编译器：在该指针的生命周期内，其指向的对象不会被别的指针所引用。\r#define N 1000\r__declspec(align(64)) float X[N], X2[N];\rvoid foo(float * restrict a, int n, int n1, int n2)\r{\r__assume_aligned(a, 64);\r__assume((n1 % 16) == 0);\r__assume((n2 % 16) == 0);\rfor (int i = 0; i \u0026lt; n; i++)\r{\rX[i] += a[i] + a[i + n1] + a[i - n1] + a[i + n2] + a[i - n2];\r}\rfor (int i = 0; i \u0026lt; n; i++)\r{\rX2[i] += X[i] * a[i];\r}\r}\r八、总结 本文主要介绍了 SIMD 的基本概念，以及 SIMD 的优化思路，最后通过一些简单的示例代码，介绍了 SIMD 的使用方法。主要内容如下：\n在代码中使用 SSE 和 AVX 指令的硬件和软件要求。 可用的向量数据类型。 有关如何检查自动向量化使用情况的信息，以及有关可自动向量化的循环的提示。 C++中的 SSE/AVX 框架。 掩码和条件加载。 数据流控制。 数据对齐。 SIMD 的优势和劣势：\n优势\n与线性代码相比，潜在的性能提升 300%到 600%。 与在 GPU 级别进行向量化编程的 CUDA 相似。 劣势\n性能取决于运行硬件。 当存在大量数据加载和卸载时，性能不佳。 数据流会变得很难控制，而且向量内每个值的执行时间都会影响整个向量的执行时间。在所有值都满足退出条件之前，不能提前退出。 编码复杂。 缺乏内置函数： 三角函数、随机数、整数除法等。 总的来说，SIMD 的优势远大于劣势，SIMD 的使用可以大大提高程序的性能，但是需要注意的是，SIMD 的使用需要编码复杂，而且需要硬件支持，所以在使用 SIMD 之前，需要对程序进行分析，判断是否有必要使用 SIMD。\n参考资料 [1] Introduction to SIMD instructions\r[2] Agner Fog\u0026rsquo;s instruction tables\r[3] Intel C++编译器的矢量化\r[4] Intel Intrinsics Guide\r[5] x86 内置函数 Cheet Sheet\r[6] libdivide\r[7] Avoiding AVX-SSE Transition Penalties\r[8] Why is this SSE code 6 times slower without VZEROUPPER on Skylake?\r[9] Intel Data Alignment Guide\r","date":"2023-08-12T08:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/173b9c0b3728e5e9e05d12a4f6dda9a2a7560722.jpg@1256w_1776h_!web-article-pic.webp","permalink":"https://cuterwrite.top/p/simd/","title":"SSE 与 AVE 向量化编程"},{"content":"程序调试与优化分析工具 一、概述 在编程中我们通常会遇到如下问题：\n程序运行慢，效率低 消耗了大量的内存 segmentation fault 程序崩溃 程序运行结果不正确\u0026hellip;\u0026hellip; 随着处理器复杂度的增加\n我们不再能够轻松地跟踪代码段的执行 静态/动态分支预测、预取、顺序调度\u0026hellip;\u0026hellip; 仅使用墙钟时间来衡量代码性能是不够的。 我们还需要了解到底发生了什么 对于性能评估，有直接和间接两种方法\n直接方法：需要某些形式的显示插装 追踪 为每个测量事件生成记录 只有在产生大量数据情况下，出现的性能异常数据才有用 聚合 减少数据在运行时平均/最小/最大测量 适用于应用程序和体系结构和描述和优化 间接方法：不需要插装，可不修改应用程序 事实上，直接和间接方法的界限有些模糊 聚合：如 gprof，可以不修改程序，但是需要重新编译链接 实际编程中，常见的分析工具如下：\n类型 工具 程序调试 gdb 程序调试 valgrind 程序优化 gprof 程序优化 perf 程序优化 Intel VTune Amplifier 二、程序调试分析工具简介 程序中的错误按其性质可以分为三种： 编译错误 ：即语法错误，主要是程序代码中有不符合所用编程语言语法规则的错误。 运行时错误 ：如对负数开平方、除数为 0、循环终止条件永远不能达到等。 逻辑错误 ：这类错误往往是编程前对求解的问题理解不正确或算法不正确引起的，它们很难查找（数组越界、空指针） 程序调试就是查找程序中的错误，诊断其准确位置，并予以改正。 1. gdb GDB 是 GNU 开源组织发布的一个强大的 UNIX 下的程序调试工具 GDB 具备如下 4 个方面的功能： 启动程序，可以按用户要求影响程序的运行行为 可以让被调试的程序在用户所指定的断点处暂停（断点可以是条件表达式） 当程序被暂停时，可以检查此时用户程序中所发生的事情 动态改变用户程序的执行环境，这样就可以先纠正一个错误的影响，然后再纠正其他错误 为了发挥 GDB 的全部功能，需要在编译源程序时使用-g 选项 gcc -g test.c -o proc\r启动 GDB，以参数形式将可执行程序传递给 GDB\ngdb program gdb ./proc\rgdb -p pid gdb -p `pidof proc`\rgdb program core gdb ./proc core.xxx\rgdb attach pid gdb attach 2313\r启动 gdb 后就显示其提示符：（gdb），并等待用户输入相应的内部命令\n设置断点、设置运行参数和环境变量、跟踪调试命令、查看栈信息…… 用户可以利用命令 quit 终止其执行，退出 gdb 环境\ngdb 常用命令列表如下：\n命令 解释 简写 file 装入想要调试的可执行文件 无 list 列出产生执行文件源代码的一部分 l next 执行一行源代码但不进入函数内部 n step 执行一行源代码而且进入函数内部 s run 执行当前被调试的程序 r continue 继续执行程序 c quit 终止 GDB q print 输出当前指定变量的值 p break 在代码里设置断点 b info break 查看设置断点的信息 ib delete 删除设置的断点 d watch 监视一个变量的值，一旦值有变化，程序停住 wa help GDB 中的帮助命令 h 设置断点：\n编译源程序时需要使用-g 选项 在 GDB 中用 break 命令（其缩写形式为 b）设置断点： break linenum 在当前文件指定行 linenum 处设置断点，停在该行开头 break linenum if condition 在当前文件指定行 linenum 处设置断点，但仅在条件表达式 condition 成立时才停止程序执行 break function 在当前文件函数 function 的入口处设置断点 break file:linenum 在源文件 file 的 linenum 行上设置断点 break file:function 在源文件 file 的函数 function 的入口处设置断点 break *address 运行程序在指定的内存地址 address 处停止 break 不带任何参数，则表示在下一条指令处停止 断点应设置在可执行的行上，不应是变量定义之类的语句 删除断点：\ndelete [bkptnums] 显示断点：\ninfo breakpoints [num] info break [num] 运行程序：\nrun [args] 程序的单步跟踪和\nstep [N] 参数 N 表示每步执行的语句行数，进入被调用函数内部执行 next [N] 参数 N 表示每步执行的语句行数，被调用函数被当做一条指令执行 stepi（缩写为 si）或 nexti（缩写为 ni）命令一条一条地执行机器指令 程序的连续执行\n利用 continue，c 或 fg 命令连续执行到下一个断点 显示源文件命令 list （l）\nlist：没有参数，显示当前行之后或周围的 10 多行 list -：显示之前的 10 行 list [file]:num：显示源文件 file 中给定行号 num 周围的 10 行。如果缺少 file，则默认为当前文件。例如，list 100 list start, end：显示从行号 start 至 end 之间的代码行。例如，list 20,38 list [file:]fun：显示源文件 file 中指定函数 function 的代码行。如果缺少 file，则默认为当前文件。例如，list meng1.c:square set listsize linenum : 可以使用该命令设置一次显示的行数 查看运行时数据命令 print （p）\n当被调试的程序停止时，可以用 print 命令或同义命令 inspect 来查看当前程序中运行的数据 print 命令的一般使用格式：print [/fmt] exp print i （或 p i） 显示当前变量 i 的值 print i*j (或 p i*j) 将根据程序当前运行的实际情况显示出 i*j 的值 print 所支持的运算符： 取地址\u0026amp;符号 @ 是一个与数组有关的双目运算符，使用形式如 print array@10 打印从 array（数组名，即数组的基地址）开始的 10 个值 print array[3]@5 打印从 array 第三个元素开始的 5 个数组元素的数值 file::i 或 function ::i 表示文件或者函数中 i 的值 GDB 使用示例\n// test.c\r#include \u0026lt;stdio.h\u0026gt;\rint sum(int n);\rint main(int argc, char **argv)\r{\rint i, result = 0;\rfor (i = 1; i \u0026lt;= 50; i++)\r{\rresult += i;\r}\rprintf(\u0026quot;result[1-50]=%d\\n\u0026quot;, result);\rprintf(\u0026quot;result[1-100]=%d\\n\u0026quot;, sum(100));\r}\rint sum(int n)\r{\rint i, sum;\rfor (i = 1; i \u0026lt;= n; i++)\r{\rsum += i;\r}\rreturn sum;\r}\r编译带调试信息的可执行文件 gcc -g test.c -o test\r启动 GDB gdb test\r调试结果 GNU gdb (Ubuntu 9.2-0ubuntu1~20.04.1) 9.2\rCopyright (C) 2020 Free Software Foundation, Inc.\rLicense GPLv3+: GNU GPL version 3 or later \u0026lt;http://gnu.org/licenses/gpl.html\u0026gt;\rThis is free software: you are free to change and redistribute it.\rThere is NO WARRANTY, to the extent permitted by law.\rType \u0026quot;show copying\u0026quot; and \u0026quot;show warranty\u0026quot; for details.\rThis GDB was configured as \u0026quot;x86_64-linux-gnu\u0026quot;.\rType \u0026quot;show configuration\u0026quot; for configuration details.\rFor bug reporting instructions, please see:\r\u0026lt;http://www.gnu.org/software/gdb/bugs/\u0026gt;.\rFind the GDB manual and other documentation resources online at:\r\u0026lt;http://www.gnu.org/software/gdb/documentation/\u0026gt;.\rFor help, type \u0026quot;help\u0026quot;.\rType \u0026quot;apropos word\u0026quot; to search for commands related to \u0026quot;word\u0026quot;...\rReading symbols from test...\r(gdb) list\r1 #include \u0026lt;stdio.h\u0026gt;\r2\r3 int sum(int n);\r4\r5 int main(int argc, char **argv)\r6 {\r7 int i, result = 0;\r8 for (i = 1; i \u0026lt;= 50; i++)\r9 {\r10 result += i;\r(gdb)\r11 }\r12 printf(\u0026quot;result[1-50]=%d\\n\u0026quot;, result);\r13 printf(\u0026quot;result[1-100]=%d\\n\u0026quot;, sum(100));\r14 }\r15\r16 int sum(int n)\r17 {\r18 int i, sum;\r19 for (i = 1; i \u0026lt;= n; i++)\r20 {\r(gdb)\r21 sum += i;\r22 }\r23 return sum;\r24 }\r(gdb) b 8\rBreakpoint 1 at 0x1163: file test.c, line 8.\r(gdb) info b\rNum Type Disp Enb Address What\r1 breakpoint keep y 0x0000000000001163 in main at test.c:8\r(gdb) r\rStarting program: /root/workspace/test\rBreakpoint 1, main (argc=1, argv=0x7fffffffe2d8) at test.c:8\r8 for (i = 1; i \u0026lt;= 50; i++)\r(gdb) p i\r$1 = 0\r(gdb) p result\r$2 = 0\r(gdb) n\r10 result += i;\r(gdb) n\r8 for (i = 1; i \u0026lt;= 50; i++)\r(gdb) p i\r$3 = 1\r(gdb) p result\r$4 = 1\r(gdb) d 1\r(gdb) info b\rNo breakpoints or watchpoints.\r(gdb) c\rContinuing.\rresult[1-50]=1275\rresult[1-100]=26895\r[Inferior 1 (process 286758) exited normally]\r(gdb) q\r总的来说，GDB 调试的过程为： 编译带调试信息的可执行文件 启动 GDB，开始调试 GDB 中查看文件 设置断点 查看断点情况 运行代码 跟踪变量值 删除所设断点 恢复程序运行 退出 GDB 2. Valgrind Valgrind 是一个 Linux 下灵活的调试和剖析工具 收集各种有用的运行时信息，可以帮助找到程序中潜在的 bug 和性能瓶颈 Valgrind 包含多个工具： 工具 功能 Memcheck 这是 valgrind 应用最广泛的工具，一个重量级的内存检查器，能够发现开发中绝大多数内存错误使用情况，比如：使用未初始化的内存、使用已经释放了的内存、内存访问越界等 Callgrind 主要用来检查程序中函数调用过程中出现的问题 Cachegrind 主要用来检查程序中缓存使用出现的问题 Helgrind 主要用来检查多线程程序中出现的竞争问题 Massif 主要用来检查程序中堆栈使用中出现的问题 Extensio 可以利用 core 提供的功能，自己编写特定的内存调试工具 Valgrind 使用需要先进行安装，在 ubuntu 下可以使用 apt-get 进行安装 sudo apt-get install valgrind\r为了使 Valgrind 发现的错误更精确，建议在编译时加上-g 参数，编译优化选择O0，即： gcc -g -O0 test.c -o test\rvalgrind 命令格式为: valgrind [options] prog-and-args [options]\n[options]: 常用选项，适用于所有 Valgrind 工具 \u0026ndash;tool=\u0026lt;name\u0026gt;： 最常用的选项，运行 valgrind 中名为 toolname 的工具，默认 memcheck -h|\u0026ndash;help：显示帮助信息 \u0026ndash;version：显示 valgrind 内核的版本，每个工具都有各自的版本 -q|\u0026ndash;quiet：安静地运行，只打印错误信息 -v|\u0026ndash;verbose：更详细的信息，增加错误数统计 \u0026hellip;\u0026hellip; Memcheck 内存错误检查：\n可以检查出下列几种错误 使用已经释放的内存 内存块越界 使用未初始化的变量 内存泄漏 同一个内存块释放多次 Memcheck 命令行选项： \u0026ndash;leak-check=\u0026lt;no|summary|yes|full\u0026gt; [default: summary] summary 是给出最后 leak 的汇总，yes 或者 full 将会给出比较详细的 leak 信息 \u0026ndash;leak-resolution=\u0026lt;low|med|high\u0026gt; [default: high] 用于合并 leak 信息来源的 backtraces，low 是有两层匹配的时候就可以合并，med 是四层，high 必须完全比配。该选项不影响查找 leak 的能力，只影响结果的显示方式 Cachegrind 缓存检查\n通过模拟 cpu 的 1,3 级缓存，收集应用程序运行时关于 cpu 的一些统计数据，最后在将明细数据和汇总信息打印出来 执行方式： $ valgrind \u0026ndash;tool=cachegrind your_application cachegrind 的结果也会以输出文件的方式输出更多的细节，输出文件的缺省文件名是 cachegrind.out.，其中是当前进程的 pid。该文件名可以通过\u0026ndash;cachegrind-out-file 选择指定更可读的文件名，这个文件将会成为 cg_annotate 的输入 Cachegrind 命令行选项： \u0026ndash;cache-sim=no|yes [yes] 指定是否收集 cache accesses 和 miss counts \u0026ndash;branch-sim=no|yes [no] 指定是否收集 branch instruction 和 misprediction counts Callgrind 函数调用分析\nCallgrind 收集程序运行时的一些数据，建立函数调用关系图，还可以有选择地进行 cache 模拟。被分析的程序编译时要加-g，编译优化选项建议选择-O2 执行方式： $ valgrind \u0026ndash;tool=callgrind your_application 输出文件的缺省文件名是 callgrind.out. ，其中是当前进程的 pid Cachegrind 命令行选项： \u0026ndash;callgrind-out-file= 指定 profile data 的输出文件，而不是缺省命名规则生成的文件 \u0026ndash;dump-line=\u0026lt;no|yes\u0026gt; [default: yes] 事件计数将以 source line 作为统计的粒度，但是源程序在编译的时候加入-g 选项 Helgrind 多线程分析器\n主要用来检查多线程程序中出现的竞争问题 执行方式： $ valgrind \u0026ndash;tool=helgrind your_application Massif 堆栈分析\n堆栈分析器，它能测量程序在堆栈中使用了多少内存，告诉我们堆块，堆管理块和栈的大小。Massif 能帮助我们减少内存的使用 执行方式： $ valgrind \u0026ndash;tool=massif your_application 输出文件：massif..ps massif. .txt，其中是当前进程的 pid Valgrind 使用示例 1：内存检查\n// test.c\r#include \u0026lt;stdlib.h\u0026gt;\rvoid f(void)\r{\rint* x = malloc(10 * sizeof(int));\rx[10] = 0; // 问题 1：数组下标越界\r// 问题 2：内存泄漏，没有 free(x)\r}\rint main(int argc, char** argv)\r{\rf();\rreturn 0;\r}\r编译并运行： gcc -g -O0 test.c -o test\rvalgrind --tool=memcheck --leak-check=full ./test\r输出结果： ==292701== Memcheck, a memory error detector\r==292701== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.\r==292701== Using Valgrind-3.15.0 and LibVEX; rerun with -h for copyright info\r==292701== Command: ./test\r==292701==\r==292701== Invalid write of size 4\r==292701== at 0x10916B: f (test.c:6)\r==292701== by 0x10918B: main (test.c:12)\r==292701== Address 0x4a4b068 is 0 bytes after a block of size 40 alloc'd\r==292701== at 0x483B7F3: malloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so)\r==292701== by 0x10915E: f (test.c:5)\r==292701== by 0x10918B: main (test.c:12)\r==292701==\r==292701==\r==292701== HEAP SUMMARY:\r==292701== in use at exit: 40 bytes in 1 blocks\r==292701== total heap usage: 1 allocs, 0 frees, 40 bytes allocated\r==292701==\r==292701== 40 bytes in 1 blocks are definitely lost in loss record 1 of 1\r==292701== at 0x483B7F3: malloc (in /usr/lib/x86_64-linux-gnu/valgrind/vgpreload_memcheck-amd64-linux.so)\r==292701== by 0x10915E: f (test.c:5)\r==292701== by 0x10918B: main (test.c:12)\r==292701==\r==292701== LEAK SUMMARY:\r==292701== definitely lost: 40 bytes in 1 blocks\r==292701== indirectly lost: 0 bytes in 0 blocks\r==292701== possibly lost: 0 bytes in 0 blocks\r==292701== still reachable: 0 bytes in 0 blocks\r==292701== suppressed: 0 bytes in 0 blocks\r==292701==\r==292701== For lists of detected and suppressed errors, rerun with: -s\r==292701== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0)\r可以看到：valgrind 检测到了两个错误，一个是内存越界，一个是内存泄漏 Invalid write of size 4：提示了内存越界的错误 40 bytes in 1 blocks are definitely lost in loss record 1 of 1：提示了内存泄漏的错误 Valgrind 使用示例 2：Cachegrind 缓存检查\n// test.c\r#include \u0026lt;stdlib.h\u0026gt;\r#include \u0026lt;string.h\u0026gt;\rint main(void)\r{\rchar *arr = malloc(4);\rint *arr2 = malloc(sizeof(int));\rstrcpy(arr, \u0026quot;1234\u0026quot;);\rexit(arr2[0]);\r}\r编译并运行： gcc -g -O0 test.c -o test\rvalgrind --tool=cachegrind ./test\r当前目录下会生成一个 cachegrind.out.文件，其中是当前进程的 pid，使用ls 命令查看： $ ls\rcachegrind.out.293847 test test.c\r使用cg_annnotate 命令查看 cachegrind.out.文件的内容： $ cg_annotate cachegrind.out.293847\r--------------------------------------------------------------------------------\rI1 cache: 32768 B, 64 B, 8-way associative\rD1 cache: 32768 B, 64 B, 8-way associative\rLL cache: 31457280 B, 64 B, 15-way associative\rCommand: ./test\rData file: cachegrind.out.293847\rEvents recorded: Ir I1mr ILmr Dr D1mr DLmr Dw D1mw DLmw\rEvents shown: Ir I1mr ILmr Dr D1mr DLmr Dw D1mw DLmw\rEvent sort order: Ir I1mr ILmr Dr D1mr DLmr Dw D1mw DLmw\rThresholds: 0.1 100 100 100 100 100 100 100 100\rInclude dirs:\rUser annotated:\rAuto-annotation: off\r/* 以下内容省略 */\r可以看到，cachegrind.out.文件中记录了程序运行时的缓存信息，包括 I1 cache，D1 cache，LL cache 等，这些信息可以帮助我们分析程序的缓存使用情况 cachegrind 输出的信息中，我们比较关注的是： Ir: 指令读取次数 I1mr：指令读取 miss 次数 ILmr：指令读取 miss 次数 Dr：数据读取次数 D1mr：数据读取 miss 次数 DLmr：数据读取 miss 次数 Dw：数据写入次数 D1mw：数据写入 miss 次数 DLmw：数据写入 miss 次数 Valgrind 使用示例 3：Callgrind 调用图检查\n// test.c\r#include \u0026lt;stdio.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\rvoid f(void)\r{\rint *x = malloc(10 * sizeof(int));\rx[10] = 0; // 问题 1: 数组下标越界\r} //问题 2: 内存没有释放\rint main(void)\r{\rint i;\rf();\rprintf(\u0026quot;i=%d\\n\u0026quot;, i); // 问题 3：变量没有赋初值\rreturn 0;\r}\r编译并运行： gcc -g -O2 test.c -o test\rvalgrind --tool=callgrind ./test\r当前目录下会生成一个 callgrind.out.文件，其中是当前进程的 pid，使用ls 命令查看： $ ls\rcallgrind.out.295036 test test.c\r使用callgrind_annotate 命令查看 callgrind.out.文件的内容： $ callgrind_annotate callgrind.out.295036\r--------------------------------------------------------------------------------\rProfile data file 'callgrind.out.295036' (creator: callgrind-3.15.0)\r--------------------------------------------------------------------------------\rI1 cache:\rD1 cache:\rLL cache:\rTimerange: Basic block 0 - 43734\rTrigger: Program termination\rProfiled target: ./test (PID 295036, part 1)\rEvents recorded: Ir\rEvents shown: Ir\rEvent sort order: Ir\rThresholds: 99\rInclude dirs:\rUser annotated:\rAuto-annotation: off\r--------------------------------------------------------------------------------\rIr\r--------------------------------------------------------------------------------\r193,311 PROGRAM TOTALS\r--------------------------------------------------------------------------------\rIr file:function\r--------------------------------------------------------------------------------\r71,545 /build/glibc-SzIz7B/glibc-2.31/elf/dl-addr.c:_dl_addr [/usr/lib/x86_64-linux-gnu/libc-2.31.so]\r/* 以下内容省略 */\r可以看到，callgrind.out.文件中记录了程序运行时的调用图信息，包括函数调用次数，函数调用路径等，这些信息可以帮助我们分析程序的调用图使用情况 callgrind 输出的信息中，我们比较关注的是： Ir：指令读取次数 三、程序优化分析工具简介 运行缓慢的代码将消耗大量的 CPU 时间, 因此，我们必需评估代码的运行效率, 在整个代码的设计和实现周期里都需考虑性能。 Amdahl 定律：在一个系统中，如果某部分的执行时间占总执行时间的比例为 p，那么优化这部分的执行时间，系统的整体执行时间至少降低 p 倍。 $$ \\begin{array}{c}T_{new} = T_{old} \\times (1-p) + \\frac{T_{old} \\times p}{k} \\ = T_{old} \\times (1-p + \\frac{p}{k})\\end{array} $$\n根据 Amdahl 定律，对热点部分进行性能优化能够获得最大收益 常见的程序优化分析工具有： gprof perf Vtune \u0026hellip;\u0026hellip; 1. gprof Gprof，又称 GNU profiler，是 Linux/Unix 系统上的性能 profiling 软件，其功能是获得程序各个函数运行时间，帮助找出耗时最多的函数，以及显示函数调用关系，包括调用次数，帮助分析程序运行流程。\n基本原理为：\n编译链接程序时，编译器在程序的每个函数中都加入了一个函数，程序里的每一个函数都会调用该函数, 该函数 会在内存中保存一张函数调用图，并通过函数调用堆栈的形式查找子函数和父函数的地址 调用图也保存了所有与函数相关的调用时间，调用次数等信息 Gprof 需要先使用-pg 编译和链接应用程序\nifort -pg -O3 -o prog prog.f90\r执行应用程序使之生成供 gprof 分析的数据，生成 gmon.out ./prog\r使用 gprof 程序分析应用程序生成的数据 gprof prog gmon.out \u0026gt; gprof.out\rgprof 的输出信息包括： 序号 列名 说明 1 time 函数执行时间占总执行时间的百分比 2 cumulative seconds 函数和上列函数累计执行的时间 3 self seconds 函数本身所执行的时间 4 calls 函数被调用次数 5 self ms/call 每一次调用花费在函数的时间 6 total ms/call 每一次调用，花费在函数及其衍生函数的平均时间 7 name 函数名 gprof 常用的命令选项有： 选项 说明 -b 不再输出统计图表中每个字段的详细描述 -p 只输出函数的调用图 -q 只输出函数的时间消耗列表 -e Name 不再输出函数 Name 及其子函数的调用图 -E Name 不再输出函数 Name 及其子函数的调用图，在总时间和百分比时间计算中排除了由函数 Name 及其子函数所用的时间 -f Name 输出函数 Name 及其子函数的调用图 -F Name 输出函数 Name 及其子函数的调用图，类似于-f，但它在总时间和百分比时间计算中仅使用所打印的例程的时间 对于由多个源文件组成的程序，编译时需要在生成每个.o 文件的时候加上-pg 参数，同时在链接的时候也要加上-pg 参数 -pg 参数只能记录源代码中各个函数的调用关系，而不能记录库函数的调用情况 要想记录每个库函数（如 memcpy、memset、sprintf 等函数）的调用情况，链接的时候必须指定库函数的动态（或者静态）链接库 libc_p.a，即加上-lc_p，而不是-lc $ gcc example1.c –pg -lc_p -o example1 若只有部分代码在编译时指定了-pg 参数，则生成的 gmon.out 文件中将缺少部分函数，也没有这些函数的调用关系，但是并不影响 gprof 对其它函数进行记录 gprof 使用示例\n// test.c\r#include \u0026lt;stdio.h\u0026gt;\rint fast_multiply(int x, int y)\r{\rreturn x * y;\r}\rint slow_multiply(int x, int y)\r{\rint i, j, z;\rfor (i = 0, z = 0; i \u0026lt; x; i++)\rz = z + y;\rreturn z;\r}\rint main(int argc, char *argv[])\r{\rint i, j;\rint x, y;\rfor (i = 0; i \u0026lt; 200; i++)\r{\rfor (j = 0; j \u0026lt; 30; j++)\r{\rx = fast_multiply(i, j);\ry = slow_multiply(i, j);\r}\r}\rprintf(\u0026quot;x=%d, y=%d\\n\u0026quot;, x, y);\rreturn 0;\r}\r编译链接并运行程序 gcc -pg -o test test.c\r./test\r在当前目录下生成 gmon.out 文件，使用 gprof 分析 gprof -b test gmon.out \u0026gt; gprof.out\rgprof.out 文件内容如下 Flat profile:\rEach sample counts as 0.01 seconds.\rno time accumulated\r% cumulative self self total\rtime seconds seconds calls Ts/call Ts/call name\r0.00 0.00 0.00 6000 0.00 0.00 fast_multiply\r0.00 0.00 0.00 6000 0.00 0.00 slow_multiply\rCall graph\rgranularity: each sample hit covers 2 byte(s) no time propagated\rindex % time self children called name\r0.00 0.00 6000/6000 main [8]\r[1] 0.0 0.00 0.00 6000 fast_multiply [1]\r-----------------------------------------------\r0.00 0.00 6000/6000 main [8]\r[2] 0.0 0.00 0.00 6000 slow_multiply [2]\r-----------------------------------------------\rIndex by function name\r[1] fast_multiply [2] slow_multiply\r可以看到：程序中只有两个函数，fast_multiply 和 slow_multiply，gprof 分析结果中也只有这两个函数，但是这两个函数的调用次数都是 6000 次，这是因为 gprof 默认的采样周期是 0.01 秒，而程序运行时间很短，所以两个函数的调用次数都是 6000 次，如果程序运行时间更长，那么两个函数的调用次数就会不一样了。 2. perf Perf 是内置于 Linux 内核源码树中的性能剖析(profiling)工具，基于事件采样原理，以性能事件为基础，支持针对处理器相关性能指标与操作系统相关性能指标的性能剖析，常用于性能瓶颈的查找与热点代码的定位。\nPerf 包含 22 种子工具的工具集，以下是最常用的 5 种：\nperf list：列出当前系统支持的所有性能事件。包括硬件性能事件、软件性能事件以及检查点 perf top：类似于 Linux 的 top 命令，对系统性能进行实时分析 perf stat：剖析某个特定进程的性能概况，包括 CPI、Cache 丢失率等 perf record：收集采样信息，并将其记录在数据文件中 perf report：读取 perf record 创建的数据文件，并给出热点分析结果 perf list\n查看当前软硬件平台支持的性能事件列表 事件分为以下三种： Hardware Event: 由 PMU 硬件产生的事件，比如 cache 命中，当要了解程序对硬件特性的使用情况时，便需要对这些事件进行采样 Software Event: 内核软件产生的事件，比如进程切换、tick 数等 Tracepoint event: 内核中的静态 tracepoint 所触发的事件，这些 tracepoint 用来判断程序运行期间内核的行为细节，比如 slab 分配器的分配次数等 命令格式：perf list [hw | sw | cache | tracepoint] perf list 工具仅列出了具有字符描述的硬件性能事件 perf top\n主要用于实时分析各个函数在某个性能事件上的热度，能够快速的定位热点函数，包括应用程序函数、模块函数与内核函数，甚至能够定位到热点指令，默认的性能事件为 cpu cycles 命令格式： perf top [\u0026lt;options\u0026gt;] 常用命令行参数 -e ：指明要分析的性能事件 -p ：仅分析目标进程及其创建的线程 -k ：带符号表的内核映像所在的路径 -K：不显示属于内核或模块的符号 -U：不显示属于用户态程序的符号 -d ：界面的刷新周期，默认为 2s -G：得到函数的调用关系图 perf stat\n用于分析指定程序的性能概况 命令格式：perf stat [\u0026lt;options\u0026gt;] [\u0026lt;command\u0026gt;] 常用命令行参数 -p ：仅分析目标进程及其创建的线程 -a：从所有 CPU 上收集性能数据 -r ：重复执行命令求平均 -C ：从指定 CPU 上收集性能数据 -v：显示更多性能数据 -n：只显示任务的执行时间 -x ：指定输出列的分隔符 -o ：指定输出文件。\u0026ndash;append 指定追加模式，\u0026ndash;pre 执行目标程序前先执行的程序，\u0026ndash;post 执行目标程序后再执行的程序 perf record\n收集采样信息，并将其记录在数据文件中 随后可以通过其它工具(perf report)对数据文件进行分析，结果类似于 perf top 命令格式：perf record [\u0026lt;options\u0026gt;] [\u0026lt;command\u0026gt;] perf report\n读取 perf record 创建的数据文件，并给出热点分析结果 命令格式：perf report [\u0026lt;options\u0026gt;] [\u0026lt;datafile\u0026gt;] perf 使用示例\napt-get 安装 perf sudo apt-get install linux-tools-common linux-tools-generic linux-tools-`uname -r`\r使用 perf list 查看当前系统支持的性能事件 perf list\rperf list 结果： 使用 perf top 查看当前系统的热点函数 perf top\rperf top 结果： 使用 perf stat 查看测试程序的性能概况\n使用在 gprof 时的程序代码 test.c\n执行 perf stat\nperf stat ./test\rperf stat 结果： 使用 perf record 和 perf report 查看热点函数 perf record ./test\rperf report\rperf report 结果： 进阶：火炬图 FlameGraph：基于 perf record 和 perf report 的结果绘制火炬图\n下载 FlameGraph 工具：\ngit clone https://github.com/brendangregg/FlameGraph.git\r收集性能数据：\nperf record -g ./test\r对可执行文件 test 进行采样，每秒 99 次，采样结果保存在 perf.data 文件中 使用 FlameGraph 生成火炬图：运行以下命令使用 FlameGraph 生成火炬图：\nperf script | ./FlameGraph/stackcollapse-perf.pl \u0026gt; out.perf-folded\r./FlameGraph/flamegraph.pl out.perf-folded \u0026gt; perf.svg\rFlameGrpah 绘制结果：\n3. Vtune Intel VTune Amplifier XE 是 Intel 针对其处理器的性能测试分析工具，支持 Windows/Linux，提供图形用户界面和命令行接口，支持 C、C++、Fortran、C#、Java、.NET 等多种语言。 Vtune 基于硬件性能监视部件(PMU)性能测试，获得微体系结构级数据 指令类型与数目 存储访问事件 指令流水线事件 Vtune 性能分析粒度包括：进程、线程、子程序、代码行 Vtune 可以帮助用户分析算法选择，标识出应用程序怎样更好的利用可用的硬件资源，可以帮助用户如下性能方面问题： 程序中或者整个系统中时间消耗最多的函数 没有有效利用处理器时间的代码片段 优化串行和线程化性能的最好代码片段 影响程序性能的同步对象 程序的 I/O 操作是否花费很多时间，以及在哪里、为什么花费时间 不同的同步方法，不同的线程数量或者不同算法对于性能的影响 线程活跃性和变迁 代码中硬件相关的瓶颈 Vtune 还可以提供寻找热点、分析锁和等待以及标识硬件问题等功能 Vtune 命令格式为： amplxe-cl \u0026lt;-action\u0026gt; [-action-option] [-global-option] [[--] \u0026lt;target\u0026gt; [target-options]]\ramplxe-cl：VTune Amplifier 命令行工具名称\n\u0026lt;-action\u0026gt; ：要执行的操作，如 collect 或 report。每个命令必须只有一个操作。如，一个命令中不能同时有收集数据和生成报表\n[-action-option] ：操作选项，用于修改特定操作的行为。每个操作可以有多个操作选项，操作选项使用不当会导致使用错误\n[-global-option] ：全局选项，用于以相同的方式修改所有操作的行为。每个操作可以有多个全局选项\n[\u0026ndash;] ：要分析的目标程序\n[target-options] ：目标程序参数选项\nActions：amplxe-cl 支持不同的命令选项\ncollect：运行指定的分析类型并将数据收集到结果中 collect-with：运行用户设置的基于事件的硬件采样或用户模式采样，并跟踪收集 command：向正在运行的收集操作发出命令 finalize：执行符号解析以完成或重新获得结果 help： 显示命令行参数的简短解释 import：导入一个或多个收集数据文件/目录 report：从分析结果中生成指定类型的报表 version：显示 amplxe-cl 版本信息 Action Options\n定义适用于指定操作的行为，如“-result-dir”选项是指定收集操作结果的目录路径 若要访问操作的可用操作选项列表，请使用命令“amplxe-cl –help” ，其中 是可用操作之一；要查看所有可用的操作, 请使用命令“amplxe-cl –help” 如果在同一命令行上使用了相反的操作选项，则将应用最后的操作选项 忽略上下文中冗余或没有意义的操作选项 使用不适当的操作选项，会导致意外行为返回使用错误 Global Options\n定义适用于所有操作的行为，如“-quiet”选项会取消所有操作的非必需消息。每个命令可能有一个或多个全局选项 Vtune 使用示例：\n同样使用在 gprof 时的程序代码 test.c，但是需要使用 icc 编译器编译，因为 Vtune 只支持 icc 编译器编译的程序\n安装 icc 编译器：Intel C++ Compiler\r注：icc 编译器是收费的，需要购买或者申请学生许可 安装 Vtune：Intel Vtune\rUbuntu 下 apt 安装 Vtune\nwget -O- https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB \\\r| gpg --dearmor | sudo tee /usr/share/keyrings/oneapi-archive-keyring.gpg \u0026gt; /dev/null\recho \u0026quot;deb [signed-by=/usr/share/keyrings/oneapi-archive-keyring.gpg] https://apt.repos.intel.com/oneapi all main\u0026quot; | sudo tee /etc/apt/sources.list.d/oneAPI.list\rsudo apt update\rsudo apt install intel-oneapi-vtune\r编译程序： icc test.c -o test\r激活 vtune 环境： source /opt/intel/oneapi/vtune/latest/amplxe-vars.sh\r收集 hosspot 数据： ampxel-cl -collect hotspots -result-dir res ./test\r总结 本文介绍了几种常用的程序调试与优化分析工具，这些工具在软件开发过程中发挥着重要的作用。调试工具如 gdb 和 Valgrind 帮助开发人员快速定位和解决程序中的错误和问题，保障了代码的质量和稳定性。而优化分析工具，如 gprof、perf 和 Vtune，则专注于提升程序性能，帮助开发人员找到性能瓶颈并进行优化。\n通过合理使用这些工具，开发人员可以更高效地开发和维护代码，减少调试时间，提高软件性能，并且为用户提供更好的使用体验。在今后的软件开发过程中，了解和掌握这些工具将是提高开发技能和水平的重要一步。同时，不断了解新的调试与优化工具也是跟上技术发展的必要途径。\n参考资料 [1] gdb 官方网站\r[2] valgrind 官方网站\r[3] gprof 官方文档\r[4] perf 文档\r[5] Intel Vtune Profiler\r","date":"2023-08-02T01:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/1c86d46879544786889dcdbaa1cf158f1fb36107.jpg@1256w_1774h_!web-article-pic.webp","permalink":"https://cuterwrite.top/p/debug-and-optimize/","title":"程序调试与优化分析工具"},{"content":"高性能异步 I/O 框架：io_uring 一、 引言 1. Linux 原生 aio 接口 在 Linux 中，有很多方法可以进行基于文件的 I/O。最早的和最基本的就是系统调用 read(2)和 write(2)。后来增加了允许传入偏移量的 pread(2)和 pwrite(2)，以及基于 vector 的 preadv(2)和 pwrite(2)。再后来，Linux 提供了 preadv2(2)和 pwritev2(2)。它们进一步扩展了 API 以允许修饰符标志。抛开这些系统调用的不同点不谈，它们有一个共同的特点：都是同步接口。这意味着当数据准备好读（或写入）时，系统调用才会返回。对于某些场景，这远远不够，因此还需要异步接口。POSIX 提供了 aio_read(3)和 aio_write(3)来满足这种需求，但是它们的实现通常性能不佳。Linux 原生 aio 接口是 Linux 内核中提供的一种异步 I/O 接口，它使用 io_submit(2)、io_getevents(2)等系统调用来提交和获取 I/O 请求，并使用 struct iocb 来描述每个 I/O 请求。它支持 O_DIRECT（或非缓冲）访问的异步 I/O，并且可以使用信号或回调函数来通知 I/O 完成事件。\n然而，Linux 原生 aio 接口存在着许多的限制与不足之处：\n最大的限制是它只能支持 O_DIRECT（或非缓冲）访问的异步 I/O。由于 O_DIRECT 的限制（缓存绕过和大小/对齐限制），这使得原生 aio 接口在大多数情况下都无法使用。对于普遍的缓冲 I/O，接口会以同步方式运行。 即使满足了 I/O 异步的所有约束条件，有时也会出现阻塞。I/O 提交可能会通过多种方式导致阻塞： 如果执行 I/O 时需要元数据，提交就会阻塞，等待元数据。 对于存储设备，有固定数量的请求槽可用。如果这些插槽目前都在使用中，提交就会阻塞，等待有一个插槽可用。 I/O 请求元数据开销大：每次 I/O 提交都需要复制 64 + 8 字节的数据，而每次完成则需要复制 32 字节的数据。这意味着对于所谓的零拷贝 I/O 来说，每次操作都需要复制 104 字节的内存。根据 I/O 的大小不同，这种内存复制的开销可能是明显可见的。而且，暴露的完成事件环缓冲区实际上会妨碍完成操作的速度，并且很难（甚至不可能）从应用程序中正确地使用。这可能意味着使用这个 API 进行 I/O 操作时，完成操作的效率会受到影响。此外，在 Spectre/Meltdown 漏洞修复后，I/O 总是需要至少两个系统调用（提交+等待完成），这会导致严重的性能下降。这可能是因为在修复这些漏洞后，系统对于系统调用的处理变得更加复杂和缓慢。 IOPOLL 支持不好。 随着时间的推移，尽管有一些努力试图解决这些限制，但没有成功。随着具备亚 10 微秒延迟和非常高 IOPS 的设备的出现，这个接口开始显现出其性能缺陷。对于这些类型的设备来说，慢速和非确定性的提交延迟是一个很大的问题，而且单个核心无法提供足够的性能。此外，由于前面提到的限制，可以说原生的 Linux aio 接口用途并不广泛。它被限制在应用程序的一小部分领域中，并且伴随着一些问题。\n2. io_uring 接口 io_uring 是 Linux 内核中的一种新的异步 I/O 接口，旨在提供高效和可扩展的 I/O 操作。它通过使用一对环形队列（提交队列和完成队列）作为应用程序和内核之间的通信通道，实现了零拷贝的 I/O 操作。\nio_uring 的设计目标是在提供高性能的同时解决传统异步 I/O 接口的一些限制和问题。它避免了内存复制和内存方向性，通过共享数据结构和内存来优雅地实现应用程序和内核之间的协调。这种设计使得 io_uring 能够更高效地处理 I/O 请求，并且不需要频繁的系统调用来同步和通信。\n通过 io_uring，应用程序可以作为生产者将 I/O 请求提交到提交队列，而内核作为消费者处理这些请求。一旦请求完成，内核会生成相应的完成事件，并将其放入完成队列中，应用程序可以从完成队列中消费这些事件。这种异步的方式使得应用程序能够更好地利用系统资源，提高 I/O 操作的效率和性能。\nio_uring 的优势主要在于：\n使用方便：简单且强大的系统调用，提供三个系统调用，liburing 用户态库编程友好 (io_uring_setup, io_uring_enter, io_uring_register)。 通用性强：提供内核统一的异步编程框架，既支持传统 I/O (Buffer I/O + Direct I/O)，也支持类 epoll 型编程。 特性丰富：支持非常多的高级特性。 高性能：I/O 请求 overhead 小。 3. liburing 库 liburing 是一个基于 io_uring 接口的用户空间库，它是 Linux 内核开发者 Axboe 于 2019 年发布的一个开源项目。io_uring 是一种新的 Linux 异步 I/O 接口，它通过使用一对环形缓冲区（ring buffer）来实现用户空间和内核空间之间的通信，从而避免了传统异步 I/O 接口（如 AIO）所需的系统调用、信号、回调等机制。这样，用户空间可以直接向内核提交 I/O 请求，并从内核获取 I/O 结果，而无需等待或切换上下文。这大大提高了异步 I/O 操作的效率和性能。\nliburing 是对 io_uring 接口的封装和扩展，它提供了一套简洁和灵活的 API，让开发者可以方便地使用 io_uring 的功能，而无需关心底层的细节和复杂性。liburing 主要包括以下几个组件：\nliburing.h：定义了 liburing 库的主要数据结构和函数 liburing.a：提供了 liburing 库的静态链接版本 liburing.so：提供了 liburing 库的动态链接版本 liburing/io_uring.h：定义了 io_uring 接口相关的数据结构和常量 liburing/compat.h：提供了一些兼容性相关的宏定义 二、io_uring 的核心数据结构与原理 1. io_uring 的核心数据结构 每个 io_uring 实例都有两个环形队列(称为 ring)，在内核和应用程序之间共享： 提交队列：submission queue( SQ ) 完成队列：completion queue( CQ ) 这两个队列： 都是单生产者、单消费者的队列，size 为 2 的幂次方。 提供无锁接口，内部使用内存屏障来进行同步。 请求时： 应用创建 SQ Entries (SQE)，更新 SQ tail 内核消费 SQE，更新 SQ head 完成后： 内核为完成的一个或多个请求创建 CQ Entries (CQE)，更新 CQ tail 应用消费 CQE，更新 CQ head 完成事件可能以任意顺序到达，到总是与特定的 SQE 相关联的 消费 CQE 过程无需切换内核态 这样做的好处在于： 原本需要多次系统调用，现在变成批处理一次提交 此外，io_uring 使异步 I/O 的使用场景也不再仅限于数据库应用， 普通的非数据库应用也能用 2. io_uring 的三种工作模式： 中断驱动模式 (interrupt-driven) 默认模式, 可通过 io_uring_enter()提交 I/O 请求，然后直接检查 CQ 状态判断是否完成。 轮询模式 (polling) Busy waiting for I/O completion，而不是通过异步 IRQ(Interrupt Request)来接收通知 这种模式需要文件系统和块设备支持轮询功能。相比中断驱动模式，这种方式延迟更低，但是 CPU 占用率可能会更高。 目前，只有指定了 O_DIRECT 标志打开的文件描述符才能使用这种模式。当一个读或写请求提交给轮询上下文之后，应用必须调用 io_uring_enter()来轮询 CQ 队列，判断请求是否完成。 对于一个 io_uring 实例来说，不支持混合使用轮询和非轮询模式。 内核轮询模式 (kernel polling) 这种模式会创建一个内核线程来执行 SQ 的轮询工作。 使用这种模式的 io_uring 实例，应用无需切到内核态就能触发 I/O 操作。通过 SQ 来提交 SQE，以及监控 CQ 的完成状态，应用无需任何系统调用，就能提交和收割 I/O。 如果内核线程的空闲事件超过了用户的配置值，它会通知应用，然后进入 idle 状态。这种情况下，应用必须调用 io_uring_enter()来唤醒内核线程。如果 I/O 一直很繁忙，内核线程是不会 sleep 的。 3. io_uring 的系统调用 API io_uring 的系统调用 API 有三个，分别是：\nio_uring_setup(2) io_uring_register(2) io_uring_enter(2) 首先是 io_uring_setup(2)：\nint io_uring_setup(unsigned entries, struct io_uring_params *p);\r用于创建一个 io_uring 实例，返回一个文件描述符，用于后续的 io_uring 系统调用。 参数： entries：SQ 和 CQ 的大小，必须是 2 的幂次方 params：io_uring 的参数，包括 flags、sq_thread_cpu 等 返回值： 成功：返回一个文件描述符 失败：返回-1，并设置 errno 创建一个 SQ 和一个 CQ，它们的大小都是 entries。如果 entries 是 0，那么 SQ 和 CQ 的大小都是默认值(4096)。SQ 和 CQ 在应用和内核之间共享，避免了在初始化和完成 I/O 时拷贝数据 io_uring_register(2)：\nint io_uring_register(int fd, unsigned int opcode, const void *arg, unsigned int nr_args);\r注册用于异步 I/O 的文件或用户缓冲区，使内核能长时间持有对该文件在内核内部的数据结构引用，或创建应用内存的长期映射，这个操作只会在注册时执行一次，而不是每个 I/O 操作都会处理，因此减少了 per-I/O 的 overhead 开销。 参数： fd：文件描述符 opcode：操作码，用于指定注册的类型，如 IORING_REGISTER_BUFFERS、IORING_REGISTER_FILES 等 arg：指向一个数组，数组中的每个元素都是一个指向用户缓冲区或文件描述符的指针 nr_args：arg 数组的大小 返回值： 成功：返回 0 失败：返回-1，并设置 errno 注册的缓冲区将会被锁定到内存中，并计入用户的 RLIMIT_MEMLOCK 限制。如果注册的是文件描述符，那么内核会增加对该文件的引用计数，直到应用调用 io_uring_unregister(2)来注销它。 每个缓冲区有 1GB 的大小限制。 缓冲区必须是匿名的、非文件后端的内存，例如 malloc(3)或带 MAP_ANONYMOUS 标识的 mmap(2)返回的内存。 Huge pages 也是支持的。整个 Huge page 都会被 pin 到内核，即使只使用其中一部分。 已经注册的缓冲区无法调整大小，想调整只能先 unregister，再重新注册。 io_uring_enter(2):\nint io_uring_enter(unsigned int fd, unsigned int to_submit, unsigned int min_complete, unsigned int flags, sigset_t *sig);\r这个系统调用用于初始化和完成（initiate and complete）I/O，使用共享的 SQ 和 CQ。单次调用同时执行： 提交新的 I/O 请求 等待 I/O 完成 参数： fd：io_uring 实例的文件描述符 to_submit：SQ 中提交的 I/O 请求数量 min_complete：最少完成的 I/O 请求数量 flags：用于指定 I/O 请求的类型，如 IORING_ENTER_GETEVENTS、IORING_ENTER_SQ_WAKEUP 等 sig：用于指定信号集，如果 flags 指定了 IORING_ENTER_GETEVENTS，那么 sig 必须是一个有效的信号集 在默认模式下，如果指定了 min_complete，那么 io_uring_enter(2)会等待至少 min_complete 个 I/O 请求完成，然后返回。如果没有指定 min_complete，那么 io_uring_enter(2)会等待 SQ 中所有的 I/O 请求完成，然后返回。在 polling 模式下，如果指定了 min_complete，如果 min_complete 为 0，则要求内核返回当前以及完成的所有 events，无阻塞；如果 min_complete 大于 0，如果有事件完成，内核仍然立即返回；如果没有完成事件，内核会 poll，等待指定的次数完成，或者这个进程的时间片用完。 4. io_uring 的高级特性 io_uring 还提供了一些用于特殊场景的高级特性 File registration(文件注册)：每次发起一个指定文件描述的操作，内核都需要花费一些时钟周期(cycles)文件描述符映射到内部表示。对于那些 针对同一文件进行重复操作 的场景，io_uring 支持提前注册这些文件，后面直接查找就行了。 Buffer registration(缓冲区注册)：与 file registration 类似，Direct I/O 场景中，内核需要 map/unmap memory areas。io_uring 支持提前注册这些缓冲区（buffers）。 Poll ring(轮询环形缓冲区)：对于非常快是设备，处理中断的开销是比较大的。io_uring 允许用户关闭中断，使用轮询模式。 Linked operations(链接操作)：允许用户发送串联的请求。这两个请求同时提交，但后面的会等前面的处理完才开始执行。 三、io_uring 的使用示例 liburing 提供了一个简单的高层 API， 可用于一些基本场景，应用程序避免了直接使用更底层的系统调用。此外，这个 API 还避免了一些重复操作的代码，如设置 io_uring 实例。\n1. 在项目中引入 liburing apt-get 安装 liburing 在 ubuntu 系统下安装 liburing 十分简单，只需要执行以下命令即可 （注意：ubuntu 版本需要大于等于 20.04，因为内核版本需要大于等于 5.4） sudo apt-get install liburing-dev\r在项目中引入 liburing 的头文件 #include \u0026quot;liburing.h\u0026quot;\r在项目中引入 liburing 的库文件 -luring\r手动安装 下载 liburing 的源码 git clone https://github.com/axboe/liburing.git\r编译 liburing cd liburing\r./configure\rmake -j\rsudo make install\r在项目中引入 liburing 的头文件 #include \u0026quot;liburing.h\u0026quot;\r在项目中引入 liburing 的库文件 -luring\r2. 代码示例 使用 4 个 SQE，从输入文件中读取最多 16KB 的数据。 #include \u0026quot;liburing.h\u0026quot;\r#include \u0026lt;stdio.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\r#include \u0026lt;string.h\u0026gt;\r#include \u0026lt;sys/stat.h\u0026gt;\r#include \u0026lt;sys/types.h\u0026gt;\r#include \u0026lt;fcntl.h\u0026gt;\r#include \u0026lt;unistd.h\u0026gt;\r#include \u0026lt;errno.h\u0026gt;\r// io_uring 队列长度\r#define QUEUE_DEPTH 4\rint main(int argc, char** argv)\r{\rint fd, pending, done;\rvoid* buf;\r// 1. 初始化一个 io_uring 实例\rstruct io_uring ring;\r// 创建一个 io_uring 实例，队列长度为 QUEUE_DEPTH，flags 为 0，使用默认模式\rint ret = io_uring_queue_init(QUEUE_DEPTH, \u0026amp;ring, 0);\rif (ret)\r{\rfprintf(stderr, \u0026quot;io_uring_queue_init: %s\\n\u0026quot;, strerror(-ret));\rreturn 1;\r}\r// 2. 打开输入文件，指定 O_DIRECT 标志\rfd = open(argv[1], O_RDONLY | O_DIRECT);\rstruct stat st;\rfstat(fd, \u0026amp;st);\r// 3. 初始化 4 个读缓冲区\rsize_t filesize = 0;\rstruct iovec *iovecs = calloc(QUEUE_DEPTH, sizeof(struct iovec));\rfor (int i = 0; i \u0026lt; QUEUE_DEPTH; i++)\r{\rif (posix_memalign(\u0026amp;buf, 4096, 4096))\r{\rperror(\u0026quot;posix_memalign\u0026quot;);\rreturn 1;\r}\riovecs[i].iov_base = buf;\riovecs[i].iov_len = 4096;\rfilesize += 4096;\r}\r// 4. 依次准备 4 个读请求，指定将随后读入的数据写入 iovecs 中\rstruct io_uring_sqe *sqe;\rsize_t offset = 0;\rint i = 0;\rdo\r{\rsqe = io_uring_get_sqe(\u0026amp;ring);\rio_uring_prep_readv(sqe, fd, \u0026amp;iovecs[i], 1, offset);\roffset += iovecs[i].iov_len;\ri++;\r// 如果超出文件大小，停止准备后面的 SQE\rif (offset \u0026gt;= st.st_size)\r{\rbreak;\r}\r} while (1);\r// 5. 提交 SQE 读请求\rret = io_uring_submit(\u0026amp;ring);\rif (ret \u0026lt; 0)\r{\rfprintf(stderr, \u0026quot;io_uring_submit: %s\\n\u0026quot;, strerror(-ret));\rreturn 1;\r} else if (ret != i) {\rfprintf(stderr, \u0026quot;io_uring_submit submitted less %d\\n\u0026quot;, ret);\rreturn 1;\r}\r// 6. 等待读请求完成\rstruct io_uring_cqe *cqe;\rdone = 0;\rpending = ret;\rfilesize = 0;\rfor (int i = 0; i \u0026lt; pending; i++) {\r// 等待一个读完成事件\rio_uring_wait_cqe(\u0026amp;ring, \u0026amp;cqe);\rdone++;\rif (cqe-\u0026gt;res != 4096 \u0026amp;\u0026amp; cqe-\u0026gt;res + filesize != st.st_size) {\rfprintf(stderr, \u0026quot;cqe-\u0026gt;res: %d\\n\u0026quot;, cqe-\u0026gt;res);\rreturn 1;\r}\rfilesize += cqe-\u0026gt;res;\r// 更新完成队列\rio_uring_cqe_seen(\u0026amp;ring, cqe);\r}\r// 7. 打印统计信息\rprintf(\u0026quot;Submitted = %d, completed = %d, bytes = %lu\\n\u0026quot;, pending, done, (unsigned long)filesize);\r// 8. 销毁资源\rclose(fd);\rio_uring_queue_exit(\u0026amp;ring);\rreturn 0;\r}\rlink-cp：使用 io_uring 高级特性 SQE chaining 实现复制文件功能，将创建一个长度为 2 的 SQE 链，第一个 SQE 用于读，第二个 SQE 用于写。 #include \u0026lt;assert.h\u0026gt;\r#include \u0026lt;errno.h\u0026gt;\r#include \u0026lt;fcntl.h\u0026gt;\r#include \u0026lt;inttypes.h\u0026gt;\r#include \u0026lt;stdio.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\r#include \u0026lt;string.h\u0026gt;\r#include \u0026lt;sys/ioctl.h\u0026gt;\r#include \u0026lt;sys/stat.h\u0026gt;\r#include \u0026lt;sys/types.h\u0026gt;\r#include \u0026lt;unistd.h\u0026gt;\r#include \u0026quot;liburing.h\u0026quot;\r#define QD 64\r#define BS (32 * 1024)\rstruct io_data\r{\rsize_t offset;\rint index;\rstruct iovec iov;\r};\rstatic int infd, outfd;\rstatic int inflight;\rstatic int setup_context(unsigned entries, struct io_uring *ring)\r{\rint ret;\rret = io_uring_queue_init(entries, ring, 0);\rif (ret \u0026lt; 0)\r{\rfprintf(stderr, \u0026quot;queue_init: %s\\n\u0026quot;, strerror(-ret));\rreturn -1;\r}\rreturn 0;\r}\rstatic int get_file_size(int fd, off_t *size)\r{\rstruct stat st;\rif (fstat(fd, \u0026amp;st) \u0026lt; 0)\rreturn -1;\rif (S_ISREG(st.st_mode))\r{\r*size = st.st_size;\rreturn 0;\r}\relse if (S_ISBLK(st.st_mode))\r{\runsigned long long bytes;\rif (ioctl(fd, BLKGETSIZE64, \u0026amp;bytes) != 0)\rreturn -1;\r*size = bytes;\rreturn 0;\r}\rreturn -1;\r}\rstatic void queue_rw_pair(struct io_uring *ring, off_t size, off_t offset)\r{\rstruct io_uring_sqe *sqe;\rstruct io_data *data;\rvoid *ptr;\rptr = malloc(size + sizeof(*data));\rdata = ptr + size;\rdata-\u0026gt;index = 0;\rdata-\u0026gt;offset = offset;\rdata-\u0026gt;iov.iov_base = ptr;\rdata-\u0026gt;iov.iov_len = size;\rsqe = io_uring_get_sqe(ring);\rio_uring_prep_readv(sqe, infd, \u0026amp;data-\u0026gt;iov, 1, offset);\rsqe-\u0026gt;flags |= IOSQE_IO_LINK;\rio_uring_sqe_set_data(sqe, data);\rsqe = io_uring_get_sqe(ring);\rio_uring_prep_writev(sqe, outfd, \u0026amp;data-\u0026gt;iov, 1, offset);\rio_uring_sqe_set_data(sqe, data);\r}\rstatic int handle_cqe(struct io_uring *ring, struct io_uring_cqe *cqe)\r{\rstruct io_data *data = io_uring_cqe_get_data(cqe);\rint ret = 0;\rdata-\u0026gt;index++;\rif (cqe-\u0026gt;res \u0026lt; 0)\r{\rif (cqe-\u0026gt;res == -ECANCELED)\r{\rqueue_rw_pair(ring, data-\u0026gt;iov.iov_len, data-\u0026gt;offset);\rinflight += 2;\r}\relse\r{\rprintf(\u0026quot;cqe error: %s\\n\u0026quot;, strerror(-cqe-\u0026gt;res));\rret = 1;\r}\r}\rif (data-\u0026gt;index == 2)\r{\rvoid *ptr = (void *)data - data-\u0026gt;iov.iov_len;\rfree(ptr);\r}\rio_uring_cqe_seen(ring, cqe);\rreturn ret;\r}\rstatic int copy_file(struct io_uring *ring, off_t insize)\r{\rstruct io_uring_cqe *cqe;\roff_t this_size;\roff_t offset;\roffset = 0;\rwhile (insize)\r{\rint has_inflight = inflight;\rint depth;\rwhile (insize \u0026amp;\u0026amp; inflight \u0026lt; QD)\r{\rthis_size = BS;\rif (this_size \u0026gt; insize)\rthis_size = insize;\rqueue_rw_pair(ring, this_size, offset);\roffset += this_size;\rinsize -= this_size;\rinflight += 2;\r}\rif (has_inflight != inflight)\rio_uring_submit(ring);\rif (insize)\rdepth = QD;\relse\rdepth = 1;\rwhile (inflight \u0026gt;= depth)\r{\rint ret;\rret = io_uring_wait_cqe(ring, \u0026amp;cqe);\rif (ret \u0026lt; 0)\r{\rprintf(\u0026quot;wait cqe: %s\\n\u0026quot;, strerror(-ret));\rreturn 1;\r}\rif (handle_cqe(ring, cqe))\rreturn 1;\rinflight--;\r}\r}\rreturn 0;\r}\rint main(int argc, char *argv[])\r{\rstruct io_uring ring;\roff_t insize;\rint ret;\rif (argc \u0026lt; 3)\r{\rprintf(\u0026quot;%s: infile outfile\\n\u0026quot;, argv[0]);\rreturn 1;\r}\rinfd = open(argv[1], O_RDONLY);\rif (infd \u0026lt; 0)\r{\rperror(\u0026quot;open infile\u0026quot;);\rreturn 1;\r}\routfd = open(argv[2], O_WRONLY | O_CREAT | O_TRUNC, 0644);\rif (outfd \u0026lt; 0)\r{\rperror(\u0026quot;open outfile\u0026quot;);\rreturn 1;\r}\rif (setup_context(QD, \u0026amp;ring))\rreturn 1;\rif (get_file_size(infd, \u0026amp;insize))\rreturn 1;\rret = copy_file(\u0026amp;ring, insize);\rclose(infd);\rclose(outfd);\rio_uring_queue_exit(\u0026amp;ring);\rreturn ret;\r}\rcopy_file()：高层复制循环逻辑；它会调用 queue_rw_pair(ring, this_size, offset) 来构造 SQE pair；并通过一次 io_uring_submit() 调用将所有构建的 SQE pair 提交。 这个函数维护了一个最大 DQ 数量的 inflight SQE，只要数据 copy 还在进行中；否则，即数据已经全部读取完成，就开始等待和收割所有的 CQE。 queue_rw_pair() 构造一个 read-write SQE pair. read SQE 的 IOSQE_IO_LINK flag 表示开始一个 chain，write SQE 不用设置这个 flag，标志着这个 chain 的结束。用户 data 字段设置为同一个 data 描述符，并且在随后的 completion 处理中会用到。 handle_cqe() 从 CQE 中提取之前由 queue_rw_pair() 保存的 data 描述符，并在描述符中记录处理进展（index）。 如果之前请求被取消，它还会重新提交 read-write pair。 一个 CQE pair 的两个 member 都处理完成之后（index==2），释放共享的 data descriptor。最后通知内核这个 CQE 已经被消费。 3. 最佳实践 io_uring 是一个高性能的异步 I/O 框架，它在 Linux 内核中引入了一种新的 I/O 模型，可以显著提高 I/O 操作的吞吐量和响应速度。然而，要充分发挥 io_uring 的优势，需要注意一些优化和最佳实践。\n优化 说明 批量提交（Batch Submission） io_uring 支持批量提交多个 I/O 请求，以减少系统调用的开销。通过一次性提交多个请求，可以减少上下文切换和系统调用的次数，提高效率。建议根据系统的负载和性能需求，合理选择批量提交的数量。 预分配 I/O 请求（Pre-allocate I/O Requests） 在使用 io_uring 之前，可以预先分配一定数量的 I/O 请求，避免在运行时动态分配请求的开销。这样可以减少内存分配和释放的次数，提高性能。 使用 I/O 链接（I/O Linking） io_uring 支持将多个 I/O 请求链接在一起，形成一个链表。这样可以减少上下文切换的开销，提高效率。在链接 I/O 请求时，需要注意保持请求的顺序和正确处理链接的完成。 使用 I/O 向量（I/O Vector） io_uring 支持使用 I/O 向量来进行批量的读写操作。通过使用 I/O 向量，可以减少系统调用的次数，提高效率。在使用 I/O 向量时，需要注意正确设置每个向量的偏移量和长度。 使用事件完成通知（Event Completion Notification） io_uring 支持使用事件完成通知来提高效率。通过使用事件完成通知，可以避免轮询等待 I/O 完成，而是在 I/O 完成时立即得到通知。这样可以减少 CPU 的占用和响应时间。 合理设置 I/O 队列深度（I/O Queue Depth） io_uring 的性能受到 I/O 队列深度的影响。较大的队列深度可以提高并发性能，但也会增加内存开销。建议根据系统的负载和性能需求，合理设置 I/O 队列深度。 使用合适的内存分配策略 io_uring 的性能也受到内存分配策略的影响。建议使用高效的内存分配器，如 jemalloc 或 tcmalloc，来减少内存分配和释放的开销。 避免阻塞操作 io_uring 是一个异步 I/O 框架，应尽量避免在 io_uring 的上下文中进行阻塞操作。阻塞操作会导致 io_uring 的性能下降，甚至可能引起死锁。 使用合适的文件描述符（File Descriptor） io_uring 支持对文件、套接字和管道等不同类型的文件描述符进行操作。在使用 io_uring 时，需要根据实际情况选择合适的文件描述符类型，并正确设置相关的参数。 注意错误处理 在使用 io_uring 时，需要注意正确处理错误。io_uring 的错误码可能是负数，可以使用 errno.h 中定义的错误码来进行解析和处理。 通过遵循上述优化和最佳实践，可以充分发挥 io_uring 的性能优势，提高系统的 I/O 性能和响应速度。然而，需要根据具体的应用场景和需求，进行合理的调优和配置。在实际使用中，可以通过性能测试和监测来评估和优化 io_uring 的性能。\n结论 io_uring 是一个高性能的异步 I/O 框架，通过在 Linux 内核中引入新的 I/O 模型，它能够显著提高 I/O 操作的吞吐量和响应速度。本章节我们深入探讨了 io_uring 的优化和最佳实践，以帮助开发者充分发挥其性能优势。\n在使用 io_uring 时，我们可以采取一系列优化措施来提高性能。首先，批量提交多个 I/O 请求可以减少系统调用的开销，提高效率。此外，预分配 I/O 请求、使用 I/O 链接和 I/O 向量等技术也能够减少内存分配和系统调用的次数，进一步提升性能。\n除了以上的优化技巧，我们还介绍了一些最佳实践。合理设置 I/O 队列深度、使用事件完成通知和选择合适的文件描述符类型等都能够对性能产生积极影响。此外，避免阻塞操作和正确处理错误也是使用 io_uring 时需要注意的事项。\n通过遵循这些优化和最佳实践，开发者可以充分发挥 io_uring 的性能优势，提高系统的 I/O 性能和响应速度。然而，需要根据具体的应用场景和需求，进行合理的调优和配置。在实际使用中，可以通过性能测试和监测来评估和优化 io_uring 的性能。\nio_uring 作为一个新兴的异步 I/O 框架，具有很大的潜力和广阔的应用前景。它已经在许多领域得到了广泛的应用，如数据库、网络服务器和存储系统等。随着对 io_uring 的进一步研究和优化，相信它将在未来发挥更大的作用，并成为开发者们的首选工具之一。\n参考文献 [1] io_uring 官方文档：https://kernel.dk/io_uring.pdf\r[2] How io_uring and eBPF Will Revolutionize Programming in Linux[1], ScyllaDB\n[3] 2020 An Introduction to the io_uring Asynchronous I/O Framework[2], Oracle, 2020\n[4] liburing GitHub 仓库：https://github.com/axboe/liburing\r","date":"2023-08-01T01:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/20230801145236.webp","permalink":"https://cuterwrite.top/p/efficient-liburing/","title":"高性能异步 I/O 框架：io_uring"},{"content":"RDMA 技术及其编程方法（二）：编程指导 一、libibverbs 简介 libibverbs 由 Roland Dreier 自 2006 年开始开发和维护，实际上是*nix 中的 Verbs API 标准 开源 Verbs 的核心部分自 2005 年起集成到 Linux 内核中\u0026ndash;内核 2.6.11 Inbox in several *nix distributions 目前有多个硬件供应商提供的级别较低的库 对所有启用 RDMA 的传输协议使用相同的 API InfiniBand： 支持 RDMA 的网络体系结构 需要支持它的网卡和 InfiniBand 交换机。 RoCE：基于以太网/IP 帧的 RDMA 数据包封装 需要支持它的网卡和标准以太网交换机 iWARP：提供基于流控制传输协议(SCTP)和传输控制协议(TCP)的 RDMA 需要支持它的网卡和标准以太网交换机 libibverbs 是完全线程安全的 libibverbs 本身是线程安全的 用户态空间低级驱动程序库也是线程安全的 应用程序可以在多线程中使用 RDMA 资源 销毁一个线程中的资源并在另一个线程中使用它将导致 segmentation fault，这个问题在非多线程代码中也会发生\n使用 libibverbs 的基本须知 tips 说明 头文件引入 #include\u0026lt;infiniband/verbs.h\u0026gt; 编译时链接 -libverbs 所有的 input structures 需要为 zeroed 使用 memset()或结构初始化、如果该 structure 有扩充的需求，则零值将保留遗留行为 大多数资源句柄都是指针，因此使用错误的句柄可能会导致分段错误 使用 NULL 检查句柄 返回指针的 Verbs 成功时返回有效值，失败时返回 NULL 检查返回值 返回整形变量的 Verbs 如果成功则返回零，如果成功则返回-1 或 errno 检查返回值 二、Verbs API 详解 1. 简介 在内核和用户态空间均可使用 Verbs 中的类 资源管理：Qps、CQs、SRQs 等等 WR 处理：post send, 轮询 CQ 等等 内存注册 地址句柄 Verbs 中的操作 Device 操作 上下文操作 PD 操作 QP bringup 活跃 QP 操作 2. Verbs 对象创建层次 获取 devide 列表 打开请求的 device 查询 device 功能 分配 PD 内存空间 注册内存域 MR 关联并创建完成队列 CQ 创建 QP Bring up a QP Post WR 并且轮询 CQ 清理资源 3. 两个动态库 libibverbs.so 用于直接通过用户态空间访问 InfiniBand 硬件的库 Infiniband(根据 Infiniband 规范)和 iWarp(iWARP 动词规范)的 RDMA Verbs 的实现 它处理创建、修改、查询和销毁资源的控制路径，如保护域(PD)、完成队列(CQ)、队列对(QP)、共享接收队列(SRQ)、地址句柄(AH)、内存区域(MR) 它还处理发送和接收发布到 QPS 和 SRQ 的数据，使用轮询和完成事件从 CQs 获取完成 librdmacm.so 用户态空间的 RDMA 连接管理器 使用 Socket 语义的 RDMA(InfiniBand、ROCE 和 iWARP)通信管理库 三、Connection Manager 1. 连接的建立 基于 Infiniband 通信管理(CM)协议（在通用服务接口(GSI)上定义的协议 QP：QP1）\n提供以下服务\n在对等 RC 和 QP 之间交换必要的参数，使它们为通信做好准备 初始化器请求连接到远程上的服务 ID（服务 ID 映射） 类 TCP 握手：请求/响应/即用消息 查找给定服务 ID 的远程 UD 和 QP 序号 服务 ID 请求/响应消息 加载备用路径 连接管理器（Connection Manager，CM）是一个用户态空间的库，它提供了一个通用的接口，用于在 RDMA 网络中建立连接。它可以用于建立连接，也可以用于查找远程 QP 的地址，以便在不建立连接的情况下发送数据。\n需要在对等 QP 之间交换信息 负责 RC、UC、RD 连接的建立 应用程序使用 SA 来获取其他信息(例如路径记录) SIDR 用于 UD 2. CM 的抽象类型（RDMACM） 类似于 Socket 连接模式的语义 对 IB 和 ROCE 都使用基于 IP 的寻址模式 类 说明 rdma_create/destroy_id creates/destroys a connection identifier (equivalent to a socket) rdma_create/destroy_qp allocate/destroy a qp for communication rdma_bind_addr set local port to listen on rdma_resolve_addr obtain local RDMA device to reach remote address rdma_resolve_route determine route to remote address rdma_get_src_port query local port rdma_get_local_addr query local ip rdma_get_peer_addr query remote ip rdma_connect/disconnect connect/disconnect rc qps, or resolve service id to qp for ud qps rdma_listen listen for incoming connections rdma_accept/reject accept/reject incoming connection requests rdma_create/destroy_event_channel allocate/destroy an event channel rdma_get_cm_event get next event rdma_ack_cm_event acknowledge event(s) to rdmacm rdma_join/leave_multicast join/leave multicast addresses 使用 rdmacm 的基本须知 tips 说明 头文件引入 #include\u0026lt;rdma/rdma_cma.h\u0026gt; 编译时链接 -lrdmacm 四、 RDMACM 程序解析——被动方 流程如下：\n创建事件 channel，以便我们可以接收 rdmacm 事件，如连接请求和连接建立通知。 创建连接 ID 并绑定到地址。 创建 Listener 并返回端口/地址。 等待连接请求 创建 PD、CQ 和 Send-Receive QP 接受连接请求 等待建立连接 视情况发布操作 1. 创建事件 channel 打开用于报告通信事件的 channel。异步事件将通过事件 channel 报告给用户，对应方法为struct rdma_event_channel * rdma_create_event_channel(void)。 事件 channel 用于定向 rdma_cm_id 上的所有事件。对于许多客户端来说，单个事件 channel 可能就足够了，然而，当管理大量的连接或 cm_id 时，用户可能会发现将不同 cm_id 的事件定向到不同的 channel 进行处理是有用的。 必须通过调用rdma_destroy_event_channel 销毁所有创建的事件 channel。用户应该调用rdma_get_cm_event 来检索事件 channel 上的事件。 struct rdma_event_channel *channel = rdma_create_event_channel();\rif (!channel) {\rperror(\u0026quot;rdma_create_event_channel\u0026quot;);\rreturn -1;\r}\rstruct rdma_cm_event* event;\r// 此处会阻塞，直到有事件发生\rint err = rdma_get_cm_event(channel, \u0026amp;event);\rif (err) {\rperror(\u0026quot;rdma_get_cm_event\u0026quot;);\rreturn err;\r}\r// 中间处理代码...\rrdma_destroy_event_channel(channel);\r每个事件 channel 都映射到一个文件描述符。可以像使用和操作任何其他 FD 一样使用和操作关联的文件描述符，以更改其行为。 2. 创建连接 ID 创建用于跟踪通信信息的标识符，对应方法为int rdma_create_id(struct rdma_event_channel *channel, struct rdma_cm_id **id, void *context, enum rdma_port_space ps)。 输入参数： channel：事件 channel id：指向 rdma_cm_id 指针的指针，用于返回新创建的 rdma_cm_id context：用户上下文，将在事件中返回给用户 ps：RDMA 端口空间，指定要使用的端口空间 rdma_cm_id 在概念上等同于用于 RDMA 通信的套接字。不同之处在于，RDMA 通信需要显式绑定到指定的 RDMA 设备，然后才能进行通信，并且大多数操作本质上是异步的。 端口空间 RDMA_PS_TCP：提供可靠、面向连接的 QP 通信。与 TCP 不同，RDMA 端口空间提供基于消息的通信，而不是基于流的通信。 RDMA_PS_UDP：提供不可靠、无连接的 QP 通信。支持数据报和组播通信。 销毁：在调用此函数并确认相关事件之前，用户必须释放任何与 rdma_cm_id 相关的 QP。 struct rdma_cm_id *listen_id;\rint err = rdma_create_id(channel, \u0026amp;listen_id, NULL, RDMA_PS_TCP);\rif (err) {\rperror(\u0026quot;rdma_create_id\u0026quot;);\rreturn err;\r}\r// 中间处理代码...\rrdma_destroy_id(listen_id);\r3. 绑定地址 将源地址与 rdma_cm_id 相关联。对应方法为int rdma_bind_addr(struct rdma_cm_id *id, struct sockaddr *addr)。 地址中可以包含通配符。 如果绑定到特定本地地址，则 rdma_cm_id 也将绑定到本地 RDMA 设备。 通常，在调用rdma_listen 以绑定到特定端口号之前调用此函数，但也可以在调用rdma_resolve_addr 以绑定到特定地址之前在主动方调用该函数。 如果用于绑定到端口 0，rdma_cm 将选择一个可用端口，可以使用rdma_get_src_port 检索该端口。 /* sockaddr_in 是 IPV4 的地址结构体\r* AF_INET：IPV4\r* htons：将主机字节序转换为网络字节序（小端存储）, 20079 是端口号\r* INADDR_ANY：表示任意地址\r*/\rstruct sockaddr_in addr = {\r.sin_family = AF_INET,\r.sin_port = htons(20079),\r.sin_addr = { .s_addr = INADDR_ANY },\r};\rerr = rdma_bind_addr(listen_id, (struct sockaddr *)\u0026amp;addr);\rif (err) {\rperror(\u0026quot;rdma_bind_addr\u0026quot;);\rreturn err;\r}\r4. 创建 Listener，返回端口/地址 初始化传入连接请求或数据报服务查找的 Listener。对应方法为int rdma_listen(struct rdma_cm_id *id, int backlog)。 侦听将被限制为本地绑定源地址 在调用此函数之前，用户必须已通过调用rdma_bind_addr 将rdma_cm_id 绑定到本地地址。 如果rdma_cm_id 绑定到特定的 IP 地址，则侦听将仅限于该地址和关联的 RDMA 设备。 如果rdma_cm_id 仅绑定到 RDMA 端口号，则将在所有 RDMA 设备上进行侦听。 返回已绑定到本地地址的rdma_cm_id 的本地端口号。对应方法为uint16_t rdma_get_src_port(struct rdma_cm_id *id)。 返回已绑定到本地设备的rdma_cm_id 的本地 IP 地址。对应方法为struct sockaddr * rdma_get_local_addr(struct rdma_cm_id *id)。 解析目的节点和服务地址，并返回建立通信所需的信息。提供与 getaddrinfo 等效的 RDMA 功能(配合rdma_create_ep 使用)。对应方法为int rdma_getaddrinfo (char *node, char *service, struct rdma_addrinfo *hints, struct rdma_addrinfo **res)。 node: 可选，目的节点的主机名，或者点分十进制的 IPv4/IPv6 十六进制地址 service：地址的服务名称或端口号。 hints：一个包含有关调用方支持的服务类型的提示的 rdma_addrinfo 结构的引用。 res：指向包含响应信息的 rdma_addrinfo 结构的 LinkedList 的指针。 // 等待连接请求的最大数量\rint backlog = 10;\rerr = rdma_listen(listen_id, backlog);\rif (err) {\rperror(\u0026quot;rdma_listen\u0026quot;);\rreturn err;\r}\ruint16_t port = rdma_get_src_port(listen_id);\rport = ntohs(port);\rprintf(\u0026quot;listening on port %u.\\n\u0026quot;, port);\rstruct sockaddr *local_addr = rdma_get_local_addr(listen_id);\rif (local_addr-\u0026gt;sa_family == AF_INET) {\rstruct sockaddr_in *sin = (struct sockaddr_in *)local_addr;\rchar ip[INET_ADDRSTRLEN];\r// 需要加上头文件 #include \u0026lt;arpa/inet.h\u0026gt;\rinet_ntop(AF_INET, \u0026amp;(sin-\u0026gt;sin_addr), ip, INET_ADDRSTRLEN);\rprintf(\u0026quot;Local IP address is: %s\\n\u0026quot;, ip);\rprintf(\u0026quot;Local port is: %d\\n\u0026quot;, ntohs(sin-\u0026gt;sin_port));\r}\rstruct rdma_addrinfo hints;\rmemset(\u0026amp;hints, 0, sizeof(hints));\rhints.ai_flags = RAI_PASSIVE;\rhints.ai_port_space = RDMA_PS_TCP;\rstruct rdma_addrinfo *res;\rerr = rdma_getaddrinfo(NULL, \u0026quot;20079\u0026quot;, \u0026amp;hints, \u0026amp;res);\rif (err) {\rperror(\u0026quot;rdma_getaddrinfo\u0026quot;);\rreturn err;\r}\r// do something with struct rdma_addrinfo *cur = res...\r5. 等待连接请求 检索通信事件。如果没有挂起的事件，默认情况下，调用将阻塞，直到接收到事件。对应方法为int rdma_get_cm_event(struct rdma_event_channel *channel, struct rdma_cm_event **event)。 通过修改与给定通道相关联的文件描述符，可以更改此函数的默认同步行为。 所有报告的事件都必须通过调用rdma_ack_cm_event 进行确认。 rdma_cm_id 的销毁将被阻塞，直到相关事件被确认。 struct rdma_cm_event* event;\r// 此处会阻塞，直到有事件发生\rerr = rdma_get_cm_event(channel, \u0026amp;event);\r6. 创建 PD、CQ 和 Send-Receive QP 分配与指定的rdma_cm_id 相关联的 QP，并将其转换为用于发送和接收。对应方法为int rdma_create_qp(struct rdma_cm_id *id, struct ibv_pd *pd, struct ibv_qp_init_attr *qp_init_attr)。 在调用此函数之前，rdma_cm_id 必须绑定到本地 RDMA 设备，且保护域 PD 必须用于同一设备。 被分配给rdma_cm_id 的 QP 会由 librdmacm 自动转换状态. 分配完毕后，QP 将准备就绪，处理接收信息的发布。如果 QP 未连接，它将准备好发布发送。 pd = ibv_alloc_pd(cm_client_id-\u0026gt;verbs);\rif (!pd) {\rperror(\u0026quot;Failed to allocate a protection domain\u0026quot;);\rreturn -1;\r}\rio_completion_channel = ibv_create_comp_channel(cm_client_id-\u0026gt;verbs);\rif (!io_completion_channel) {\rperror(\u0026quot;Failed to create an I/O completion event channel\u0026quot;);\rreturn -1;\r}\rcq = ibv_create_cq(cm_client_id-\u0026gt;verbs, 10, NULL, io_completion_channel, 0);\rif (!cq) {\rperror(\u0026quot;Failed to create a completion queue\u0026quot;);\rreturn -1;\r}\rret = ibv_req_notify_cq(cq, 0);\rif (ret) {\rperror(\u0026quot;Failed to request notifications\u0026quot;);\rreturn -1;\r}\rbzero(\u0026amp;qp_init_attr, sizeof(qp_init_attr));\rqp_init_attr.qp_type = IBV_QPT_RC;\rqp_init_attr.cap.max_send_wr = 10;\rqp_init_attr.cap.max_recv_wr = 10;\rqp_init_attr.cap.max_send_sge = 1;\rqp_init_attr.cap.max_recv_sge = 1;\rqp_init_attr.send_cq = cq;\rqp_init_attr.recv_cq = cq;\rret = rdma_create_qp(cm_client_id, pd, \u0026amp;qp_init_attr);\rif (ret) {\rperror(\u0026quot;Failed to create QP\u0026quot;);\rreturn -1;\r}\rclient_qp = cm_client_id-\u0026gt;qp;\r7. 最后的操作 Accept 请求连接 等待连接建立 发布操作 五、 RDMACM 程序解析——主动方 1. 创建事件 channel 与被动方相同 2. 创建连接 ID 与被动方相同 3. 绑定地址 将目的地址和可选源地址从 IP 地址解析为 RDMA 地址。如果成功，则指定的 rdma_cm_id 将绑定到本地设备。对应方法为int rdma_resolve_addr (struct rdma_cm_id *id, struct sockaddr *src_addr, struct sockaddr *dst_addr, int timeout_ms)。 此方法用于将给定的目标 IP 地址映射到可用的 RDMA 地址。 IP 到 RDMA 地址的映射使用本地路由表或通过 ARP 完成。 如果给定源地址，则将rdma_cm_id 绑定到该地址，就像调用rdma_ind_addr 一样。 如果没有给出源地址，并且rdma_cm_id 尚未绑定到设备，则rdma_cm_id 将根据本地路由表绑定到源地址。 在此方法调用之后，rdma_cm_id 将绑定到 RDMA 设备。 该方法调用通常在调用 rdma_resolve_route 和 rdma_connect 之前在主动方上进行。 InfiniBand 特定\n此方法还会将目标 IP 地址和源 IP 地址(如果给定)映射到 GID。 为了执行映射，IPoIB 必须同时在本地和远程节点上运行。 4. 创建 QP 与被动方相同 5. 解析路由 解析指向目标地址的 RDMA 路由，以建立连接。目标地址必须已通过调用 rdma_resolve_addr 解析。对应方法为int rdma_resolve_route (struct rdma_cm_id *id, int timeout_ms); 6. 建立连接 对应方法为int rdma_connect (struct rdma_cm_id *id, struct rdma_conn_param *conn_param);\nid：指向 rdma_cm_id 的指针 conn_param：指向 rdma_conn_param 结构的指针，包含连接参数 对于 RDMA_PS_TCP 类型的 rdma_cm_id，该调用会向远程目的地发起连接请求\n对于 RDMA_PS_UDP 类型的 rdma_cm_id，它会启动对提供数据报服务的远程 QP 的查询\n7. 最后的操作 等待连接建立 发布操作 六、实战：基于 RDMA 的 client-server 程序 1. server 端 工作流程： 初始化 RDMA 资源 等待 client 连接 分配并固定服务器缓冲区 buffer 接受客户端连接 将有关本地服务器缓冲区的信息发送到客户端 等待断开连接 2. client 端 工作流程： 初始化 RDMA 资源 连接 server 通过发送/接收 exchange 接收服务器端缓冲区信息 从（第一个）本地缓冲区向服务器缓冲区进行 RDMA 写入。 进行 RDMA 读取，将服务器缓冲区的内容读入第二个本地缓冲区。 比较第一缓冲区和第二缓冲区的内容，并进行匹配 断开连接 3. 项目实现 RDMA-examples\rRDMA-examples: A repository of practical code examples showcasing the fundamental concepts and usage of RDMA (Remote Direct Memory Access) technology. C\r4. 补充：RDMA 应用程序标准流程 参考文献 Mellanox Technologies, Inc. (2017). RDMA Aware Networks Programming User Manual. Mellanox Technologies, Inc. ","date":"2023-07-27T01:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/20230725145210.webp","permalink":"https://cuterwrite.top/p/rdma-tutorial/2/","title":"RDMA 技术及其编程方法（二）：编程指导"},{"content":"RDMA 技术及其编程方法（一）：RDMA 技术 一、 RDMA 技术简介 RDMA: Remote Direct Memory Access RDMA 就是一种远程直接内存访问技术，它可以让远程主机直接访问本地内存，而不需要经过 CPU 的参与，从而大大减少了 CPU 的开销，提高了数据传输的效率。 术语 含义 Remote 数据在同一网络中的节点之间传输 Direct （1）传输过程没有操作系统内核的参与 （2）所有关于传输的协议都负载在网卡上 Memory （1）在用户态的应用程序的虚拟内存之间传输（2）没有额外的内存拷贝或缓存 Access send、receive、read、write、原子操作 RDMA 的各种协议 InfiniBand - (41.8% of top 500 supercomputers) InfiniBand 是一个工业标准的分组交换网络 在高性能计算机系统中越来越多地被采用 用户层网络，可绕过操作系统内核 SDR 4x - 8 Gbps DDR 4x - 16 Gbps QDR 4x - 32 Gbps FDQ 4x - 54 Gbps RoCE - RDMA over Converged Ethernet 允许在以太网络上执行 RDMA 的网络协议 RoCE v1 - 10 Gbps RoCE v2 - 25 Gbps iWarp - internet Wide Area RDMA Protocol 运行在 TCP/IP 协议栈上的 RDMA 协议 10 Gbps RDMA 的支持嵌入在内核之中：Kernel 中的 drivers/infiniband RDMA 协议优势 Zero-copy：零拷贝，能够读写远程内存，能够直接访问远程缓冲区，无需在不同软件层之间复制数据 Kernel bypass：跳过内核，可在相同的代码上下文（即用户空间或内核）中收发数据，节省了上下文切换时间 No CPU involvement：无 CPU 参与，可使用专用硬件收发数据，而不需要 CPU 干预。可降低远程端的 CPU 使用率，因为不需要它执行任何主动操作 Message based transactions：基于消息的事务，可在不同的连接上同时执行多个事务，而无需等待任何事务完成 Scatter/gather entries support：支持分散/聚集条目，可在单个操作中传输多个缓冲区，而无需将它们合并到单个缓冲区中 二、 RDMA 工作原理 1. Infiband 与以太网的对比 Feature/Network Type InfiniBand Ethernet Addressing lids, gid macs, IP addresses Path resolution Path queries ARP Lossless network Credit-based flow control Pause frames/PFC QoS SLs/VLs Priorities/TC Virtual networks Pkeys VLANs 可以看到，InfiniBand 与以太网的区别首先在于网络地址的表示方式不同，以太网使用 mac 地址和 IP 地址，而 InfiniBand 使用 lid 和 gid 其次，网络的路径解析方式不同，以太网使用 ARP 地址解析协议，而 InfiniBand 使用 path queries； 然后，在网络的可靠性方面，以太网使用 Pause frames/PFC（Priority-based Flow Control，基于优先级的流量控制），而 InfiniBand 使用的是 Credit-based flow control(基于信用的流量控制) 接着在网络的服务质量方面，以太网使用 Priorities/TC（Traffic Class，流量类别），而 InfiniBand 使用 SLs/VLs（Service Level，服务等级） 最后，在网络的虚拟化方面，以太网使用 VLANs（Virtual Local Area Network，虚拟局域网），而 InfiniBand 使用 Pkeys（Partition Keys，分区键）。 2. RDMA 中的重要概念 缩写 全称 说明 PD Protection Domain 保护域，是 RDMA 中的一种资源管理机制。PD 定义了一组内存区域和访问权限，用于控制 RDMA 操作的安全性。PD 与 QP、MR 均有关联。 MR Memory Region 内存区域，是 RDMA 中的一种抽象，用于描述应用程序中的内存区域。MR 定义了一块内存区域的起始地址、大小和访问权限，并与 PD 关联。包含 R_Key 和 L_Key。MR 的配套机制用来解决 RDMA 操作中的两个问题：（1）APP 提供的地址都是虚拟地址，经过 MMU 的转换才能得到真实的物理地址，RDMA 网卡是如何得到真实物理地址从而去内存中读取或写入数据的？（2）假设网卡有能力获取目的地址，但如果用户恶意指定了一个非法的虚拟地址，网卡就有可能被指使去读写系统关键内存，如何预防？因此，MR 的作用之一就是实现虚拟地址与物理地址的转换，APP 只能看到虚拟地址，而且会在发起 RDMA Write 时把本地和对端的内存的虚拟地址传递给 RDMA 网卡。网卡需要知道 APP 提供的虚拟地址所对应的物理地址才能访问系统内存。在注册 MR 的过程中，软件会在内存中创建并填写一个虚拟地址到物理地址的映射表供网卡查询。MR 的第二个作用是控制 HCA 访问内存的权限，程序在注册 MR 时会产生两把钥匙 L_KEY（Local）和 R_KEY（Remote）。 QP Queue Pair 队列对，是 RDMA 中的一种通信机制。QR 由发送队列（Send Queue, SQ）和接收队列（Receive Queue, RQ）组成，用于发送和接收 RDMA 操作的请求和数据。SQ 专门用来存放发送任务，RQ 专门用来存放接收任务。在一次 SEND-RECV 流程中，发送端需要把表示一次发送任务的 WR 放到 SQ 里面(这种操作称为 Post Send)，接收端需要把表示一次接收任务的 WR 放到 QP 里面（称为 Post Receive），这样硬件才知道收到数据之后放到内存中的哪个位置。在 RDMA 中，通信的基本对象是 QP，而不是节点。对于每个节点来说，每个进程都可以申请和使用若干个 QP，而每个本地 QP 可以连接到一个远端的 QP。每个节点中的 QP 都有一个唯一的编号，称为 QPN，通过 QPN 可以唯一确定一个节点上的 QP。 CQ Completion Queue 完成队列，用于存储 RDMA 操作的完成事件。当 RDMA 操作完成时，相关的完成事件会被放入 CQ 中，应用程序可以通过轮询或事件通知方式获取这些完成事件。CQ 与 QP 相关联。CQ 中有很多元素，称为 CQE。CQE 是硬件完成任务之后返回给软件的“完成报告”，与 WR 相反。每个 CQE 都包含某个 WR 的完成信息。 WR Work Request 工作请求，用于描述 RDMA 操作的请求。WR 包含了操作类型、源地址、目的地址等信息，应用程序通过将 WR 放入 QP 的发送队列来触发 RDMA 操作。 SGE Scatter/Gather Element 即将读或写的内存地址。必须提供 L_Key 或 R_Key 来认证 MR 的连接 WC Work Completion 工作完成，用于描述 RDMA 操作的完成事件。WC 包含了操作类型、状态、传输长度等信息，应用程序可以通过读取 CQ 中的 WC 来获取 RDMA 操作的结果。 3. QPs/WRs 执行模型 硬件提供 针对每个 QP 上下文 虚拟到物理内存的转换 安全的进程控制机制 可靠性(取决于传输服务) 操作系统管理资源创建 但不发布 WR 和轮询 CQ 结果 应用程序以安全的方式直接访问硬件 软件处理缓冲区而不是信息包 在快速路径中不需要操作系统干预。 完全异步的过程 4. 通信语义 Channel（消息传递） 请求者提供源缓冲区 接收者提供目的缓冲区 Remote Direct Memory Access（RDMA） 请求者同时提供源缓冲区和目标缓冲区 同时支持 RDMA 读取和写入 5. 传输服务 分类：Connected（连接）与 Datagram（数据报）\n分类：Reliable（可靠）与 Unreliable（不可靠）\n两两组合形成四种类型的传输：\nReliable Connected（RC），例如 TCP Unreliable Datagram（UD），例如 UDP UC 也可以实现 RD 不支持，虽然它是由规范定义的，但在 API/DIVER/硬件中不支持 QP 的传输类型：\n可靠连接 RC QP 仅与一个远程 QP 关联 由一个 QP 的发送队列发送的消息被可靠地递送到另一个 QP 的接收队列。 数据包按顺序发送 发送端，每条消息都被划分为长度为路径 MTU 的数据包，接收方将数据包重组为消息。支持发送、RDMA write/read 不可靠连接 RC QP 仅与一个远程 QP 关联 连接是不可靠的，即发送的数据包可能会丢失 消息出错时不会重传，错误处理必须由更高级别的协议提供。 支持发送、RDMA write 不可靠数据报 UD 队列对可以向/从任何其他多个 QP 发送和接收单数据包消息。 不能保证有序和数据包到达，并且发送的数据包可能会被接收方丢弃。 支持广播消息(一对多) 只支持发送操作 RDMA 支持的传输操作\nSend（立即） 发送方需要加上时间戳 接收方也需要在某些地方加上该时间戳用来标识该消息 RDMA Write（立即） RDMA Read（异步） Atomic operations（原子操作） 发送方发送读/写请求，并指定其将访问读写的本地和远程地址 Send 操作流程：\n接收方需要发送接收请求（Receive Request, RR）给发送方 发送方发送 Send 操作请求（Send Request, SR）给接收方 只在可靠连接中发送 ACK 接收方轮询 CQ，获取 SR 的完成事件 发送方轮询 CQ，获取 RR 的完成事件 RDMA Write 操作流程： 请求方发送 Send 操作请求（Send Request, SR）加上远程地址与 key 给接收方 只在可靠连接中发送 ACK 请求方轮询 CQ，获取 SR 的完成事件 RDMA Write 操作是一端应用主动写入远端内存的行为，除了准备阶段，远端 CPU 不需要参与，也不感知何时有数据写入、数据在何时接收完毕，所以这是一种单端操作。 需要注意的是，操作发起端的应用程序是通过虚拟地址来读写远端内存的，上层应用可以非常方便的对其进行操作。实际的虚拟地址——物理地址的转换由 RDMA 网卡完成。 RDMA Read 与 Atomic 操作流程： 请求方发送 Send 操作请求（Send Request, SR）加上远程地址与 key 给接收方 只在可靠连接中发送 ACK 请求方轮询 CQ，获取 SR 的完成事件 小结：UD、UC、RC 三种 QP 传输方式对比，w/o-\u0026gt;with/without 操作原语 UD UC RC Send(w/o immediate) 支持 支持 支持 RDMA Write(w/o immediate) 不支持 支持 支持 RDMA Read 不支持 不支持 支持 Atomic operations 不支持 不支持 支持 连接类型 数据报（一对多） 连接（一对一） 连接（一对一） 最大消息大小 最大路径 MTU 2GB 2GB 广播 支持 不支持 不支持 6. RDMA 架构层级结构 三、Verbs 与 OFA Verbs API 1. Verbs 简介 Verbs 是对为使用 RDMA 的应用程序提供的功能的抽象描述 Verbs 不是 API Verbs 有多种实现 Verbs 可以被分为两大类 控制：管理资源，通常需要切换上下文。 创建/销毁/修改/查询/处理事件 数据：使用资源发送/接收数据，不需要切换上下文。 发送 Send/发送 Receive/轮询 CQ/请求完成事件 Verbs 是对 RDMA 编程的底层描述。 Verbs 旨在提供延迟、带宽、消息速率等方面的最佳性能。它可以被视作许多应用构建的基石。 Sockets 存储 并行计算 InfiniBand 规范以 Verbs 接口形式编写 所需行为的语义描述 没有语法或操作系统特定的详细信息 可以自由定义实现 函数、结构、类型等的语法。 OpenFabrics Alliance (OFA) Verbs API 一种 Verbs 接口，由 OpenFabrics Alliance（OFA）组织定义和推广。OFA Verbs 是基于 RDMA Verbs 的扩展，提供了更加统一和标准化的 RDMA 编程接口。OFA Verbs 是 RDMA 领域的一个重要标准，被广泛应用于高性能计算、数据中心和云计算等领域。 旨在提供一个开放、跨平台的 RDMA 编程接口，使应用程序能够在不同的 RDMA 硬件和操作系统上进行移植和开发 OFA 统一 InfiniBand 市场的战略 OFA 面向 Linux、FreeBSD、Windows 等操作系统实现 应用程序的软件接口：支持 C/C++程序的数据结构、函数原型 用户态空间和内核态空间的变体：大多数应用程序和库都在用户态空间中 客户端-服务器编程模型 与 TCP/IP 套接字有一些明显的相似之处 而许多的其它不同之处，则是由于 RDMA 与 TCP/IP 的不同导致 2. OFA Verbs API 支持应用 MPI： Message Passing Interface，支持多种版本 OpenMPI MVAPICH Intel MPI 文件系统： Lustre NFS_RDMA DDN 和 NetApp 公司生产的存储设备 SRP：SCSI RDMA (Remote) Protocol – Linux kernel iSER – iSCSI Extensions for RDMA – Linux kernel 伪 Socket 库 SDP – Sockets Direct Protocol – supported by Oracle rsockets – RDMA Sockets – supported by Intel mva – Mellanox Messaging Accelerator SMC-R – proposed by IBM 四、总结 RDMA 技术是一种远程直接内存访问技术，它可以让远程主机直接访问本地内存，而不需要经过 CPU 的参与，从而大大减少了 CPU 的开销，提高了数据传输的效率。 RDMA 技术的各种协议：InfiniBand、RoCE、iWarp RDMA 技术的优势：Zero-copy、Kernel bypass、No CPU involvement、Message based transactions、Scatter/gather entries support RDMA 技术的传输服务：Connected（连接）与 Datagram（数据报）、Reliable（可靠）与 Unreliable（不可靠） RDMA 技术的 QP 传输类型：RC、UC、UD RDMA 技术的操作原语：Send、RDMA Write、RDMA Read、Atomic operations RDMA 技术的 Verbs 与 OFA Verbs API RDMA 技术的应用：MPI、文件系统、存储设备、伪 Socket 库 参考文献 Mellanox Technologies, Inc. (2017). RDMA Aware Networks Programming User Manual. Mellanox Technologies, Inc. ","date":"2023-07-21T01:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/20230722162905.webp","permalink":"https://cuterwrite.top/p/rdma-tutorial/1/","title":"RDMA 技术及其编程方法（一）：RDMA 简介与原理"},{"content":"MPI 与并行计算（五）：MPI 扩展 1. 动态进程 MPI-1 假定所有的进程都是静态的，运行时不能增加和删除进程。MPI-2 引入了动态进程的概念：\nMPI-1 不定义如何创建进程和如何建立通信。MPI-2 中的动态进程机制以可移植的方式(平台独立)提供了这种能力。 动态进程有利于将 PVM 程序移植到 MPI 上。并且还可能支持一些重要的应用类型， 如 Client/Server 和 Process farm。 动态进程允许更有效地使用资源和负载平衡。例如，所用节点数可以按需要减少和增加。 支持容错。当一个节点失效时，可以在另一个节点上创建一个新进程运行该节点上的进程的工作。 在 MPI-1 中 一个 MPI 程序一旦启动，一直到该 MPI 程序结束，进程的个数是固定的，在程序运行过程中是不可能动态改变的。在 MPI-2 中，允许在程序运行过程中动态改变进程的数目，并提供了动态进程创建和管理的各种调用。\n组间通信域在动态进程管理中处于核心的地位，只有掌握了它的基本概念，才能准确把握和使用进程的动态特性和动态进程之间的通信。\n在 MPI-2 中，对点到点通信和组通信都给出了使用组间通信域时的确切含义。在语法上，不管是使用组内还是组间通信域，二者没有任何区别，但其语义是不同的。\n对于构成组间通信域的两个进程组，调用进程把自己所在的组看作是本地组，而把另一个组称为远地组，使用组间通信域的一个特点是本地组进程发送的数据被远地组进程接收而本地组接收的数据必然来自远地组。 在使用组间通信域的点到点通信中，发送语句指定的目的进程是远地组中的进程编号，接收进程指出的源进程编号也是远地组的进程编号。 如图所示为组间通信域上的点到点通信 对于组通信，如果使用组间通信域，则其含义分不同的形式而有所不同：对于多对多通信，本地进程组的所有进程向远地进程组的所有进程发送数据，同时本地进程组的所有进程从远地进程组的所有进程接收数据，如图所示：\n此外，组间通信域上的一对多通信或多对一通信如图所示： 示例 1：动态进程的创建和通信\n// dynamic.c\r#include \u0026lt;stdio.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\r#include \u0026lt;mpi.h\u0026gt;\rint main(int argc, char *argv[])\r{\rint rank, size, color, new_rank, new_size;\rMPI_Comm new_comm;\rMPI_Init(\u0026amp;argc, \u0026amp;argv);\rMPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank);\rMPI_Comm_size(MPI_COMM_WORLD, \u0026amp;size);\rcolor = rank / 2; // 0, 0, 1, 1, 2, 2, 3, 3\rMPI_Comm_split(MPI_COMM_WORLD, color, rank, \u0026amp;new_comm);\rMPI_Comm_rank(new_comm, \u0026amp;new_rank);\rMPI_Comm_size(new_comm, \u0026amp;new_size);\rprintf(\u0026quot;rank = %d, size = %d, new_rank = %d, new_size = %d\\n\u0026quot;, rank, size, new_rank, new_size);\rMPI_Finalize();\rreturn 0;\r}\r在 16 个进程中，每两个进程一组，共 8 组，每组的进程编号相同，运行结果如下： root@ubuntu:~# mpicc dynamic.c -o dynamic\rroot@ubuntu:~# mpirun -n 16 ./dynamic\rrank = 0, size = 16, new_rank = 0, new_size = 2\rrank = 1, size = 16, new_rank = 1, new_size = 2\rrank = 2, size = 16, new_rank = 0, new_size = 2\rrank = 3, size = 16, new_rank = 1, new_size = 2\rrank = 4, size = 16, new_rank = 0, new_size = 2\rrank = 5, size = 16, new_rank = 1, new_size = 2\rrank = 6, size = 16, new_rank = 0, new_size = 2\rrank = 7, size = 16, new_rank = 1, new_size = 2\rrank = 8, size = 16, new_rank = 0, new_size = 2\rrank = 9, size = 16, new_rank = 1, new_size = 2\rrank = 10, size = 16, new_rank = 0, new_size = 2\rrank = 11, size = 16, new_rank = 1, new_size = 2\rrank = 12, size = 16, new_rank = 0, new_size = 2\rrank = 13, size = 16, new_rank = 1, new_size = 2\rrank = 14, size = 16, new_rank = 0, new_size = 2\rrank = 15, size = 16, new_rank = 1, new_size = 2\r示例 2：更复杂的动态进程的创建和通信\n#include \u0026lt;mpi.h\u0026gt;\r#include \u0026lt;cmath\u0026gt;\r#include \u0026lt;fstream\u0026gt;\r#include \u0026lt;iostream\u0026gt;\rint world_rank, world_size;\rMPI_Comm custom_comm1, custom_comm2, custom_comm3, tmp;\rvoid splitting()\r{\rint color;\rMPI_Comm *new_comm;\r// 1- First splitting here.\r// With only one call to MPI_Comm_split you should be able to split processes 0-3 in\r// custom_comm1 and processes 4-6 in custom_comm2\rcolor = MPI_UNDEFINED;\rnew_comm = \u0026amp;tmp;\rif (world_rank \u0026gt;= 0 \u0026amp;\u0026amp; world_rank \u0026lt;= 3)\r{\rcolor = 0;\rnew_comm = \u0026amp;custom_comm1;\r}\rif (world_rank \u0026gt;= 4 \u0026amp;\u0026amp; world_rank \u0026lt;= 6)\r{\rcolor = 1;\rnew_comm = \u0026amp;custom_comm2;\r}\rMPI_Comm_split(MPI_COMM_WORLD, color, world_rank, new_comm);\r// 2- Second splitting here\r// Now put processes 0 and 4 in custom_comm3\rcolor = MPI_UNDEFINED;\rnew_comm = \u0026amp;tmp;\rif (world_rank == 0 || world_rank == 4)\r{\rcolor = 2;\rnew_comm = \u0026amp;custom_comm3;\r}\rMPI_Comm_split(MPI_COMM_WORLD, color, world_rank, new_comm);\r}\rint main(int argc, char **argv)\r{\rMPI_Init(\u0026amp;argc, \u0026amp;argv);\rMPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;world_rank);\rMPI_Comm_size(MPI_COMM_WORLD, \u0026amp;world_size);\rsplitting();\rif (world_rank \u0026gt;= 0 \u0026amp;\u0026amp; world_rank \u0026lt;= 3)\r{\rint row_rank;\rint row_size;\rMPI_Comm_rank(custom_comm1, \u0026amp;row_rank);\rMPI_Comm_size(custom_comm1, \u0026amp;row_size);\rstd::cout \u0026lt;\u0026lt; \u0026quot;custom_comm1: \u0026quot; \u0026lt;\u0026lt; row_rank \u0026lt;\u0026lt; \u0026quot;/\u0026quot; \u0026lt;\u0026lt; row_size \u0026lt;\u0026lt; std::endl;\r}\rif (world_rank \u0026gt;= 4 \u0026amp;\u0026amp; world_rank \u0026lt;= 6)\r{\rint row_rank;\rint row_size;\rMPI_Comm_rank(custom_comm2, \u0026amp;row_rank);\rMPI_Comm_size(custom_comm2, \u0026amp;row_size);\rstd::cout \u0026lt;\u0026lt; \u0026quot;custom_comm2: \u0026quot; \u0026lt;\u0026lt; row_rank \u0026lt;\u0026lt; \u0026quot;/\u0026quot; \u0026lt;\u0026lt; row_size \u0026lt;\u0026lt; std::endl;\r}\rif (world_rank == 0 || world_rank == 4)\r{\rint row_rank;\rint row_size;\rMPI_Comm_rank(custom_comm3, \u0026amp;row_rank);\rMPI_Comm_size(custom_comm3, \u0026amp;row_size);\rstd::cout \u0026lt;\u0026lt; \u0026quot;custom_comm3: \u0026quot; \u0026lt;\u0026lt; row_rank \u0026lt;\u0026lt; \u0026quot;/\u0026quot; \u0026lt;\u0026lt; row_size \u0026lt;\u0026lt; std::endl;\r}\rMPI_Finalize();\rreturn 0;\r}\r2. 远程存储访问（Remote Memory Access，RMA） 在 MPI-2 中增加远程存储访问的能力，主要是为了使 MPI 在编写特定算法和通信模型的并行程序时更加自然和简洁。因为在许多情况下，都需要一个进程对另外一个进程的存储区域进行直接访问。 MPI-2 对远程存储的访问主要是通过窗口来进行的，为了进行远程存储访问，首先需要定义一个窗口，该窗口开在各个进程的一段本地进程存储空间，其目的是为了让其它的进程可以通过这一窗口来访问本地的数据。 定义好窗口之后，就可以通过窗口来访问远程存储区域的数据了。MPI-2 提供了三种基本的访问形式，即读、写和累计，读操作只是从远端的窗口获取数据，并不对远端数据进行任何修改；写操作将本地的内容写入远端的窗口，它修改远端窗口的内容；累计操作就更复杂一些，它将远端窗口的数据和本地的数据进行某种指定方式的运算之后，再将运算的结果写入远端窗口。 MPI-2 就是通过读、写和累计三种操作来实现对远程存储的访问和更新的。除了基本的窗口操作之外 MPI-2 还提供了窗口管理功能 用来实现对窗口操作的同步管理。MPI-2 对窗口的同步管理有三种方式 ： 栅栏方式 fence：在这种方式下，对窗口的操作必须放在一对栅栏语句之间，这样可以保证当栅栏语句结束之后，其内部的窗口操作可以正确完成。 握手方式：在这种方式下，调用窗口操作的进程需要将具体的窗口调用操作放在以 MPI_WIN_START 开始，以 MPI_WIN_COMPLETE 结束的调用之间。相应的,被访问的远端进程需要以一对调用 MPI_WIN_POST 和 MPI_WIN_WAIT 与之相适应。MPI_WIN_POST 允许其它的进程对自己的窗口进行访问，而 MPI_WIN_WAIT 调用结束之后可以保证对本窗口的调用操作全部完成。MPI_WIN_START 申请对远端进程窗口的访问，只有当远端窗口执行了 MPI_WIN_POST 操作之后才可以访问远端窗口，MPI_WIN_COMPLETE 完成对远端窗口访问操作。 锁方式：在这种方式下，不同的进程通过对特定的窗口加锁来实现互斥访问。当然用户根据需要可以使用共享的锁，这是就可以允许使用共享锁的进程对同一窗口同时访问。远端存储的访问窗口是具体的实现形式，通过窗口操作实现来实现单边通信，通过对窗口的管理操作来实现对窗口操作的同步控制。 窗口操作 说明 MPI_Win_create 创建窗口 MPI_Win_free 释放窗口 MPI_Win_fence 栅栏同步 MPI_Win_start 握手同步 MPI_Win_complete 握手同步 MPI_Win_post 握手同步 MPI_Win_wait 握手同步 MPI_Win_lock 锁同步 MPI_Win_unlock 锁同步 MPI_Win_test 锁同步 MPI_Win_lock_all 锁同步 MPI_Win_unlock_all 锁同步 MPI_Win_flush 锁同步 MPI_Win_flush_all 锁同步 MPI_Win_flush_local 锁同步 MPI_Win_flush_local_all 锁同步 MPI_Win_shared_query 查询窗口 小结：窗口是远程存储访问中的重要概念，其实 MPI-2 的远程存储访问就是各进程将自己的一部分内存区域开辟成其它所有进程都可以访问的窗口，从而使其它的进程实现对自己数据的远程访问，窗口操作是相对简单的，对窗口访问的同步控制是需要注意的问题。 示例 3：远程存储访问\n// rma.c\r#include \u0026lt;stdio.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\r#include \u0026lt;mpi.h\u0026gt;\rint main(int argc, char *argv[])\r{\rint rank, size, i, j, *buf, *winbuf;\rMPI_Win win;\rMPI_Init(\u0026amp;argc, \u0026amp;argv);\rMPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank);\rMPI_Comm_size(MPI_COMM_WORLD, \u0026amp;size);\rbuf = (int *)malloc(size * sizeof(int));\rMPI_Win_create(buf, size * sizeof(int), sizeof(int), MPI_INFO_NULL, MPI_COMM_WORLD, \u0026amp;win);\rfor (i = 0; i \u0026lt; size; i++)\rbuf[i] = 0;\rMPI_Win_fence(0, win);\rif (rank == 0)\r{\rfor (i = 0; i \u0026lt; size; i++)\rbuf[i] = i;\r}\rMPI_Win_fence(0, win);\rif (rank == 1)\r{\rfor (i = 0; i \u0026lt; size; i++)\rprintf(\u0026quot;buf[%d] = %d\\n\u0026quot;, i, buf[i]);\r}\rMPI_Win_free(\u0026amp;win);\rMPI_Finalize();\rreturn 0;\r}\r3. 并行 I/O（MPI-IO） MPI-1 没有对并行文件 I/O 给出任何定义，原因在于并行 I/O 过于复杂，很难找到一个统一的标准。但是，I/O 是很多应用不可缺少的部分，MPI-2 在大量实践的基础上，提出了一个并行 I/O 的标准接口。MPI-2 提供的关于并行文件 I/O 的调用十分丰富，根据读写定位方法的不同，可以分为三种：\n指定显示的偏移：这种调用没有文件指针的概念 每次读写操作都必须明确指定读写文件的位置。 各进程拥有独立的文件指针：这种方式的文件操作不需要指定读写的位置每一个进程都有一个相互独立的文件指针，读写的起始位置就是当前指针的位置。读写完成后文件指针自动移到下一个有效数据的位置。这种方式的文件操作需要每一个进程都定义各自在文件中的文件视图（view），文件视图（view）数据是文件连续或不连续的一部分，各个进程对文件视图（view）的操作就如同是对一个打开的独立的连续文件的操作一样。 共享文件指针：在这种情况下，每一个进程对文件的操作都是从当前共享文件指针的位置开始，操作结束后共享文件指针自动转移到下一个位置。共享指针位置的变化对所有进程都是可见的，各进程使用的是同一个文件指针。任何一个进程对文件的读写操作都会引起其它所有进程文件指针的改变。 MPI-IO 文件访问过程 在进行 I/O 之前，必须要通过调用 MPI_File_open 打开文件 每个进程都需要定义文件指针用来控制文件访问 I/O 操作完成后，必须通过调用 MPI_File_close 来关闭文件 并行文件的基本操作 打开：MPI_File_open(comm, filename, amode, info, fh) comm：组内通信域 filename：文件名 amode：打开模式 info：传递给运行时的信息 fh：返回的文件句柄 文件访问模式 含义 MPI_MODE_RDONLY 只读 MPI_MODE_RDWR 读写 MPI_MODE_WRONLY 只写 MPI_MODE_CREATE 若文件不存在则创建 MPI_MODE_EXCL 创建不存在的新文件，若文件已存在则报错 MPI_MODE_DELETE_ON_CLOSE 关闭文件时删除文件 MPI_MODE_UNIQUE_OPEN 文件只能被一个进程打开 MPI_MODE_SEQUENTIAL 文件只能被顺序访问 MPI_MODE_APPEND 追加方式打开，初始文件指针指向文件末尾 关闭：MPI_File_close(fh) fh：文件句柄 删除：MPI_File_delete(filename, info) filename：文件名 info：传递给运行时的信息 修改文件大小：MPI_File_set_size(fh, size) fh：文件句柄 size：新的文件大小(字节) 查看文件大小：MPI_File_get_size(fh, size) fh：文件句柄 size：文件大小(字节) 预申请空间：MPI_File_preallocate(fh, size) fh：文件句柄 size：预申请的空间大小(字节) 示例 4：并行 I/O - 指定显示偏移并行读\n#include \u0026lt;mpi.h\u0026gt;\r#include \u0026lt;stdio.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\r#include \u0026lt;sys/stat.h\u0026gt;\r#include \u0026lt;unistd.h\u0026gt;\r#include \u0026lt;string.h\u0026gt;\rint main(int argc, char **argv)\r{\rint rank, size;\rMPI_File fh;\rMPI_Status status;\rMPI_Init(\u0026amp;argc, \u0026amp;argv);\rMPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank);\rMPI_Comm_size(MPI_COMM_WORLD, \u0026amp;size);\rchar *filename = \u0026quot;testfile\u0026quot;;\rstruct stat st;\rstat(filename, \u0026amp;st);\rint filesize = st.st_size;\rint bufsize = filesize / size;\rMPI_File_open(MPI_COMM_WORLD, filename, MPI_MODE_RDONLY, MPI_INFO_NULL, \u0026amp;fh);\rMPI_Offset offset = rank * bufsize;\rif (rank == size - 1)\r{\rbufsize += filesize % size;\r}\rchar* buf = (char*)malloc(bufsize * sizeof(char));\rprintf(\u0026quot;Buf size: %d\\n\u0026quot;, bufsize);\rMPI_File_read_at(fh, offset, buf, bufsize, MPI_CHAR, \u0026amp;status);\rprintf(\u0026quot;Process %d read: %s\\n\u0026quot;, rank, buf);\rMPI_File_close(\u0026amp;fh);\rMPI_Finalize();\rfree(buf);\rreturn 0;\r}\rtesfile 文件内容为： ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz01234567891\r运行结果为： root@ubuntu:~# mpicc read.c -o read\rroot@ubuntu:~# mpirun -n 2 ./read\rBuf size: 125\rProcess 1 read: ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz01234567891\rBuf size: 124\rProcess 0 read: ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\r4. 正确地使用 MPI-IO 正确使用 MPI-IO 根据 I/O 需求，每个应用都有其特定的 I/O 访问模式 对于不同的 I/O 系统，同样的 I/O 访问模式也可以使用不同的 I/O 函数和 I/O 方式实现 通常 MPI-IO 中 I/O 访问模式的实现方式可分为 4 级：level0-level3 以分布式数组访问为例 level0：每个进程对本地数组的一行发出一个独立的读请求（就像在 unix 中一样） MPI_File_open(..., file, ..., \u0026amp;fh);\rfor (i = 0; i \u0026lt; n_local_rows; i++)\r{\rMPI_File_seek(fh, ...);\rMPI_File_read(fh, \u0026amp;(A[i][0]), ...);\r}\rMPI_File_close(\u0026amp;fh);\rlevel1：类似于 level 0，但每个过程都使用集合 I/O 函数 MPI_File_open(MPI_COMM_WORLD, file, ...,\u0026amp;fh);\rfor (i = 0; i \u0026lt; n_local_rows; i++)\r{\rMPI_File_seek(fh, ...);\rMPI_File_read_all(fh, \u0026amp;(A[i][0]), ...);\r}\rMPI_File_close(\u0026amp;fh);\rlevel2：每个进程创建一个派生数据类型来描述非连续访问模式，定义一个文件视图，并调用独立的 I/O 函数 MPI_Type_create_subarray(...,\u0026amp;subarray, ...);\rMPI_Type_commit(\u0026amp;subarray);\rMPI_File_open(..., file, ..., \u0026amp;fh);\rMPI_File_set_view(fh, ..., subarray, ...);\rMPI_File_read(fh, A, ...);\rMPI_File_close(\u0026amp;fh);\rlevel3：类似于 level 0，但每个过程都使用集合 I/O 函数 MPI_Type_create_subarray(...,\u0026amp;subarray, ...);\rMPI_Type_commit(\u0026amp;subarray);\rMPI_File_open(MPI_COMM_WORLD, file,...,\u0026amp;fh);\rMPI_File_set_view(fh, ..., subarray, ...);\rMPI_File_read_all(fh, A, ...);\rMPI_File_close(\u0026amp;fh);\r5. 总结 MPI-IO 有许多功能，可以帮助用户获得高性能 I/O 支持非连续性访问 派生数据类型 文件视图 集合 I/O 用户应该根据应用程序 I/O 特性来选择适合的 I/O 访问模式实现 同时，MPI-IO 不是实现并行 I/O 的唯一选择。目前已有一些更高级的库可代替 MPI-IO HDF5、netCDF\u0026hellip;\u0026hellip; 这些库都是基于 MPI-IO 实现 ","date":"2023-07-20T03:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/9a5806864623b04c918b9d8bee35c49fc2790c52.jpg@1256w_828h_!web-article-pic.avif","permalink":"https://cuterwrite.top/p/mpi-tutorial/5/","title":"MPI 与并行计算（五）：MPI 扩展"},{"content":"MPI 与并行计算（四）：数据类型 1. 预定义数据类型 MPI 支持异构计算(Heterogeneous Computing)，它指在不同计算机系统上运行程序，每台计算可能有不同生产厂商，不同操作系统。 MPI 通过提供预定义数据类型来解决异构计算中的互操作性问题，建立它与具体语言的对应关系。\nMPI 中预定义的数据类型如下： MPI 数据类型(C 语言绑定) C 语言数据类型 MPI_CHAR char MPI_SHORT short MPI_INT int MPI_LONG long MPI_UNSIGNED_CHAR unsigned char MPI_UNSIGNED_SHORT unsigned short MPI_UNSIGNED unsigned MPI_UNSIGNED_LONG unsigned long MPI_FLOAT float MPI_DOUBLE double MPI_LONG_DOUBLE long double MPI_BYTE 无 MPI_PACKED 无 但是，对于点对点通信，仅仅使用包含一系列相同基本数据类型的缓冲区是不够的。我们经常要传递包含不同数据类型值的信息（例如一个整数变量 count，然后是一串实数）；并且我们经常要发送不连续的数据（例如，矩阵的一个子块）。\nOpenMPI 为发送非连续数据提供 pack/unpack 函数。用户在发送数据前要明确地将数据打包到连续的缓冲区中，并在接收数据后将其从连续的缓冲区中解包。虽然使用这些函数可以实现非连续数据的发送，但是这种方式不够灵活，而且效率低下。不过为了与以前的库或代码兼容，下面提供了这两个函数的使用方法。\nint MPI_Pack(const void* inbuf, int incount, MPI_Datatype datatype, void *outbuf, int outsize, int *position, MPI_Comm comm)\rinbuf：输入缓冲区的起始地址 incount：输入缓冲区中数据的个数 datatype：输入缓冲区中数据的类型 outbuf：输出缓冲区的起始地址 outsize：输出缓冲区的大小 position：输出缓冲区中的位置 comm：通信域 int MPI_Unpack(const void* inbuf, int insize, int *position, void *outbuf, int outcount, MPI_Datatype datatype, MPI_Comm comm)\rinbuf：输入缓冲区的起始地址 insize：输入缓冲区的大小 position：输入缓冲区中的位置 outbuf：输出缓冲区的起始地址 outcount：输出缓冲区中数据的个数 datatype：输出缓冲区中数据的类型 comm：通信域 示例 1：Pack/Unpack\n#include \u0026lt;stdio.h\u0026gt;\r#include \u0026lt;string.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\r#include \u0026quot;mpi.h\u0026quot;\r#define MASTER 0\r#define STRLEN 25\rint main(int argc, char* argv[])\r{\rint rank;\rint size;\rint position;\rchar message[BUFSIZ];\rfloat value; //VALUE TO SEND\rchar name[STRLEN]; //ASSIGNED NAME\rint param; //ADDITIONAL PARAM\rMPI_Init( \u0026amp;argc, \u0026amp;argv );\rMPI_Comm_size( MPI_COMM_WORLD, \u0026amp;size );\rMPI_Comm_rank( MPI_COMM_WORLD, \u0026amp;rank );\rif (rank == MASTER) {\rvalue = 10;\rsprintf(name, \u0026quot;My Name\u0026quot;);\rparam = 1;\rposition = 0;\r/* now let's pack all those values into a single message */\rMPI_Pack(\u0026amp;value, 1, MPI_FLOAT, message, BUFSIZ,\r\u0026amp;position, MPI_COMM_WORLD);\r/* position has been incremented to first free byte in the message.. */\rMPI_Pack(name, STRLEN, MPI_CHAR, message, BUFSIZ,\r\u0026amp;position, MPI_COMM_WORLD);\r/* position has been incremented again.. */\rMPI_Pack(\u0026amp;param, 1, MPI_INT, message, BUFSIZ,\r\u0026amp;position, MPI_COMM_WORLD);\rMPI_Send(message, BUFSIZ, MPI_PACKED, 1, 1, MPI_COMM_WORLD);\r}\relse {\rMPI_Recv(message, BUFSIZ, MPI_PACKED, 0, 1, MPI_COMM_WORLD, NULL);\rposition = 0;\rMPI_Unpack(message, BUFSIZ, \u0026amp;position, \u0026amp;value, 1,\rMPI_FLOAT, MPI_COMM_WORLD);\r/* Note that we must know the length of string to expect here! */\rMPI_Unpack(message, BUFSIZ, \u0026amp;position, name, STRLEN,\rMPI_CHAR, MPI_COMM_WORLD);\rMPI_Unpack(message, BUFSIZ, \u0026amp;position, \u0026amp;param, 1,\rMPI_INT, MPI_COMM_WORLD);\rprintf(\u0026quot;rank %d:\\t%d %.1f %s\\n\u0026quot;, rank, param, value, name);\r}\rMPI_Finalize();\rreturn EXIT_SUCCESS;\r}\r2. 派生数据类型 MPI 提供了全面而强大的 构造函数(Constructor Function) 来定义派生数据类型。派生数据类型是一种抽象的数据结构，可以用来描述数据的组织形式，而不是数据本身。 派生数据类型可以用类型图来描述，这是一种通用的类型描述方法，它是一系列二元组\u0026lt;基类型，偏移\u0026gt;的集合，可以表示成如下格式： \u0026lt;基类型 1，偏移 1\u0026gt;，\u0026lt;基类型 2，偏移 2\u0026gt;，...，\u0026lt;基类型 n，偏移 n\u0026gt;\r在派生数据类型中，基类型可以是任何 MPI 预定义数据类型，也可以是其它的派生数据类型，即支持数据类型的嵌套定义。\n如图，阴影部分是基类型所占用的空间，其它空间可以是特意留下的，也可以是为了方便数据对齐。 基类型指出了该类型图中包括哪些基本的数据类型，而偏移则指出该基类型在整个类型图中的起始位置，基类型可以是预定义类型或派生类型，偏移可正可负，没有递增或递减的顺序要求，而一个类型图中包括的所有基类型的集合称为某类型的类型表，表示为：\n类型表={基类型 1，基类型 2，...，基类型 n}\r将类型图和一个数据缓冲区的基地址结合起来 可以说明一个通信缓冲区内的数据分布情况 预定义数据类型是通用数据类型的特例，比如 MPI_INT 是一个预先定义好了的数据类型句柄，其类型图为{(int, 0)}，有一个基类型入口项 int 和偏移 0，其它的基本数据类型与此相似，数据类型的跨度被定义为该数据类型的类型图中从第一个基类型到最后一个基类型间的距离 即如果某一个类型的类型图为: typemap={(type0,disp0),...,(typen-1,dispn-1)},\r则该类型图的下界定义为： lb(typemap)=min{dispj}, j=0,...,n-1\r该类型图的上界定义为： ub(typemap)=max{dispj+sizeof(typej)}, j=0,...,n-1\r该类型图的跨度定义为： extent(typemap)=ub(typemap)-lb(typemap) + e\r由于不同的类型有不同的对齐位置的要求 e(extent)就是能够使类型图的跨度满足该类型的类型表中的所有的类型都能达到下一个对齐要求所需要的最小非负整数值\n假设type={(double, 0), (char, 8)}，进一步假设 double 型的值必须严格分配到地址为 8 的倍数的存储空间，则该数据类型的 extent 是 16（(从 9 循环到下一个 8 的倍数)，一个由一个字符后面紧跟一个双精度值的数据类型,其 extent 也是 16\n在 MPI 中，派生数据类型的构造函数有如下几种：\n函数名 含义 MPI_Type_contiguous 定义由相同数据类型的元素组成的类型 MPI_Type_vector 定义由成块的元素组成的类型，块之间具有相同间隔 MPI_Type_indexed 定义由成块的元素组成的类型，块长度和偏移由参数指定 MPI_Type_struct 定义由不同数据类型的元素组成的类型 MPI_Type_commit 提交一个派生数据类型 MPI_Type_free 释放一个派生数据类型 （1）最简单的数据类型构造函数是 MPI_Type_contiguous ，它允许将数据类型复制到连续位置。\nint MPI_Type_contiguous(int count, MPI_Datatype oldtype,MPI_Datatype *newtype)\rcount: 重复的次数 oldtype: 基本数据类型 newtype: 派生数据类型 示例 2： MPI_Type_contiguous 的使用\n#include \u0026quot;mpi.h\u0026quot;\r#include \u0026lt;stdio.h\u0026gt;\rint main(int argc, char *argv[])\r{\rint myrank;\rMPI_Status status;\rMPI_Datatype type;\rint buffer[100];\rMPI_Init(\u0026amp;argc, \u0026amp;argv);\rMPI_Type_contiguous( 100, MPI_CHAR, \u0026amp;type );\rMPI_Type_commit(\u0026amp;type);\rMPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;myrank);\rif (myrank == 0)\r{\rMPI_Send(buffer, 1, type, 1, 123, MPI_COMM_WORLD);\r}\relse if (myrank == 1)\r{\rMPI_Recv(buffer, 1, type, 0, 123, MPI_COMM_WORLD, \u0026amp;status);\r}\rMPI_Finalize();\rreturn 0;\r}\r（2）函数 MPI_Type_vector 是一个更通用的构造函数，它允许将数据类型复制到由等间距块组成的位置。每个块都是通过连接相同数量的旧数据类型副本来获得的。块之间的间距是旧数据类型范围的倍数。\nint MPI_Type_vector(int count, int blocklength, int stride,MPI_Datatype oldtype, MPI_Datatype *newtype)\rcount: 重复的次数 blocklength: 每个块中的元素数 stride: 旧数据类型的跨度 oldtype: 基本数据类型 newtype: 派生数据类型 示例 3： MPI_Type_vector 的使用\n#include \u0026quot;mpi.h\u0026quot;\r#include \u0026lt;stdio.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\r#define SIZE 4\r/*Sendind each colum to a processor*/\rint main (int argc, char *argv[])\r{\rint numtasks, rank, source=0, dest, tag=1, i;\rfloat a[SIZE][SIZE] =\r{1.0, 2.0, 3.0, 4.0,\r5.0, 6.0, 7.0, 8.0,\r9.0, 10.0, 11.0, 12.0,\r13.0, 14.0, 15.0, 16.0};\rfloat b[SIZE];\rMPI_Status stat;\rMPI_Datatype columntype;\rMPI_Init(\u0026amp;argc,\u0026amp;argv);\rMPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank);\rMPI_Comm_size(MPI_COMM_WORLD, \u0026amp;numtasks);\rMPI_Type_vector(SIZE/*num of element in a column*/,\r1 /*one element for row*/,\rSIZE /*take an element each 4*/, MPI_FLOAT, \u0026amp;columntype);\rMPI_Type_commit(\u0026amp;columntype);\rif (numtasks == SIZE) {\rif (rank == 0) {\rfor (i=0; i\u0026lt;numtasks; i++)\rMPI_Send(\u0026amp;a[0][i], 1, columntype, i, tag, MPI_COMM_WORLD);\r}\rMPI_Recv(b, SIZE, MPI_FLOAT, source, tag, MPI_COMM_WORLD, \u0026amp;stat);\rprintf(\u0026quot;rank= %d b= %3.1f %3.1f %3.1f %3.1f\\n\u0026quot;,\rrank,b[0],b[1],b[2],b[3]);\r}\relse\rprintf(\u0026quot;Must specify %d processors. Terminating.\\n\u0026quot;,SIZE);\rMPI_Type_free(\u0026amp;columntype);\rMPI_Finalize();\r}\r（3）函数 MPI_Type_index 允许将旧数据类型复制到一系列块中(每个块是旧数据类型的串联)，其中每个块可以包含不同数量的副本，并且具有不同的位移。所有块位移都是旧类型范围的倍数。\nint MPI_Type_indexed(int count, const int array_of_blocklengths[],const int array_of_displacements[], MPI_Datatype oldtype,MPI_Datatype *newtype)\rcount: 重复的次数 array_of_blocklengths: 每个块中的元素数 array_of_displacements: 每个块的偏移量 oldtype: 基本数据类型 newtype: 派生数据类型 示例 4： MPI_Type_indexed 的使用\n#include \u0026quot;mpi.h\u0026quot;\r#include \u0026lt;stdio.h\u0026gt;\r#define NELEMENTS 6\rmain(int argc, char *argv[]) {\rint numtasks, rank, source=0, dest, tag=1, i;\rint blocklengths[2], displacements[2];\rfloat a[16] = {1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0};\rfloat b[NELEMENTS];\rMPI_Status stat;\rMPI_Datatype indextype; // required variable\rMPI_Init(\u0026amp;argc,\u0026amp;argv);\rMPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank);\rMPI_Comm_size(MPI_COMM_WORLD, \u0026amp;numtasks);\rblocklengths[0] = 4; /*take 4 elements from the array*/\rblocklengths[1] = 2; /*take 2 elemnets from the array*/\rdisplacements[0] = 5;/*start from the element index 5 the first block that is 6.0 */\rdisplacements[1] = 12;/*start from the element index 12 the first block that is 13.0 */\r// create indexed derived data type\rMPI_Type_indexed(2, blocklengths, displacements, MPI_FLOAT, \u0026amp;indextype);\rMPI_Type_commit(\u0026amp;indextype);\rif (rank == 0) {\rfor (i=0; i\u0026lt;numtasks; i++)\r// task 0 sends one element of indextype to all tasks\rMPI_Send(a, 1, indextype, i, tag, MPI_COMM_WORLD);\r}\r// all tasks receive indextype data from task 0\rMPI_Recv(b, NELEMENTS, MPI_FLOAT, source, tag, MPI_COMM_WORLD, \u0026amp;stat);\rprintf(\u0026quot;rank= %d b= %3.1f %3.1f %3.1f %3.1f %3.1f %3.1f\\n\u0026quot;,\rrank,b[0],b[1],b[2],b[3],b[4],b[5]);\r// free datatype when done using it\rMPI_Type_free(\u0026amp;indextype);\rMPI_Finalize();\r}\r（4）MPI_Type_create_struct 是最通用的类型构造函数。允许程序员定义由组件数据类型的完全定义的映射形成的新数据类型。\nint MPI_Type_create_struct(int count, const int array_of_blocklengths[],const MPI_Aint array_of_displacements[],const MPI_Datatype array_of_types[], MPI_Datatype *newtype\rcount: 重复的次数 array_of_blocklengths: 每个块中的元素数 array_of_displacements: 每个块的偏移量 array_of_types: 每个块的数据类型 newtype: 派生数据类型 示例 5：MPI_Type_create_struct 的使用\n#include \u0026quot;mpi.h\u0026quot;\r#include \u0026lt;stdio.h\u0026gt;\r#define NELEM 25\rmain(int argc, char *argv[])\r{\rint numtasks, rank, source = 0, dest, tag = 1, i;\rtypedef struct\r{\rfloat x, y, z;\rfloat velocity;\rint n, type;\r} Particle;\rParticle p[NELEM], particles[NELEM];\rMPI_Datatype particletype, oldtypes[2]; // required variables\rint blockcounts[2];\r// MPI_Aint type used to be consistent with syntax of\r// MPI_Type_extent routine\rMPI_Aint offsets[2], lb, extent;\rMPI_Status stat;\rMPI_Init(\u0026amp;argc, \u0026amp;argv);\rMPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank);\rMPI_Comm_size(MPI_COMM_WORLD, \u0026amp;numtasks);\r// setup description of the 4 MPI_FLOAT fields x, y, z, velocity\roffsets[0] = 0;\roldtypes[0] = MPI_FLOAT;\rblockcounts[0] = 4;\r// setup description of the 2 MPI_INT fields n, type\r// need to first figure offset by getting size of MPI_FLOAT\rMPI_Type_get_extent(MPI_FLOAT, \u0026amp;lb, \u0026amp;extent);\roffsets[1] = 4 * extent;\roldtypes[1] = MPI_INT;\rblockcounts[1] = 2;\r// define structured type and commit it\rMPI_Type_create_struct(2, blockcounts, offsets, oldtypes, \u0026amp;particletype);\rMPI_Type_commit(\u0026amp;particletype);\r// task 0 initializes the particle array and then sends it to each task\rif (rank == 0)\r{\rfor (i = 0; i \u0026lt; NELEM; i++)\r{\rparticles[i].x = i * 1.0;\rparticles[i].y = i * -1.0;\rparticles[i].z = i * 1.0;\rparticles[i].velocity = 0.25;\rparticles[i].n = i;\rparticles[i].type = i % 2;\r}\rfor (i = 0; i \u0026lt; numtasks; i++)\rMPI_Send(particles, NELEM, particletype, i, tag, MPI_COMM_WORLD);\r}\r// all tasks receive particletype data\rMPI_Recv(p, NELEM, particletype, source, tag, MPI_COMM_WORLD, \u0026amp;stat);\rprintf(\u0026quot;rank= %d %3.2f %3.2f %3.2f %3.2f %d %d\\n\u0026quot;, rank, p[3].x, p[3].y, p[3].z,\rp[3].velocity, p[3].n, p[3].type);\r// free datatype when done using it\rMPI_Type_free(\u0026amp;particletype);\rMPI_Finalize();\r}\r在这里，偏移量有一个问题。手动计算偏移量可能比较麻烦。虽然这种情况越来越少，但有些类型的大小会因系统/操作系统而异，因此硬编码可能会带来麻烦。一种更简洁的方法是使用标准库中的 offsetof 宏（在 C 语言中必须包含 stddef.h，在 C++ 语言中必须包含 cstddef）。它会返回一个 size_t（可隐式转换为 MPI_Aint），与该属性的偏移量相对应。于是可以将偏移量表定义为：\nMPI_Aint displacements[2] = {offsetof(Particle, x), offsetof(Particle, n)};\r","date":"2023-07-20T01:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/20230720120242.webp","permalink":"https://cuterwrite.top/p/mpi-tutorial/4/","title":"MPI 与并行计算（四）：数据类型"},{"content":"MPI 与并行计算（三）：集合通信 1. 定义 集合通信（Collective Communication）：是一个进程组中的所有进程都参加的全局通信操作。 特点： 通信空间中的所有进程都参与通信操作 每一个进程都需要调用该操作函数 数据移动类型\nBroadcast Scatter Gather AllGather Alltoall 2. 集合通信实现的功能 集合通信一般实现三个功能：通信、聚合和同步\n类型 函数名 含义 通信 MPI_Bcast 一对多广播同样的消息 通信 MPI_Gather 多对一收集各个进程的消息 通信 MPI_Gatherv MPI_Gather 的一般化 通信 MPI_Allgather 全局收集 通信 MPI_Allgatherv MPI_Allgather 的一般化 通信 MPI_Scatter 一对多散播不同的消息 通信 MPI_Scatterv MPI_Scatter 的一般化 通信 MPI_Alltoall 多对多全局交换消息 通信 MPI_Alltoallv MPI_Alltoall 的一般化 聚合 MPI_Reduce 多对一规约 聚合 MPI_Allreduce MPI_Reduce 的一般化 聚合 MPI_Scan 多对多扫描 聚合 MPI_Reduce_scatter MPI_Reduce 的一般化 同步 MPI_Barrier 路障同步 通信：集合通信，按照通信方向的不同，又可以分为三种：一对多通信，多对一通信和多对多通信。\n一对多通信：一个进程向其它所有的进程发送消息，这个负责发送消息的进程叫做 Root 进程。\n多对一通信：一个进程负责从其它所有的进程接收消息，这个接收的进程也叫做 Root 进程。\n多对多通信：每一个进程都向其它所有的进程发送或者接收消息。\n3. 一对多通信：广播 广播是一对多通信的典型例子，其调用格式为：MPI_Bcast(void *buffer, int count, MPI_Datatype datatype, int root, MPI_Comm comm) 示例 1：广播\n// bcast.c\r#include \u0026lt;stdio.h\u0026gt;\r#include \u0026lt;mpi.h\u0026gt;\rint main(int argc, char *argv[])\r{\rint rank, size;\rint data;\rMPI_Init(\u0026amp;argc, \u0026amp;argv);\rMPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank);\rMPI_Comm_size(MPI_COMM_WORLD, \u0026amp;size);\rif (rank == 0)\r{\rdata = 123;\r}\rMPI_Bcast(\u0026amp;data, 1, MPI_INT, 0, MPI_COMM_WORLD);\rprintf(\u0026quot;Process %d got data %d\\n\u0026quot;, rank, data);\rMPI_Finalize();\rreturn 0;\r}\r结果： root@ubuntu:~# mpicc bcast.c -o bcast\rroot@ubuntu:~# mpirun -n 2 ./bcast\rProcess 0 got data 123\rProcess 1 got data 123\r广播的特点 标号为 Root 的进程发送相同的消息给通信域 Comm 中的所有进程。 消息的内容如同点对点通信一样由三元组\u0026lt;Address, Count, Datatype\u0026gt;标识。 对 Root 进程来说，这个三元组既定义了发送缓冲也定义了接收缓冲。对其它进程来说，这个三元组只定义了接收缓冲 4. 多对一通信：收集 收集是多对一通信的典型例子，其调用格式为：MPI_Gather(void *sendbuf, int sendcount, MPI_Datatype sendtype, void *recvbuf, int recvcount, MPI_Datatype recvtype, int root, MPI_Comm comm) 示例 2：收集\n// gather.c\r#include \u0026lt;mpi.h\u0026gt;\r#include \u0026lt;stdio.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\rint main(int argc, char *argv[])\r{\rint rank, size;\r// 分布变量\rint data[2];\rint *buf;\rMPI_Init(\u0026amp;argc, \u0026amp;argv);\rMPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank);\rMPI_Comm_size(MPI_COMM_WORLD, \u0026amp;size);\rdata[0] = rank * 2 + 1;\rdata[1] = rank * rank * 3 + 2;\rif (rank == 0)\r{\r// 开辟接收缓存区\rbuf = malloc(2 * size * sizeof(int));\r}\rMPI_Gather(data, 2, MPI_INT, buf, 2, MPI_INT, 0, MPI_COMM_WORLD);\rif (rank == 0)\r{\rfor (int i = 0; i \u0026lt; 2 * size; i++)\r{\rprintf(\u0026quot;%d \u0026quot;, buf[i]);\r}\rprintf(\u0026quot;\\n\u0026quot;);\rfree(buf);\r}\rMPI_Finalize();\rreturn 0;\r}\r结果： root@ubuntu:~# mpicc gather.c -o gather\rroot@ubuntu:~# mpirun -n 2 ./gather\r1 2 3 5\r收集的特点 在收集操作中，Root 进程从进程域 Comm 的所有进程(包括它自已)接收消息。 这 n 个消息按照进程的标识 rank 排序进行拼接，然后存放在 Root 进程的接收缓冲中。 接收缓冲由三元组\u0026lt;RecvAddress, RecvCount, RecvDatatype\u0026gt;标识，发送缓冲由三元组\u0026lt;SendAddress, SendCount, SendDatatype\u0026gt;标识，所有非 Root 进程忽略接收缓冲。 5. 一对多通信：散播 散播是一个一对多操作，其调用格式为：MPI_Scatter(void *sendbuf, int sendcount, MPI_Datatype sendtype, void *recvbuf, int recvcount, MPI_Datatype recvtype, int root, MPI_Comm comm) 示例 3：散播\n// scatter.c\r#include \u0026lt;mpi.h\u0026gt;\r#include \u0026lt;stdio.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\rint main(int argc, char *argv[])\r{\rint rank, size;\rint *buf;\rint data[2];\rMPI_Init(\u0026amp;argc, \u0026amp;argv);\rMPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank);\rMPI_Comm_size(MPI_COMM_WORLD, \u0026amp;size);\rif (rank == 0)\r{\rbuf = malloc(2 * size * sizeof(int));\rfor (int i = 0; i \u0026lt; 2 * size; i++)\r{\rbuf[i] = i;\r}\r}\rMPI_Scatter(buf, 2, MPI_INT, data, 2, MPI_INT, 0, MPI_COMM_WORLD);\rprintf(\u0026quot;rank = %d, data = %d %d\\n\u0026quot;, rank, data[0], data[1]);\rif (rank == 0)\r{\rfree(buf);\r}\rMPI_Finalize();\rreturn 0;\r}\r结果： root@ubuntu:~# mpicc scatter.c -o scatter\rroot@ubuntu:~# mpirun -n 2 ./scatter\rrank = 0, data = 0 1\rrank = 1, data = 2 3\r散播的特点 Scatter 执行与 Gather 相反的操作。 Root 进程给所有进程(包括它自已)发送一个不同的消息，这 n (n 为进程域 comm 包括的进程个数)个消息在 Root 进程的发送缓冲区中按进程标识的顺序有序地存放。 每个接收缓冲由三元组\u0026lt;RecvAddress, RecvCount, RecvDatatype\u0026gt;标识，所有的非 Root 进程忽略发送缓冲。对 Root 进程，发送缓冲由三元组\u0026lt;SendAddress,SendCount, SendDatatype\u0026gt;标识。 6. 聚合 集合通信的聚合功能使得 MPI 进行通信的同时完成一定的计算。 MPI 聚合的功能分三步实现： 首先是通信的功能，即消息根据要求发送到目标进程，目标进程也已经收到了各自需要的消息 然后是对消息的处理，即执行计算功能 最后把处理结果放入指定的接收缓冲区 MPI 提供了两种类型的聚合操作: 归约(Reduce)和扫描(Scan)。 7. 同步 同步功能用来协调各个进程之间的进度和步伐 。目前 MPI 的实现中支持一个同步操作，即路障同步(Barrier)。 路障同步的调用格式为：MPI_Barrier(MPI_Comm comm) 在路障同步操作MPI_Barrier(Comm)中，通信域 Comm 中的所有进程相互同步。 在该操作调用返回后，可以保证组内所有的进程都已经执行完了调用之前的所有操作，可以开始该调用后的操作。 8. 规约 MPI_REDUCE 将组内每个进程输入缓冲区中的数据按给定的操作 op 进行运算，并将其结果返回到序列号为 root 的进程的输出缓冲区中，输入缓冲区由参数 sendbuf、count 和 datatype 定义，输出缓冲区由参数 recvbuf count 和 datatype 定义，要求两者的元素数目和类型都必须相同，因为所有组成员都用同样的参数 count、datatype、op、root 和 comm 来调用此例程 故而所有进程都提供长度相同、元素类型相同的输入和输出缓冲区，每个进程可能提供一个元素或一系列元素 组合操作依次针对每个元素进行。\n操作 op 始终被认为是可结合的 并且所有 MPI 定义的操作被认为是可交换的，用户自定义的操作被认为是可结合的，但可以不是可交换的。MPI 中已经定义好的一些操作,它们是为函数MPI_Reduce 和一些其他的相关函数,如MPI_Allreduce、MPI_Reduce_scatter 和MPI_Scan 而定义的 这些操作用来设定相应的 op。\nMPI 预定的归约操作如下:\n操作 含义 操作 含义 MPI_MAX 最大值 MPI_MIN 最小值 MPI_SUM 求和 MPI_PROD 求积 MPI_LAND 逻辑与 MPI_BAND 按位与 MPI_LOR 逻辑或 MPI_BOR 按位或 MPI_LXOR 逻辑异或 MPI_BXOR 按位异或 MPI_MAXLOC 最大值和位置 MPI_MINLOC 最小值和位置 示例 4：计算 pi 值\n// reduce.c\r#include \u0026lt;math.h\u0026gt;\r#include \u0026lt;mpi.h\u0026gt;\r#include \u0026lt;stdio.h\u0026gt;\rdouble f(double);\rdouble f(double x)\r{\rreturn 4.0 / (1.0 + x * x);\r}\rint main(int argc, char **argv)\r{\rint done = 0, n, myid, numprocs, i;\rdouble PI25DT = 3.141592653589793238462643;\rdouble mypi, pi, h, sum, x;\rdouble startwtime = 0.0, endwtime;\rint namelen;\rchar process_name[MPI_MAX_PROCESSOR_NAME];\rMPI_Init(\u0026amp;argc, \u0026amp;argv);\rMPI_Comm_size(MPI_COMM_WORLD, \u0026amp;numprocs);\rMPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;myid);\rMPI_Get_processor_name(process_name, \u0026amp;namelen);\rfprintf(stdout, \u0026quot;Process %d of %d is on %s\\n\u0026quot;, myid, numprocs, process_name);\rn = 0;\rif (myid == 0)\r{\rfprintf(stdout, \u0026quot;Enter the number of intervals: (0 quits) \u0026quot;);\rfflush(stdout);\rscanf(\u0026quot;%d\u0026quot;, \u0026amp;n);\rstartwtime = MPI_Wtime();\r}\r/* 将 n 广播给所有进程 */\rMPI_Bcast(\u0026amp;n, 1, MPI_INT, 0, MPI_COMM_WORLD);\r/* 矩形宽度 */\rh = 1.0 / (double)n;\r/* 矩形面积初值 */\rsum = 0.0;\r/* 每个进程计算自己的部分 */\rfor (i = myid + 1; i \u0026lt;= n; i += numprocs)\r{\rx = h * ((double)i - 0.5);\rsum += f(x);\r}\r/* 各个进程并行计算得到的和 */\rmypi = h * sum;\rMPI_Reduce(\u0026amp;mypi, \u0026amp;pi, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD);\r/* 将部分和累加得到最终结果 */\rif (myid == 0)\r{\rprintf(\u0026quot;pi is approximately %.16f, Error is %.16f\\n\u0026quot;, pi, fabs(pi - PI25DT));\rendwtime = MPI_Wtime();\rprintf(\u0026quot;wall clock time = %f\\n\u0026quot;, endwtime - startwtime);\rfflush(stdout);\r}\rMPI_Finalize();\rreturn 0;\r}\r","date":"2023-07-19T15:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/20230720002052.webp","permalink":"https://cuterwrite.top/p/mpi-tutorial/3/","title":"MPI 与并行计算（三）：集合通信"},{"content":"MPI 与并行计算（二）：点到点通信 1. MPI 的通信模式 通信模式：指的是缓冲管理以及发送方和接收方之间的同步方式。 MPI 支持四种通信模式：标准通信模式、缓冲通信模式、就绪通信模式和同步通信模式 2. 标准通信模式：MPI_Send 和 MPI_Recv 由 MPI 决定是否缓冲消息 没有足够的系统缓冲区时或出于性能的考虑， MPI 可能进行直接拷贝： 仅当相应的接收开始后，发送语句才能返回 MPI 缓冲消息：发送语句地相应的接收语句完成前返回 发送的结束 == 消息已从发送方发出，而不是滞留在发送方的系统缓冲区中 非本地的：发送操作的成功与否依赖于接收操作 理论上要求有接收进程的 recv 调用配合，发送函数是MPI_Send()。 示例 1：标准通信模式\n#include \u0026lt;mpi.h\u0026gt;\r#include \u0026lt;iostream\u0026gt;\r#include \u0026lt;thread\u0026gt;\r#define BUF_SIZE 10\rint main(int argc, char *argv[])\r{\rint myid, numprocs;\rint other;\rint sb[BUF_SIZE];\rint rb[BUF_SIZE];\r// 初始化 MPI 环境\rMPI_Init(\u0026amp;argc, \u0026amp;argv);\rMPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;myid);\rMPI_Comm_size(MPI_COMM_WORLD, \u0026amp;numprocs);\rMPI_Status status;\rfor (int i = 0; i \u0026lt; BUF_SIZE; i++)\r{\rsb[i] = myid + i;\r}\rif (myid == 0)\r{\rother = 1;\r}\relse if (myid == 1)\r{\rother = 0;\r}\rif (myid == 0)\r{\rstd::cout \u0026lt;\u0026lt; \u0026quot;process \u0026quot; \u0026lt;\u0026lt; myid \u0026lt;\u0026lt; \u0026quot; tring send...\u0026quot; \u0026lt;\u0026lt; std::endl;\rMPI_Send(sb, BUF_SIZE, MPI_INT, other, 1, MPI_COMM_WORLD);\rstd::cout \u0026lt;\u0026lt; \u0026quot;process \u0026quot; \u0026lt;\u0026lt; myid \u0026lt;\u0026lt; \u0026quot; tring receiving...\u0026quot; \u0026lt;\u0026lt; std::endl;\rMPI_Recv(rb, BUF_SIZE, MPI_INT, other, 1, MPI_COMM_WORLD, \u0026amp;status);\r}\relse if (myid == 1)\r{\r// sleep 10s, 与缓冲通信模式相比，这里的发送和接收操作是阻塞的\rstd::this_thread::sleep_for(std::chrono::seconds(10));\rstd::cout \u0026lt;\u0026lt; \u0026quot;process \u0026quot; \u0026lt;\u0026lt; myid \u0026lt;\u0026lt; \u0026quot; tring receiving...\u0026quot; \u0026lt;\u0026lt; std::endl;\rMPI_Recv(rb, BUF_SIZE, MPI_INT, other, 1, MPI_COMM_WORLD, \u0026amp;status);\rstd::cout \u0026lt;\u0026lt; \u0026quot;process \u0026quot; \u0026lt;\u0026lt; myid \u0026lt;\u0026lt; \u0026quot; tring send...\u0026quot; \u0026lt;\u0026lt; std::endl;\rMPI_Send(sb, BUF_SIZE, MPI_INT, other, 1, MPI_COMM_WORLD);\r}\rstd::cout \u0026lt;\u0026lt; \u0026quot;Hello World! Process \u0026quot; \u0026lt;\u0026lt; myid \u0026lt;\u0026lt; \u0026quot; of \u0026quot; \u0026lt;\u0026lt; numprocs \u0026lt;\u0026lt; std::endl;\rstd::cout \u0026lt;\u0026lt; \u0026quot;Send buffer: \u0026quot; \u0026lt;\u0026lt; std::endl;\rfor (int i = 0; i \u0026lt; BUF_SIZE; i++)\r{\rstd::cout \u0026lt;\u0026lt; sb[i] \u0026lt;\u0026lt; \u0026quot; \u0026quot;;\r}\rstd::cout \u0026lt;\u0026lt; std::endl;\rstd::cout \u0026lt;\u0026lt; \u0026quot;Receive buffer: \u0026quot; \u0026lt;\u0026lt; std::endl;\rfor (int i = 0; i \u0026lt; BUF_SIZE; i++)\r{\rstd::cout \u0026lt;\u0026lt; rb[i] \u0026lt;\u0026lt; \u0026quot; \u0026quot;;\r}\rstd::cout \u0026lt;\u0026lt; std::endl;\rMPI_Finalize();\rreturn 0;\r}\r运行结果： root@ubuntu:~# mpicxx -o mpi mpi.cpp\rroot@ubuntu:~# mpirun -n 2 ./mpi\rprocess 0 tring send...\rprocess 0 tring receiving...\rprocess 1 tring receiving...\rprocess 1 tring send...\rHello World! Process 1 of 2\rSend buffer:\r1 2 3 4 5 6 7 8 9 10\rReceive buffer:\r0 1 2 3 4 5 6 7 8 9\rHello World! Process 0 of 2\rSend buffer:\r0 1 2 3 4 5 6 7 8 9\rReceive buffer:\r1 2 3 4 5 6 7 8 9 10\r这就是点对点通信的基本用法，通过发送和接收操作，进程之间可以进行数据交换和协调工作。 3. 缓冲通信模式 前提: 用户显示地指定用于缓冲消息的系统缓冲区MPI_Buffer_attach(*buffer, *size) 。 发送是本地的: 完成不依赖于与其匹配的接收操作。 发送的结束仅表明消息进入系统的缓冲区中，发送缓冲区可以重用，而对接收方的情况并不知道。 缓冲模式在相匹配的接收未开始的情况下，总是将送出的消息放在缓冲区内，这样发送者可以很快地继续计算,然后由系统处理放在缓冲区中的消息。 占用内存，一次内存拷贝。 函数调用形式为：MPI_Bsend()。B 表示缓冲，缓冲通信模式主要用于解开阻塞通信的发送与接收之间的耦合。 作用总结：通常情况下，MPI 发送和接收操作是阻塞的，即发送操作会等待接收方准备好接收，接收操作会等待发送方发送数据。但是，MPI 提供了一种称为缓冲区（buffering）的机制，可以使发送操作立即返回，而不需要等待接收方准备好。 示例 2：缓冲通信模式\n#include \u0026lt;mpi.h\u0026gt;\r#include \u0026lt;iostream\u0026gt;\r#include \u0026lt;thread\u0026gt;\rint main(int argc, char **argv)\r{\rint myid, numprocs;\r// 初始化\rMPI_Init(\u0026amp;argc, \u0026amp;argv);\rMPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;myid);\rMPI_Comm_size(MPI_COMM_WORLD, \u0026amp;numprocs);\rint s1, s2;\r// 取缓冲区的上界，以字节为单位\rMPI_Pack_size(7, MPI_CHAR, MPI_COMM_WORLD, \u0026amp;s1);\rMPI_Pack_size(2, MPI_DOUBLE, MPI_COMM_WORLD, \u0026amp;s2);\rint buffer_size = 2 * MPI_BSEND_OVERHEAD + s1 + s2;\rchar *buffer = new char[buffer_size];\r// 装配一个用于通信的缓冲区\rMPI_Buffer_attach(buffer, buffer_size);\rchar msg1[7] = \u0026quot;Hello\u0026quot;;\rdouble msg2[2] = {1.0, 2.0};\rchar rmsg1[7];\rdouble rmsg2[2];\rif (myid == 0)\r{\rMPI_Bsend(msg1, 7, MPI_CHAR, 1, 1, MPI_COMM_WORLD);\rMPI_Bsend(msg2, 2, MPI_DOUBLE, 1, 2, MPI_COMM_WORLD);\rstd::cout \u0026lt;\u0026lt; \u0026quot;Send msg1: \u0026quot; \u0026lt;\u0026lt; msg1 \u0026lt;\u0026lt; std::endl;\rstd::cout \u0026lt;\u0026lt; \u0026quot;Send msg2: \u0026quot; \u0026lt;\u0026lt; msg2[0] \u0026lt;\u0026lt; \u0026quot; \u0026quot; \u0026lt;\u0026lt; msg2[1] \u0026lt;\u0026lt; std::endl;\r}\relse if (myid == 1)\r{\r// sleep 10s\rstd::this_thread::sleep_for(std::chrono::seconds(10));\rMPI_Recv(rmsg1, 7, MPI_CHAR, 0, 1, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\rMPI_Recv(rmsg2, 2, MPI_DOUBLE, 0, 2, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\rstd::cout \u0026lt;\u0026lt; \u0026quot;Receive msg1: \u0026quot; \u0026lt;\u0026lt; rmsg1 \u0026lt;\u0026lt; std::endl;\rstd::cout \u0026lt;\u0026lt; \u0026quot;Receive msg2: \u0026quot; \u0026lt;\u0026lt; rmsg2[0] \u0026lt;\u0026lt; \u0026quot; \u0026quot; \u0026lt;\u0026lt; rmsg2[1] \u0026lt;\u0026lt; std::endl;\r}\rMPI_Buffer_detach(\u0026amp;buffer, \u0026amp;buffer_size);\rfree(buffer);\rMPI_Finalize();\rreturn 0;\r}\r运行结果： root@ubuntu:~# mpicxx -o mpi mpi.cpp\rroot@ubuntu:~# mpirun -n 2 ./mpi\rSend msg1: Hello\rSend msg2: 1 2\rReceive msg1: Hello\rReceive msg2: 1 2\r4. 就绪通信模式 发送请求仅当有匹配的接收后才能发出，否则出错。在就绪模式下，系统默认与其相匹配的接收已经调用。 接收必须先于发送。 它不可以不依赖于接收方的匹配的接收请求而任意发出 其函数调用形式为：MPI_RSend()。R 表示就绪，仅当对方的接收操作启动并准备就绪时，才可以发送数据。 示例 3：就绪通信模式\n#include \u0026lt;mpi.h\u0026gt;\r#include \u0026lt;iostream\u0026gt;\rint main(int argc, char **argv)\r{\rint myid, numprocs;\r// 初始化\rMPI_Init(\u0026amp;argc, \u0026amp;argv);\rMPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;myid);\rMPI_Comm_size(MPI_COMM_WORLD, \u0026amp;numprocs);\rMPI_Status status;\rint buffer[10];\rif (myid == 0)\r{\rfor (int i = 0; i \u0026lt; 10; i++)\r{\rbuffer[i] = -1;\r}\rMPI_Recv(buffer, 10, MPI_INT, 1, 1, MPI_COMM_WORLD, \u0026amp;status);\rfor (int i = 0; i \u0026lt; 10; i++)\r{\rif (buffer[i] != i)\r{\rstd::cout \u0026lt;\u0026lt; \u0026quot;error\u0026quot; \u0026lt;\u0026lt; std::endl;\rbreak;\r}\r}\r}\relse if (myid == 1)\r{\rfor (int i = 0; i \u0026lt; 10; i++)\r{\rbuffer[i] = i;\r}\rMPI_Rsend(buffer, 10, MPI_INT, 0, 1, MPI_COMM_WORLD);\r}\rMPI_Finalize();\rreturn 0;\r}\r5. 同步通信模式 本质特征：收方接收该消息的缓冲区已准备好， 不需要附加的系统缓冲区 任意发出：发送请求可以不依赖于收方的匹配的接收请求而任意发出 成功结束： 仅当收方已发出接收该消息的请求后才成功返回，否则将阻塞。意味着： 发送方缓冲区可以重用 收方已发出接收请求 是非本地的 函数调用形式为：MPI_Ssend()。S 表示同步。 示例 4：同步通信模式\n#include \u0026lt;mpi.h\u0026gt;\r#include \u0026lt;iostream\u0026gt;\rint main(int argc, char **argv)\r{\rint myid, numprocs;\r// 初始化\rMPI_Init(\u0026amp;argc, \u0026amp;argv);\rMPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;myid);\rMPI_Comm_size(MPI_COMM_WORLD, \u0026amp;numprocs);\rMPI_Status status;\rint buffer[10];\rif (myid == 0)\r{\rfor (int i = 0; i \u0026lt; 10; i++)\r{\rbuffer[i] = -1;\r}\rMPI_Recv(buffer, 10, MPI_INT, 1, 1, MPI_COMM_WORLD, \u0026amp;status);\rstd::cout \u0026lt;\u0026lt; \u0026quot;process \u0026quot; \u0026lt;\u0026lt; myid \u0026lt;\u0026lt; \u0026quot; receiving...\u0026quot; \u0026lt;\u0026lt; std::endl;\rfor (int i = 0; i \u0026lt; 10; i++)\r{\rif (buffer[i] != i)\r{\rstd::cout \u0026lt;\u0026lt; \u0026quot;error\u0026quot; \u0026lt;\u0026lt; std::endl;\rbreak;\r}\r}\r}\relse if (myid == 1)\r{\rfor (int i = 0; i \u0026lt; 10; i++)\r{\rbuffer[i] = i;\r}\rstd::cout \u0026lt;\u0026lt; \u0026quot;process \u0026quot; \u0026lt;\u0026lt; myid \u0026lt;\u0026lt; \u0026quot; sending...\u0026quot; \u0026lt;\u0026lt; std::endl;\rMPI_Ssend(buffer, 10, MPI_INT, 0, 1, MPI_COMM_WORLD);\r}\rMPI_Finalize();\rreturn 0;\r}\r6. 阻塞通信与非阻塞通信 阻塞通信调用时，整个程序只能执行通信相关的内容，而无法执行计算相关的内容；非阻塞调用的初衷是尽量让通信和计算重叠进行，提高程序整体执行效率。\n非阻塞通信调用返回意味着通信开始启动；而非阻塞通信完成则需要调用其他的接口来查询。\n非阻塞通信的调用接口 非阻塞通信的完成查询接口 非阻塞通信的发送和接受过程都需要同时具备以上两个要素：调用与完成。（1）”调用“按照通信方式的不同（标准、缓存、同步、就绪），有各种函数接口；（2）”完成“是重点，因为程序员需要知道非阻塞调用是否执行完成了，来做下一步的操作。\nMPI 为“完成”定义了一个内部变量 MPI_Request request，每个 request 与一个在非阻塞调用发生时与该调用发生关联（这里的调用包括发送和接收）。“完成”不区分通信方式的不同，统一用 MPI_Wait 系列函数来完成。\nMPI_Wait(MPI_Request *request)，均等着 request 执行完毕了，再往下进行 对于非重复非阻塞通信，MPI_Wait 系列函数调用的返回，还意味着 request 对象被释放了，程序员不用再显式释放 request 变量。 对于重复非阻塞通信，MPI_Wait 系列函数调用的返回，意味着将于 request 对象关联的非阻塞通信处于不激活状态，并不释放 request MPI_Wait 会迫使进程进入“阻塞模式”。发送过程将简单地等待请求完成。如果进程在 MPI_Isend 之后立即等待，则 Send 与调用 MPI_Send 相同。等待 MPI_WAIT 和 MPI_WAITANY 有两种方式 int MPI_Wait(MPI_Request *request, MPI_Status *status);\rint MPI_Waitany(int count, MPI_Request array_of_requests[], int *index, MPI_Status *status);\r前者 MPI_WAIT 只是等待给定请求的完成。请求一完成，就会返回一个状态为 MPI_STATUS 的实例。后者MPI_Waitany 等待一系列请求中的第一个完成的请求继续。一旦请求完成，INDEX 的值被设置为存储 ARRAY_OF_REQUESTS 中已完成请求的索引。该调用还存储已完成请求的状态。\n对于阻塞通信，如果不想跟踪此信息，可以将指向 MPI_STATUS 实例的指针替换为 MPI_STATUS_IGNORE。\n正如我们之前看到的，等待会阻止进程，直到请求（或某个请求）被满足。测试则是检查请求是否可以完成。如果可以，请求将自动完成并传输数据。关于等待，有两种测试等待：MPI_Test 和 MPI_Testany。它们的调用方式如下\nint MPI_Test(MPI_Request *request, int *flag, MPI_Status *status);\rint MPI_Testany(int count, MPI_Request array_of_requests[], int *index, int *flag, MPI_Status *status);\r让我们从 MPI_Test 开始。至于 MPI_Wait，参数 request 和 status 并不神秘。请记住，测试是非阻塞的，因此在任何情况下，调用后进程都会继续执行。变量 flag 的作用是告诉你请求是否在测试过程中完成。如果 flag != 0 表示请求已完成 MPI_Testany 现在应该是完全显而易见的。如果有任何请求可完成，它会将 FLAG 设置为非零值。如果是这样的话，状态和索引也被赋予一个值 7. 非阻塞的发送和接收 int MPI_Isend(void *buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm, MPI_Request *request) buf: 发送缓冲区的起始地址 count: 发送数据的个数 datatype: 发送数据的类型 dest: 目标进程的 rank tag: 消息标签 comm: 通信子 request: 非阻塞通信完成对象 MPI_Ibsend/MPI_Issend/MPI_Irsend: 缓冲/同步/就绪通信的非阻塞发送 int MPI_Irecv(void *buf, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm comm, MPI_Request *request) 示例 5：非阻塞通信\nvoid play_non_blocking_scenario()\r{\rMPI_Request request;\rMPI_Status status;\rint request_finished = 0;\r// Initialising buffer :\rfor (int i = 0; i \u0026lt; buffer_count; ++i)\r{\rbuffer[i] = (rank == 0 ? i * 2 : 0);\r}\rMPI_Barrier(MPI_COMM_WORLD);\r// Starting the chronometer\rdouble time = -MPI_Wtime();\rif (rank == 0)\r{\rsleep(3);\r// 1- Initialise the non-blocking send to process 1\r// [...]\rMPI_Isend(buffer, buffer_count, MPI_INT, 1, 0, MPI_COMM_WORLD, \u0026amp;request);\rdouble time_left = 6000.0;\rwhile (time_left \u0026gt; 0.0)\r{\rusleep(1000); // We work for 1ms\r// 2- Test if the request is finished (only if not already finished)\r// [...]\rif (!request_finished)\r{\rMPI_Test(\u0026amp;request, \u0026amp;request_finished, \u0026amp;status);\r}\r// 1ms left to work\rtime_left -= 1000.0;\r}\r// 3- If the request is not yet complete, wait here.\r// [...]\rif (!request_finished)\r{\rMPI_Wait(\u0026amp;request, \u0026amp;status);\r}\r// Modifying the buffer for second step\rfor (int i = 0; i \u0026lt; buffer_count; ++i)\r{\rbuffer[i] = -i;\r}\r// 4- Prepare another request for process 1 with a different tag\r// [...]\rMPI_Isend(buffer, buffer_count, MPI_INT, 1, 1, MPI_COMM_WORLD, \u0026amp;request);\rtime_left = 3000.0;\rwhile (time_left \u0026gt; 0.0)\r{\rusleep(1000); // We work for 1ms\r// 5- Test if the request is finished (only if not already finished)\r// [...]\rif (!request_finished)\r{\rMPI_Wait(\u0026amp;request, \u0026amp;status);\r}\r// 1ms left to work\rtime_left -= 1000.0;\r}\r// 6- Wait for it to finish\r// [...]\rif (!request_finished)\r{\rMPI_Wait(\u0026amp;request, \u0026amp;status);\r}\r}\relse\r{\r// Work for 5 seconds\rsleep(5);\r// 7- Initialise the non-blocking receive from process 0\r// [...]\rMPI_Irecv(buffer, buffer_count, MPI_INT, 0, 0, MPI_COMM_WORLD, \u0026amp;request);\r// 8- Wait here for the request to be completed\r// [...]\rMPI_Wait(\u0026amp;request, \u0026amp;status);\rprint_buffer();\r// Work for 3 seconds\rsleep(3);\r// 9- Initialise another non-blocking receive\r// [...]\rMPI_Irecv(buffer, buffer_count, MPI_INT, 0, 1, MPI_COMM_WORLD, \u0026amp;request);\r// 10- Wait for it to be completed\r// [...]\rMPI_Wait(\u0026amp;request, \u0026amp;status);\rprint_buffer();\r}\r// Stopping the chronometer\rtime += MPI_Wtime();\r// This line gives us the maximum time elapsed on each process.\rdouble final_time;\rMPI_Reduce(\u0026amp;time, \u0026amp;final_time, 1, MPI_DOUBLE, MPI_MAX, 0, MPI_COMM_WORLD);\rif (rank == 0)\r{\rstd::cout \u0026lt;\u0026lt; \u0026quot;Total time for non-blocking scenario : \u0026quot; \u0026lt;\u0026lt; final_time \u0026lt;\u0026lt; \u0026quot;s\u0026quot; \u0026lt;\u0026lt; std::endl;\r}\r}\r8. 探测 Probe 探测实际上非常有用，它有很多用途，例如获取即将接收的元素数量、接收进程的 ID 和标记，或者是否真的接收到了任何信息。 用于探测的函数有两个：MPI_Probe 和 MPI_IProbe。第一个是阻塞调用，而第二个则不是。现在，MPI_Probe 只会给出与收到的下一条消息相关的 MPI_Status 值，该消息对应于某个标签和 ID。如果想探测任何类型或来自任何来源的消息接收情况，可以使用 MPI_ANY_SOURCE 和 MPI_ANY_TAG。然后，可以将生成的 MPI_Status 对象与其他函数结合使用，以获取更多信息。 示例 6：探测\nvoid probing_process(int \u0026amp;int_sum, float \u0026amp;float_sum) {\rMPI_Status status;\r// 1- Probe the incoming message\rMPI_Probe(MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, \u0026amp;status);\r// 2- Get the tag and the source\rint tag = status.MPI_TAG;\rint source = status.MPI_SOURCE;\r// Printing the message\rstd::cout \u0026lt;\u0026lt; \u0026quot;Received a message from process \u0026quot; \u0026lt;\u0026lt; source \u0026lt;\u0026lt; \u0026quot; with tag \u0026quot; \u0026lt;\u0026lt; tag \u0026lt;\u0026lt; std::endl;\r// 3- Add to int_sum or float_sum depending on the tag of the message\rif (tag == 0) {\rint other;\rMPI_Recv(\u0026amp;other, 1, MPI_INT, source, tag, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\rint_sum += other;\r} else if (tag == 1) {\rfloat other;\rMPI_Recv(\u0026amp;other, 1, MPI_FLOAT, source, tag, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\rfloat_sum += other;\r}\r}\r9. 总结 理解各种模式通信过程的行为，关键是弄清楚各个模式对缓冲使用的方式。简而言之，各个模式使用缓冲的特点可总结为：标准的 Send 实际利用了 MPI 环境提供的默认缓冲区；Bsend 实际相当于将 MPI 环境提供的 buffer 放在用户空间管理；Rsend 实际相当于不要缓冲区，但发送端不能提前等待；Ssend 实际也相当于不要缓冲区，但允许等待；异步方式下各个模式工作原理也是类似的，只不过可将其理解为 MPI 环境会另起一个线程在后台做实际的消息传输，通过 Wait、Test 等机制与 MPI 进程的主线程进行通信和同步。\n通信模式 阻塞型 非阻塞型 缓冲方式 发送方等待 接收方等待 是否本地 是否阻塞 标准通信 MPI_Send MPI_Isend MPI 环境提供的默认缓冲区 是 是 是 是 缓冲通信 MPI_Bsend MPI_Ibsend 用户空间管理 否 是 是 是 就绪通信 MPI_Rsend MPI_Irsend 无 否 是 否 是 同步通信 MPI_Ssend MPI_Issend 无 否 是 否 是 ","date":"2023-07-19T13:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/20230719212254.webp","permalink":"https://cuterwrite.top/p/mpi-tutorial/2/","title":"MPI 与并行计算（二）：点到点通信"},{"content":"MPI 与并行计算（一）：并行环境及编程模型 1. 什么是 MPI Massage Passing Interface：是消息传递函数库的标准规范，由 MPI 论坛开发，支持 Fortran 和 C。\n一种新的库描述，不是一种语言。共有上百个函数调用接口，在 Fortran 和 C 语言中可以直接对这些函数进行调用。 MPI 是一种标准或规范的代表，而不是特指某一个对它的具体实现。迄今为止所有的并行计算机制造商都提供对 MPI 的支持。 Intel MPI OpenMPI mpich MPI 是一种消息传递编程模型，并成为这种编程模型的代表和事实上的标准。 2. MPI 的发展过程 MPI 1.1：1995 MPICH:是 MPI 最流行的非专利实现,由 Argonne 国家实验室和密西西比州立大学联合开发,具有更好的可移植性. MPI 1.2~2.0：动态进程, 并行 I/O, 支持 F90 和 C++(1997) 3. 为什么要用 MPI 高可移植性：MPI 已在 IBM PC 机上、 MS Windows 上、所有主要的 Unix 工作站上和所有主流的并行机上得到实现。使用 MPI 作消息传递的 C 或 Fortran 并行程序可不加改变地运行在 IBMPC、 MS Windows、 Unix 工作站、以及各种并行机上。 4. 并行编程模式 隐式并行：借助编译器和运行时环境的支持发掘程序的并行性，对串行程序进行并行化。 数据并行：数据并行依靠所处理的数据集合无关性，借助数据划分来驱动程序之间的并行执行。 消息传递：消息传递模型可以通过如下的几个概念加以定义： 一组仅有本地内存空间的进程 进程之间通过发送和接收消息进行通信 进程之间需要使用协同操作完成数据传递，如发送操作必须要求有与之配对的接收操作 共享变量：并行代码分别驻留在不同的处理器上，通过读写公共存储器中的共享变量进行同步和通信，一般适合在多核系统，SMP 系统上运行。分布式存储系统可以在运行时库支持下通过自定义机制以共享变量的方式运行。 5. MPI 的工作模式 运行方式：以串行方式编写，运行时分别执行不同的块。 资源分配：所有程序元素只要没有进行显示区分，无论是代码、函数、全局变量还是局部变量，都默认的由全部进程共同拥有，所有进程看到的虽然是相同的名字，但在“物理”上却彼此无关。 显示区分：就是指程序员需在程序设计阶段通过显示的条件判断来指定在不同进程上运行不同的代码块。这正是 MPI 程序的特点，也恰好是难点之一。 一个典型的 MPI 程序代码模式如下：\n// Inititalization code block\rif (rank == process1) {\r// define works to be carried out by process1\r} else if (rank == process2) {\r// define works to be carried out by process2\r} else if (rank == process3) {\r// define works to be carried out by process3\r} else if (rank == process4) {\r// define works to be carried out by process4\r}...else if (rank == processn) {\r// define works to be carried out by processn\r} else {\r// define works to be carried out by all processes\r}\r6. MPI 消息传递通信的基本概念 消息：一个消息可以比做一个封信。需要定义消息的内容以及消息的发送与接收者。前者称为消息的缓冲(Message Buffer)，后者称为消息信封(Message Envelop)。在 MPI 中，消息缓冲由三元组\u0026lt;起始地址，数据个数，数据类型\u0026gt;来标识，而消息信封则是由三元组\u0026lt;源/目标进程，消息标签，通讯域\u0026gt;来标识。如下为MPI_Send 的消息缓冲和消息信封。 缓冲区：MPI 环境定义了 3 种缓冲区：应用缓冲区，系统缓冲区和用户向系统注册的缓冲区。\n应用缓冲区：保存将要发送或接收的消息内容即上述的消息缓冲。 系统缓冲区：MPI 环境为通信所准备的存储空间。 用户缓冲区：指用户向系统注册的缓冲区，用户使用某些 API(如MPI_Bsend)时，在程序中显示申请的存储空间，然后注册到 MPI 环境中供通信所用。 通信子：MPI 环境管理进程及通信的基本设施。MPI_COMM_WORLD 就是 MPI 环境启动时默认创建的通信子。对某个进程的操作必须放在通信子内方可有效。\n进程号：进程号即进程的rank，指在某个通信子内某个进程号 rank 为 num。在一个通信子内，每一个进程都有它唯一的 num，这个标识号是在进程初始化时由系统分配，从 0 开始编号。\n进程组：定义一个通信子，也就指定了一组共享该空间的进程，这些进程组成了该通信子的进程组(group)。\n通信协议：MPI 环境依据实现的策略不同，可能采用如下一种或几种协议。\n立即通信协议，总是假定目标进程具有保存消息数据的能力。 集中通信协议，在目标准备好之后，才可以执行发送动作。 短消息协议，消息数据与信封封装在一起发送。 7. MPI 程序编译、运行 MPI 环境安装： 更新 apt 源：sudo apt-get update 安装 build-essential：sudo apt-get install -y build-essential 安装 mpich: sudo apt-get install -y mpich MPI 程序编译：mpicc Intel MPI Mpich/OpenMPI Fortran mpiifort mpi90 C mpiicc mpicc C++ mpiicpc mpicxx mpicc 编译示例\nmpicc -o mpi mpi.c\rMPI 程序运行：mpirun 使用 mpirun 来运行 mpi 程序（intel mpi、mpich、openmpi 等） 用法：mpirun -n 进程数 可执行文件名 示例：mpirun -n 2 ./example 第一个 MPI 程序示例 - Hello World\n// mpi.c\r#include \u0026lt;mpi.h\u0026gt;\r#include \u0026lt;stdio.h\u0026gt;\rint main(int argc, char **argv)\r{\rMPI_Init(\u0026amp;argc, \u0026amp;argv);\rprintf(\u0026quot;Hello World!\\n\u0026quot;);\rMPI_Finalize();\rreturn 0;\r}\r编译与运行 mpi.c mpicc -o mpi mpi.c\rmpirun -n 2 ./mpi\r注意： root 用户运行 mpirun 时，需要加上\u0026ndash;allow-run-as-root 参数，否则会报错。\n8. MPI 的四个基本接口 接口名 功能 MPI_Init(\u0026amp;argc, \u0026amp;argv) 初始化 MPI 环境，MPI 系统将通过 argc, argv 得到命令行参数 MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;myrank) 缺省的通信子为 MPI_COMMON_WORLD，获得进程所在缺省通信子的编号，赋值给 myrank MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;nprocs) 获得缺省通信子中进程的个数，赋值给 nprocs MPI_Finalize() 一般放在程序最后一行，如果没有此行，MPI 程序将不会终止 MPI 初始化：MPI_Init int MPI_Init(int *argc, char ***argv) MPI_Init 是 MPI 程序的第一个调用，它完成 MPI 程序的所有初始化工作。所有的 MPI 程序的第一条可执行语句都是这条语句。 启动 MPI 环境,标志并行代码的开始. 要求 main 必须带参数运行,否则出错 MPI 结束：MPI_Finalize int MPI_Finalize(void) MPI_FINALIZE 是 MPI 程序的最后一个调用，它结束 MPI 程序的运行，它是 MPI 程序的最后一条可执行语句，否则程序的运行结果是不可预知的。 标志并行代码的结束,结束除主进程外其它进程。 之后串行代码仍可在主进程(rank = 0)上运行(如果必须)。 进程号：MPI_Comm_rank int MPI_Comm_rank(MPI_Comm comm, int *rank) MPI_COMM_RANK 是 MPI 程序中的一个重要函数，它返回调用进程在通信子中的进程号，即 rank。 通信子：MPI_COMM_WORLD 进程号：rank 进程数：MPI_Comm_size int MPI_Comm_size(MPI_Comm comm, int *size) MPI_COMM_SIZE 是 MPI 程序中的一个重要函数，它返回通信子中的进程数，即 size。 通信子：MPI_COMM_WORLD 进程数：size 示例 2：打印进程 ID 和进程数\n// mpi.c\r#include \u0026lt;mpi.h\u0026gt;\r#include \u0026lt;stdio.h\u0026gt;\rint main(int argc, char **argv)\r{\rint myrank, nprocs;\rMPI_Init(\u0026amp;argc, \u0026amp;argv);\rMPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;myrank);\rMPI_Comm_size(MPI_COMM_WORLD, \u0026amp;nprocs);\rprintf(\u0026quot;Hello World! I'm %d of %d\\n\u0026quot;, myrank, nprocs);\rMPI_Finalize();\rreturn 0;\r}\r结果： root@ubuntu:~# mpicc -o mpi mpi.c\rroot@ubuntu:~# mpirun -n 2 ./mpi\rHello World! I'm 0 of 2\rHello World! I'm 1 of 2\r","date":"2023-07-18T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/20230719012753.webp","permalink":"https://cuterwrite.top/p/mpi-tutorial/1/","title":"MPI 与并行计算（一）：并行环境及编程模型"},{"content":"CUDA 编程：从基础到应用 一、什么是 CUDA CUDA 是 NVIDIA 推出的一种通用并行计算平台和编程模型，可以利用 GPU 的强大计算能力来加速各种应用程序。 CUDA 的优势在于： 提供了一套简单易用的编程接口，支持 C/C++/Fortran/Python 等多种语言。 兼容各种操作系统，如 Windows/Linux/MacOS 等。 支持多种 GPU 架构，如 Tesla/Fermi/Kepler/Maxwell/Pascal/Volta/Turing/Ampere 等。 支持多种并行编程模式，如数据并行/任务并行/流并行等。 支持多种优化技术，如共享内存/纹理内存/常量内存/原子操作/同步机制等。 Why CUDA? 串行速度提升已经结束 无法继续提升频率 难以继续降低功耗 当前计算机性能提升趋势 计算机没有变得更快，而是变得更宽 多核 CPU、GPU、超级计算机 数据级别并行 同样的指令作用于多个数据 线程级别的并行 二、CPU vs. GPU CPU 和 GPU 都是计算机中的重要组件，但它们有着不同的设计目标和特点。 CPU 的特点是： 拥有较少的核心数，但每个核心都有较高的时钟频率和较强的运算能力。 拥有较大的缓存和复杂的控制流机制，可以有效地降低延迟和提高串行代码的性能。 更适合于处理复杂的单任务或少量的多任务，如操作系统/数据库/编译器等。 类比于摩托车，可以灵活地在城市中穿梭。 GPU 的特点是： 拥有较多的核心数，但每个核心都有较低的时钟频率和较弱的运算能力。 拥有较小的缓存和简单的控制流机制，可以有效地提高吞吐量和利用大规模并行架构。 更适合于处理大量相似或简单的任务，如图形渲染/科学计算/机器学习等。 类比于大巴车，可以承载更多的乘客。 CPU GPU 缓存 大缓存：掩盖较长的存储器延迟 小缓存：但通过更快的存储提高吞吐量 运算器 强大的运算器：降低运算延迟 更节能的运算器：延迟大但总吞吐量大 控制机制 复杂的控制机制：分支预测等 简单的控制流机制：无分支预测 线程 线程高度轻量级：大量并发 线程高度轻量级：大量并发 三、异构计算 异构计算是指利用不同类型的处理器协同工作来完成一个任务，如 CPU+GPU、CPU+FPGA、CPU+ASIC 等。 异构计算的优势在于： 可以充分发挥每种处理器的特长，提高性能和效率。 可以降低功耗和成本，延长设备寿命和节约资源。 可以增加灵活性和可扩展性，适应不同场景和需求。 异构计算的挑战在于： 需要设计合适的编程模型和接口，实现不同处理器之间的协调和通信。 需要考虑不同处理器之间的负载均衡和数据一致性，避免性能瓶颈和错误发生。 需要优化不同处理器之间的数据传输和转换，减少开销和延迟。 CPU+GPU 利用 CPU 处理复杂控制流 利用 GPU 处理大规模运算 CPU 与 GPU 之间通过 PCIe 总线通信 新显卡支持 NVLink 连接（5-12 倍 PCIe3.0) 四、CUDA 编程模型 CUDA 编程模型是基于数据并行思想设计的一种分层抽象模型，可以将一个复杂的问题分解为多个简单的子问题，并将其映射到 GPU 上执行。\nCUDA 编程模型包括以下几个层次：\n线程（thread）：线程是 CUDA 中最基本的执行单元，每个线程都有自己独立的寄存器、指令指针、栈空间等。 块（block）：块是由多个线程组成的一维或二维的逻辑分组，每个块都有自己独立的共享内存、同步机制等。 网格（grid）：网格是由多个块组成的一维或二维的逻辑分组，每个网格都有自己独立的全局内存、常量内存、纹理内存等。 设备（device）：设备是指 GPU 本身，包括多个流式处理器（SM）、多个 CUDA 核心（core）、多个缓存、总线等。 主机（host）：主机是指 CPU 本身，包括内存、硬盘、键盘、鼠标等。 CUDA 编程模型的执行流程如下：\n在主机端编写并行代码，称为核函数（kernel），并使用__global__修饰符标记。 在主机端调用核函数，并使用\u0026lt;\u0026lt;\u0026lt; grid,block \u0026gt;\u0026gt;\u0026gt;语法指定网格和块的维度，称为执行配置。 在设备端执行核函数，每个块被分配到一个 SM 上，每个线程被分配到一个 core 上。 在设备端完成核函数后，返回主机端继续执行后续代码。 2 级架构\n每个 GPU 拥有多个 Streaming Multiprocessor(SM) 具体数目及设计因产品而异 SM 共用显存 每个 SM 拥有多个 CUDA core 数目因产品而异 Core 共用调度器和指令缓存 2 级架构下的执行模型：线程束（warp）\nCUDA 线程以 32 个为一组在 GPU 上执行 线程束以单指令多线程的方式运行（SIMT） 所有线程在不同数据上执行相同的指令 SMIT、SIMD、SMT 灵活度：SIMD \u0026lt; SIMT \u0026lt; SMT 性能： SIMD \u0026gt; SIMT \u0026gt; SMT SIMT 与 SIMD 相比：多个状态寄存器，多个地址，独立的执行路径 SM 负责调度并执行线程束 线程束调度时会产生上下文切换 调度方式因架构而异 Host 与 device\nHost（CPU）相关：运行在 CPU 上的代码及主机内存 Device（GPU）相关：运行在 GPU 上的代码及显存（设备内存） 通过在主机上调用核函数（kernel）执行并行代码 指明 host 与 device 代码\n__host__从主机端调用，在主机端执行 __global__从主机端调用，在设备端执行 __device__从设备端调用，在设备端执行 __host__和__device__可以一起使用 \u0026lt;\u0026lt;\u0026lt; 1,4 \u0026gt;\u0026gt;\u0026gt;：执行配置 指明网格中有 1 个块 每块中有 4 个线程 cudaDeviceSynchronize() 与 OpenMP 不同，CUDA 核函数为异步执行 核函数限制条件（__global__函数） 只能访问设备内存 必须返回 void 不支持可变数量的参数 参数不可为引用类型 不支持静态变量 指明网格及块的维度\n形式为\u0026lt;\u0026lt;\u0026lt; grid,block \u0026gt;\u0026gt;\u0026gt; grid 与 block 为 dim3 类型 grid 与 block 的大小受到计算能力的限制 GPU 架构与线程执行 一个 CUDA core 执行一个线程 一个 SM 执行一个 block 中的线程 GPU 中执行 grid 中的所有线程 确定线程编号 使用内置变量 threadIdx、blockIdx、blockDim CUDA 编程例子：向量加法 __global__ void VecAdd(int *a, int *b, int *c)\r{\rint tid = blockIdx.x;\rif (tid \u0026lt; N) {\rc[tid] = a[tid] + b[tid];\r}\r}\rint main()\r{\r...\r// Kernel invocation with N threads\rVecAdd\u0026lt;\u0026lt;\u0026lt;1, N\u0026gt;\u0026gt;\u0026gt;(A, B, C);\r...\r}\rGPU 内存管理：\n创建：cudaMalloc 拷贝：cudaMemcpy 使用 cudaMemcpyHostToDevice 与 cudaMemcpyDeviceToHost 指明拷贝方向 释放：cudaFree 处理错误\n使用宏定义 block 中最大线程限制：n 必须不大于 1024\n同一个 block 只在一个 SM 上执行：没有充分利用 GPU 计算资源\n思路：使用多个 block\n每个 block 使用 m 个 thread（如 m=32） grid,block 设置：\u0026lt;\u0026lt;\u0026lt; n/m, m \u0026gt;\u0026gt;\u0026gt; n 无法被 m 整除？ 需对 n/m 向上取整 需判断 tid 是否会超过范围 确定 thread 的全局编号 五、CUDA 线程执行模型 逻辑视图 每个线程块由一个 SM 执行 由硬件调度 无法控制线程块的执行顺序 硬件视图 所有线程块在硬件上都是一维的 三维线程将沿 x-\u0026gt;y-\u0026gt;z 的顺序展开到一维 展开后的一维线程每 32 个形成一个线程束 最后不足 32 的部分也将创建线程 不活跃 仍将消耗 SM 资源 线程束调度 线程束切换开销为 0 SM 保存每个线程束的执行上下文 在整个线程束的生命周期中保存于芯片内 上下文切换没有损失 可切换同一 SM 上不同线程块的线程束 SM 中常驻线程块数量受可用资源限制 资源：程序计数器、寄存器、共享内存 活跃线程束：具备计算资源的线程束 Kepler 上最大为 64 选定的线程束：被调度到执行单元的线程束（Kepler 上最大为 4） 符合条件的线程束：准备执行但尚未执行 阻塞的线程束：没做好执行准备（指令参数未就绪，无可用 CUDA core） 活跃线程束于延迟隐藏 满载：线程调度器在每个时钟周期都有符合条件的线程束 通过调度符合条件的线程束，可以有效的掩盖指令延迟 算数指令：算数操作从开始到产生输出（10~20 时钟周期） 内存指令：发出加载/存储操作到数据到达目的地（全局内存~800 时钟周期） 应适当增加活跃线程束 Little\u0026rsquo;s law 线程数不宜过少（每个线程处理的任务数与线程数需要平衡） 线程块资源不易过多（如，共享内存的大小与活跃线程块数量需要平衡） 线程束执行 每个线程束以 SIMD 方式在 SM 上执行 线程束内同时执行同样语句 线程束外的视角看来为 SIMT 分支分化 线程束出现不同的控制流 性能优化：避免分支分化，因为线程束只能执行相同的逻辑，在执行某一个路径的线程时会禁用另一路径的线程。 busy waiting vs signal busy waiting：如，使用 while 循环不断检查条件是否满足 signal：当条件满足由系统发送指令 __syncthreads()：只能在线程块内同步，不能在不同的线程块同步 busy waiting 的问题：死锁 减少分支分化的影响 减少 if 语句 尤其是减少基于 threadIdx 的 if 语句 使用条件赋值代替条件语句 平衡分支执行时间 避免出现执行时间过长的分支 六、CUDA 原子操作 原子指令 执行过程不能分解为更小的部分：不被中断 避免竞争条件出现 竞争条件 程序运行结果依赖于不可控的执行顺序 CUDA 原子操作： 基本操作：atomicCAS 其它所有原子操作均可由 atomicCAS()实现 CAS：compare and swap 读取目标位置(address)并与预期值(old_val)进行比较 相等则将 new_val 写入目标位置 不相等则不发生变化 返回目标位置中原值：可用来检查 CAS 操作是否成功 原子指令与并发控制：原子指令在并发控制中起着重要的作用。在多线程或多进程的环境中，当多个线程或进程尝试同时访问和修改共享数据时，如果没有适当的控制机制，可能会导致数据的不一致性。原子指令通过确保某些操作在执行过程中不会被其他线程或进程中断，来避免这种情况。 竞争条件与死锁：竞争条件是并发编程中的一个主要问题，它发生在两个或更多的线程或进程在无序或未同步的情况下访问和修改共享数据，导致结果不可预测。原子指令是解决竞争条件的一种方法，但也可能引入另一个问题 - 死锁。死锁是指两个或更多的进程或线程互相等待对方释放资源，导致所有进程或线程都无法继续执行。 CUDA 原子操作与 GPU 编程：在 GPU 编程中，由于大量的线程并行执行，可能会有多个线程同时访问和修改同一块内存。CUDA 的原子操作提供了一种机制，使得在这种情况下仍能保证数据的一致性。然而，过度依赖原子操作可能会导致性能下降，因为它们违反了 GPU 编程的基本原则——并行执行。因此，在设计 GPU 算法时，应尽量减少原子操作的使用，或者寻找可以避免使用原子操作的算法。 CUDA 原子操作的应用：在某些情况下，CUDA 原子操作是必要的。例如，在统计或计数问题中，需要多个线程共享一个计数器，并且每个线程都可能需要增加计数器的值。在这种情况下，使用 CUDA 原子操作可以保证计数器的正确性。另一个例子是图形处理，其中可能需要多个线程同时更新像素的值。使用 CUDA 原子操作可以避免同时更新导致的数据不一致问题。 ","date":"2023-07-11T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/img/ba25bc69cbefbfac1287056fee570cee2b6458ff.jpg@1256w_880h_!web-article-pic.avif","permalink":"https://cuterwrite.top/p/cuda-tutorial/","title":"CUDA 编程：从基础到应用"},{"content":"SVD 与 NMF：矩阵分解的两种方法 在数据科学中，矩阵分解技术是一种强大的工具，可以用于各种应用，如推荐系统、图像处理和自然语言处理。在这篇文章中，我们将深入探讨两种流行的矩阵分解技术：奇异值分解（SVD）和非负矩阵分解（NMF）。我们将详细解析它们的理论基础，以及如何在实际问题中应用它们。\n一、奇异值分解（SVD） 奇异值分解是一种在线性代数中常用的矩阵分解方法。对于给定的 $m\\times n$ 矩阵 A，我们可以将其分解为三个矩阵的乘积：\n$$ A = U\\Sigma V^T $$\n这里，$U$ 是一个 $m\\times m$ 的正交矩阵，$V$ 是一个 $n\\times n$ 的正交矩阵，$\\Sigma$ 是一个 $m\\times n$ 的对角矩阵。对角线上的元素称为奇异值，它们是 $A^T A$ 的特征值的平方根。它们是按降序排列的，代表了原始矩阵中的“能量”或信息量。。我们可以将奇异值分解看作是一种特征值分解，其中 $U$ 和 $V$ 是特征向量，$\\Sigma$ 是特征值的对角矩阵。\n计算 SVD 的基本步骤如下：\n构造矩阵 A 的 Gram 矩阵：对于给定的 $m\\times n$ 矩阵 A，我们可以构造一个 $n\\times n$ 的矩阵 $A^T A$，称为 A 的 Gram 矩阵。Gram 矩阵是一个对称半正定矩阵，因此它的特征值都是非负的。 计算 Gram 矩阵的特征值和特征向量：我们可以使用任何标准的特征值分解算法来计算 Gram 矩阵的特征值和特征向量。这些特征值就是 A 的奇异值的平方，特征向量则构成了右奇异向量和左奇异向量。我们将特征值按降序排列，将特征向量按相同的顺序排列。 构造奇异值矩阵 $\\Sigma$ ：我将特征值的平方根按照从大到小的顺序排列在对角线上，构成 $m\\times n $ 的对角矩阵 $\\Sigma$ 。 构造左奇异向量矩阵 $U$ 和右奇异向量矩阵 $V$ ：将对应于特征值的特征向量按照特征值的顺序排列，构成 $n\\times n$ 的矩阵 $V$ 和 $m\\times m$ 的矩阵 $U$ 。这些特征向量是标准化的，即它们的长度为 1，并且互相正交。 这样，我们就得到了 A 的奇异值分解。在 Python 中，我们可以使用 NumPy 的np.linalg.svd 函数来计算 SVD，这个函数会自动执行上述步骤，并返回 $ U, \\Sigma, V^T $ 。如下所示：\nimport numpy as np\rU, S, Vt = np.linalg.svd(A)\r需要注意的是，虽然理论上 SVD 总是存在的，但在实际计算中可能会遇到数值稳定性的问题。此外，对于非常大的矩阵，计算 SVD 可能会非常耗时。在这些情况下，我们可能需要使用一些更高效的算法或者近似方法，如随机 SVD。\nSVD 的一个重要应用是在推荐系统中进行矩阵补全。在推荐系统中，我们通常有一个用户-商品评分矩阵，但这个矩阵通常是非常稀疏的，因为大多数用户只评价了少数商品。SVD 可以用于预测用户对未评价商品的评分，从而提供个性化的推荐。\n二、非负矩阵分解（NMF） 由于维度的复杂性和维度诅咒，直接处理高维数据需要大量的计算资源。非负矩阵分解（NMF）作为一种降维技术被提出，在图像处理中得到了重要的应用。通过采用 NMF，非负的高维矩阵可以被分解成两个非负的低维矩阵，其中一个包括列向量，可以被视为数据空间中的基向量，另一个则包含缩放这些基向量的系数行。此外，NMF 也可用于文本数据处理。我们可以检查系数矩阵中的每一列，并确定具有最大系数的行号，其中行号表示原始矩阵中各列的聚类 ID。这种聚类特性意味着 NMF 可以用于数据聚类。\nNMF 对矩阵的元素有一个额外的非负约束。对于给定的 $K\\times N$ 非负矩阵 $M\\in R^{K\\times N}$ ，我们可以找到两个非负矩阵 $W$ 和 $H$ ，使得 $M\\approx WH$ 。其中 $W\\in R^{K\\times r}$ 和 $H\\in R^{r\\times N}$ 是两个非负矩阵，即 $W\\geq 0$ 和 $H\\geq 0$ 。矩阵 $W$ 代表捕捉数据特征的基向量，而矩阵 $H$ 是表示每个基向量对重建原始数据的贡献的权重。NMF 中的非负约束允许学习整体数据的部分表征，而这种约束在 SVD 中是不允许的。为了找到 $M\\approx WH$的近似解，定义基于欧氏距离的成本函数来量化近似的质量，即:\n$$ Q=\\Vert M-WH\\Vert^2_F=\\sum_{i,j}(M_{ij}-(WH)_{ij})^2 $$\n由于成本函数 $Q$ 在 $W$ 和 $H$ 中都是非凸的，所以在求解 $Q$ 的最小值过程中找到全局最小值是不现实的。一些数值优化技术，如梯度下降和共轭梯度，可以被用来寻找局部最小值。然而，梯度下降的收敛速度很慢，共轭梯度的实现很复杂。此外，基于梯度的方法对步长的参数设置很敏感，这对现实应用来说并不方便。为此，可以利用 $W$ 和 $H$ 的 multiplicative update rules，作为收敛速度和实现复杂性之间的折中方案，具体如下:\n$$ H_{aj} \\leftarrow H_{aj} \\frac{W^T M_{aj}}{W^T W H_{aj}}, W_{ia} \\leftarrow W_{ia} \\frac{M H^T_{ia}}{W H H^T_{ia}} $$\n其中，矩阵 $W$ 和 $H$ 可以被随机初始化，然后通过迭代更新来优化 $Q$ 。这些更新规则可以保证 $Q$ 在每次迭代中都会减少，因此可以保证收敛到局部最小值。\n在 Python 中，我们可以使用sklearn.decomposition.NMF 类来计算 NMF。如下所示：\nfrom sklearn.decomposition import NMF\rmodel = NMF(n_components=2, init='random', random_state=0)\rW = model.fit_transform(X)\rH = model.components_\r三、SVD 与 NMF 的比较 虽然 SVD 和 NMF 都是矩阵分解技术，但它们有一些重要的区别。\n数据类型和约束：SVD 可以应用于任何矩阵，而 NMF 只能应用于非负矩阵。其次，SVD 提供了一种最优的低秩近似，而 NMF 则没有这种保证。然而，NMF 的非负约束使得它的分解更具解释性，这在许多应用中是非常有用的。 分解的解释性：虽然 SVD 和 NMF 都可以将原始矩阵分解为一些基本的“构成元素”，但 NMF 的分解通常更具解释性。这是因为 NMF 的非负约束使得分解的结果更容易解释和理解。在许多应用中，如主题模型或社区发现，NMF 的分解可以直接解释为数据的一些基本模式或特征。 优化和稳定性：SVD 的优化问题有闭式解，这意味着我们可以直接计算出最优解。而 NMF 的优化问题通常需要使用迭代方法来求解，如梯度下降或坐标下降。这使得 NMF 的计算过程可能更复杂，而且可能需要更多的时间。而且 SVD 的结果是唯一的（除了奇异向量的符号），而 NMF 的结果可能依赖于初始化和优化算法。这意味着对同一个数据集，NMF 可能会给出不同的结果。 近似质量：SVD 提供了一种最优的低秩近似，即它可以找到最接近原始矩阵的低秩矩阵。而 NMF 则没有这种保证，它的近似质量可能会比 SVD 差。然而，NMF 的非负约束使得它的近似可能更符合实际的需求，尤其是在那些原始数据是非负的情况下。 计算复杂性：SVD 和 NMF 的计算复杂性也有所不同。对于一个 $m\\times n$ 的矩阵，SVD 的计算复杂性大约为 $\\mathbf{O}(\\min {m^2n, mn^2})$ ，而 NMF 的计算复杂性则取决于迭代次数和所选的优化算法。在实践中，NMF 通常比 SVD 更慢，但也有一些高效的 NMF 算法可以缩短计算时间。 总的来说，SVD 和 NMF 各有优势，选择使用哪一种技术取决于具体的应用和需求。\n四、实战：图像压缩 让我们通过一个实战演示来看看如何使用 SVD 和 NMF 进行图像压缩。我们将使用 Python 的 NumPy 和 scikit-learn 库来执行这些任务。\n首先，我们需要导入必要的库，并加载一张图像：\nimport numpy as np\rfrom sklearn.decomposition import NMF\rfrom PIL import Image\r# 加载图像\rimg = Image.open('image.jpg')\rwidth, height = img.size\rimg = np.array(img)\rr, g, b = img[:, :, 0], img[:, :, 1], img[:, :, 2]\rimg_matrix = []\rimg_matrix.extend([r.flatten(), g.flatten(), b.flatten()])\rM = np.array(img_matrix).T\r然后，我们可以使用 NumPy 的np.linalg.svd 函数来进行 SVD，得到 $U, S, V^T$ ：\n# 执行 SVD\rU, s, Vt = np.linalg.svd(M, full_matrices=False)\r我们可以选择前 $r$ 个奇异值和对应的 $U$ 和 $V^T$ 的列来进行低秩近似：\nd = 16\rU_d = U[:, :d]\rs_d = s[:d]\rVt_d = Vt[:d, :]\rM_d = U_d @ np.diag(s_d) @ Vt_d\rr, g, b = M_d[:, 0], M_d[:, 1], M_d[:, 2]\rimg = np.dstack((r, g, b)).reshape(height, width, 3)\rimg[img \u0026lt; 0] = 0\rimg[img \u0026gt; 255] = 255\rimg = Image.fromarray(np.uint8(img), mode='RGB')\rimg.show()\r同样，我们也可以使用 scikit-learn 的 NMF 类来进行 NMF：\n# 执行 NMF\rmodel = NMF(n_components=16, init='random', random_state=0)\rW = model.fit_transform(M)\rH = model.components_\rM_d = W @ H\rr, g, b = M_d[:, 0], M_d[:, 1], M_d[:, 2]\rimg = np.dstack((r, g, b)).reshape(height, width, 3)\rimg[img \u0026lt; 0] = 0\rimg[img \u0026gt; 255] = 255\rimg = Image.fromarray(np.uint8(img), mode='RGB')\rimg.show()\r最后，我们可以比较原始图像和重构图像的差异，以及 SVD 和 NMF 的压缩效果。这种压缩方法的优点是可以大大减少存储和传输图像所需的数据量，而且如果选择的秩 r 足够大，压缩后的图像的质量也可以接受。\n五、结论 总的来说，SVD 和 NMF 都是强大的矩阵分解技术，它们在许多数据科学应用中都有广泛的用途。虽然 SVD 提供了一种最优的低秩近似，但 NMF 的非负约束使得它的分解更具解释性。在选择使用哪一种技术时，我们需要考虑我们的具体需求，以及我们的数据是否满足这些技术的要求。\n参考资料 [1] Lee, Daniel, and H. Sebastian Seung. \u0026ldquo;Unsupervised learning by convex and conic coding. \u0026quot; Advances in neural information processing systems 9 (1996).\n[2] Lee, Daniel D., and H. Sebastian Seung. \u0026ldquo;Learning the parts of objects by non-negative matrix factorization.\u0026rdquo; Nature 401.6755 (1999): 788-791.\n[3] Lee, Daniel, and H. Sebastian Seung. \u0026ldquo;Algorithms for non-negative matrix factorization. \u0026quot; Advances in neural information processing systems 13 (2000).\n","date":"2023-07-11T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/65cf6588fa725014c7cd617ccbeb997f27742e49.jpg@1256w_1880h_!web-article-pic.webp","permalink":"https://cuterwrite.top/p/matrix-factorization/","title":"SVD 与 NMF：矩阵分解的两种方法"},{"content":"最小反馈弧集合问题 一、引言 在复杂网络分析、社会学、生物信息学等领域，我们经常需要处理的一个问题是如何从一个有向图中移除最少的边，使得图中不再存在环。这个问题被称为最小反馈弧集问题（Minimum Feedback Arc Set，简称 MinFAS）。在本文中，我们将详细介绍这个问题的定义、性质，以及一些常见的解决算法。我们还将讨论这个问题在实际应用中的一些例子。\n二、问题定义 首先，我们来详细定义一下最小反馈弧集问题。给定一个有向图 G=(V, E)，其中 V 是顶点集，E 是边集。给定有向图 G(V,E)，集合 F 是 E 的一个子集，若 G 的生成子图 G′(V,E−F)中不包含环，则称 F 是 G 的一个反馈弧集合。容易推出：若有向图 G 包含环，则其每个环至少有一条边在 F 中。我们将基数最小的反馈弧集合称为最小反馈弧集合。最小反馈弧集合问题就是在给定有向图 G 的情况下，求解最小反馈弧集合 F。\n例如：$ F={(1, 2), (4, 5)} $ 在这个问题中，我们的目标是找到最小的反馈弧集，也就是说，我们希望找到尽可能少的边，使得去掉这些边后图中不再有环。这个问题在许多实际应用中都有重要的意义。例如，在社会网络分析中，我们可以通过这个问题来找出社区内的关键人物；在生物信息学中，我们可以通过这个问题来找出基因调控网络中的关键基因。\n最小反馈弧集问题已经被证明是一个 NP 难问题。这意味着，我们无法在多项式时间内找到这个问题的精确解（除非 P=NP）。然而，尽管这个问题很难，但是我们仍然可以通过一些方法来找到它的近似解。在理论计算机科学中，有一类算法被称为近似算法，它们可以在多项式时间内找到问题的近似解。对于最小反馈弧集问题，我们也可以使用这类算法来求解。在接下来的部分中，我们将介绍一些常见的近似算法。\n三、解决方案 对于最小反馈弧集问题，我们有多种解决方案，其中包括贪心算法（GreedyFAS）、排序算法（SortFAS）和基于 PageRank 的算法（PageRankFAS）。\n1. GreedyFAS GreedyFAS 算法的核心思想在于用贪心法生成一个线性排列，将该线性排列中的后向边集作为结果返回。该算法的伪代码如下图所示： 对任一有向图 G，GreedyFAS 算法使用的贪心策略为：\n查找源头点（入度为 0 的点）。若查到源头点则排在序列 $s_1$ 末尾并移除该点，重复直到 $G$ 无源头点。 查找汇集点（出度为 0 的点）。若查到汇集点则排在序列 $s_2$ 首部并移除该点，重复直到 $G$ 无汇集点。 计算剩余点的 $\\delta$ 值（出度与入度的差值），将 $\\delta$ 值最大的点排在 $s_1$ 末尾并移除该点。 重复上述过程直到 $G$ 不存在任何点。 返回序列 $s_1 s_2$ 。 2. SortFAS SortFAS 算法的基本思想是该算法根据序号的自然顺序生成初始最小线性排列问题（LA），不断调整 LA 使后向边的数量尽可能少。该算法的伪代码如下图所示： 对任一有向图 G，SortFAS 算法的步骤如下：\n生成初始最小线性排列问题（LA）。 对于 LA 中的每个序号 v，记录全局变量 val，初始化为 0，表示调整后新增的后向边数。记录 v 的位置 loc。记录最小值 min=0 从序号 loc-1 开始，向前遍历 LA 得到序号 w，若 v-\u0026gt;w 存在则 val\u0026ndash;，否则 val++。 如果 val 小于等于 min，则赋值 min=val，记录位置 loc=w 在位置 loc 插入序号 v 3. PageRankFAS PageRankFAS 算法的核心思想在于将原始图的强连通分量转换为线图，然后用 PageRank 算法评估线图中节点的重要性，然后依次删除线图中 PageRank 值最高的节点对应的边。该算法的伪代码如下图所示：\n对任一有向图 G，PageRankFAS 的算法步骤如下：\n检测图是否有环，如果存在环，执行以下循环：\n识别有向图中的强连接分量 $s_i, i=0,1,\\cdots$ 遍历强连通分量 $s_i$ ，对于每个强连通分量 $s_i$ ，执行： 如果 $s-i$ 的大小小于等于 1，跳过该强连通分量的处理。 选择 $s_i$ 中的一个随机节点 $v$ ，从 $v$ 开始遍历创建 $s_i$ 的线图 $L(s_i)$ 计算 $L(s_i)$ 的 PageRank 值。 选择 $L(s_i)$ 中 PageRank 值最大的节点，找到 $s_i$ 中对应的边 $e$ ，添加到最小反馈弧集。 在 $G$ 中删除边 $e$ 。 如果仍有环，重复执行 1 和 2，直到图不存在环为止。 四、实际应用 最小反馈弧集问题在许多领域都有广泛的应用。例如，在生物信息学中，我们可以通过求解最小反馈弧集问题，来找出基因调控网络中的关键基因。在这种情况下，我们通常将基因调控网络表示为一个有向图，其中的顶点代表基因，边代表基因之间的调控关系。然后，我们可以通过求解最小反馈弧集问题，来找出那些对整个网络有重要影响的基因。\n在社会网络分析中，我们可以通过求解最小反馈弧集问题，来检测社区内的关键人物。在这种情况下，我们通常将社区表示为一个有向图，其中的顶点代表人，边代表人之间的关系。然后，我们可以通过求解最小反馈弧集问题，来找出那些对整个社区有重要影响的人。\n","date":"2023-07-11T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/20230711173143.webp","permalink":"https://cuterwrite.top/p/fas/","title":"最小反馈弧集合问题"},{"content":"RDMA: Soft-RoCE 环境搭建实验 1. RoCE 简介 RoCE 是三大 RDMA 协议之一，全称为 RDMA Over Converged Ethernet，即基于融合以太网的 RDMA。它是一种基于传统以太网的部分下层协议，在其基础上实现 InfiniBand 的部分上层协议。\nRoCE 的发展历史如下：\n1999 年，由 Compaq, Dell, HP, IBM, Intel, Microsoft 和 Sun 公司组成了 IBTA 组织。愿景是设计一种更高速的新的互联协议规范标准，来应对传统以太网在面对未来计算机行业的发展时可能遇到的瓶颈。\n2000 年，IBTA 组织设计并发布了 Infiniband Architecture Specification 1.0（IB 规范）。\n2007 年，IETF 发布了 iWARP（Internet Wide Area RDMA Protocol）的一系列 RFC。\n2010 年，IBTA 发布了 RoCE v1 规范。\n2014 年，IBTA 发布了 RoCE v2 规范。\n2. RoCE 的协议层次 首先是二层的以太网链路帧，然后是 IP 报文头和 UDP 报文头，最后是各层级协议的校验。而 Infiniband 传输层报文实际上是 UDP 层的负载，也就是深蓝色背景的部分。UDP 报文头中有一个字段 Destination Port Number（目的端口号），对于 RoCE v2 来说固定是 4791，当对端网卡收到报文后，会根据该字段识别是普通的以太网数据包，还是 RoCE 数据包，或者是其他协议的数据包，然后再进行解析。深蓝色背景的 IB 传输层部分又分成了 IB 报头，实际的用户数据（Payload）以及校验部分。\n3. RoCE 的优势 为什么我们有了 Infiniband 协议之后，还要设计 RoCE 协议呢？最主要的原因还是成本问题：由于 Infiniband 协议本身定义了一套全新的层次架构，从链路层到传输层，都无法与现有的以太网设备兼容。也就是说，如果某个数据中心因为性能瓶颈，想要把数据交换方式从以太网切换到 Infiniband 技术，那么需要购买全套的 Infiniband 设备，包括网卡、线缆、交换机和路由器等等。商用级设备由于对可靠性有比较高的要求，所以这一套下来是非常昂贵的。\n而 RoCE 协议的出现解决了这一问题，如果用户想要从以太网切换到 RoCE，那么只需要购买支持 RoCE 的网卡就可以了，线缆、交换机和路由器（RoCE v1 不支持以太网路由器）等网络设备都是兼容的——因为我们只是在以太网传输层基础上又定义了一套协议而已。\n所以 RoCE 相比于 Infiniband，主要还是省钱，当然性能上相比 Infiniband 还是有一些损失，毕竟人家是全套重新设计的。\n至于 iWARP，相比于 RoCE 协议栈更复杂，并且由于 TCP 的限制，只能支持可靠传输，即无法支持 UD 等传输类型。所以目前 iWARP 的发展并不如 RoCE 和 Infiniband。\n4. Soft-RoCE 虽然 RoCE 相比 Infiniband 具有兼容性优势，价格也便宜，但是实际应用的时候依然需要专用的网卡支持。\nRoCE 本身确实可以由软件实现，也就是本节即将介绍的 Soft-RoCE，但是商用的时候，几乎不会有人用软件实现的 RoCE。RDMA 技术本身的一大特点就是“硬件卸载”，即把本来软件（CPU）做的事情放到硬件中实现以达到加速的目的。CPU 主要是用来计算的，让它去处理协议封包和解析以及搬运数据，这是对计算资源的浪费。所以 RoCE 网卡会把 TCP/IP 协议栈放到硬件中实现以解放 CPU，让它去做更重要的事。\n我们说回 Soft-RoCE，它由 IBM 和 Mellanox 牵头的 IBTA RoCE 工作组实现。本身的设计初衷有几点：\n降低 RoCE 部署成本：Soft-RoCE 可以使不具备 RoCE 能力的硬件和支持 RoCE 的硬件间进行基于 IB 语义的交流，这样可以免于替换网络中的一些非关键节点的旧型号网卡。\n相比 TCP 提升性能：虽然软件实现 IB 传输层带来了一定的开销，但是相比基于 Socket-TCP/IP 的传统通信方式，Soft-RoCE 因为减少了系统调用（只在软件通知硬件下发了新 SQ WQE 时才会使用系统调用），发送端的零拷贝以及接收端的只需要单次拷贝等原因，仍然带来了性能上的提升。\n便于开发和测试 RDMA 程序：有了 Soft-RoCE，我们基于 Verbs API 编写的程序，就可以不依赖于硬件执行起来，可以很方便地运行程序。\n实现原理\nSoft-RoCE 就是把本来应该卸载到硬件的封包和解析工作，又拿到软件来做。其本身是基于 Linux 内核的 TCP/IP 协议栈实现的，网卡本身并不感知收发的数据包是 RoCE 报文，其驱动程序按照 IB 规范中的报文格式将用户数据封装成 IB 传输层报文，然后把报文整体当做数据填入 Socket Buffer 当中，由网卡进行下一步收发包处理。\n5. 部署实验 5.1. 实验环境 本实验主要使用 Ubuntu 20.04 64 位作为系统环境，采用 2 台 2 核 4GB 云服务器作为 Soft-RoCE 的部署环境。\n节点 IP 地址 RDMA 设备名 node1 172.16.16.10 node1 node2 172.16.16.6 node2 5.2. 部署 RDMA 软件栈 5.2.1. 确认当前内核是否支持 RXE cat /boot/config-$(uname -r) | grep RXE\r如果 CONFIG_RDMA_RXE 的值为 y 或者 m，表示当前的操作系统可以使用 RXE。\n5.2.2. 安装用户态动态链接库 sudo apt-get install libibverbs1 ibverbs-utils librdmacm1 libibumad3 ibverbs-providers rdma-core\r这几个软件包的作用如下：\n软件包名 主要功能 libibverbs1 ibverbs 动态链接库 ibverbs-utils ibverbs 示例程序 librdmacm1 rdmacm 动态链接库 libibumad3 ibumad 动态链接库 ibverbs-providers ibverbs 各厂商用户态驱动（包括 RXE） rdma-core 文档及用户态配置文件 安装完上述软件之后，可以执行 ibv_devices 看看有没有报错：\n这是个基于 verbs 接口编写的小程序，用来获取并打印出当前系统中的 RDMA 设备列表。\n查看安装的版本：\ndpkg -L libibverbs1\r可以看到安装的版本是 1.14.19.0\n5.2.3. 安装 iproute2 和 perftest iproute2 是用来替代 net-tools 软件包的，是一组开源的网络工具集合，比如用更强大 ip 命令替换了以前常用的 ifconfig。我们需要其中的 rdma 工具来对 RXE 进行配置。一般的操作系统都已经包含了，安装也很简单：\nsudo apt-get install iproute2\rperftest 是一个基于 Verbs 接口开发的开源 RDMA 性能测试工具，可以对支持 RDMA 技术的节点进行带宽和时延测试。相比于 rdma-core 自带的示例程序 ，功能更加强大，当然也更复杂。使用如下命令安装：\nsudo apt-get install perftest\r5.3. 配置 RXE 网卡 首先我们需要加载内核驱动，modprobe 会自动加载依赖的其他驱动。\nsudo modprobe rdma_rxe\r然后进行用户态配置：\nsudo rdma link add rxe_0 type rxe netdev eth0\r其中 rxe_0 是你希望的 RDMA 的设备名，可任意取名。eth0 为 Soft-RoCE 设备所绑定的网络设备名，也就是 ifconfig 中看到的网卡名。\n接着我们用 rdma 工具查看是否添加成功：\nrdma link\r再次运行ibv_devices 程序，可以看到 RXE 网卡已经出现在设备列表里。\n也可以运行ibv_devinfo -d node1 命令查看虚拟 RDMA 设备的信息。\n5.4. 执行 perftest 测试 分别在两端执行以下命令：\nib_send_bw -d node2\r以及：\nib_send_bw -d node1 172.16.16.6\rib_send_bw 是用来测试 SEND 操作的带宽的程序（infiniband_send bandwidth），其中 \u0026lt;server_ip\u0026gt; 表示对端的 IP\n两端的结果如下，Server 端：\nClient 端：\n可以看到两端都打印出了一些测试信息以及最后的测试结果，也就是带宽信息。\n","date":"2023-02-11T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/86.webp","permalink":"https://cuterwrite.top/p/soft-roce/","title":"RDMA：Soft-RoCE 环境搭建实验"},{"content":"基于 Flink Native Kubernetes 的词频统计实验 1 简介 1.1 实验环境 本实验主要使用 Ubuntu 20.04 64 位作为系统环境，采用 3 台 4 核 8GB 云服务器作为 Kubernetes 集群部署机器，1 台 4 核 8GB 云服务器作为集群管理工具 Kuboard Spary 部署机器，并作为 NFS Server 部署机器。使用的软件如下：\n名称 版本 kuboard spary v1.2.3-amd64 kubernetes v1.25.4 calico v3.23.3 etcd v3.5.5 crictl v1.25.0 crun 1.4.5 krew v0.4.3 runc v1.1.4 cni v1.1.1 nerdctl 1.0.0 coredns v1.8.6 dnsautoscaler 1.8.5 pod_infra 3.7 flink 1.16.0 hadoop 3.2.3 1.2 集群规划 Kuborad Spary 主机名 IP kuborad 192.168.0.15 NFS Server 主机名 IP NFS-server 192.168.0.15 Kubernetes 集群规划 主机名 IP 控制节点 etcd 节点 工作节点 node1 192.168.0.6 是 是 是 node2 192.168.0.7 是 是 是 node3 192.168.0.14 是 是 是 2 Kubernetes 集群部署 这部分内容已经在Spark on K8s\r实验中给出详细步骤，这里不再重复。 3 Flink Native Kubernetes 部署 3.1 配置 flink 用户权限 创建用户flink 并配置权限 kubectl create serviceaccount flink -n bigdata\rkubectl create clusterrolebinding flink-role-binding-flink \\\r--clusterrole=edit \\\r--serviceaccount=bigdata:flink\r3.2 创建 session cluster 在安装了 Flink 的节点上进入 flink 根目录，执行以下命令并指定资源：\n./bin/kubernetes-session.sh \\\r-Dkubernetes.namespace=bigdata \\\r-Dkubernetes.jobmanager.service-account=flink \\\r-Dkubernetes.rest-service.exposed.type=NodePort \\\r-Dkubernetes.cluster-id=flink-session-cluster \\\r-Dtaskmanager.memory.process.size=2048m \\\r-Dkubernetes.taskmanager.cpu=1 \\\r-Dkubernetes.jobmanager.replicas=1 \\\r-Dtaskmanager.numberOfTaskSlots=3 \\\r-Dresourcemanager.taskmanager-timeout=3600000\r可以看到，控制台提示创建成功，并且提示了 Flink Web UI 的访问地址为：http://192.168.0.6:32077，可以看到 Web\rUI 界面如下：\n继续在 flink 根目录下执行以下命令，将官方自带的 WindowJoin 任务提交到 session cluster 测试部署是否成功：\n./bin/flink run -d \\\r--target kubernetes-session \\\r-Dkubernetes.namespace=bigdata \\\r-Dkubernetes.cluster-id=flink-session-cluster \\\r-Dkubernetes.service-account=flink \\\r-Dkubernetes.namespace=bigdata \\\r-Dkubernetes.taskmanager.cpu=1 \\\rexamples/streaming/WindowJoin.jar\r可以看到WindowJoin.jar 已经被提交到 session cluster，占用 1 个 Slot，总共 Slot 数为 4\n4 编写 WordCount 程序 配置 POM 文件： \u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt;\r\u0026lt;project xmlns=\u0026quot;http://maven.apache.org/POM/4.0.0\u0026quot;\rxmlns:xsi=\u0026quot;http://www.w3.org/2001/XMLSchema-instance\u0026quot;\rxsi:schemaLocation=\u0026quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026quot;\u0026gt;\r\u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt;\r\u0026lt;groupId\u0026gt;com.cuterwrite\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;FlinkApp\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt;\r\u0026lt;properties\u0026gt;\r\u0026lt;flink.version\u0026gt;1.16.0\u0026lt;/flink.version\u0026gt;\r\u0026lt;maven.compiler.source\u0026gt;11\u0026lt;/maven.compiler.source\u0026gt;\r\u0026lt;maven.compiler.target\u0026gt;11\u0026lt;/maven.compiler.target\u0026gt;\r\u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt;\r\u0026lt;/properties\u0026gt;\r\u0026lt;dependencies\u0026gt;\r\u0026lt;!-- Flink dependencies --\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.apache.flink\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;flink-java\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;${flink.version}\u0026lt;/version\u0026gt;\r\u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.apache.flink\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;flink-streaming-java\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;${flink.version}\u0026lt;/version\u0026gt;\r\u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;/dependencies\u0026gt;\r\u0026lt;build\u0026gt;\r\u0026lt;plugins\u0026gt;\r\u0026lt;plugin\u0026gt;\r\u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;maven-shade-plugin\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;3.1.1\u0026lt;/version\u0026gt;\r\u0026lt;executions\u0026gt;\r\u0026lt;execution\u0026gt;\r\u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt;\r\u0026lt;goals\u0026gt;\r\u0026lt;goal\u0026gt;shade\u0026lt;/goal\u0026gt;\r\u0026lt;/goals\u0026gt;\r\u0026lt;configuration\u0026gt;\r\u0026lt;artifactSet\u0026gt;\r\u0026lt;excludes\u0026gt;\r\u0026lt;exclude\u0026gt;com.google.code.findbugs:jsr305\u0026lt;/exclude\u0026gt;\r\u0026lt;/excludes\u0026gt;\r\u0026lt;/artifactSet\u0026gt;\r\u0026lt;filters\u0026gt;\r\u0026lt;filter\u0026gt;\r\u0026lt;!-- Do not copy the signatures in the META-INF folder.\rOtherwise, this might cause SecurityExceptions when using the JAR. --\u0026gt;\r\u0026lt;artifact\u0026gt;*:*\u0026lt;/artifact\u0026gt;\r\u0026lt;excludes\u0026gt;\r\u0026lt;exclude\u0026gt;META-INF/*.SF\u0026lt;/exclude\u0026gt;\r\u0026lt;exclude\u0026gt;META-INF/*.DSA\u0026lt;/exclude\u0026gt;\r\u0026lt;exclude\u0026gt;META-INF/*.RSA\u0026lt;/exclude\u0026gt;\r\u0026lt;/excludes\u0026gt;\r\u0026lt;/filter\u0026gt;\r\u0026lt;/filters\u0026gt;\r\u0026lt;transformers\u0026gt;\r\u0026lt;transformer implementation=\u0026quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\u0026quot;\u0026gt;\r\u0026lt;!-- Replace this with the main class of your job --\u0026gt;\r\u0026lt;mainClass\u0026gt;com.cuterwrite.WordCount\u0026lt;/mainClass\u0026gt;\r\u0026lt;/transformer\u0026gt;\r\u0026lt;transformer implementation=\u0026quot;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer\u0026quot;/\u0026gt;\r\u0026lt;/transformers\u0026gt;\r\u0026lt;/configuration\u0026gt;\r\u0026lt;/execution\u0026gt;\r\u0026lt;/executions\u0026gt;\r\u0026lt;/plugin\u0026gt;\r\u0026lt;/plugins\u0026gt;\r\u0026lt;/build\u0026gt;\r\u0026lt;/project\u0026gt;\r编写WordCount.java： package com.cuterwrite;\rimport org.apache.flink.api.common.functions.FlatMapFunction;\rimport org.apache.flink.api.java.tuple.Tuple2;\rimport org.apache.flink.streaming.api.datastream.DataStreamSource;\rimport org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\rimport org.apache.flink.streaming.api.functions.sink.SinkFunction;\rimport org.apache.flink.streaming.api.windowing.assigners.TumblingProcessingTimeWindows;\rimport org.apache.flink.streaming.api.windowing.time.Time;\rimport org.apache.flink.util.Collector;\rimport org.slf4j.LoggerFactory;\rimport org.slf4j.Logger;\rpublic class WordCount {\rprivate static final Logger log = LoggerFactory.getLogger(WordCount.class);\rpublic WordCount() {}\rpublic static void main(String[] args) throws Exception {\rStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\renv.setParallelism(3);\r// 监听 9999 端口的 socket 输入\rDataStreamSource\u0026lt;String\u0026gt; text = env.socketTextStream(\u0026quot;192.168.0.6\u0026quot;, 9999);\rtext.flatMap(new FlatMapFunction\u0026lt;String, Tuple2\u0026lt;String, Integer\u0026gt;\u0026gt;() {\r@Override\rpublic void flatMap(String value, Collector\u0026lt;Tuple2\u0026lt;String, Integer\u0026gt;\u0026gt; collector) throws Exception {\rString[] tokens = value.toLowerCase().split(\u0026quot; \u0026quot;);\rfor (String token : tokens) {\rcollector.collect(new Tuple2\u0026lt;\u0026gt;(token, 1));\r}\r}\r// 合并相同单词的频数\r})\r.keyBy(item -\u0026gt; item.f0)\r.window(TumblingProcessingTimeWindows.of(Time.seconds(5)))\r.sum(1)\r.addSink(new SinkFunction\u0026lt;Tuple2\u0026lt;String, Integer\u0026gt;\u0026gt;() {\r@Override\rpublic void invoke(Tuple2\u0026lt;String, Integer\u0026gt; value, Context context) throws Exception {\rlog.info(\u0026quot;单词：\u0026quot; + value.f0 + \u0026quot;,频率：\u0026quot; + value.f1);\r}\r});\renv.execute(\u0026quot;Word Count\u0026quot;);\r}\r}\r5 实验结果 提交 WordCount 程序 jar 包\n./bin/flink run -d \\\r--target kubernetes-session \\\r-Dkubernetes.namespace=bigdata \\\r-Dkubernetes.cluster-id=flink-session-cluster \\\r-Dkubernetes.service-account=flink \\\r-Dkubernetes.namespace=bigdata \\\r/root/FlinkApp-1.0-SNAPSHOT.jar\r查看 Flink Web UI：\n使用 socket 传输字符进行测试：\nnc 192.168.0.6 9999\r实验结果：\n","date":"2022-12-23T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/YSFD_P2_50.webp","permalink":"https://cuterwrite.top/p/flink-native-k8s/","title":"基于 Flink Native Kubernetes 的词频统计实验"},{"content":"基于 Spark on k8s 的词频统计实验 1 简介 1.1 实验环境 本实验主要使用 Ubuntu 20.04 64 位作为系统环境，采用 6 台 4 核 8GB 云服务器作为 Kubernetes 集群部署机器，1 台 2 核 4GB 云服务器作为集群管理工具 Kuboard Spary 部署机器，1 台 2 核 4GB 云服务器作为 NFS Server（使用 Centos 7.6 系统）部署机器。\n使用的软件如下：\n名称 版本 kuboard spary v1.2.3-amd64 kubernetes v1.25.4 calico v3.23.3 etcd v3.5.5 crictl v1.25.0 crun 1.4.5 krew v0.4.3 runc v1.1.4 cni v1.1.1 nerdctl 1.0.0 coredns v1.8.6 dnsautoscaler 1.8.5 pod_infra 3.7 spark 3.3.1 hadoop 3.2.3 1.2 集群规划 Kuborad Spary 主机名 IP kuborad 192.168.0.115 NFS Server 主机名 IP NFS-server 192.168.0.132 Kubernetes 集群规划 主机名 IP 控制节点 etcd 节点 工作节点 node1 192.168.0.76 是 是 是 node2 192.168.0.213 是 是 是 node3 192.168.0.2 是 是 是 node4 192.168.0.41 否 否 是 node5 192.168.0.73 否 否 是 node6 192.168.0.12 否 否 是 2 部署 Kubernetes 集群 2.1 安装 Kuboard-Spray Kuboard-Spray 是一款可以在图形界面引导下完成 Kubernetes 高可用集群离线安装的工具，开源仓库的地址为 Kuboard-Spray\r在 kuborad 节点上安装 docker-ce\n# 1. 安装必备的系统工具\rsudo apt-get remove docker docker-engine docker.io containerd runc;\rsudo apt-get install apt-transport-https ca-certificates curl gnupg2 software-properties-common;\r# 2. 安装 GPG 证书\rcurl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/docker.gpg;\r# 3. 写入软件源信息\recho \\\r\u0026quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/docker.gpg] https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/ubuntu \\\r$(lsb_release -cs) stable\u0026quot; | sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null\r# 4. 更新并安装 Docker-CE\rsudo apt-get update;\rsudo apt-get install docker-ce;\r# 5. 配置 docker 镜像加速器(可以在阿里云获取地址)\rsudo mkdir -p /etc/docker;\rsudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-'EOF'\r{\r\u0026quot;registry-mirrors\u0026quot;: [\r\u0026quot;https://docker.mirrors.ustc.edu.cn\u0026quot;,\r\u0026quot;https://cr.console.aliyun.com/\u0026quot; ]\r}\rEOF\rsudo systemctl daemon-reload;\rsudo systemctl restart docker;\r在 kuboard 节点上执行以下命令：\ndocker run -d \\\r--privileged \\\r--restart=unless-stopped \\\r--name=kuboard-spray \\\r-e TZ=Asia/Shanghai \\\r-p 80:80/tcp \\\r-v /var/run/docker.sock:/var/run/docker.sock \\\r-v ~/kuboard-spray-data:/data \\\reipwork/kuboard-spray:v1.2.3-amd64\r在浏览器打开地址 http://这台机器的 IP，输入用户名 admin，默认密码 Kuboard123，即可登录 Kuboard-Spray 界面。\n2.2 加载离线资源包 在 Kuboard-Spray 界面中，导航到 系统设置 \u0026ndash;\u0026gt; 资源包管理 界面，可以看到已经等候您多时的 Kuboard-Spray 离线资源包，如下图所示\n点击 导入 按钮，在界面的引导下完成资源包的加载。\n2.3 安装 Kubernetes 集群 在 Kuboard-Spray 界面中，导航到 集群管理 界面，点击界面中的 添加集群安装计划 按钮，填写表单如下：\n集群名称： 自定义名称，本文中填写为 kuboard，此名称不可以修改；\n资源包：选择前面步骤中导入的离线资源包。\n点击 确定 按钮后，将进入集群规划页面，在该界面中添加每个集群节点的连接参数并设置节点的角色，如下图所示：\n重要： kuboard-spray 所在机器不能当做 K8S 集群的一个节点，因为安装过程中会重启集群节点的容器引擎，这会导致 kuboard-spray 被重启掉。\n注意：\n最少的节点数量是 1 个； ETCD 节点、控制节点的总数量必须为奇数； 点击上图的 保存 按钮，再点击 执行 按钮，可以启动集群的离线安装过程，安装结果如下：\n3 部署 Spark on k8s 3.1 制作 spark 容器镜像 下载 spark-3.3.1-bin-hadoop3\nwget https://mirrors.pku.edu.cn/apache/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz;\rtar -xzf spark-3.3.1-bin-hadoop.tgz;\rmv spark-3.3.1-bin-hadoop spark;\r修改 Dockerfile 默认 apt 源加速\ncd spark/kubernetes/dockerfiles/spark;\r// 修改 Dockerfile 内容\r// 修改前：\rsed -i 's/http:\\/\\/deb.\\(.*\\)/https:\\/\\/deb.\\1/g' /etc/apt/sources.list\r// 修改后：\rsed -i 's#http://deb.debian.org#https://mirrors.ustc.edu.cn#g' /etc/apt/source.list\rsed -i 's|security.debian.org/debian-security|mirrors.ustc.edu.cn/debian-security|g' /etc/apt/source.list\r构建 docker 镜像\ncd spark/bin;\r// -r \u0026lt;repo\u0026gt; -t \u0026lt;tag\u0026gt;\r./docker-image-tool.sh -r cuterwrite -t 0.1 build;\r推送镜像到阿里云仓库（参考容器镜像服务-\u0026gt;实例列表-\u0026gt;镜像仓库）\ndocker login --username=[阿里云账号] registry.cn-hangzhou.aliyuncs.com;\rdocker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/[repository]:[镜像版本号];\rdocker push registry.cn-hangzhou.aliyuncs.com/[repository]:[镜像版本号];\r3.2 创建命名空间 访问 Kuboard，通常默认用户名为 admin，默认密码为 Kuboard123，访问地址为第一个控制节点的 80 端口（取决于安装时的参数），如下图所示：\n点击进入 default 集群，在下图所示的页面点击创建spark 命名空间：\n3.3 配置 spark 用户权限 创建用户spark 并配置权限\nkubectl create serviceaccount spark\rkubectl create clusterrolebinding spark-role --clusterrole=edit --serviceaccount=spark:spark --namesparce=spark\r3.4 配置 spark 历史服务器 创建一个名为spark-history-server 的 deployment，配置如下：\n容器信息：\n名称：spark-history-server\n容器镜像：registry.cn-hangzhou.aliyuncs.com/[用户名]/spark:0.1（需配置仓库仓库名和密码）\n环境变量：SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=hdfs://192.168.0.238:8020/sparkhistory（需提前部署 HDFS)\n容器端口：18080，端口名称 http\n参数：[\u0026quot;/opt/spark/bin/spark-class\u0026quot;, \u0026ldquo;org.apache.spark.deploy.history.HistoryServer\u0026rdquo;]\n服务信息：\n端口：18080\n协议：TCP\n目标端口：18080\nNodePort：30080\n类型：NodePort\n测试配置是否成功：\n./spark-submit \\\r--master k8s://https://127.0.0.1:6443 \\\r--deploy-mode cluster \\\r--name spark-pi \\\r--class org.apache.spark.examples.SparkPi \\\r--conf spark.kubernetes.executor.request.cores=1 \\\r--conf spark.kubernetes.executor.limit.cores=1 \\\r--conf spark.kubernetes.driver.limit.cores=1 \\\r--conf spark.kubernetes.driver.request.cores=1 \\\r--conf spark.eventLog.enabled=true \\\r--conf spark.eventLog.dir=hdfs://192.168.0.238:8020/sparkhistory \\\r--conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \\\r--conf spark.kubernetes.namespace=bigdata \\\r--conf spark.executor.instances=2 \\\r--conf spark.kubernetes.file.upload.path=/tmp \\\r--conf spark.kubernetes.container.pullSecrets=aliyun-repository \\\r--conf spark.kubernetes.container.image=registry.cn-hangzhou.aliyuncs.com/cuterwrite/spark:0.1 \\\rhdfs://192.168.0.238:8020/user/root/jars/spark-examples_2.12-3.3.1.jar\r提交任务成功后可以在 Kuboard 管理界面看到一个新启动的容器组：\n访问 spark 历史服务器，可以看到以下记录：\n4 编写 WordCount 程序 WordCount.java\npackage com.cuterwrite;\rimport org.apache.spark.api.java.function.FlatMapFunction;\rimport org.apache.spark.sql.Dataset;\rimport org.apache.spark.sql.Encoders;\rimport org.apache.spark.sql.Row;\rimport org.apache.spark.sql.SparkSession;\rimport java.util.Arrays;\rimport java.util.Iterator;\rpublic class WordCount {\rpublic static void main(String[] args) throws Exception {\rSparkSession spark = SparkSession.builder().appName(\u0026quot;WordCount\u0026quot;).getOrCreate();\rDataset\u0026lt;String\u0026gt; lines = spark.read().textFile(\u0026quot;hdfs://192.168.0.238:8020/input/news.txt\u0026quot;);\rDataset\u0026lt;String\u0026gt; words = lines.flatMap(new FlatMapFunction\u0026lt;String, String\u0026gt;() {\r@Override\rpublic Iterator\u0026lt;String\u0026gt; call(String line) throws Exception {\rreturn Arrays.asList(line.split(\u0026quot; \u0026quot;)).iterator();\r}\r}, Encoders.STRING());\rDataset\u0026lt;Row\u0026gt; wordCounts = words.groupBy(\u0026quot;value\u0026quot;).count();\rwordCounts.write().format(\u0026quot;csv\u0026quot;).save(\u0026quot;hdfs://192.168.0.238:8020/output/word_count_result\u0026quot;);\r}\r}\r5 实验结果 提交词频统计任务到Kubernetes ./spark-submit \\\r--master k8s://https://127.0.0.1:6443 \\\r--deploy-mode cluster \\\r--name wordcount \\\r--class com.cuterwrite.WordCount \\\r--conf spark.kubernetes.executor.request.cores=2 \\\r--conf spark.kubernetes.executor.limit.cores=2 \\\r--conf spark.kubernetes.driver.limit.cores=1 \\\r--conf spark.kubernetes.driver.request.cores=1 \\\r--conf spark.eventLog.enabled=true \\\r--conf spark.eventLog.dir=hdfs://192.168.0.238:8020/sparkhistory \\\r--conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \\\r--conf spark.kubernetes.namespace=bigdata \\\r--conf spark.executor.instances=3 \\\r--conf spark.kubernetes.file.upload.path=/tmp \\\r--conf spark.kubernetes.container.pullSecrets=aliyun-repository \\\r--conf spark.kubernetes.container.image=registry.cn-hangzhou.aliyuncs.com/cuterwrite/spark:0.1 \\\rhdfs://192.168.0.238:8020/user/root/jars/SparkApp-1.0.jar\r执行结果： hdfs dfs -cat output/wordCount/_temporary/0/task_202212221534101760903765384745539_0002_m_000000/*\r","date":"2022-12-23T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/92.webp","permalink":"https://cuterwrite.top/p/spark-on-k8s/","title":"基于 Spark on k8s 的词频统计实验"},{"content":"MapReduce 实验 1 简介 1.1 实验环境 本实验主要使用 Ubuntu 20.04 64 位作为系统环境，采用 3 台 4 核 8GB 云服务器作为 Haddop 集群部署机器，使用的软件如下：\n名称 版本 Hadoop 3.2.3 IDEA 2022.2.3 1.2 集群规划 主机名 IP DataNode NameNode JournalNode ZKFC node1 192.168.0.76 是 是 是 是 node2 192.168.0.213 是 是 是 是 node3 192.168.0.2 是 否 是 否 2 在 IDEA 中创建项目 打开 IDEA 界面，点击File-\u0026gt;New Project，选择Maven Archetype，创建一个名为MapReduce的 Maven 项目：\n编写pom.xml 文件，内容如下：\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt;\r\u0026lt;project xmlns=\u0026quot;http://maven.apache.org/POM/4.0.0\u0026quot;\rxmlns:xsi=\u0026quot;http://www.w3.org/2001/XMLSchema-instance\u0026quot;\rxsi:schemaLocation=\u0026quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026quot;\u0026gt;\r\u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt;\r\u0026lt;groupId\u0026gt;com.cuterwrite\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;MapReduce\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt;\r\u0026lt;properties\u0026gt;\r\u0026lt;maven.compiler.source\u0026gt;11\u0026lt;/maven.compiler.source\u0026gt;\r\u0026lt;maven.compiler.target\u0026gt;11\u0026lt;/maven.compiler.target\u0026gt;\r\u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt;\r\u0026lt;/properties\u0026gt;\r\u0026lt;dependencies\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.apache.hadoop\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;hadoop-client\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;3.2.3\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;/dependencies\u0026gt;\r\u0026lt;/project\u0026gt;\r3 编写 MapReduce 应用程序 分别编写IntSumReducer.java、TokenizerMapper.java、WordCount.java 文件：\npackage com.cuterwrite;\rimport org.apache.hadoop.io.IntWritable;\rimport org.apache.hadoop.io.Text;\rimport org.apache.hadoop.mapreduce.Reducer;\rimport java.io.IOException;\rimport java.util.Iterator;\rpublic class IntSumReducer extends Reducer\u0026lt;Text, IntWritable, Text, IntWritable\u0026gt; {\rprivate IntWritable result = new IntWritable();\rpublic IntSumReducer() {\r}\rpublic void reduce(Text key, Iterable\u0026lt;IntWritable\u0026gt; values, Reducer\u0026lt;Text, IntWritable, Text, IntWritable\u0026gt;.Context context)\rthrows IOException, InterruptedException {\rint sum = 0;\rIntWritable val;\rfor (Iterator\u0026lt;IntWritable\u0026gt; iterator = values.iterator(); iterator.hasNext(); sum += val.get()) {\rval = (IntWritable)iterator.next();\r}\rthis.result.set(sum);\rcontext.write(key, this.result);\r}\r}\rpackage com.cuterwrite;\rimport java.io.IOException;\rimport java.util.StringTokenizer;\rimport org.apache.hadoop.io.IntWritable;\rimport org.apache.hadoop.io.Text;\rimport org.apache.hadoop.mapreduce.Mapper;\rpublic class TokenizerMapper extends Mapper\u0026lt;Object, Text, Text, IntWritable\u0026gt; {\rprivate static final IntWritable one = new IntWritable(1);\rprivate Text word = new Text();\rpublic TokenizerMapper() {\r}\rpublic void map(Object key, Text value, Mapper\u0026lt;Object, Text, Text, IntWritable\u0026gt;.Context context) throws IOException, InterruptedException {\rStringTokenizer tokenizer = new StringTokenizer(value.toString());\rwhile (tokenizer.hasMoreTokens()) {\rthis.word.set(tokenizer.nextToken());\rcontext.write(this.word, one);\r}\r}\r}\rpackage com.cuterwrite;\rimport org.apache.hadoop.conf.Configuration;\rimport org.apache.hadoop.fs.Path;\rimport org.apache.hadoop.io.IntWritable;\rimport org.apache.hadoop.io.Text;\rimport org.apache.hadoop.mapreduce.Job;\rimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\rimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\rpublic class WordCount {\rpublic WordCount() {}\rpublic static void main(String[] args) throws Exception {\rConfiguration conf = new Configuration();\rconf.set(\u0026quot;fs.defaultFS\u0026quot;, \u0026quot;hdfs://ha-cluster\u0026quot;);\rconf.set(\u0026quot;fs.hdfs.impl\u0026quot;, \u0026quot;org.apache.hadoop.hdfs.DistributedFileSystem\u0026quot;);\rString[] filePath = new String[] {\r\u0026quot;hdfs://ha-cluster/user/root/input/news1.txt\u0026quot;,\r\u0026quot;hdfs://ha-cluster/user/root/input/news2.txt\u0026quot;,\r\u0026quot;hdfs://ha-cluster/user/root/input/news3.txt\u0026quot;\r};\rJob job = Job.getInstance(conf, \u0026quot;word count\u0026quot;);\rjob.setJarByClass(WordCount.class);\rjob.setMapperClass(TokenizerMapper.class);\rjob.setCombinerClass(IntSumReducer.class);\rjob.setReducerClass(IntSumReducer.class);\rjob.setOutputKeyClass(Text.class);\rjob.setOutputValueClass(IntWritable.class);\rfor (int i = 0; i \u0026lt; filePath.length ; i++) {\rFileInputFormat.addInputPath(job, new Path(filePath[i]));\r}\rString outputPath = \u0026quot;hdfs://ha-cluster/user/root/output/mapreduce\u0026quot;;\rFileOutputFormat.setOutputPath(job, new Path(outputPath));\rSystem.exit(job.waitForCompletion(true) ? 0 : 1);\r}\r}\r4 实验结果 将应用程序编译打包成 jar 包：\nmvn clean install\r上传 jar 包至 HDFS 中的jars 目录下：\nhdfs dfs -put MapReduce-1.0-SNAPSHOT.jar jars\r创建 input、output 目录，上传数据文件至 HDFS\nhdfs dfs -mkdir -p input\rhdfs dfs -mkdir -p output\rhdfs dfs -put news1.txt news2.txt news3.txt input\r运行 jar 包：\nhadoop jar MapReduce-1.0-SNAPSHOT.jar com.cuterwrite.WordCount\r查看执行结果：\nhdfs dfs -cat output/mapreduce/*\r","date":"2022-12-22T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/202210221658.webp","permalink":"https://cuterwrite.top/p/mapreduce/","title":"MapReduce 实验"},{"content":"Zookeeper on k8s 部署实验 1 简介 1.1 实验环境 已经使用 Kuboard Spary 搭建好 Kubernetes 集群和 Kuboard，使用的软件如下：\n名称 版本 kuboard spary v1.2.3-amd64 kubernetes v1.25.5 zookeeper 3.8.0 1.2 集群规划 Zookeeper（三台 4 核 8G 的 Ubuntu20.04 服务器） 主机名 IP node1 192.168.0.6 node2 192.168.0.7 node3 192.168.0.14 2 创建 ConfigMap 2.1 创建 zookeeper-environment 创建一个名为zookeeper-environment 的配置字典，包含变量对如下： Key Value ALLOW_ANONYMOUS_LOGIN yes BITNAMI_DEBUG false ZOO_4LW_COMMANDS_WHITELIST srvr, mntr, ruok ZOO_DATA_LOG_DIR ZOO_ENABLE_AUTH no ZOO_INIT_LIMIT 10 ZOO_LOG_LEVEL ERROR ZOO_MAX_CLIENT_CNXNS 60 ZOO_PORT_NUMBER 2181 ZOO_SERVERS zookeeper-statefulset-0.zookeeper-statefulset.bigdata.svc.cluster.local:2888:3888::1 zookeeper-statefulset-1.zookeeper-statefulset.bigdata.svc.cluster.local:2888:3888::2 zookeeper-statefulset-2.zookeeper-statefulset.bigdata.svc.cluster.local:2888:3888::3 ZOO_SYNC_LIMIT 5 ZOO_TICK_TIME 2000 2.2 创建 zookeeper-setup 创建一个名为zookeeper-setup 的配置字典，Key 为setup.sh，value 如下：\n#!/bin/bash\rif [[ -f \u0026quot;/bitnami/zookeeper/data/myid\u0026quot; ]]; then\rexport ZOO_SERVER_ID=\u0026quot;$(cat /bitnami/zookeeper//data/myid)\u0026quot;\relse\rHOSTNAME=\u0026quot;$(hostname -s)\u0026quot;\rif [[ $HOSTNAME =~ (.*)-([0-9]+)$ ]]; then\rORD=${BASH_REMATCH[2]}\rexport ZOO_SERVER_ID=\u0026quot;$((ORD + 1 ))\u0026quot;\relse\recho \u0026quot;Failed to get index from hostname $HOST\u0026quot;\rexit 1\rfi\rfi\rexec /entrypoint.sh /run.sh\r3 创建 StatefulSet 创建一个名为zookeeper-statefulset 的有状态副本集，设置 replica 为3 3.1 创建工作容器 容器名称：zookeeper\n容器镜像：bitnami/zookeeper:3.8.0\n命令：/opt/scripts/setup.sh\n环境变量：引用之前创建的配置字典zookeeper-environment\n容器端口：2181\n资源请求限制：\nCPU 资源请求：500m\n内存资源请求：500Mi\nCPU 资源限制：500m\n内存资源限制：500Mi\n健康检查：\n容器存活探针：\n执行命令：/bin/bash -c 'echo \u0026quot;ruok\u0026quot; | timeout 2 nc -w 2 localhost 2181 | grep imok'\n初始延迟：30 秒\n执行探测频率：10 秒\n超时时间：5 秒\n健康阈值：1 秒\n不健康阈值：6 秒\n容器就绪探针：与容器存活探针相同\n容器安全上下文：\nrunAsNonRoot：true\n用户：1001\n3.2 创建存储挂载 数据卷：配置字典zookeeper-setup\n挂载路径：/opt/scripts/setup.sh\n子路径：setup.sh\n3.3 创建 SVC 服务类型：NodePort\n端口：\n端口名称 port targetPort client 2181 2181 server 2888 2888 leader-election 3888 3888 3.4 设置亲和性 设置 Node 亲和性（硬策略）\n必须满足标签表达式：app.kubernetes.io/component=zookeeper 设置 Pod 反亲和性（软策略）\n尽量满足标签表达式\n权重：49\ntogologykey：app.kubernetes.io/name\n表达式：app.kubernetes.io/component=zookeeper\n4 部署结果 4.1 集群信息 4.2 节点状态测试 zkServer.sh status\r","date":"2022-12-21T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/202210172323.webp","permalink":"https://cuterwrite.top/p/zookeeper-on-k8s/","title":"Zookeeper on k8s 部署实验"},{"content":" Hadoop3 HA 模式三节点高可用集群搭建实验 关于 Hadoop3 HA 模式 单点故障（SPOF） 简单来说，单点故障指的是分布式系统过度依赖于某一个节点，以至于只要该节点宕掉，就算整个集群的其它节点是完好的，集群也无法正常工作。而单点故障问题一般出现在集群的元数据存储节点上，这种节点一般一个集群就一个，一旦坏了整个系统就不能正常使用。Hadoop 的单点故障出现在 namenode 上，影响集群不可用主要有以下两种情况：一是 namenode 节点宕机，将导致集群不可用，重启 namenode 之后才可使用；二是计划内的 namenode 节点软件或硬件升级，导致集群短时间内不可用。\n为了避免出现单点故障，Hadoop 官方给出了高可用 HA 方案：可以采取同时启动两个 namenode：其中一个工作（active），另一个总是处于后备机（standby）的状态，让它只是单纯地同步活跃机的数据，当活跃机宕掉的时候就可以自动切换过去。这种模式称为HA 模式。HA 模式下不能用[namenode 主机:端口]的模式来访问 Hadoop 集群，因为 namenode 主机已经不再是一个固定的 IP 了，而是采用 serviceid 的方式来访问，这个 serviceid 存储在 ZooKeeper 上。\nZookeeper Zookeeper 是一个轻量级的分布式架构集群，为分布式应用提供一致性服务，提供的功能包括：配置维护、域名服务、分布式同步和组服务等。在 HA 模式中，Zookeeper 最大的功能之一是知道某个节点是否宕机了。其原理是：每一个机器在 Zookeeper 中都有一个会话，如果某个机器宕机了，这个会话就会过期，Zookeeper 就能发现该节点已宕机。\n实验过程和结果 环境 本实验使用 Ubuntu 18.04 64 位作为系统环境，采用 3 台 2 核 16GB（ MA3.MEDIUM16 型号）的腾讯云服务器作为集群部署机器。\n使用的软件如下：\n名称 版本 Hadoop 3.2.3 Zookeeper 3.6.3 JDK 11.0.2 建议：在以下的部署过程中使用 root 用户可以避免很多权限问题。\n集群规划 主机名 IP Namenode Datanode Zookeeper JournalNode master 172.31.0.12 是 是 是 是 slave1 172.31.0.16 是 是 是 是 slave2 172.31.0.10 否 是 是 是 创建 hadoop 用户 在终端输出如下命令创建一个名为 hadoop 的用户。\nsudo useradd -m hadoop -s /bin/bash\r接着使用如下命令设置密码，按提示输入两次密码，这里简单设置为 hadoop\nsudo passwd hadoop\r此外，可以为 hadoop 用户添加管理员权限，方便后续的部署，避免一些权限问题的出现。\nsudo adduser hadoop sudo\r主机名和网络映射配置 为了便于区分 master 节点和 slave 节点，可以修改各个节点的主机名。在 Ubuntu 系统中，我们可以执行以下命令来修改主机名。\nsudo vim /etc/hostname\r执行上面命令后，就打开了/etc/hostname 这个文件，这个文件记录了主机名。打开这个文件之后，里面只有当前的主机名这一行内容，可以直接删除，并修改为 master 或 slave1、slave2，然后保存退出 vim 编辑器，这样就完成了主机名的修改，需要重启系统后才能看到主机名的变化。\n然后，在 master 节点中执行如下命令打开并修改 master 节点的/etc/hosts 文件\nsudo vim /etc/hosts\r在 hosts 文件中增加如下三条 IP（局域网 IP）和主机名映射关系。\n172.31.0.12 master\r172.31.0.16 slave1\r172.31.0.10 slave2\r需要注意的是，一般 hosts 文件中只能有一个 127.0.0.1，其对应主机名为 localhost，如果有多余 127.0.0.1 映射，应删除，特别是不能存在“127.0.0.1 Master”这样的映射记录。修改后需要重启 Linux 系统。\n上面完成了 master 节点的配置，接下来要继续完成对其他 slave 节点的配置修改。请参照上面的方法，把 slave1 节点上的“/etc/hostname”文件中的主机名修改为“slave1”，把 slave1 节点上的“/etc/hostname”文件中的主机名修改为“slave2”同时，修改“/etc/hosts”的内容，在 hosts 文件中增加如下三条 IP 和主机名映射关系：\n172.31.0.12 master\r172.31.0.16 slave1\r172.31.0.10 slave2\r修改完成以后，重新启动 slave 节点的 Linux 系统。\n这样就完成了 master 节点和 slave 节点的配置，然后，需要在各个节点上都执行如下命令，测试是否相互 ping 得通，如果 ping 不通，后面就无法顺利配置成功：\nping master -c 3\rping slave1 -c 3\rping slave2 -c 3\r例如，在 master 节点上 ping slave1，如果 ping 通的话，会显示如下图所示的结果：\n安装 SSH 并配置 SSH 免密登录 集群模式需要用到 SSH 登陆，Ubuntu 默认已经安装 SSH client，此外还需要安装 SSH server\nsudo apt-get install openssh-server\r安装后，可以使用如下命令登陆本机\nssh localhost\r在集群模式中，必须要让 master 节点可以 SSH 免密登录到各个 slave 节点上。首先，生成 master 节点的公钥，如果之前已经生成过公钥，必须要删除原来生成的公钥，重新生成一次。具体命令如下：\ncd ~/.ssh #如果没有该目录，先执行一次 ssh localhost\rrm ./id_rsa* #删除之前生成的公钥\rssh-keygen -t rsa #执行该命令后一直按回车就可以\r为了让 master 节点能够 SSH 免密登录本机，需要在 master 节点上执行如下命令：\ncat ./id_rsa.pub \u0026gt;\u0026gt; ./authorized_keys\r完成后可以执行“ssh master”来验证一下，可能会遇到提示信息，输入 yes 即可，测试成功后执行 exit 命令返回原来的终端。\n接下来，在 master 节点上将公钥传输到 slave1 和 slave2 节点\nscp ~/.ssh/id_rsa.pub hadoop@slave1:/home/hadoop/\rscp ~/.ssh/id_rsa.pub hadoop@slave2:/home/hadoop/\r接着在 slave1（slave2）节点上将 SSH 公钥加入授权\nmkdir ~/.ssh\rcat ~/id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys\rrm ~/id_rsa.pub #用完之后可以删除掉\r这样，master 节点就可以免密登录到各个 slave 节点上了，例如执行如下命令：\nssh slave1\r会显示如下结果，显示已经登录到 slave1 节点上。\n安装 Java 环境 Hadoop3 需要 JDK 版本在 1.8 以上，这里我选择 11 版本 JDK 作为 Java 环境，先执行以下命令下载压缩包。\ncd /usr/local/softwares;\rsudo wget https://repo.huaweicloud.com/openjdk/11.0.2/openjdk-11.0.2_linux-x64_bin.tar.gz\r然后，使用如下命令解压缩：\nsudo tar -xzf openjdk-11.0.2_linux-x64_bin.tar.gz;\rsudo mv jdk-11.0.2 openjdk;\r这时，可以执行以下命令查看是否安装成功\ncd openjdk;\r./bin/java --version;\r如果返回如下信息，则说明安装成功：\n安装 hadoop3 先执行以下命令下载压缩包。\ncd /usr/local/softwares;\rsudo wget https://mirrors.pku.edu.cn/apache/hadoop/common/hadoop-3.2.3/hadoop-3.2.3.tar.gz\r然后，使用如下命令解压缩：\nsudo tar -xzf hadoop-3.2.3.tar.gz;\rsudo mv hadoop-3.2.3 hadoop\r这时，可以执行以下命令查看是否安装成功\ncd hadoop;\r./bin/hadoop version\r如果返回如下信息，则说明安装成功：\n安装 Zookeeper 先执行以下命令下载压缩包。\ncd /usr/local/softwares;\rsudo wget https://mirrors.pku.edu.cn/apache/zookeeper/stable/apache-zookeeper-3.6.3-bin.tar.gz;\r然后，使用如下命令解压缩：\nsudo tar -xzf apache-zookeeper-3.6.3-bin.tar.gz;\rsudo mv apache-zookeeper-3.6.3-bin zookeeper;\r接下来，将 Zookeeper 中的 conf 文件夹里的 zoo_sample.cfg 文件复制一份，改名为 zoo.cfg，然后编辑这个文件，其他的部分不用动，需要修改 dataDir 这一行。dataDir 是 ZooKeeper 的数据文件夹的位置，在我的机器上我用的是/data/zookeeper，你们可以设置成你们的目录。此外，需要在末尾加上所有节点的信息（数字与 myid 要对应）：\nserver.1=master:2888:3888\rserver.2=slave1:2888:3888\rserver.3=slave2:2888:3888\r然后再修改 bin/zkEnv.sh，添加以下日志输出文件夹配置：\nZOO_LOG_DIR=/data/logs/zookeeper\r最后，需要在每一个节点上的 dataDir 目录下手动创建一个文件，命名为 myid，并写入这台服务器的 Zookeeper ID。这个 ID 数字可以自己随便写，取值范围是 1~255，在这里我将 master、slave1 和 slave2 分别取值为 1，2，3。配置完成以上全部后，分别使用 zkServer.sh start 命令启动集群，ZooKeeper 会自动根据配置把所有的节点连接成一个集群。启动后使用 jps 命令可以查看到 QuorumPeerMain 进程已经启动成功。\n配置环境变量 配置环境变量后可以在任意目录中直接使用 hadoop、hdfs 等命令。配置方法也比较简单。首先执行命令：\nsudo vim ~/.bashrc\r然后，在该文件最上面的位置加入下面内容：\nexport JAVA_HOME=/usr/local/softwares/openjdk\rexport HADOOP_HOME=/usr/local/softwares/hadoop\rexport HADOOP_PREFIX=$HADOOP_HOME\rexport HADOOP_MAPRED_HOME=$HADOOP_HOME\rexport HADOOP_COMMON_HOME=$HADOOP_HOME\rexport HADOOP_HDFS_HOME=$HADOOP_HOME\rexport YARN_HOME=$HADOOP_HOME\rexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/natvie\rexport HADOOP_INSTALL=$HADOOP_HOME\rexport ZK_HOME=/usr/local/softwares/zookeeper\rexport PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$ZK_HOME/bin\r保存后执行如下命令使配置生效：\nsource ~/.bashrc\r配置 HA 模式集群分布式环境 修改文件 workers 需要把所有数据节点的主机名写入该文件，每行一个，默认为 localhost（即把本机作为数据节点），在本实验中，master 和 slave1、slave2 都充当 datanode，所以该文件内容配置如下：\nmaster\rslave1\rslave2\r修改文件 core-site.xml 在一般集群模式中，fs.defaultFS 配置为 hdfs://master:9000，即名称节点所在的主机名加上端口号，但需要注意的是，在 HA 模式下分别有一个 active 和 standby 的名称节点，需要将该属性设置为集群 id，这里写的 ha-cluster 需要与 hdfs-site.xml 中的配置一致，所以将该文件修改为如下内容：\n\u0026lt;configuration\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;fs.defaultFS\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;hdfs://ha-cluster\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;ha.zookeeper.quorum\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;master:2181,slave1:2181,slave2:2181\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;ha.zookeeper.session-timeout.ms\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;30000\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;/configuration\u0026gt;\r修改文件 hdfs-site.xml 对以下属性进行配置：\n\u0026lt;configuration\u0026gt;\r\u0026lt;!-- 服务 ID--\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.nameservices\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;ha-cluster\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.ha.namenodes.ha-cluster\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;master,slave1\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;!-- rpc 地址--\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.namenode.rpc-address.ha-cluster.master\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;master:8020\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.namenode.rpc-address.ha-cluster.slave1\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;slave1:8020\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;!-- http 地址--\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.namenode.http-address.ha-cluster.master\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;master:9870\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.namenode.http-address.ha-cluster.slave1\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;slave1:9870\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;!-- journalnode 集群访问地址--\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.namenode.shared.edits.dir\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;qjournal://master:8485;slave1:8485;slave2:8485/ha-cluster\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;!-- dfs 客户端--\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.client.failover.proxy.provider.ha-cluster\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;!-- 配置 kill 方式--\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.ha.fencing.methods\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;sshfence\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.ha.fencing.ssh.private-key-files\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;/home/hadoop/.ssh/id_rsa\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;!-- 自动 failover 机制--\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.ha.automatic-failover.enabled\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;true\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;ha.zookeeper.quorum\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;master:2181,slave1:2181,slave2:2181\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;!-- 冗余因子，datanode 有 3 个，所以设置为 3--\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.replication\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;3\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.namenode.name.dir\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;file:/data/hadoop/hdfs/nn\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.datanode.data.dir\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;file:/data/hadoop/hdfs/dn\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;!-- 不要加 file 前缀--\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;dfs.journalnode.edits.dir\u0026lt;/name\u0026gt;\r\u0026lt;value\u0026gt;/data/hadoop/hdfs/jn\u0026lt;/value\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;/configuration\u0026gt;\r修改文件 hadoop-env.sh 在文件开头添加以下变量\nexport HADOOP_NAMENODE_OPS=\u0026quot; -Xms1024m -Xmx1024m -XX:+UseParallelGC\u0026quot;\rexport HADOOP_DATANODE_OPS=\u0026quot; -Xms1024m -Xmx1024m\u0026quot;\rexport HADOOP_LOG_DIR=/data/logs/hadoop\r在所有节点上创建数据文件夹和日志文件夹 sudo mkdir -p /data/hadoop/hdfs/nn;\rsudo mkdir -p /data/hadoop/hdfs/dn;\rsudo mkdir -p /data/hadoop/hdfs/jn;\rsudo mkdir -p /data/zookeeper;\rsudo chown -R hadoop.hadoop /data/hadoop;\rsudo chown -R hadoop.hadoop /data/zookeeper;\rsudo mkdir /data/logs;\rsudo mkdir /data/logs/hadoop;\rsudo mkdir /data/logs/zookeeper;\rsudo chown -R hadoop.hadoop /data/logs\r在所有节点上分别启动 journalnode hdfs --daemon start journalnode\r格式化 namenode 节点 在第一个 namenode 上进行格式化并启动 hdfs：\nhdfs namenode -format;\rhdfs --daemon start namenode\r在第二个 namenode 上进行备用初始化\nhdfs namenode -bootstrapStandby\r在第一个 namenode 上进行 journalnode 的初始化\nhdfs namenode -initializeSharedEdits\r分别在 namenode 节点上启动 zkfc hdfs zkfc -formatZK\r在主节点上启动所有 datanode 节点 start-dfs.sh\r实验结果 实例运行 首先创建 HDFS 上的用户目录，命令如下：\nhdfs dfs -mkdir -p /user/hadoop\r然后，在 HDFS 中创建一个 input 目录，并将“/usr/local/softwares/hadoop/etc/hadoop”目录中的配置文件作为输入文件复制到 input 目录中，命令如下：\nhdfs dfs -mkdir input;\rhdfs dfs -put /usr/local/softwares/hadoop/etc/hadoop/*.xml input\r接着就可以运行 MapReduce 作业了，命令如下：\nhadoop jar /usr/local/softwares/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.3.jar grep input output 'dfs[a-z.]+'\r运行结果如下：\n补充：可选配置 HDFS Web UI 配置认证 HDFS 带有一个可视化的端口号默认为 9870 的 Web UI 界面，这个界面如果没有做防火墙限制的话会暴露在公网上。而该界面又存在着大量的日志和配置信息，直接暴露在公网上不利于系统的安全，所以在这里可以配置一个简单的系统认证功能。步骤如下：\n安装 httpd 或安装 httpd-tools\nsudo apt-get install httpd\r安装 nginx：这部分内容较多，不是重点，网上有大量的教程，跟着其中一个进行就行。\n通过 htpasswd 命令生成用户名和密码数据库文件\nhtpasswd -c passwd.db [username]\r查看生成的 db 文件内容\ncat passwd.db\r通过 nginx 代理并设置访问身份验证\n# nginx 配置文件\rvim nginx.conf\rserver {\r# 使用 9871 端口替代原有的 9870 端口\rlisten 9871;\rserver_name localhost;\rlocation / {\rauth_basic \u0026quot;hadoop authentication\u0026quot;;\rauth_basic_user_file /home/hadoop/hadoop/passwd.db\rproxy_pass http://127.0.0.1:9870\r}\r}\r重新加载 nginx 配置\ncd /usr/local/lighthouse/softwares/nginx/sbin\r./nginx -s reload\r启动 nginx\nsystemctl start nginx\r到此为止，HDFS Web UI 界面认证设置完成，效果如下：.\n","date":"2022-09-22T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/32756284e8854b9ba653bd3632af435d.webp","permalink":"https://cuterwrite.top/p/hadoop-ha/","title":"Hadoop3 HA 模式三节点高可用集群搭建实验"},{"content":"路径规划算法之 A* 与 D* Lite 原理详解 问题描述 如何在一个网格地图中找到两点之间的最短路径\n基础算法介绍 如果要在一个网格地图中找到两点之间的最短路径，很容易想到的广度优先算法（Breadth First）、最佳优先算法和 Dijkstra 算法。\n广度优先搜索 广度优先搜索算法如其名称所示以广度做为优先级进行搜索。\n从起点开始，首先遍历起点周围邻近的点，然后再遍历已经遍历过的点邻近的点，逐步的向外扩散，直到找到终点。\n这种算法就像洪水（Flood fill）一样向外扩张，算法的过程如下图所示：\n广度优先算法的优点是一定可以找到两点间的最优路径，但是代价就是需要搜索的点非常多，速度会比较慢。\n最佳优先算法 在一些情况下，如果我们可以预先计算出每个节点到终点的距离，则我们可以利用这个信息更快的到达终点。\n最佳优先算法和广度优先算法不同，它需要使用一个优先队列，用每个节点到终点的距离作为优先级每次始终选取到终点移动代价最小（离终点最近）的节点作为下一个遍历的节点，直到到达终点。这种算法称之为最佳优先（Best First）算法。和广度优先相比，最佳优先所需要搜索的点要少很多，可以大大加快路径的搜索速度，如下图所示：\n但最佳优先算法的缺点就是，当起点和终点有障碍物时，可能最佳优先算法找到的路径并不是最佳的路径，下图描述了这种情况：\nDijkstra 算法 Dijkstra 算法是由计算机科学家Edsger W. Dijkstra\r在 1956 年提出的\nDijkstra 算法用来寻找图形中节点之间的最短路径。\n考虑这样一种场景，在一些情况下，图形中相邻节点之间的移动代价并不相等。例如，游戏中的一幅图，既有平地也有山脉，那么游戏中的角色在平地和山脉中移动的速度通常是不相等的。\n在 Dijkstra 算法中，需要计算每一个节点距离起点的总移动代价。同时，还需要一个优先队列结构。对于所有待遍历的节点，放入优先队列中会按照代价进行排序。\n在算法运行的过程中，每次都从优先队列中选出代价最小的作为下一个遍历的节点。直到到达终点为止。\n下面对比了不考虑节点移动代价差异的广度优先搜索与考虑移动代价的 Dijkstra 算法的运算结果：\n当图形为网格图，并且每个节点之间的移动代价是相等的，那么 Dijkstra 算法将和广度优先算法变得一样。\nA* 算法 A* 算法最初发表于 1968 年，由 Stanford 研究院的 Peter Hart, Nils Nilsson 以及 Bertram Raphael 发表。它可以被认为是 Dijkstra 算法的扩展。\n由于借助启发函数的引导，A*算法通常拥有更好的性能。\nA* 算法通过下面这个函数来计算每个节点的优先级。 $$ f(n) = g(n) + h(n) $$ 其中：\nf(n) 是节点 n 的综合优先级。当我们选择下一个要遍历的节点时，我们总会选取综合优先级最高（值最小）的节点。 g(n) 是节点 n 距离起点的实际代价。 h(n) 是启发函数，是节点 n 到终点的估计值 在极端情况下，启发函数始终为 0，则将由 g(n)g(n)决定节点的优先级，此时算法就退化成了 Dijkstra 算法。 如果 h(n)始终小于等于节点 n 到终点的代价，则 A*算法保证一定能够找到最短路径。但是当 h(n)的值越小，算法将遍历越多的节点，也就导致算法越慢。 如果 h(n)完全等于节点 n 到终点的代价，则 A*算法将找到最佳路径，并且速度很快。可惜的是，并非所有场景下都能做到这一点。因为在没有达到终点之前，我们很难确切算出距离终点还有多远。 如果 h(n)的值比节点 n 到终点的代价要大，则 A*算法不能保证找到最短路径，不过此时会很快。 在另外一个极端情况下，如果 h(n)相较于 g(n)大很多，则此时只有 h(n)产生效果，这也就变成了最佳优先搜索。 由上面这些信息我们可以知道，通过调节启发函数我们可以控制算法的速度和精确度。因为在一些情况，我们可能未必需要最短路径，而是希望能够尽快找到一个路径即可。这也是 A*算法比较灵活的地方。\n对于网格形式的图，有以下这些启发函数可以使用：\n如果图形中只允许朝上下左右四个方向移动，则可以使用曼哈顿距离（Manhattan distance）。 如果图形中允许朝八个方向移动，则可以使用对角距离。 如果图形中允许朝任何方向移动，则可以使用欧几里得距离（Euclidean distance）。 A* 算法还需要使用两个集合来表示待遍历的节点，与已经遍历过的节点。\nOpenList：可到达的节点 CloseList：已到达的节点 A* 算法具体的运行过程为：每次从优先队列中选取 f(n)值最小（优先级最高）的节点作为下一个待遍历的节点，如果该节点是目标节点，则直接返回，算法结束。如果不是，则遍历其邻居节点，对所有不在 CloseList 中的、在网格范围内的、非障碍物的节点，计算其中 F 值、G 值和 H 值，添加到优先队列（OpenList）中和 CloseList 中。\nA* 算法 Java 实现如下图所示：\nA* 算法变种 A* 算法有不少的变种，主要有如下算法：\nARA * ：ARA* - Anytime A* with Provable Bounds on Sub-Optimality\rD* ：D* 是 Dynamic A* 的简写，其算法和 A*类似，不同的是，其代价的计算在算法运行过程中可能会发生变化。\nProject “Fast Replanning （Incremental Heuristic Search）”\rReal-Time Replanning in Dynamic and Unknown Environments\rField D* ： Field D* 扩展了 D* 和 D* Lite，是一种基于插值（ interpolation-based ）的规划算法，它使用线性插值来有效地生成低成本路径，从而消除不必要的转向。\n在给定线性插值假设的情况下，路径是最优的，并且在实践中非常有效。该算法目前被各种现场机器人系统使用。\n关于 Field D* 的详细内容可以看下面这篇论文：\nField D*: An Interpolation-based Path Planner and Replanner\rD* Lite 算法 D* Lite 算法是一种增量启发式搜素算法，由 Sven Koeing 和 Maxim Likhachev 于 2004 年提出，是基于 LPA* 和 Dynamic SWSF-FP 的一种算法。D* Lite 算法可以适用于地图未知、环境随时会发生变化的情况，在遇到新增加的障碍物时，可以利用先前搜索所获得的信息，而不需要完全重新规划路径。\nD* Lite 的启发函数与 A* 类似，同样有一个启发函数，不过因为 D* Lite 是从终点向起点搜索，所以对应的启发函数 h(n) 也变成了节点 n 到起点的估计值。\nD* Lite 中几个概念的定义：\ng(n)：当前节点到终点的实际代价\nh(n)：当前节点到起点的估计值\nrhs（right-hand side)：公式如下\n一个点的 rhs 值是它的父代节点中 g 值加上这两点之间的代价中的最小值，相当于一个点从父代节点到达这个点的最小代价。其实在算法的大部分过程中，g 值和 rhs 值是相等的。\n两个 key 值：在 A* 算法中，通过 f(n) 的大小来判断一个点的优先级，而在 D* Lite 中，需要通过两个 key 值来判断一个点的优先级，key 值越小优先级越高，先判断第一个 key 值，如果第一个 key 值相等再判断第二个 key 值。公式如下：\n其中 km 的定义为，算法初始化时会先将 km 设置为 0，之后当机器人有检测到地图的变化时，km 需要加上上一个起点与当前位置的启发距离，并且把当前所在的点设置为新的起点，即更新起点的位置。\n如果在机器人还没有移动的时候 km 就等于 0，这时算法其实就相当于一个反向从终点往起点方向搜索的 A* 算法了。\n当机器人检测到障碍的变化时会再一次规划路径，这时候的实际起点应该是机器人当前的位置，起点发生了变化，每个点的 h 值也会相应变化，key 值也发生了变化。如果不引入这个参数的话，就需要把优先队列中的全部节点都重新计算一遍 key 值，增加了计算量。引入之后就可以一定程度上保证 key 值的一致性，减少计算量。\n第二 key 值就是 g 值和 rhs 值中的最小值，它的意义在于当两个点的第一个 key 值相等的时候，算法会优先选择距离终点近的点。\n局部一致性：D* Lite 算法中还有一个很重要的概念就是局部一致性，通过一个点的局部一致性来判断当前点是否需要计算。其定义如下：当一个点的 g 值等于 rhs 值时称这个点为局部一致的点，否则称这个点为局部不一致。其中局部不一致的情况还可细分成为局部过一致和局部欠一致：当一个点的 g 值大于 rhs 值时，这个点为局部过一致，通常是有障碍物删除时或者算法第一次搜索路径时；当一个点的 g 值小于 rhs 值时，这个点为局部欠一致，通常是检测到了新增的障碍物。\nD* Lite 算法的步骤：\n将当前点设置为起点 将优先队列设置为空队列，将所有节点的 g 值和 rhs 值设置为无穷，将终点的 rhs 值设为 0，并且计算它的 key 值加入到优先队列中。 调用 ComputeShortestPath()开始计算它的最短路径 移动到子代中 g 值加上这两个点之间代价中最小的点。 如果检测到了障碍的变化，根据上一个起点和当前点的启发值，修改 k_m 的值，并将当前节点设置为新的起点。 对所有两个点之间的代价发生变化的，更新这两个点之间的代价，如果两个点之间的代价变小，说明有障碍物删除，更新它的 rhs 值，如果代价变大了，说明新增了一个障碍物，需要通过它的子代来更新 rhs 值。 更新受影响的节点。 计算最短路径。 D* Lite 算法 Java 代码实现还未完成\npython 版代码参考：https://github.com/avgaydashenko/d_star\r参考文献 [1]路径规划之 A*算法\r[2]路径规划之 D* Lite 算法详解及实现\r","date":"2021-08-31T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/photo-1563207153-f403bf289096.4ciiq7uwjl40.webp","permalink":"https://cuterwrite.top/p/route-planning-alogrithm/","title":"路径规划算法之 A* 与 D* Lite 原理详解"},{"content":"聊聊前缀树 Trie Trie 树简介 Trie 树，也叫“字典树”。顾名思义，它是一个树形结构。它是一种专门处理字符串匹配的数据结构，用来解决在一组字符串集合中快速查找某个字符串的问题。\n此外 Trie 树也称前缀树（因为某节点的后代存在共同的前缀，比如 pan 是 panda 的前缀）。\n它的 key 都为字符串，能做到高效查询和插入，时间复杂度为 O(k)，k 为字符串长度，缺点是如果大量字符串没有共同前缀时很耗内存。\n它的核心思想就是通过最大限度地减少无谓的字符串比较，使得查询高效率，即「用空间换时间」，再利用共同前缀来提高查询效率。\nTrie 树特点 假设有 5 个字符串，它们分别是：code，cook，five，file，fat。现在需要在里面多次查找某个字符串是否存在。常见的方案有：①如果每次查找，都是拿要查找的字符串跟这 5 个字符串依次进行字符串匹配，时间复杂度为 O(n)。②将字符串存入 HashSet 中，查找的时候时间复杂度为 O(1)，但是缺点是空间复杂度高，假如有大量的字符串（比如 10 亿条）则会浪费大量的空间。\nTrie 树则通过空间换时间的方式，将字符串组织成下图的结构：\n通过上图，可以发现 Trie 树 的三个特点：\n根节点不包含字符，除根节点外每一个节点都只包含一个字符 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串 每个节点的所有子节点包含的字符都不相同 Trie 树的插入操作 Trie 树的插入操作很简单，其实就是将单词的每个字母逐一插入 Trie 树。插入前先看字母对应的节点是否存在，存在则共享该节点，不存在则创建对应的节点。比如要插入新单词cook，就有下面几步：\n插入第一个字母 c，发现 root 节点下方存在子节点 c，则共享节点 c 插入第二个字母 o，发现 c 节点下方存在子节点 o，则共享节点 o 插入第三个字母 o，发现 o 节点下方不存在子节点 o，则创建子节点 o 插入第三个字母 k，发现 o 节点下方不存在子节点 k，则创建子节点 k 至此，单词 cook 中所有字母已被插入 Trie 树 中，然后设置节点 k 中的标志位，标记路径 root-\u0026gt;c-\u0026gt;o-\u0026gt;o-\u0026gt;k 这条路径上所有节点的字符可以组成一个单词cook Trie 树的查询操作 在 Trie 树中查找一个字符串的时候，比如查找字符串 code，可以将要查找的字符串分割成单个的字符 c，o，d，e，然后从 Trie 树的根节点开始匹配。如图所示，绿色的路径就是在 Trie 树中匹配的路径\nTrie 树的删除操作 Trie 树的删除操作与二叉树的删除操作有类似的地方，需要考虑删除的节点所处的位置，这里分三种情况进行分析： 删除整个单词（比如hi）\n从根节点开始查找第一个字符h 找到h 子节点后，继续查找h 的下一个子节点i i 是单词hi 的标志位，将该标志位去掉 i 节点是hi 的叶子节点，将其删除 删除后发现h 节点为叶子节点，并且不是单词标志位，也将其删除 这样就完成了hi 单词的删除操作 删除前缀单词（比如cod）\n这种方式删除比较简单。 只需要将cod 单词整个字符串查找完后，d 节点因为不是叶子节点，只需将其单词标志去掉即可。\n删除分支单词（比如cook）\n与 删除整个单词 情况类似，区别点在于删除到 cook 的第一个 o 时，该节点为非叶子节点，停止删除，这样就完成cook 字符串的删除操作。\nTrie 树应用与实现 事实上 Trie 树 在日常生活中的使用随处可见，比如这个： 具体来说就是经常用于统计和排序大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是：最大限度地减少无谓的字符串比较，查询效率比哈希表高。\n实现：最简单的字典树\nclass TrieNode {\rString word;\rboolean isEnd;\rTrieNode[] children;\rpublic TrieNode() {\rchildren = new TrieNode[26];\r}\r}\r前缀匹配/自动补全 例如：找出一个字符串集合中所有以 五分钟 开头的字符串。我们只需要用所有字符串构造一个 trie 树，然后输出以 五−\u0026gt;分−\u0026gt;钟 开头的路径上的关键字即可。 trie 树前缀匹配常用于搜索提示。如当输入一个网址，可以自动搜索出可能的选择。当没有完全匹配的搜索结果，可以返回前缀最相似的可能\n实现：自动补全功能\n（1）先找出匹配词语的节点（可能是中间的路径，不一定是最终节点）\n（2）递归的查询该节点下的所有单词\npublic class Trie {\rprivate class TrieNode {\rString word;\rboolean isEnd;\rMap\u0026lt;Character, TrieNode\u0026gt; children;\rpublic TrieNode() {\rchildren = new HashMap\u0026lt;\u0026gt;();\r}\r}\rTrieNode root;\rpublic Trie() {\rroot = new TrieNode();\r}\rpublic void insert(String word) {\rTrieNode node = root;\rfor (char c : word.toCharArray()) {\rif (!node.children.containsKey(c)) {\rnode.children.put(c, new TrieNode());\r}\rnode = node.children.get(c);\r}\rnode.isEnd = true;\rnode.word = word;\r}\rpublic List\u0026lt;String\u0026gt; autoComplete(TrieNode node, String word) {\rList\u0026lt;String\u0026gt; res = new ArrayList\u0026lt;\u0026gt;();\rfor (char c : word.toCharArray()) {\rif (!node.children.containsKey(c)) {\rnode = node.children.get(c);\r}\r}\rhelper(node, res);\rreturn res;\r}\rprivate void helper(TrieNode node, List\u0026lt;String\u0026gt; words) {\rif (node.isEnd) {\rwords.add(node.word);\r}\rfor (Map.Entry\u0026lt;Character, TrieNode\u0026gt; entry : node.children.entrySet()) {\rhelper(entry.getValue(), words);\r}\r}\r}\r字符串检索 给出 N 个单词组成的熟词表，以及一篇全用小写英文书写的文章，按最早出现的顺序写出所有不在熟词表中的生词。 检索/查询功能是 Trie 树最原始的功能。给定一组字符串，查找某个字符串是否出现过，思路就是从根节点开始一个一个字符进行比较：\n如果沿路比较，发现不同的字符，则表示该字符串在集合中不存在。 如果所有的字符全部比较完并且全部相同，还需判断最后一个节点的标志位（标记该节点是否代表一个关键字）。 public class Trie {\rprivate class TrieNode {\rString word;\rboolean isEnd;\rMap\u0026lt;Character, TrieNode\u0026gt; children;\rpublic TrieNode() {\rchildren = new HashMap\u0026lt;\u0026gt;();\r}\r}\rTrieNode root;\rpublic Trie() {\rroot = new TrieNode();\r}\rpublic void insert(String word) {\rTrieNode node = root;\rfor (char c : word.toCharArray()) {\rif (!node.children.containsKey(c)) {\rnode.children.put(c, new TrieNode());\r}\rnode = node.children.get(c);\r}\rnode.isEnd = true;\rnode.word = word;\r}\rpublic boolean search(String word) {\rTrieNode node = root;\rfor (char c : word.toCharArray()) {\rif (!node.children.containsKey(c)) {\rreturn false;\r}\rnode = node.children.get(c);\r}\rreturn node.isEnd;\r}\r}\r动态路由 实现动态路由最常用的数据结构，被称为前缀树(Trie 树)。看到名字你大概也能知道前缀树长啥样了：每一个节点的所有的子节点都拥有相同的前缀。这种结构非常适用于路由匹配，比如我们定义了如下路由规则：\n/:lang/doc /:lang/tutorial /:lang/intro /about /p/blog /p/related HTTP 请求的路径恰好是由/分隔的多段构成的，因此，每一段可以作为前缀树的一个节点。我们通过树结构查询，如果中间某一层的节点都不满足条件，那么就说明没有匹配到的路由，查询结束。\n接下来我们实现的动态路由具备以下两个功能。\n参数匹配:。例如 /p/:lang/doc，可以匹配 /p/c/doc 和 /p/go/doc。 通配*。例如 /static/*filepath，可以匹配/static/fav.ico，也可以匹配/static/js/jQuery.js，这种模式常用于静态服务器，能够递归地匹配子路径。 实现：动态路由\n（1）由于路由规则允许模糊匹配，匹配子节点时可能还包括了含有模糊字符串的结构，比如插入/:lang/tutorial 这个路由 pattern 后再插入/golang/intro 时，虽然 golang 与:lang 并不匹配，但还是需要将 intro 插入在:lang 节点下，而不是再创建一个 golang 节点，所以仅使用哈希表查找子节点并不合适，需要改用为 ArrayList 来存 TrieNode，使用一个单独的字符串 part 来保存节点的信息，isWild 来判断节点是否是模糊节点。\n（2）插入与查询的逻辑与字符串检索区别不大，关键修改在于：插入时还需要插入 part 和 isWild 信息，搜搜时如果碰到了*号开头的节点，需要终止查询，返回该节点。\npublic class Trie {\rprivate class TrieNode {\rString part;\rString pattern;\rboolean isWild;\rboolean isEnd;\rList\u0026lt;TrieNode\u0026gt; children;\rpublic TrieNode() {\rchildren = new ArrayList\u0026lt;\u0026gt;();\r}\rpublic TrieNode(boolean isWild, String part) {\rthis.isWild = isWild;\rthis.part = part;\rchildren = new ArrayList\u0026lt;\u0026gt;();\r}\r}\rprivate TrieNode root;\rpublic Trie() {\rroot = new TrieNode();\r}\rpublic List\u0026lt;String\u0026gt; parsePattern(String pattern) {\rString[] parts = pattern.split(\u0026quot;/\u0026quot;);\rList\u0026lt;String\u0026gt; res = new ArrayList\u0026lt;\u0026gt;();\rfor (String part : parts) {\rif (part.isEmpty()) {\rcontinue;\r}\rres.add(part);\rif (part.charAt(0) == '*') {\rbreak;\r}\r}\rreturn res;\r}\rpublic TrieNode matchChild(TrieNode node, String part) {\rfor (TrieNode child : node.children) {\rif ((child.part != null \u0026amp;\u0026amp; child.part.equals(part)) || child.isWild) {\rreturn child;\r}\r}\rreturn null;\r}\rpublic List\u0026lt;TrieNode\u0026gt; matchChildren(TrieNode node, String part) {\rList\u0026lt;TrieNode\u0026gt; children = new ArrayList\u0026lt;\u0026gt;();\rfor (TrieNode child : node.children) {\rif ((child.part != null \u0026amp;\u0026amp; child.part.equals(part)) || child.isWild) {\rchildren.add(child);\r}\r}\rreturn children;\r}\rpublic void insert(String pattern) {\rList\u0026lt;String\u0026gt; parts = parsePattern(pattern);\rinsert(root, pattern, parts, 0);\r}\rprivate void insert(TrieNode node, String pattern, List\u0026lt;String\u0026gt; parts, int depth) {\rif (parts.size() == depth) {\rnode.pattern = pattern;\rnode.isEnd = true;\rreturn;\r}\rString part = parts.get(depth);\rTrieNode child = matchChild(node, part);\rif (child == null) {\rboolean isWild = part.charAt(0) == ':' || part.charAt(0) == '*';\rchild = new TrieNode(isWild, part);\rnode.children.add(child);\r}\rinsert(child, pattern, parts, depth + 1);\r}\rpublic TrieNode search(TrieNode node, int depth, List\u0026lt;String\u0026gt; parts) {\rif ((parts.size() == depth) || (node.part != null \u0026amp;\u0026amp; node.part.startsWith(\u0026quot;*\u0026quot;))) {\rif (node.isEnd) {\rreturn node;\r}\rreturn null;\r}\rString part = parts.get(depth);\rList\u0026lt;TrieNode\u0026gt; children = matchChildren(node, part);\rfor (TrieNode child : children) {\rTrieNode result = search(child, depth + 1, parts);\rif (result != null) {\rreturn result;\r}\r}\rreturn null;\r}\rpublic String getPattern(String path) {\rList\u0026lt;String\u0026gt; searchParts = parsePattern(path);\rTrieNode node = search(root, 0, searchParts);\rif (node != null) {\rreturn node.pattern;\r}\rreturn null;\r}\r}\rTrie 树的局限性 如前文所讲，Trie 的核心思想是空间换时间，利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的。 假设字符的种数有m 个，有若干个长度为 n 的字符串构成了一个 Trie 树 ，则每个节点的出度为 m（即每个节点的可能子节点数量为m），Trie 树 的高度为n。很明显我们浪费了大量的空间来存储字符，此时 Trie 树的最坏空间复杂度为O(m^n)。也正由于每个节点的出度为m，所以我们能够沿着树的一个个分支高效的向下逐个字符的查询，而不是遍历所有的字符串来查询，此时 Trie 树的最坏时间复杂度为O(n)。 这正是空间换时间的体现，也是利用公共前缀降低查询时间开销的体现。\n","date":"2021-08-16T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/typora/image-hosting-master/image-hosting-master/store/mountains-6522018__340.3begmxsrjam0.webp","permalink":"https://cuterwrite.top/p/trie/","title":"聊聊前缀树 Trie"},{"content":"Spring Cloud OAuth2 从零开始实现用户认证和单点登录 OAuth2 是什么 OAuth2 其实是一个关于授权的网络标准，它制定了设计思路和运行流程，利用这个标准我们其实是可以自己实现 OAuth2 的认证过程的。 spring-cloud-starter-oauth2 是 Spring Cloud 按照 OAuth2 的标准并结合 spring-security 封装好的一个具体实现。\nOAuth 2 有四种授权模式，分别是授权码模式（authorization code）、简化模式（implicit）、密码模式（resource owner password credentials）、客户端模式（client credentials），具体 OAuth2 是什么，可以参考这篇文章（http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html\r）。\nOAuth2 的使用场景 典型的 OAuth2 使用场景：微信登录、QQ 登录、微博登录、Google 帐号登录、Github 帐号登录等。第一次使用就无需注册，直接通过第三方平台授权登录即可，大大提高了使用效率。此外，服务不需要存储用户的密码，只需要存储认证平台返回的唯一 ID 和用户信息即可。 不使用 OAuth2 的场景：用户需要先完成注册，然后用注册号的帐号密码或者用手机验证码登录。 OAuth2 实现统一认证功能 创建并配置认证服务端 auth-server 认证服务端负责验证帐号、密码、存储 Token、检查 Token、刷新 Token 等。\n1、引入需要的 Maven 包 \u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-oauth2\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r2、配置 bootstrap.yml 和 Nacos 配置 认证服务器采用 Nacos Config 方案，将配置放在 Nacos 注册中心上\nbootstrap.yml 配置 spring:\rapplication:\rname: auth-server\rcloud:\rnacos:\rconfig:\rprefix: auth-server-config\rserver-addr: xxxx\rfile-extension: yaml\rgroup: refactored-spring-cloud\rauth-server-config 配置 server:\rport: 18003\rspring:\rdatasource:\rurl: jdbc:mysql://xxxx:3306/spring?useUnicode=true\u0026amp;\u0026amp;characterEncoding=UTF-8\u0026amp;\u0026amp;serverTimezone=Asia/Shanghai\rusername: xxxx\rpassword: xxxx\rjpa:\rshow-sql: true\rgenerate-ddl: true\rdatabase-platform: org.hibernate.dialect.MYSQL5InnoDBDialect\rdatabase: mysql\rapplication:\rname: auth-server\rcloud:\rnacos:\rdiscovery:\rserver-addr: xxxx:8848\rgroup: refactored-spring-cloud\rinetutils:\rignored-interfaces: eth.*\rpreferred-networks: xxxx\rredis:\rhost: xxxx\rport: 6379\rmanagement:\rendpoint:\rhealth:\renabled: true\rdubbo:\rprotocol:\rname: dubbo\rport: -1\rregistry:\raddress: spring-cloud://xxxx\rconsumer:\rtimeout: 3000\r3、配置 Spring Security public class WebSecurityConfig extends WebSecurityConfigurerAdapter {\r@Bean\rpublic PasswordEncoder passwordEncoder() {\rreturn new BCryptPasswordEncoder();\r}\r@Bean\r@Override\rpublic AuthenticationManager authenticationManager() throws Exception {\rreturn super.authenticationManager();\r}\r/**\r* 开放所有接口\r*/\r@Override\rprotected void configure(HttpSecurity http) throws Exception {\rhttp.authorizeRequests()\r.antMatchers(\u0026quot;/**\u0026quot;)\r.permitAll();\r}\r}\rPasswordEncoder：采用 BCrypt 加密算法 AuthenticationManager：OAuth2 密码模式必须制定的授权管理，用默认的即可 configure：配置拦截器，使用通配符开放所有接口访问权限 4、实现 UserDetailsService @Slf4j\r@Commponent(value = \u0026quot;kiteUserDetailService\u0026quot;)\rpublic class KiteUserDetailService implements UserDetailService {\r@DubboReference\rIUserService service;\r@Override\rpublic UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {\rlog.info(\u0026quot;username is: \u0026quot; + username);\r// 查询用户\rif (user == null) {\rthrow new UsernameNotFoundException(\u0026quot;The user is not found\u0026quot;);\r} else {\r// 查询角色\rList\u0026lt;SysRole\u0026gt; roles = user.getRoles();\rList\u0026lt;SimpleGrantedAuthority\u0026gt; authorities = new ArrayList\u0026lt;\u0026gt;();\rfor (SysRole role : roles) {\rauthorities.add(new SimpleGrantedAuthority(role.getRoleName()));\r}\r// 查询密码\rString password = user.getPassword();\rreturn new User(username, password, authorities);\r}\r}\r}\rloadUserByUsername：首先利用用户微服务接口通过 username 查询用户、角色以及密码，然后返回org.springframework.security.core.userdetails.User 即可。 5、配置 OAuth2 @Configuration\r@EnableAuthorizationServer\rpublic class OAuth2Config extends AuthorizationServerConfigurerAdapter {\r@Autowired\rpublic PasswordEncoder passwordEncoder;\r@Autowired\rpublic UserDetailsService kiteUserDetailsService;\r@Autowired\rprivate TokenStore jwtTokenStore;\r@Autowired\rprivate JwtAccessTokenConverter jwtAccessTokenConverter;\r@Autowired\rprivate DataSource dataSource;\r@Override\rpublic void configure(final AuthorizationServerEndpointsConfigurer endpoints) throws Exception {\r// Redis token 方式\rendpoints.authenticaionManager(authenticationManager)\r.userDetailsService(kiteUserDetailsService)\r.accessTokenConverter(jwtAccessTokenConverter)\r.tokenStore(jwtTokenStore);\r}\r@Override\rpublic void configure(ClientDetailsServiceConfigurer clients) throws Exception {\rJdbcClientDetailsServiceBuilder builder = clients.jdbc(dataSource);\rbuilder.passwordEncoder(passwordEncoder);\r}\r@Override\rpublic void configure(AuthorizationServerSecurityConfigurer security) throws Exception {\rsecurity.allowFromAuthenticationForClients();\rsecurity.checkTokenAccess(\u0026quot;isAuthenticated\u0026quot;);\rsecurity.tokenKeyAccess(\u0026quot;isAuthenticated\u0026quot;);\r}\r}\r有三个 configure 方法的重写\nAuthorizationServerEndpointConfigurer 参数的重写\nauthenticationManager：用于支持 password 模式 userDetailsService：设置用户验证服务 tokenStore：制定 token 的存储方式 accessTokenConverter：开启 json web token 模式 ClientDetailsServiceConfigure 参数的重写：采用数据库配置的方式，预先定义好 oauth2_client_details 表，如下：\n参数说明：\nclientId、client_secret：这两个参数对应请求端定义的 cleint-id 和 client-secret authorized_grant_types：包括 authorization_code（授权码模式）、password（密码模式）、implicit（隐式授权类型）、client_credentials、refresh_token 这五种中的一种或多种。 access_token_validity：token 的有效期 scopes：用来限定客户端访问的权限，只有在 scopes 定义内的，才可以正常换取 token。 create table oauth_client_details (\rclient_id VARCHAR(256) PRIMARY KEY,\rresource_ids VARCHAR(256),\rclient_secret VARCHAR(256),\rscope VARCHAR(256),\rauthorized_grant_types VARCHAR(256),\rweb_server_redirect_uri VARCHAR(256),\rauthorities VARCHAR(256),\raccess_token_validity INTEGER,\rrefresh_token_validity INTEGER,\radditional_information VARCHAR(4096),\rautoapprove VARCHAR(256)\r);\rAuthorizationServerSecurityConfigurer 参数的重写：限制客户端访问认证接口的权限\nallowFormAuthenticationForClients()：允许客户端访问 OAuth2 授权接口，否则返回 401 checkTokenAccess ：允许已授权用户访问 checkToken 接口。 tokenKeyAccess：允许已授权用户访问获取 token 接口。 6、配置 JWTTokenStore @Configuration\rpublic class JWTTokenStore {\r@Bean\rpublic TokenStore jwtTokenStore() {\rreturn new JwtTokenStore(jwtAccessTokenConverter());\r}\r@Bean\rpublic JwtAccessTokenConverter jwtAccessTokenConverter() {\rJwtAccessTokenConverter accessTokenConverter = new JwtAccessTokenConverter();\raccessTokenConverter.setSigningKey(\u0026quot;dev\u0026quot;);\rreturn accessTokenConverter;\r}\r}\r7、启动 auth-server 现在已经可以访问 OAuth2 相关的 Restful 接口：\nPOST /oauth/authorize 授权码模式认证授权接口 GET/POST /oauth/token 获取 token 的接口 POST /oauth/check_token 检查 token 合法性接口 ","date":"2021-07-15T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/image.rglemef8w74.webp","permalink":"https://cuterwrite.top/p/oauth2-guide/","title":"Spring Cloud OAuth2 从零开始实现用户认证和单点登录"},{"content":"机器学习重要术语词汇表 精确度 Accuracy 在分类中，准确性是正确分类的项数目除以测试集内的项总数。 范围从 0（最不准确）到 1（最准确）。 准确性是模型性能的评估指标之一。 将其与 Precision、Recall 和 F-score 结合考虑。\n曲线下面积 (AUC) 二元分类的一项评估指标，即曲线下面积值，它绘制真阳性率（y 轴）与误报率（x 轴）进行对照。 范围从 0.5（最差）到 1（最佳）。 也称为 ROC 曲线下面积。\n二元分类 一个分类任务，其中标签仅为两个类中的一个。\n校准 校准是将原始分数映射到类成员身份的过程，用于二元和多类分类。\n分类 当使用这些数据来预测某一类别，有监督学习任务被称为“分类”。 二分类指的是仅预测两个类别（例如，将图像划分为“猫”或“狗”图片）。 多分类指的是预测多个类别（例如，当将图像划分为特定品种狗的图片）。\n决定系数 回归中的一项评估指标，表明数据与模型的匹配程度。 范围从 0 到 1。 值 0 表示数据是随机的，否则就无法与模型相匹配。 1 表示模型与数据完全匹配。 这通常称 r 平方值。\n特征工程 特征工程是涉及定义一组特征和开发软件以从可用现象数据中生成特征向量（即特征提取）的过程。\nF-score 分类的一项评估指标，用于平衡 Precision 和 Recall\n超参数 机器学习算法的参数。 示例包括在决策林中学习的树的数量，或者梯度下降算法中的步长。 在对模型进行定型之前，先设置超参数 的值，并控制查找预测函数参数的过程，例如，决策树中的比较点或线性回归模型中的权重。\nLabel 使用机器学习模型进行预测的元素。 例如，狗的品种或将来的股票价格。\n对数损失 在分类中，描述分类器准确性的评估指标。 对数损失越小，分类器越准确。\n损失函数 损失函数是指训练标签值与模型所做预测之间的差异。 通过最小化损失函数来估算模型参数。\n可以为不同的训练程序配置不同的损失函数。\n平均绝对误差 (MAE) 回归中的一项评估指标，即所有模型误差的平均值，其中模型误差是预测标签\r值和正确标签值之间的差距。\n多类分类 一种分类任务，其中标签为三个或三个以上类中的一个。\nN 元语法 文本数据的特征提取方案：N 个单词的任何序列都将转变为特征值\n标准化 标准化是将浮点数据缩放到 0 到 1 之间的值的过程。\n管道 要将模型与数据集相匹配所需的所有操作。 管道由数据导入、转换、特征化和学习步骤组成。 对管道进行定型后，它会转变为模型。\nPrecision 在分类中，Precision 是正确预测为属于该类的项目的数量，除以预测为属于该类的项目的总数。\nRecall 在分类中，Recall 是正确预测为属于该类的项目的数量，除以实际属于该类的项目的总数。\n正则化 正则化会对过于复杂的线性模型进行惩罚。 正则化有两种类型：\nL1 正则化将无意义特征的权重归零。 进行这种正则化之后，所保存模型的大小可能会变小。 L2 正则化将无意义特征的权重范围最小化。 这是一种更通用的过程，并且对离群值不太敏感。 回归 有监督学习任务，其中输出是一个实际值，例如，双精度值。 示例包括预测股票价格。\n相对绝对误差 回归中的一项评估指标，即所有绝对误差总和除以正确标签值和所有正确标签值的平均值之间的差值总和。\n相对平方误差 回归中的一项评估指标，即所有绝对平方误差总和除以正确标签值和所有正确标签值的平均值之间的平方差值总和。\n均方误差根 (RMSE) 误差平方平均值的平方根。\n","date":"2021-07-15T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/image.2lqvb7dnlg80.webp","permalink":"https://cuterwrite.top/p/machine-learning-terms/","title":"机器学习重要术语词汇表"},{"content":" Stream 常见用法 1 Stream 概述 Stream 将要处理的元素集合看作一种流，在流的过程中，借助Stream API 对流中的元素进行操作，比如：筛选、排序、聚合等。\nStream 可以由数组或集合创建，对流的操作分为两种：\n中间操作，每次返回一个新的流，可以有多个。 终端操作，每个流只能进行一次终端操作，终端操作结束后流无法再次使用。终端操作会产生一个新的集合或值。 另外，Stream 有几个特性：\nstream 不存储数据，而是按照特定的规则对数据进行计算，一般会输出结果。 stream 不会改变数据源，通常情况下会产生一个新的集合或一个值。 stream 具有延迟执行特性，只有调用终端操作时，中间操作才会执行。 2 Stream 创建 2.1 Collection.stream() List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;();\rStream\u0026lt;Integer\u0026gt; stream = list.stream();\r//并行流\rStream\u0026lt;Integer\u0026gt; parallelStream = list.parallelStream();\r2.2 Arrays.stream(T[] array) int[] array = new int[]{1, 2, 3, 4, 5};\rIntStream stream = Arrays.stream(array)\r2.3 Stream.of / iterate / generate Stream\u0026lt;Integer\u0026gt; stream = Stream.of(1, 2, 3, 4, 5, 6);\r//创建从 0 开始，间距为 3 的 stream（个数为 4）\rStream\u0026lt;Integer\u0026gt; stream2 = Stream.iterate(0, x -\u0026gt; x + 3).limit(4);\r3 Stream 使用 3.1 Optional Optional 类是一个可以为null 的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。\n3.2 遍历 forEach/find/match 遍历输出符合条件的元素\nlist.stream().filter(x -\u0026gt; x \u0026gt; 6).forEach(System.out::println);\r遍历对元素执行某个方法\nlist.stream().forEach(methodName);\r匹配一个\nlist.stream().filter(x -\u0026gt; x \u0026gt; 6).findFirst();\r是否包含特定条件的元素\nlist.stream().anyMatch(x -\u0026gt; x \u0026lt; 6);\r所有元素满足条件\nlist.stream().allMatch(x -\u0026gt; x == 1);\r3.3 筛选 filter 同上，直接在 stream 对象上使用就行\n3.4 聚合 max/min/count 获取 int 数组中中的最大值\nArrays.stream(array).max().getAsInt();\r获取 Integer 列表中的最大值，需要传入一个 Comparator 对象\nlist.stream().max(Integer::compareTo).get();\r获取 String 列里中长度最长的元素\nlist.stream().max(Comparator.comparing(String::length)).get();\r获取员工列表工资最高的员工\nlist.stream().max(Comparator.comparing(Person::getSalary)).get();\r计算 Integer 集合中大于 6 的元素的个数\nlist.stream().filter(x -\u0026gt; x \u0026gt; 6).count();\r3.5 映射 map/flatMap 映射，可以将一个流的元素按照一定的映射规则映射到另一个流中。分为map 和flatMap：\nmap：接收一个函数作为参数，该函数会被应用到每个元素上，并将其映射成一个新的元素。 flatMap：接收一个函数作为参数，将流中的每个值都换成另一个流，然后把所有流连接成一个流。 将字符串数组的元素全部改成大写\nArrays.stream(array).map(String::toUpperCase).collect(Collectors.toList());\r将员工薪资全部增加 1000\nlist.stream().map(person -\u0026gt; {\rperson.setSalary(person.getSalary() + 1000);\rreturn person;\r}).collect(Collectors.toList());\r3.6 规约 reduce 将一个流缩减为一个值，能实现集合求和，求乘积和求最值操作等。\n求 Integer 列表的元素之和，乘积和最大值\nlist.stream().reduce(Integer::sum).get();\rlist.stream().reduce((x,y) -\u0026gt; x + y).get();\rlist.stream().reduce((x,y) -\u0026gt; x * y).get();\r3.7 收集 collect 就是把一个流收集起来，最终可以是收集成一个值也可以收集成一个新的集合。\ncollect 主要依赖java.util.stream.Collectors 类内置的静态方法。\n归集：toList()，toSet()，toMap() 统计：counting、averagingInt、averagingLong、averagingDouble、maxBy、minBy、summingInt、summingLong、summingDouble、sumarizingInt、sumarizingLong、sumarizingDouble 3.8 分组 groupingBy/partitioningBy 将员工按薪资是否高于 8000 分组\nlist.stream().collect(Collectors.groupingBy(x -\u0026gt; x.getSalary() \u0026gt; 8000))\r将员工按性别分组\nlist.stream().collect(Collectors.groupingBy(Person::getSex));\r3.9 连接 joining 将 stream 中的元素用特定的连接符（没有的话，则直接连接）连接成一个字符串。\nlist.stream().collect(Collectors.joining(\u0026quot;,\u0026quot;));\r3.10 排序 sorted 按工资升序排序\nlist.stream().sorted(Compartor.comparing(Person::getSalary));\r按工资倒序排序\nlist.stream().sorted(Compartor.comparing(Person::getSalary)).reversed();\r多列排序\nlist.stream().sorted(Compartor.comparing(Person::getSalary).thenComparing(Person::getAge));\r","date":"2021-05-11T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/bridge-5621201_1920.6p53ez4buso0.webp","permalink":"https://cuterwrite.top/p/java-stream/","title":"Java-Stream 常见用法"},{"content":"Java 并发知识点笔记 1 使用线程的方法 实现 Runnable 接口； 实现 Callable 接口； 继承 Thread 类。 2 基础线程机制 2.1 Executor Executor 管理多个异步任务的执行，而无需程序员显式地管理线程的生命周期。这里的异步是指多个任务的执行互不干扰，不需要进行同步操作。\n主要有三种 Executor：\nCachedThreadPool：一个任务创建一个线程； FixedThreadPool：所有任务只能使用固定大小的线程； SingleThreadExecutor：相当于大小为 1 的 FixedThreadPool。 2.2 Daemon 守护线程是程序运行时在后台提供服务的线程，不属于程序中不可或缺的部分。\n当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。\nmain() 属于非守护线程。\n在线程启动之前使用 setDaemon() 方法可以将一个线程设置为守护线程。\n2.3 sleep() Thread.sleep(millisec) 方法会休眠当前正在执行的线程，millisec 单位为毫秒。\nsleep() 可能会抛出 InterruptedException，因为异常不能跨线程传播回 main() 中，因此必须在本地进行处理。线程中抛出的其它异常也同样需要在本地进行处理。\n2.4 yield() 对静态方法 Thread.yield() 的调用声明了当前线程已经完成了生命周期中最重要的部分，可以切换给其它线程来执行。该方法只是对线程调度器的一个建议，而且也只是建议具有相同优先级的其它线程可以运行。\n3 线程中断 一个线程执行完毕之后会自动结束，如果在运行过程中发生异常也会提前结束。\n3.1 InterruptedException 通过调用一个线程的 interrupt() 来中断该线程，如果该线程处于阻塞、限期等待或者无限期等待状态，那么就会抛出 InterruptedException，从而提前结束该线程。但是不能中断 I/O 阻塞和 synchronized 锁阻塞。\n3.2 interrupted() 如果一个线程的 run() 方法执行一个无限循环，并且没有执行 sleep() 等会抛出 InterruptedException 的操作，那么调用线程的 interrupt() 方法就无法使线程提前结束。\n但是调用 interrupt() 方法会设置线程的中断标记，此时调用 interrupted() 方法会返回 true。因此可以在循环体中使用 interrupted() 方法来判断线程是否处于中断状态，从而提前结束线程。\n3.3 Executor 的中断操作 调用 Executor 的 shutdown() 方法会等待线程都执行完毕之后再关闭，但是如果调用的是 shutdownNow() 方法，则相当于调用每个线程的 interrupt() 方法。\n4 互斥锁 Java 提供了两种锁机制来控制多个线程对共享资源的互斥访问，第一个是 JVM 实现的 synchronized，而另一个是 JDK 实现的 ReentrantLock。\n4.1 synchronized 同步代码块：锁对象 同步一个方法：锁对象 同步一个类：锁整个类 同步一个静态方法：锁整个类 4.2 ReentrantLock ReentrantLock 是 java.util.concurrent（J.U.C）包中的锁。\n通过 lock 和 unlock 操作\n4.3 比较 1. 锁的实现\nsynchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的。\n2. 性能\n新版本 Java 对 synchronized 进行了很多优化，例如自旋锁等，synchronized 与 ReentrantLock 大致相同。\n3. 等待可中断\n当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。\nReentrantLock 可中断，而 synchronized 不行。\n4. 公平锁\n公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。\nsynchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但是也可以是公平的。\n5. 锁绑定多个条件\n一个 ReentrantLock 可以同时绑定多个 Condition 对象。\n4.4 选择 除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。这是因为 synchronized 是 JVM 实现的一种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。\n5 线程协作 5.1 join 在线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是忙等待，直到目标线程结束。\n5.2 wait/notify 调用 wait() 使得线程等待某个条件满足，线程在等待时会被挂起，当其他线程的运行使得这个条件满足时，其它线程会调用 notify() 或者 notifyAll() 来唤醒挂起的线程。\n它们都属于 Object 的一部分，而不属于 Thread。\n只能用在同步方法或者同步控制块中使用，否则会在运行时抛出 IllegalMonitorStateException。\n使用 wait() 挂起期间，线程会释放锁。这是因为，如果没有释放锁，那么其它线程就无法进入对象的同步方法或者同步控制块中，那么就无法执行 notify() 或者 notifyAll() 来唤醒挂起的线程，造成死锁\nwait() 和 sleep() 的区别\nwait() 是 Object 的方法，而 sleep() 是 Thread 的静态方法； wait() 会释放锁，sleep() 不会。 5.3 await/signal java.util.concurrent 类库中提供了 Condition 类来实现线程之间的协调，可以在 Condition 上调用 await() 方法使线程等待，其它线程调用 signal() 或 signalAll() 方法唤醒等待的线程。\n相比于 wait() 这种等待方式，await() 可以指定等待的条件，因此更加灵活。\n使用 Lock 来获取一个 Condition 对象。\n6 线程状态 new runable blocked waiting timed_waiting terminated 7 JUC 包/AQS 7.1 CountDownLatch 用来控制一个或者多个线程等待多个线程。\n维护了一个计数器 cnt，每次调用 countDown() 方法会让计数器的值减 1，减到 0 的时候，那些因为调用 await() 方法而在等待的线程就会被唤醒。\n7.2 CyclicBarrier 用来控制多个线程互相等待，只有当多个线程都到达时，这些线程才会继续执行。\n和 CountdownLatch 相似，都是通过维护计数器来实现的。线程执行 await() 方法之后计数器会减 1，并进行等待，直到计数器为 0，所有调用 await() 方法而在等待的线程才能继续执行。\nCyclicBarrier 和 CountdownLatch 的一个区别是，CyclicBarrier 的计数器通过调用 reset() 方法可以循环使用，所以它才叫做循环屏障。\nCyclicBarrier 有两个构造函数，其中 parties 指示计数器的初始值，barrierAction 在所有线程都到达屏障的时候会执行一次。\n7.3 Semaphore Semaphore 类似于操作系统中的信号量，可以控制对互斥资源的访问线程数。\n8 JUC 包其它组件 8.1 FutureTask 在介绍 Callable 时我们知道它可以有返回值，返回值通过 Future\u0026lt;V\u0026gt; 进行封装。FutureTask 实现了 RunnableFuture 接口，该接口继承自 Runnable 和 Future\u0026lt;V\u0026gt; 接口，这使得 FutureTask 既可以当做一个任务执行，也可以有返回值。\nFutureTask 可用于异步获取执行结果或取消执行任务的场景。当一个计算任务需要执行很长时间，那么就可以用 FutureTask 来封装这个任务，主线程在完成自己的任务之后再去获取结果。\n8.2 BlockingQueue java.util.concurrent.BlockingQueue 接口有以下阻塞队列的实现：\nFIFO 队列 ：LinkedBlockingQueue、ArrayBlockingQueue（固定长度） 优先级队列 ：PriorityBlockingQueue 提供了阻塞的 take() 和 put() 方法：如果队列为空 take() 将阻塞，直到队列中有内容；如果队列为满 put() 将阻塞，直到队列有空闲位置。\n8.3 ForkJoin 主要用于并行计算中，和 MapReduce 原理类似，都是把大的计算任务拆分成多个小任务并行计算。\nForkJoinPool 实现了工作窃取算法来提高 CPU 的利用率。每个线程都维护了一个双端队列，用来存储需要执行的任务。工作窃取算法允许空闲的线程从其它线程的双端队列中窃取一个任务来执行。窃取的任务必须是最晚的任务，避免和队列所属线程发生竞争。例如下图中，Thread2 从 Thread1 的队列中拿出最晚的 Task1 任务，Thread1 会拿出 Task2 来执行，这样就避免发生竞争。但是如果队列中只有一个任务时还是会发生竞争。\n9 内存模型 Java 内存模型试图屏蔽各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台下都能达到一致的内存访问效果。\n9.1 主内存与工作内存 处理器上的寄存器的读写的速度比内存快几个数量级，为了解决这种速度矛盾，在它们之间加入了高速缓存。\n加入高速缓存带来了一个新的问题：缓存一致性。如果多个缓存共享同一块主内存区域，那么多个缓存的数据可能会不一致，需要一些协议来解决这个问题。\n所有的变量都存储在主内存中，每个线程还有自己的工作内存，工作内存存储在高速缓存或者寄存器中，保存了该线程使用的变量的主内存副本拷贝。\n线程只能直接操作工作内存中的变量，不同线程之间的变量值传递需要通过主内存来完成。\n9.2 内存间交互操作 Java 内存模型定义了 8 个操作来完成主内存和工作内存的交互操作。\nread：把一个变量的值从主内存传输到工作内存中 load：在 read 之后执行，把 read 得到的值放入工作内存的变量副本中 use：把工作内存中一个变量的值传递给执行引擎 assign：把一个从执行引擎接收到的值赋给工作内存的变量 store：把工作内存的一个变量的值传送到主内存中 write：在 store 之后执行，把 store 得到的值放入主内存的变量中 lock：作用于主内存的变量 unlock 9.3 内存模型三大特性 9.3.1. 原子性 Java 内存模型保证了 read、load、use、assign、store、write、lock 和 unlock 操作具有原子性，例如对一个 int 类型的变量执行 assign 赋值操作，这个操作就是原子性的。但是 Java 内存模型允许虚拟机将没有被 volatile 修饰的 64 位数据（long，double）的读写操作划分为两次 32 位的操作来进行，即 load、store、read 和 write 操作可以不具备原子性。\n有一个错误认识就是，int 等原子性的类型在多线程环境中不会出现线程安全问题。前面的线程不安全示例代码中，cnt 属于 int 类型变量，1000 个线程对它进行自增操作之后，得到的值为 997 而不是 1000。\n为了方便讨论，将内存间的交互操作简化为 3 个：load、assign、store。\n下图演示了两个线程同时对 cnt 进行操作，load、assign、store 这一系列操作整体上看不具备原子性，那么在 T1 修改 cnt 并且还没有将修改后的值写入主内存，T2 依然可以读入旧值。可以看出，这两个线程虽然执行了两次自增运算，但是主内存中 cnt 的值最后为 1 而不是 2。因此对 int 类型读写操作满足原子性只是说明 load、assign、store 这些单个操作具备原子性。\nAtomicInteger 能保证多个线程修改的原子性。\n除了使用原子类之外，也可以使用 synchronized 互斥锁来保证操作的原子性。它对应的内存间交互操作为：lock 和 unlock，在虚拟机实现上对应的字节码指令为 monitorenter 和 monitorexit。\n9.3.2. 可见性 可见性指当一个线程修改了共享变量的值，其它线程能够立即得知这个修改。Java 内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可见性的。\n主要有三种实现可见性的方式：\nvolatile synchronized，对一个变量执行 unlock 操作之前，必须把变量值同步回主内存。 final，被 final 关键字修饰的字段在构造器中一旦初始化完成，并且没有发生 this 逃逸（其它线程通过 this 引用访问到初始化了一半的对象），那么其它线程就能看见 final 字段的值。 对前面的线程不安全示例中的 cnt 变量使用 volatile 修饰，不能解决线程不安全问题，因为 volatile 并不能保证操作的原子性。\n9.3.3. 有序性 有序性是指：在本线程内观察，所有操作都是有序的。在一个线程观察另一个线程，所有操作都是无序的，无序是因为发生了指令重排序。在 Java 内存模型中，允许编译器和处理器对指令进行重排序，重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。\nvolatile 关键字通过添加内存屏障的方式来禁止指令重排，即重排序时不能把后面的指令放到内存屏障之前。\n也可以通过 synchronized 来保证有序性，它保证每个时刻只有一个线程执行同步代码，相当于是让线程顺序执行同步代码。\n9.4 先行发生原则 上面提到了可以用 volatile 和 synchronized 来保证有序性。除此之外，JVM 还规定了先行发生原则，让一个操作无需控制就能先于另一个操作完成。\n单一线程原则：在一个线程内，在程序前面的操作先行发生于后面的操作。 管程锁定规则：一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。 volatile 变量规则：对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作。 线程启动规则：Thread 对象的 start() 方法调用先行发生于此线程的每一个动作。 线程加入规则：Thread 对象的结束先行发生于 join() 方法返回。 线程中断规则：对线程 interrupt() 方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过 interrupted() 方法检测到是否有中断发生。 对象终结规则：一个对象的初始化完成（构造函数执行结束）先行发生于它的 finalize() 方法的开始。 传递性：如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么操作 A 先行发生于操作 C。 10 线程安全策略 10.1 不可变 不可变的类型：\nfinal 关键字修饰的基本数据类型 String 枚举类型 Number 部分子类，如 Long 和 Double 等数值包装类型，BigInteger 和 BigDecimal 等大数据类型。但同为 Number 的原子类 AtomicInteger 和 AtomicLong 则是可变的。 对于集合类型，可以使用 Collections.unmodifiableXXX() 方法来获取一个不可变的集合。\n10.2 互斥同步 synchronized 和 ReentrantLock。\n10.3 非阻塞同步 CAS AtomicInteger ABA 问题：如果一个变量初次读取的时候是 A 值，它的值被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。\n解决方法：J.U.C 包提供了一个带有标记的原子引用类 AtomicStampedReference 来解决这个问题，它可以通过控制变量值的版本来保证 CAS 的正确性。大部分情况下 ABA 问题不会影响程序并发的正确性，如果需要解决 ABA 问题，改用传统的互斥同步可能会比原子类更高效。\n10.4 无同步 10.4.1 栈封闭 多个线程访问同一个方法的局部变量时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有的。\n10.4.2 线程本地存储 如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。\n它提供了线程本地变量，也就是如果你创建了一个 ThreadLocal 变量，那么访问这个变量的每个线程都会有这个变量的一个本地拷贝，多个线程操作这个变量的时候，实际是操作的自己本地内存里面的变量，从而避免了线程安全问题\n每个 Thread 都有一个 ThreadLocal.ThreadLocalMap 对象。\n当调用一个 ThreadLocal 的 set(T value) 方法时，先得到当前线程的 ThreadLocalMap 对象，然后将 ThreadLocal-\u0026gt;value 键值对插入到该 Map 中。\n10.4.3 可重入代码 这种代码也叫做纯代码（Pure Code），可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回后，原来的程序不会出现任何错误。\n可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。\n11 锁优化 11.1 自旋锁 自旋锁的思想是让一个线程在请求一个共享数据的锁时执行忙循环（自旋）一段时间，如果在这段时间内能获得锁，就可以避免进入阻塞状态。\n自旋锁虽然能避免进入阻塞状态从而减少开销，但是它需要进行忙循环操作占用 CPU 时间，它只适用于共享数据的锁定状态很短的场景。\n在 JDK 1.6 中引入了自适应的自旋锁。自适应意味着自旋的次数不再固定了，而是由前一次在同一个锁上的自旋次数及锁的拥有者的状态来决定。\n11.2 锁消除 锁消除是指对于被检测出不可能存在竞争的共享数据的锁进行消除。\n锁消除主要是通过逃逸分析来支持，如果堆上的共享数据不可能逃逸出去被其它线程访问到，那么就可以把它们当成私有数据对待，也就可以将它们的锁进行消除。\n11.3 锁粗化 如果一系列的连续操作都对同一个对象反复加锁和解锁，频繁的加锁操作就会导致性能损耗。\n如果虚拟机探测到由这样的一串零碎的操作都对同一个对象加锁，将会把加锁的范围扩展（粗化）到整个操作序列的外部。\n11.4 轻量级锁 JDK 1.6 引入了偏向锁和轻量级锁，从而让锁拥有了四个状态：无锁状态（unlocked）、偏向锁状态（biasble）、轻量级锁状态（lightweight locked）和重量级锁状态（inflated）。\n轻量级锁是相对于传统的重量级锁而言，它使用 CAS 操作来避免重量级锁使用互斥量的开销。对于绝大部分的锁，在整个同步周期内都是不存在竞争的，因此也就不需要都使用互斥量进行同步，可以先采用 CAS 操作进行同步，如果 CAS 失败了再改用互斥量进行同步。\n11.5 偏向锁 偏向锁的思想是偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要。\n本文转载自：https://github.com/CyC2018/CS-Notes\r，用于个人复习。\n","date":"2021-05-04T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/santorini-1578440_1920.3ldusy6rm1k0.webp","permalink":"https://cuterwrite.top/p/java-concurrent/","title":"Java 并发知识点笔记"},{"content":"Java 容器知识点笔记 1 概述 容器主要包括 Collection 和 Map 两种，Collection 存储着对象的集合，而 Map 存储着键值对（两个对象）的映射表。\n1.1 Collection 1.1.1 Set TreeSet：基于红黑树实现，支持有序性操作，例如根据一个范围查找元素的操作。但是查找效率不如 HashSet，HashSet 查找的时间复杂度为 O(1)，TreeSet 则为 O(logN)。\nHashSet：基于哈希表实现，支持快速查找，但不支持有序性操作。并且失去了元素的插入顺序信息，也就是说使用 Iterator 遍历 HashSet 得到的结果是不确定的。\nLinkedHashSet：具有 HashSet 的查找效率，并且内部使用双向链表维护元素的插入顺序。\n1.1.2 List ArrayList：基于动态数组实现，支持随机访问。\nVector：和 ArrayList 类似，但它是线程安全的。\nLinkedList：基于双向链表实现，只能顺序访问，但是可以快速地在链表中间插入和删除元素。不仅如此，LinkedList 还可以用作栈、队列和双向队列。\n1.1.3 Queue LinkedList：可以用它来实现双向队列。 PriorityQueue：基于堆结构实现，可以用它来实现优先队列。 2 源码分析 2.1 ArrayList 2.1.1 概述 因为 ArrayList 是基于数组实现的，所以支持快速随机访问。RandomAccess 接口标识着该类支持快速随机访问，默认容量为 10\ntransient Object[] elementData;\rprivate static final int DEFAULT_CAPACITY = 10;\r2.1.2 扩容 添加元素时使用 ensureCapacityInternal() 方法来保证容量足够，如果不够时，需要使用 grow() 方法进行扩容，新容量的大小为 oldCapacity + (oldCapacity \u0026gt;\u0026gt; 1)，即 oldCapacity+oldCapacity/2。其中 oldCapacity \u0026raquo; 1 需要取整，所以新容量大约是旧容量的 1.5 倍左右。（oldCapacity 为偶数就是 1.5 倍，为奇数就是 1.5 倍-0.5）\n扩容操作需要调用 Arrays.copyOf() 把原数组整个复制到新数组中，这个操作代价很高，因此最好在创建 ArrayList 对象时就指定大概的容量大小，减少扩容操作的次数。\n2.1.3 删除元素 需要调用 System.arraycopy() 将 index+1 后面的元素都复制到 index 位置上，该操作的时间复杂度为 O(N)，可以看到 ArrayList 删除元素的代价是非常高的。\n2.1.4 序列化 ArrayList 基于数组实现，并且具有动态扩容特性，因此保存元素的数组不一定都会被使用，那么就没必要全部进行序列化。\n保存元素的数组 elementData 使用 transient 修饰，该关键字声明数组默认不会被序列化。\nArrayList 实现了 writeObject() 和 readObject() 来控制只序列化数组中有元素填充那部分内容。\n序列化时需要使用 ObjectOutputStream 的 writeObject() 将对象转换为字节流并输出。而 writeObject() 方法在传入的对象存在 writeObject() 的时候会去反射调用该对象的 writeObject() 来实现序列化。反序列化使用的是 ObjectInputStream 的 readObject() 方法，原理类似。\n2.1.5 Fail-fast modCount 用来记录 ArrayList 结构发生变化的次数。结构发生变化是指添加或者删除至少一个元素的所有操作，或者是调整内部数组的大小，仅仅只是设置元素的值不算结构发生变化。\n在进行序列化或者迭代等操作时，需要比较操作前后 modCount 是否改变，如果改变了需要抛出 ConcurrentModificationException。代码参考上节序列化中的 writeObject() 方法。\n2.2 Vector 2.2.1 同步 它的实现与 ArrayList 类似，但是使用了 synchronized 进行同步。\n2.2.2 扩容 Vector 的构造函数可以传入 capacityIncrement 参数，它的作用是在扩容时使容量 capacity 增长 capacityIncrement。如果这个参数的值小于等于 0，扩容时每次都令 capacity 为原来的两倍。\n调用没有 capacityIncrement 的构造函数时，capacityIncrement 值被设置为 0，也就是说默认情况下 Vector 每次扩容时容量都会翻倍。\n2.2.3 与 ArrayList 的比较 Vector 是同步的，因此开销就比 ArrayList 要大，访问速度更慢。最好使用 ArrayList 而不是 Vector，因为同步操作完全可以由程序员自己来控制； Vector 每次扩容请求其大小的 2 倍（也可以通过构造函数设置增长的容量），而 ArrayList 是 1.5 倍。 2.2.4 替代方案 可以使用 Collections.synchronizedList(); 得到一个线程安全的 ArrayList。\n也可以使用 concurrent 并发包下的 CopyOnWriteArrayList 类。\n2.3 CopyOnWriteArrayList 2.3.1 读写分离 写操作在一个复制的数组上进行，读操作还是在原始数组中进行，读写分离，互不影响。\n写操作需要加锁，防止并发写入时导致写入数据丢失。\n写操作结束之后需要把原始数组指向新的复制数组。\n2.3.2 适用场景 CopyOnWriteArrayList 在写操作的同时允许读操作，大大提高了读操作的性能，因此很适合读多写少的应用场景。\n但是 CopyOnWriteArrayList 有其缺陷：\n内存占用：在写操作时需要复制一个新的数组，使得内存占用为原来的两倍左右； 数据不一致：读操作不能读取实时性的数据，因为部分写操作的数据还未同步到读数组中。 所以 CopyOnWriteArrayList 不适合内存敏感以及对实时性要求很高的场景。\n2.4 LinkedList 2.4.1 概述 基于双向链表实现，使用 Node 存储链表节点信息。\nprivate static class Node\u0026lt;E\u0026gt; {\rE item;\rNode\u0026lt;E\u0026gt; next;\rNode\u0026lt;E\u0026gt; prev;\r}\r每个链表存储了 first 和 last 指针：\ntransient Node\u0026lt;E\u0026gt; first;\rtransient Node\u0026lt;E\u0026gt; last;\r2.4.2 与 ArrayList 的比较 ArrayList 基于动态数组实现，LinkedList 基于双向链表实现。ArrayList 和 LinkedList 的区别可以归结为数组和链表的区别：\n数组支持随机访问，但插入删除的代价很高，需要移动大量元素； 链表不支持随机访问，但插入删除只需要改变指针。 2.5 HashMap 2.5.1 概述 基于数组+链表+红黑树实现 transient Node\u0026lt;K,V\u0026gt;[] table;\r默认容量 16，每次扩容为 2 倍 默认负载因子为 0.75 当链表长度大于等于 8 时，检查 table 长度是否大于 64，如果是则转成红黑树。 基本原理：通过 key 的 hashcode 经过扰动处理得到 hash 值，然后通过(n - 1) \u0026amp; hash 判断当前元素存放的位置，如果当前位置存在元素的话，就判断该元素与要存放的元素的 hash 值以及 key 是否相同，如果相同则直接覆盖，不相同就用拉链法解决冲突。 2.5.2 拉链法 将链表和数组相结合。也就是说创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可。\n2.5.3 确认桶下标方法 计算 key 的 hash（h = key.hashcode(); h ^ (h \u0026raquo;\u0026gt; 16)） hash \u0026amp; (n - 1) 2.5.4 扩容基本原理 设 HashMap 的 table 长度为 M，需要存储的键值对数量为 N，如果哈希函数满足均匀性的要求，那么每条链表的长度大约为 N/M，因此查找的复杂度为 O(N/M)。\n为了让查找的成本降低，应该使 N/M 尽可能小，因此需要保证 M 尽可能大，也就是说 table 要尽可能大。HashMap 采用动态扩容来根据当前的 N 值来调整 M 值，使得空间效率和时间效率都能得到保证。\n扩容使用 resize() 实现，需要注意的是，扩容操作同样需要把 oldTable 的所有键值对重新插入 newTable 中，因此这一步是很费时的。\n2.5.5 扩容重新计算桶下标 在进行扩容时，需要把键值对重新计算桶下标，从而放到对应的桶上。在前面提到，HashMap 使用 hash%capacity 来确定桶下标。HashMap capacity 为 2 的 n 次方这一特点能够极大降低重新计算桶下标操作的复杂度。\n2.5.6 与 HashTable 对比 Hashtable 使用 synchronized 来进行同步。 HashMap 可以插入键为 null 的 Entry。 HashMap 的迭代器是 fail-fast 迭代器。 HashMap 不能保证随着时间的推移 Map 中的元素次序是不变的。 2.6 ConcurrentHashMap 2.6.1 存储结构 ConcurrentHashMap 和 HashMap 实现上类似，最主要的差别是 ConcurrentHashMap 采用了分段锁（Segment），每个分段锁维护着几个桶（HashEntry），多个线程可以同时访问不同分段锁上的桶，从而使其并发度更高（并发度就是 Segment 的个数）。\nSegment 继承自 ReentrantLock。\n默认的并发级别为 16，也就是说默认创建 16 个 Segment。\n2.6.2 size 操作 每个 Segment 维护了一个 count 变量来统计该 Segment 中的键值对个数。\n在执行 size 操作时，需要遍历所有 Segment 然后把 count 累计起来。\nConcurrentHashMap 在执行 size 操作时先尝试不加锁，如果连续两次不加锁操作得到的结果一致，那么可以认为这个结果是正确的。\n尝试次数使用 RETRIES_BEFORE_LOCK 定义，该值为 2，retries 初始值为 -1，因此尝试次数为 3。\n如果尝试的次数超过 3 次，就需要对每个 Segment 加锁。\n2.6.3 jdk8 的改动 JDK 1.7 使用分段锁机制来实现并发更新操作，核心类为 Segment，它继承自重入锁 ReentrantLock，并发度与 Segment 数量相等。\nJDK 1.8 使用了 CAS 操作来支持更高的并发度，在 CAS 操作失败时使用内置锁 synchronized。\n并且 JDK 1.8 的实现也在链表过长时会转换为红黑树。\n2.7 LinkedHashMap 2.7.1 存储结构 继承自 HashMap，因此具有和 HashMap 一样的快速查找特性。\n内部维护了一个双向链表，用来维护插入顺序或者 LRU 顺序。\ntransient LinkedHashMap.Entry\u0026lt;K,V\u0026gt; head;\rtransient LinkedHashMap.Entry\u0026lt;K,V\u0026gt; tail;\raccessOrder 决定了顺序，默认为 false，此时维护的是插入顺序。\nfinal boolean accessOrder;\rLinkedHashMap 最重要的是以下用于维护顺序的函数，它们会在 put、get 等方法中调用。\nvoid afterNodeAccess(Node\u0026lt;K,V\u0026gt; p) { }\rvoid afterNodeInsertion(boolean evict) { }\r2.7.2 afterNodeAccess() 当一个节点被访问时，如果 accessOrder 为 true，则会将该节点移到链表尾部。也就是说指定为 LRU 顺序之后，在每次访问一个节点时，会将这个节点移到链表尾部，保证链表尾部是最近访问的节点，那么链表首部就是最近最久未使用的节点。\n2.7.3 afterNodeInsertion() 在 put 等操作之后执行，当 removeEldestEntry() 方法返回 true 时会移除最晚的节点，也就是链表首部节点 first。\nevict 只有在构建 Map 的时候才为 false，在这里为 true。\n本文转载自：https://github.com/CyC2018/CS-Notes\r，用于个人复习。\n","date":"2021-05-04T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/antarctica-1987579_1920.4sf6q29twew0.webp","permalink":"https://cuterwrite.top/p/java-collection/","title":"Java 容器知识点笔记"},{"content":"JavaSE 知识点笔记 1 数据类型 1.1 基本类型 byte/8 char/16 short/16 int/32 float/32 long/64 double/64 boolean/~ 1.2 包装类型 基本类型都有对应的包装类型，基本类型与其对应的包装类型之间的赋值使用自动装箱与拆箱完成。\nInteger x = 2; // 装箱 调用了 Integer.valueOf(2)\rint y = x; // 拆箱 调用了 X.intValue()\r1.3 缓存池 new Integer(123) 与 Integer.valueOf(123) 的区别在于：\nnew Integer(123) 每次都会新建一个对象； Integer.valueOf(123) 会使用缓存池中的对象，多次调用会取得同一个对象的引用。 valueOf() 方法的实现比较简单，就是先判断值是否在缓存池中，如果在的话就直接返回缓存池的内容。\n在 Java 8 中，Integer 缓存池的大小默认为 -128~127。\n编译器会在自动装箱过程调用 valueOf() 方法，因此多个值相同且值在缓存池范围内的 Integer 实例使用自动装箱来创建，那么就会引用相同的对象。\n基本类型对应的缓冲池如下：\nboolean values true and false all byte values short values between -128 and 127 int values between -128 and 127 char in the range \\u0000 to \\u007F 2 String 2.1 概述 String 被声明为 final，因此它不可被继承。(Integer 等包装类也不能被继承）\n在 Java 8 中，String 内部使用 char 数组存储数据。\nprivate final char[] value;\r在 Java 9 之后，String 类的实现改用 byte 数组存储字符串，同时使用 coder 来标识使用了哪种编码。\nprivate final byte[] value;\rprivate final byte coder;\rvalue 数组被声明为 final，这意味着 value 数组初始化之后就不能再引用其它数组。并且 String 内部没有改变 value 数组的方法，因此可以保证 String 不可变。\n2.2 不可变的优点 2.2.1 可以缓存 hash 值 因为 String 的 hash 值经常被使用，例如 String 用做 HashMap 的 key。不可变的特性可以使得 hash 值也不可变，因此只需要进行一次计算。\n2.2.2 String Pool 如果一个 String 对象已经被创建过了，那么就会从 String Pool 中取得引用。只有 String 是不可变的，才可能使用 String Pool。\n2.2.3 安全性 String 经常作为参数，String 不可变性可以保证参数不可变。例如在作为网络连接参数的情况下如果 String 是可变的，那么在网络连接过程中，String 被改变，改变 String 的那一方以为现在连接的是其它主机，而实际情况却不一定是。\n2.2.4 线程安全 String 不可变性天生具备线程安全，可以在多个线程中安全地使用。\n2.3 String、StringBuilder 和 StringBuffer 2.3.1 可变性 String 不可变 StringBuilder 和 StringBuffer 可变 2.3.2 线程安全 String 线程安全 StringBuilder 线程不安全 StringBuffer 线程安全：synchronized 机制 2.4 String Pool 字符串常量池（String Pool）保存着所有字符串字面量（literal strings），这些字面量在编译时期就确定。不仅如此，还可以使用 String 的 intern() 方法在运行过程将字符串添加到 String Pool 中。\n当一个字符串调用 intern() 方法时，如果 String Pool 中已经存在一个字符串和该字符串值相等（使用 equals() 方法进行确定），那么就会返回 String Pool 中字符串的引用；否则，就会在 String Pool 中添加一个新的字符串，并返回这个新字符串的引用。\n在 Java 7 之前，String Pool 被放在运行时常量池中，它属于永久代。而在 Java 7，String Pool 被移到堆中。这是因为永久代的空间有限，在大量使用字符串的场景下会导致 OutOfMemoryError 错误。\n2.5 new String（“abc”） 使用这种方式一共会创建两个字符串对象（前提是 String Pool 中还没有 \u0026ldquo;abc\u0026rdquo; 字符串对象）。\n\u0026ldquo;abc\u0026rdquo; 属于字符串字面量，因此编译时期会在 String Pool 中创建一个字符串对象，指向这个 \u0026ldquo;abc\u0026rdquo; 字符串字面量； 而使用 new 的方式会在堆中创建一个字符串对象。 3 运算 3.1 参数传递 Java 的参数是以值传递的形式传入方法中，而不是引用传递。\n3.2 float 与 double Java 不能隐式执行向下转型，因为这会使得精度降低。\n3.3 隐式类型转换 使用+=和++运算符会执行隐式类型转换，相当于强制类型转换。\n（比如：int 转 short）\n4 关键字 4.1 final （1）数据\n声明数据为常量，可以是编译时常量，也可以是在运行时被初始化后不能被改变的常量。\n对于基本类型，final 使数值不变； 对于引用类型，final 使引用不变，也就不能引用其它对象，但是被引用的对象本身是可以修改的。 （2）方法\n声明方法不能被子类重写。\nprivate 方法隐式地被指定为 final，如果在子类中定义的方法和基类中的一个 private 方法签名相同，此时子类的方法不是重写基类方法，而是在子类中定义了一个新的方法。\n（3）类\n声明类不允许被继承。\n4.2 static 1. 静态变量\n静态变量：又称为类变量，也就是说这个变量属于类的，类所有的实例都共享静态变量，可以直接通过类名来访问它。静态变量在内存中只存在一份。 实例变量：每创建一个实例就会产生一个实例变量，它与该实例同生共死。 2. 静态方法\n静态方法在类加载的时候就存在了，它不依赖于任何实例。所以静态方法必须有实现，也就是说它不能是抽象方法。\n3. 静态语句块\n静态语句块在类初始化时运行一次。\n4. 静态内部类\n非静态内部类依赖于外部类的实例，也就是说需要先创建外部类实例，才能用这个实例去创建非静态内部类。而静态内部类不需要。\n5. 静态导包\n在使用静态变量和方法时不用再指明 ClassName，从而简化代码，但可读性大大降低。\n6. 初始化顺序\n静态变量和静态语句块优先于实例变量和普通语句块，静态变量和静态语句块的初始化顺序取决于它们在代码中的顺序。\n5 Object 通用方法 hashcode equals clone toString getClass finalize notify notifyAll wait 6 继承 6.1 访问权限 private、protected、public，以及 default（如果不加访问修饰符，表示包级可见。）\n可以对类或类中的成员（字段和方法）加上访问修饰符。\n类可见表示其它类可以用这个类创建实例对象。 成员可见表示其它类可以用这个类的实例对象访问到该成员； protected 用于修饰成员，表示在继承体系中成员对于子类可见，但是这个访问修饰符对于类没有意义。\n6.2 抽象类与接口 1. 抽象类\n抽象类和抽象方法都使用 abstract 关键字进行声明。如果一个类中包含抽象方法，那么这个类必须声明为抽象类。\n抽象类和普通类最大的区别是，抽象类不能被实例化，只能被继承。\n2. 接口\n接口是抽象类的延伸，在 Java 8 之前，它可以看成是一个完全抽象的类，也就是说它不能有任何的方法实现。\n从 Java 8 开始，接口也可以拥有默认的方法实现，这是因为不支持默认方法的接口的维护成本太高了。在 Java 8 之前，如果一个接口想要添加新的方法，那么要修改所有实现了该接口的类，让它们都实现新增的方法。\n接口的成员（字段 + 方法）默认都是 public 的，并且不允许定义为 private 或者 protected。从 Java 9 开始，允许将方法定义为 private，这样就能定义某些复用的代码又不会把方法暴露出去。\n接口的字段默认都是 static 和 final 的。\n6.3 super 访问父类的构造函数：可以使用 super() 函数访问父类的构造函数，从而委托父类完成一些初始化的工作。应该注意到，子类一定会调用父类的构造函数来完成初始化工作，一般是调用父类的默认构造函数，如果子类需要调用父类其它构造函数，那么就可以使用 super() 函数。 访问父类的成员：如果子类重写了父类的某个方法，可以通过使用 super 关键字来引用父类的方法实现。 6.4 重写与重载 1. 重写（Override）\n存在于继承体系中，指子类实现了一个与父类在方法声明上完全相同的一个方法。\n为了满足里式替换原则，重写有以下三个限制：\n子类方法的访问权限必须大于等于父类方法； 子类方法的返回类型必须是父类方法返回类型或为其子类型。 子类方法抛出的异常类型必须是父类抛出异常类型或为其子类型。 使用 @Override 注解，可以让编译器帮忙检查是否满足上面的三个限制条件。\n2. 重载（Overload）\n存在于同一个类中，指一个方法与已经存在的方法名称上相同，但是参数类型、个数、顺序至少有一个不同。\n应该注意的是，返回值不同，其它都相同不算是重载。\n7 反射 每个类都有一个 Class 对象，包含了与类有关的信息。当编译一个新类时，会产生一个同名的 .class 文件，该文件内容保存着 Class 对象。\n类加载相当于 Class 对象的加载，类在第一次使用时才动态加载到 JVM 中。也可以使用 Class.forName(\u0026quot;com.mysql.jdbc.Driver\u0026quot;) 这种方式来控制类的加载，该方法会返回一个 Class 对象。\n反射可以提供运行时的类信息，并且这个类可以在运行时才加载进来，甚至在编译时期该类的 .class 不存在也可以加载进来。\nClass 和 java.lang.reflect 一起对反射提供了支持，java.lang.reflect 类库主要包含了以下三个类：\nField ：可以使用 get() 和 set() 方法读取和修改 Field 对象关联的字段； Method ：可以使用 invoke() 方法调用与 Method 对象关联的方法； Constructor ：可以用 Constructor 的 newInstance() 创建新的对象。 反射的优点：\n可扩展性 ：应用程序可以利用全限定名创建可扩展对象的实例，来使用来自外部的用户自定义类。 类浏览器和可视化开发环境 ：一个类浏览器需要可以枚举类的成员。可视化开发环境（如 IDE）可以从利用反射中可用的类型信息中受益，以帮助程序员编写正确的代码。 调试器和测试工具 ： 调试器需要能够检查一个类里的私有成员。测试工具可以利用反射来自动地调用类里定义的可被发现的 API 定义，以确保一组测试中有较高的代码覆盖率。 反射的缺点：\n尽管反射非常强大，但也不能滥用。如果一个功能可以不用反射完成，那么最好就不用。在我们使用反射技术时，下面几条内容应该牢记于心。\n性能开销 ：反射涉及了动态类型的解析，所以 JVM 无法对这些代码进行优化。因此，反射操作的效率要比那些非反射操作低得多。我们应该避免在经常被执行的代码或对性能要求很高的程序中使用反射。 安全限制 ：使用反射技术要求程序必须在一个没有安全限制的环境中运行。如果一个程序必须在有安全限制的环境中运行，如 Applet，那么这就是个问题了。 内部暴露 ：由于反射允许代码执行一些在正常情况下不被允许的操作（比如访问私有的属性和方法），所以使用反射可能会导致意料之外的副作用，这可能导致代码功能失调并破坏可移植性。反射代码破坏了抽象性，因此当平台发生改变的时候，代码的行为就有可能也随着变化。 8 异常 Throwable 可以用来表示任何可以作为异常抛出的类，分为两种： Error 和 Exception。其中 Error 用来表示 JVM 无法处理的错误，Exception 分为两种：\n受检异常 ：需要用 try\u0026hellip;catch\u0026hellip; 语句捕获并进行处理，并且可以从异常中恢复； 非受检异常 ：是程序运行时错误，例如除 0 会引发 Arithmetic Exception，此时程序崩溃并且无法恢复。 9 泛型、注解、新特性 略。\n本文转载自：https://github.com/CyC2018/CS-Notes\r，用于个人复习。\n","date":"2021-05-04T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/river-6021951_1920.4hwe8w8ugb20.webp","permalink":"https://cuterwrite.top/p/java-se/","title":"JavaSE 知识点笔记"},{"content":"JVM 知识点笔记 1 运行时数据区域 1.1 程序计数器 记录正在执行的虚拟机字节码指令的地址（如果正在执行的是本地方法则为空）。\n1.2 Java 虚拟机栈 每个 Java 方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。\n可以通过 -Xss 这个虚拟机参数来指定每个线程的 Java 虚拟机栈内存大小，在 JDK 1.4 中默认为 256K，而在 JDK 1.5+ 默认为 1M：\n该区域可能抛出以下异常：\n当线程请求的栈深度超过最大值，会抛出 StackOverflowError 异常； 栈进行动态扩展时如果无法申请到足够内存，会抛出 OutOfMemoryError 异常。 1.3 本地方法栈 本地方法栈与 Java 虚拟机栈类似，它们之间的区别只不过是本地方法栈为本地方法服务。\n本地方法一般是用其它语言（C、C++ 或汇编语言等）编写的，并且被编译为基于本机硬件和操作系统的程序，对待这些方法需要特别处理。\n1.4 堆 所有对象都在这里分配内存，是垃圾收集的主要区域（\u0026ldquo;GC 堆\u0026rdquo;）。\n现代的垃圾收集器基本都是采用分代收集算法，其主要的思想是针对不同类型的对象采取不同的垃圾回收算法。可以将堆分成两块：\n新生代（Young Generation） 老年代（Old Generation） 堆不需要连续内存，并且可以动态增加其内存，增加失败会抛出 OutOfMemoryError 异常。\n可以通过 -Xms 和 -Xmx 这两个虚拟机参数来指定一个程序的堆内存大小，第一个参数设置初始值，第二个参数设置最大值。\njava -Xms1M -Xmx2M HackTheJava\r1.5 方法区 用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。\n和堆一样不需要连续的内存，并且可以动态扩展，动态扩展失败一样会抛出 OutOfMemoryError 异常。\n对这块区域进行垃圾回收的主要目标是对常量池的回收和对类的卸载，但是一般比较难实现。\nHotSpot 虚拟机把它当成永久代来进行垃圾回收。但很难确定永久代的大小，因为它受到很多因素影响，并且每次 Full GC 之后永久代的大小都会改变，所以经常会抛出 OutOfMemoryError 异常。为了更容易管理方法区，从 JDK 1.8 开始，移除永久代，并把方法区移至元空间，它位于本地内存中，而不是虚拟机内存中。\n方法区是一个 JVM 规范，永久代与元空间都是其一种实现方式。在 JDK 1.8 之后，原来永久代的数据被分到了堆和元空间中。元空间存储类的元信息，静态变量和常量池等放入堆中。\n1.6 运行时常量池 运行时常量池是方法区的一部分。\nClass 文件中的常量池（编译器生成的字面量和符号引用）会在类加载后被放入这个区域。\n除了在编译期生成的常量，还允许动态生成，例如 String 类的 intern()。\n1.7 直接内存 在 JDK 1.4 中新引入了 NIO 类，它可以使用 Native 函数库直接分配堆外内存，然后通过 Java 堆里的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在堆内存和堆外内存来回拷贝数据。\n2 垃圾收集 垃圾收集主要是针对堆和方法区进行。程序计数器、虚拟机栈和本地方法栈这三个区域属于线程私有的，只存在于线程的生命周期内，线程结束之后就会消失，因此不需要对这三个区域进行垃圾回收。\n2.1 判断一个对象是否可回收 2.1.1 引用计数算法 为对象添加一个引用计数器，当对象增加一个引用时计数器加 1，引用失效时计数器减 1。引用计数为 0 的对象可被回收。\n在两个对象出现循环引用的情况下，此时引用计数器永远不为 0，导致无法对它们进行回收。正是因为循环引用的存在，因此 Java 虚拟机不使用引用计数算法。\n2.1.2 可达性分析算法 以 GC Roots 为起始点进行搜索，可达的对象都是存活的，不可达的对象可被回收。\nJava 虚拟机使用该算法来判断对象是否可被回收，GC Roots 一般包含以下内容：\n虚拟机栈中局部变量表中引用的对象 本地方法栈中 JNI 中引用的对象 方法区中类静态属性引用的对象 方法区中的常量引用的对象 2.1.3 方法区的回收 因为方法区主要存放永久代对象，而永久代对象的回收率比新生代低很多，所以在方法区上进行回收性价比不高。\n主要是对常量池的回收和对类的卸载。\n为了避免内存溢出，在大量使用反射和动态代理的场景都需要虚拟机具备类卸载功能。\n类的卸载条件很多，需要满足以下三个条件，并且满足了条件也不一定会被卸载：\n该类所有的实例都已经被回收，此时堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 Class 对象没有在任何地方被引用，也就无法在任何地方通过反射访问该类方法。 2.1.4 finalize() 类似 C++ 的析构函数，用于关闭外部资源。但是 try-finally 等方式可以做得更好，并且该方法运行代价很高，不确定性大，无法保证各个对象的调用顺序，因此最好不要使用。\n当一个对象可被回收时，如果需要执行该对象的 finalize() 方法，那么就有可能在该方法中让对象重新被引用，从而实现自救。自救只能进行一次，如果回收的对象之前调用了 finalize() 方法自救，后面回收时不会再调用该方法。\n2.2 引用类型 无论是通过引用计数算法判断对象的引用数量，还是通过可达性分析算法判断对象是否可达，判定对象是否可被回收都与引用有关。\nJava 提供了四种强度不同的引用类型。\n2.2.1 强引用 被强引用关联的对象不会被回收。\n使用 new 一个新对象的方式来创建强引用。\n2.2.2 软引用 被软引用关联的对象只有在内存不够的情况下才会被回收。\n使用 SoftReference 类来创建软引用。\n2.2.3 弱引用 被弱引用关联的对象一定会被回收，也就是说它只能存活到下一次垃圾回收发生之前。\n使用 WeakReference 类来创建弱引用。\n2.2.4 虚引用 又称为幽灵引用或者幻影引用，一个对象是否有虚引用的存在，不会对其生存时间造成影响，也无法通过虚引用得到一个对象。\n为一个对象设置虚引用的唯一目的是能在这个对象被回收时收到一个系统通知。\n使用 PhantomReference 来创建虚引用。\n2.3 垃圾收集算法 2.3.1 标记 - 清除 在标记阶段，程序会检查每个对象是否为活动对象，如果是活动对象，则程序会在对象头部打上标记。\n在清除阶段，会进行对象回收并取消标志位，另外，还会判断回收后的分块与前一个空闲分块是否连续，若连续，会合并这两个分块。回收对象就是把对象作为分块，连接到被称为 “空闲链表” 的单向链表，之后进行分配时只需要遍历这个空闲链表，就可以找到分块。\n在分配时，程序会搜索空闲链表寻找空间大于等于新对象大小 size 的块 block。如果它找到的块等于 size，会直接返回这个分块；如果找到的块大于 size，会将块分割成大小为 size 与 (block - size) 的两部分，返回大小为 size 的分块，并把大小为 (block - size) 的块返回给空闲链表。\n不足：\n标记和清除过程效率都不高； 会产生大量不连续的内存碎片，导致无法给大对象分配内存。 2.3.2 标记-整理 让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。\n优点:\n不会产生内存碎片 不足:\n需要移动大量对象，处理效率比较低。 2.3.3 复制 将内存划分为大小相等的两块，每次只使用其中一块，当这一块内存用完了就将还存活的对象复制到另一块上面，然后再把使用过的内存空间进行一次清理。\n主要不足是只使用了内存的一半。\n现在的商业虚拟机都采用这种收集算法回收新生代，但是并不是划分为大小相等的两块，而是一块较大的 Eden 空间和两块较小的 Survivor 空间，每次使用 Eden 和其中一块 Survivor。在回收时，将 Eden 和 Survivor 中还存活着的对象全部复制到另一块 Survivor 上，最后清理 Eden 和使用过的那一块 Survivor。\nHotSpot 虚拟机的 Eden 和 Survivor 大小比例默认为 8:1，保证了内存的利用率达到 90%。如果每次回收有多于 10% 的对象存活，那么一块 Survivor 就不够用了，此时需要依赖于老年代进行空间分配担保，也就是借用老年代的空间存储放不下的对象。\n2.3.4 分代收集 现在的商业虚拟机采用分代收集算法，它根据对象存活周期将内存划分为几块，不同块采用适当的收集算法。\n一般将堆分为新生代和老年代。\n新生代使用：复制算法 老年代使用：标记 - 清除 或者 标记 - 整理 算法 2.4 垃圾收集器 以上是 HotSpot 虚拟机中的 7 个垃圾收集器，连线表示垃圾收集器可以配合使用。\n单线程与多线程：单线程指的是垃圾收集器只使用一个线程，而多线程使用多个线程； 串行与并行：串行指的是垃圾收集器与用户程序交替执行，这意味着在执行垃圾收集的时候需要停顿用户程序；并行指的是垃圾收集器和用户程序同时执行。除了 CMS 和 G1 之外，其它垃圾收集器都是以串行的方式执行。 3 内存分配与回收策略 3.1 Minor GC 和 Full GC Minor GC：回收新生代，因为新生代对象存活时间很短，因此 Minor GC 会频繁执行，执行的速度一般也会比较快。 Full GC：回收老年代和新生代，老年代对象其存活时间长，因此 Full GC 很少执行，执行速度会比 Minor GC 慢很多。 3.2 内存分配策略 3.2.1. 对象优先在 Eden 分配 大多数情况下，对象在新生代 Eden 上分配，当 Eden 空间不够时，发起 Minor GC。\n3.2.2. 大对象直接进入老年代 大对象是指需要连续内存空间的对象，最典型的大对象是那种很长的字符串以及数组。\n经常出现大对象会提前触发垃圾收集以获取足够的连续空间分配给大对象。\n-XX:PretenureSizeThreshold，大于此值的对象直接在老年代分配，避免在 Eden 和 Survivor 之间的大量内存复制。\n3.2.3. 长期存活的对象进入老年代 为对象定义年龄计数器，对象在 Eden 出生并经过 Minor GC 依然存活，将移动到 Survivor 中，年龄就增加 1 岁，增加到一定年龄则移动到老年代中。\n-XX:MaxTenuringThreshold 用来定义年龄的阈值。\n3.2.4. 动态对象年龄判定 虚拟机并不是永远要求对象的年龄必须达到 MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 中相同年龄所有对象大小的总和大于 Survivor 空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代，无需等到 MaxTenuringThreshold 中要求的年龄。\n3.2.5. 空间分配担保 在发生 Minor GC 之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立的话，那么 Minor GC 可以确认是安全的。\n如果不成立的话虚拟机会查看 HandlePromotionFailure 的值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC；如果小于，或者 HandlePromotionFailure 的值不允许冒险，那么就要进行一次 Full GC。\n3.3 Full GC 触发条件 对于 Minor GC，其触发条件非常简单，当 Eden 空间满时，就将触发一次 Minor GC。而 Full GC 则相对复杂，有以下条件：\n3.3.1. 调用 System.gc() 只是建议虚拟机执行 Full GC，但是虚拟机不一定真正去执行。不建议使用这种方式，而是让虚拟机管理内存。\n3.3.2. 老年代空间不足 老年代空间不足的常见场景为前文所讲的大对象直接进入老年代、长期存活的对象进入老年代等。\n为了避免以上原因引起的 Full GC，应当尽量不要创建过大的对象以及数组。除此之外，可以通过 -Xmn 虚拟机参数调大新生代的大小，让对象尽量在新生代被回收掉，不进入老年代。还可以通过 -XX:MaxTenuringThreshold 调大对象进入老年代的年龄，让对象在新生代多存活一段时间。\n3.3.3. 空间分配担保失败 使用复制算法的 Minor GC 需要老年代的内存空间作担保，如果担保失败会执行一次 Full GC。具体内容请参考上面的第 5 小节。\n3.3.4. JDK 1.7 及以前的永久代空间不足 在 JDK 1.7 及以前，HotSpot 虚拟机中的方法区是用永久代实现的，永久代中存放的为一些 Class 的信息、常量、静态变量等数据。\n当系统中要加载的类、反射的类和调用的方法较多时，永久代可能会被占满，在未配置为采用 CMS GC 的情况下也会执行 Full GC。如果经过 Full GC 仍然回收不了，那么虚拟机会抛出 java.lang.OutOfMemoryError。\n为避免以上原因引起的 Full GC，可采用的方法为增大永久代空间或转为使用 CMS GC。\n3.3.5. Concurrent Mode Failure 执行 CMS GC 的过程中同时有对象要放入老年代，而此时老年代空间不足（可能是 GC 过程中浮动垃圾过多导致暂时性的空间不足），便会报 Concurrent Mode Failure 错误，并触发 Full GC。\n4 类加载机制 类是在运行期间第一次使用时动态加载的，而不是一次性加载所有类。因为如果一次性加载，那么会占用很多的内存。\n4.1 类的生命周期 包括以下 7 个阶段：\n加载（Loading） 验证（Verification） 准备（Preparation） 解析（Resolution） 初始化（Initialization） 使用（Using） 卸载（Unloading） 4.2 类加载过程 包含了加载、验证、准备、解析和初始化这 5 个阶段。\n4.2.1. 加载 加载是类加载的一个阶段，注意不要混淆。\n加载过程完成以下三件事：\n通过类的完全限定名称获取定义该类的二进制字节流。 将该字节流表示的静态存储结构转换为方法区的运行时存储结构。 在内存中生成一个代表该类的 Class 对象，作为方法区中该类各种数据的访问入口。 其中二进制字节流可以从以下方式中获取：\n从 ZIP 包读取，成为 JAR、EAR、WAR 格式的基础。 从网络中获取，最典型的应用是 Applet。 运行时计算生成，例如动态代理技术，在 java.lang.reflect.Proxy 使用 ProxyGenerator.generateProxyClass 的代理类的二进制字节流。 由其他文件生成，例如由 JSP 文件生成对应的 Class 类。 4.2.2. 验证 确保 Class 文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。\n4.2.3. 准备 类变量是被 static 修饰的变量，准备阶段为类变量分配内存并设置初始值，使用的是方法区的内存。\n实例变量不会在这阶段分配内存，它会在对象实例化时随着对象一起被分配在堆中。应该注意到，实例化不是类加载的一个过程，类加载发生在所有实例化操作之前，并且类加载只进行一次，实例化可以进行多次。\n初始值一般为 0 值，例如下面的类变量 value 被初始化为 0 而不是 123。\npublic static int value = 123;\r如果类变量是常量，那么它将初始化为表达式所定义的值而不是 0。例如下面的常量 value 被初始化为 123 而不是 0。\npublic static final int value = 123;\r4.2.4. 解析 将常量池的符号引用替换为直接引用的过程。\n其中解析过程在某些情况下可以在初始化阶段之后再开始，这是为了支持 Java 的动态绑定。\n4.2.5. 初始化 初始化阶段才真正开始执行类中定义的 Java 程序代码。初始化阶段是虚拟机执行类构造器 \u0026lt;clinit\u0026gt;() 方法的过程。在准备阶段，类变量已经赋过一次系统要求的初始值，而在初始化阶段，根据程序员通过程序制定的主观计划去初始化类变量和其它资源。\n\u0026lt;clinit\u0026gt;() 是由编译器自动收集类中所有类变量的赋值动作和静态语句块中的语句合并产生的，编译器收集的顺序由语句在源文件中出现的顺序决定。特别注意的是，静态语句块只能访问到定义在它之前的类变量，定义在它之后的类变量只能赋值，不能访问。例如以下代码：\npublic class Test {\rstatic {\ri = 0; // 给变量赋值可以正常编译通过\rSystem.out.print(i); // 这句编译器会提示“非法向前引用”\r}\rstatic int i = 1;\r}\r由于父类的 \u0026lt;clinit\u0026gt;() 方法先执行，也就意味着父类中定义的静态语句块的执行要优先于子类。例如以下代码：\nstatic class Parent {\rpublic static int A = 1;\rstatic {\rA = 2;\r}\r}\rstatic class Sub extends Parent {\rpublic static int B = A;\r}\rpublic static void main(String[] args) {\rSystem.out.println(Sub.B); // 2\r}\r接口中不可以使用静态语句块，但仍然有类变量初始化的赋值操作，因此接口与类一样都会生成 \u0026lt;clinit\u0026gt;() 方法。但接口与类不同的是，执行接口的 \u0026lt;clinit\u0026gt;() 方法不需要先执行父接口的 \u0026lt;clinit\u0026gt;() 方法。只有当父接口中定义的变量使用时，父接口才会初始化。另外，接口的实现类在初始化时也一样不会执行接口的 \u0026lt;clinit\u0026gt;() 方法。\n虚拟机会保证一个类的 \u0026lt;clinit\u0026gt;() 方法在多线程环境下被正确的加锁和同步，如果多个线程同时初始化一个类，只会有一个线程执行这个类的 \u0026lt;clinit\u0026gt;() 方法，其它线程都会阻塞等待，直到活动线程执行 \u0026lt;clinit\u0026gt;() 方法完毕。如果在一个类的 \u0026lt;clinit\u0026gt;() 方法中有耗时的操作，就可能造成多个线程阻塞，在实际过程中此种阻塞很隐蔽。\n4.3 类初始化时机 4.3.1. 主动引用 虚拟机规范中并没有强制约束何时进行加载，但是规范严格规定了有且只有下列五种情况必须对类进行初始化（加载、验证、准备都会随之发生）：\n遇到 new、getstatic、putstatic、invokestatic 这四条字节码指令时，如果类没有进行过初始化，则必须先触发其初始化。最常见的生成这 4 条指令的场景是：使用 new 关键字实例化对象的时候；读取或设置一个类的静态字段（被 final 修饰、已在编译期把结果放入常量池的静态字段除外）的时候；以及调用一个类的静态方法的时候。\n使用 java.lang.reflect 包的方法对类进行反射调用的时候，如果类没有进行初始化，则需要先触发其初始化。\n当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。\n当虚拟机启动时，用户需要指定一个要执行的主类（包含 main() 方法的那个类），虚拟机会先初始化这个主类；\n当使用 JDK 1.7 的动态语言支持时，如果一个 java.lang.invoke.MethodHandle 实例最后的解析结果为 REF_getStatic, REF_putStatic, REF_invokeStatic 的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化；\n4.3.2. 被动引用 以上 5 种场景中的行为称为对一个类进行主动引用。除此之外，所有引用类的方式都不会触发初始化，称为被动引用。被动引用的常见例子包括：\n通过子类引用父类的静态字段，不会导致子类初始化。 System.out.println(SubClass.value); // value 字段在 SuperClass 中定义\r通过数组定义来引用类，不会触发此类的初始化。该过程会对数组类进行初始化，数组类是一个由虚拟机自动生成的、直接继承自 Object 的子类，其中包含了数组的属性和方法。 SuperClass[] sca = new SuperClass[10];\r常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。 System.out.println(ConstClass.HELLOWORLD);\r4.4 类与类加载器 两个类相等，需要类本身相等，并且使用同一个类加载器进行加载。这是因为每一个类加载器都拥有一个独立的类名称空间。\n这里的相等，包括类的 Class 对象的 equals() 方法、isAssignableFrom() 方法、isInstance() 方法的返回结果为 true，也包括使用 instanceof 关键字做对象所属关系判定结果为 true。\n4.5 类加载器分类 从 Java 虚拟机的角度来讲，只存在以下两种不同的类加载器：\n启动类加载器（Bootstrap ClassLoader），使用 C++ 实现，是虚拟机自身的一部分；\n所有其它类的加载器，使用 Java 实现，独立于虚拟机，继承自抽象类 java.lang.ClassLoader。\n从 Java 开发人员的角度看，类加载器可以划分得更细致一些：\n启动类加载器（Bootstrap ClassLoader）此类加载器负责将存放在 \u0026lt;JRE_HOME\u0026gt;\\lib 目录中的，或者被 -Xbootclasspath 参数所指定的路径中的，并且是虚拟机识别的（仅按照文件名识别，如 rt.jar，名字不符合的类库即使放在 lib 目录中也不会被加载）类库加载到虚拟机内存中。启动类加载器无法被 Java 程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给启动类加载器，直接使用 null 代替即可。\n扩展类加载器（Extension ClassLoader）这个类加载器是由 ExtClassLoader（sun.misc.Launcher$ExtClassLoader）实现的。它负责将 \u0026lt;JAVA_HOME\u0026gt;/lib/ext 或者被 java.ext.dir 系统变量所指定路径中的所有类库加载到内存中，开发者可以直接使用扩展类加载器。\n应用程序类加载器（Application ClassLoader）这个类加载器是由 AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的。由于这个类加载器是 ClassLoader 中的 getSystemClassLoader() 方法的返回值，因此一般称为系统类加载器。它负责加载用户类路径（ClassPath）上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。\n4.6 双亲委派模型 应用程序是由三种类加载器互相配合从而实现类加载，除此之外还可以加入自己定义的类加载器。\n下图展示了类加载器之间的层次关系，称为双亲委派模型（Parents Delegation Model）。该模型要求除了顶层的启动类加载器外，其它的类加载器都要有自己的父类加载器。这里的父子关系一般通过组合关系（Composition）来实现，而不是继承关系（Inheritance）。\n4.6.1. 工作过程 一个类加载器首先将类加载请求转发到父类加载器，只有当父类加载器无法完成时才尝试自己加载。\n4.6.2. 好处 使得 Java 类随着它的类加载器一起具有一种带有优先级的层次关系，从而使得基础类得到统一。\n例如 java.lang.Object 存放在 rt.jar 中，如果编写另外一个 java.lang.Object 并放到 ClassPath 中，程序可以编译通过。由于双亲委派模型的存在，所以在 rt.jar 中的 Object 比在 ClassPath 中的 Object 优先级更高，这是因为 rt.jar 中的 Object 使用的是启动类加载器，而 ClassPath 中的 Object 使用的是应用程序类加载器。rt.jar 中的 Object 优先级更高，那么程序中所有的 Object 都是这个 Object。\n4.6.3. 实现 以下是抽象类 java.lang.ClassLoader 的代码片段，其中的 loadClass() 方法运行过程如下：先检查类是否已经加载过，如果没有则让父类加载器去加载。当父类加载器加载失败时抛出 ClassNotFoundException，此时尝试自己去加载。\npublic abstract class ClassLoader {\r// The parent class loader for delegation\rprivate final ClassLoader parent;\rpublic Class\u0026lt;?\u0026gt; loadClass(String name) throws ClassNotFoundException {\rreturn loadClass(name, false);\r}\rprotected Class\u0026lt;?\u0026gt; loadClass(String name, boolean resolve) throws ClassNotFoundException {\rsynchronized (getClassLoadingLock(name)) {\r// First, check if the class has already been loaded\rClass\u0026lt;?\u0026gt; c = findLoadedClass(name);\rif (c == null) {\rtry {\rif (parent != null) {\rc = parent.loadClass(name, false);\r} else {\rc = findBootstrapClassOrNull(name);\r}\r} catch (ClassNotFoundException e) {\r// ClassNotFoundException thrown if class not found\r// from the non-null parent class loader\r}\rif (c == null) {\r// If still not found, then invoke findClass in order\r// to find the class.\rc = findClass(name);\r}\r}\rif (resolve) {\rresolveClass(c);\r}\rreturn c;\r}\r}\rprotected Class\u0026lt;?\u0026gt; findClass(String name) throws ClassNotFoundException {\rthrow new ClassNotFoundException(name);\r}\r}\r4.7 自定义类加载器实现 以下代码中的 FileSystemClassLoader 是自定义类加载器，继承自 java.lang.ClassLoader，用于加载文件系统上的类。它首先根据类的全名在文件系统上查找类的字节代码文件（.class 文件），然后读取该文件内容，最后通过 defineClass() 方法来把这些字节代码转换成 java.lang.Class 类的实例。\njava.lang.ClassLoader 的 loadClass() 实现了双亲委派模型的逻辑，自定义类加载器一般不去重写它，但是需要重写 findClass() 方法。\n本文转载自：https://github.com/CyC2018/CS-Notes\r，用于个人复习。\n","date":"2021-05-04T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/naples-122698_1920.2vb750rs8te0.webp","permalink":"https://cuterwrite.top/p/jvm/","title":"JVM 知识点笔记"},{"content":"Socket 与 IO 模型 1 IO 模型 1.1 阻塞式 IO 应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回。\n应该注意到，在阻塞的过程中，其它应用进程还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其它应用进程还可以执行，所以不消耗 CPU 时间，这种模型的 CPU 利用率会比较高。\n1.2 非阻塞式 IO 应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询（polling）。\n由于 CPU 要处理更多的系统调用，因此这种模型的 CPU 利用率比较低。\n1.3 IO 复用 使用 select 或者 poll 等待数据，并且可以等待多个套接字中的任何一个变为可读。这一过程会被阻塞，当某一个套接字可读时返回，之后再使用 recvfrom 把数据从内核复制到进程中。\n它可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O。\n如果一个 Web 服务器没有 I/O 复用，那么每一个 Socket 连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。\n1.4 信号驱动 IO 应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。\n相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。\n1.5 异步 IO 应用进程执行 aio_read 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。\n异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O。\n1.6 IO 模型对比 同步 IO：将数据从内核缓冲区复制到应用进程缓冲区的阶段（第二阶段），应用进程会阻塞。 异步 IO：第二阶段应用进程不会阻塞。 同步 IO 包括：BIO、NIO、IO 复用和信号驱动 IO，它们的区别在第一阶段\nBIO 会直接阻塞应用进程，直到数据从内核缓冲区复制到应用进程缓冲区。\nNIO 采用轮询方式判断 IO 是否完成，避免阻塞。\n信号驱动 IO 采用 SIGIO 信号方式，避免阻塞\nIO 多路复用使用 select/poll/epoll 等待描述符成为就绪状态，避免阻塞。\n其中，NIO、信号驱动 IO 和异步 IO 在第一阶段不会阻塞。\n2 IO 复用 2.1 select select 允许应用程序监视一组文件描述符，等待一个或者多个描述符成为就绪状态，从而完成 I/O 操作。\n缺点：\n单个进程所打开的 FD 是有限制的，通过 FD_SETSIZE 设置，默认 1024 每次调用 select，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大 对 socket 扫描时是线性扫描（对所有的 fds 遍历扫描），采用轮询的方法，效率较低（高并发时） 2.2 poll poll 与 select 相比，只是没有 fd 的限制，其它基本一样\n缺点：\n每次调用 poll，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大 对 socket 扫描时是线性扫描，采用轮询的方法，效率较低（高并发时） 2.3 epoll select 和 poll 速度都比较慢，每次调用都需要将全部描述符从应用进程缓冲区复制到内核缓冲区。\nepoll 只需要将描述符从进程缓冲区向内核缓冲区拷贝一次，并且进程不需要通过轮询来获得事件完成的描述符。\n缺点：epoll 只能工作在 linux 下\n2.4 LT 与 ET LT：LT 模式下，只要这个 fd 还有数据可读，每次 epoll_wait 都会返回它的事件，提醒用户程序去操作。 ET：ET 模式下，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论 fd 中是否还有数据可读。所以在 ET 模式下，read 一个 fd 的时候一定要把它的 buffer 读完，或者遇到 EAGAIN 错误。 2.5 select、poll、epoll 对比 select poll epoll 数据结构 bitmap 数组 红黑树 最大连接数 1024 无上限 无上限 fd 拷贝 每次调用 select 拷贝 每次调用 poll 拷贝 fd 首次调用 epoll_ctl 拷贝，每次调用 epoll_wait 不拷贝 工作效率 轮询：O(n) 轮询：O(n) 回调：O(1) 本文转载自：https://github.com/CyC2018/CS-Notes\r，用于个人复习。\n","date":"2021-05-04T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/cheetah-3749168_1920.4pgxzkp625g0.webp","permalink":"https://cuterwrite.top/p/io-model/","title":"Socket 与 IO 模型"},{"content":"一、数据库系统原理 1 事务 1.1 概念 事务指的是满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。\n1.2 ACID 原子性\n事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。\n回滚可以用回滚日志（Undo Log）来实现，回滚日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。\n一致性\n数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对同一个数据的读取结果都是相同的。\n隔离性\n一个事务所做的修改在最终提交以前，对其它事务是不可见的。\n持久性\n一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。系统发生崩溃可以用重做日志（Redo Log）进行恢复，从而实现持久性。与回滚日志记录数据的逻辑修改不同，重做日志记录的是数据页的物理修改。\n原因：\n只有满足一致性，事务的执行结果才是正确的。\n在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。\n在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。\n事务满足持久化是为了能应对系统崩溃的情况。\n1.3 AUTOCOMMIT MySQL 默认采用自动提交模式。也就是说，如果不显式使用START TRANSACTION 语句来开始一个事务，那么每个查询操作都会被当做一个事务并自动提交。\n2 并发一致性问题 2.1 丢失修改 丢失修改指一个事务的更新操作被另外一个事务的更新操作替换。一般在现实生活中常会遇到，例如：T1 和 T2 两个事务都对一个数据进行修改，T1 先修改并提交生效，T2 随后修改，T2 的修改覆盖了 T1 的修改。\n2.2 读脏数据 读脏数据指在不同的事务下，当前事务可以读到另外事务未提交的数据。例如：T1 修改一个数据但未提交，T2 随后读取这个数据。如果 T1 撤销了这次修改，那么 T2 读取的数据是脏数据。\n2.3 不可重复读 不可重复读指在一个事务内多次读取同一数据集合。在这一事务还未结束前，另一事务也访问了该同一数据集合并做了修改，由于第二个事务的修改，第一次事务的两次读取的数据可能不一致。例如：T2 读取一个数据，T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。\n2.4 幻影读 幻读本质上也属于不可重复读的情况，T1 读取某个范围的数据，T2 在这个范围内插入新的数据，T1 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。\n3 封锁 3.1 封锁粒度 MySQL 中提供了两种封锁粒度：行级锁以及表级锁。\n应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。\n但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。因此封锁粒度越小，系统开销就越大。\n在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。\n3.2 封锁类型 3.2.1 读写锁 互斥锁（Exclusive），简写为 X 锁，又称写锁。 共享锁（Shared），简写为 S 锁，又称读锁。 有以下两个规定：\n一个事务对数据对象 A 加了 X 锁，就可以对 A 进行读取和更新。加锁期间其它事务不能对 A 加任何锁。 一个事务对数据对象 A 加了 S 锁，可以对 A 进行读取操作，但是不能进行更新操作。加锁期间其它事务能对 A 加 S 锁，但是不能加 X 锁。 锁的兼容关系如下：\n3.2.2 意向锁 使用意向锁（Intention Locks）可以更容易地支持多粒度封锁。\n在存在行级锁和表级锁的情况下，事务 T 想要对表 A 加 X 锁，就需要先检测是否有其它事务对表 A 或者表 A 中的任意一行加了锁，那么就需要对表 A 的每一行都检测一次，这是非常耗时的。\n意向锁在原来的 X/S 锁之上引入了 IX/IS，IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。有以下两个规定：\n一个事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁； 一个事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。 通过引入意向锁，事务 T 想要对表 A 加 X 锁，只需要先检测是否有其它事务对表 A 加了 X/IX/S/IS 锁，如果加了就表示有其它事务正在使用这个表或者表中某一行的锁，因此事务 T 加 X 锁失败。\n各种锁的兼容关系如下：\n解释如下：\n任意 IS/IX 锁之间都是兼容的，因为它们只表示想要对表加锁，而不是真正加锁； 这里兼容关系针对的是表级锁，而表级的 IX 锁和行级的 X 锁兼容，两个事务可以对两个数据行加 X 锁。（事务 T1 想要对数据行 R1 加 X 锁，事务 T2 想要对同一个表的数据行 R2 加 X 锁，两个事务都需要对该表加 IX 锁，但是 IX 锁是兼容的，并且 IX 锁与行级的 X 锁也是兼容的，因此两个事务都能加锁成功，对同一个表中的两个数据行做修改。） 3.3 封锁协议 3.3.1 三级封锁协议 一级封锁协议：事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。可以解决丢失修改问题，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。 二级封锁协议：在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。可以解决读脏数据问题，因为如果一个事务在对数据 A 进行修改，根据 1 级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据。 三级封锁协议：在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。可以解决不可重复读的问题，因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变。 3.3.2 二段锁协议 加锁和解锁分为两个阶段进行。\n可串行化调度是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。串行执行的事务互不干扰，不会出现并发一致性问题。\n事务遵循两段锁协议是保证可串行化调度的充分条件。例如以下操作满足两段锁协议，它是可串行化调度。\n3.4 MySQL 隐式与显示锁定 MySQL 的 InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。\nInnoDB 也可以使用特定的语句进行显示锁定：\nSELECT ... LOCK In SHARE MODE;\rSELECT ... FOR UPDATE;\r4 隔离级别 4.1 未提交读 事务中的修改，即使没有提交，对其它事务也是可见的。\n4.2 提交读 一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。\n4.3 可重复读 保证在同一个事务中多次读取同一数据的结果是一样的。\n4.4 可串行化 强制事务串行执行，这样多个事务互不干扰，不会出现并发一致性问题。\n该隔离级别需要加锁实现，因为要使用加锁机制保证同一时间只有一个事务执行，也就是保证事务串行执行。\n5 多版本并发控制 多版本并发控制（Multi-Version Concurrency Control, MVCC）是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。而未提交读隔离级别总是读取最新的数据行，要求很低，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。\n5.1 基本思想 在封锁一节中提到，加锁能解决多个事务同时执行时出现的并发一致性问题。在实际场景中读操作往往多于写操作，因此又引入了读写锁来避免不必要的加锁操作，例如读和读没有互斥关系。读写锁中读和写操作仍然是互斥的，而 MVCC 利用了多版本的思想，写操作更新最新的版本快照，而读操作去读旧版本快照，没有互斥关系，这一点和 CopyOnWrite 类似。\n在 MVCC 中事务的修改操作（DELETE、INSERT、UPDATE）会为数据行新增一个版本快照。\n脏读和不可重复读最根本的原因是事务读取到其它事务未提交的修改。在事务进行读取操作时，为了解决脏读和不可重复读问题，MVCC 规定只能读取已经提交的快照。当然一个事务可以读取自身未提交的快照，这不算是脏读。\n5.2 版本号 系统版本号 SYS_ID：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。 事务版本号 TRX_ID ：事务开始时的系统版本号。 5.3 Undo 日志 MVCC 的多版本指的是多个版本的快照，快照存储在 Undo 日志中，该日志通过回滚指针 ROLL_PTR 把一个数据行的所有快照连接起来。\n例如在 MySQL 创建一个表 t，包含主键 id 和一个字段 x。我们先插入一个数据行，然后对该数据行执行两次更新操作。\nINSERT INTO t(id, x) VALUES(1, \u0026quot;a\u0026quot;);\rUPDATE t SET x=\u0026quot;b\u0026quot; WHERE id=1;\rUPDATE t SET x=\u0026quot;c\u0026quot; WHERE id=1;\r因为没有使用 START TRANSACTION 将上面的操作当成一个事务来执行，根据 MySQL 的 AUTOCOMMIT 机制，每个操作都会被当成一个事务来执行，所以上面的操作总共涉及到三个事务。快照中除了记录事务版本号 TRX_ID 和操作之外，还记录了一个 bit 的 DEL 字段，用于标记是否被删除。\nINSERT、UPDATE、DELETE 操作会创建一个日志，并将事务版本号 TRX_ID 写入。DELETE 可以看成是一个特殊的 UPDATE，还会额外将 DEL 字段设置为 1。\n5.4 ReadView MVCC 维护了一个 ReadView 结构，主要包含了当前系统未提交的事务列表 TRX_IDs {TRX_ID_1, TRX_ID_2, \u0026hellip;}，还有该列表的最小值 TRX_ID_MIN 和 TRX_ID_MAX。\n在进行 SELECT 操作时，根据数据行快照的 TRX_ID 与 TRX_ID_MIN 和 TRX_ID_MAX 之间的关系，从而判断数据行快照是否可以使用：\nTRX_ID \u0026lt; TRX_ID_MIN，表示该数据行快照时在当前所有未提交事务之前进行更改的，因此可以使用。\nTRX_ID \u0026gt; TRX_ID_MAX，表示该数据行快照是在事务启动之后被更改的，因此不可使用。\nTRX_ID_MIN \u0026lt;= TRX_ID \u0026lt;= TRX_ID_MAX，需要根据隔离级别再进行判断：\n提交读：如果 TRX_ID 在 TRX_IDs 列表中，表示该数据行快照对应的事务还未提交，则该快照不可使用。否则表示已经提交，可以使用。 可重复读：都不可以使用。因为如果可以使用的话，那么其它事务也可以读到这个数据行快照并进行修改，那么当前事务再去读这个数据行得到的值就会发生改变，也就是出现了不可重复读问题。 在数据行快照不可使用的情况下，需要沿着 Undo Log 的回滚指针 ROLL_PTR 找到下一个快照，再进行上面的判断。\n5.5 快照读与当前读 5.5.1 快照读 MVCC 的 SELECT 操作是快照中的数据，不需要进行加锁操作。\n5.5.2 当前读 MVCC 其它会对数据库进行修改的操作（INSERT、UPDATE、DELETE）需要进行加锁操作，从而读取最新的数据。可以看到 MVCC 并不是完全不用加锁，而只是避免了 SELECT 的加锁操作。\n6 Next-Key Locks Next-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。\nMVCC 不能解决幻影读问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读（REPEATABLE READ）隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。\n6.1 Record Locks 锁定一个记录上的索引，而不是记录本身。\n如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。\n6.2 Gap Locks 锁定索引之间的间隙，但是不包含索引本身。\n6.3 Next-Key Locks 它是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。它锁定一个前开后闭区间。\n二、MySQL 1 索引 1.1 B+树原理 1.1.1 数据结构 B Tree 指的是 Balance Tree，也就是平衡树。平衡树是一颗查找树，并且所有叶子节点位于同一层。\nB+ Tree 是基于 B Tree 和叶子节点顺序访问指针进行实现，它具有 B Tree 的平衡性，并且通过顺序访问指针来提高区间查询的性能。\n在 B+ Tree 中，一个节点中的 key 从左到右非递减排列，如果某个指针的左右相邻 key 分别是 keyi 和 keyi+1，且不为 null，则该指针指向节点的所有 key 大于等于 keyi 且小于等于 keyi+1。\n1.1.2. 操作 进行查找操作时，首先在根节点进行二分查找，找到一个 key 所在的指针，然后递归地在指针所指向的节点进行查找。直到查找到叶子节点，然后在叶子节点上进行二分查找，找出 key 所对应的 data。\n插入删除操作会破坏平衡树的平衡性，因此在进行插入删除操作之后，需要对树进行分裂、合并、旋转等操作来维护平衡性。\n1.1.3 与红黑树的比较 红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用 B+ Tree 作为索引结构，这是因为使用 B+ 树访问磁盘数据有更高的性能。\n（一）B+ 树有更低的树高\n平衡树的树高 O(h)=O(logdN)，其中 d 为每个节点的出度。红黑树的出度为 2，而 B+ Tree 的出度一般都非常大，所以红黑树的树高 h 很明显比 B+ Tree 大非常多。\n（二）磁盘访问原理\n操作系统一般将内存和磁盘分割成固定大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I/O 就能完全载入一个节点。\n如果数据不在同一个磁盘块上，那么通常需要移动制动手臂进行寻道，而制动手臂因为其物理结构导致了移动效率低下，从而增加磁盘数据读取时间。B+ 树相对于红黑树有更低的树高，进行寻道的次数与树高成正比，在同一个磁盘块上进行访问只需要很短的磁盘旋转时间，所以 B+ 树更适合磁盘数据的读取。\n（三）磁盘预读特性\n为了减少磁盘 I/O 操作，磁盘往往不是严格按需读取，而是每次都会预读。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，并且只需要很短的磁盘旋转时间，速度会非常快。并且可以利用预读特性，相邻的节点也能够被预先载入。\n1.2 MySQL 索引 1.2.1 B+树索引 是大多数 MySQL 存储引擎的默认索引类型。\n因为不再需要进行全表扫描，只需要对树进行搜索即可，所以查找速度快很多。\n因为 B+ Tree 的有序性，所以除了用于查找，还可以用于排序和分组。\n可以指定多个列作为索引列，多个索引列共同组成键。\n适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。\nInnoDB 的 B+Tree 索引分为主索引和辅助索引。主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。\n辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。\n1.2.2 哈希索引 哈希索引能以 O(1) 时间进行查找，但是失去了有序性：\n无法用于排序与分组； 只支持精确查找，无法用于部分查找和范围查找。 InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。\n1.2.3 全文索引 MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。\n查找条件使用 MATCH AGAINST，而不是普通的 WHERE。\n全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。\nInnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。\n1.2.4 空间数据索引 MyISAM 存储引擎支持空间数据索引（R-Tree），可以用于地理数据存储。空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。\n必须使用 GIS 相关的函数来维护数据。\n1.3 索引优化 1.3.1. 独立的列 在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。\n例如下面的查询不能使用 actor_id 列的索引：\nSELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5;\r1.3.2. 多列索引 在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把 actor_id 和 film_id 设置为多列索引。\nSELECT film_id, actor_ id FROM sakila.film_actor\rWHERE actor_id = 1 AND film_id = 1;\r1.3.3. 索引列的顺序 让选择性最强的索引列放在前面。\n索引的选择性是指：不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，每个记录的区分度越高，查询效率也越高。\n例如下面显示的结果中 customer_id 的选择性比 staff_id 更高，因此最好把 customer_id 列放在多列索引的前面。\nSELECT COUNT(DISTINCT staff_id)/COUNT(*) AS staff_id_selectivity,\rCOUNT(DISTINCT customer_id)/COUNT(*) AS customer_id_selectivity,\rCOUNT(*)\rFROM payment;\rstaff_id_selectivity: 0.0001\rcustomer_id_selectivity: 0.0373\rCOUNT(*): 16049\r1.3.4. 前缀索引 对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。\n前缀长度的选取需要根据索引选择性来确定。\n1.3.5. 覆盖索引 索引包含所有需要查询的字段的值。\n具有以下优点：\n索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。 一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用（通常比较费时）。 对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。 1.4 索引的优点 大大减少了服务器需要扫描的数据行数。 帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，不需要排序和分组，也就不需要创建临时表）。 将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。 1.5 索引的使用条件 对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效； 对于中到大型的表，索引就非常有效； 但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。 1.6 MySQL 里的索引类型 普通索引 唯一索引 主键索引 组合索引 全文索引 1.7 聚簇索引和非聚簇索引 聚簇索引也叫簇类索引，是一种对磁盘上实际数据重新组织以按指定的一个或多个列的值排序。（聚簇索引就是主键的一种术语） 非聚簇索引，叶级页指向表中的记录，记录的物理顺序与逻辑顺序没有必然的联系。 或者：\n聚簇索引：规定存储在磁盘上的数据是连续的，这个连续是指物理顺序就是连续的。 非聚簇索引：既然聚簇索引是连续的，那非聚簇索引就是不连续的。索引的存储和数据的存储是分离的，也就是说找到了索引但没找到数据，需要根据索引上的值(主键)再次回表查询,非聚簇索引也叫做辅助索引。 举例：\n第一种，直接根据主键查询获取所有字段数据，此时主键是聚簇索引，因为主键对应的索引叶子节点存储了 id=1 的所有字段的值。\nselect * from student where id = 1\r第二种，根据编号查询编号和名称，编号本身是一个唯一索引，但查询的列包含了学生编号和学生名称，当命中编号索引时，该索引的节点的数据存储的是主键 ID，需要根据主键 ID 重新查询一次，所以这种查询下 no 不是聚簇索引\nselect no,name from student where no = 'test'\r第三种，我们根据编号查询编号（有人会问知道编号了还要查询？要，你可能需要验证该编号在数据库中是否存在），这种查询命中编号索引时，直接返回编号，因为所需要的数据就是该索引，不需要回表查询，这种场景下 no 是聚簇索引\nselect no from student where no = 'test'\r总结\n主键一定是聚簇索引，MySQL 的 InnoDB 中一定有主键，即便研发人员不手动设置，则会使用 unique 索引，没有 unique 索引，则会使用数据库内部的一个行的 id 来当作主键索引,其它普通索引需要区分 SQL 场景，当 SQL 查询的列就是索引本身时，我们称这种场景下该普通索引也可以叫做聚簇索引，MyisAM 引擎没有聚簇索引。\n1.8 回表查询 要说回表查询，先要从 InnoDB 的索引实现说起。InnoDB 有两大类索引，一类是聚集索引(Clustered Index)，一类是非聚簇索引(Secondary Index)。\nInnoDB 的聚集索引：InnoDB 聚集索引的叶子节点存储行记录，因此 InnoDB 必须要有且只有一个聚集索引。\n1.如果表定义了 PK(Primary Key，主键)，那么 PK 就是聚集索引。\n2.如果表没有定义 PK，则第一个 NOT NULL UNIQUE 的列就是聚集索引。\n3.否则 InnoDB 会另外创建一个隐藏的 ROWID 作为聚集索引。\n这种机制使得基于 PK 的查询速度非常快，因为直接定位的行记录。\nInnoDB 的普通索引：InnoDB 普通索引的叶子节点存储主键 ID(MyISAM 则是存储的行记录头指针)。\n回表查询：先通过非聚簇索引查询主键 ID，再通过主键 ID 查询数据。\n2 查询性能优化 2.1 Explain Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。\n比较重要的字段有：\nselect_type : 查询类型，有简单查询、联合查询、子查询等 key : 使用的索引 rows : 扫描的行数 2.2 优化数据访问 2.2.1 减少请求的数据量 只返回必要的列：最好不要使用 SELECT * 语句。 只返回必要的行：使用 LIMIT 语句来限制返回的数据。 缓存重复查询的数据：使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。 2.2.2 减少扫描的行数 最有效的方式是使用索引来覆盖查询。\n2.3 重构查询方式 2.3.1 切分大查询 一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。\n2.3.2 分解大连接查询 将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处有：\n让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。 分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。 减少锁竞争； 在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。 查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。 3 存储引擎 3.1 InnoDB 是 MySQL 默认的事务型存储引擎，只有在需要它不支持的特性时，才考虑使用其它存储引擎。\n实现了四个标准的隔离级别，默认级别是可重复读（REPEATABLE READ）。在可重复读隔离级别下，通过多版本并发控制（MVCC）+ Next-Key Locking 防止幻影读。\n主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。\n内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。\n支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。\n3.2 MyISAM 设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。\n提供了大量的特性，包括压缩表、空间数据索引等。\n不支持事务。\n不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入（CONCURRENT INSERT）。\n可以手工或者自动执行检查和修复操作，但是和事务恢复以及崩溃恢复不同，可能导致一些数据丢失，而且修复操作是非常慢的。\n如果指定了 DELAY_KEY_WRITE 选项，在每次修改执行完成时，不会立即将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作。\n3.3 区别 事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。\n并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。\n外键：InnoDB 支持外键。\n备份：InnoDB 支持在线热备份。\n崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。\n其它特性：MyISAM 支持压缩表和空间数据索引。\n4 数据类型 整型：tinyint、smallint、mediumint、int、bigint 浮点数：float、double、decimal 字符串：char、varchar 时间和日期：datetime、timestamp 5 分表 5.1 水平切分 水平切分又称为 Sharding，它是将同一个表中的记录拆分到多个结构相同的表中。\n当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓存单个数据库的压力。\n5.2 垂直切分 垂直切分是将一张表按列切分成多个表，通常是按照列的关系密集程度进行切分，也可以利用垂直切分将经常被使用的列和不经常被使用的列切分到不同的表中。\n在数据库的层面使用垂直切分将按数据库中表的密集程度部署到不同的库中，例如将原来的电商数据库垂直切分成商品数据库、用户数据库等。\n5.3 Sharding 策略 哈希取模：hash(key) % N； 范围：可以是 ID 范围也可以是时间范围； 映射表：使用单独的一个数据库来存储映射关系。 5.4 Sharding 存在的问题 5.4.1. 事务问题 使用分布式事务来解决，比如 XA 接口。\n5.4.2. 连接 可以将原来的连接分解成多个单表查询，然后在用户程序中进行连接。\n5.4.3. ID 唯一性 使用全局唯一 ID（GUID） 为每个分片指定一个 ID 范围 分布式 ID 生成器 (如 Twitter 的 Snowflake 算法) 6 复制 6.1 主从复制 主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。\nbinlog 线程 ：负责将主服务器上的数据更改写入二进制日志（Binary log）中。 I/O 线程 ：负责从主服务器上读取二进制日志，并写入从服务器的中继日志（Relay log）。 SQL 线程 ：负责读取中继日志，解析出主服务器已经执行的数据更改并在从服务器中重放（Replay）。 6.2 读写分离 主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。\n读写分离能提高性能的原因在于：\n主从服务器负责各自的读和写，极大程度缓解了锁的争用； 从服务器可以使用 MyISAM，提升查询性能以及节约系统开销； 增加冗余，提高可用性。 读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。\n三、Redis 1 概述 Redis 是速度非常快的非关系型（NoSQL）内存键值数据库，可以存储键和五种不同类型的值之间的映射。\n键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。\nRedis 支持很多特性，例如将内存中的数据持久化到硬盘中，使用复制来扩展读性能，使用分片来扩展写性能。\n2 数据类型 数据类型 可以存储的值 操作 STRING 字符串、整数或者浮点数 对整个字符串或者字符串的其中一部分执行操作\u0026lt;/br\u0026gt; 对整数和浮点数执行自增或者自减操作 LIST 列表 从两端压入或者弹出元素 \u0026lt;/br\u0026gt; 对单个或者多个元素进行修剪，\u0026lt;/br\u0026gt; 只保留一个范围内的元素 SET 无序集合 添加、获取、移除单个元素\u0026lt;/br\u0026gt; 检查一个元素是否存在于集合中\u0026lt;/br\u0026gt; 计算交集、并集、差集\u0026lt;/br\u0026gt; 从集合里面随机获取元素 HASH 包含键值对的无序散列表 添加、获取、移除单个键值对\u0026lt;/br\u0026gt; 获取所有键值对\u0026lt;/br\u0026gt; 检查某个键是否存在 ZSET 有序集合 添加、获取、删除元素\u0026lt;/br\u0026gt; 根据分值范围或者成员来获取元素\u0026lt;/br\u0026gt; 计算一个键的排名 3 数据结构 3.1 字典 dictht 是一个散列表结构，使用拉链法解决哈希冲突。\n3.2 跳跃表 是有序集合的底层实现之一。\n跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。\n在查找时，从上层指针开始查找，找到对应的区间之后再到下一层去查找。下图演示了查找 22 的过程。\n与红黑树等平衡树相比，跳跃表具有以下优点：\n插入速度非常快速，因为不需要进行旋转等操作来维护平衡性； 更容易实现； 支持无锁操作。 4 使用场景 4.1 计数器 可以对 String 进行自增自减运算，从而实现计数器功能。\nRedis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。\n4.2 缓存 将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。\n4.3 查找表 例如 DNS 记录就很适合使用 Redis 进行存储。\n查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。\n4.4 消息队列 List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息\n不过最好使用 Kafka、RabbitMQ 等消息中间件。\n4.5 会话缓存 可以使用 Redis 来统一存储多台应用服务器的会话信息。\n当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。\n4.6 分布式锁 在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。\n可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。\n4.7 其他 Set 可以实现交集、并集等操作，从而实现共同好友等功能。\nZSet 可以实现有序性操作，从而实现排行榜等功能。\n5 键的过期时间 Redis 可以为每个键设置过期时间，当键过期时，会自动删除该键。\n对于散列表这种容器，只能为整个键设置过期时间（整个散列表），而不能为键里面的单个元素设置过期时间。\n6 数据淘汰策略 可以设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略。\nRedis 具体有 6 种淘汰策略：\n策略 描述 volatile-lru 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 volatile-ttl 从已设置过期时间的数据集中挑选将要过期的数据淘汰 volatile-random 从已设置过期时间的数据集中任意选择数据淘汰 allkeys-lru 从所有数据集中挑选最近最少使用的数据淘汰 allkeys-random 从所有数据集中任意选择数据进行淘汰 noeviction 禁止驱逐数据 作为内存数据库，出于对性能和内存消耗的考虑，Redis 的淘汰算法实际实现上并非针对所有 key，而是抽样一小部分并且从中选出被淘汰的 key。\n使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用 allkeys-lru 淘汰策略，将最近最少使用的数据淘汰。\nRedis 4.0 引入了 volatile-lfu 和 allkeys-lfu 淘汰策略，LFU 策略通过统计访问频率，将访问频率最少的键值对淘汰。\n7 持久化 Redis 是内存型数据库，为了保证数据在断电后不会丢失，需要将内存中的数据持久化到硬盘上。\n7.1 RDB 将某个时间点的所有数据都存放到硬盘上。\n可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。\n如果系统发生故障，将会丢失最后一次创建快照之后的数据。\n如果数据量很大，保存快照的时间会很长。\n7.2 AOF 将写命令添加到 AOF 文件（Append Only File）的末尾。\n使用 AOF 持久化需要设置同步选项，从而确保写命令同步到磁盘文件上的时机。这是因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，然后由操作系统决定什么时候同步到磁盘。有以下同步选项：\n选项 同步频率 always 每个写命令都同步 everysec 每秒同步一次 no 让操作系统来决定何时同步 always 选项会严重减低服务器的性能； everysec 选项比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器性能几乎没有任何影响； no 选项并不能给服务器性能带来多大的提升，而且也会增加系统崩溃时数据丢失的数量。 随着服务器写请求的增多，AOF 文件会越来越大。Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。\n8 事务 一个事务包含了多个命令，服务器在执行事务期间，不会改去执行其它客户端的命令请求。\n事务中的多个命令被一次性发送给服务器，而不是一条一条发送，这种方式被称为流水线，它可以减少客户端与服务器之间的网络通信次数从而提升性能。\nRedis 最简单的事务实现方式是使用 MULTI 和 EXEC 命令将事务操作包围起来。\n9 事件 Redis 服务器是一个事件驱动程序。\n9.1 文件事件 服务器通过套接字与客户端或者其它服务器进行通信，文件事件就是对套接字操作的抽象。\nRedis 基于 Reactor 模式开发了自己的网络事件处理器，使用 I/O 多路复用程序来同时监听多个套接字，并将到达的事件传送给文件事件分派器，分派器会根据套接字产生的事件类型调用相应的事件处理器。\n9.2 时间事件 服务器有一些操作需要在给定的时间点执行，时间事件是对这类定时操作的抽象。\n时间事件又分为：\n定时事件：是让一段程序在指定的时间之内执行一次； 周期性事件：是让一段程序每隔指定时间就执行一次。 Redis 将所有时间事件都放在一个无序链表中，通过遍历整个链表查找出已到达的时间事件，并调用相应的事件处理器。\n9.3 事件的调度与执行 服务器需要不断监听文件事件的套接字才能得到待处理的文件事件，但是不能一直监听，否则时间事件无法在规定的时间内执行，因此监听时间应该根据距离现在最近的时间事件来决定。\n从事件处理的角度来看，服务器运行流程如下：\n10 复制 通过使用 slaveof host port 命令来让一个服务器成为另一个服务器的从服务器。\n一个从服务器只能有一个主服务器，并且不支持主主复制。\n10.1 连接过程 主服务器创建快照文件，发送给从服务器，并在发送期间使用缓冲区记录执行的写命令。快照文件发送完毕之后，开始向从服务器发送存储在缓冲区中的写命令；\n从服务器丢弃所有旧数据，载入主服务器发来的快照文件，之后从服务器开始接受主服务器发来的写命令；\n主服务器每执行一次写命令，就向从服务器发送相同的写命令。\n10.2 主从链 随着负载不断上升，主服务器可能无法很快地更新所有从服务器，或者重新连接和重新同步从服务器将导致系统超载。为了解决这个问题，可以创建一个中间层来分担主服务器的复制工作。中间层的服务器是最上层服务器的从服务器，又是最下层服务器的主服务器。\n11 哨兵 Sentinel（哨兵）可以监听集群中的服务器，并在主服务器进入下线状态时，自动从从服务器中选举出新的主服务器。\n12 分片 分片是将数据划分为多个部分的方法，可以将数据存储到多台机器里面，这种方法在解决某些问题时可以获得线性级别的性能提升。\n假设有 4 个 Redis 实例 R0，R1，R2，R3，还有很多表示用户的键 user:1，user:2，\u0026hellip; ，有不同的方式来选择一个指定的键存储在哪个实例中。\n最简单的方式是范围分片，例如用户 id 从 0~1000 的存储到实例 R0 中，用户 id 从 1001~2000 的存储到实例 R1 中，等等。但是这样需要维护一张映射范围表，维护操作代价很高。 还有一种方式是哈希分片，使用 CRC32 哈希函数将键转换为一个数字，再对实例数量求模就能知道应该存储的实例。 根据执行分片的位置，可以分为三种分片方式：\n客户端分片：客户端使用一致性哈希等算法决定键应当分布到哪个节点。 代理分片：将客户端请求发送到代理上，由代理转发请求到正确的节点上。 服务器分片：Redis Cluster。 13 IO 多路复用 13.1 什么是 IO 多路复用 IO 多路复用是一种同步 IO 模型，实现一个线程可以监视多个文件句柄；一旦某个文件句柄就绪，就能够通知应用程序进行相应的读写操作；没有文件句柄就绪时会阻塞应用程序，交出 cpu。多路是指网络连接，复用指的是同一个线程\n13.2 为什么需要 IO 多路复用 解决 BIO 和 NIO 的问题。\nBIO：服务端采用单线程，当 accept 一个请求后，在 recv 或 send 调用阻塞时，将无法 accept 其他请求（必须等上一个请求处 recv 或 send 完），无法处理并发。\n当服务器端采用多线程，当 accept 一个请求后，开启线程进行 recv，可以完成并发处理，但随着请求数增加需要增加系统线程，大量的线程占用很大的内存空间，并且线程切换会带来很大的开销，10000 个线程真正发生读写事件的线程数不会超过 20%，每次 accept 都开一个线程也是一种资源浪费\nNIO：服务器端当 accept 一个请求后，加入 fds 集合，每次轮询一遍 fds 集合 recv(非阻塞)数据，没有数据则立即返回错误，每次轮询所有 fd（包括没有发生读写事件的 fd）会很浪费 cpu\nIO 多路复用：服务器端采用单线程通过 select/epoll 等系统调用获取 fd 列表，遍历有事件的 fd 进行 accept/recv/send，使其能支持更多的并发连接请求\n13.3 IO 多路复用的实现方式 select poll epoll 13.4 select 缺点 单个进程所打开的 FD 是有限制的，通过 FD_SETSIZE 设置，默认 1024 每次调用 select，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大 对 socket 扫描时是线性扫描（对所有的 fds 遍历扫描），采用轮询的方法，效率较低（高并发时） 13.5 poll 与 select 对比 poll 与 select 相比，只是没有 fd 的限制，其它基本一样\n13.6 poll 缺点 每次调用 poll，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大 对 socket 扫描时是线性扫描，采用轮询的方法，效率较低（高并发时） 13.7 epoll 缺点 epoll 只能工作在 linux 下\n13.8 epoll 的应用 Redis nginx 13.9 select/poll/epoll 之间的区别 select poll epoll 数据结构 bitmap 数组 红黑树 最大连接数 1024 无上限 无上限 fd 拷贝 每次调用 select 拷贝 每次调用 poll 拷贝 fd 首次调用 epoll_ctl 拷贝，每次调用 epoll_wait 不拷贝 工作效率 轮询：O(n) 轮询：O(n) 回调：O(1) 13.10 epoll LT 和 ET 模式的区别 epoll 有 EPOLLLT 和 EPOLLET 两种触发模式，LT 是默认的模式，ET 是“高速”模式。\nLT 模式下，只要这个 fd 还有数据可读，每次 epoll_wait 都会返回它的事件，提醒用户程序去操作 ET 模式下，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论 fd 中是否还有数据可读。所以在 ET 模式下，read 一个 fd 的时候一定要把它的 buffer 读完，或者遇到 EAGAIN 错误 本文转载自：https://github.com/CyC2018/CS-Notes，用于个人复习。\n","date":"2021-05-04T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/windmills-5614160_1920.7f194ofsigg0.webp","permalink":"https://cuterwrite.top/p/database-system/","title":"计算机基础知识点总结（数据库系统 + MySQL + Redis）"},{"content":"ArrayList 源码分析 1 简介 底层：Object[]，容量能动态增长。在添加大量元素前，会先调用 ensureCapacity 来增加 ArrayList 的容量，可以减少递增再分配的次数。\nArrayList 继承了 AbstractList，实现了 List，RandomAccess，Cloneable，Serializable 等接口。\nRandomAccess：标志接口，接口体是空的，只是用来表明 ArrayList 是支持快速随机访问的。 Cloneable：能被克隆 Serializable：可序列化 1.1 ArrayList 和 Vector 的区别 底层都是 Object[]，但是 ArrayList 线程不安全，Vector 线程安全。\n1.2 ArrayList 和 LinkedList 的区别 线程安全：ArrayList 和 LinkedList 都是线程不安全的。 底层数据结构：ArrayList 是 Object[]，LinkedList 底层是双向链表。 插入和删除：ArrayList 插入和删除元素的时间复杂度受元素位置的影响，为 O(n - i)；LinkedList 的插入和删除元素的时间复杂度不受插入元素位置的影响，都近似于 O(1)，但如果在指定位置插入和删除，需要先移动到指定位置再执行操作，时间复杂度近似于 O(n)。 是否支持快速随机访问：ArrayList 支持，LinkedList 不支持。 内存空间占用：ArrayList 需要在列表末尾预留一定的容量空间，LinkedList 的每一个元素都需要多消耗 pre 和 next 指针的空间。 2 核心源码分析 2.1 属性 默认初始容量大小\nprivate static final int DEFAULT_CAPACITY = 10;\r元素个数\nprivate int size;\r存放数据的数组\ntransient Object[] elementData\r空数组\nprivate static final Object[] EMPTY_ELEMENTDATA = {};\r用于默认大小实例的共享空数组实例\nprivate static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}\r2.2 构造函数 无参\npublic ArrayList(){\rthis.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;\r}\r注意：以无参数构造方法创建 ArrayList 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量扩为 10。（用了懒汉式的单例设计模式）\n指定容量\npublic ArrayList(int initialCapacity){\rif (initialCapacity \u0026gt; 0){\rthis.elementData = new Object[initialCapacity];\r} else if (initialCapacity == 0){\rthis.elementData = EMPTY_ELEMENTDATA;\r} else {\r//抛出异常\r}\r}\r指定 collection\npublic ArrayList(Collection\u0026lt;? extends E\u0026gt; c){\relementData = c.toArray();\rif ((size = elementData.length) != 0){\rif (elementData.getClass() != Object[].class){\relementData = Arrays.copyOf(elementData, size, Object[].class);\r}\r} else {\rthis.elementData = EMPTY_ELEMENTDATA;\r}\r}\r2.3 扩容机制 2.3.1 add 方法 2.3.2 ensureCapacityInternal 方法 2.3.3 ensureExplicitCapacity 2.3.4 grow 方法 2.3.5 hugeCapacity 方法 2.4 拷贝机制 2.5 ensureCapacity 方法 ","date":"2021-04-29T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/man-5640540_1920.5mr5hqwq7xc0.webp","permalink":"https://cuterwrite.top/p/arraylist-source-code/","title":"ArrayList 源码分析"},{"content":"实用工具和网址 开发工具与实用程序 AI 工具 ChatGPT: https://chat.openai.com\rAIBUS: https://aibusx.com\r通义千问：https://tongyi.aliyun.com/\r文心一言：https://yiyan.baidu.com/\r商用图片识别图鉴：http://www.ttshitu.com/user/index.html\r万能工具箱 CyberChef：https://gchq.github.io/CyberChef/\r小白工具盒：https://www.ooopn.com/\r时间万能工具：https://www.epochconverter.com/#tools\r百川在线工具箱：https://rivers.chaitin.cn/tools/home\r在线编码与解码工具 BASE64：https://base64.supfree.net/\rMD5：https://www.zxgj.cn/g/md5\rAES/DES：http://www.fly63.com/tool/cipher/\rJWT：http://jwt.calebb.net/\rASCII：https://www.matools.com/code-convert-ascii\rUnicode：https://www.zxgj.cn/g/unicode\rUTF8：https://www.zxgj.cn/g/utf8\r字符串：https://www.zxgj.cn/g/enstring\rURL：http://tool.chinaz.com/tools/urlencode.aspx?jdfwkey=lbixzl\rSRI Hash Generator：https://www.srihash.org/\r二维码在线解码：https://cli.im/\r数据转换与计算工具 Crontab 解析和验证：https://crontab.guru/\r在线 ACSII 对照表：http://www.fly63.com/tool/ascii/\r通用进制转换工具：https://www.zxgj.cn/g/jinzhi\r在线浮点数十进制转换：http://www.binaryconvert.com/\rRGB：https://www.zxgj.cn/g/yansezhi\r时间戳：https://www.zxgj.cn/g/unix\r计量单位换算：http://www.fly63.com/tool/unitable/\r在线 JSON 解析：http://www.json.cn/\r在线 JS 代码格式化工具：https://prettier.io/playground/\rSQL 压缩/格式化工具：https://www.zxgj.cn/g/sqlformat\rJSON 和 YAML 在线转换：http://www.fly63.com/tool/jsonyaml/\rJSON 和 XML 在线转换:https://www.zxgj.cn/g/jsonxml\r人民币大小写转换：http://www.fly63.com/tool/renmingbi/\r在线画图工具 ProcessOn：https://www.processon.com/\rFigma：https://www.figma.com/\r正则表达式相关 正则表达式调试工具：https://regexr.com/\r正则表达式可视化工具：https://jex.im/regulex/\r网络与 IP 工具 IP 地址归属地查询：https://www.ip138.com/\rIP 地址查询：https://www.ipip.net/ip.html/\rHTTP 在线接口测试工具：http://www.fly63.com/php/http/\r在线编译与运行环境 C#在线编译运行（不支持 input）：https://rextester.com/\rC/C++在线编译：https://www.onlinegdb.com/\r在线编译工具套件：https://c.runoob.com/\r在线汇编转换：https://godbolt.org/\r在线 arm 汇编转换：https://armconverter.com/\r随机数与唯一标识生成 UUID：https://www.zxgj.cn/g/uuid\r随机数：https://www.zxgj.cn/g/suijishu\r开发辅助工具 在线文本与代码处理 文本差异对比工具： http://www.fly63.com/tool/textdiff/\rNginx 配置生成器：https://nginxconfig.io/\r变量命名助手：https://unbug.github.io/codelf/\r文本处理大全资源：https://gitee.com/wwwlib/funNLP?_from=gitee_search#https://github.com/wainshine/Company-Names-Corpus\r在线 markdown 编辑器：https://dillinger.io/\rmdnice markdown 排版工具：https://mdnice.com/\rmdmall markdown 排版工具：https://md.aclickall.com/\rmarkdown 目录生成器：https://ecotrust-canada.github.io/markdown-toc/\r文本工具：http://www.fly63.com/tool/textreplace/\r表格生成器：https://www.tablesgenerator.com/\r在线图床（基于 github）：https://picx.xpoet.cn/\r图壳图床：https://imgkr.com/\r免费图床：https://sm.ms/\r在线短链接工具：https://urlify.cn/\r在线字数统计：https://www.eteste.com/\rClang-format 文件生成器：https://clang-format-configurator.site/\r在线办公与文档处理 pdf 在线处理工具 1：https://smallpdf.com/cn/pdf-tools\rpdf 在线处理工具 2：https://tools.pdf24.org/zh/\r在线多媒体转换：https://cn.office-converter.com/\r在线文字识别工具：https://ocr.wdku.net/\r在线文件压缩工具：https://docsmall.com/\r网络资源与 CDN 服务 BootCDN：https://www.bootcdn.cn/\rcdnjs：https://cdnjs.com/\rjsDelivr：https://www.jsdelivr.com/\runpkg：https://unpkg.com/\rStaticfile CDN：https://staticfile.org/\r字节跳动：https://cdn.bytedance.com/\r免费云资源与服务 Upstash：https://upstash.com/\r免费 Redis，256 MB，速度快 免费 Kafka，256 MB，速度快，只有美国节点，Topic 保留 7 天，但支持多 Replication 免费 Vector 向量数据库 免费 QStash 日志聚合工具 RedisLab（免费 Redis，30 MB， 新加坡节点，速度快）：https://app.redislabs.com/\rMongoDB Atlas（512 MB，推荐 Azure HK 节点）：https://cloud.mongodb.com/\rdb4freee（免费 MySQL，仅限于学习测试，速度慢不稳定）：https://www.db4free.net/\relephantsql（免费 PostgreSQL，有香港节点，速度一般，只有 20 MB）：https://www.elephantsql.com/\rCloudAMQP（免费 RabbitMQ，有香港节点，速度一般，限制多，测试用）：https://www.cloudamqp.com/\rVercel（免费静态部署和 Serverless ）：https://vercel.com/\rNetlify（同 Vercel）：https://www.netlify.com/\rCloudflare Workers（免费 Serverless ）：https://workers.cloudflare.com/\rCloudflare Pages（免费静态部署）：https://pages.cloudflare.com/\rCloudflare Workers KV（免费 KV 数据库）：https://www.cloudflare.com/zh-cn/products/workers-kv/\rCloudflare Durable Objects：https://www.cloudflare.com/zh-cn/products/durable-objects/\rCloudflare Stream：https://www.cloudflare.com/zh-cn/products/cloudflare-stream/\r设计与创作工具 图形与图像工具 在线 PS：https://www.uupoop.com/\r在线音频剪辑：https://www.weixinsyt.com/\r在线视频剪辑：https://www.kapwing.com/\r在线视频剪辑：https://www.veed.io/zh-CN\rLOGO 在线制作：https://www.uugai.com/\r艺术字体在线生成：https://www.qt86.com/\r在线表格转换工具：https://tableconvert.com/\r在线海报设计工具：https://www.designcap.com/\r图片智能放大工具：https://bigjpg.com/\r二维码美化器：https://mh.cli.im/\r在线代码截图工具：https://carbon.now.sh/\r在线抠图工具：https://www.remove.bg/zh\rICO 图标在线生成：http://www.fly63.com/php/ico/\rSVG 转 PNG：http://www.fly63.com/tool/svg2img/\r视频转 GIF：http://www.fly63.com/tool/giftxt/\r二维码在线生成：http://www.fly63.com/tool/ewm/\r二维码在线生成：https://www.erweicaihong.cn/\r二维码在线解码：http://www.fly63.com/php/decoder/\r创意素材库 阿里巴巴矢量图标库：https://www.iconfont.cn/\rSimpleIcons：https://simpleicons.org/\rSkillIcons: https://skillicons.dev/\r表情包在线网站：https://fabiaoqing.com/\r极简壁纸：https://bz.zzzmh.cn/\rWallpaper Abyss 壁纸：https://wall.alphacoders.com\rPixabay 图片素材库：https://pixabay.com/zh\rUnsplash 图片素材库：https://unsplash.com\rPexels 图片素材库：http://www.pexels.com\rPH 图片素材库：https://pxhere.com/\rNASA 图片素材库：https://images.nasa.gov\rEmoji 大全：http://emojihomepage.com/\rMaterial Design 色系：https://www.materialui.co/colors\r中国色彩：http://zhongguose.com/\rMy Color Space（配色方案）：https://mycolor.space/\r随机动漫图片接口： https://img.r10086.com/\rhttps://api.hanximeng.com/ranimg/api.php\rhttps://img.xjh.me/random_img.php?type=bg\u0026amp;return=302\rhttps://air.moe/ranimg/api.php\rhttp://api.btstu.cn/sjbz/?lx=dongman\rhttps://api.suyanw.cn/api/comic\rhttps://api.aixiaowai.cn/api/api.php\rhttps://api.baka.fun/acgpic/?rand=719\r更优雅的 Github 徽章与标签生成器：https://shields.io/\r贡献者头像生成器：https://contrib.rocks/\rAwesome Profile：GitHub - abhisheknaiidu/awesome-github-profile-readme: 😎 A curated list of awesome GitHub Profile READMEs 📝\r文档与教程资源 Git：https://www.liaoxuefeng.com/wiki/896043488029600/900375748016320\rSVM：http://svnbook.red-bean.com/nightly/zh/index.html\rNginx 中文文档：https://www.nginx.cn/doc/index.html\rMybatis 中文文档：https://mybatis.org/mybatis-3/zh/index.html\r微信小程序官方文档：https://developers.weixin.qq.com/miniprogram/dev/framework/\rNodeJs 中文文档：http://nodejs.cn/learn\rGolang 标准库：https://studygolang.com/pkgdoc\rJava 官方文档：https://docs.oracle.com/en/java/\rMaven 官方文档：http://maven.apache.org/guides/\rSpring Boot 官方文档：https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/\rRabbitMq 官方文档：https://www.rabbitmq.com/documentation.html\rDubbo 中文文档：https://dubbo.apache.org/zh/docs/\rNetty 官方文档：https://netty.io/wiki/index.html\rElasticSearch 官方文档：https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html\rSpring Cloud 官方文档：https://spring.io/projects/spring-cloud\rDocker 官方文档：https://docs.docker.com/get-started/\rK8S 中文文档：https://kubernetes.io/zh/docs/home/\rVue.js 中文文档：https://cn.vuejs.org/v2/guide/\rReact.js 官方文档：https://reactjs.org/docs/getting-started.html\rJenkins 中文文档：https://www.jenkins.io/zh/doc/\rAnt design 官方文档：https://www.antdv.com/docs/vue/introduce-cn/\rHutool：https://www.hutool.cn/\rFlink 中文文档：https://flink-learning.org.cn/\r厦门大学大数据实验室：http://dblab.xmu.edu.cn/blog/\rFlutter 中文文档：https://flutter.cn/docs/development/tools/sdk/releases\rNeo4j 官方文档：https://neo4j.com/docs/\rCypher：https://neo4j.com/docs/cypher-manual/\rPython API：https://neo4j.com/docs/python-manual/current/\rPython 指南： Python 最佳实践：https://pythonguidecn.readthedocs.io/zh/latest/\rPython3-cookbook：https://python3-cookbook.readthedocs.io/zh_CN/latest/\rGo 语言指南： The way to Go：https://github.com/unknwon/the-way-to-go_ZH_CN/blob/master/eBook/directory.md\rGo web 编程：https://github.com/astaxie/build-web-application-with-golang/blob/master/zh/SUMMARY.md\r7 days golang：https://geektutu.com/post/gee.html\rGo 高级编程：https://chai2010.cn/advanced-go-programming-book/\rGo By Example：https://gobyexample-cn.github.io/\r清华大学人工智能技术系列报告：https://reports.aminer.cn/\rVite 官方中文文档: https://cn.vitejs.dev/\rLotus Docs 官方文档: https://lotusdocs.dev/docs/\rRust 官方文档: https://www.rust-lang.org/zh-CN/learn\rRay 分布式计算框架: https://docs.ray.io/en/latest/\r流媒体下载工具 Hotbox：https://www.hotbox.fun/\r算法与编程学习资源 算法题库与训练平台 leetcode：https://leetcode-cn.com/problemset/all/\rnowcoder：https://www.nowcoder.com\r算法学习资料 labuladong 的算法小抄：https://labuladong.gitbook.io/algo/\rMysql 索引背后的数据结构及算法原理：http://blog.codinglabs.org/articles/theory-of-mysql-index.html\r在线词典与同义词典 清华反向词典：https://wantwords.thunlp.org\r国际知名词典 韦氏词典：https://www.merriam-webster.com/\r朗文：http://www.ldoceonline.com\r麦克米伦：http://www.macmillandictionary.com\r牛津：https://www.oxfordlearnersdictionaries.com\r替换词：https://www.thesaurus.com/\rCNKI 知网词典：https://dict.cnki.net/\r计算机专业词典：http://foldoc.org/\r词源探究：https://www.etymonline.com/\r数学与科学工具 数学公式与绘图工具 Desmos：https://www.desmos.com/calculator/dxkknajdqb?lang=zh-CN\rGeoGebra：https://www.geogebra.org/graphing?lang=zh_CN\r3dplot：https://academo.org/demos/3d-surface-plotter/?expression=x\u0026amp;xRange=-50,50\u0026amp;yRange=-50,50\u0026amp;resolution=25\rMathcha：https://www.mathcha.io/editor\r在线计算器 log-calculator：https://www.calculator.net/log-calculator.html?xv=0.3\u0026amp;base=2\u0026amp;yv=\u0026amp;x=0\u0026amp;y=0\r示例代码与速查手册 代码速查表：https://devhints.io/react\rGo by example: https://gobyexample-cn.github.io/\rBash 速查：https://devhints.io/bash\r科研工具与资源 LaTeX 与绘图资源 Tex Gallery：https://github.com/sujunyan/tex-gallery#etc\rMatplotlib Gallery：https://matplotlib.org/stable/gallery/index.html\rEcharts 示例：https://echarts.apache.org/examples/en/editor.html?c=pictorialBar-dotted\r在线 Latex 公式编辑器: https://latexlive.com/\r在线实验平台 Databricks 社区（Spark 集群资源）：https://community.cloud.databricks.com/\rGoogle Colab（在线 Jupyter Notebook）：https://colab.research.google.com/notebooks/welcome.ipynb\r腾讯云 CloudStudio（在线 VS Code/Theia）：https://coding.net/products/cloudstudio\r在线课程与教育资源 计算机课程与教程 CS 自学指南：https://csdiy.wiki/\rPythonPark：https://hub.fastgit.org/Jack-Cherish/PythonPark\rUcore OS 实验指导书：https://chyyuu.gitbooks.io/ucore_os_docs/content/\rUcore Step By Step: https://1790865014.gitbook.io/ucore-step-by-step/\r学习 CSS 布局：https://zh.learnlayout.com/index.html\r计算机教育中缺失的一课：https://missing-semester-cn.github.io/\r四天学会 Rust：https://google.github.io/comprehensive-rust/\r镜像站点与学术资源检索 镜像站 阿里云镜像站：https://developer.aliyun.com/mirror\r北京大学镜像站：https://mirrors.pku.edu.cn/Mirrors\r清华大学镜像站：https://mirrors.tuna.tsinghua.edu.cn/\r电子资源检索网站 Zhelper：https://docs.zhelper.net/search/\r书享家：https://www.shuxiangjia.cn/\r中文书专用鸠摩搜书：https://www.jiumodiary.com/\r书籍知识库（Wall）：https://www.zhishikoo.com/\r苦瓜书盘：http://www.kgbook.com/\rZ-lib：https://zh.bookshome.net/\rCCF 图书馆：https://dl.ccf.org.cn\r美团技术团队：https://tech.meituan.com/\rSci-Hub：https://sci-hub.se/\r知名学术数据库与期刊网站 IEEE Xplore：https://ieeexplore.ieee.org/Xplore/home.jsp\rACM Digital Library：https://dl.acm.org/\rSpringer：https://link.springer.com/\rElsevier：https://www.sciencedirect.com/\rWeb of Science：https://www.webofscience.com/wos/alldb/basic-search\r学术会议与期刊导航 会伴: https://www.myhuiban.com/\rLetpub: https://www.letpub.com.cn/index.php?page=journalapp\rHPC 比赛 IPCC（ACM 中国国际并行计算挑战赛）：http://www.paratera-edu.org.cn/enterstep/index?id=3\rCPC（国产 CPU 并行应用挑战赛）：http://www.paratera-edu.org.cn/enterstep/index?id=6\u0026amp;groupTag=CPC\rPAC（全国并行应用挑战赛）：http://www.paratera-edu.org.cn/enterstep/index?id=5\u0026amp;groupTag=PAC\rPKU HPCGame: https://hpcgame.pku.edu.cn/\r关于就业 华为 2012 实验室（PIM、鲲鹏应用优化） 诺亚 AI 实验室（分布式 AI 部署优化） 阿里云（云上应用部署优化） 百度昆仑芯等 LeetCode 周赛如果能达到 2100 分以上，基本上大厂的机试就能满分通过。而且周赛是有排名的，能对自己当前水平有清晰的认识。并且需要许多场之后，分数才会比较稳定，所以建议越早参加越好。\n","date":"2021-04-29T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/sky-5375005_1920.4x9nxtuuftk0.webp","permalink":"https://cuterwrite.top/p/useful-tool/","title":"实用工具和网址"},{"content":"HashMap 源码分析 1 属性 初始化容量\nstatic final int DEFAULT_INITIAL_CAPACITY = 1 \u0026lt;\u0026lt; 4;\r最大容量\nstatic final int MAXIMUM_CAPACITY = 1 \u0026lt;\u0026lt; 30;\r负载因子\nstatic final float DEFAULT_LOAD_FACTOR = 0.75f;\r红黑树阈值\nstatic final int TREEIFY_THRESHOLD = 8;\r链表阈值\nstatic final int UNTREEIFY_THRESHOLD = 6;\r红黑树桶阈值\nstatic final int MIN_TREEIFY_CAPACITY = 64;\rtable 数组，用来初始化\ntransient Node\u0026lt;K,V\u0026gt;[] table;\rentrySet 存放缓存\ntransient Set\u0026lt;Map.Entry\u0026lt;K,V\u0026gt;\u0026gt; entrySet;\r桶的数量\ntransient int size\r修改次数\ntransient int modCount;\r阈值\nint threshold\r负载因子\nfloat loadFactor\r2 构造方法 HashMap()\npublic HashMap(){\rthis.loadFactor = DEFAULT_LOAD_FACTOR;\r}\rHashMap(int initialCapacity)\npublic HashMap(int initialCapacity){\rthis(int initialCapacity, DEFAULT_LOAD_FACTOR);\r}\rHashMap(int initialCapacity, float loadFactor )\npublic HashMap(int initialCapacity, float loadFactor){\rif (initialCapacity \u0026lt; 0){\r//抛出数值异常\r}\rif (initialCapacity \u0026gt; MAXIMUM_CAPACITY){\rinitialCapacity = MAXIMUM_CAPACITY;\r}\rif (loadFactor \u0026lt;= 0 || Float.isNaN(loadFactor)){\r//抛出数值异常\r}\rthis.loadFactor = loadFactor;\r//tableSizeFor，大于等于当前值的下一个 2 的幂，比如输入 17，返回 32\rthis.threshold = tableSizeFor(initialCapacity);\r}\r3 增加元素 put 方法分析\npublic V put(K key, V value){\rreturn putVal(hash(key), key, value, false, true);\r}\rhash 方法分析\nstatic int hash(Object key){\rint h;\r//key 为空返回 0，先计算 key 的 hashcode，然后与 h 无符号右移 16 位后的二进制进行异或\rreturn key == null ? 0 : (h = key.hashCode() ^ (h \u0026gt;\u0026gt;\u0026gt; 16));\r}\rputVal 方法分析\nfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict){\rNode\u0026lt;K,V\u0026gt;[] tab;\rNode\u0026lt;K,V\u0026gt; p;\rint n, i;\r/*\r* 如果 table 是否等于空或者等于 0，如果是则进行初始化\r*/\rif ((tab = table) == null || (n = tab.length) == 0){\rn = (tab = resize()).length();\r}\r/*\r* 哈希取模，i = (n - 1) \u0026amp; hash，对值的位置进行确定\r* 也是 capacity 为 2 的幂的原因，与运算效率高于%\r* capacity 为 2 的幂次时，(n - 1) \u0026amp; hash = hash % n\r* 如果 tab[i] = null，新增一个元素\r*/\rif ((p = tab[i = (n - 1) \u0026amp; hash]) == null){\rtab[i] = newNode(hash, key, value, null);\r} else {\r//说明该位置有值了\rNode\u0026lt;K,V\u0026gt; e;\rK k;\rif (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key ||\r(key != null \u0026amp;\u0026amp; key.eqauls(k)))){\r//key 值存在，无论链表还是红黑树都需要替换\re = p;\r} else if (p instanceof TreeNode){\r//如果是红黑树\re = ((TreeNode\u0026lt;K,V\u0026gt;)p).putTreeVal(this, tab, hash, key, value);\r} else {\r/*\r* 链表，遍历到最后节点然后插入；\r*/\rfor (int binCount = 0; ;binCount++){\rif ((e = p.next) == null){\rp.next = newNode(hash, key, value, null);\r//大于红黑树阈值，转换红黑树\rif (binCount \u0026gt;= TREEIFY_THRESHOLD - 1){\rtreeifyBin(tab, hash);\r}\rbreak;\r}\rif (e.hash \u0026amp;\u0026amp; hahs \u0026amp;\u0026amp; ((k = e.key) == key ||\r(key != null \u0026amp;\u0026amp; key.equals(k)))){\rbreak;\r}\rp = e;\r}\r}\r/*\r* 如果链表中重复就直接替换\r*/\rif (e != null){\rV oldValue = e.value;\rif (!onlyIfAbsent || oldValue == null){\re.value = value;\r}\rafterNodeAccess(e);\rreturn oldValue;\r}\r}\r//记录修改次数\rmodCount++;\r//如果超过 threshold，调用 resize\rif (++size \u0026gt; threshold){\rresize();\r}\rafterNodeInsertion(evict);\rreturn null;\r}\r如果定位到的数组位置没有元素，直接插入。 如果定位到的数组位置有元素，就要和插入的 key 比较，key 相同则直接覆盖，如果不相同，则判断 p 是否是 TreeNode，如果是则调用 e=((TreeNode\u0026lt;K,V)p).putTreeVal(this, tab, hash, key, value)将元素添加进入。如果不是则遍历链表插入到链表尾部。 resize 方法分析\nfinal Node\u0026lt;k,V\u0026gt;[] resize(){\rNode\u0026lt;K,V\u0026gt;[] oldTab = table;\rint oldCap = (oldTab == null) ? 0 : oldTab.length;\rint oldThr = threshold;\rint newCap, newThr = 0;\rif (oldCap \u0026gt; 0){\rif (oldCap \u0026gt;= MAXIMUM_CAPACITY){\rthreshold = Integer.MAX_VALUE;\rreturn oldTab;\r} else if ((newCap = oldCap \u0026lt;\u0026lt; 1) \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp;\roldCap \u0026gt;= DEFAULT_INITIAL_CAPACITY){\r//threshold 加倍\rnewThr = oldThr \u0026lt;\u0026lt; 1;\r}\r} else if (oldThr \u0026gt; 0){\rnewCap = oldThr;\r} else {\r//默认 Capacity 和 threshold，分别为 16 和 12\rnewCap = DEFAULT_INITIAL_CAPACITY;\rnewThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);\r}\rif (newThr == 0){\rfloat ft = (float)newCap * loadFactor;\rnewThr = (newCap \u0026lt; MAXIMUN_CAPACITY \u0026amp;\u0026amp; ft \u0026lt; (float)MAXIMUM_CAPACITY ?\r(int) ft : Integer.MAX_VALUE);\r}\rthreshold = newThr;\rNode\u0026lt;K,V\u0026gt;[] newTab = (Node\u0026lt;K,V\u0026gt;[])new Node[newCap];\rtable = newTab;\rif (oldTab != null){\r/*\r* 省略，拷贝旧的 hash 桶到 newTab\r*/\r}\r}\r4 读取元素 get 方法分析\npublic V get(Object key){\rNode\u0026lt;K,V\u0026gt; e;\rreturn (e = getNode(hash(key), key)) == null ? null : e.value;\r}\rgetNode 方法分析\nfinal Node\u0026lt;K,V\u0026gt; getNode(int hash, Object key){\rNode\u0026lt;K,V\u0026gt;[] tab;\rNode\u0026lt;K,V\u0026gt; first, e;\rint n;\rK k;\r//table 有元素\rif ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp;\r(first = tab[(n - 1) \u0026amp; hash]) != null){\r//从第一个 node 开始\rif (first.hash = hash \u0026amp;\u0026amp; ((k = first.key) == key ||\r(key != null \u0026amp;\u0026amp; key.equals(k)))){\rreturn first;\r}\r//first 的下一个 node\rif ((e = first.next) != null){\r//若是红黑树，调用红黑树查找方法\rif (first instanceof TreeNode){\rreturn ((TreeNode\u0026lt;K,V\u0026gt;)first).getTreeNode(hash, key);\r}\r//否则遍历链表查找\rdo {\rif (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key ||\r(key != null \u0026amp;\u0026amp; key.equals(k)))){\rreturn e;\r}\r} while ((e = e.next) != null);\r}\r}\r//table 没元素了，直接返回 null\rreturn null;\r}\r5 删除元素 remove 方法分析\npublic V remove(Object key){\rNode\u0026lt;K,V\u0026gt; e;\rreturn (e = removeNode(hash(key), key, null, false, true)) == null ?\rnull : e.value;\r}\rremoveNode 方法分析\nfinal Node\u0026lt;K,V\u0026gt; removeNode(int hash, Object key, Object value,\rboolean matchValue, boolean movable){\rNode\u0026lt;K,V\u0026gt;[] tab;\rNode\u0026lt;K,V\u0026gt; p;\rint n, index;\rif ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp;\r(p = tab[index = (n - 1) \u0026amp; hash]) != null){\rNode\u0026lt;K,V\u0026gt; node = null;\rNode\u0026lt;K,V\u0026gt; e;\rK k;\rV v;\rif (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key ||\r(key != null \u0026amp;\u0026amp; key.equals(k)))){\rnode = p;\r} else if ((e = p.next) != null){\r//如果是红黑树，调用红黑树查找方法\rif (p instanceof TreeNode){\rnode = ((TreeNode\u0026lt;K,V\u0026gt;)p).getTreeNode(hash,key);\r} else {\r//否则，迭代链表\rdo{\rif (e.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key ||\r(key != null \u0026amp;\u0026amp; key.equals(k)))){\rnode = e;\rbreak;\r}\rp = e;\r} while ((e = e.next) != null);\r}\r}\r//找到节点了\rif (node != null \u0026amp;\u0026amp; (!matchValue || (v = node.value) == value ||\r(value != null \u0026amp;\u0026amp; value.equals(v)))){\r//调用红黑树删除节点的方法\rif (node instanceof TreeNode){\r((TreeNode\u0026lt;K,V\u0026gt;)node).removeTreeNode(this, tab, movable);\r} else if (node == p){\r//是链表头部\rtab[index] = node.next;\r} else {\rp.next = node.next;\r}\r//修改次数\rmodCount++;\rsize--;\rafterNodeRemoval(node);\rreturn node;\r}\r}\rreturn null;\r}\r6 底层数据结构分析 6.1 JDK1.8 之前 底层：数组加链表\n基本原理：通过 key 的 hashcode 经过扰动处理得到 hash 值，然后通过(n - 1) \u0026amp; hash 判断当前元素存放的位置，如果当前位置存在元素的话，就判断该元素与要存放的元素的 hash 值以及 key 是否相同，如果相同则直接覆盖，不相同就用拉链法解决冲突。\n扰动函数：hash 方法，目的是防止一些实现比较差的 hashcode 方法，减少碰撞。\nhash 方法：\nstatic int hash(int h){\rh ^= (h \u0026gt;\u0026gt;\u0026gt; 20) ^ (h \u0026gt;\u0026gt;\u0026gt; 12);\rreturn h ^ (h \u0026gt;\u0026gt;\u0026gt; 7) ^ (h \u0026gt;\u0026gt;\u0026gt; 4);\r}\r性能较于 1.8 差，扰动次数为 4\n拉链法：将链表和数组结合，也就是创建一个链表数组 Node\u0026lt;K,V\u0026gt;[]，如果遇到哈希冲突，则将冲突的值加到链表中即可。\n6.2 JDK1.8 之后 底层：数组加链表加红黑树 基本原理：当链表长度大于阈值 8 时，会调用 treeifyBin 方法，根据 HashMap 数组决定是否转化成红黑树，只有当数组长度大于或者等于 64时，才会执行转换红黑树的操作，减减少搜索时间。否则只会进行 resize()方法对数组进行扩容。 ","date":"2021-04-27T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/mountains-6207115_1920.6ff92y51zus0.webp","permalink":"https://cuterwrite.top/p/hashmap/","title":"HashMap 源码分析"},{"content":"前端开发知识点-基础篇 1 Cookie、Session、SessionStorage 和 LocalStorage Cookie：服务器提供的一种用于维护会话状态信息的数据，通过服务器发送到浏览器，浏览器保存在本地的一种纯文本文件，当下一次有同源的请求时，将保存的 Cookie 数据添加到请求头部，发送给服务端。可以用来实现记录用户登录状态等功能。\nSession：服务器为了保存用户状态而创建的一个特殊的对象。在浏览器第一次访问服务器时，服务器会创建一个 session 对象,该对象有一个唯一的 id,即 sessionid，服务器会把 sessionid 以 cookie 的形式发送给浏览器,当浏览器再次访问服务器时,会携带 cookie 在请求头,可以通过 cookie 中的 sessionid 来访问 session 对象，可以实现在 http 无状态基础上实现用户状态管理。\nCookie 的特点：\nCookie 数据存放在客户端上。 Cookie 是非安全的，由于存在本地，有被盗取的可能。 Cookie 保存的数据不能超过 4K。 Cookie 始终在同源的 HTTP 请求中携带。 如何设置 Cookie：\n服务端：使用 Set-Cookie 的响应头部，包含 5 个属性值 expires、 domain、path、secure 和 httponly，分别代表过期时间、域名、路径、安全传输、是否禁用客户端 js 脚本访问。 客户端：通过 JS 脚本，例如 document.cookie Cookie 和 Session 和区别：\nCookie 存放在客户端，Session 存放在服务端。 Cookie 是非安全的，考虑安全应该使用 Session 访问增多时，服务器压力比较大，考虑使用 Cookie 单个 Cookie 保存的数据不能超过 4K Cookie、SessionStorage 和 LocalStorage 的区别：\nCookie 始终在同源的 HTTP 请求中携带。（即使不需要） Cookie 可以限制可访问的 path 存储大小：Cookie 存放数据不能超过 4k，WebStorage 可以达到 5M 或更大。 有效期不同：SessionStorage 只在当前浏览器窗口关闭前有效，LocalStorage 始终有效，用作持久化，Cookie 在设置的过期时间之前一直有效。 Cookie 常用场景：\n保持用户登录状态 跟踪用户行为，记录用户选项 2 Http 和 Https 的区别 HTTPS 基本原理：客户端使用 HTTPS URL 访问服务端，要去服务端建立 SSL 连接，服务端接收到客户端请求后，会将网站的证书（携带公钥）返回给客户端，客户端和服务端开始协商 SSL 连接的安全等级，也就是加密等级，然后两者通过协商一致的安全等级，建立会话密钥，然后客户端通过网站的公钥来加密会话密钥，传给网站，服务端通过自己的私钥解密出会话密钥，通过会话密钥加密与客户端的通信。\n安全性：HTTPS 是安全超文本协议，在 HTTP 基础上有更强的安全性，简单来说，HTTPS 是使用了 TLS/SSL 加密的 HTTP 协议。 申请证书：HTTPS 需要使用 CA 证书。 传输协议：HTTP 以明文形式传输数据，HTTPS 以加密形式传输数据。 端口号不同：一般来说，HTTP 协议的端口为 80，HTTPS 的端口为 443 连接方式：HTTP 的连接简单，是无状态的，HTTPS 在 HTTP 的基础上使用了 SSL 协议进行加密传输。 3 Http2.0 的特性 提升了访问速度 允许多路复用：允许同时通过单一的 HTTP/2 连接发送多重请求-响应信息。 二进制分帧：将所有的传输数据分割为更小的数据帧，并对它们进行二进制编码。 首部压缩 服务器端推送 4 OSI 七层模型 应用层：文件传输，常用协议 HTTP、STMP、FTP 表示层：数据格式化、代码转换、数据加密 会话层：建立和解除会话 传输层：提供端对端的接口，TCP/UDP 网络层：为数据包选择路由，IP/ICMP 数据链路层：传输带有地址的帧。 物理层：二进制的数据形式在物理媒体上传输数据。 5 TCP 和 UDP 的区别 TCP 是面向连接的，UDP 是无连接的，即发送数据前不需要先建立连接。 TCP 提供可靠的服务，无差错、不丢失、不重复、按序到达，UDP 尽最大努力交付。（大数据量使用 TCP） TCP 面向字节流，UDP 面向报文。（UDP 无拥塞控制，可能出现丢包） TCP 只能 1 对 1，UDP 支持 1 对 1 和 1 对多。 TCP 首部较大为 20 字节，UDP 只有 8 字节。 6 TCP 三次握手和四次挥手 TCP 三次握手：（A 为客户端，B 为服务端）\nB 处于监听，A 向 B 发送连接请求报文 SYN=1，ACK=0，选择一个初始的序号 x B 收到连接请求报文，如果同意连接，则向 A 发送连接确认报文 SYN=1，ACK=1，确认号 ack=x+1，选择初始序号 y A 收到 B 的连接确认报文，向 B 发送确认报文 ACK=1，确认号 ack=y+1，序号为 x+1 B 收到 A 的确认，连接建立。 三次握手的原因\n第三次握手防止失效的连接请求到达服务器，让服务器错误打开连接。客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务端返回的确认，导致：客户端超时重传重新建立连接，这时就会出现 2 个 SYN 连接。如果有第三次握手，客户端会忽略服务端之后发送的对滞留连接请求的确认，不进行第三次握手，因此就不会打开连接。\nTCP 四次挥手：\nA 发送连接释放报文 FIN=1，序号为 u B 收到后发出确认 ACK=1, ack=x+1, 序号为 v，此时 TCP 属于半关闭状态，A 不能发数据，B 能发数据。 B 不需要连接时，发送连接释放报文 FIN=1，ACK=1，ack=u+1，序号为 w A 收到后发出确认 ACK=1，ack=w+1，序号为 u+1，进入 TIME-WAIT 状态，等待 2MSL（最大报文存存活时间）后释放连接。 B 收到 A 的确认后释放连接。 7 HTTP 状态码 状态码按第一个数字分类，1 表示信息，2 表示成功，3 表示重定向，4 表示客户端错误，5 表示服务端错误。\n常见状态码：101 切换协议、200 成功、301 永久重定向、302 临时重定向、304 未修改、400 请求无效、401 未认证、403 拒绝执行、404 未找到资源\n200 和 304 的区别：\n200 是请求成功，一般用于 GET 和 POST 304 是未修改，所请求的资源未修改，服务器返回此状态码时，不会返回任何资源，客户端通过缓存访问资源（协商缓存）。 8 HTTP 缓存机制 强缓存：返回状态码为 200，不会向服务端发送请求，直接从缓存取资源。相关字段有 pragma、expires、cache-control（cache-control 优先级更高，pragma 优先级最高）。 协商缓存：返回状态码为 304，会向服务端发送请求，通过服务器告知缓存是否可用。相关字段有 Last-Modified/If-Modified-Since，Etag/If-None-Match 缓存流程：\n缓存是否过期：未过期，则从缓存读取（强缓存），否则下一步。 Etag 值：True，向服务端发送带 If-None-Match 的请求，否则继续判断 Last-Modified Last-Modified 为 True，向服务端发送带 If-Modified-Since 的请求，否则正式发送请求，相应后缓存协商。。（无缓存） 服务器根据 If-None-Match 和 If-Modified-Since 决策返回 200 还是 304，304 则从缓存读取（协商缓存），200 则走正常请求。 9 XSS 攻击和 CSRF 攻击 XSS 攻击：跨站脚本攻击，盗取 Cookie，在返回的 HTML 中嵌入 js 脚本，防范方法：用户输入检查（过滤特殊字符等）、设置 set-cookie 的 httponly 属性。\nCSRF 攻击：跨站请求伪造，利用 Cookie，以用户的名义发送恶意请求。防范方法：验证码、检查 HTTPS 头部的 referer、使用 token。\n10 HTTP 常见请求头 可以划分为：通用首部、请求首部、相应首部和实体首部\n通用首部：\nAccept：可接受的响应内容类型 Accept-Encoding：可接受的响应内容编码形式 Accept-Language：可接受的响应语言列表 Cache-Control：是否使用强缓存 Pragma：一般来说指，是否使用强缓存 Connection：连接类型（keep-alive） User-Agent：浏览器的身份标识字符串 Content-Length：8 进制标识的请求体的长度。 Content-Type：请求体的 MIME 类型，用于 POST 和 GET Host：服务器的域名及监听端口号，80 则可以省略 请求首部：\ncookie Etag/If-None-Match Last-Modified/if-Modified-Since 等 响应首部：\nset-cookie 等 11 HTTP 常见请求方法 get：请求资源 head：请求 header post：建立或修改资源。 put：取代资源 delete：删除指定资源 connect： options：允许客户端查看服务端的性能 trace：回显服务器收到的请求，用于测试和诊断 patch：对 put 的补充，对已有资源局部更新。 12 输入 URL 到显示页面的过程 首先需要找到这个 url 域名的服务器 ip，首先会寻找缓存中的记录，如果没有则查找本地的 hosts 文件是否有记录，如果没有则进行下一步。 DNS 解析：首先，客户端通过发送 DHCP 请求报文获取网关路由器的 IP 地址，然后通过 ARP 协议获取网关路由器的 MAC 地址，接着向网关路由器发送 DNS 查询报文，到达 DNS 服务器后，在 DNS 数据库中查询域名解析后的 IP 地址。 浏览器根据得到的 IP 地址及相应的端口号，构造一个 HTTP 请求报文，并将这个 HTTP 请求封装在一个 TCP 包中，依次经过传输层、网络层、数据链路层、物理层到达服务端，服务端解析这个请求来作出响应给浏览器。 浏览器解析响应内容并渲染页面，结束连接。（DOM 树和 CSSOM 树） 13 Websocket WebSocket 是 HTML5 中的协议，支持持久连续，http 协议不支持持久性连接。Http1.0 和 HTTP1.1 都不支持持久性的链接，HTTP1.1 中的 keep-alive，将多个 http 请求合并为 1 个。\nHTTP 的生命周期通过 Request 来界定，也就是 Request 一个 Response，那么在 Http1.0 协议中，这次 Http 请求就结束了。在 Http1.1 中进行了改进，有一个 connection：Keep-alive，也就是说，在一个 Http 连接中，可以发送多个 Request，接收多个 Response。但是必须记住，在 Http 中一个 Request 只能对应有一个 Response，而且这个 Response 是被动的，不能主动发起。\nWebSocket 是基于 Http 协议的，或者说借用了 Http 协议来完成一部分握手，在握手阶段与 Http 是相同的。有 2 个相关的请求头，upgrade，connection。\nupgrade:websocket\nconnection:upgrade\n14 BOM 对象 浏览器对象，location、history 和 navigator\n常用属性和方法：\nhistory：go、back、forward navigator：userAgent、cookieEnabled location： get 类型：href、search、hash、host、hostname、pathname、port、protocal set 类型：assgin（设置 url）、replace（设置 url，并且在 history 中移除）、reload 15 CORS 跨域请求的方式 cors：跨域资源共享，客服了 AJAX 只能同源使用的限制。\n只要同时满足以下两大条件，就属于简单请求\n请求方法为 head、get、post 之一 请求头只有：Accepet、Accpet-Language、Content-Language、Last-Event-ID、Content-Type 这五种，并且 Content-type 只有 application/x-www-form-unlencoded、multipart/form-data、text/plain 这三种。 对于简单请求，浏览器直接发出 CORS 请求，在请求头加上 Origin 字段，用来说明来自哪个源，服务器根据这个值决定是否同意此次请求，同意则返回响应，响应头多出几个字段（以Access-Control-开头），否则返回一个正常的 HTTP 响应，但请求头不包含 Access-Control-Allow-Origin 字段，抛出一个错误。\nwithCredentials 属性\nCORS 请求默认不发送 Cookie 和 HTTP 认证信息，如果需要发送，一方面需要服务器同意，指定 Access-Control-Allow-Credentials 为 True，另一方面 ajax 请求要设置 withCredentials 属性为 true。此外，如果要发送 Cookie，Access-Control-Allow-Origin 就不能设置为星号，必须指定明确的、与明确网页一致的域名。同时，Cookie 依然遵循同源政策。\n预检请求\n对于复杂请求的 CORS 请求，会在正式通信前，增加一次 HTTP 查询请求，称为预检请求，浏览器先询问服务器，如果同意才会发出正式的 XMLHttpRequest 请求，否则就报错。\n预检请求用的请求方法为 OPTIONS，请求头有 Origin、Access-Control-Request-Method、Access-Control-Request-Headers 这三个字段。\n一旦服务器通过了预检请求，以后每次浏览器正常的 CORS 请求，都跟正常请求一样，会有一个 OrIgin 请求头字段，服务器响应请求头会带有 Access-Control-Allow-Origin。\n16 CSS 盒模型 标准盒模型：box-sizing：content-box；width=content IE 盒模型：box-sizing：border-box；width=content+border+padding box-sizing：padding-box；width=content+padding 17 link 标签和 import 标签的区别 link 属于 html 标签，@import 是 css 提供的。 加载时机：页面加载时，link 会同时加载，而@import 引用的 css 会等到页面加载结束后加载。 兼容性：@import 只有 IE5 以上才支持。 优先级：link 大于@import 18 transition 和 animation 的区别 大部分属性相同，都是随时间改变元素的属性值。 transition 需要触发一个事件才能改变属性，而 animation 不需要触发任何事件。 transition 为 2 帧，animation 可以一帧一帧。 19 Flex 布局 弹性布局，用来为盒状模型提供最大的灵活性。\n划分：容器属性和元素属性\n容器属性：\nflex-direction：主轴方向 flex-wrap：换行规则 flew-flow：上面两者结合。 justify-content：主轴对齐方式 align-items：交叉轴对齐方式 元素属性：\norder：排列顺序 flex-glow：放大比例 flex-shrink：缩小比例 flex-basis：占据空间 flex：上面三者的缩写 align-self：允许元素与其它项目的对齐方式不一样，默认 auto，继承父元素的 align-item 20 BFC BFC：块级格式化上下文，用于清除浮动，防止 margin 重叠等\nBFC 是页面上的一个独立容器，子元素不会影响到外面，计算 BFC 的高度时，浮动元素也会参与计算。\n会生成 BFC 的元素：\nfloat 不为 none 的元素 position 为 fixed 和 absolute 的元素 display 为 inline-block、table-cell、table-caption、flex、inline-flex 的元素。 overflow 不为 visible 的元素 21 块元素和行元素 块元素：独占一行，并且有自动填满父元素，可以设置 margin 和 padding 以及高度和宽度 行元素：不会独占一行，width 和 height 会失效，并且在垂直方向的 padding 和 margin 会失效。 22 HTML5 和 CSS3 的新元素 HTML5 新增元素： 新标签：8 个语义标签（header、section、footer、aside、nav、main、article、figure）、mark 高亮、progress 进度、新表单控件(calendar、data、time、email、url、search)、新的 input 类型（color、date、datetime、datetime-local、email） canvas 绘图，支持内联 SVG，支持 MathML 多媒体：audio、video、source、embed track 本地离线存储：manifest 配置文件 web 存储：localStorage、SessionStorage 其它：web worker、websocket CSS3 新元素 边框： border-radius、box-shadow 背景：background-size、background-origin 文本效果：text-shadow、word-wrap、word-break 等 2D/3D 转换：transform 动画：animation 23 重绘和重排 DOM 的变化影响到了预算内宿的几何属性比如宽高，浏览器重新计算元素的几何属性，其他元素的几何属性也会受到影响，浏览器需要重新构造渲染树，这个过程称之为重排，浏览器将受到影响的部分重新绘制在屏幕上的过程称为重绘。\n重绘和重排的原因：\n添加或删除可见的 DOM 元素 元素尺寸位置的改变 浏览器页面初始化 浏览器窗口大小发生改变。 重排一定导致重绘，重绘不一定导致重排。\n减少重排，提高性能的方法：\n元素的多次样式修改合并成一次修改。 如需进行对 DOM 节点进行多次操作，先将其脱离文本流之后再进行多次操作。 table 布局的渲染与普通 DOM 节点的操作相比，性能消耗更大，如果可以，尽量减少 table 布局的使用。 缓存常用的布局信息。 24 闭包 闭包：当一个嵌套的内部函数引用了外部函数的变量或者函数时，外部函数在执行时就产生了闭包。\n典型的闭包：\n将函数作为灵一个函数的返回值 将函数作为实参传给另一个函数调用 闭包特点：函数嵌套函数，内部函数引用外部函数的变量。\n闭包的作用：\n延长外部函数局部变量的生命周期，可以用于实现计数器。 可以形成变量的局部作用域，实现函数封装。 闭包的缺点：函数定义的变量和数据会一直存在内存函数中，不会被及时释放，容易导致内存泄漏。\n25 类的创建和继承 类的创建：new 一个 function，在这个 function 中的 prototype 里面添加属性和方法\nfunction Animal(name){\rthis.name = name || 'Animal';\r//实例方法\rthis.sleep = function(){\rconsole.log(this.name + \u0026quot;正在睡觉!\u0026quot;);\r}\r//原型方法\rAnimal.prototype.eat = function(food){\rconsole.log(this.name + \u0026quot;正在吃\u0026quot; + food);\r};\r}\r类的继承：4 种方式\n原型链继承（new 一个空对象，空对象指向 Animal，缺点是无法多继承）\nfunction Cat(){\rCat.prototype = new Animal();\rCat.prototype.name = 'Cat';\r}\r构造继承（使用父亲的构造函数来增强子类实例，等于复制父亲的实例属性）\nfunction Cat(name){\rAnimal.call(this);\rthis.name = name || 'Tom';\r}\r优点：可以多继承\n缺点：只能继承实例属性和方法\n实例集成和拷贝继承：\n实例继承：为父亲实例添加新特性，作为子类实例返回 拷贝继承：拷贝父亲元素上的属性和方法 组合继承：构造继承和原型链继承的组合\nfunction Cat(name){\rAnimal.call(this);\rthis.name = name || 'Tom';\r}\rCat.prototype = new Animal();\rCat.prototype.constructor = Cat;\r通过调用父类构造，继承父亲的属性并保留传参的优点，然后通过将父亲实例作为子类原型，实现函数复用。\n特点：可以继承实例属性，也可以继承原型属性\n缺点：调用了两次父类构造函数，生成了两份实例\n寄生组合继承：通过寄生方式，砍掉父亲的实例属性\nfunction Cat(name){\rAnimal.call(this);\rthis.name = name || 'Tom';\r}\rvar Super = function(){};\rSuper.prototype = Animal.prototype;\rCat.prototype = new Super();\r最常用的方法：\nCat.prototype = Object.create(Animal.prototype);\r26 promise、generator、async/await promise：CommonJS 工作组提出的一种规范，目的是为异步编程提供统一接口。每一个异步任务返回一个 Promise 对象，该对象有一个 then 方法，允许指定回调函数。有三个状态：等待（pending）、已完成（resolved，又称 fulfilled）、已拒绝（rejected）。promise 必须实现 then 方法（可以说，then 就是 promise 的核心），而且 then 必须返回一个 promise，同一个 promise 的 then 可以调用多次，并且回调的执行顺序跟它们被定义时的顺序一致。then 方法接受两个参数，第一个参数是成功时的回调，在 promise 由“等待”态转换到“完成”态时调用，另一个是失败时的回调，在 promise 由“等待”态转换到“拒绝”态时调用。同时，then 可以接受另一个 promise 传入，也接受一个“类 then”的对象或方法，即 thenable 对象。\n使用举例：\nfunc(){\rreturn new Promise((resolve,reject)=\u0026gt;{\rwork().then(res=\u0026gt;{\rthis.data = res.data;\rresolve();\r}).catch(error=\u0026gt;{\rreject(error);\r})\r})\r}\rpromise 的用处\n解决了回调函数的回调地狱问题，有时候我们的请求需要上一个请求返回的结果，会造成相互间回调函数的嵌套，使得代码的可读性和维护性很低。 让代码变得扁平，可读性更好，then 返回一个 promise，可以把 then 串起来，then 返回的 promise 装载了由调用返回的值。 在异步回调中，函数的执行栈与原函数分离开，导致外部无法抓住异常。在 promise 中我们可以使用 reject 捕获失败情况，和 catch 捕获执行异常。 promise 只不过是一种更良好的编程风格。 promise 的缺点：\n不设置回调函数，promise 内部抛出的错误，无法返回到外部。 处于 pending 状态时，无法得知进展到哪一个阶段。 async 和 await：\nasync 函数返回一个 promise 对象，在没有 await 的情况下执行 async 函数，它会立即返回一个 promise 对象，并且，绝对不会注意后面语句的执行，await 关键字只能用在 aync 定义的函数内； await 可以用于等待一个 async 函数的返回值，如果它等到的是一个 Promise 对象，await 就忙起来了，它会阻塞后面的代码，等着 Promise 对象 resolve，然后得到 resolve 的值，作为 await 表达式的运算结果。async/await 使得异步代码看起来像同步代码，使代码简洁，可读性更好，避免嵌套。 27 事件流 事件流：从页面接受事件的顺序，DOM2 级事件流包括下面几个阶段\n事件捕获阶段 处于目标阶段 事件冒泡阶段 addEventListener：DOM2 级事件新增的指定事件处理程序的操作，这个方法接受三个参数，要处理的事件名，作为事件处理程序的函数和一个布尔值（true 则在捕获阶段调用事件处理程序，否则在冒泡阶段调用）。IE 只支持事件冒泡。\naddEventListener 示例：\nvar op = document.getElementById(\u0026quot;id\u0026quot;);\rop.addEventListener('click', function(e){\r//do something\r}, false);\r28 事件委托（代理） 事件委托：事件委托指的是，不在事件的发生地（直接 dom）上设置监听函数，而是在其父元素上设置监听函数，通过事件冒泡，父元素可以监听到子元素上事件的触发，通过判断事件发生元素 DOM 的类型，来做出不同的响应。\n举例：最经典的就是 ul 和 li 标签的事件监听，比如我们在添加事件时候，采用事件委托机制，不会在 li 标签上直接添加，而是在 ul 父元素上添加。\n优点：比较合适动态元素的绑定，新添加的子元素也会有监听函数，也可以有事件触发机制。\n29 事件循环 事务队列中，在每一次事件循环中，宏任务只会提取一个执行，而微任务会一直提取，直到微任务队列为空为止。\n也就是说如果某个微任务任务被推入到执行中，那么当主线程任务执行完成后，会循环调用该队列任务中的下一个任务来执行，直到该任务队列到最后一个任务为止。而事件循环每次只会入栈一个宏任务,主线程执行完成该任务后又会检查微任务队列并完成里面的所有任务后再执行宏任务队列的任务。\n宏任务：setTimeOut、setInterval、setImmediate、IO、UI 渲染、主 JS、requestAnimationFrame 等。\n微任务：process.nextTick、promise.then()，Object.observe()等\n30 图片懒加载和预加载 懒加载：迟缓加载甚至不加载。（减少服务器的压力）\n实现方法：图片地址不放在 src，而是放在其它属性，页面加载后，根据 scrollTop 判断图片是否在用户视野内，如果在，则将 data-original 属性中的值放在 src。在滚动事件中重复判断图片是否进入视野。 预加载：提前加载图片，当用户需要查看时直接从本地缓存中渲染。（会增大服务器的压力）\nCSS 实现：background：url()\nJS 实现：\nconst img = new Image();\rimg.src = 'xxx';\r31 new 操作符 new 操作符新建了一个空对象，这个对象原型指向构造函数的 prototype，执行构造函数后返回这个对象\n实现一个 new 的方法：\nfunction Animal(){...}\r//var a = new Animal();\rfunction myNew(){\rlet obj = {}\rlet Constructor = [].shifit.apply(arguments);\r//绑定原型\robj.__proto__ = Constructor.prototype;\r//调用构造函数\rlet res = Constructor.apply(obj, arguments);\rreturn typeof res === 'object' ? res : obj;\r}\r32 bind、apply、call 的区别 apply 和 call 用来改变函数的 this 指向，它们两个函数的第一个参数都是一样的，表示要改变指向的那个对象，第二个参数，apply 中是数组，而 call 是 arg1,arg2\u0026hellip;的形式。 bind 改变 this 作用域会返回一个新的函数，这个函数不会立即执行。 33 节流和防抖 防抖：持续拖动滚动条，只要不停止触发，就永远不会有输出。短时间内触发的事件，在某个时间期限内，函数只执行一次。\nfunction debounce(func, wait){\rvar timeout;\rreturn function(){\rclearTimeout(timeout);\rtimeout = setTimeout(func,wait);\r}\r}\r节流：持续拖动滚动条，每间隔一段时间，就会输出反馈。相当于技能冷却，执行之后，函数会失效一段时间，冷却之后，又会恢复，设置一个状态位，判断是否处于工作状态。（在防抖基础上，到达指定事件必须输出）\nfunction throttle(func, wait, mustRun){\rvar timeout, start = new Data();\rreturn function(){\rvar context = this, args = arguments;\rvar cur = new Data();\rclearTimeout(timeout);\rif (cur - start \u0026gt;= mustRun){\rfunc.apply(context, args);\rstart = cur;\r} else {\rtimeout = setTimeout(func, wait);\r}\r}\r}\r34 深拷贝 简单深拷贝：JSON 序列化和反序列化\nfunction deepCopy(obj){\rlet __obj = JSON.stringify(obj);\rreturn JSON.parse(_obj);\r}\r递归方法：\nfunction deepCopy(obj){\rlet res;\rif (typeof obj === 'Object'){\rif (Array.isArray(obj)){\rres = []\rfor (let i in obj){\rres.push(deepCopy(obj[i]))\r}\r} else if (obj == null){\rres = null;\r} else if (obj.constructor === 'RegExp'){\rres = obj;\r} else {\rres = {}\rfor (let i in obj){\rres[i] = deepCopy(obj[i])\r}\r}\r} else {\rres = obj;\r}\rreturn res;\r}\r35 对象属性改变监听-Proxy 示例\nvar user = new Proxy({}, {\rset:function(target,key,value,receiver){\r}\r})\r36 变量提升和暂时性死区 变量提升：var 定义变量，变量可以在声明前使用，值为 undefined；let 不会出现这个情况。\n暂时性死区 TDZ：只要一进入当前作用域，所要使用的变量就已经存在了，但是不可获取，只有等待变量声明的那一行代码出现，才可以获取和使用该变量。\n只要块级作用域内存在 let 和 const 命令，它所声明的变量就会绑定这个区域，不再受外部影响。\n37 箭头函数 基本语法\nlet func = value=\u0026gt;value;\r//aka\rlet func = function(value){\rreturn value;\r};\r与普通函数的区别\n箭头函数没有 this，如果普通函数包含箭头函数，那么 this 访问的就是最近一层普通函数的 this 箭头函数是匿名函数，不能作为构造函数，不能使用 new 箭头函数没有自己的 arguments 参数，虽然有 name 属性但是是空字符串，用\u0026hellip;扩展运算符。 箭头函数通过 call()或 apply()方法调用一个函数时，只传入了一个参数，对 this 并没有影响。 箭头函数没有原型属性 prototype 38 原型链 原型：prototype，是一个对象，作用是共享属性和方法\n原型链：原型与原型层层连接的过程即为原型链\n假设 B 继承了 A，b 是 B 的实例，那么就有以下关系：\n（1）\nb.__proto__ = B.prototype\r（2）B.prototype.constructor = B，A.prototype.constructor = A\n（3）\nB.__proto__ = A\r（4）\nB.prototype.__proto__ = A.prototype\r39 ES6 新特性 let（解决了变量提升）、 const 常量，块级作用域（暂时性死区）。 模板字符串：“xxx${}” 箭头函数 对象，数组解构赋值 for in 和 for of class 类 extend 类继承 40 垂直居中的方法 margin：auto，left、right、top、bottom 全设为 0 display：flex，align-items:center，justify-content:center; 41 前端性能优化 降低请求量：合并资源、减少 HTTP 请求数、minify/gzip 压缩，webP，懒加载 加快请求速度：预解析 DNS、减少域名数、并行加载、CDN 分发 缓存：HTTP 协议缓存请求、离线缓存 manifest、离线数据缓存 localStorage 渲染：JS/CSS 优化，加载顺序，服务端渲染，pipeline 42 get 和 post 的区别 get 参数通过 url 传递，post 放在 request body 中 get 请求在 url 中传递的参数有长度限制，post 没有 get 参数暴露在 url，不安全。 get 请求只能进行 url 编码，post 支持多种编码方式 get 请求浏览器会主动缓存。 get 请求参数会被完整保留在浏览历史记录。 get 用来获取资源，post 用来增加或更新资源。 43 web worker 在 HTML 页面中，如果在执行脚本时，页面的状态是不可响应的，直到脚本执行完成后，页面才变成可响应。web worker 是运行在后台的 js，独立于其他脚本，不会影响页面你的性能。并且通过 postMessage 将结果回传到主线程。这样在进行复杂操作的时候，就不会阻塞主线程了。\n如何创建 web worker：\n检测浏览器对于 web worker 的支持性\n创建 web worker 文件（js，回传函数等）\n创建 web worker 对象\n44 浮动清除 overflow:hidden/auto 给浮动的元素的容器添加浮动 45 CSS 选择器 ID 选择器、Class 选择器、标签选择器、伪元素选择器、伪类选择器\n优先级：\n引入了同类的选择器：排在后面的样式属性优先 引入了不同的选择器：id\u0026gt;class\u0026gt;标签 ","date":"2021-04-27T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/lake-5538757_1920.2fnhpht9u2vw.webp","permalink":"https://cuterwrite.top/p/web-development-1/","title":"前端开发知识点复习-基础篇"},{"content":"一、操作系统 1、进程与线程的区别 进程是对运行时程序的封装，是系统进行资源调度和分配的的基本单位，实现了操作系统的并发；\n线程是进程的子任务，是 CPU 调度和分派的基本单位，用于保证程序的 实时性，实现进程内部的并发；\n一个程序至少有一个进程，一个进程至少有一个线程，线程依赖于进程而存在；\n进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。\n2、进程间的通信的几种方式 管道（pipe）及命名管道（named pipe）：管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信； 信号（signal）：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生； 消息队列：消息队列是消息的链接表，它克服了上两种通信方式中信号量有限的缺点，具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息； 共享内存：可以说这是最有用的进程间通信方式。它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等； 信号量：主要作为进程之间及同一种进程的不同线程之间得同步和互斥手段； 套接字：这是一种更为一般得进程间通信机制，它可用于网络中不同机器之间的进程间通信，应用非常广泛。 3、线程同步的方式 互斥量 Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问 信号量 Semphare：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量 事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作 4、进程同步的方式 临界区：对临界资源进行访问的那段代码称为临界区。为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。 同步与互斥 信号量 管程：有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。管程引入了 条件变量 以及相关的操作：wait() 和 signal() 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。 5、死锁 5.1、死锁的定义 在两个或者多个并发进程中，如果每个进程持有某种资源而又等待其它进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。通俗的讲，就是两个或多个进程无限期的阻塞、相互等待的一种状态。\n5.2、死锁必要条件 互斥：每个资源要么已经分配给了一个进程，要么就是可用的。 占有和等待：已经得到了某个资源的进程可以再请求新的资源。 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。 5.3、死锁处理 鸵鸟策略：把头埋在沙子里，假装根本没发生问题。因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。\n死锁检测与死锁恢复：不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。\n每种类型一个资源的死锁检测：通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。 每种类型多个资源的死锁检测：每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。 寻找一个没有标记的进程 Pi，它所请求的资源小于等于 A。 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。 如果没有这样一个进程，算法终止。 死锁恢复：在程序运行之前预防发生死锁。\n破坏互斥条件 破坏占有和等待条件 破坏不可抢占条件 破坏环路等待条件 死锁避免：在程序运行时避免发生死锁。\n安全状态：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。\n银行家算法：检查一个状态是否安全的算法如下：\n查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。 重复以上两步，直到所有进程都标记为终止，则状态是安全的。 如果一个状态不是安全的，需要拒绝进入这个状态。\n6、进程的状态 ready running waiting 只有 ready 和 running 可以相互转换，其它都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。 阻塞状态是缺少需要的资源从 running 状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从 running 变成 ready。 7、进程调度算法 先来先服务 first-come first-serverd（FCFS）：非抢占式的调度算法，按照请求的顺序进行调度。有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。 短作业优先 shortest job first（SJF）：非抢占式的调度算法，按估计运行时间最短的顺序进行调度。长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。 最短剩余时间优先 shortest remaining time next（SRTN）：最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。 时间片轮转：将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。 优先级调度：每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。 多级反馈队列：可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。 8、虚拟内存 虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。\n为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。\n9、页面置换算法 OPT LRU LFU FIFO 10、分页与分段的区别 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。\n地址空间的维度：分页是一维地址空间，分段是二维的。\n大小是否可以改变：页的大小不可变，段的大小可以动态改变。\n出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。\n二、计算机网络 1、计算机网络体系结构 1.1、五层协议 应用层 运输层 网络层 数据链路层 物理层 1.2、OSI 七层协议 应用层：为特定应用程序提供数据传输服务 表示层：数据压缩、加密以及数据描述 会话层：建立和管理回话 运输层：提供的是进程间的通用数据传输服务。 网络层：为主机间提供数据传输服务 数据链路层：主机之间可以有很多链路，链路层协议就是为同一链路的节点提供服务。数据链路层把网络层传来的分组封装成帧。 物理层：尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异。 2、UDP 和 TCP 的特点 用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。 传输控制协议 TCP（Transmission Control Protocol）是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。 3、UDP 首部格式 首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。\n4、TCP 首部格式 序号 ：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。 确认号 ：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。 数据偏移 ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。 确认 ACK ：当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。 同步 SYN ：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。 终止 FIN ：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。 窗口 ：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。 5、TCP 三次握手 假设 A 为客户端，B 为服务器端。\n首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。 A 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。 B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。 A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。 B 收到 A 的确认后，连接建立。 三次握手的原因\n第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。\n客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。\n6、TCP 四次挥手 以下描述不讨论序号和确认号，因为序号和确认号的规则比较简单。并且不讨论 ACK，因为 ACK 在连接建立之后都为 1。\nA 发送连接释放报文，FIN=1。\nB 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。\n当 B 不再需要连接时，发送连接释放报文，FIN=1。\nA 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接。\nB 收到 A 的确认后释放连接。\n四次挥手的原因\n客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。\nTIME_WAIT\n客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由：\n确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。 7、TCP 可靠传输 TCP 使用超时重传来实现可靠传输：如果一个已经发送的报文段在超时时间内没有收到确认，那么就重传这个报文段。\n8、TCP 滑动窗口 窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。\n发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。\n接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。\n9、TCP 流量控制 流量控制是为了控制发送方发送速率，保证接收方来得及接收。\n接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。\n10、TCP 拥塞控制 如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。\nTCP 主要通过四个算法来进行拥塞控制：慢开始、拥塞避免、快重传、快恢复。\n发送方需要维护一个叫做拥塞窗口（cwnd）的状态变量，注意拥塞窗口与发送方窗口的区别：拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口。\n为了便于讨论，做如下假设：\n接收方有足够大的接收缓存，因此不会发生流量控制； 虽然 TCP 的窗口基于字节，但是这里设窗口的大小单位为报文段。 1、慢开始与拥塞避免\n发送的最初执行慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 \u0026hellip;\n注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh，当 cwnd \u0026gt;= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。\n如果出现了超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始。\n2、快重传与快恢复\n在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。\n在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M2，则 M3 丢失，立即重传 M3。\n在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。\n慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。\n11、域名系统 DNS 是一个分布式数据库，提供了主机名和 IP 地址之间相互转换的服务。这里的分布式数据库是指，每个站点只保留它自己的那部分数据。\n域名具有层次结构，从上到下依次为：根域名、顶级域名、二级域名。\nDNS 可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。大多数情况下 DNS 使用 UDP 进行传输，这就要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。在两种情况下会使用 TCP 进行传输：\n如果返回的响应超过的 512 字节（UDP 最大只支持 512 字节的数据）。 区域传送（区域传送是主域名服务器向辅助域名服务器传送变化的那部分数据）。 12、FTP 协议 FTP 使用 TCP 进行连接，它需要两个连接来传送一个文件：\n控制连接：服务器打开端口号 21 等待客户端的连接，客户端主动建立连接后，使用这个连接将客户端的命令传送给服务器，并传回服务器的应答。 数据连接：用来传送一个文件数据。 根据数据连接是否是服务器端主动建立，FTP 有主动和被动两种模式：\n主动模式：服务器端主动建立数据连接，其中服务器端的端口号为 20，客户端的端口号随机，但是必须大于 1024，因为 0~1023 是熟知端口号。 被动模式：客户端主动建立数据连接，其中客户端的端口号由客户端自己指定，服务器端的端口号随机。 主动模式要求客户端开放端口号给服务器端，需要去配置客户端的防火墙。被动模式只需要服务器端开放端口号即可，无需客户端配置防火墙。但是被动模式会导致服务器端的安全性减弱，因为开放了过多的端口号。\n13、DHCP 协议 DHCP (Dynamic Host Configuration Protocol) 提供了即插即用的连网方式，用户不再需要手动配置 IP 地址等信息。\nDHCP 配置的内容不仅是 IP 地址，还包括子网掩码、网关 IP 地址。\nDHCP 工作过程如下：\n客户端发送 Discover 报文，该报文的目的地址为 255.255.255.255:67，源地址为 0.0.0.0:68，被放入 UDP 中，该报文被广播到同一个子网的所有主机上。如果客户端和 DHCP 服务器不在同一个子网，就需要使用中继代理。 DHCP 服务器收到 Discover 报文之后，发送 Offer 报文给客户端，该报文包含了客户端所需要的信息。因为客户端可能收到多个 DHCP 服务器提供的信息，因此客户端需要进行选择。 如果客户端选择了某个 DHCP 服务器提供的信息，那么就发送 Request 报文给该 DHCP 服务器。 DHCP 服务器发送 Ack 报文，表示客户端此时可以使用提供给它的信息。 14、SSH 协议 TELNET 用于登录到远程主机上，并且远程主机上的输出也会返回。\nTELNET 可以适应许多计算机和操作系统的差异，例如不同操作系统系统的换行符定义。\n15、SMTP 协议 一个电子邮件系统由三部分组成：用户代理、邮件服务器以及邮件协议。\n邮件协议包含发送协议和读取协议，发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。\nSMTP 只能发送 ASCII 码，而互联网邮件扩充 MIME 可以发送二进制文件。MIME 并没有改动或者取代 SMTP，而是增加邮件主体的结构，定义了非 ASCII 码的编码规则。\nPOP3 的特点是只要用户从服务器上读取了邮件，就把该邮件删除。但最新版本的 POP3 可以不删除邮件。\nIMAP 协议中客户端和服务器上的邮件保持同步，如果不手动删除邮件，那么服务器上的邮件也不会被删除。IMAP 这种做法可以让用户随时随地去访问服务器上的邮件。\n16、Web 页面请求过程 16.1. DHCP 配置主机信息 假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。 主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。 该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。 该数据报则被放置在 MAC 帧中，该帧具有目的地址 FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:FF，将广播到与交换机连接的所有设备。 连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。 该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。 主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。 16.2. ARP 解析 MAC 地址 主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。\n主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。\n该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。\n该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。\nDHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。\n主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址（FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。\n网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。\n16.3. DNS 解析域名 知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。\n网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。\n因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。\n到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。\n找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。\n16.4. HTTP 请求页面 有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。 在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。 HTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。 连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。 HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。 浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。 本文转载自：https://github.com/CyC2018/CS-Notes，用于个人复习。\n","date":"2021-04-22T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/rocky-coast-5059912_1920.5upaeily96k0.webp","permalink":"https://cuterwrite.top/p/interview-help/","title":"计算机基础知识点总结（操作系统+计算机网络）"},{"content":"1、命令返回值 状态回复 OK：成功 PONG：响应 PING 错误回复：命令不存在或者命令格式有误 Error Unknown command 整数回复： INCR 命令：返回递增后的键值 DBSIZE 命令：返回键的数量 字符串回复： 请求键的值或者请求一个其他类型键中的某个元素 多行字符串回复： 请求非字符串类型键的元素列表 Keys (Pattern)：返回数据库中符合指定规则的键名 2、多数据库 一个 Redis 实例提供了多个用来存储数据的字典，客户端可以指定数据存储在哪个字典中。 数据库默认从 0 开始递增命名，默认支持 16 个数据库（DB0，DB1，\u0026hellip;，DB15） 不支持自定义数据库名字，也不支持单独设置访问密码 3、命令大全 1、通用命令 keys pattern 获得符合规则的键名列表，支持？、*、[]、\\x 四种通配符\nkeys 命令会遍历所有键，不建议在生产环境中使用 命令不区分大小写 exists key 如果键存在返回 1，否则返回 0 del key 删除一个或多个键，返回删除的键的个数 type key 获得键值的数据类型 2、字符串类型 简介 字符串类型是 Redis 中最基本的数据类型，它能存储任何形式的字符串，包括二进制数据，可以存储邮箱、JSON、或者一张图片，允许存储的最大容量是 512MB set key value / get key 赋值与取值 incr key 递增数字，让当前键值递增，并返回递增后的值 如果 key 不存在时会默认键值为 0 incrby key increment 增加指定的整数 decr key 同上 decrby key decrement 同上 incrbyfloat key increment 增加指定浮点数 append key value 尾部追加 strlen key 字符串长度 mget key / mset key1 value1 \u0026hellip; 同时获取/设置多个键值 位操作 getbit key offset setbit key offset value bitcount key bittop 使用场景 文章访问量统计：为每篇文章使用一个名为 post:文 h 章 ID:page.view 的键来记录文章的访问量，每次访问文章的时候使用 incr 命令。（键命名建议：“对象类型：对象 ID：对象属性”） 生成自增 ID：对于每一类对象使用名为对象类型：count 的键来存储当前类型对象的数量（如 users:count），每次新增一个对象时都使用 incr 命令，返回值就是该新增对象的 ID。 存储文章数据：JSON 存储 3、hash 类型 简介 散列类型适合存储对象：使用对象类别和 ID 构成键名，使用字段表示属性，字段值则存储属性值。一个键最多存 2^32 - 1 个元素 hset key field value hset car price 500 hget key field hget car price hmset key field value hmget key field hgetall key hexists key field hsetnx key field value 当字段不存在时赋值\n原子操作，线程安全\nhincrby key field increment hdel key field 其他命令 hkeys hvals hlen 使用场景 存储文章数据 存储文章缩略名：使用 slug.to.id 的键来存储文章缩略名和 ID 之间的映射关系。这样就可以用 hexists 判断缩略名是否存在，使用 hget 命令来获取缩略名对应的文章 ID 4、list 类型 简介 可以存储一个有序的字符串列表，常用操作是向列表两端添加元素 底层：双向链表，添加复杂度 O（1） 适用场景：只关心最新的内容 一个键最多存 2^32 - 1 个元素 lpush key value1\u0026hellip; rpush key value1\u0026hellip; lpop key rpop key llen key lrange key start stop 获取列表片段（两边都是闭区间） 支持负索引（与 python 类似） 0，-1 会返回所有元素 start \u0026gt; stop：返回空 stop \u0026gt; len：返回 start,start + len lrem key count value 删除列表中前 count 个值为 value 的元素，返回值是实际删除的元素个数 count\u0026gt;0 时，从列表左边开始删除 count\u0026lt;0 时，从列表右边开始删除 count=0 时，删除所有 lindex key index 索引取值，支持负数 lset key index value 索引赋值 ltrim key start end 删除指定索引外的全部值 linsert key before|after pivot value 首先查找 pivot，然后插入其前面或后面 rpoplpush source destination 将一个元素转到另一个列表 使用场景 存储文章 ID 列表 存储评论列表 5、set 类型 简介 无序、唯一 最多 2^32 - 1 个元素 常用操作：插入、删除、判断某个元素是否存在、交集、并集、差集 sadd key member srem key member smembers 返回所有元素 sismember key member 判断元素是否在集合中\nO（1）\nsdiff key1 key2 \u0026hellip; 求差集（ key1 - key2） sinter key1 key2\u0026hellip; 求交集 sunion key1 key2\u0026hellip; 求并集 scard key 获取元素个数 sdiffstore/sinterstore/sunionstore destination key1 key2\u0026hellip; 存储集合操作的结果 srandmember key count count\u0026gt;0 时，获取不重复的随机 count 个元素 count\u0026lt;0 时，获取可能重复的随机 count 个元素 spop 随机选择一个元素弹出 使用场景 存储文章标签 通过标签搜索文章 6、zset 类型 简介 有序 唯一 可以获取某一范围的袁旭 底层：散列表和跳表，读取速度为 O(logn) zadd key score member 支持整数、双精度浮点数，甚至-inf 和+inf 可以修改 score zscore key member zrange key start stop [withscores] 获得排名在某个范围的元素\n可以添加分数\n复杂度为 O(logn + m)\nzrangebyscore key min max [withscores] limit offset count 获得指定分数范围的元素，两边是闭区间 支持 inf 数字前添加左圆括号表示开区间 可以用 limit 限制返回的个数 zrevrangebyscore key max min [withscores] limit offset count 同上，改成降序 zincrby key increment member 增加某个元素的分数 zcard key 元素数量 zcount key min max 分数范围内个数 zrem key member1 \u0026hellip; zremrangebyranke key start stop 根据排名范围删除元素 zremrangebyscore key min max 根据分数范围删除元素 zrank key member 获取元素排名 zrevrank key member 降序排名 ","date":"2021-04-07T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/groningen-5372387_1920.jhh1ofhqnjs.webp","permalink":"https://cuterwrite.top/p/redis-1/","title":"Redis 入门"},{"content":"Spring Cloud alibaba 笔记 SOA 与微服务的区别： SOA 关注的是服务的重用性及解决信息孤岛问题 微服务关注的是解耦，虽然解耦和可重用性从特定的角度来看是一样的，但本质上是有区别的，解耦是降低业务之间的耦合度，而重用性关注的是服务的复用。 微服务会更多地关注在 DevOps 的持续交付上，因为服务粒度细化之后使得开发运维变得更加重要，因此微服务与容器化技术的结合更加紧密。 Spring Cloud Alibaba 与 Spring Cloud Netflix 的对比 Alibaba 开源组件在没有织入 Spring Cloud 生态之前，已经在各大公司广泛应用，所以容易实现技术整合及迁移。 Alibaba 开源组件在服务治理上和处理高并发的能力上有天然的优势。 什么是 Spring Boot？ 帮助开发者快速构建一个基于 Spring Framework 及 Spring 生态体系的应用解决方案，也是对于“约定优于配置”理念的最佳实践。\nIOC/DI（控制反转与依赖注入） IOC：把对象的生命周期托管到 Spring 容器中，而反转是指对象的获取方式被反转了。 当使用 IOC 容器之后，客户端类不需要通过 new 来创建这些对象，而是直接从 IOC 容器中获得。早期的 Spring 中，主要通过 XML 的方式来定义 Bean，Spring 会解析 XML 文件，把定义的 Bean 转载到 IOC 容器中。 DI：IOC 容器在运行期间，动态地把某种依赖关系注入组件中。 DI 的三种方法：接口注入、构造方法注入、setter 方法注入；目前是基于注解的形式：有@Autowired、@Inject 和@Resource Spring 发展过程 J2EE 的 EJB 时代 Spring XML 配置文件时代 JavaConfig 的无配置化注入时代 Spring Boot 时代：约定优于配置，核心为： Starter 组件：开箱即用 自动装配：自动根据上下文完成 Bean 的装配 Actuator：应用监控 Spring Boot CLI：脚手架 自动装配的实现 实现原理：@EnableAutoConfiguration，这个注解的声明在启动类注解@SpringBootApplication 内。进一步又涉及到@Enable 注解（本质上是对@Configuration 和@Bean 的封装）；使用 Enable 注解后，Spring 会解析到@Import 导入的配置类，从而根据这个配置类中的描述来实现 Bean 的装配。\n例子：可以直接使用@Autowired 来注入 RedisTemplate 实例。\nEnableAutoConfiguration 的原理\n@Import：导入一个 AutoConfigurationImportSelector 类。\n@AutoConfigurationPackage：把使用了该注解的类所在的类所在的包及子包下所有组件扫描到 Spring IoC 容器中\nAutoConfigurationImportSelector：是 ImportSelector 的实现类，只有一个 selectImports 抽象方法，并且返回一个 String 数组，在这个数组中可以指定需要装配到 IOC 容器的类，当@Import 中导入一个 ImportSelectord 的实现类后，会把该实现类中返回的 Class 名称都装载到 IOC 容器中。\nImportSelector 与@Configuration 的区别：前者可以实现批量装配，并且还可以通过逻辑处理来实现 Bean 的选择性装配，也就是根据上下文来决定哪些类能够被 IOC 容器初始化。\n自动装配原理总结：\n通过@Import(AutoConfigurationImportSelector)实现配置类的导入 AutoConfigurationImportSelector 类实现了 ImportSelector 接口，重写了方法 selectImports，用于实现选择性批量配置类的装配。 通过 Spring 提供的 SpringFactoriesLoader 机制，扫描 classpath 路径下的 META-INF/spring.factories，读取需要实现自动装配的配置类。 通过条件筛选的方式，把不符合条件的配置类移除，最终完成自动装配。 @Conditional 条件装配\n是 Spring Framework 提供的一个核心注解，这个注解的作用是提供自动装配的条件约束，一般与@Configuration 和**@Bean**配合使用。\n简单来说，Spring 在解析@Configuration 配置类时，如果该配置类增加了@Conditional 注解，那么就会根据该注解配置的条件来决定是否要实现 Bean 的装配。\n@Configuration\rpublic class ConditionConfig {\r@Bean\r@Conditional(GpCondition.class)\rpublic ThirdClass thirdClass() {\rreturn new ThirdClass();\r}\r}\r表示：如果 GpCondition 类中的 matches 返回 true，则装载 ThirdClass 这个类。\n@Conditional 在 Spring Boot 中的扩展\n常用装配注解：\n@ConditionalOnBean\n@ConditionalOnMissingBean\n@ConditionalOnResource\n@ConditionalOnProperties\nspring-autoconfigure-metadata\n用于实现批量自动装配条件配置，作用和@Conditional 一致，只是把这些条件配置放在了配置文件中。\n两个条件：\n（1）配置文件的路径和名称必须是/META-INF/spring-autoconfigure-metadata.properties\n（2）配置文件中 key 的配置格式：自动配置类的类全路径名.条件=值\n好处：有效降低 Spring Boot 的启动时间，通过这种过滤方式可以减少配置类的加载数量，因为这个过滤发生在配置类的装载之前，所以它可以降低 Spring Boot 启动时装载 Bean 的耗时。\n手写实现一个 Starter 1 Starter 的功能 涉及相关组件的 Jar 包依赖 自动实现 Bean 的装配 自动声明并且加载 application.properties 文件中的属性配置。 2 Starter 的命名规范 Starter 的命名主要分为官方命名和自定义组件命名两类，这种命名格式不是强制性的，也是一种约定俗成的方式。\n官方命名格式：spring-boot-starter-模块名称 自定义命名格式：模块名称-spring-boot-starter 3 实现基于 Redis 的 Starter 创建一个工程，命名为 redis-spring-boot-starter 添加 Jar 包依赖 定义属性类，实现在 application.properties 中配置 Redis 的连接参数，使用@ConfigurationProperties，把当前类中的属性和配置文件中的配置进行绑定，并且规定前缀。 定义需要自动装配的配置类，主要就是把 RedissonClient 装配到 IOC 容器中。 Apache Dubbo 什么是 Dubbo：一个分布式服务框架，主要实现多个系统之间的高性能、透明化调用，简单来说就是一个 RPC 框架，但是和普通的 RPC 框架不同，它提供了服务治理功能，比如服务注册、监控、路由、容错等。\n服务提供者开发流程：\n创建一个普通的 Maven 工程 provider，并创建两个模块：api 和 provider，其中 provider 是一个 Spring Boot 工程 在 api 模块中定义接口，并且通过 mvn install 安装到本地仓库 在 provider 模块的 pom 文件中引入 api 和 dubbo 组件。 在 provider 中实现接口，并且使用@DubboService 注解发布服务 在 application.properties 文件（或 yml）中添加 Dubbo 服务的配置信息，包括 application.name、protocal.name、protocol.port 和 registry.address 启动 Spring Boot 服务调用者的开发流程：\n创建一个 Spring Boot 项目 consumer，添加 Jar 包依赖（Dubbo 和 api） 在 application.properties 中配置 dubbo.application.name 使用@DubboReference 注解获取一个远程代理对象。 Zookeeper Zookeeper 是一个高性能的分布式协调中间件，基于 Java 编写。\nZookeeper 的数据结构：数据模型和分布式文件系统类似，是一种层次化的属性结构，区别是：Zookeeper 的数据是结构化存储的，并没有在物理上体现出文件和目录。Zookeeper 树中的每个节点被称为 Znode，Znode 维护了一个 stat 状态信息，其中包含数据变化的时间和版本等。并且每个 Znode 可以设置一个 value 值，Zookeeper 并不用于通用的数据库或者大容量的对象存储，它只是管理和协调有关的数据，所以 value 的数据大小不建议设置得非常大，否则会带来更大的网络开销。Zookeeper 上的每一个节点的数据都是允许读和写的，读表示指定获得 Znode 上的 value 数据，写表示修改 Znode 上的 value 数据。另外，节点的创建规则和文件系统中文件的创建规则类似，必须按照层次创建。例如：创建/node/node1/node1-1，先要创建/node/node1 这两个层次节点。\nZookeeper 的特性：Znode 在被创建后，需要指定节点的类型，节点类型分为：\nWatcher 机制：\nZnode 的订阅/通知机制：当 Znode 节点状态发生变化时或者 Zookeeper 客户端连接状态发生变化时，会触发事件通知。这个机制在服务注册与发现中，针对服务调用者及时感知到服务提供者的变化提供了非常好的解决方案。\nZookeeper 提供的 Java API 中，提供了三种机制来针对 Znode 进行注册监听，分别是：\n常用应用场景分析\n分布式锁：（1）多线程中 Synchronized 和 Lock 用于解决共享资源访问的数据安全性问题，但范围是线程级别的。（2）在分布式架构中，多个进程对同一个共享资源的访问，也存在数据安全性问题，因此也需要使用锁的形式来解决这类问题，而解决分布式环境下多进程对于共享资源访问带来的安全性问题的方案就是使用分布式锁。锁的本质是排他性，也就是避免同一时刻多个进程同时访问某一个共享资源。（3）如果使用 Zookeeper 实现分布式锁来达到排他性的目的，只需要用到节点的特性：临时节点，以及同级节点的唯一性。（4）具体实现：a.获得锁的过程：所有客户端可以去 Zookeeper 服务器上/Exclusive_Locks 节点下创建一个临时节点/lock。Zookeeper 基于同级节点的唯一性，会保证所有客户端中只有一个客户端能创建成功，创建成功的客户端获得了排它锁，没有获得锁的客户端就需要通过 Watcher 机制监听/Exclusive_Locks 节点下子节点的变更事件，用于实时监听/lock 节点的变化情况以作出反应。 b.释放锁的过程：①获得锁的客户端因为异常断开了和服务端的连接，临时节点会自动删除。②获得锁的客户端执行完业务逻辑后，主动删除创建的 lock 节点。 Master 选举：分布式系统中的集群模式，某一机器宕机后，其他节点会接替故障节点继续工作。（1）Zookeeper 有两种方式来实现 Master 选举的场景。假设集群中有 3 个节点，需要选举出 Master，那么三个节点同时去 Zookeeper 服务器上创建一个临时节点/master-election，由于节点的唯一性，只会有一个客户端创建成功，创建成功就称为 Master。同时，其他没有创建成功的客户端，针对该节点注册 Watcher 事件，监控 master，一旦/master-election 节点被删除，其他客户端重新发起 master 选举。（2）方法二：利用临时有序节点的特性来实现。所有参与选举的节点在/master 节点下创建一个临时有序节点，编号最小的节点表示 master，后续的节点监听上一个节点的删除事件，用于触发重新选举。 Dubbo 集成 Zookeeper 1 需要解决的问题 服务动态上下线感知：服务调用者要感知到服务提供者上下线的变化。 负载均衡 2 实现步骤 在 provider 模块中添加 Zookeeper 相关依赖 修改 application.properties 配置文件，修改 dubbo 的 registry-addr 为 zookeeper 服务器的地址，表示当前 Dubbo 服务需要注册到 Zookeeper 上。 consumer 只需要修改 application.properties，设置 dubbo 的 registry-addr 即可 3 原理 Dubbo 服务注册到 Zookeeper 上之后，可以在 Zookeeper 服务器上看到图下所示的树形结构。\n其中 URL 是临时节点，其他皆为持久化节点，如果注册该节点的服务器下线了，那么这个服务器的 URL 地址就会被移除。\n当 Dubbo 服务消费者启动时，会对/providers 下的子节点注册 Watcher 监听，这样就可以感知到服务提供方的上下线变化，从而防止请求发送到已经下线的服务器造成访问失败。同时，服务消费者会在/consumers 下写入自己的 URL，这样可以在监控平台上看到某个 Dubbo 服务正在被哪些服务调用。最重要的是，如果服务消费者需要调用一个服务，那么它会先去/providers 路径下获得所有该服务的提供方 URL 列表，然后通过负载均衡算法计算出一个地址进行远程访问。\n此外，Dubbo 还可以针对不同的情况实现以下功能：\n基于临时节点的特性，当服务器宕机或者下线时，注册中心会自动删除该服务提供者的信息。 注册中心重启时，Dubbo 能自动恢复注册数据及订阅请求。 为了保证节点操作的安全性，Zookeeper 提供了 ACL 权限控制，在 Dubbo 中可以通过 register.username 和 password 来设置节点的验证信息。 注册中心默认的根节点为/dubbo，如果需要针对不同环境设置不同的根节点，可以使用 registry.group 修改根节点名称。 4 实战 Dubbo Spring Cloud 创建 service-provider 工程，创建两个子模块 api 和 provider，前者为 maven 工程，后者为 Spring Boot 工程 在 api 中声明接口，并执行 mvn install 在 provider 中添加 api、Spring Boot、Spring Cloud 和 Spring Cloud Alibaba 相关组件的依赖。（包括 spring-cloud-starter、spring-cloud-starter-dubbo、api、discovery） 在父 pom 中显示声明 dependencyManagement 配置版本。 在 provider 中创建接口的实现类，并且声明@DubboService 在 application.properties 中配置 Dubbo 相关信息。 启动 provider 服务。 创建 consumer，依赖与 provider 类似，同样在 application.properties 中配置 Dubbo 相关信息。注意：dubbo-cloud-subscribed-services 表示服务调用者订阅的服务提供方的应用名称列表，如果有多个应用名称，可以通过\u0026quot;,\u0026ldquo;分开，默认值为“*” 使用@DubboReference 消费服务，启动即可。 Dubbo 的高级应用 1 集群容错 Dubbo 默认提供 6 种容错模式，默认为 Failover Cluster，此外可以根据实际需求自行扩展。\n配置方式：在@DubboService 中增加参数 cluster=\u0026ldquo;failfast\u0026rdquo; 即可。 推荐：查询语句容错策略建议使用默认的 Failover Cluster，而增删改操作建议使用 Failfast Cluster 或者使用 Failover Cluster(retries=0)，防止出现数据重复添加等其他问题！建议在设计接口的时候把查询接口方法单独做成一个接口提供查询。 2 负载均衡 Dubbo 提供了 4 种负载均衡策略，默认为 random，也可以自行扩展（基于 SPI 机制）。\n3 服务降级 服务降级是一种系统保护策略，当服务器访问压力较大时，可以根据当前业务情况对不重要的服务进行降级，以保证核心业务的正常运行。所谓的降级，就是把一些非必要的功能在流量较大的时间段暂时关闭，比如在双十一大促时，淘宝会把查看历史订单、商品评论等功能关闭。\n降级的分类：\n是否自动化：人工降级、自动降级 功能划分：读服务降级和写服务降级 自动降级更多来自于系统出现某些异常时自动触发“兜底的流畅”，比如：\n故障降级：调用的远程服务挂了，网络故障或者 RPC 服务返回异常。这类情况在业务情况下可以通过设置兜底数据响应给客户端。 限流降级：为了保护系统不被压垮，在系统中会针对核心业务进行限流，当请求流量达到阈值时，后续的请求会被拦截。 Dubbo 提供了一种 Mock 配置来实现服务降级，也就是当服务提供方出现网络异常无法访问时，客户端不抛出异常，步骤如下：\n在 consumer 中创建 MockService，这个类只需要实现降级的接口即可，重写接口中的抽象方法实现本地数据的返回。 在@DubboReference 中增加 mock 参数，制定 MockService 的位置。 在不启动 Dubbo 服务或者服务端的返回值超过默认的超时时间时，得到的数据就是 MockService 中的数据。 主机绑定规则 主机绑定表示的是 Dubbo 服务对外发布的 IP 地址，默认情况下 Dubbo 会按照以下顺序来查找并绑定主机 IP 地址。\n查找环境变量 DUBBO_IP_TO_BIND 属性配置的 IP 地址。\n查找 dubbo.protocol.host 属性的 IP 地址，默认是空，如果没有配置或者 IP 地址不合法则继续查找。\n通过 LocalHost.getHostAddress 获取本机 IP 地址，获取失败则继续。\n如果配置了注册中心的地址，则使用 Socket 通信连接到注册中心的地址后，使用 for 循环通过 socket.getLocalAddress().getHostAddress()扫描各个网卡来获取网卡 IP 的地址。\n建议：通过 dubbo.protocal.host 设置主机地址，防止注册错误的 IP 地址，使服务消费者无法调用。\ndocker 部署解决方案：使用\u0026ndash;net=host 绑定网络，然后配置 application.yml\n配置 inetutils 下的两个参数\nDubbo 源码分析 1 核心点 SPI 机制 自适应扩展点 IOC 和 AOP Dubbo 如何与 Spring 集成。 2 生成 IDE 工程的命令 mvn idea:idea mvn eclipse:eclipse 3 SPI(Service Provider Interface) 自适应扩展点：AdaptiveExtension 指定名称扩展点：Extension(name) 激活扩展点：ActivateExtension(url,key) SPI 是 JDK 内置的一种服务提供发现机制，主要用于服务的扩展实现。SPI 机制在很多场景中都有运用，比如数据库连接，JDK 提供了 Driver 接口，这个驱动类由不同的数据库厂商来实现，然后 JDK 利用 SPI 机制从 classpath 下找到相应的驱动来获得指定数据库的连接。这种插拔式的扩展加载方式，也同样遵循一定的协议约定，比如所有的扩展点必须要放在 resources/META-INF/services 目录下，SPI 机制会默认扫描这个路径下的属性文件以完成加载。\n4 Dubbo 中的 SPI 思想 Dubbo 或者 SpringFactoriesLoader 并没有使用 JDK 内置的 SPI 机制，只是利用了 SPI 的思想。Dubbo SPI 的相关逻辑被封装在了 ExtensionLoader 类中，通过 ExtensionLoader 我们可以加载指定的实现类。\nDubbo 的 SPI 扩展有两个规则：\n和 JDK 内置的 SPI 一样，需要在 resources 目录下创建任一目录结构：META-INF/dubbo、META-INF/dubbp/internal、META-INF/services，在对应的目录下创建以接口全路径名命名的文件，Dubbo 会去三个目录下加载相应扩展点。 文件内容和 JDK 内置的 SPI 不一样，内容是 key-value 形式的数据，key 是一个字符串，value 是一个对应扩展点的实现，这样的方式可以按照需要加载指定的实现类。 实现步骤如下：\n在一个依赖了 Dubbo 框架的工程中，创建一个扩展点及一个实现。其中，扩展点需要声明@SPI 注解。 在 resources/META-INF/dubbo 目录下创建以 SPI 接口命名的文件 使用 ExtensionLoader.getExtensionLoader.getExtension(key)获得指定名称的扩展点实现。 5 Dubbo 中的 SPI 原理 （1）ExtensionLoader.getExtensionLoader：这个方法用于返回一个 ExtensionLoader 实例，逻辑如下：\n先从缓存中获取与扩展类对应的 ExtensionLoader 缓存未命中，则创建一个新的实例，保存到 eEXTENXION_LOADERS 集合中缓存起来。 在 ExtensionLoader 构造方法中，初始化一个 objectFactory （2）getExtension：这个方法用于根据指定名称获取对应的扩展点并返回。\nname 用于参数的判断，如果 name=\u0026ldquo;true\u0026rdquo;，则返回一个默认的扩展实现。 创建一个 Holder 对象，用户缓存该扩展点的实例。 如果缓存中不存在，则通过 createExtension(name)创建一个扩展点。 （3）createExtension()：去指定的路径下查找 name 对应的扩展点的实现。\n通过 getExtensionClasses().get(name)获取一个扩展类 通过反射实例化之后缓存到 EXTENSION_INSTANCES 集合中。 injectExtension 实例依赖注入 把扩展类对象通过 Wrapper 进行包装。 （4）getExtensionClasses()\n从缓存中换取已经被加载的扩展类 如果缓存未命中，则调用 loadExtensionClasses 加载扩展类。 （5）loadExtensionClasses()\n通过 cacheDefaultExtensionName 方法获取当且扩展接口的默认扩展对象，并且缓存。 调用 loadDirectory 方法加载指定文件目录下的配置文件。 （6）cacheDefaultExtensionName()\n获得指定扩展接口的@SPI 注解 得到@SPI 注解中的名字，保存到 cacheDefaultName 属性中。 6 自适应扩展点 Adaptive Extension：能够根据上下文动态匹配一个扩展类，使用方式如下：\nExtensionLoader.getExtensionLoader(class).getAdaptiveExtension();\r自适应扩展点通过@Adaptive 注解声明，有两种使用方式\n（1）@Adaptive 注解定义在类上面，表示当前类为自适应扩展点。\n（2）@Adaptive 注解定义上方法层面，会通过动态代理的方式生成一个动态字节码，进行自适应匹配。\n7 Protocol 自适应扩展点源码 ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();\r首先是 getExtensionLoader：\n（1）从缓存中获取自适应扩展点实例。\n（2）如果缓存未命中，则通过 createAdaptiveExtension 创建自适应扩展点。\n然后是 createAdaptiveExtension：\n（1）getAdaptiveExtensionClass：获取一个自适应扩展类的实例。\n（2）injectExtension 完成依赖注入。\n接着是 getAdaptiveExtensionClass：\n（1）通过getExtensionClasses方法加载当前传入类型的所有扩展点，缓存在一个集合中。\n（2）如果 cachedAdaptiveClass 为空，则调用 createAdaptiveExtensionClass 进行创建。\n8 IOC 上文中的 injectExtension 就是依赖注入的实现，整体逻辑为：\n（1）遍历被加载的扩展类中的所有 set 方法。\n（2）得到 set 方法中的参数类型，如果参数类型是对象类型，则获得这个 set 方法中的属性名称。\n（3）使用自适应扩展点加载该属性名称对应的扩展类。\n（4）调用 set 完成赋值。\n简单来说，injectExtension 方法的主要功能是，如果当前加载的扩展类中存在一个成员对象，并且为它提供了 set 方法，那么就会通过自适应扩展点进行加载并赋值。\n9 AOP 面向切面编程，意图是把业务逻辑和功能逻辑分离，然后在运行期间或者类加载期间进行织入，可以降低代码的复杂性，以及提高重用性。\ninstance = injectExtension((T)WrapperClass.getConstructor(type).newInstance(instance));\r这段代码分别用到了依赖注入和 AOP，AOP 体现在基于 Wrapper 装饰器类实现对原有的扩展类 instance 进行包装。\n10 Dubbo 集成 Spring 机制（略） p89\n什么是 Nacos？ Nacos 致力于解决微服务中的统一配置、服务注册与发现等问题。它提供了一组简单易用的特性集，帮助开发者快速实现动态服务发现、服务配置、服务元数据以及流量管理。\n1 关键特性 服务发现和服务健康监测\nNacos 基于 DNS 和基于 RPC 的服务发现。服务提供者通过原生 SDK、OpenAPI 或一个独立的 Agent TODO 注册 Service 后，服务消费者可以使用 DNS 或 HTTP\u0026amp;API 查找和发现服务。\nNacos 提供对服务的实时的健康检查，阻止向不健康的主机或服务实例发送请求。Nacos 支持传输层（PING 或 TCP）和应用层（如 HTTP、MYSQL、用户自定义）的健康检查。对于复杂的云环境和网络拓扑环境（如 VPC、边缘网络等）服务的健康检查，Nacos 提供了agent 上报和服务端主动监测两种健康检查模式。Nacos 还提供了统一的健康检查仪表盘。\n动态配置服务\n业务服务一般都会维护一个本地配置文件，然后把一些常量配置到这个文件中。这种方式在某些场景会存在某些问题，比如配置变更时需要重新部署应用。而动态配置服务可以以中心化、外部化和动态化的方式管理所有环境的应用配置和服务配置。\n动态 DNS 服务\n支持权重路由，让开发者更容易实现中间层负载均衡、更灵活的路由策略、流量控制，以及数据中心内网的简单 DNS 服务。\n服务及其元数据管理\n2 Nacos 集群 包含一个 Leader 节点和多个 Follower 节点。\n数据一致性算法采用的 Raft（Etcd、Redis 哨兵选举也是这个算法）\n3 个或 3 个以上 Nacos 节点才能构成集群。\n搭建 Nacos 注册中心的注意点 dubbo.scan.base-packages 功能等同于@DubboComponentScan dubbo.registry.address：Dubbo 服务注册中心的配置地址，它的值 spring-cloud://url 表示挂载到 Spring Cloud 注册中心，不配置的话会提示没有配置注册中心的错误。 spring.cloud.nacos.discovery.server-addr：Nacos 服务注册中心的地址。 Nacos 实现原理 1 模块组成 Provider App Consumer App Name Server Nacos Server Nacos Console 整体来说，服务提供者通过 Virtual IP 访问 Nacos Server 高可用集群，基于 Open API 完成服务的注册和服务的查询。Nacos Server 本身可以支持主备模式，所以底层会采用数据一致性算法来完成主从节点的整体同步。服务消费者也是如此。\n2 注册中心的原理 服务注册的功能主要体现在：\n服务实例在启动时注册到服务注册表，并在关闭时注销。（Open API） 服务消费者查询服务注册表，获得可用实例。 服务注册中心需要调用服务实例的健康检查 API 来验证它是否能够处理请求。（心跳机制） 3 Nacos 源码（略） 服务注册 服务地址的获取 服务地址变化的感知 Nacos 实现统一配置管理 各个应用自己独立维护本地配置方式的不足：\n1 Nacos 集成 Spring Boot 在 application.properties 中配置 nacos.config.server-addr 创建 NacosConfigController，用于从 Nacos Server 动态读取配置。 @NacosPropertiesSource：用于加载 dataId 为 example 的配置源，autoRefreshed 表示开启自动更新。 @NacosValue：设置属性的值，其中 info 表示 key，而 Local Hello World 表示默认值。也就是说如果 key 不存在，则使用默认值。这是一种高可用的策略。 2 Nacos 集成 Spring Cloud spring.cloud.nacos.config.prefix 表示 Nacos 配置中心上的 DataID 的前缀。 spring.cloud.nacos.config.server-addr 表示 Nacos 配置中心的地址。 在 Nacos Console 创建配置 在启动类中，读取配置中心的数据。 注意坑：配置文件必须用 bootstrap.yml 这个名称，因为 bootstrap 加载顺序优于 application，因为需要在 bootstrap 配置文件中添加连接到配置中心的配置属性来加载外部配置中心的配置信息。 3 动态更新配置 通过一个 while 循环不断读取 info 属性，当 info 属性发生变化时，控制台可以监听到。\n4 基于 DataID 配置 yaml 的文件扩展名 DataID 默认规则是${prefix}-${spring.profile.active}.${file-extension}\n在默认情况下，会去 Nacos 服务器上加载 DataID 以${spring.application.name}.${file-extension:properties}为前缀的基础配置。例如：在不通过 spring.cloud.nacos.config.prefix 指定 DataID 时，会默认读取 DataID 为 nacos-config-demo.properties 的配置信息。 如果明确指定了 spring.cloud.nacos.config.prefix，则会加载 DataID 为指定值的配置。 spring.profile.active 表示多环境支持。 在实际应用中，如果使用 YAML 格式配置，则需要声明 spring.cloud.nacos.config.file-extension=yaml\n5 不同环境的配置切换 Spring Boot 多环境支持配置步骤如下：\n在 resource 目录下根据不同环境创建不同的配置： application-dev.properties application-test.properties application-prod.properties 定义一个 application.properties 默认配置，在该配置中通过 spring.profile.active=${env}来指定使用哪个环境的配置，如果${env}的值为 prod，表示使用 prod 环境。 也可以通过设置 VM Options=-Dspring.profiles.active=prod 来指定。 Nacos Config 配置步骤如下：\n在 bootstrap.properties 中声明 spring.profiles.active=prod 在 Nacos 控制台新增 DataID 为 nacos-config-demo-prod.properties 的配置项。 6 自定义 Namespace 和 Group Namespace：解决多环境及多租户数据的隔离问题。 使用：在 bootstrap.properties 里指定 spring.cloud.nacos.config.namespace Group：用于分组管理 Data ID 使用：在 bootstrap.properties 里指定 spring.cloud.nacos.config.group Nacos Config 实现原理（略） 获取配置 监听配置 发布配置 删除配置 分为两类：配置的 CRUD 和配置的动态监听\nSpring Cloud 加载配置的原理（略） Nacos 源码（略） Sentinel 限流及熔断 1 服务限流的作用及实现 主要作用：损失一部分用户的可用性，为大部分用户提供稳定可靠的服务。\n计算器算法：在制定周期内累加访问次数，当访问次数达到阈值时，触发限流策略。\n滑动窗口算法：源于 TCP 拥塞控制，原理是在固定窗口中分割出多个小时间窗口，分别在每个小时间窗口中记录访问次数，然后根据时间将窗口往前滑动并删除过期的小时间窗口。最终只需要统计滑动窗口范围内所有小时间窗口总的计数即可。（Sentinel 的原理）\n令牌桶算法：每一个请求，都需要从令牌桶中获取一个令牌，如果没有获得令牌，则触发限流策略。\n特性：短时间内新增的流量系统能够正常处理。\n漏桶限流算法：用于控制数据注入网络的速度，平滑网络上的突发流量。\n2 服务熔断和降级 在微服务架构中，由于服务拆分粒度较细，会出现请求链路较长的情况，用户发起一个请求操作，需要调用多个微服务才能完成。\n雪崩效应：某个服务因为网络延迟或者请求超时等原因不可用时，就会导致当前请求阻塞，一旦某个链路上被依赖的服务不可用，很可能出现请求堆积而产生雪崩。\n所以，服务熔断就是用来解决这个问题的方案，它指的是当某个服务提供者无法正常为服务调用者提供服务时，为了防止整个系统出现雪崩效应，暂时将出现故障的接口隔离出来，断绝与外部接口的联系，当触发熔断后，后续一段时间内该服务调用者的请求都会直接失败，直至目标服务恢复正常。\n3 Sentinel 的特性 丰富的应用场景：秒杀、消息削峰填谷、集群流量控制等。 实时监控 开源生态支持 SPI 扩展点支持 4 Sentinel 的组成： 核心库（Java 客户端）：不依赖任何框架与库，能够运行于所有 Java 运行时环境。 控制台（Dashboard） 5 Sentinel 基本应用： 步骤如下：\n（1）定义资源：限流保护的最基本元素，比如一个方法。\n（2）定义限流规则\n（3）检验规则是否生效\n限流规则：通过 initFlowRules 方法设置\ngrade：限流阈值类型，有 QPS 模式和并发线程数模式。 count：限流阈值 resource：设置需要保护的资源 6 Sentinel 资源保护规则 Sentinel 支持多种保护规则：流量控制规则、熔断降级规则、系统保护规则、来源访问控制规则、热点参数规则。\n限流规则：先通过 FlowRules 来定义限流规则，然后通过 FlowRuleManager.loadRules 来加载规则列表。 1 QPS 流量控制行为 通过 controlBehavior 设置，包含：\n直接拒接 Warm UP，冷启动 匀速排队 冷启动 + 匀速排队 7 Sentinel 实现服务熔断 通过 DegradeRule 实现：\ngrade：熔断策略，支持秒级 RT、秒级异常比例、分钟异常数。默认是秒级 RT。 timeWindow：熔断降级的时间窗口，单位为 s。也就是出发熔断降级之后多长时间内自动熔断。 rtSlowRequestAmount：在 RT 模式下，1s 内持续多少个请求的平均 RT 超出阈值后出发熔断，默认值是 5 minRequestAmout：触发的异常熔断最小请求数，请求数小于该值时即使异常比例超出阈值也不会触发熔断，默认值是 5. 三种熔断策略：\n平均响应时间 RT：如果 1s 内持续进来 5 个请求，对应的平均响应时间都超过了阈值(count，单位为 ms)，那么在接下来的时间窗口内，对这个方法的调用都会自动熔断，抛出 DegradeException 异常比例 最近一分钟异常数：如果 timeWindow 小于 60s，则结束熔断状态后仍然可能再进入熔断状态。 Sentinel 集成 Spring Cloud 步骤如下：\n创建项目，集成 Spring Cloud 依赖。\n添加 Sentinel 依赖。\n创建一个 REST 接口，并且通过@SentinelResource 配置限流保护资源。\n在上述代码中，配置限流资源有几种情况\nSentinel starter 在默认情况下会为所有的 HTTP 服务提供限流埋点，所以如果只想对 HTTP 服务进行限流，只需添加依赖即可。 如果想要对特定的方法进行限流或降级，则需要通过@SentinelResource 注解来定义资源。 可以通过 SphU.entry()方法来配置资源。 手动配置流控规则，可以借助 Sentinel 的 InitFunc SPI 扩展接口来实现，只需要实现自己的 InitFunc 接口，并在 init 方法中编写规则加载的逻辑即可。\n基于 Sentinel Dashboard 来实现流控配置 步骤如下：\n启动 Sentinel Dashboard\n在 application.yml 中增加以下配置\n提供一个 REST 接口\n进入 Sentinel Dashboard 中配置流控规则。\n访问簇点链路，找到资源名称。\n单机流控按钮设置流控规则\n注意 sentinel 的坑：\nSentinel 自定义 URL 限流异常 默认情况下，URL 触发限流后会返回 Blocked by Sentinel 字符串\n在实际应用中，大都采用 JSON 格式，所以如果希望修改触发限流之后的返回结果形式，则可以通过自定义限流异常来处理，实现UrlBlockHandler并且重写 blocked 方法。\n还有一种场景，当触发限流后，希望跳转到一个降级页面，可以通过下面这个配置来实现。\nspring.cloud.sentinel.servlet.block-page={url}\nSentinel 对 URL 资源清洗 Sentinel 中 HTTP 服务的限流默认由 Sentinel-Web-Servlet 包中的 CommonFilter 来实现，这个 Filter 会把每个不同的 URL 都作为不同的资源来处理。\n举例：\n限流统计不准确，实际需求是控制 clean 方法总的 QPS，结果统计的是每个 URL 的 QPS 导致 Sentinel 中资源数量过多，默认资源数量阈值为 6000，对于多出的资源规则将不会生效。 针对这个问题可以通过URLCleaner接口来实现资源清洗，也就是对于/clean/{id}这个 URL，我们可以统一归集到/clean/*资源下，具体代码如下：\nSentinel 集成 Nacos 实现动态流控规则 Sentinel 的理念是只需要开发者关注资源的定义，默认会对资源进行流控。当然我们还需要自定义流控规则，前面有两种方式：\n通过 FlowRuleManager.loadRules(List rules)手动加载流控规则 在 Sentinel Dashboard 上针对资源动态创建流控规则。 针对第一种方式，如果接入 Sentinel Dashboard，那么同样支持动态修改流控规则。但是，这里会存在一个问题，基于 Sentinel Dashboard 所配置的流控规则，都是保存在内存中的，一旦应用重启，这些规则都会被清除。为了解决这个问题，Sentinel 提供了动态数据源支持。\n目前，Sentinel 支持 Consul、Zookeeper、Redis、Nacos、Apollo、etcd 等数据源的扩展，我们使用 Nacos 的方式来扩展。\n步骤如下：\n添加 Nacos 数据源依赖包\n创建一个 REST 接口用于测试。\n在 application.yml 中添加数据源配置。\n配置说明：\nrule-type：flow、degrade、param-flow、gw-flow 等\ndata-type：Spring Cloud Alibaba 提供了 JSON 和 XML 两种格式。如果需要自定义，则可以将值配置为 custom，并配置 converter-class 指向 converter 类。\n登录 Nacos 控制台，创建流控配置规则，配置信息如下：\n最后，登录 Sentinel Dashboard，找到执行项目名称菜单下的“流控规则”，就可以看到在 Nacos 上所配置的流控规则已经被加载了。\n当在 Nacos 控制台修改流控规则后，可以同步在 Sentinel Dashboard 上看到流控规则的变化。\n注意：在 Sentinel Dashboard 上修改无法同步到 Nacos 上。 强烈建议：不要在 Nacos 上修改流控规则，因为这种修改的危险系数很高。这就意味着流控规则的管理应该集中在 Sentinel Dashboard 上，所以我们需要实现 Sentinel Dashboard 来动态维护规则并同步到 Nacos 上，目前官方还没有提供支持，但可以自己实现。\n这里有一个坑：出现了空指针异常org.springframework.beans.factory.BeanCreationException: Error creating bean with name \u0026lsquo;ds1-sentinel-nacos-datasource\u0026rsquo;: FactoryBean threw exception on object creation; nested exception is java.lang.NullPointerException，出现原因是 Spring-Cloud-Alibaba 与 Sentinel 的版本对应不上，解决办法是把 Spring Cloud Alibaba 的版本升到 2.2.5.RELEASE 即可。\nSentinel 集成 Nacos 实现规则同步 Sentinel Dashboard 的“流控规则”下的所有操作，都会调用 Sentinel 源码中的 FlowControllerV1 类，这个类包含流控规则本地化的 CRUD\n另外，在 com.alibaba.csp.sentinel.dashboard.controller.v2 包下存在一个 FlowControllerV2 类，这个类同样提供流控规则的 CRUD，和 V1 版本不同的是，它可以实现指定数据源的规则拉取和同步。\nFlowControllerV2 依赖以下两个非常重要的类\nDynamicRuleProvider：动态规则的拉取，从指定数据源中获取流控规则后在 Sentinel Dashboard 中展示。 DynamicRulePublisher：动态规则的发布，将在 Sentinel Dashboard 中修改的规则同步到指定数据源中。 这里我们扩展这两个类，然后集成 Nacos 来实现 Sentinel Dashboard 规则的同步。\n1 Sentinel Dashboard 源码修改： 具体步骤如下：\n打开 sentinel-dashboard 工程，在 pom.xml 中把 sentinel-datasource-nacos 依赖的 scope 注释掉。\n修改 resouces/app/scripts/directives/sidebar/sidebar.html 文件下的代码，将 dashboard.flowV1 改成 dashboard.flow\n修改之后，会调用 FlowControllerV2 中的接口。\n在 com.alibaba.csp.sentinel.dashboard.rule 包中创建一个 nacos 包，并创建一个类用来加载外部化配置。\n创建一个 Nacos 配置类 NacosConfiguration\n注入 Converter 转换器，将 FlowRuleEntity 转化为 FlowRule，以及反向转化。 注入 Nacos 配置服务 ConfigService 创建一个常量类 NacosConstants，分别表示默认的 GROUP_ID 和 DATA_ID 的后缀。\n实现动态从 Nacos 配置中心获取流控规则。\n创建一个流控规则发布类，在 Sentinel Dashboard 上修改完配置后，需要调用该发布方法将数据持久化到 Nacos 中。\n修改 FlowControllerV2 类，将上面配置的两个类注入进来，表示规则的拉取和规则的发布统一用我们前面自定义的两个实例。\n在 application.properties 文件中添加 nacos 服务端的配置信息。\n将代码打包成一个 fat jar\n详见 https://blog.csdn.net/weixin_42073629/article/details/107117433\r或者 test 包中的 nacos 代码\n2 Sentinel Dashboard 规则同步 应用程序需要修改的地方比较少，只需注意配置文件中 data-id 的命名要以-sentinel-flow 结尾即可。\nSentinel 集成 Dubbo 实现限流 Sentinel 提供了与 Dubbo 整合的模块 Sentinel Apache Dubbo Adapter，可以针对服务提供者和服务消费者进行流控，在使用的时候，只需要添加以下依赖。\n添加后该依赖后，Dubbo 服务中的接口和方法（包括服务端和消费端）就会成为 Sentinel 中的资源，只需针对指定资源配置流控规则就可以实现 Sentinel 流控功能。\nSentinel Apache Dubbo Adapter 实现限流的核心原理是基于 Dubbo 的 SPI 机制实现 Filter 扩展，Dubbo 的 Filter 机制是专门为服务提供者和服务消费者调用过程进行拦截设计的，每次执行远程方法，该拦截都会被执行。\n同时，Sentinel Apache Dubbo Adapter 还可以自定义开启或者关闭某个 Filter 的功能，下面表示关闭消费端的过滤器。\n1 Dubbo 服务接入 Sentinel Dashboard 引入 sentinel-transport-simple-http 依赖\n添加启动参数\n登录 Sentinel Dashboard 之后，进入“簇点链路”，就可以看到资源信息。\n需要注意的是，限流可以通过服务接口或服务方法设置\n服务接口：resourceName 为接口的全限定名（包+接口名） 服务方法：resourceName 为接口全限定名：方法名（包+接口名:方法名） 2 Dubbo 服务限流规则 两种方式\nSentinel Dashboard FlowRuleManager.loadRules(List rules) Sentinel Apache Dubbo Adapter 组件中没有实现规则持久化，因此有以下步骤来支持：\n在 dubbo 服务中添加 sentinel-datasource-nacos 依赖 通过 Sentinel 提供的 InitFunc 扩展点，实现 Nacos 数据源的配置 访问 Sentinel Dashboard，在针对某个资源创建流控规则时，这个规则会同步保存到 Nacos 的配置中心，而当 Nacos 配置中心发生变化时，会触发事件机制通知 Dubbo 应用重新加载流控规则。 Sentinel 热点限流 热点数据表示经常访问的数据，在有限场景中我们希望针对这些访问频次非常高的数据进行限流，比如针对一段时间内频繁访问的用户 ID 地址进行限流，或者针对频繁访问的某个用户 ID 进行限流。\nSentinel 提供了热点参数限流的规则，它是一种特殊的限流，在普通限流的基础上对同一个受保护的资源区根据请求中的参数分别处理，该策略只对包含热点参数的资源调用生效。热点限流在以下场景使用较多：\n服务网关层：例如防止网络爬虫和恶意攻击，一种常用方法就是限制爬虫的 IP 地址。 写数据的服务：例如业务系统提供写数据的服务，数据会写入数据库之类的存储系统。存储系统的底层会加锁写磁盘上的文件，部分存储系统会将某一类数据写入同一个文件中。如果底层写同一文件，会出现抢占锁的情况，导致出现大量超时和失败。出现这种情况时一般有两种解决方法：修改存储设计、对热点参数限流。 Sentinel 通过LRU 策略结合滑动窗口机制来实现热点参数的统计，其中 LRU 策略可以统计单位时间内最常访问的热点数据，滑动窗口机制可以协助统计每个参数的 QPS。\n1 热点参数限流的使用 引用热点参数限流依赖包 sentinel-parameter-flow-control 接下来创建一个 REST 接口，并定义限流埋点，此处针对参数 ID 配置热点限流规则。 针对不同的热点参数，需要通过 SphU.entry(resourceName,EntryType.IN,1,id)方法设置，其最后一个参数是一个数组，有多个热点参数就按照次序依次传入，该配置表示后续会针对该参数进行热点限流。 通过 ParamFlowRuleManager.loadRules 加载热点参数规则。 2 @SentinelResource 如果是通过@SentinelResource 注解来定义资源，当注解所配置得方法上有参数时，Sentinel 会把这些参数传入 SphU.entry 中\n3 热点参数规则说明 durationInSec：统计窗口时间长度，单位为 s maxQueueingTimeMS：最长排队等待时长，只有当流控为 controlBehavior 设置为匀速排队模式时生效。 paramIdx：热点参数的索引，属于必填项，对应的是 SphU.entry 中的参数索引位置。 paramFlowItemList：针对指定参数值单独设置限流阈值，不受 count 阈值的限制。 Sentinel 的工作原理（略） 工作流程：由各个 Slot 插槽组成（责任链模式） p229 Spring Cloud Sentinel 工作原理（略） starter 自动装配 p232 Sentinel 核心源码分析（略） sentinel-adapter sentinel-core sentinel-dashboard sentinel-demo sentinel-extension sentinel-transport 1 限流的源码实现 2 实时指标数据统计 3 服务降级的实现原理 什么是分布式事务？ 事务：作为单个逻辑工作单元执行的多个数据库操作，要么同时成功，要么同时失败，必须满足 ACID 特性。（单库多表）\n在微服务架构下，随着业务服务的拆分及数据库的拆分，举例说，订单和库存分别拆分成两个独立的数据库，当客户端发起一个下单操作，需要在订单服务对应的数据库创建订单，同时基于 RPC 通信调用库存服务完成商品库存的扣减。\n这样，原来的单库事务操作就变成了多个数据库的事务操作 =\u0026gt; 数据不一致问题。\n1 分布式事务问题的理论模型 核心原因：存储资源的分布性\n在实际应用中，应该尽可能从设计层面去避免分布式事务的问题。\n1 X/Open 分布式模型 X/Open DTP 是 X/Open 这个组织定义的一套分布式事务的标准。这个标准提出了两阶段提交（2PC，2-phase-commit）来保证分布式事务的完整性。X/Open DTP 包含以下三种角色。\nAP：Application RM：Resource Manager TM：Transaction Manager 如果 TM 需要能够管理多个数据库的事务，则实现步骤如下：\n配置 TM，把多个 RM 注册到 TM，相当于 TM 注册 RM 作为数据源。 AP 从 TM 管理的 RM 中获取连接，如果 RM 是数据库则获取 JDBC 连接。 AP 向 TM 发起一个全局事务，生成全局事务 ID（XID），XID 会通知各个 RM。 AP 通过第二步获得的连接直接操作 RM 完成数据库操作。这时，AP 在每次操作会把 XID 传递给 RM。 AP 结束全局事务，TM 会通知各个 RM 全局事务结束。 根据各个 RM 的事务执行结果，执行提交或者回滚操作。 其中，TM 和多个 RM 之间的事务控制，是基于 XA 协议来完成的。目前 Oracle、MySQL、DB2 都实现了 XA 接口，因此都能作为 RM。\n2 两阶段提交协议 第一阶段：事务的准备阶段\n第二阶段：事务的提交或回滚阶段\n这两个阶段都是由事务管理器发起的，流程如下：\n准备阶段：TM 通知 RM 准备分支事务，记录事务日志，并告知 TM 的准备结果。 提交/回滚阶段：如果所有的 RM 在准备阶段都明确返回成功，TM 向所有 RM 发起提交指令完成数据的变更；反之，则 TM 向所有 RM 发送回滚指令。 然而，它并不是完美的，也有缺点：\n同步阻塞：所有 RM 都是事务阻塞型的，对于任何一次指令都必须要有明确的响应才能进行下一步，否则会处于阻塞状态。 过于保守：任何一个节点失败都会导致数据回滚。 TM 的单点故障：如果 TM 在第二阶段故障，则所有 RM 会一直处于锁定状态。 “脑裂”导致数据不一致问题：在第二阶段中，TM 向所有 RM 发送 commit 请求后，发生局部网络异常导致只有一部分 RM 接受到 commit，剩余未收到请求的则没提交，导致数据出现不一致问题。 3 三阶段提交协议 利用超时机制解决了同步阻塞的问题\nCanCommit（询问阶段）：TM 向 RM 发送事务执行请求，询问是否可以完成指令，参与者只需回答是或者不是即可，不需要做真正的事务操作，这个阶段会有超时中止机制。 PreCommit（准备阶段）：TM 根据 RM 的反馈结果决定是否继续，如果在询问阶段所有 RM 都能执行操作，则 TM 向所有 RM 发送 PreCommit 请求，RM 收到请求后写 redo 和 undo 日志，执行事务操作但是不提交事务，然后返回 ACK 响应等待 TM 的下一步通知。如果询问阶段任意参与者返回不能执行操作的结果，则 TM 发送事务中断请求。 DoCommit（提交或回滚阶段）：根据上一步骤的执行结果，如果每个 RM 都返回成功，则 TM 发送事务提交指令，反之则中止。 三阶段提交协议与二阶段提交协议的区别\n增加了一个 CanCommit 阶段，可以尽早发现无法执行操作而中止后续的行为。 在准备阶段之后，TM 和 RM 都引入超时机制，一旦超时，TM 和 RM 会继续提交事务，并且认为处于成功状态，因为这种情况下事务默认为成功的可能性比较大。 实际上，一旦超时，在三阶段提交协议下仍然可能出现数据不一致的问题，当然概率是比较小的。另外，最大的好处是基于超时机制来避免资源的永久锁定。\n4 CAP 定理和 BASE 理论 XA 协议：二阶段提交和三阶段提交，数据一致性强，但可用性低。\nCAP 定理：布鲁尔定理，指在分布式系统中不可能同时满足一致性 C、可用性 A、分区容错性 P，最多同时满足两个。\nC：数据在多个副本中要保持强一致 A：系统对外提供的服务必须一直处于可用状态。 P：在分布式系统中遇到任何网络分区故障，系统仍然能够正常对外提供服务。 在分布式系统中，要么满足 CP，要么满足 AP，不可能实现 CAP 或者 CA，因为网络通信不是绝对可靠的。\nAP：放弃强一致性，实现最终的一致。（很多互联网公司的主要选择） CP：放弃高可用性，实现强一致性。（2PC 和 3PC，存在问题：用户完成一个操作可能会等待较长的时间，用户体验差） BASE 理论：由于 CAP 中 CA 不可兼得衍生出来的一种新的思想。核心思想是：牺牲数据的强一致性来获得高可用性，有三个特性：\nBasically Avaliable（基本可用）：分布式系统出现故障时，允许损失一部分功能的可用性，保证核心功能的可用。 Soft State（软状态）：允许系统中的数据存在中间状态，这个状态不影响系统的可用性，也就是允许系统中不同节点的数据副本之间的同步存在延时。 Eventually Consistent（最终一致性）：中间状态的数据在经过一段时间之后，会达到一个最终的数据一致性。 2 分布式事务问题的常见解决方案 1 TCC 补偿性方案 TCC（Try-Confirm-Cancel）是一种比较成熟的分布式数据一致性解决方案，它实际上是把一个完整的业务拆分为如下三个步骤\nTry：这个阶段主要是对数据的校验或者资源的预留。 Confirm：确定真正执行的任务，只操作 Try 阶段预留的资源。 Cancel：取消执行，释放 Try 阶段预留的资源。 本质：二阶段提交的思想，第一阶段通过 Try 准备，第二阶段通过 Confirm/Cancel\n2 基于可靠性消息的最终一致性方案 基于可靠性消息的最终一致性方案是互联网公司比较常用的分布式数据一致性解决方案，它主要利用消息中间件（Kafka、RocketMQ 或 RabbitMQ）的可靠性机制来实现数据一致性的投递。\n总结：消费者没有向消息中间件服务器发送确认之前，这个消息会被重复投递，确保消息的可靠性消费。\n3 最大努力通知型 与基于可靠性消息的最终一致性方案实现类似，是一种比较简单的柔性事务解决方案。\n如果没有返回一个消息确认时，则不断进行重试，直到收到一个消息确认或者达到最大重试次数。\n3 分布式事务框架 Seata 提供了 AT、TCC、Saga 和 XA 四种事务模式。\n1 AT 模式 Seata 最主推的分布式事务解决方案，基于 XA 演进而来，分为 TM、RM 和 TC，TC 作为 Seata 的服务器独立部署。\n2 Saga 模式 又称长事务解决方案，主要描述的是在没有 2PC 的情况下如何解决分布式事务问题。其核心思想是：把一个业务流程中的长事务拆分为多个本地短事务，业务流程中的每个参与者都提交真实提交给本地段事务，当其中一个参与者失败，则通过补偿机制补偿前面已经成功的参与者。\n两种补偿恢复方式：\n向后恢复：如果任一子事务失败，则撤销执行结果。 向前恢复：不进行补偿，而是对失败的事务进行 redo，这种方式比较适合于事务必须要执行成功的场景。 优点：\n一阶段直接提交本地事务 没有锁等待，性能较高 在事件驱动的模式下，短事务可以异步执行。 补偿机制的实现比较简单。 缺点：不提供原子性和隔离性支持\n协调模式：\n事件/编排式 命令/协同式 ","date":"2021-04-07T00:00:00Z","image":"https://cuterwrite-1302252842.file.myqcloud.com/blog/dolomites-5076492_1920.5srkr3iefto0.webp","permalink":"https://cuterwrite.top/p/spring-cloud-alibaba-1/","title":"Spring Cloud Alibaba 笔记"}]