[{"content":"Table of Contents generated with DocToc\n Stream常见用法  1 Stream概述 2 Stream创建  2.1 Collection.stream() 2.2 Arrays.stream(T[] array) 2.3 Stream.of / iterate / generate   3 Stream使用  3.1 Optional 3.2 遍历 forEach/find/match 3.3 筛选 filter 3.4 聚合 max/min/count 3.5 映射 map/flatMap 3.6 规约 reduce 3.7 收集 collect 3.8 分组 groupingBy/partitioningBy 3.9 连接 joining 3.10 排序 sorted       Stream常见用法 1 Stream概述 Stream将要处理的元素集合看作一种流，在流的过程中，借助Stream API对流中的元素进行操作，比如：筛选、排序、聚合等。\nStream可以由数组或集合创建，对流的操作分为两种：\n 中间操作，每次返回一个新的流，可以有多个。 终端操作，每个流只能进行一次终端操作，终端操作结束后流无法再次使用。终端操作会产生一个新的集合或值。  另外，Stream有几个特性：\n stream不存储数据，而是按照特定的规则对数据进行计算，一般会输出结果。 stream不会改变数据源，通常情况下会产生一个新的集合或一个值。 stream具有延迟执行特性，只有调用终端操作时，中间操作才会执行。  2 Stream创建 2.1 Collection.stream() List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); Stream\u0026lt;Integer\u0026gt; stream = list.stream(); //并行流 Stream\u0026lt;Integer\u0026gt; parallelStream = list.parallelStream(); 2.2 Arrays.stream(T[] array) int[] array = new int[]{1, 2, 3, 4, 5}; IntStream stream = Arrays.stream(array) 2.3 Stream.of / iterate / generate Stream\u0026lt;Integer\u0026gt; stream = Stream.of(1, 2, 3, 4, 5, 6);\r//创建从0开始，间距为3的stream（个数为4）\rStream\u0026lt;Integer\u0026gt; stream2 = Stream.iterate(0, x -\u0026gt; x + 3).limit(4);\r3 Stream使用 3.1 Optional Optional类是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。\n3.2 遍历 forEach/find/match   遍历输出符合条件的元素\nlist.stream().filter(x -\u0026gt; x \u0026gt; 6).forEach(System.out::println);   遍历对元素执行某个方法\nlist.stream().forEach(methodName);   匹配一个\nlist.stream().filter(x -\u0026gt; x \u0026gt; 6).findFirst();   是否包含特定条件的元素\nlist.stream().anyMatch(x -\u0026gt; x \u0026lt; 6);   所有元素满足条件\nlist.stream().allMatch(x -\u0026gt; x == 1);   3.3 筛选 filter 同上，直接在stream对象上使用就行\n3.4 聚合 max/min/count   获取int数组中中的最大值\nArrays.stream(array).max().getAsInt();   获取Integer列表中的最大值，需要传入一个Comparator对象\nlist.stream().max(Integer::compareTo).get();   获取String列里中长度最长的元素\nlist.stream().max(Comparator.comparing(String::length)).get();   获取员工列表工资最高的员工\nlist.stream().max(Comparator.comparing(Person::getSalary)).get();   计算Integer集合中大于6的元素的个数\nlist.stream().filter(x -\u0026gt; x \u0026gt; 6).count();   3.5 映射 map/flatMap 映射，可以将一个流的元素按照一定的映射规则映射到另一个流中。分为map和flatMap：\n map：接收一个函数作为参数，该函数会被应用到每个元素上，并将其映射成一个新的元素。 flatMap：接收一个函数作为参数，将流中的每个值都换成另一个流，然后把所有流连接成一个流。     将字符串数组的元素全部改成大写\nArrays.stream(array).map(String::toUpperCase).collect(Collectors.toList());   将员工薪资全部增加1000\nlist.stream().map(person -\u0026gt; { person.setSalary(person.getSalary() + 1000); return person; }).collect(Collectors.toList());   3.6 规约 reduce 将一个流缩减为一个值，能实现集合求和，求乘积和求最值操作等。\n  求Integer列表的元素之和，乘积和最大值\nlist.stream().reduce(Integer::sum).get(); list.stream().reduce((x,y) -\u0026gt; x + y).get(); list.stream().reduce((x,y) -\u0026gt; x * y).get();   3.7 收集 collect 就是把一个流收集起来，最终可以是收集成一个值也可以收集成一个新的集合。\ncollect主要依赖java.util.stream.Collectors类内置的静态方法。\n 归集：toList()，toSet()，toMap() 统计：counting、averagingInt、averagingLong、averagingDouble、maxBy、minBy、summingInt、summingLong、summingDouble、sumarizingInt、sumarizingLong、sumarizingDouble  3.8 分组 groupingBy/partitioningBy   将员工按薪资是否高于8000分组\nlist.stream().collect(Collectors.groupingBy(x -\u0026gt; x.getSalary() \u0026gt; 8000))   将员工按性别分组\nlist.stream().collect(Collectors.groupingBy(Person::getSex));   3.9 连接 joining 将stream中的元素用特定的连接符（没有的话，则直接连接）连接成一个字符串。\nlist.stream().collect(Collectors.joining(\u0026#34;,\u0026#34;)); 3.10 排序 sorted   按工资升序排序\nlist.stream().sorted(Compartor.comparing(Person::getSalary));   按工资倒序排序\nlist.stream().sorted(Compartor.comparing(Person::getSalary)).reversed();   多列排序\nlist.stream().sorted(Compartor.comparing(Person::getSalary).thenComparing(Person::getAge));   ","date":"2021-05-11T00:00:00Z","image":"https://cdn.jsdelivr.net/gh/PKUcoldkeyboard/image-hosting@master/20210503/bridge-5621201_1920.6p53ez4buso0.jpg","permalink":"https://cuterwrite.top/p/java-stream/","title":"Java-Stream常见用法"},{"content":"Table of Contents generated with DocToc\n JavaSE知识点笔记  1 数据类型  1.1 基本类型 1.2 包装类型 1.3 缓存池   2 String  2.1 概述 2.2 不可变的优点  2.2.1 可以缓存hash值 2.2.2 String Pool 2.2.3 安全性 2.2.4 线程安全   2.3 String、StringBuilder和StringBuffer  2.3.1 可变性 2.3.2 线程安全   2.4 String Pool 2.5 new String（“abc”）   3 运算  3.1 参数传递 3.2 float与double 3.3 隐式类型转换   4 关键字  4.1 final 4.2 static   5 Object通用方法 6 继承  6.1 访问权限 6.2 抽象类与接口 6.3 super 6.4 重写与重载   7 反射 8 异常 9 泛型、注解、新特性    JavaSE知识点笔记 1 数据类型 1.1 基本类型  byte/8 char/16 short/16 int/32 float/32 long/64 double/64 boolean/~  1.2 包装类型 基本类型都有对应的包装类型，基本类型与其对应的包装类型之间的赋值使用自动装箱与拆箱完成。\nInteger x = 2; // 装箱 调用了 Integer.valueOf(2) int y = x; // 拆箱 调用了 X.intValue() 1.3 缓存池 new Integer(123) 与 Integer.valueOf(123) 的区别在于：\n new Integer(123) 每次都会新建一个对象； Integer.valueOf(123) 会使用缓存池中的对象，多次调用会取得同一个对象的引用。  valueOf() 方法的实现比较简单，就是先判断值是否在缓存池中，如果在的话就直接返回缓存池的内容。\n在 Java 8 中，Integer 缓存池的大小默认为 -128~127。\n编译器会在自动装箱过程调用 valueOf() 方法，因此多个值相同且值在缓存池范围内的 Integer 实例使用自动装箱来创建，那么就会引用相同的对象。\n基本类型对应的缓冲池如下：\n boolean values true and false all byte values short values between -128 and 127 int values between -128 and 127 char in the range \\u0000 to \\u007F  2 String 2.1 概述 String 被声明为 final，因此它不可被继承。(Integer 等包装类也不能被继承）\n在 Java 8 中，String 内部使用 char 数组存储数据。\nprivate final char[] value; 在 Java 9 之后，String 类的实现改用 byte 数组存储字符串，同时使用 coder 来标识使用了哪种编码。\nprivate final byte[] value; private final byte coder; value 数组被声明为 final，这意味着 value 数组初始化之后就不能再引用其它数组。并且 String 内部没有改变 value 数组的方法，因此可以保证 String 不可变。\n2.2 不可变的优点 2.2.1 可以缓存hash值 因为 String 的 hash 值经常被使用，例如 String 用做 HashMap 的 key。不可变的特性可以使得 hash 值也不可变，因此只需要进行一次计算。\n2.2.2 String Pool 如果一个 String 对象已经被创建过了，那么就会从 String Pool 中取得引用。只有 String 是不可变的，才可能使用 String Pool。\n2.2.3 安全性 String 经常作为参数，String 不可变性可以保证参数不可变。例如在作为网络连接参数的情况下如果 String 是可变的，那么在网络连接过程中，String 被改变，改变 String 的那一方以为现在连接的是其它主机，而实际情况却不一定是。\n2.2.4 线程安全 String 不可变性天生具备线程安全，可以在多个线程中安全地使用。\n2.3 String、StringBuilder和StringBuffer 2.3.1 可变性  String不可变 StringBuilder和StringBuffer可变  2.3.2 线程安全  String线程安全 StringBuilder线程不安全 StringBuffer线程安全：synchronized机制  2.4 String Pool 字符串常量池（String Pool）保存着所有字符串字面量（literal strings），这些字面量在编译时期就确定。不仅如此，还可以使用 String 的 intern() 方法在运行过程将字符串添加到 String Pool 中。\n当一个字符串调用 intern() 方法时，如果 String Pool 中已经存在一个字符串和该字符串值相等（使用 equals() 方法进行确定），那么就会返回 String Pool 中字符串的引用；否则，就会在 String Pool 中添加一个新的字符串，并返回这个新字符串的引用。\n在 Java 7 之前，String Pool 被放在运行时常量池中，它属于永久代。而在 Java 7，String Pool 被移到堆中。这是因为永久代的空间有限，在大量使用字符串的场景下会导致 OutOfMemoryError 错误。\n2.5 new String（“abc”） 使用这种方式一共会创建两个字符串对象（前提是 String Pool 中还没有 \u0026ldquo;abc\u0026rdquo; 字符串对象）。\n \u0026ldquo;abc\u0026rdquo; 属于字符串字面量，因此编译时期会在 String Pool 中创建一个字符串对象，指向这个 \u0026ldquo;abc\u0026rdquo; 字符串字面量； 而使用 new 的方式会在堆中创建一个字符串对象。  3 运算 3.1 参数传递 Java 的参数是以值传递的形式传入方法中，而不是引用传递。\n3.2 float与double Java 不能隐式执行向下转型，因为这会使得精度降低。\n3.3 隐式类型转换 使用+=和++运算符会执行隐式类型转换，相当于强制类型转换。\n（比如：int转short）\n4 关键字 4.1 final （1）数据\n声明数据为常量，可以是编译时常量，也可以是在运行时被初始化后不能被改变的常量。\n 对于基本类型，final 使数值不变； 对于引用类型，final 使引用不变，也就不能引用其它对象，但是被引用的对象本身是可以修改的。  （2）方法\n声明方法不能被子类重写。\nprivate 方法隐式地被指定为 final，如果在子类中定义的方法和基类中的一个 private 方法签名相同，此时子类的方法不是重写基类方法，而是在子类中定义了一个新的方法。\n（3）类\n声明类不允许被继承。\n4.2 static 1. 静态变量\n 静态变量：又称为类变量，也就是说这个变量属于类的，类所有的实例都共享静态变量，可以直接通过类名来访问它。静态变量在内存中只存在一份。 实例变量：每创建一个实例就会产生一个实例变量，它与该实例同生共死。  2. 静态方法\n静态方法在类加载的时候就存在了，它不依赖于任何实例。所以静态方法必须有实现，也就是说它不能是抽象方法。\n3. 静态语句块\n静态语句块在类初始化时运行一次。\n4. 静态内部类\n非静态内部类依赖于外部类的实例，也就是说需要先创建外部类实例，才能用这个实例去创建非静态内部类。而静态内部类不需要。\n5. 静态导包\n在使用静态变量和方法时不用再指明 ClassName，从而简化代码，但可读性大大降低。\n6. 初始化顺序\n静态变量和静态语句块优先于实例变量和普通语句块，静态变量和静态语句块的初始化顺序取决于它们在代码中的顺序。\n5 Object通用方法  hashcode equals clone toString getClass finalize notify notifyAll wait  6 继承 6.1 访问权限 private、protected、public，以及default（如果不加访问修饰符，表示包级可见。）\n可以对类或类中的成员（字段和方法）加上访问修饰符。\n 类可见表示其它类可以用这个类创建实例对象。 成员可见表示其它类可以用这个类的实例对象访问到该成员；  protected 用于修饰成员，表示在继承体系中成员对于子类可见，但是这个访问修饰符对于类没有意义。\n6.2 抽象类与接口 1. 抽象类\n抽象类和抽象方法都使用 abstract 关键字进行声明。如果一个类中包含抽象方法，那么这个类必须声明为抽象类。\n抽象类和普通类最大的区别是，抽象类不能被实例化，只能被继承。\n2. 接口\n接口是抽象类的延伸，在 Java 8 之前，它可以看成是一个完全抽象的类，也就是说它不能有任何的方法实现。\n从 Java 8 开始，接口也可以拥有默认的方法实现，这是因为不支持默认方法的接口的维护成本太高了。在 Java 8 之前，如果一个接口想要添加新的方法，那么要修改所有实现了该接口的类，让它们都实现新增的方法。\n接口的成员（字段 + 方法）默认都是 public 的，并且不允许定义为 private 或者 protected。从 Java 9 开始，允许将方法定义为 private，这样就能定义某些复用的代码又不会把方法暴露出去。\n接口的字段默认都是 static 和 final 的。\n6.3 super  访问父类的构造函数：可以使用 super() 函数访问父类的构造函数，从而委托父类完成一些初始化的工作。应该注意到，子类一定会调用父类的构造函数来完成初始化工作，一般是调用父类的默认构造函数，如果子类需要调用父类其它构造函数，那么就可以使用 super() 函数。 访问父类的成员：如果子类重写了父类的某个方法，可以通过使用 super 关键字来引用父类的方法实现。  6.4 重写与重载 1. 重写（Override）\n存在于继承体系中，指子类实现了一个与父类在方法声明上完全相同的一个方法。\n为了满足里式替换原则，重写有以下三个限制：\n 子类方法的访问权限必须大于等于父类方法； 子类方法的返回类型必须是父类方法返回类型或为其子类型。 子类方法抛出的异常类型必须是父类抛出异常类型或为其子类型。  使用 @Override 注解，可以让编译器帮忙检查是否满足上面的三个限制条件。\n2. 重载（Overload）\n存在于同一个类中，指一个方法与已经存在的方法名称上相同，但是参数类型、个数、顺序至少有一个不同。\n应该注意的是，返回值不同，其它都相同不算是重载。\n7 反射 每个类都有一个 Class 对象，包含了与类有关的信息。当编译一个新类时，会产生一个同名的 .class 文件，该文件内容保存着 Class 对象。\n类加载相当于 Class 对象的加载，类在第一次使用时才动态加载到 JVM 中。也可以使用 Class.forName(\u0026quot;com.mysql.jdbc.Driver\u0026quot;) 这种方式来控制类的加载，该方法会返回一个 Class 对象。\n反射可以提供运行时的类信息，并且这个类可以在运行时才加载进来，甚至在编译时期该类的 .class 不存在也可以加载进来。\nClass 和 java.lang.reflect 一起对反射提供了支持，java.lang.reflect 类库主要包含了以下三个类：\n Field ：可以使用 get() 和 set() 方法读取和修改 Field 对象关联的字段； Method ：可以使用 invoke() 方法调用与 Method 对象关联的方法； Constructor ：可以用 Constructor 的 newInstance() 创建新的对象。  反射的优点：\n 可扩展性 ：应用程序可以利用全限定名创建可扩展对象的实例，来使用来自外部的用户自定义类。 类浏览器和可视化开发环境 ：一个类浏览器需要可以枚举类的成员。可视化开发环境（如 IDE）可以从利用反射中可用的类型信息中受益，以帮助程序员编写正确的代码。 调试器和测试工具 ： 调试器需要能够检查一个类里的私有成员。测试工具可以利用反射来自动地调用类里定义的可被发现的 API 定义，以确保一组测试中有较高的代码覆盖率。  反射的缺点：\n尽管反射非常强大，但也不能滥用。如果一个功能可以不用反射完成，那么最好就不用。在我们使用反射技术时，下面几条内容应该牢记于心。\n 性能开销 ：反射涉及了动态类型的解析，所以 JVM 无法对这些代码进行优化。因此，反射操作的效率要比那些非反射操作低得多。我们应该避免在经常被执行的代码或对性能要求很高的程序中使用反射。 安全限制 ：使用反射技术要求程序必须在一个没有安全限制的环境中运行。如果一个程序必须在有安全限制的环境中运行，如 Applet，那么这就是个问题了。 内部暴露 ：由于反射允许代码执行一些在正常情况下不被允许的操作（比如访问私有的属性和方法），所以使用反射可能会导致意料之外的副作用，这可能导致代码功能失调并破坏可移植性。反射代码破坏了抽象性，因此当平台发生改变的时候，代码的行为就有可能也随着变化。  8 异常 Throwable 可以用来表示任何可以作为异常抛出的类，分为两种： Error 和 Exception。其中 Error 用来表示 JVM 无法处理的错误，Exception 分为两种：\n 受检异常 ：需要用 try\u0026hellip;catch\u0026hellip; 语句捕获并进行处理，并且可以从异常中恢复； 非受检异常 ：是程序运行时错误，例如除 0 会引发 Arithmetic Exception，此时程序崩溃并且无法恢复。  9 泛型、注解、新特性 略。\n 本文转载自：https://github.com/CyC2018/CS-Notes，用于个人复习。\n","date":"2021-05-04T00:00:00Z","image":"https://cdn.jsdelivr.net/gh/PKUcoldkeyboard/image-hosting@master/20210503/river-6021951_1920.4hwe8w8ugb20.jpg","permalink":"https://cuterwrite.top/p/java-se/","title":"JavaSE知识点笔记"},{"content":"Table of Contents generated with DocToc\n Java容器知识点笔记  1 概述  1.1 Collection  1.1.1 Set 1.1.2 List 1.1.3 Queue     2 源码分析  2.1 ArrayList  2.1.1 概述 2.1.2 扩容 2.1.3 删除元素 2.1.4 序列化 2.1.5 Fail-fast   2.2 Vector  2.2.1 同步 2.2.2 扩容 2.2.3 与ArrayList的比较 2.2.4 替代方案   2.3 CopyOnWriteArrayList  2.3.1 读写分离 2.3.2 适用场景   2.4 LinkedList  2.4.1 概述 2.4.2 与ArrayList的比较   2.5 HashMap  2.5.1 概述 2.5.2 拉链法 2.5.3 确认桶下标方法 2.5.4 扩容基本原理 2.5.5 扩容重新计算桶下标 2.5.6 与HashTable对比   2.6 ConcurrentHashMap  2.6.1 存储结构 2.6.2 size操作 2.6.3 jdk8的改动   2.7 LinkedHashMap  2.7.1 存储结构 2.7.2 afterNodeAccess() 2.7.3 afterNodeInsertion()        Java容器知识点笔记 1 概述 容器主要包括 Collection 和 Map 两种，Collection 存储着对象的集合，而 Map 存储着键值对（两个对象）的映射表。\n1.1 Collection 1.1.1 Set   TreeSet：基于红黑树实现，支持有序性操作，例如根据一个范围查找元素的操作。但是查找效率不如 HashSet，HashSet 查找的时间复杂度为 O(1)，TreeSet 则为 O(logN)。\n  HashSet：基于哈希表实现，支持快速查找，但不支持有序性操作。并且失去了元素的插入顺序信息，也就是说使用 Iterator 遍历 HashSet 得到的结果是不确定的。\n  LinkedHashSet：具有 HashSet 的查找效率，并且内部使用双向链表维护元素的插入顺序。\n  1.1.2 List   ArrayList：基于动态数组实现，支持随机访问。\n  Vector：和 ArrayList 类似，但它是线程安全的。\n  LinkedList：基于双向链表实现，只能顺序访问，但是可以快速地在链表中间插入和删除元素。不仅如此，LinkedList 还可以用作栈、队列和双向队列。\n  1.1.3 Queue  LinkedList：可以用它来实现双向队列。 PriorityQueue：基于堆结构实现，可以用它来实现优先队列。  2 源码分析 2.1 ArrayList 2.1.1 概述 因为 ArrayList 是基于数组实现的，所以支持快速随机访问。RandomAccess 接口标识着该类支持快速随机访问，默认容量为10\ntransient Object[] elementData; private static final int DEFAULT_CAPACITY = 10; 2.1.2 扩容 添加元素时使用 ensureCapacityInternal() 方法来保证容量足够，如果不够时，需要使用 grow() 方法进行扩容，新容量的大小为 oldCapacity + (oldCapacity \u0026gt;\u0026gt; 1)，即 oldCapacity+oldCapacity/2。其中 oldCapacity \u0026raquo; 1 需要取整，所以新容量大约是旧容量的 1.5 倍左右。（oldCapacity 为偶数就是 1.5 倍，为奇数就是 1.5 倍-0.5）\n扩容操作需要调用 Arrays.copyOf() 把原数组整个复制到新数组中，这个操作代价很高，因此最好在创建 ArrayList 对象时就指定大概的容量大小，减少扩容操作的次数。\n2.1.3 删除元素 需要调用 System.arraycopy() 将 index+1 后面的元素都复制到 index 位置上，该操作的时间复杂度为 O(N)，可以看到 ArrayList 删除元素的代价是非常高的。\n2.1.4 序列化 ArrayList 基于数组实现，并且具有动态扩容特性，因此保存元素的数组不一定都会被使用，那么就没必要全部进行序列化。\n保存元素的数组 elementData 使用 transient 修饰，该关键字声明数组默认不会被序列化。\nArrayList 实现了 writeObject() 和 readObject() 来控制只序列化数组中有元素填充那部分内容。\n序列化时需要使用 ObjectOutputStream 的 writeObject() 将对象转换为字节流并输出。而 writeObject() 方法在传入的对象存在 writeObject() 的时候会去反射调用该对象的 writeObject() 来实现序列化。反序列化使用的是 ObjectInputStream 的 readObject() 方法，原理类似。\n2.1.5 Fail-fast modCount 用来记录 ArrayList 结构发生变化的次数。结构发生变化是指添加或者删除至少一个元素的所有操作，或者是调整内部数组的大小，仅仅只是设置元素的值不算结构发生变化。\n在进行序列化或者迭代等操作时，需要比较操作前后 modCount 是否改变，如果改变了需要抛出 ConcurrentModificationException。代码参考上节序列化中的 writeObject() 方法。\n2.2 Vector 2.2.1 同步 它的实现与 ArrayList 类似，但是使用了 synchronized 进行同步。\n2.2.2 扩容 Vector 的构造函数可以传入 capacityIncrement 参数，它的作用是在扩容时使容量 capacity 增长 capacityIncrement。如果这个参数的值小于等于 0，扩容时每次都令 capacity 为原来的两倍。\n调用没有 capacityIncrement 的构造函数时，capacityIncrement 值被设置为 0，也就是说默认情况下 Vector 每次扩容时容量都会翻倍。\n2.2.3 与ArrayList的比较  Vector 是同步的，因此开销就比 ArrayList 要大，访问速度更慢。最好使用 ArrayList 而不是 Vector，因为同步操作完全可以由程序员自己来控制； Vector 每次扩容请求其大小的 2 倍（也可以通过构造函数设置增长的容量），而 ArrayList 是 1.5 倍。  2.2.4 替代方案 可以使用 Collections.synchronizedList(); 得到一个线程安全的 ArrayList。\n也可以使用 concurrent 并发包下的 CopyOnWriteArrayList 类。\n2.3 CopyOnWriteArrayList 2.3.1 读写分离 写操作在一个复制的数组上进行，读操作还是在原始数组中进行，读写分离，互不影响。\n写操作需要加锁，防止并发写入时导致写入数据丢失。\n写操作结束之后需要把原始数组指向新的复制数组。\n2.3.2 适用场景 CopyOnWriteArrayList 在写操作的同时允许读操作，大大提高了读操作的性能，因此很适合读多写少的应用场景。\n但是 CopyOnWriteArrayList 有其缺陷：\n 内存占用：在写操作时需要复制一个新的数组，使得内存占用为原来的两倍左右； 数据不一致：读操作不能读取实时性的数据，因为部分写操作的数据还未同步到读数组中。  所以 CopyOnWriteArrayList 不适合内存敏感以及对实时性要求很高的场景。\n2.4 LinkedList 2.4.1 概述 基于双向链表实现，使用 Node 存储链表节点信息。\nprivate static class Node\u0026lt;E\u0026gt; { E item; Node\u0026lt;E\u0026gt; next; Node\u0026lt;E\u0026gt; prev; } 每个链表存储了 first 和 last 指针：\ntransient Node\u0026lt;E\u0026gt; first; transient Node\u0026lt;E\u0026gt; last; 2.4.2 与ArrayList的比较 ArrayList 基于动态数组实现，LinkedList 基于双向链表实现。ArrayList 和 LinkedList 的区别可以归结为数组和链表的区别：\n 数组支持随机访问，但插入删除的代价很高，需要移动大量元素； 链表不支持随机访问，但插入删除只需要改变指针。  2.5 HashMap 2.5.1 概述  基于数组+链表+红黑树实现  transient Node\u0026lt;K,V\u0026gt;[] table;  默认容量16，每次扩容为2倍 默认负载因子为0.75 当链表长度大于等于8时，检查table长度是否大于64，如果是则转成红黑树。 基本原理：通过key的hashcode经过扰动处理得到hash值，然后通过(n - 1) \u0026amp; hash判断当前元素存放的位置，如果当前位置存在元素的话，就判断该元素与要存放的元素的hash值以及key是否相同，如果相同则直接覆盖，不相同就用拉链法解决冲突。  2.5.2 拉链法 将链表和数组相结合。也就是说创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可。\n2.5.3 确认桶下标方法  计算key的hash（h = key.hashcode(); h ^ (h \u0026raquo;\u0026gt; 16)） hash \u0026amp; (n - 1)  2.5.4 扩容基本原理 设 HashMap 的 table 长度为 M，需要存储的键值对数量为 N，如果哈希函数满足均匀性的要求，那么每条链表的长度大约为 N/M，因此查找的复杂度为 O(N/M)。\n为了让查找的成本降低，应该使 N/M 尽可能小，因此需要保证 M 尽可能大，也就是说 table 要尽可能大。HashMap 采用动态扩容来根据当前的 N 值来调整 M 值，使得空间效率和时间效率都能得到保证。\n扩容使用 resize() 实现，需要注意的是，扩容操作同样需要把 oldTable 的所有键值对重新插入 newTable 中，因此这一步是很费时的。\n2.5.5 扩容重新计算桶下标 在进行扩容时，需要把键值对重新计算桶下标，从而放到对应的桶上。在前面提到，HashMap 使用 hash%capacity 来确定桶下标。HashMap capacity 为 2 的 n 次方这一特点能够极大降低重新计算桶下标操作的复杂度。\n2.5.6 与HashTable对比  Hashtable 使用 synchronized 来进行同步。 HashMap 可以插入键为 null 的 Entry。 HashMap 的迭代器是 fail-fast 迭代器。 HashMap 不能保证随着时间的推移 Map 中的元素次序是不变的。  2.6 ConcurrentHashMap 2.6.1 存储结构 ConcurrentHashMap 和 HashMap 实现上类似，最主要的差别是 ConcurrentHashMap 采用了分段锁（Segment），每个分段锁维护着几个桶（HashEntry），多个线程可以同时访问不同分段锁上的桶，从而使其并发度更高（并发度就是 Segment 的个数）。\nSegment 继承自 ReentrantLock。\n默认的并发级别为 16，也就是说默认创建 16 个 Segment。\n2.6.2 size操作 每个 Segment 维护了一个 count 变量来统计该 Segment 中的键值对个数。\n在执行 size 操作时，需要遍历所有 Segment 然后把 count 累计起来。\nConcurrentHashMap 在执行 size 操作时先尝试不加锁，如果连续两次不加锁操作得到的结果一致，那么可以认为这个结果是正确的。\n尝试次数使用 RETRIES_BEFORE_LOCK 定义，该值为 2，retries 初始值为 -1，因此尝试次数为 3。\n如果尝试的次数超过 3 次，就需要对每个 Segment 加锁。\n2.6.3 jdk8的改动 JDK 1.7 使用分段锁机制来实现并发更新操作，核心类为 Segment，它继承自重入锁 ReentrantLock，并发度与 Segment 数量相等。\nJDK 1.8 使用了 CAS 操作来支持更高的并发度，在 CAS 操作失败时使用内置锁 synchronized。\n并且 JDK 1.8 的实现也在链表过长时会转换为红黑树。\n2.7 LinkedHashMap 2.7.1 存储结构 继承自 HashMap，因此具有和 HashMap 一样的快速查找特性。\n内部维护了一个双向链表，用来维护插入顺序或者 LRU 顺序。\ntransient LinkedHashMap.Entry\u0026lt;K,V\u0026gt; head; transient LinkedHashMap.Entry\u0026lt;K,V\u0026gt; tail; accessOrder 决定了顺序，默认为 false，此时维护的是插入顺序。\nfinal boolean accessOrder; LinkedHashMap 最重要的是以下用于维护顺序的函数，它们会在 put、get 等方法中调用。\nvoid afterNodeAccess(Node\u0026lt;K,V\u0026gt; p) { } void afterNodeInsertion(boolean evict) { } 2.7.2 afterNodeAccess() 当一个节点被访问时，如果 accessOrder 为 true，则会将该节点移到链表尾部。也就是说指定为 LRU 顺序之后，在每次访问一个节点时，会将这个节点移到链表尾部，保证链表尾部是最近访问的节点，那么链表首部就是最近最久未使用的节点。\n2.7.3 afterNodeInsertion() 在 put 等操作之后执行，当 removeEldestEntry() 方法返回 true 时会移除最晚的节点，也就是链表首部节点 first。\nevict 只有在构建 Map 的时候才为 false，在这里为 true。\n 本文转载自：https://github.com/CyC2018/CS-Notes，用于个人复习。\n","date":"2021-05-04T00:00:00Z","image":"https://cdn.jsdelivr.net/gh/PKUcoldkeyboard/image-hosting@master/20210503/antarctica-1987579_1920.4sf6q29twew0.jpg","permalink":"https://cuterwrite.top/p/java-collection/","title":"Java容器知识点笔记"},{"content":"Table of Contents generated with DocToc\n Java并发知识点笔记  1 使用线程的方法 2 基础线程机制  2.1 Executor 2.2 Daemon 2.3 sleep() 2.4 yield()   3 线程中断  3.1 InterruptedException 3.2 interrupted() 3.3 Executor 的中断操作   4 互斥锁  4.1 synchronized 4.2 ReentrantLock 4.3 比较 4.4 选择   5 线程协作  5.1 join 5.2 wait/notify 5.3 await/signal   6 线程状态 7 JUC包/AQS  7.1 CountDownLatch 7.2 CyclicBarrier 7.3 Semaphore   8 JUC包其它组件  8.1 FutureTask 8.2 BlockingQueue 8.3 ForkJoin   9 内存模型  9.1 主内存与工作内存 9.2 内存间交互操作 9.3 内存模型三大特性  9.3.1. 原子性 9.3.2. 可见性 9.3.3. 有序性   9.4 先行发生原则   10 线程安全策略  10.1 不可变 10.2 互斥同步 10.3 非阻塞同步 10.4 无同步  10.4.1 栈封闭 10.4.2 线程本地存储 10.4.3 可重入代码     11 锁优化  11.1 自旋锁 11.2 锁消除 11.3 锁粗化 11.4 轻量级锁 11.5 偏向锁      Java并发知识点笔记 1 使用线程的方法  实现 Runnable 接口； 实现 Callable 接口； 继承 Thread 类。  2 基础线程机制 2.1 Executor Executor 管理多个异步任务的执行，而无需程序员显式地管理线程的生命周期。这里的异步是指多个任务的执行互不干扰，不需要进行同步操作。\n主要有三种 Executor：\n CachedThreadPool：一个任务创建一个线程； FixedThreadPool：所有任务只能使用固定大小的线程； SingleThreadExecutor：相当于大小为 1 的 FixedThreadPool。  2.2 Daemon 守护线程是程序运行时在后台提供服务的线程，不属于程序中不可或缺的部分。\n当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。\nmain() 属于非守护线程。\n在线程启动之前使用 setDaemon() 方法可以将一个线程设置为守护线程。\n2.3 sleep() Thread.sleep(millisec) 方法会休眠当前正在执行的线程，millisec 单位为毫秒。\nsleep() 可能会抛出 InterruptedException，因为异常不能跨线程传播回 main() 中，因此必须在本地进行处理。线程中抛出的其它异常也同样需要在本地进行处理。\n2.4 yield() 对静态方法 Thread.yield() 的调用声明了当前线程已经完成了生命周期中最重要的部分，可以切换给其它线程来执行。该方法只是对线程调度器的一个建议，而且也只是建议具有相同优先级的其它线程可以运行。\n3 线程中断 一个线程执行完毕之后会自动结束，如果在运行过程中发生异常也会提前结束。\n3.1 InterruptedException 通过调用一个线程的 interrupt() 来中断该线程，如果该线程处于阻塞、限期等待或者无限期等待状态，那么就会抛出 InterruptedException，从而提前结束该线程。但是不能中断 I/O 阻塞和 synchronized 锁阻塞。\n3.2 interrupted() 如果一个线程的 run() 方法执行一个无限循环，并且没有执行 sleep() 等会抛出 InterruptedException 的操作，那么调用线程的 interrupt() 方法就无法使线程提前结束。\n但是调用 interrupt() 方法会设置线程的中断标记，此时调用 interrupted() 方法会返回 true。因此可以在循环体中使用 interrupted() 方法来判断线程是否处于中断状态，从而提前结束线程。\n3.3 Executor 的中断操作 调用 Executor 的 shutdown() 方法会等待线程都执行完毕之后再关闭，但是如果调用的是 shutdownNow() 方法，则相当于调用每个线程的 interrupt() 方法。\n4 互斥锁 Java 提供了两种锁机制来控制多个线程对共享资源的互斥访问，第一个是 JVM 实现的 synchronized，而另一个是 JDK 实现的 ReentrantLock。\n4.1 synchronized  同步代码块：锁对象 同步一个方法：锁对象 同步一个类：锁整个类 同步一个静态方法：锁整个类  4.2 ReentrantLock ReentrantLock 是 java.util.concurrent（J.U.C）包中的锁。\n通过lock和unlock操作\n4.3 比较 1. 锁的实现\nsynchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的。\n2. 性能\n新版本 Java 对 synchronized 进行了很多优化，例如自旋锁等，synchronized 与 ReentrantLock 大致相同。\n3. 等待可中断\n当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。\nReentrantLock 可中断，而 synchronized 不行。\n4. 公平锁\n公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。\nsynchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但是也可以是公平的。\n5. 锁绑定多个条件\n一个 ReentrantLock 可以同时绑定多个 Condition 对象。\n4.4 选择 除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。这是因为 synchronized 是 JVM 实现的一种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。\n5 线程协作 5.1 join 在线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是忙等待，直到目标线程结束。\n5.2 wait/notify 调用 wait() 使得线程等待某个条件满足，线程在等待时会被挂起，当其他线程的运行使得这个条件满足时，其它线程会调用 notify() 或者 notifyAll() 来唤醒挂起的线程。\n它们都属于 Object 的一部分，而不属于 Thread。\n只能用在同步方法或者同步控制块中使用，否则会在运行时抛出 IllegalMonitorStateException。\n使用 wait() 挂起期间，线程会释放锁。这是因为，如果没有释放锁，那么其它线程就无法进入对象的同步方法或者同步控制块中，那么就无法执行 notify() 或者 notifyAll() 来唤醒挂起的线程，造成死锁\nwait() 和 sleep() 的区别\n wait() 是 Object 的方法，而 sleep() 是 Thread 的静态方法； wait() 会释放锁，sleep() 不会。  5.3 await/signal java.util.concurrent 类库中提供了 Condition 类来实现线程之间的协调，可以在 Condition 上调用 await() 方法使线程等待，其它线程调用 signal() 或 signalAll() 方法唤醒等待的线程。\n相比于 wait() 这种等待方式，await() 可以指定等待的条件，因此更加灵活。\n使用 Lock 来获取一个 Condition 对象。\n6 线程状态  new runable blocked waiting timed_waiting terminated  7 JUC包/AQS 7.1 CountDownLatch 用来控制一个或者多个线程等待多个线程。\n维护了一个计数器 cnt，每次调用 countDown() 方法会让计数器的值减 1，减到 0 的时候，那些因为调用 await() 方法而在等待的线程就会被唤醒。\n7.2 CyclicBarrier 用来控制多个线程互相等待，只有当多个线程都到达时，这些线程才会继续执行。\n和 CountdownLatch 相似，都是通过维护计数器来实现的。线程执行 await() 方法之后计数器会减 1，并进行等待，直到计数器为 0，所有调用 await() 方法而在等待的线程才能继续执行。\nCyclicBarrier 和 CountdownLatch 的一个区别是，CyclicBarrier 的计数器通过调用 reset() 方法可以循环使用，所以它才叫做循环屏障。\nCyclicBarrier 有两个构造函数，其中 parties 指示计数器的初始值，barrierAction 在所有线程都到达屏障的时候会执行一次。\n7.3 Semaphore Semaphore 类似于操作系统中的信号量，可以控制对互斥资源的访问线程数。\n8 JUC包其它组件 8.1 FutureTask 在介绍 Callable 时我们知道它可以有返回值，返回值通过 Future\u0026lt;V\u0026gt; 进行封装。FutureTask 实现了 RunnableFuture 接口，该接口继承自 Runnable 和 Future\u0026lt;V\u0026gt; 接口，这使得 FutureTask 既可以当做一个任务执行，也可以有返回值。\nFutureTask 可用于异步获取执行结果或取消执行任务的场景。当一个计算任务需要执行很长时间，那么就可以用 FutureTask 来封装这个任务，主线程在完成自己的任务之后再去获取结果。\n8.2 BlockingQueue java.util.concurrent.BlockingQueue 接口有以下阻塞队列的实现：\n FIFO 队列 ：LinkedBlockingQueue、ArrayBlockingQueue（固定长度） 优先级队列 ：PriorityBlockingQueue  提供了阻塞的 take() 和 put() 方法：如果队列为空 take() 将阻塞，直到队列中有内容；如果队列为满 put() 将阻塞，直到队列有空闲位置。\n8.3 ForkJoin 主要用于并行计算中，和 MapReduce 原理类似，都是把大的计算任务拆分成多个小任务并行计算。\nForkJoinPool 实现了工作窃取算法来提高 CPU 的利用率。每个线程都维护了一个双端队列，用来存储需要执行的任务。工作窃取算法允许空闲的线程从其它线程的双端队列中窃取一个任务来执行。窃取的任务必须是最晚的任务，避免和队列所属线程发生竞争。例如下图中，Thread2 从 Thread1 的队列中拿出最晚的 Task1 任务，Thread1 会拿出 Task2 来执行，这样就避免发生竞争。但是如果队列中只有一个任务时还是会发生竞争。\n9 内存模型 Java 内存模型试图屏蔽各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台下都能达到一致的内存访问效果。\n9.1 主内存与工作内存 处理器上的寄存器的读写的速度比内存快几个数量级，为了解决这种速度矛盾，在它们之间加入了高速缓存。\n加入高速缓存带来了一个新的问题：缓存一致性。如果多个缓存共享同一块主内存区域，那么多个缓存的数据可能会不一致，需要一些协议来解决这个问题。\n所有的变量都存储在主内存中，每个线程还有自己的工作内存，工作内存存储在高速缓存或者寄存器中，保存了该线程使用的变量的主内存副本拷贝。\n线程只能直接操作工作内存中的变量，不同线程之间的变量值传递需要通过主内存来完成。\n9.2 内存间交互操作 Java 内存模型定义了 8 个操作来完成主内存和工作内存的交互操作。\n read：把一个变量的值从主内存传输到工作内存中 load：在 read 之后执行，把 read 得到的值放入工作内存的变量副本中 use：把工作内存中一个变量的值传递给执行引擎 assign：把一个从执行引擎接收到的值赋给工作内存的变量 store：把工作内存的一个变量的值传送到主内存中 write：在 store 之后执行，把 store 得到的值放入主内存的变量中 lock：作用于主内存的变量 unlock  9.3 内存模型三大特性 9.3.1. 原子性 Java 内存模型保证了 read、load、use、assign、store、write、lock 和 unlock 操作具有原子性，例如对一个 int 类型的变量执行 assign 赋值操作，这个操作就是原子性的。但是 Java 内存模型允许虚拟机将没有被 volatile 修饰的 64 位数据（long，double）的读写操作划分为两次 32 位的操作来进行，即 load、store、read 和 write 操作可以不具备原子性。\n有一个错误认识就是，int 等原子性的类型在多线程环境中不会出现线程安全问题。前面的线程不安全示例代码中，cnt 属于 int 类型变量，1000 个线程对它进行自增操作之后，得到的值为 997 而不是 1000。\n为了方便讨论，将内存间的交互操作简化为 3 个：load、assign、store。\n下图演示了两个线程同时对 cnt 进行操作，load、assign、store 这一系列操作整体上看不具备原子性，那么在 T1 修改 cnt 并且还没有将修改后的值写入主内存，T2 依然可以读入旧值。可以看出，这两个线程虽然执行了两次自增运算，但是主内存中 cnt 的值最后为 1 而不是 2。因此对 int 类型读写操作满足原子性只是说明 load、assign、store 这些单个操作具备原子性。\nAtomicInteger 能保证多个线程修改的原子性。\n除了使用原子类之外，也可以使用 synchronized 互斥锁来保证操作的原子性。它对应的内存间交互操作为：lock 和 unlock，在虚拟机实现上对应的字节码指令为 monitorenter 和 monitorexit。\n9.3.2. 可见性 可见性指当一个线程修改了共享变量的值，其它线程能够立即得知这个修改。Java 内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可见性的。\n主要有三种实现可见性的方式：\n volatile synchronized，对一个变量执行 unlock 操作之前，必须把变量值同步回主内存。 final，被 final 关键字修饰的字段在构造器中一旦初始化完成，并且没有发生 this 逃逸（其它线程通过 this 引用访问到初始化了一半的对象），那么其它线程就能看见 final 字段的值。  对前面的线程不安全示例中的 cnt 变量使用 volatile 修饰，不能解决线程不安全问题，因为 volatile 并不能保证操作的原子性。\n9.3.3. 有序性 有序性是指：在本线程内观察，所有操作都是有序的。在一个线程观察另一个线程，所有操作都是无序的，无序是因为发生了指令重排序。在 Java 内存模型中，允许编译器和处理器对指令进行重排序，重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。\nvolatile 关键字通过添加内存屏障的方式来禁止指令重排，即重排序时不能把后面的指令放到内存屏障之前。\n也可以通过 synchronized 来保证有序性，它保证每个时刻只有一个线程执行同步代码，相当于是让线程顺序执行同步代码。\n9.4 先行发生原则 上面提到了可以用 volatile 和 synchronized 来保证有序性。除此之外，JVM 还规定了先行发生原则，让一个操作无需控制就能先于另一个操作完成。\n 单一线程原则：在一个线程内，在程序前面的操作先行发生于后面的操作。 管程锁定规则：一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。 volatile 变量规则：对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作。 线程启动规则：Thread 对象的 start() 方法调用先行发生于此线程的每一个动作。 线程加入规则：Thread 对象的结束先行发生于 join() 方法返回。 线程中断规则：对线程 interrupt() 方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过 interrupted() 方法检测到是否有中断发生。 对象终结规则：一个对象的初始化完成（构造函数执行结束）先行发生于它的 finalize() 方法的开始。 传递性：如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么操作 A 先行发生于操作 C。  10 线程安全策略 10.1 不可变 不可变的类型：\n final 关键字修饰的基本数据类型 String 枚举类型 Number 部分子类，如 Long 和 Double 等数值包装类型，BigInteger 和 BigDecimal 等大数据类型。但同为 Number 的原子类 AtomicInteger 和 AtomicLong 则是可变的。  对于集合类型，可以使用 Collections.unmodifiableXXX() 方法来获取一个不可变的集合。\n10.2 互斥同步 synchronized 和 ReentrantLock。\n10.3 非阻塞同步  CAS AtomicInteger  ABA问题：如果一个变量初次读取的时候是 A 值，它的值被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。\n解决方法：J.U.C 包提供了一个带有标记的原子引用类 AtomicStampedReference 来解决这个问题，它可以通过控制变量值的版本来保证 CAS 的正确性。大部分情况下 ABA 问题不会影响程序并发的正确性，如果需要解决 ABA 问题，改用传统的互斥同步可能会比原子类更高效。\n10.4 无同步 10.4.1 栈封闭 多个线程访问同一个方法的局部变量时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有的。\n10.4.2 线程本地存储 如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。\n它提供了线程本地变量，也就是如果你创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的一个本地拷贝，多个线程操作这个变量的时候，实际是操作的自己本地内存里面的变量，从而避免了线程安全问题\n每个 Thread 都有一个 ThreadLocal.ThreadLocalMap 对象。\n当调用一个 ThreadLocal 的 set(T value) 方法时，先得到当前线程的 ThreadLocalMap 对象，然后将 ThreadLocal-\u0026gt;value 键值对插入到该 Map 中。\n10.4.3 可重入代码 这种代码也叫做纯代码（Pure Code），可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回后，原来的程序不会出现任何错误。\n可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。\n11 锁优化 11.1 自旋锁 自旋锁的思想是让一个线程在请求一个共享数据的锁时执行忙循环（自旋）一段时间，如果在这段时间内能获得锁，就可以避免进入阻塞状态。\n自旋锁虽然能避免进入阻塞状态从而减少开销，但是它需要进行忙循环操作占用 CPU 时间，它只适用于共享数据的锁定状态很短的场景。\n在 JDK 1.6 中引入了自适应的自旋锁。自适应意味着自旋的次数不再固定了，而是由前一次在同一个锁上的自旋次数及锁的拥有者的状态来决定。\n11.2 锁消除 锁消除是指对于被检测出不可能存在竞争的共享数据的锁进行消除。\n锁消除主要是通过逃逸分析来支持，如果堆上的共享数据不可能逃逸出去被其它线程访问到，那么就可以把它们当成私有数据对待，也就可以将它们的锁进行消除。\n11.3 锁粗化 如果一系列的连续操作都对同一个对象反复加锁和解锁，频繁的加锁操作就会导致性能损耗。\n如果虚拟机探测到由这样的一串零碎的操作都对同一个对象加锁，将会把加锁的范围扩展（粗化）到整个操作序列的外部。\n11.4 轻量级锁 JDK 1.6 引入了偏向锁和轻量级锁，从而让锁拥有了四个状态：无锁状态（unlocked）、偏向锁状态（biasble）、轻量级锁状态（lightweight locked）和重量级锁状态（inflated）。\n轻量级锁是相对于传统的重量级锁而言，它使用 CAS 操作来避免重量级锁使用互斥量的开销。对于绝大部分的锁，在整个同步周期内都是不存在竞争的，因此也就不需要都使用互斥量进行同步，可以先采用 CAS 操作进行同步，如果 CAS 失败了再改用互斥量进行同步。\n11.5 偏向锁 偏向锁的思想是偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要。\n 本文转载自：https://github.com/CyC2018/CS-Notes，用于个人复习。\n","date":"2021-05-04T00:00:00Z","image":"https://cdn.jsdelivr.net/gh/PKUcoldkeyboard/image-hosting@master/20210503/santorini-1578440_1920.3ldusy6rm1k0.jpg","permalink":"https://cuterwrite.top/p/java-concurrent/","title":"Java并发知识点笔记"},{"content":"Table of Contents generated with DocToc\n JVM知识点笔记  1 运行时数据区域  1.1 程序计数器 1.2 Java虚拟机栈 1.3 本地方法栈 1.4 堆 1.5 方法区 1.6 运行时常量池 1.7 直接内存   2 垃圾收集  2.1 判断一个对象是否可回收  2.1.1 引用计数算法 2.1.2 可达性分析算法 2.1.3 方法区的回收 2.1.4 finalize()   2.2 引用类型  2.2.1 强引用 2.2.2 软引用 2.2.3 弱引用 2.2.4 虚引用   2.3 垃圾收集算法  2.3.1 标记 - 清除 2.3.2 标记-整理 2.3.3 复制 2.3.4 分代收集   2.4 垃圾收集器   3 内存分配与回收策略  3.1 Minor GC和Full GC 3.2 内存分配策略  3.2.1. 对象优先在 Eden 分配 3.2.2. 大对象直接进入老年代 3.2.3. 长期存活的对象进入老年代 3.2.4. 动态对象年龄判定 3.2.5. 空间分配担保   3.3 Full GC触发条件  3.3.1. 调用 System.gc() 3.3.2. 老年代空间不足 3.3.3. 空间分配担保失败 3.3.4. JDK 1.7 及以前的永久代空间不足 3.3.5. Concurrent Mode Failure     4 类加载机制  4.1 类的生命周期 4.2 类加载过程  4.2.1. 加载 4.2.2. 验证 4.2.3. 准备 4.2.4. 解析 4.2.5. 初始化   4.3 类初始化时机  4.3.1. 主动引用 4.3.2. 被动引用   4.4 类与类加载器 4.5 类加载器分类 4.6 双亲委派模型  4.6.1. 工作过程 4.6.2. 好处 4.6.3. 实现   4.7 自定义类加载器实现      JVM知识点笔记 1 运行时数据区域 1.1 程序计数器 记录正在执行的虚拟机字节码指令的地址（如果正在执行的是本地方法则为空）。\n1.2 Java虚拟机栈 每个 Java 方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。\n可以通过 -Xss 这个虚拟机参数来指定每个线程的 Java 虚拟机栈内存大小，在 JDK 1.4 中默认为 256K，而在 JDK 1.5+ 默认为 1M：\n该区域可能抛出以下异常：\n 当线程请求的栈深度超过最大值，会抛出 StackOverflowError 异常； 栈进行动态扩展时如果无法申请到足够内存，会抛出 OutOfMemoryError 异常。  1.3 本地方法栈 本地方法栈与 Java 虚拟机栈类似，它们之间的区别只不过是本地方法栈为本地方法服务。\n本地方法一般是用其它语言（C、C++ 或汇编语言等）编写的，并且被编译为基于本机硬件和操作系统的程序，对待这些方法需要特别处理。\n1.4 堆 所有对象都在这里分配内存，是垃圾收集的主要区域（\u0026ldquo;GC 堆\u0026rdquo;）。\n现代的垃圾收集器基本都是采用分代收集算法，其主要的思想是针对不同类型的对象采取不同的垃圾回收算法。可以将堆分成两块：\n 新生代（Young Generation） 老年代（Old Generation）  堆不需要连续内存，并且可以动态增加其内存，增加失败会抛出 OutOfMemoryError 异常。\n可以通过 -Xms 和 -Xmx 这两个虚拟机参数来指定一个程序的堆内存大小，第一个参数设置初始值，第二个参数设置最大值。\njava -Xms1M -Xmx2M HackTheJava 1.5 方法区 用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。\n和堆一样不需要连续的内存，并且可以动态扩展，动态扩展失败一样会抛出 OutOfMemoryError 异常。\n对这块区域进行垃圾回收的主要目标是对常量池的回收和对类的卸载，但是一般比较难实现。\nHotSpot 虚拟机把它当成永久代来进行垃圾回收。但很难确定永久代的大小，因为它受到很多因素影响，并且每次 Full GC 之后永久代的大小都会改变，所以经常会抛出 OutOfMemoryError 异常。为了更容易管理方法区，从 JDK 1.8 开始，移除永久代，并把方法区移至元空间，它位于本地内存中，而不是虚拟机内存中。\n方法区是一个 JVM 规范，永久代与元空间都是其一种实现方式。在 JDK 1.8 之后，原来永久代的数据被分到了堆和元空间中。元空间存储类的元信息，静态变量和常量池等放入堆中。\n1.6 运行时常量池 运行时常量池是方法区的一部分。\nClass 文件中的常量池（编译器生成的字面量和符号引用）会在类加载后被放入这个区域。\n除了在编译期生成的常量，还允许动态生成，例如 String 类的 intern()。\n1.7 直接内存 在 JDK 1.4 中新引入了 NIO 类，它可以使用 Native 函数库直接分配堆外内存，然后通过 Java 堆里的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在堆内存和堆外内存来回拷贝数据。\n2 垃圾收集 垃圾收集主要是针对堆和方法区进行。程序计数器、虚拟机栈和本地方法栈这三个区域属于线程私有的，只存在于线程的生命周期内，线程结束之后就会消失，因此不需要对这三个区域进行垃圾回收。\n2.1 判断一个对象是否可回收 2.1.1 引用计数算法 为对象添加一个引用计数器，当对象增加一个引用时计数器加 1，引用失效时计数器减 1。引用计数为 0 的对象可被回收。\n在两个对象出现循环引用的情况下，此时引用计数器永远不为 0，导致无法对它们进行回收。正是因为循环引用的存在，因此 Java 虚拟机不使用引用计数算法。\n2.1.2 可达性分析算法 以 GC Roots 为起始点进行搜索，可达的对象都是存活的，不可达的对象可被回收。\nJava 虚拟机使用该算法来判断对象是否可被回收，GC Roots 一般包含以下内容：\n 虚拟机栈中局部变量表中引用的对象 本地方法栈中 JNI 中引用的对象 方法区中类静态属性引用的对象 方法区中的常量引用的对象  2.1.3 方法区的回收 因为方法区主要存放永久代对象，而永久代对象的回收率比新生代低很多，所以在方法区上进行回收性价比不高。\n主要是对常量池的回收和对类的卸载。\n为了避免内存溢出，在大量使用反射和动态代理的场景都需要虚拟机具备类卸载功能。\n类的卸载条件很多，需要满足以下三个条件，并且满足了条件也不一定会被卸载：\n 该类所有的实例都已经被回收，此时堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 Class 对象没有在任何地方被引用，也就无法在任何地方通过反射访问该类方法。  2.1.4 finalize() 类似 C++ 的析构函数，用于关闭外部资源。但是 try-finally 等方式可以做得更好，并且该方法运行代价很高，不确定性大，无法保证各个对象的调用顺序，因此最好不要使用。\n当一个对象可被回收时，如果需要执行该对象的 finalize() 方法，那么就有可能在该方法中让对象重新被引用，从而实现自救。自救只能进行一次，如果回收的对象之前调用了 finalize() 方法自救，后面回收时不会再调用该方法。\n2.2 引用类型 无论是通过引用计数算法判断对象的引用数量，还是通过可达性分析算法判断对象是否可达，判定对象是否可被回收都与引用有关。\nJava 提供了四种强度不同的引用类型。\n2.2.1 强引用 被强引用关联的对象不会被回收。\n使用 new 一个新对象的方式来创建强引用。\n2.2.2 软引用 被软引用关联的对象只有在内存不够的情况下才会被回收。\n使用 SoftReference 类来创建软引用。\n2.2.3 弱引用 被弱引用关联的对象一定会被回收，也就是说它只能存活到下一次垃圾回收发生之前。\n使用 WeakReference 类来创建弱引用。\n2.2.4 虚引用 又称为幽灵引用或者幻影引用，一个对象是否有虚引用的存在，不会对其生存时间造成影响，也无法通过虚引用得到一个对象。\n为一个对象设置虚引用的唯一目的是能在这个对象被回收时收到一个系统通知。\n使用 PhantomReference 来创建虚引用。\n2.3 垃圾收集算法 2.3.1 标记 - 清除 在标记阶段，程序会检查每个对象是否为活动对象，如果是活动对象，则程序会在对象头部打上标记。\n在清除阶段，会进行对象回收并取消标志位，另外，还会判断回收后的分块与前一个空闲分块是否连续，若连续，会合并这两个分块。回收对象就是把对象作为分块，连接到被称为 “空闲链表” 的单向链表，之后进行分配时只需要遍历这个空闲链表，就可以找到分块。\n在分配时，程序会搜索空闲链表寻找空间大于等于新对象大小 size 的块 block。如果它找到的块等于 size，会直接返回这个分块；如果找到的块大于 size，会将块分割成大小为 size 与 (block - size) 的两部分，返回大小为 size 的分块，并把大小为 (block - size) 的块返回给空闲链表。\n不足：\n 标记和清除过程效率都不高； 会产生大量不连续的内存碎片，导致无法给大对象分配内存。  2.3.2 标记-整理 让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。\n优点:\n 不会产生内存碎片  不足:\n 需要移动大量对象，处理效率比较低。  2.3.3 复制 将内存划分为大小相等的两块，每次只使用其中一块，当这一块内存用完了就将还存活的对象复制到另一块上面，然后再把使用过的内存空间进行一次清理。\n主要不足是只使用了内存的一半。\n现在的商业虚拟机都采用这种收集算法回收新生代，但是并不是划分为大小相等的两块，而是一块较大的 Eden 空间和两块较小的 Survivor 空间，每次使用 Eden 和其中一块 Survivor。在回收时，将 Eden 和 Survivor 中还存活着的对象全部复制到另一块 Survivor 上，最后清理 Eden 和使用过的那一块 Survivor。\nHotSpot 虚拟机的 Eden 和 Survivor 大小比例默认为 8:1，保证了内存的利用率达到 90%。如果每次回收有多于 10% 的对象存活，那么一块 Survivor 就不够用了，此时需要依赖于老年代进行空间分配担保，也就是借用老年代的空间存储放不下的对象。\n2.3.4 分代收集 现在的商业虚拟机采用分代收集算法，它根据对象存活周期将内存划分为几块，不同块采用适当的收集算法。\n一般将堆分为新生代和老年代。\n 新生代使用：复制算法 老年代使用：标记 - 清除 或者 标记 - 整理 算法  2.4 垃圾收集器 以上是 HotSpot 虚拟机中的 7 个垃圾收集器，连线表示垃圾收集器可以配合使用。\n 单线程与多线程：单线程指的是垃圾收集器只使用一个线程，而多线程使用多个线程； 串行与并行：串行指的是垃圾收集器与用户程序交替执行，这意味着在执行垃圾收集的时候需要停顿用户程序；并行指的是垃圾收集器和用户程序同时执行。除了 CMS 和 G1 之外，其它垃圾收集器都是以串行的方式执行。  3 内存分配与回收策略 3.1 Minor GC和Full GC  Minor GC：回收新生代，因为新生代对象存活时间很短，因此 Minor GC 会频繁执行，执行的速度一般也会比较快。 Full GC：回收老年代和新生代，老年代对象其存活时间长，因此 Full GC 很少执行，执行速度会比 Minor GC 慢很多。  3.2 内存分配策略 3.2.1. 对象优先在 Eden 分配 大多数情况下，对象在新生代 Eden 上分配，当 Eden 空间不够时，发起 Minor GC。\n3.2.2. 大对象直接进入老年代 大对象是指需要连续内存空间的对象，最典型的大对象是那种很长的字符串以及数组。\n经常出现大对象会提前触发垃圾收集以获取足够的连续空间分配给大对象。\n-XX:PretenureSizeThreshold，大于此值的对象直接在老年代分配，避免在 Eden 和 Survivor 之间的大量内存复制。\n3.2.3. 长期存活的对象进入老年代 为对象定义年龄计数器，对象在 Eden 出生并经过 Minor GC 依然存活，将移动到 Survivor 中，年龄就增加 1 岁，增加到一定年龄则移动到老年代中。\n-XX:MaxTenuringThreshold 用来定义年龄的阈值。\n3.2.4. 动态对象年龄判定 虚拟机并不是永远要求对象的年龄必须达到 MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 中相同年龄所有对象大小的总和大于 Survivor 空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代，无需等到 MaxTenuringThreshold 中要求的年龄。\n3.2.5. 空间分配担保 在发生 Minor GC 之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立的话，那么 Minor GC 可以确认是安全的。\n如果不成立的话虚拟机会查看 HandlePromotionFailure 的值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC；如果小于，或者 HandlePromotionFailure 的值不允许冒险，那么就要进行一次 Full GC。\n3.3 Full GC触发条件 对于 Minor GC，其触发条件非常简单，当 Eden 空间满时，就将触发一次 Minor GC。而 Full GC 则相对复杂，有以下条件：\n3.3.1. 调用 System.gc() 只是建议虚拟机执行 Full GC，但是虚拟机不一定真正去执行。不建议使用这种方式，而是让虚拟机管理内存。\n3.3.2. 老年代空间不足 老年代空间不足的常见场景为前文所讲的大对象直接进入老年代、长期存活的对象进入老年代等。\n为了避免以上原因引起的 Full GC，应当尽量不要创建过大的对象以及数组。除此之外，可以通过 -Xmn 虚拟机参数调大新生代的大小，让对象尽量在新生代被回收掉，不进入老年代。还可以通过 -XX:MaxTenuringThreshold 调大对象进入老年代的年龄，让对象在新生代多存活一段时间。\n3.3.3. 空间分配担保失败 使用复制算法的 Minor GC 需要老年代的内存空间作担保，如果担保失败会执行一次 Full GC。具体内容请参考上面的第 5 小节。\n3.3.4. JDK 1.7 及以前的永久代空间不足 在 JDK 1.7 及以前，HotSpot 虚拟机中的方法区是用永久代实现的，永久代中存放的为一些 Class 的信息、常量、静态变量等数据。\n当系统中要加载的类、反射的类和调用的方法较多时，永久代可能会被占满，在未配置为采用 CMS GC 的情况下也会执行 Full GC。如果经过 Full GC 仍然回收不了，那么虚拟机会抛出 java.lang.OutOfMemoryError。\n为避免以上原因引起的 Full GC，可采用的方法为增大永久代空间或转为使用 CMS GC。\n3.3.5. Concurrent Mode Failure 执行 CMS GC 的过程中同时有对象要放入老年代，而此时老年代空间不足（可能是 GC 过程中浮动垃圾过多导致暂时性的空间不足），便会报 Concurrent Mode Failure 错误，并触发 Full GC。\n4 类加载机制  类是在运行期间第一次使用时动态加载的，而不是一次性加载所有类。因为如果一次性加载，那么会占用很多的内存。\n4.1 类的生命周期 包括以下 7 个阶段：\n 加载（Loading） 验证（Verification） 准备（Preparation） 解析（Resolution） 初始化（Initialization） 使用（Using） 卸载（Unloading）  4.2 类加载过程 包含了加载、验证、准备、解析和初始化这 5 个阶段。\n4.2.1. 加载 加载是类加载的一个阶段，注意不要混淆。\n加载过程完成以下三件事：\n 通过类的完全限定名称获取定义该类的二进制字节流。 将该字节流表示的静态存储结构转换为方法区的运行时存储结构。 在内存中生成一个代表该类的 Class 对象，作为方法区中该类各种数据的访问入口。  其中二进制字节流可以从以下方式中获取：\n 从 ZIP 包读取，成为 JAR、EAR、WAR 格式的基础。 从网络中获取，最典型的应用是 Applet。 运行时计算生成，例如动态代理技术，在 java.lang.reflect.Proxy 使用 ProxyGenerator.generateProxyClass 的代理类的二进制字节流。 由其他文件生成，例如由 JSP 文件生成对应的 Class 类。  4.2.2. 验证 确保 Class 文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。\n4.2.3. 准备 类变量是被 static 修饰的变量，准备阶段为类变量分配内存并设置初始值，使用的是方法区的内存。\n实例变量不会在这阶段分配内存，它会在对象实例化时随着对象一起被分配在堆中。应该注意到，实例化不是类加载的一个过程，类加载发生在所有实例化操作之前，并且类加载只进行一次，实例化可以进行多次。\n初始值一般为 0 值，例如下面的类变量 value 被初始化为 0 而不是 123。\npublic static int value = 123; 如果类变量是常量，那么它将初始化为表达式所定义的值而不是 0。例如下面的常量 value 被初始化为 123 而不是 0。\npublic static final int value = 123; 4.2.4. 解析 将常量池的符号引用替换为直接引用的过程。\n其中解析过程在某些情况下可以在初始化阶段之后再开始，这是为了支持 Java 的动态绑定。\n4.2.5. 初始化 初始化阶段才真正开始执行类中定义的 Java 程序代码。初始化阶段是虚拟机执行类构造器 \u0026lt;clinit\u0026gt;() 方法的过程。在准备阶段，类变量已经赋过一次系统要求的初始值，而在初始化阶段，根据程序员通过程序制定的主观计划去初始化类变量和其它资源。\n\u0026lt;clinit\u0026gt;() 是由编译器自动收集类中所有类变量的赋值动作和静态语句块中的语句合并产生的，编译器收集的顺序由语句在源文件中出现的顺序决定。特别注意的是，静态语句块只能访问到定义在它之前的类变量，定义在它之后的类变量只能赋值，不能访问。例如以下代码：\npublic class Test { static { i = 0; // 给变量赋值可以正常编译通过  System.out.print(i); // 这句编译器会提示“非法向前引用”  } static int i = 1; } 由于父类的 \u0026lt;clinit\u0026gt;() 方法先执行，也就意味着父类中定义的静态语句块的执行要优先于子类。例如以下代码：\nstatic class Parent { public static int A = 1; static { A = 2; } } static class Sub extends Parent { public static int B = A; } public static void main(String[] args) { System.out.println(Sub.B); // 2 } 接口中不可以使用静态语句块，但仍然有类变量初始化的赋值操作，因此接口与类一样都会生成 \u0026lt;clinit\u0026gt;() 方法。但接口与类不同的是，执行接口的 \u0026lt;clinit\u0026gt;() 方法不需要先执行父接口的 \u0026lt;clinit\u0026gt;() 方法。只有当父接口中定义的变量使用时，父接口才会初始化。另外，接口的实现类在初始化时也一样不会执行接口的 \u0026lt;clinit\u0026gt;() 方法。\n虚拟机会保证一个类的 \u0026lt;clinit\u0026gt;() 方法在多线程环境下被正确的加锁和同步，如果多个线程同时初始化一个类，只会有一个线程执行这个类的 \u0026lt;clinit\u0026gt;() 方法，其它线程都会阻塞等待，直到活动线程执行 \u0026lt;clinit\u0026gt;() 方法完毕。如果在一个类的 \u0026lt;clinit\u0026gt;() 方法中有耗时的操作，就可能造成多个线程阻塞，在实际过程中此种阻塞很隐蔽。\n4.3 类初始化时机 4.3.1. 主动引用 虚拟机规范中并没有强制约束何时进行加载，但是规范严格规定了有且只有下列五种情况必须对类进行初始化（加载、验证、准备都会随之发生）：\n  遇到 new、getstatic、putstatic、invokestatic 这四条字节码指令时，如果类没有进行过初始化，则必须先触发其初始化。最常见的生成这 4 条指令的场景是：使用 new 关键字实例化对象的时候；读取或设置一个类的静态字段（被 final 修饰、已在编译期把结果放入常量池的静态字段除外）的时候；以及调用一个类的静态方法的时候。\n  使用 java.lang.reflect 包的方法对类进行反射调用的时候，如果类没有进行初始化，则需要先触发其初始化。\n  当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。\n  当虚拟机启动时，用户需要指定一个要执行的主类（包含 main() 方法的那个类），虚拟机会先初始化这个主类；\n  当使用 JDK 1.7 的动态语言支持时，如果一个 java.lang.invoke.MethodHandle 实例最后的解析结果为 REF_getStatic, REF_putStatic, REF_invokeStatic 的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化；\n  4.3.2. 被动引用 以上 5 种场景中的行为称为对一个类进行主动引用。除此之外，所有引用类的方式都不会触发初始化，称为被动引用。被动引用的常见例子包括：\n 通过子类引用父类的静态字段，不会导致子类初始化。  System.out.println(SubClass.value); // value 字段在 SuperClass 中定义  通过数组定义来引用类，不会触发此类的初始化。该过程会对数组类进行初始化，数组类是一个由虚拟机自动生成的、直接继承自 Object 的子类，其中包含了数组的属性和方法。  SuperClass[] sca = new SuperClass[10];  常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。  System.out.println(ConstClass.HELLOWORLD); 4.4 类与类加载器 两个类相等，需要类本身相等，并且使用同一个类加载器进行加载。这是因为每一个类加载器都拥有一个独立的类名称空间。\n这里的相等，包括类的 Class 对象的 equals() 方法、isAssignableFrom() 方法、isInstance() 方法的返回结果为 true，也包括使用 instanceof 关键字做对象所属关系判定结果为 true。\n4.5 类加载器分类 从 Java 虚拟机的角度来讲，只存在以下两种不同的类加载器：\n  启动类加载器（Bootstrap ClassLoader），使用 C++ 实现，是虚拟机自身的一部分；\n  所有其它类的加载器，使用 Java 实现，独立于虚拟机，继承自抽象类 java.lang.ClassLoader。\n  从 Java 开发人员的角度看，类加载器可以划分得更细致一些：\n  启动类加载器（Bootstrap ClassLoader）此类加载器负责将存放在 \u0026lt;JRE_HOME\u0026gt;\\lib 目录中的，或者被 -Xbootclasspath 参数所指定的路径中的，并且是虚拟机识别的（仅按照文件名识别，如 rt.jar，名字不符合的类库即使放在 lib 目录中也不会被加载）类库加载到虚拟机内存中。启动类加载器无法被 Java 程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给启动类加载器，直接使用 null 代替即可。\n  扩展类加载器（Extension ClassLoader）这个类加载器是由 ExtClassLoader（sun.misc.Launcher$ExtClassLoader）实现的。它负责将 \u0026lt;JAVA_HOME\u0026gt;/lib/ext 或者被 java.ext.dir 系统变量所指定路径中的所有类库加载到内存中，开发者可以直接使用扩展类加载器。\n  应用程序类加载器（Application ClassLoader）这个类加载器是由 AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的。由于这个类加载器是 ClassLoader 中的 getSystemClassLoader() 方法的返回值，因此一般称为系统类加载器。它负责加载用户类路径（ClassPath）上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。\n  4.6 双亲委派模型 应用程序是由三种类加载器互相配合从而实现类加载，除此之外还可以加入自己定义的类加载器。\n下图展示了类加载器之间的层次关系，称为双亲委派模型（Parents Delegation Model）。该模型要求除了顶层的启动类加载器外，其它的类加载器都要有自己的父类加载器。这里的父子关系一般通过组合关系（Composition）来实现，而不是继承关系（Inheritance）。\n4.6.1. 工作过程 一个类加载器首先将类加载请求转发到父类加载器，只有当父类加载器无法完成时才尝试自己加载。\n4.6.2. 好处 使得 Java 类随着它的类加载器一起具有一种带有优先级的层次关系，从而使得基础类得到统一。\n例如 java.lang.Object 存放在 rt.jar 中，如果编写另外一个 java.lang.Object 并放到 ClassPath 中，程序可以编译通过。由于双亲委派模型的存在，所以在 rt.jar 中的 Object 比在 ClassPath 中的 Object 优先级更高，这是因为 rt.jar 中的 Object 使用的是启动类加载器，而 ClassPath 中的 Object 使用的是应用程序类加载器。rt.jar 中的 Object 优先级更高，那么程序中所有的 Object 都是这个 Object。\n4.6.3. 实现 以下是抽象类 java.lang.ClassLoader 的代码片段，其中的 loadClass() 方法运行过程如下：先检查类是否已经加载过，如果没有则让父类加载器去加载。当父类加载器加载失败时抛出 ClassNotFoundException，此时尝试自己去加载。\npublic abstract class ClassLoader { // The parent class loader for delegation  private final ClassLoader parent; public Class\u0026lt;?\u0026gt; loadClass(String name) throws ClassNotFoundException { return loadClass(name, false); } protected Class\u0026lt;?\u0026gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { synchronized (getClassLoadingLock(name)) { // First, check if the class has already been loaded  Class\u0026lt;?\u0026gt; c = findLoadedClass(name); if (c == null) { try { if (parent != null) { c = parent.loadClass(name, false); } else { c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found  // from the non-null parent class loader  } if (c == null) { // If still not found, then invoke findClass in order  // to find the class.  c = findClass(name); } } if (resolve) { resolveClass(c); } return c; } } protected Class\u0026lt;?\u0026gt; findClass(String name) throws ClassNotFoundException { throw new ClassNotFoundException(name); } } 4.7 自定义类加载器实现 以下代码中的 FileSystemClassLoader 是自定义类加载器，继承自 java.lang.ClassLoader，用于加载文件系统上的类。它首先根据类的全名在文件系统上查找类的字节代码文件（.class 文件），然后读取该文件内容，最后通过 defineClass() 方法来把这些字节代码转换成 java.lang.Class 类的实例。\njava.lang.ClassLoader 的 loadClass() 实现了双亲委派模型的逻辑，自定义类加载器一般不去重写它，但是需要重写 findClass() 方法。\n 本文转载自：https://github.com/CyC2018/CS-Notes，用于个人复习。\n","date":"2021-05-04T00:00:00Z","image":"https://cdn.jsdelivr.net/gh/PKUcoldkeyboard/image-hosting@master/20210503/naples-122698_1920.2vb750rs8te0.jpg","permalink":"https://cuterwrite.top/p/jvm/","title":"JVM知识点笔记"},{"content":"Table of Contents generated with DocToc\n Socket与IO模型  1 IO模型  1.1 阻塞式IO 1.2 非阻塞式IO 1.3 IO复用 1.4 信号驱动IO 1.5 异步IO 1.6 IO模型对比   2 IO复用  2.1 select 2.2 poll 2.3 epoll 2.4 LT与ET 2.5 select、poll、epoll对比      Socket与IO模型 1 IO模型 1.1 阻塞式IO 应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回。\n应该注意到，在阻塞的过程中，其它应用进程还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其它应用进程还可以执行，所以不消耗 CPU 时间，这种模型的 CPU 利用率会比较高。\n1.2 非阻塞式IO 应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询（polling）。\n由于 CPU 要处理更多的系统调用，因此这种模型的 CPU 利用率比较低。\n1.3 IO复用 使用 select 或者 poll 等待数据，并且可以等待多个套接字中的任何一个变为可读。这一过程会被阻塞，当某一个套接字可读时返回，之后再使用 recvfrom 把数据从内核复制到进程中。\n它可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O。\n如果一个 Web 服务器没有 I/O 复用，那么每一个 Socket 连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。\n1.4 信号驱动IO 应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。\n相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。\n1.5 异步IO 应用进程执行 aio_read 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。\n异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O。\n1.6 IO模型对比  同步IO：将数据从内核缓冲区复制到应用进程缓冲区的阶段（第二阶段），应用进程会阻塞。 异步IO：第二阶段应用进程不会阻塞。  同步IO包括：BIO、NIO、IO复用和信号驱动IO，它们的区别在第一阶段\n  BIO会直接阻塞应用进程，直到数据从内核缓冲区复制到应用进程缓冲区。\n  NIO采用轮询方式判断IO是否完成，避免阻塞。\n  信号驱动IO采用SIGIO信号方式，避免阻塞\n  IO多路复用使用select/poll/epoll等待描述符成为就绪状态，避免阻塞。\n  其中，NIO、信号驱动IO和异步IO在第一阶段不会阻塞。\n2 IO复用 2.1 select select 允许应用程序监视一组文件描述符，等待一个或者多个描述符成为就绪状态，从而完成 I/O 操作。\n缺点：\n 单个进程所打开的FD是有限制的，通过FD_SETSIZE设置，默认1024 每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大 对socket扫描时是线性扫描（对所有的fds遍历扫描），采用轮询的方法，效率较低（高并发时）  2.2 poll poll与select相比，只是没有fd的限制，其它基本一样\n缺点：\n 每次调用poll，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大 对socket扫描时是线性扫描，采用轮询的方法，效率较低（高并发时）  2.3 epoll select 和 poll 速度都比较慢，每次调用都需要将全部描述符从应用进程缓冲区复制到内核缓冲区。\nepoll 只需要将描述符从进程缓冲区向内核缓冲区拷贝一次，并且进程不需要通过轮询来获得事件完成的描述符。\n缺点：epoll只能工作在linux下\n2.4 LT与ET  LT：LT模式下，只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作。 ET：ET模式下，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论fd中是否还有数据可读。所以在ET模式下，read一个fd的时候一定要把它的buffer读完，或者遇到EAGAIN错误。  2.5 select、poll、epoll对比     select poll epoll     数据结构 bitmap 数组 红黑树   最大连接数 1024 无上限 无上限   fd拷贝 每次调用select拷贝 每次调用poll拷贝 fd首次调用epoll_ctl拷贝，每次调用epoll_wait不拷贝   工作效率 轮询：O(n) 轮询：O(n) 回调：O(1)     本文转载自：https://github.com/CyC2018/CS-Notes，用于个人复习。\n","date":"2021-05-04T00:00:00Z","image":"https://cdn.jsdelivr.net/gh/PKUcoldkeyboard/image-hosting@master/20210503/cheetah-3749168_1920.4pgxzkp625g0.jpg","permalink":"https://cuterwrite.top/p/io-model/","title":"Socket与IO模型"},{"content":"Table of Contents generated with DocToc\n 一、数据库系统原理  1 事务  1.1 概念 1.2 ACID 1.3 AUTOCOMMIT   2 并发一致性问题  2.1 丢失修改 2.2 读脏数据 2.3 不可重复读 2.4 幻影读   3 封锁  3.1 封锁粒度 3.2 封锁类型  3.2.1 读写锁 3.2.2 意向锁   3.3 封锁协议  3.3.1 三级封锁协议 3.3.2 二段锁协议   3.4 MySQL隐式与显示锁定   4 隔离级别  4.1 未提交读 4.2 提交读 4.3 可重复读 4.4 可串行化   5 多版本并发控制  5.1 基本思想 5.2 版本号 5.3 Undo日志 5.4 ReadView 5.5 快照读与当前读  5.5.1 快照读 5.5.2 当前读     6 Next-Key Locks  6.1 Record Locks 6.2 Gap Locks 6.3 Next-Key Locks     二、MySQL  1 索引  1.1 B+树原理  1.1.1 数据结构 1.1.2. 操作 1.1.3 与红黑树的比较   1.2 MySQL索引  1.2.1 B+树索引 1.2.2 哈希索引 1.2.3 全文索引 1.2.4 空间数据索引   1.3 索引优化  1.3.1. 独立的列 1.3.2. 多列索引 1.3.3. 索引列的顺序 1.3.4. 前缀索引 1.3.5. 覆盖索引   1.4 索引的优点 1.5 索引的使用条件 1.6 MySQL里的索引类型 1.7 聚簇索引和非聚簇索引 1.8 回表查询   2 查询性能优化  2.1 Explain 2.2 优化数据访问  2.2.1 减少请求的数据量 2.2.2 减少扫描的行数   2.3 重构查询方式  2.3.1 切分大查询 2.3.2 分解大连接查询     3 存储引擎  3.1 InnoDB 3.2 MyISAM 3.3 区别   4 数据类型 5 分表  5.1 水平切分 5.2 垂直切分 5.3 Sharding 策略 5.4 Sharding 存在的问题  5.4.1. 事务问题 5.4.2. 连接 5.4.3. ID 唯一性     6 复制  6.1 主从复制 6.2 读写分离     三、Redis  1 概述 2 数据类型 3 数据结构  3.1 字典 3.2 跳跃表   4 使用场景  4.1 计数器 4.2 缓存 4.3 查找表 4.4 消息队列 4.5 会话缓存 4.6 分布式锁 4.7 其他   5 键的过期时间 6 数据淘汰策略 7 持久化  7.1 RDB 7.2 AOF   8 事务 9 事件  9.1 文件事件 9.2 时间事件 9.3 事件的调度与执行   10 复制  10.1 连接过程 10.2 主从链   11 哨兵 12 分片 13 IO多路复用  13.1 什么是IO多路复用 13.2 为什么需要IO多路复用 13.3 IO多路复用的实现方式 13.4 select缺点 13.5 poll与select对比 13.6 poll缺点 13.7 epoll缺点 13.8 epoll的应用 13.9 select/poll/epoll之间的区别 13.10 epoll LT和ET模式的区别      一、数据库系统原理 1 事务 1.1 概念 事务指的是满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。\n1.2 ACID   原子性\n事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。\n回滚可以用回滚日志（Undo Log）来实现，回滚日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。\n  一致性\n数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对同一个数据的读取结果都是相同的。\n  隔离性\n一个事务所做的修改在最终提交以前，对其它事务是不可见的。\n  持久性\n一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。系统发生崩溃可以用重做日志（Redo Log）进行恢复，从而实现持久性。与回滚日志记录数据的逻辑修改不同，重做日志记录的是数据页的物理修改。\n   原因：\n  只有满足一致性，事务的执行结果才是正确的。\n  在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。\n  在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。\n  事务满足持久化是为了能应对系统崩溃的情况。\n  1.3 AUTOCOMMIT MySQL 默认采用自动提交模式。也就是说，如果不显式使用START TRANSACTION语句来开始一个事务，那么每个查询操作都会被当做一个事务并自动提交。\n2 并发一致性问题 2.1 丢失修改 丢失修改指一个事务的更新操作被另外一个事务的更新操作替换。一般在现实生活中常会遇到，例如：T1和 T2两个事务都对一个数据进行修改，T1先修改并提交生效，T2随后修改，T2的修改覆盖了 T1的修改。\n2.2 读脏数据 读脏数据指在不同的事务下，当前事务可以读到另外事务未提交的数据。例如：T1修改一个数据但未提交，T2随后读取这个数据。如果 T1撤销了这次修改，那么 T2读取的数据是脏数据。\n2.3 不可重复读 不可重复读指在一个事务内多次读取同一数据集合。在这一事务还未结束前，另一事务也访问了该同一数据集合并做了修改，由于第二个事务的修改，第一次事务的两次读取的数据可能不一致。例如：T2读取一个数据，T1对该数据做了修改。如果 T2再次读取这个数据，此时读取的结果和第一次读取的结果不同。\n2.4 幻影读 幻读本质上也属于不可重复读的情况，T1读取某个范围的数据，T2在这个范围内插入新的数据，T1再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。\n3 封锁 3.1 封锁粒度 MySQL 中提供了两种封锁粒度：行级锁以及表级锁。\n应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。\n但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。因此封锁粒度越小，系统开销就越大。\n在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。\n3.2 封锁类型 3.2.1 读写锁  互斥锁（Exclusive），简写为 X 锁，又称写锁。 共享锁（Shared），简写为 S 锁，又称读锁。  有以下两个规定：\n 一个事务对数据对象 A 加了 X 锁，就可以对 A 进行读取和更新。加锁期间其它事务不能对 A 加任何锁。 一个事务对数据对象 A 加了 S 锁，可以对 A 进行读取操作，但是不能进行更新操作。加锁期间其它事务能对 A 加 S 锁，但是不能加 X 锁。  锁的兼容关系如下：\n3.2.2 意向锁 使用意向锁（Intention Locks）可以更容易地支持多粒度封锁。\n在存在行级锁和表级锁的情况下，事务 T 想要对表 A 加 X 锁，就需要先检测是否有其它事务对表 A 或者表 A 中的任意一行加了锁，那么就需要对表 A 的每一行都检测一次，这是非常耗时的。\n意向锁在原来的 X/S 锁之上引入了 IX/IS，IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。有以下两个规定：\n 一个事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁； 一个事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。  通过引入意向锁，事务 T 想要对表 A 加 X 锁，只需要先检测是否有其它事务对表 A 加了 X/IX/S/IS 锁，如果加了就表示有其它事务正在使用这个表或者表中某一行的锁，因此事务 T 加 X 锁失败。\n各种锁的兼容关系如下：\n解释如下：\n 任意 IS/IX 锁之间都是兼容的，因为它们只表示想要对表加锁，而不是真正加锁； 这里兼容关系针对的是表级锁，而表级的 IX 锁和行级的 X 锁兼容，两个事务可以对两个数据行加 X 锁。（事务 T1想要对数据行 R1加 X 锁，事务 T2想要对同一个表的数据行 R2加 X 锁，两个事务都需要对该表加 IX 锁，但是 IX 锁是兼容的，并且 IX 锁与行级的 X 锁也是兼容的，因此两个事务都能加锁成功，对同一个表中的两个数据行做修改。）  3.3 封锁协议 3.3.1 三级封锁协议  一级封锁协议：事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。可以解决丢失修改问题，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。 二级封锁协议：在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。可以解决读脏数据问题，因为如果一个事务在对数据 A 进行修改，根据 1 级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据。 三级封锁协议：在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。可以解决不可重复读的问题，因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变。  3.3.2 二段锁协议 加锁和解锁分为两个阶段进行。\n可串行化调度是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。串行执行的事务互不干扰，不会出现并发一致性问题。\n事务遵循两段锁协议是保证可串行化调度的充分条件。例如以下操作满足两段锁协议，它是可串行化调度。\n3.4 MySQL隐式与显示锁定 MySQL 的 InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。\nInnoDB 也可以使用特定的语句进行显示锁定：\nSELECT ... LOCK In SHARE MODE; SELECT ... FOR UPDATE; 4 隔离级别 4.1 未提交读 事务中的修改，即使没有提交，对其它事务也是可见的。\n4.2 提交读 一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。\n4.3 可重复读 保证在同一个事务中多次读取同一数据的结果是一样的。\n4.4 可串行化 强制事务串行执行，这样多个事务互不干扰，不会出现并发一致性问题。\n该隔离级别需要加锁实现，因为要使用加锁机制保证同一时间只有一个事务执行，也就是保证事务串行执行。\n 5 多版本并发控制 多版本并发控制（Multi-Version Concurrency Control, MVCC）是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。而未提交读隔离级别总是读取最新的数据行，要求很低，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。\n5.1 基本思想 在封锁一节中提到，加锁能解决多个事务同时执行时出现的并发一致性问题。在实际场景中读操作往往多于写操作，因此又引入了读写锁来避免不必要的加锁操作，例如读和读没有互斥关系。读写锁中读和写操作仍然是互斥的，而 MVCC 利用了多版本的思想，写操作更新最新的版本快照，而读操作去读旧版本快照，没有互斥关系，这一点和 CopyOnWrite 类似。\n在 MVCC 中事务的修改操作（DELETE、INSERT、UPDATE）会为数据行新增一个版本快照。\n脏读和不可重复读最根本的原因是事务读取到其它事务未提交的修改。在事务进行读取操作时，为了解决脏读和不可重复读问题，MVCC 规定只能读取已经提交的快照。当然一个事务可以读取自身未提交的快照，这不算是脏读。\n5.2 版本号  系统版本号 SYS_ID：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。 事务版本号 TRX_ID ：事务开始时的系统版本号。  5.3 Undo日志 MVCC 的多版本指的是多个版本的快照，快照存储在 Undo 日志中，该日志通过回滚指针 ROLL_PTR 把一个数据行的所有快照连接起来。\n例如在 MySQL 创建一个表 t，包含主键 id 和一个字段 x。我们先插入一个数据行，然后对该数据行执行两次更新操作。\nINSERT INTO t(id, x) VALUES(1, \u0026#34;a\u0026#34;); UPDATE t SET x=\u0026#34;b\u0026#34; WHERE id=1; UPDATE t SET x=\u0026#34;c\u0026#34; WHERE id=1; 因为没有使用 START TRANSACTION 将上面的操作当成一个事务来执行，根据 MySQL 的 AUTOCOMMIT 机制，每个操作都会被当成一个事务来执行，所以上面的操作总共涉及到三个事务。快照中除了记录事务版本号 TRX_ID 和操作之外，还记录了一个 bit 的 DEL 字段，用于标记是否被删除。\nINSERT、UPDATE、DELETE 操作会创建一个日志，并将事务版本号 TRX_ID 写入。DELETE 可以看成是一个特殊的 UPDATE，还会额外将 DEL 字段设置为 1。\n5.4 ReadView MVCC 维护了一个 ReadView 结构，主要包含了当前系统未提交的事务列表 TRX_IDs {TRX_ID_1, TRX_ID_2, \u0026hellip;}，还有该列表的最小值 TRX_ID_MIN 和 TRX_ID_MAX。\n在进行 SELECT 操作时，根据数据行快照的 TRX_ID 与 TRX_ID_MIN 和 TRX_ID_MAX 之间的关系，从而判断数据行快照是否可以使用：\n  TRX_ID \u0026lt; TRX_ID_MIN，表示该数据行快照时在当前所有未提交事务之前进行更改的，因此可以使用。\n  TRX_ID \u0026gt; TRX_ID_MAX，表示该数据行快照是在事务启动之后被更改的，因此不可使用。\n  TRX_ID_MIN \u0026lt;= TRX_ID \u0026lt;= TRX_ID_MAX，需要根据隔离级别再进行判断：\n 提交读：如果 TRX_ID 在 TRX_IDs 列表中，表示该数据行快照对应的事务还未提交，则该快照不可使用。否则表示已经提交，可以使用。 可重复读：都不可以使用。因为如果可以使用的话，那么其它事务也可以读到这个数据行快照并进行修改，那么当前事务再去读这个数据行得到的值就会发生改变，也就是出现了不可重复读问题。    在数据行快照不可使用的情况下，需要沿着 Undo Log 的回滚指针 ROLL_PTR 找到下一个快照，再进行上面的判断。\n5.5 快照读与当前读 5.5.1 快照读 MVCC 的 SELECT 操作是快照中的数据，不需要进行加锁操作。\n5.5.2 当前读 MVCC 其它会对数据库进行修改的操作（INSERT、UPDATE、DELETE）需要进行加锁操作，从而读取最新的数据。可以看到 MVCC 并不是完全不用加锁，而只是避免了 SELECT 的加锁操作。\n6 Next-Key Locks Next-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。\nMVCC 不能解决幻影读问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读（REPEATABLE READ）隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。\n6.1 Record Locks 锁定一个记录上的索引，而不是记录本身。\n如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。\n6.2 Gap Locks 锁定索引之间的间隙，但是不包含索引本身。\n6.3 Next-Key Locks 它是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。它锁定一个前开后闭区间。\n二、MySQL 1 索引 1.1 B+树原理 1.1.1 数据结构 B Tree 指的是 Balance Tree，也就是平衡树。平衡树是一颗查找树，并且所有叶子节点位于同一层。\nB+ Tree 是基于 B Tree 和叶子节点顺序访问指针进行实现，它具有 B Tree 的平衡性，并且通过顺序访问指针来提高区间查询的性能。\n在 B+ Tree 中，一个节点中的 key 从左到右非递减排列，如果某个指针的左右相邻 key 分别是 keyi和 keyi+1，且不为 null，则该指针指向节点的所有 key 大于等于 keyi且小于等于 keyi+1。\n1.1.2. 操作 进行查找操作时，首先在根节点进行二分查找，找到一个 key 所在的指针，然后递归地在指针所指向的节点进行查找。直到查找到叶子节点，然后在叶子节点上进行二分查找，找出 key 所对应的 data。\n插入删除操作会破坏平衡树的平衡性，因此在进行插入删除操作之后，需要对树进行分裂、合并、旋转等操作来维护平衡性。\n1.1.3 与红黑树的比较 红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用 B+ Tree 作为索引结构，这是因为使用 B+ 树访问磁盘数据有更高的性能。\n（一）B+ 树有更低的树高\n平衡树的树高 O(h)=O(logdN)，其中 d 为每个节点的出度。红黑树的出度为 2，而 B+ Tree 的出度一般都非常大，所以红黑树的树高 h 很明显比 B+ Tree 大非常多。\n（二）磁盘访问原理\n操作系统一般将内存和磁盘分割成固定大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I/O 就能完全载入一个节点。\n如果数据不在同一个磁盘块上，那么通常需要移动制动手臂进行寻道，而制动手臂因为其物理结构导致了移动效率低下，从而增加磁盘数据读取时间。B+ 树相对于红黑树有更低的树高，进行寻道的次数与树高成正比，在同一个磁盘块上进行访问只需要很短的磁盘旋转时间，所以 B+ 树更适合磁盘数据的读取。\n（三）磁盘预读特性\n为了减少磁盘 I/O 操作，磁盘往往不是严格按需读取，而是每次都会预读。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，并且只需要很短的磁盘旋转时间，速度会非常快。并且可以利用预读特性，相邻的节点也能够被预先载入。\n1.2 MySQL索引 1.2.1 B+树索引 是大多数 MySQL 存储引擎的默认索引类型。\n因为不再需要进行全表扫描，只需要对树进行搜索即可，所以查找速度快很多。\n因为 B+ Tree 的有序性，所以除了用于查找，还可以用于排序和分组。\n可以指定多个列作为索引列，多个索引列共同组成键。\n适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。\nInnoDB 的 B+Tree 索引分为主索引和辅助索引。主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。\n辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。\n1.2.2 哈希索引 哈希索引能以 O(1) 时间进行查找，但是失去了有序性：\n 无法用于排序与分组； 只支持精确查找，无法用于部分查找和范围查找。  InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。\n1.2.3 全文索引 MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。\n查找条件使用 MATCH AGAINST，而不是普通的 WHERE。\n全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。\nInnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。\n1.2.4 空间数据索引 MyISAM 存储引擎支持空间数据索引（R-Tree），可以用于地理数据存储。空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。\n必须使用 GIS 相关的函数来维护数据。\n1.3 索引优化 1.3.1. 独立的列 在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。\n例如下面的查询不能使用 actor_id 列的索引：\nSELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5; 1.3.2. 多列索引 在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把 actor_id 和 film_id 设置为多列索引。\nSELECT film_id, actor_ id FROM sakila.film_actor WHERE actor_id = 1 AND film_id = 1; 1.3.3. 索引列的顺序 让选择性最强的索引列放在前面。\n索引的选择性是指：不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，每个记录的区分度越高，查询效率也越高。\n例如下面显示的结果中 customer_id 的选择性比 staff_id 更高，因此最好把 customer_id 列放在多列索引的前面。\nSELECT COUNT(DISTINCT staff_id)/COUNT(*) AS staff_id_selectivity, COUNT(DISTINCT customer_id)/COUNT(*) AS customer_id_selectivity, COUNT(*) FROM payment; staff_id_selectivity: 0.0001 customer_id_selectivity: 0.0373 COUNT(*): 16049 1.3.4. 前缀索引 对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。\n前缀长度的选取需要根据索引选择性来确定。\n1.3.5. 覆盖索引 索引包含所有需要查询的字段的值。\n具有以下优点：\n 索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。 一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用（通常比较费时）。 对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。  1.4 索引的优点  大大减少了服务器需要扫描的数据行数。 帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，不需要排序和分组，也就不需要创建临时表）。 将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。  1.5 索引的使用条件  对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效； 对于中到大型的表，索引就非常有效； 但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。  1.6 MySQL里的索引类型  普通索引 唯一索引 主键索引 组合索引 全文索引  1.7 聚簇索引和非聚簇索引  聚簇索引也叫簇类索引，是一种对磁盘上实际数据重新组织以按指定的一个或多个列的值排序。（聚簇索引就是主键的一种术语） 非聚簇索引，叶级页指向表中的记录，记录的物理顺序与逻辑顺序没有必然的联系。  或者：\n 聚簇索引：规定存储在磁盘上的数据是连续的，这个连续是指物理顺序就是连续的。 非聚簇索引：既然聚簇索引是连续的，那非聚簇索引就是不连续的。索引的存储和数据的存储是分离的，也就是说找到了索引但没找到数据，需要根据索引上的值(主键)再次回表查询,非聚簇索引也叫做辅助索引。  举例：\n第一种，直接根据主键查询获取所有字段数据，此时主键是聚簇索引，因为主键对应的索引叶子节点存储了id=1的所有字段的值。\nselect * from student where id = 1 第二种，根据编号查询编号和名称，编号本身是一个唯一索引，但查询的列包含了学生编号和学生名称，当命中编号索引时，该索引的节点的数据存储的是主键ID，需要根据主键ID重新查询一次，所以这种查询下no不是聚簇索引\nselect no,name from student where no = \u0026#39;test\u0026#39; 第三种，我们根据编号查询编号（有人会问知道编号了还要查询？要，你可能需要验证该编号在数据库中是否存在），这种查询命中编号索引时，直接返回编号，因为所需要的数据就是该索引，不需要回表查询，这种场景下no是聚簇索引\nselect no from student where no = \u0026#39;test\u0026#39; 总结\n主键一定是聚簇索引，MySQL的InnoDB中一定有主键，即便研发人员不手动设置，则会使用unique索引，没有unique索引，则会使用数据库内部的一个行的id来当作主键索引,其它普通索引需要区分SQL场景，当SQL查询的列就是索引本身时，我们称这种场景下该普通索引也可以叫做聚簇索引，MyisAM引擎没有聚簇索引。\n1.8 回表查询 要说回表查询，先要从InnoDB的索引实现说起。InnoDB有两大类索引，一类是聚集索引(Clustered Index)，一类是非聚簇索引(Secondary Index)。\nInnoDB的聚集索引：InnoDB聚集索引的叶子节点存储行记录，因此InnoDB必须要有且只有一个聚集索引。\n1.如果表定义了PK(Primary Key，主键)，那么PK就是聚集索引。\n2.如果表没有定义PK，则第一个NOT NULL UNIQUE的列就是聚集索引。\n3.否则InnoDB会另外创建一个隐藏的ROWID作为聚集索引。\n这种机制使得基于PK的查询速度非常快，因为直接定位的行记录。\nInnoDB的普通索引：InnoDB普通索引的叶子节点存储主键ID(MyISAM则是存储的行记录头指针)。\n回表查询：先通过非聚簇索引查询主键ID，再通过主键ID查询数据。\n2 查询性能优化 2.1 Explain Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。\n比较重要的字段有：\n select_type : 查询类型，有简单查询、联合查询、子查询等 key : 使用的索引 rows : 扫描的行数  2.2 优化数据访问 2.2.1 减少请求的数据量  只返回必要的列：最好不要使用 SELECT * 语句。 只返回必要的行：使用 LIMIT 语句来限制返回的数据。 缓存重复查询的数据：使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。  2.2.2 减少扫描的行数 最有效的方式是使用索引来覆盖查询。\n2.3 重构查询方式 2.3.1 切分大查询 一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。\n2.3.2 分解大连接查询 将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处有：\n 让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。 分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。 减少锁竞争； 在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。 查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。  3 存储引擎 3.1 InnoDB 是 MySQL 默认的事务型存储引擎，只有在需要它不支持的特性时，才考虑使用其它存储引擎。\n实现了四个标准的隔离级别，默认级别是可重复读（REPEATABLE READ）。在可重复读隔离级别下，通过多版本并发控制（MVCC）+ Next-Key Locking 防止幻影读。\n主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。\n内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。\n支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。\n3.2 MyISAM 设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。\n提供了大量的特性，包括压缩表、空间数据索引等。\n不支持事务。\n不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入（CONCURRENT INSERT）。\n可以手工或者自动执行检查和修复操作，但是和事务恢复以及崩溃恢复不同，可能导致一些数据丢失，而且修复操作是非常慢的。\n如果指定了 DELAY_KEY_WRITE 选项，在每次修改执行完成时，不会立即将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作。\n3.3 区别   事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。\n  并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。\n  外键：InnoDB 支持外键。\n  备份：InnoDB 支持在线热备份。\n  崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。\n  其它特性：MyISAM 支持压缩表和空间数据索引。\n  4 数据类型  整型：tinyint、smallint、mediumint、int、bigint 浮点数：float、double、decimal 字符串：char、varchar 时间和日期：datetime、timestamp  5 分表 5.1 水平切分 水平切分又称为 Sharding，它是将同一个表中的记录拆分到多个结构相同的表中。\n当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓存单个数据库的压力。\n5.2 垂直切分 垂直切分是将一张表按列切分成多个表，通常是按照列的关系密集程度进行切分，也可以利用垂直切分将经常被使用的列和不经常被使用的列切分到不同的表中。\n在数据库的层面使用垂直切分将按数据库中表的密集程度部署到不同的库中，例如将原来的电商数据库垂直切分成商品数据库、用户数据库等。\n5.3 Sharding 策略  哈希取模：hash(key) % N； 范围：可以是 ID 范围也可以是时间范围； 映射表：使用单独的一个数据库来存储映射关系。  5.4 Sharding 存在的问题 5.4.1. 事务问题 使用分布式事务来解决，比如 XA 接口。\n5.4.2. 连接 可以将原来的连接分解成多个单表查询，然后在用户程序中进行连接。\n5.4.3. ID 唯一性  使用全局唯一 ID（GUID） 为每个分片指定一个 ID 范围 分布式 ID 生成器 (如 Twitter 的 Snowflake 算法)  6 复制 6.1 主从复制 主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。\n binlog 线程 ：负责将主服务器上的数据更改写入二进制日志（Binary log）中。 I/O 线程 ：负责从主服务器上读取二进制日志，并写入从服务器的中继日志（Relay log）。 SQL 线程 ：负责读取中继日志，解析出主服务器已经执行的数据更改并在从服务器中重放（Replay）。  6.2 读写分离 主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。\n读写分离能提高性能的原因在于：\n 主从服务器负责各自的读和写，极大程度缓解了锁的争用； 从服务器可以使用 MyISAM，提升查询性能以及节约系统开销； 增加冗余，提高可用性。  读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。\n三、Redis 1 概述 Redis 是速度非常快的非关系型（NoSQL）内存键值数据库，可以存储键和五种不同类型的值之间的映射。\n键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。\nRedis 支持很多特性，例如将内存中的数据持久化到硬盘中，使用复制来扩展读性能，使用分片来扩展写性能。\n2 数据类型    数据类型 可以存储的值 操作     STRING 字符串、整数或者浮点数 对整个字符串或者字符串的其中一部分执行操作\u0026lt;/br\u0026gt; 对整数和浮点数执行自增或者自减操作   LIST 列表 从两端压入或者弹出元素 \u0026lt;/br\u0026gt; 对单个或者多个元素进行修剪，\u0026lt;/br\u0026gt; 只保留一个范围内的元素   SET 无序集合 添加、获取、移除单个元素\u0026lt;/br\u0026gt; 检查一个元素是否存在于集合中\u0026lt;/br\u0026gt; 计算交集、并集、差集\u0026lt;/br\u0026gt; 从集合里面随机获取元素   HASH 包含键值对的无序散列表 添加、获取、移除单个键值对\u0026lt;/br\u0026gt; 获取所有键值对\u0026lt;/br\u0026gt; 检查某个键是否存在   ZSET 有序集合 添加、获取、删除元素\u0026lt;/br\u0026gt; 根据分值范围或者成员来获取元素\u0026lt;/br\u0026gt; 计算一个键的排名    3 数据结构 3.1 字典 dictht 是一个散列表结构，使用拉链法解决哈希冲突。\n3.2 跳跃表 是有序集合的底层实现之一。\n跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。\n在查找时，从上层指针开始查找，找到对应的区间之后再到下一层去查找。下图演示了查找 22 的过程。\n与红黑树等平衡树相比，跳跃表具有以下优点：\n 插入速度非常快速，因为不需要进行旋转等操作来维护平衡性； 更容易实现； 支持无锁操作。  4 使用场景 4.1 计数器 可以对 String 进行自增自减运算，从而实现计数器功能。\nRedis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。\n4.2 缓存 将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。\n4.3 查找表 例如 DNS 记录就很适合使用 Redis 进行存储。\n查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。\n4.4 消息队列 List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息\n不过最好使用 Kafka、RabbitMQ 等消息中间件。\n4.5 会话缓存 可以使用 Redis 来统一存储多台应用服务器的会话信息。\n当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。\n4.6 分布式锁 在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。\n可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。\n4.7 其他 Set 可以实现交集、并集等操作，从而实现共同好友等功能。\nZSet 可以实现有序性操作，从而实现排行榜等功能。\n5 键的过期时间 Redis 可以为每个键设置过期时间，当键过期时，会自动删除该键。\n对于散列表这种容器，只能为整个键设置过期时间（整个散列表），而不能为键里面的单个元素设置过期时间。\n6 数据淘汰策略 可以设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略。\nRedis 具体有 6 种淘汰策略：\n   策略 描述     volatile-lru 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰   volatile-ttl 从已设置过期时间的数据集中挑选将要过期的数据淘汰   volatile-random 从已设置过期时间的数据集中任意选择数据淘汰   allkeys-lru 从所有数据集中挑选最近最少使用的数据淘汰   allkeys-random 从所有数据集中任意选择数据进行淘汰   noeviction 禁止驱逐数据    作为内存数据库，出于对性能和内存消耗的考虑，Redis 的淘汰算法实际实现上并非针对所有 key，而是抽样一小部分并且从中选出被淘汰的 key。\n使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用 allkeys-lru 淘汰策略，将最近最少使用的数据淘汰。\nRedis 4.0 引入了 volatile-lfu 和 allkeys-lfu 淘汰策略，LFU 策略通过统计访问频率，将访问频率最少的键值对淘汰。\n7 持久化 Redis 是内存型数据库，为了保证数据在断电后不会丢失，需要将内存中的数据持久化到硬盘上。\n7.1 RDB 将某个时间点的所有数据都存放到硬盘上。\n可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。\n如果系统发生故障，将会丢失最后一次创建快照之后的数据。\n如果数据量很大，保存快照的时间会很长。\n7.2 AOF 将写命令添加到 AOF 文件（Append Only File）的末尾。\n使用 AOF 持久化需要设置同步选项，从而确保写命令同步到磁盘文件上的时机。这是因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，然后由操作系统决定什么时候同步到磁盘。有以下同步选项：\n   选项 同步频率     always 每个写命令都同步   everysec 每秒同步一次   no 让操作系统来决定何时同步     always 选项会严重减低服务器的性能； everysec 选项比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器性能几乎没有任何影响； no 选项并不能给服务器性能带来多大的提升，而且也会增加系统崩溃时数据丢失的数量。  随着服务器写请求的增多，AOF 文件会越来越大。Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。\n8 事务 一个事务包含了多个命令，服务器在执行事务期间，不会改去执行其它客户端的命令请求。\n事务中的多个命令被一次性发送给服务器，而不是一条一条发送，这种方式被称为流水线，它可以减少客户端与服务器之间的网络通信次数从而提升性能。\nRedis 最简单的事务实现方式是使用 MULTI 和 EXEC 命令将事务操作包围起来。\n9 事件 Redis 服务器是一个事件驱动程序。\n9.1 文件事件 服务器通过套接字与客户端或者其它服务器进行通信，文件事件就是对套接字操作的抽象。\nRedis 基于 Reactor 模式开发了自己的网络事件处理器，使用 I/O 多路复用程序来同时监听多个套接字，并将到达的事件传送给文件事件分派器，分派器会根据套接字产生的事件类型调用相应的事件处理器。\n9.2 时间事件 服务器有一些操作需要在给定的时间点执行，时间事件是对这类定时操作的抽象。\n时间事件又分为：\n 定时事件：是让一段程序在指定的时间之内执行一次； 周期性事件：是让一段程序每隔指定时间就执行一次。  Redis 将所有时间事件都放在一个无序链表中，通过遍历整个链表查找出已到达的时间事件，并调用相应的事件处理器。\n9.3 事件的调度与执行 服务器需要不断监听文件事件的套接字才能得到待处理的文件事件，但是不能一直监听，否则时间事件无法在规定的时间内执行，因此监听时间应该根据距离现在最近的时间事件来决定。\n从事件处理的角度来看，服务器运行流程如下：\n10 复制 通过使用 slaveof host port 命令来让一个服务器成为另一个服务器的从服务器。\n一个从服务器只能有一个主服务器，并且不支持主主复制。\n10.1 连接过程   主服务器创建快照文件，发送给从服务器，并在发送期间使用缓冲区记录执行的写命令。快照文件发送完毕之后，开始向从服务器发送存储在缓冲区中的写命令；\n  从服务器丢弃所有旧数据，载入主服务器发来的快照文件，之后从服务器开始接受主服务器发来的写命令；\n  主服务器每执行一次写命令，就向从服务器发送相同的写命令。\n  10.2 主从链 随着负载不断上升，主服务器可能无法很快地更新所有从服务器，或者重新连接和重新同步从服务器将导致系统超载。为了解决这个问题，可以创建一个中间层来分担主服务器的复制工作。中间层的服务器是最上层服务器的从服务器，又是最下层服务器的主服务器。\n11 哨兵 Sentinel（哨兵）可以监听集群中的服务器，并在主服务器进入下线状态时，自动从从服务器中选举出新的主服务器。\n12 分片 分片是将数据划分为多个部分的方法，可以将数据存储到多台机器里面，这种方法在解决某些问题时可以获得线性级别的性能提升。\n假设有 4 个 Redis 实例 R0，R1，R2，R3，还有很多表示用户的键 user:1，user:2，\u0026hellip; ，有不同的方式来选择一个指定的键存储在哪个实例中。\n 最简单的方式是范围分片，例如用户 id 从 0~1000 的存储到实例 R0 中，用户 id 从 1001~2000 的存储到实例 R1 中，等等。但是这样需要维护一张映射范围表，维护操作代价很高。 还有一种方式是哈希分片，使用 CRC32 哈希函数将键转换为一个数字，再对实例数量求模就能知道应该存储的实例。  根据执行分片的位置，可以分为三种分片方式：\n 客户端分片：客户端使用一致性哈希等算法决定键应当分布到哪个节点。 代理分片：将客户端请求发送到代理上，由代理转发请求到正确的节点上。 服务器分片：Redis Cluster。  13 IO多路复用 13.1 什么是IO多路复用 IO多路复用是一种同步IO模型，实现一个线程可以监视多个文件句柄；一旦某个文件句柄就绪，就能够通知应用程序进行相应的读写操作；没有文件句柄就绪时会阻塞应用程序，交出cpu。多路是指网络连接，复用指的是同一个线程\n13.2 为什么需要IO多路复用 解决BIO和NIO的问题。\n  BIO：服务端采用单线程，当accept一个请求后，在recv或send调用阻塞时，将无法accept其他请求（必须等上一个请求处recv或send完），无法处理并发。\n当服务器端采用多线程，当accept一个请求后，开启线程进行recv，可以完成并发处理，但随着请求数增加需要增加系统线程，大量的线程占用很大的内存空间，并且线程切换会带来很大的开销，10000个线程真正发生读写事件的线程数不会超过20%，每次accept都开一个线程也是一种资源浪费\n  NIO：服务器端当accept一个请求后，加入fds集合，每次轮询一遍fds集合recv(非阻塞)数据，没有数据则立即返回错误，每次轮询所有fd（包括没有发生读写事件的fd）会很浪费cpu\n  IO多路复用：服务器端采用单线程通过select/epoll等系统调用获取fd列表，遍历有事件的fd进行accept/recv/send，使其能支持更多的并发连接请求\n  13.3 IO多路复用的实现方式  select poll epoll  13.4 select缺点  单个进程所打开的FD是有限制的，通过FD_SETSIZE设置，默认1024 每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大 对socket扫描时是线性扫描（对所有的fds遍历扫描），采用轮询的方法，效率较低（高并发时）  13.5 poll与select对比 poll与select相比，只是没有fd的限制，其它基本一样\n13.6 poll缺点  每次调用poll，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大 对socket扫描时是线性扫描，采用轮询的方法，效率较低（高并发时）  13.7 epoll缺点 epoll只能工作在linux下\n13.8 epoll的应用  redis nginx  13.9 select/poll/epoll之间的区别     select poll epoll     数据结构 bitmap 数组 红黑树   最大连接数 1024 无上限 无上限   fd拷贝 每次调用select拷贝 每次调用poll拷贝 fd首次调用epoll_ctl拷贝，每次调用epoll_wait不拷贝   工作效率 轮询：O(n) 轮询：O(n) 回调：O(1)    13.10 epoll LT和ET模式的区别 epoll有EPOLLLT和EPOLLET两种触发模式，LT是默认的模式，ET是“高速”模式。\n LT模式下，只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作 ET模式下，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论fd中是否还有数据可读。所以在ET模式下，read一个fd的时候一定要把它的buffer读完，或者遇到EAGAIN错误   本文转载自：https://github.com/CyC2018/CS-Notes，用于个人复习。\n","date":"2021-05-04T00:00:00Z","image":"https://cdn.jsdelivr.net/gh/PKUcoldkeyboard/image-hosting@master/20210503/windmills-5614160_1920.7f194ofsigg0.jpg","permalink":"https://cuterwrite.top/p/database-system/","title":"计算机基础知识点总结（数据库系统 + MySQL + Redis）"},{"content":"Table of Contents generated with DocToc\n ArrayList源码分析  1 简介  1.1 ArrayList和Vector的区别 1.2 ArrayList和LinkedList的区别   2 核心源码分析  2.1 属性 2.2 构造函数 2.3 扩容机制  2.3.1 add方法 2.3.2 ensureCapacityInternal方法 2.3.3 ensureExplicitCapacity 2.3.4 grow方法 2.3.5 hugeCapacity方法   2.4 拷贝机制 2.5 ensureCapacity方法      ArrayList源码分析 1 简介 底层：Object[]，容量能动态增长。在添加大量元素前，会先调用ensureCapacity来增加ArrayList的容量，可以减少递增再分配的次数。\nArrayList继承了AbstractList，实现了List，RandomAccess，Cloneable，Serializable等接口。\n RandomAccess：标志接口，接口体是空的，只是用来表明ArrayList是支持快速随机访问的。 Cloneable：能被克隆 Serializable：可序列化  1.1 ArrayList和Vector的区别 底层都是Object[]，但是ArrayList线程不安全，Vector线程安全。\n1.2 ArrayList和LinkedList的区别  线程安全：ArrayList和LinkedList都是线程不安全的。 底层数据结构：ArrayList是Object[]，LinkedList底层是双向链表。 插入和删除：ArrayList插入和删除元素的时间复杂度受元素位置的影响，为O(n - i)；LinkedList的插入和删除元素的时间复杂度不受插入元素位置的影响，都近似于O(1)，但如果在指定位置插入和删除，需要先移动到指定位置再执行操作，时间复杂度近似于O(n)。 是否支持快速随机访问：ArrayList支持，LinkedList不支持。 内存空间占用：ArrayList需要在列表末尾预留一定的容量空间，LinkedList的每一个元素都需要多消耗pre和next指针的空间。  2 核心源码分析 2.1 属性   默认初始容量大小\nprivate static final int DEFAULT_CAPACITY = 10;   元素个数\nprivate int size;   存放数据的数组\ntransient Object[] elementData   空数组\nprivate static final Object[] EMPTY_ELEMENTDATA = {};   用于默认大小实例的共享空数组实例\nprivate static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}   2.2 构造函数   无参\npublic ArrayList(){ this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; } 注意：以无参数构造方法创建 ArrayList 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量扩为 10。（用了懒汉式的单例设计模式）\n  指定容量\npublic ArrayList(int initialCapacity){ if (initialCapacity \u0026gt; 0){ this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0){ this.elementData = EMPTY_ELEMENTDATA; } else { //抛出异常  } }   指定collection\npublic ArrayList(Collection\u0026lt;? extends E\u0026gt; c){ elementData = c.toArray(); if ((size = elementData.length) != 0){ if (elementData.getClass() != Object[].class){ elementData = Arrays.copyOf(elementData, size, Object[].class); } } else { this.elementData = EMPTY_ELEMENTDATA; } }   2.3 扩容机制 2.3.1 add方法 2.3.2 ensureCapacityInternal方法 2.3.3 ensureExplicitCapacity 2.3.4 grow方法 2.3.5 hugeCapacity方法 2.4 拷贝机制 2.5 ensureCapacity方法 ","date":"2021-04-29T00:00:00Z","image":"https://cdn.jsdelivr.net/gh/PKUcoldkeyboard/image-hosting@master/20210503/man-5640540_1920.5mr5hqwq7xc0.jpg","permalink":"https://cuterwrite.top/p/arraylist-source-code/","title":"ArrayList源码分析"},{"content":"实用工具和网址 在线画图工具  ProcessOn：https://www.processon.com/  在线解编码工具  BASE64：https://base64.supfree.net/ MD5：https://www.zxgj.cn/g/md5 AES/DES：http://www.fly63.com/tool/cipher/ JWT：http://jwt.calebb.net/ ASCII：https://www.matools.com/code-convert-ascii Unicode：https://www.zxgj.cn/g/unicode UTF8：https://www.zxgj.cn/g/utf8 字符串：https://www.zxgj.cn/g/enstring URL：http://tool.chinaz.com/tools/urlencode.aspx?jdfwkey=lbixzl  在线转换工具  在线ACSII对照表：http://www.fly63.com/tool/ascii/ 通用进制转换工具：https://www.zxgj.cn/g/jinzhi 在线浮点数十进制转换：http://www.binaryconvert.com/ RGB：https://www.zxgj.cn/g/yansezhi 时间戳：https://www.zxgj.cn/g/unix 计量单位换算：http://www.fly63.com/tool/unitable/ 在线JSON解析：http://www.json.cn/ 在线JS代码格式化工具：https://prettier.io/playground/ SQL压缩/格式化工具：https://www.zxgj.cn/g/sqlformat JSON和YAML在线转换：http://www.fly63.com/tool/jsonyaml/ JSON和XML在线转换:https://www.zxgj.cn/g/jsonxml 人民币大小写转换：http://www.fly63.com/tool/renmingbi/  正则表达式工具  正则表达式调试工具：https://regexr.com/ 正则表达式可视化工具：https://jex.im/regulex/  网络工具  IP地址归属地查询：https://www.ip138.com/ IP地址查询：https://www.ipip.net/ip.html/ HTTP在线接口测试工具：http://www.fly63.com/php/http/  在线编译运行工具  C#在线编译运行（不支持input）：https://rextester.com/ C/C++在线编译：https://www.onlinegdb.com/ 在线编译工具套装：https://c.runoob.com/  在线生成器  UUID：https://www.zxgj.cn/g/uuid 随机数：https://www.zxgj.cn/g/suijishu  其它常用开发工具  在线Nginx配置工具：https://nginxconfig.io/ 在线对比工具：http://www.fly63.com/tool/textdiff/ 在线Chrome浏览器插件：https://www.crx4chrome.com/  在线素材网站  阿里巴巴矢量图标库：https://www.iconfont.cn/ 表情包在线网站：https://fabiaoqing.com/ 极简壁纸：https://bz.zzzmh.cn/ Wallpaper Abyss壁纸：https://wall.alphacoders.com Pixabay图片素材库：https://pixabay.com/zh Unsplash图片素材库：https://unsplash.com Pexels图片素材库：http://www.pexels.com NASA图片素材库：https://images.nasa.gov  设计制作类工具  在线PS：https://www.uupoop.com/ 在线音频剪辑：https://www.weixinsyt.com/ 在线视频剪辑：https://www.kapwing.com/ LOGO在线制作：https://www.uugai.com/ 艺术字体在线生成：https://www.qt86.com/ 在线表格转换工具：https://tableconvert.com/ 在线海报设计工具：https://www.designcap.com/ 图片智能放大工具：https://bigjpg.com/ 二维码美化器：https://mh.cli.im/ 在线代码截图工具：https://carbon.now.sh/ 在线抠图工具：https://www.remove.bg/zh ICO图标在线生成：http://www.fly63.com/php/ico/ SVG转PNG：http://www.fly63.com/tool/svg2img/ 视频转GIF：http://www.fly63.com/tool/giftxt/ 二维码在线生成：http://www.fly63.com/tool/ewm/ 二维码在线解码：http://www.fly63.com/php/decoder/  写作辅助工具  在线字数统计：https://www.eteste.com/ mdnice markdown排版工具：https://mdnice.com/ mdmall markdown排版工具：https://md.aclickall.com/ markdown目录生成器：https://ecotrust-canada.github.io/markdown-toc/ 在线图床（基于github）：https://picx.xpoet.cn/ 图壳图床：https://imgkr.com/ 免费图床：https://sm.ms/ 在线短链接工具：https://urlify.cn/ 在线文本替换：http://www.fly63.com/tool/textreplace/  在线办公工具  pdf在线处理工具1：https://smallpdf.com/cn/pdf-tools pdf在线处理工具2：https://tools.pdf24.org/zh/ 在线多媒体转换：https://cn.office-converter.com/ 在线文字识别工具：https://ocr.wdku.net/ 在线文件压缩工具：https://docsmall.com/  官方文档  Git：https://www.liaoxuefeng.com/wiki/896043488029600/900375748016320 SVM：http://svnbook.red-bean.com/nightly/zh/index.html Nginx中文文档：https://www.nginx.cn/doc/index.html Mybatis中文文档：https://mybatis.org/mybatis-3/zh/index.html 微信小程序官方文档：https://developers.weixin.qq.com/miniprogram/dev/framework/ NodeJs中文文档：http://nodejs.cn/learn Golang标准库：https://studygolang.com/pkgdoc Java 8官方文档：https://docs.oracle.com/javase/8/docs.api/index.html Maven官方文档：http://maven.apache.org/guides/ Spring Boot官方文档：https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/ RabbitMq官方文档：https://www.rabbitmq.com/documentation.html Dubbo中文文档：https://dubbo.apache.org/zh/docs/ Netty官方文档：https://netty.io/wiki/index.html ElasticSearch官方文档：https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html Spring Cloud官方文档：https://spring.io/projects/spring-cloud Docker官方文档：https://docs.docker.com/get-started/ K8S中文文档：https://kubernetes.io/zh/docs/home/ Vue.js中文文档：https://cn.vuejs.org/v2/guide/ React.js官方文档：https://reactjs.org/docs/getting-started.html Jenkins中文文档：https://www.jenkins.io/zh/doc/ Ant design官方文档：https://www.antdv.com/docs/vue/introduce-cn/ Hutool：https://www.hutool.cn/ 厦门大学大数据实验室：http://dblab.xmu.edu.cn/blog/ Flutter中文文档：https://flutter.cn/docs/development/tools/sdk/releases Neo4j官方文档：https://neo4j.com/docs/  Cypher：https://neo4j.com/docs/cypher-manual/ Python API：https://neo4j.com/docs/python-manual/current/    算法学习  leetcode：https://leetcode-cn.com/problemset/all/ nowcoder：https://www.nowcoder.com labuladong的算法小抄：https://labuladong.gitbook.io/algo/    转载自：https://www.jianshu.com/p/467b7e01fb69\n ","date":"2021-04-29T00:00:00Z","image":"https://cdn.jsdelivr.net/gh/PKUcoldkeyboard/image-hosting@master/20210503/sky-5375005_1920.4x9nxtuuftk0.jpg","permalink":"https://cuterwrite.top/p/useful-tool/","title":"实用工具和网址"},{"content":"Table of Contents generated with DocToc\n HashMap源码分析  1 属性 2 构造方法 3 增加元素 4 读取元素 5 删除元素 6 底层数据结构分析  6.1 JDK1.8之前 6.2 JDK1.8之后      HashMap源码分析 1 属性   初始化容量\nstatic final int DEFAULT_INITIAL_CAPACITY = 1 \u0026lt;\u0026lt; 4;   最大容量\nstatic final int MAXIMUM_CAPACITY = 1 \u0026lt;\u0026lt; 30;   负载因子\nstatic final float DEFAULT_LOAD_FACTOR = 0.75f;   红黑树阈值\nstatic final int TREEIFY_THRESHOLD = 8;   链表阈值\nstatic final int UNTREEIFY_THRESHOLD = 6;   红黑树桶阈值\nstatic final int MIN_TREEIFY_CAPACITY = 64;   table数组，用来初始化\ntransient Node\u0026lt;K,V\u0026gt;[] table;   entrySet存放缓存\ntransient Set\u0026lt;Map.Entry\u0026lt;K,V\u0026gt;\u0026gt; entrySet;   桶的数量\ntransient int size   修改次数\ntransient int modCount;   阈值\nint threshold   负载因子\nfloat loadFactor   2 构造方法   HashMap()\npublic HashMap(){ this.loadFactor = DEFAULT_LOAD_FACTOR; }   HashMap(int initialCapacity)\npublic HashMap(int initialCapacity){ this(int initialCapacity, DEFAULT_LOAD_FACTOR); }   HashMap(int initialCapacity, float loadFactor )\npublic HashMap(int initialCapacity, float loadFactor){ if (initialCapacity \u0026lt; 0){ //抛出数值异常  } if (initialCapacity \u0026gt; MAXIMUM_CAPACITY){ initialCapacity = MAXIMUM_CAPACITY; } if (loadFactor \u0026lt;= 0 || Float.isNaN(loadFactor)){ //抛出数值异常  } this.loadFactor = loadFactor; //tableSizeFor，大于等于当前值的下一个2的幂，比如输入17，返回32  this.threshold = tableSizeFor(initialCapacity); }   3 增加元素   put方法分析\npublic V put(K key, V value){ return putVal(hash(key), key, value, false, true); }   hash方法分析\nstatic int hash(Object key){ int h; //key为空返回0，先计算key的hashcode，然后与h无符号右移16位后的二进制进行异或  return key == null ? 0 : (h = key.hashCode() ^ (h \u0026gt;\u0026gt;\u0026gt; 16)); }   putVal方法分析\nfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict){ Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; p; int n, i; /* * 如果table是否等于空或者等于0，如果是则进行初始化 */ if ((tab = table) == null || (n = tab.length) == 0){ n = (tab = resize()).length(); } /* * 哈希取模，i = (n - 1) \u0026amp; hash，对值的位置进行确定 * 也是capacity为2的幂的原因，与运算效率高于% * capacity为2的幂次时，(n - 1) \u0026amp; hash = hash % n * 如果tab[i] = null，新增一个元素 */ if ((p = tab[i = (n - 1) \u0026amp; hash]) == null){ tab[i] = newNode(hash, key, value, null); } else { //说明该位置有值了  Node\u0026lt;K,V\u0026gt; e; K k; if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.eqauls(k)))){ //key值存在，无论链表还是红黑树都需要替换  e = p; } else if (p instanceof TreeNode){ //如果是红黑树  e = ((TreeNode\u0026lt;K,V\u0026gt;)p).putTreeVal(this, tab, hash, key, value); } else { /* * 链表，遍历到最后节点然后插入； */ for (int binCount = 0; ;binCount++){ if ((e = p.next) == null){ p.next = newNode(hash, key, value, null); //大于红黑树阈值，转换红黑树  if (binCount \u0026gt;= TREEIFY_THRESHOLD - 1){ treeifyBin(tab, hash); } break; } if (e.hash \u0026amp;\u0026amp; hahs \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))){ break; } p = e; } } /* * 如果链表中重复就直接替换 */ if (e != null){ V oldValue = e.value; if (!onlyIfAbsent || oldValue == null){ e.value = value; } afterNodeAccess(e); return oldValue; } } //记录修改次数  modCount++; //如果超过threshold，调用resize  if (++size \u0026gt; threshold){ resize(); } afterNodeInsertion(evict); return null; }  如果定位到的数组位置没有元素，直接插入。 如果定位到的数组位置有元素，就要和插入的key比较，key相同则直接覆盖，如果不相同，则判断p是否是TreeNode，如果是则调用e=((TreeNode\u0026lt;K,V)p).putTreeVal(this, tab, hash, key, value)将元素添加进入。如果不是则遍历链表插入到链表尾部。    resize方法分析\nfinal Node\u0026lt;k,V\u0026gt;[] resize(){ Node\u0026lt;K,V\u0026gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap \u0026gt; 0){ if (oldCap \u0026gt;= MAXIMUM_CAPACITY){ threshold = Integer.MAX_VALUE; return oldTab; } else if ((newCap = oldCap \u0026lt;\u0026lt; 1) \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; oldCap \u0026gt;= DEFAULT_INITIAL_CAPACITY){ //threshold加倍  newThr = oldThr \u0026lt;\u0026lt; 1; } } else if (oldThr \u0026gt; 0){ newCap = oldThr; } else { //默认Capacity和threshold，分别为16和12  newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } if (newThr == 0){ float ft = (float)newCap * loadFactor; newThr = (newCap \u0026lt; MAXIMUN_CAPACITY \u0026amp;\u0026amp; ft \u0026lt; (float)MAXIMUM_CAPACITY ? (int) ft : Integer.MAX_VALUE); } threshold = newThr; Node\u0026lt;K,V\u0026gt;[] newTab = (Node\u0026lt;K,V\u0026gt;[])new Node[newCap]; table = newTab; if (oldTab != null){ /* * 省略，拷贝旧的hash桶到newTab */ } }   4 读取元素   get方法分析\npublic V get(Object key){ Node\u0026lt;K,V\u0026gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; }   getNode方法分析\nfinal Node\u0026lt;K,V\u0026gt; getNode(int hash, Object key){ Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; first, e; int n; K k; //table有元素  if ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp; (first = tab[(n - 1) \u0026amp; hash]) != null){ //从第一个node开始  if (first.hash = hash \u0026amp;\u0026amp; ((k = first.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))){ return first; } //first的下一个node  if ((e = first.next) != null){ //若是红黑树，调用红黑树查找方法  if (first instanceof TreeNode){ return ((TreeNode\u0026lt;K,V\u0026gt;)first).getTreeNode(hash, key); } //否则遍历链表查找  do { if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))){ return e; } } while ((e = e.next) != null); } } //table没元素了，直接返回null  return null; }   5 删除元素   remove方法分析\npublic V remove(Object key){ Node\u0026lt;K,V\u0026gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; }   removeNode方法分析\nfinal Node\u0026lt;K,V\u0026gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable){ Node\u0026lt;K,V\u0026gt;[] tab; Node\u0026lt;K,V\u0026gt; p; int n, index; if ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp; (p = tab[index = (n - 1) \u0026amp; hash]) != null){ Node\u0026lt;K,V\u0026gt; node = null; Node\u0026lt;K,V\u0026gt; e; K k; V v; if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))){ node = p; } else if ((e = p.next) != null){ //如果是红黑树，调用红黑树查找方法  if (p instanceof TreeNode){ node = ((TreeNode\u0026lt;K,V\u0026gt;)p).getTreeNode(hash,key); } else { //否则，迭代链表  do{ if (e.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))){ node = e; break; } p = e; } while ((e = e.next) != null); } } //找到节点了  if (node != null \u0026amp;\u0026amp; (!matchValue || (v = node.value) == value || (value != null \u0026amp;\u0026amp; value.equals(v)))){ //调用红黑树删除节点的方法  if (node instanceof TreeNode){ ((TreeNode\u0026lt;K,V\u0026gt;)node).removeTreeNode(this, tab, movable); } else if (node == p){ //是链表头部  tab[index] = node.next; } else { p.next = node.next; } //修改次数  modCount++; size--; afterNodeRemoval(node); return node; } } return null; }   6 底层数据结构分析 6.1 JDK1.8之前   底层：数组加链表\n  基本原理：通过key的hashcode经过扰动处理得到hash值，然后通过(n - 1) \u0026amp; hash判断当前元素存放的位置，如果当前位置存在元素的话，就判断该元素与要存放的元素的hash值以及key是否相同，如果相同则直接覆盖，不相同就用拉链法解决冲突。\n  扰动函数：hash方法，目的是防止一些实现比较差的hashcode方法，减少碰撞。\n  hash方法：\nstatic int hash(int h){ h ^= (h \u0026gt;\u0026gt;\u0026gt; 20) ^ (h \u0026gt;\u0026gt;\u0026gt; 12); return h ^ (h \u0026gt;\u0026gt;\u0026gt; 7) ^ (h \u0026gt;\u0026gt;\u0026gt; 4); } 性能较于1.8差，扰动次数为4\n  拉链法：将链表和数组结合，也就是创建一个链表数组Node\u0026lt;K,V\u0026gt;[]，如果遇到哈希冲突，则将冲突的值加到链表中即可。\n  6.2 JDK1.8之后  底层：数组加链表加红黑树 基本原理：当链表长度大于阈值8时，会调用treeifyBin方法，根据HashMap数组决定是否转化成红黑树，只有当数组长度大于或者等于64时，才会执行转换红黑树的操作，减减少搜索时间。否则只会进行resize()方法对数组进行扩容。  ","date":"2021-04-27T00:00:00Z","image":"https://cdn.jsdelivr.net/gh/PKUcoldkeyboard/image-hosting@master/20210503/mountains-6207115_1920.6ff92y51zus0.jpg","permalink":"https://cuterwrite.top/p/hashmap/","title":"HashMap源码分析"},{"content":"Table of Contents generated with DocToc\n 前端开发知识点-基础篇  1 Cookie、Session、SessionStorage和LocalStorage 2 Http和Https的区别 3 Http2.0的特性 4 OSI七层模型 5 TCP和UDP的区别 6 TCP三次握手和四次挥手 7 HTTP状态码 8 HTTP缓存机制 9 XSS攻击和CSRF攻击 10 HTTP常见请求头 11 HTTP常见请求方法 12 输入URL到显示页面的过程 13 Websocket 14 BOM对象 15 CORS跨域请求的方式 16 CSS盒模型 17 link标签和import标签的区别 18 transition和animation的区别 19 Flex布局 20 BFC 21 块元素和行元素 22 HTML5和CSS3的新元素 23 重绘和重排 24 闭包 25 类的创建和继承 26 promise、generator、async/await 27 事件流 28 事件委托（代理） 29 事件循环 30 图片懒加载和预加载 31 new操作符 32 bind、apply、call的区别 33 节流和防抖 34 深拷贝 35 对象属性改变监听-Proxy 36 变量提升和暂时性死区 37 箭头函数 38 原型链 39 ES6新特性 40 垂直居中的方法 41 前端性能优化 42 get和post的区别 43 web worker 44 浮动清除 45 CSS选择器    前端开发知识点-基础篇 1 Cookie、Session、SessionStorage和LocalStorage Cookie：服务器提供的一种用于维护会话状态信息的数据，通过服务器发送到浏览器，浏览器保存在本地的一种纯文本文件，当下一次有同源的请求时，将保存的Cookie数据添加到请求头部，发送给服务端。可以用来实现记录用户登录状态等功能。\nSession：服务器为了保存用户状态而创建的一个特殊的对象。在浏览器第一次访问服务器时，服务器会创建一个session对象,该对象有一个唯一的id,即sessionid，服务器会把sessionid以cookie的形式发送给浏览器,当浏览器再次访问服务器时,会携带cookie在请求头,可以通过cookie中的sessionid来访问session对象，可以实现在http无状态基础上实现用户状态管理。\nCookie的特点：\n Cookie数据存放在客户端上。 Cookie是非安全的，由于存在本地，有被盗取的可能。 Cookie保存的数据不能超过4K。 Cookie始终在同源的HTTP请求中携带。  如何设置Cookie：\n 服务端：使用Set-Cookie的响应头部，包含5个属性值expires、 domain、path、secure和httponly，分别代表过期时间、域名、路径、安全传输、是否禁用客户端js脚本访问。 客户端：通过JS脚本，例如document.cookie  Cookie和Session和区别：\n Cookie存放在客户端，Session存放在服务端。 Cookie是非安全的，考虑安全应该使用Session 访问增多时，服务器压力比较大，考虑使用Cookie 单个Cookie保存的数据不能超过4K  Cookie、SessionStorage和LocalStorage的区别：\n Cookie始终在同源的HTTP请求中携带。（即使不需要） Cookie可以限制可访问的path 存储大小：Cookie存放数据不能超过4k，WebStorage可以达到5M或更大。 有效期不同：SessionStorage只在当前浏览器窗口关闭前有效，LocalStorage始终有效，用作持久化，Cookie在设置的过期时间之前一直有效。  Cookie常用场景：\n 保持用户登录状态 跟踪用户行为，记录用户选项  2 Http和Https的区别 HTTPS基本原理：客户端使用HTTPS URL访问服务端，要去服务端建立SSL连接，服务端接收到客户端请求后，会将网站的证书（携带公钥）返回给客户端，客户端和服务端开始协商SSL连接的安全等级，也就是加密等级，然后两者通过协商一致的安全等级，建立会话密钥，然后客户端通过网站的公钥来加密会话密钥，传给网站，服务端通过自己的私钥解密出会话密钥，通过会话密钥加密与客户端的通信。\n 安全性：HTTPS是安全超文本协议，在HTTP基础上有更强的安全性，简单来说，HTTPS是使用了TLS/SSL加密的HTTP协议。 申请证书：HTTPS需要使用CA证书。 传输协议：HTTP以明文形式传输数据，HTTPS以加密形式传输数据。 端口号不同：一般来说，HTTP协议的端口为80，HTTPS的端口为443 连接方式：HTTP的连接简单，是无状态的，HTTPS在HTTP的基础上使用了SSL协议进行加密传输。  3 Http2.0的特性  提升了访问速度 允许多路复用：允许同时通过单一的HTTP/2连接发送多重请求-响应信息。 二进制分帧：将所有的传输数据分割为更小的数据帧，并对它们进行二进制编码。 首部压缩 服务器端推送  4 OSI七层模型  应用层：文件传输，常用协议HTTP、STMP、FTP 表示层：数据格式化、代码转换、数据加密 会话层：建立和解除会话 传输层：提供端对端的接口，TCP/UDP 网络层：为数据包选择路由，IP/ICMP 数据链路层：传输带有地址的帧。 物理层：二进制的数据形式在物理媒体上传输数据。  5 TCP和UDP的区别  TCP是面向连接的，UDP是无连接的，即发送数据前不需要先建立连接。 TCP提供可靠的服务，无差错、不丢失、不重复、按序到达，UDP尽最大努力交付。（大数据量使用TCP） TCP面向字节流，UDP面向报文。（UDP无拥塞控制，可能出现丢包） TCP只能1对1，UDP支持1对1和1对多。 TCP首部较大为20字节，UDP只有8字节。  6 TCP三次握手和四次挥手 TCP三次握手：（A为客户端，B为服务端）\n B处于监听，A向B发送连接请求报文SYN=1，ACK=0，选择一个初始的序号x B收到连接请求报文，如果同意连接，则向A发送连接确认报文SYN=1，ACK=1，确认号ack=x+1，选择初始序号y A收到B的连接确认报文，向B发送确认报文ACK=1，确认号ack=y+1，序号为x+1 B收到A的确认，连接建立。  三次握手的原因\n第三次握手防止失效的连接请求到达服务器，让服务器错误打开连接。客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务端返回的确认，导致：客户端超时重传重新建立连接，这时就会出现2个SYN连接。如果有第三次握手，客户端会忽略服务端之后发送的对滞留连接请求的确认，不进行第三次握手，因此就不会打开连接。\nTCP四次挥手：\n A发送连接释放报文FIN=1，序号为u B收到后发出确认ACK=1, ack=x+1, 序号为v，此时TCP属于半关闭状态，A不能发数据，B能发数据。 B不需要连接时，发送连接释放报文FIN=1，ACK=1，ack=u+1，序号为w A收到后发出确认ACK=1，ack=w+1，序号为u+1，进入TIME-WAIT状态，等待2MSL（最大报文存存活时间）后释放连接。 B收到A的确认后释放连接。  7 HTTP状态码 状态码按第一个数字分类，1表示信息，2表示成功，3表示重定向，4表示客户端错误，5表示服务端错误。\n常见状态码：101切换协议、200成功、301永久重定向、302临时重定向、304未修改、400请求无效、401未认证、403拒绝执行、404未找到资源\n200和304的区别：\n 200是请求成功，一般用于GET和POST 304是未修改，所请求的资源未修改，服务器返回此状态码时，不会返回任何资源，客户端通过缓存访问资源（协商缓存）。  8 HTTP缓存机制  强缓存：返回状态码为200，不会向服务端发送请求，直接从缓存取资源。相关字段有pragma、expires、cache-control（cache-control优先级更高，pragma优先级最高）。 协商缓存：返回状态码为304，会向服务端发送请求，通过服务器告知缓存是否可用。相关字段有Last-Modified/If-Modified-Since，Etag/If-None-Match  缓存流程：\n 缓存是否过期：未过期，则从缓存读取（强缓存），否则下一步。 Etag值：True，向服务端发送带If-None-Match的请求，否则继续判断Last-Modified Last-Modified为True，向服务端发送带If-Modified-Since的请求，否则正式发送请求，相应后缓存协商。。（无缓存） 服务器根据If-None-Match和If-Modified-Since决策返回200还是304，304则从缓存读取（协商缓存），200则走正常请求。  9 XSS攻击和CSRF攻击 XSS攻击：跨站脚本攻击，盗取Cookie，在返回的HTML中嵌入js脚本，防范方法：用户输入检查（过滤特殊字符等）、设置set-cookie的httponly属性。\nCSRF攻击：跨站请求伪造，利用Cookie，以用户的名义发送恶意请求。防范方法：验证码、检查HTTPS头部的referer、使用token。\n10 HTTP常见请求头 可以划分为：通用首部、请求首部、相应首部和实体首部\n通用首部：\n Accept：可接受的响应内容类型 Accept-Encoding：可接受的响应内容编码形式 Accept-Language：可接受的响应语言列表 Cache-Control：是否使用强缓存 Pragma：一般来说指，是否使用强缓存 Connection：连接类型（keep-alive） User-Agent：浏览器的身份标识字符串 Content-Length：8进制标识的请求体的长度。 Content-Type：请求体的MIME类型，用于POST和GET Host：服务器的域名及监听端口号，80则可以省略  请求首部：\n cookie Etag/If-None-Match Last-Modified/if-Modified-Since等  响应首部：\n set-cookie等  11 HTTP常见请求方法  get：请求资源 head：请求header post：建立或修改资源。 put：取代资源 delete：删除指定资源 connect： options：允许客户端查看服务端的性能 trace：回显服务器收到的请求，用于测试和诊断 patch：对put的补充，对已有资源局部更新。  12 输入URL到显示页面的过程  首先需要找到这个url域名的服务器ip，首先会寻找缓存中的记录，如果没有则查找本地的hosts文件是否有记录，如果没有则进行下一步。 DNS解析：首先，客户端通过发送DHCP请求报文获取网关路由器的IP地址，然后通过ARP协议获取网关路由器的MAC地址，接着向网关路由器发送DNS查询报文，到达DNS服务器后，在DNS数据库中查询域名解析后的IP地址。 浏览器根据得到的IP地址及相应的端口号，构造一个HTTP请求报文，并将这个HTTP请求封装在一个TCP包中，依次经过传输层、网络层、数据链路层、物理层到达服务端，服务端解析这个请求来作出响应给浏览器。 浏览器解析响应内容并渲染页面，结束连接。（DOM树和CSSOM树）  13 Websocket WebSocket是HTML5中的协议，支持持久连续，http协议不支持持久性连接。Http1.0和HTTP1.1都不支持持久性的链接，HTTP1.1中的keep-alive，将多个http请求合并为1个。\nHTTP的生命周期通过Request来界定，也就是Request一个Response，那么在Http1.0协议中，这次Http请求就结束了。在Http1.1中进行了改进，有一个connection：Keep-alive，也就是说，在一个Http连接中，可以发送多个Request，接收多个Response。但是必须记住，在Http中一个Request只能对应有一个Response，而且这个Response是被动的，不能主动发起。\nWebSocket是基于Http协议的，或者说借用了Http协议来完成一部分握手，在握手阶段与Http是相同的。有2个相关的请求头，upgrade，connection。\nupgrade:websocket\nconnection:upgrade\n14 BOM对象 浏览器对象，location、history和navigator\n常用属性和方法：\n history：go、back、forward navigator：userAgent、cookieEnabled location：  get类型：href、search、hash、host、hostname、pathname、port、protocal set类型：assgin（设置url）、replace（设置url，并且在history中移除）、reload    15 CORS跨域请求的方式 cors：跨域资源共享，客服了AJAX只能同源使用的限制。\n只要同时满足以下两大条件，就属于简单请求\n 请求方法为head、get、post之一 请求头只有：Accepet、Accpet-Language、Content-Language、Last-Event-ID、Content-Type这五种，并且Content-type只有application/x-www-form-unlencoded、multipart/form-data、text/plain这三种。  对于简单请求，浏览器直接发出CORS请求，在请求头加上Origin字段，用来说明来自哪个源，服务器根据这个值决定是否同意此次请求，同意则返回响应，响应头多出几个字段（以Access-Control-开头），否则返回一个正常的HTTP响应，但请求头不包含Access-Control-Allow-Origin字段，抛出一个错误。\nwithCredentials属性\nCORS请求默认不发送Cookie和HTTP认证信息，如果需要发送，一方面需要服务器同意，指定Access-Control-Allow-Credentials为True，另一方面ajax请求要设置withCredentials属性为true。此外，如果要发送Cookie，Access-Control-Allow-Origin就不能设置为星号，必须指定明确的、与明确网页一致的域名。同时，Cookie依然遵循同源政策。\n预检请求\n对于复杂请求的CORS请求，会在正式通信前，增加一次HTTP查询请求，称为预检请求，浏览器先询问服务器，如果同意才会发出正式的XMLHttpRequest请求，否则就报错。\n预检请求用的请求方法为OPTIONS，请求头有Origin、Access-Control-Request-Method、Access-Control-Request-Headers这三个字段。\n一旦服务器通过了预检请求，以后每次浏览器正常的CORS请求，都跟正常请求一样，会有一个OrIgin请求头字段，服务器响应请求头会带有Access-Control-Allow-Origin。\n16 CSS盒模型  标准盒模型：box-sizing：content-box；width=content IE盒模型：box-sizing：border-box；width=content+border+padding box-sizing：padding-box；width=content+padding  17 link标签和import标签的区别  link属于html标签，@import是css提供的。 加载时机：页面加载时，link会同时加载，而@import引用的css会等到页面加载结束后加载。 兼容性：@import只有IE5以上才支持。 优先级：link大于@import  18 transition和animation的区别  大部分属性相同，都是随时间改变元素的属性值。 transition需要触发一个事件才能改变属性，而animation不需要触发任何事件。 transition为2帧，animation可以一帧一帧。  19 Flex布局 弹性布局，用来为盒状模型提供最大的灵活性。\n划分：容器属性和元素属性\n容器属性：\n flex-direction：主轴方向 flex-wrap：换行规则 flew-flow：上面两者结合。 justify-content：主轴对齐方式 align-items：交叉轴对齐方式  元素属性：\n order：排列顺序 flex-glow：放大比例 flex-shrink：缩小比例 flex-basis：占据空间 flex：上面三者的缩写 align-self：允许元素与其它项目的对齐方式不一样，默认auto，继承父元素的align-item  20 BFC BFC：块级格式化上下文，用于清除浮动，防止margin重叠等\nBFC是页面上的一个独立容器，子元素不会影响到外面，计算BFC的高度时，浮动元素也会参与计算。\n会生成BFC的元素：\n float不为none的元素 position为fixed和absolute的元素 display为inline-block、table-cell、table-caption、flex、inline-flex的元素。 overflow不为visible的元素  21 块元素和行元素  块元素：独占一行，并且有自动填满父元素，可以设置margin和padding以及高度和宽度 行元素：不会独占一行，width和height会失效，并且在垂直方向的padding和margin会失效。  22 HTML5和CSS3的新元素  HTML5新增元素：  新标签：8个语义标签（header、section、footer、aside、nav、main、article、figure）、mark高亮、progress进度、新表单控件(calendar、data、time、email、url、search)、新的input类型（color、date、datetime、datetime-local、email） canvas绘图，支持内联SVG，支持MathML 多媒体：audio、video、source、embed track 本地离线存储：manifest配置文件 web存储：localStorage、SessionStorage 其它：web worker、websocket   CSS3新元素  边框： border-radius、box-shadow 背景：background-size、background-origin 文本效果：text-shadow、word-wrap、word-break等 2D/3D转换：transform 动画：animation    23 重绘和重排 DOM的变化影响到了预算内宿的几何属性比如宽高，浏览器重新计算元素的几何属性，其他元素的几何属性也会受到影响，浏览器需要重新构造渲染树，这个过程称之为重排，浏览器将受到影响的部分重新绘制在屏幕上的过程称为重绘。\n重绘和重排的原因：\n 添加或删除可见的DOM元素 元素尺寸位置的改变 浏览器页面初始化 浏览器窗口大小发生改变。  重排一定导致重绘，重绘不一定导致重排。\n减少重排，提高性能的方法：\n 元素的多次样式修改合并成一次修改。 如需进行对DOM节点进行多次操作，先将其脱离文本流之后再进行多次操作。 table布局的渲染与普通DOM节点的操作相比，性能消耗更大，如果可以，尽量减少table布局的使用。 缓存常用的布局信息。  24 闭包 闭包：当一个嵌套的内部函数引用了外部函数的变量或者函数时，外部函数在执行时就产生了闭包。\n典型的闭包：\n 将函数作为灵一个函数的返回值 将函数作为实参传给另一个函数调用  闭包特点：函数嵌套函数，内部函数引用外部函数的变量。\n闭包的作用：\n 延长外部函数局部变量的生命周期，可以用于实现计数器。 可以形成变量的局部作用域，实现函数封装。  闭包的缺点：函数定义的变量和数据会一直存在内存函数中，不会被及时释放，容易导致内存泄漏。\n25 类的创建和继承 类的创建：new一个function，在这个function中的prototype里面添加属性和方法\nfunction Animal(name){ this.name = name || \u0026#39;Animal\u0026#39;; //实例方法 \tthis.sleep = function(){ console.log(this.name + \u0026#34;正在睡觉!\u0026#34;); } //原型方法 \tAnimal.prototype.eat = function(food){ console.log(this.name + \u0026#34;正在吃\u0026#34; + food); }; } 类的继承：4种方式\n  原型链继承（new一个空对象，空对象指向Animal，缺点是无法多继承）\nfunction Cat(){ Cat.prototype = new Animal(); Cat.prototype.name = \u0026#39;Cat\u0026#39;; }   构造继承（使用父亲的构造函数来增强子类实例，等于复制父亲的实例属性）\nfunction Cat(name){ Animal.call(this); this.name = name || \u0026#39;Tom\u0026#39;; } 优点：可以多继承\n缺点：只能继承实例属性和方法\n  实例集成和拷贝继承：\n 实例继承：为父亲实例添加新特性，作为子类实例返回 拷贝继承：拷贝父亲元素上的属性和方法    组合继承：构造继承和原型链继承的组合\nfunction Cat(name){ Animal.call(this); this.name = name || \u0026#39;Tom\u0026#39;; } Cat.prototype = new Animal(); Cat.prototype.constructor = Cat; 通过调用父类构造，继承父亲的属性并保留传参的优点，然后通过将父亲实例作为子类原型，实现函数复用。\n特点：可以继承实例属性，也可以继承原型属性\n缺点：调用了两次父类构造函数，生成了两份实例\n  寄生组合继承：通过寄生方式，砍掉父亲的实例属性\nfunction Cat(name){ Animal.call(this); this.name = name || \u0026#39;Tom\u0026#39;; } var Super = function(){}; Super.prototype = Animal.prototype; Cat.prototype = new Super();   最常用的方法：\nCat.prototype = Object.create(Animal.prototype);   26 promise、generator、async/await promise：CommonJS工作组提出的一种规范，目的是为异步编程提供统一接口。每一个异步任务返回一个Promise对象，该对象有一个then方法，允许指定回调函数。有三个状态：等待（pending）、已完成（resolved，又称fulfilled）、已拒绝（rejected）。promise必须实现then方法（可以说，then就是promise的核心），而且then必须返回一个promise，同一个promise的then可以调用多次，并且回调的执行顺序跟它们被定义时的顺序一致。then方法接受两个参数，第一个参数是成功时的回调，在promise由“等待”态转换到“完成”态时调用，另一个是失败时的回调，在promise由“等待”态转换到“拒绝”态时调用。同时，then可以接受另一个promise传入，也接受一个“类then”的对象或方法，即thenable对象。\n  使用举例：\nfunc(){ return new Promise((resolve,reject)=\u0026gt;{ work().then(res=\u0026gt;{ this.data = res.data; resolve(); }).catch(error=\u0026gt;{ reject(error); }) }) }   promise的用处\n 解决了回调函数的回调地狱问题，有时候我们的请求需要上一个请求返回的结果，会造成相互间回调函数的嵌套，使得代码的可读性和维护性很低。 让代码变得扁平，可读性更好，then返回一个promise，可以把then串起来，then返回的promise装载了由调用返回的值。 在异步回调中，函数的执行栈与原函数分离开，导致外部无法抓住异常。在promise中我们可以使用reject捕获失败情况，和catch捕获执行异常。 promise只不过是一种更良好的编程风格。  promise的缺点：\n 不设置回调函数，promise内部抛出的错误，无法返回到外部。 处于pending状态时，无法得知进展到哪一个阶段。  async和await：\n async函数返回一个promise对象，在没有await的情况下执行async函数，它会立即返回一个promise对象，并且，绝对不会注意后面语句的执行，await关键字只能用在aync定义的函数内； await 可以用于等待一个 async 函数的返回值，如果它等到的是一个 Promise 对象，await 就忙起来了，它会阻塞后面的代码，等着 Promise 对象 resolve，然后得到 resolve 的值，作为 await 表达式的运算结果。async/await使得异步代码看起来像同步代码，使代码简洁，可读性更好，避免嵌套。  27 事件流 事件流：从页面接受事件的顺序，DOM2级事件流包括下面几个阶段\n 事件捕获阶段 处于目标阶段 事件冒泡阶段  addEventListener：DOM2级事件新增的指定事件处理程序的操作，这个方法接受三个参数，要处理的事件名，作为事件处理程序的函数和一个布尔值（true则在捕获阶段调用事件处理程序，否则在冒泡阶段调用）。IE只支持事件冒泡。\n  addEventListener示例：\nvar op = document.getElementById(\u0026#34;id\u0026#34;); op.addEventListener(\u0026#39;click\u0026#39;, function(e){ //do something }, false);   28 事件委托（代理） 事件委托：事件委托指的是，不在事件的发生地（直接dom）上设置监听函数，而是在其父元素上设置监听函数，通过事件冒泡，父元素可以监听到子元素上事件的触发，通过判断事件发生元素DOM的类型，来做出不同的响应。\n举例：最经典的就是ul和li标签的事件监听，比如我们在添加事件时候，采用事件委托机制，不会在li标签上直接添加，而是在ul父元素上添加。\n优点：比较合适动态元素的绑定，新添加的子元素也会有监听函数，也可以有事件触发机制。\n29 事件循环 事务队列中，在每一次事件循环中，宏任务只会提取一个执行，而微任务会一直提取，直到微任务队列为空为止。\n也就是说如果某个微任务任务被推入到执行中，那么当主线程任务执行完成后，会循环调用该队列任务中的下一个任务来执行，直到该任务队列到最后一个任务为止。而事件循环每次只会入栈一个宏任务,主线程执行完成该任务后又会检查微任务队列并完成里面的所有任务后再执行宏任务队列的任务。\n宏任务：setTimeOut、setInterval、setImmediate、IO、UI渲染、主JS、requestAnimationFrame等。\n微任务：process.nextTick、promise.then()，Object.observe()等\n30 图片懒加载和预加载   懒加载：迟缓加载甚至不加载。（减少服务器的压力）\n 实现方法：图片地址不放在src，而是放在其它属性，页面加载后，根据scrollTop判断图片是否在用户视野内，如果在，则将data-original属性中的值放在src。在滚动事件中重复判断图片是否进入视野。    预加载：提前加载图片，当用户需要查看时直接从本地缓存中渲染。（会增大服务器的压力）\n  CSS实现：background：url()\n  JS实现：\nconst img = new Image(); img.src = \u0026#39;xxx\u0026#39;;     31 new操作符 new操作符新建了一个空对象，这个对象原型指向构造函数的prototype，执行构造函数后返回这个对象\n  实现一个new的方法：\nfunction Animal(){...} //var a = new Animal(); function myNew(){ let obj = {} let Constructor = [].shifit.apply(arguments); //绑定原型  obj.__proto__ = Constructor.prototype; //调用构造函数  let res = Constructor.apply(obj, arguments); return typeof res === \u0026#39;object\u0026#39; ? res : obj; }   32 bind、apply、call的区别  apply和call用来改变函数的this指向，它们两个函数的第一个参数都是一样的，表示要改变指向的那个对象，第二个参数，apply中是数组，而call是arg1,arg2\u0026hellip;的形式。 bind改变this作用域会返回一个新的函数，这个函数不会立即执行。  33 节流和防抖   防抖：持续拖动滚动条，只要不停止触发，就永远不会有输出。短时间内触发的事件，在某个时间期限内，函数只执行一次。\nfunction debounce(func, wait){ var timeout; return function(){ clearTimeout(timeout); timeout = setTimeout(func,wait); } }   节流：持续拖动滚动条，每间隔一段时间，就会输出反馈。相当于技能冷却，执行之后，函数会失效一段时间，冷却之后，又会恢复，设置一个状态位，判断是否处于工作状态。（在防抖基础上，到达指定事件必须输出）\nfunction throttle(func, wait, mustRun){ var timeout, start = new Data(); return function(){ var context = this, args = arguments; var cur = new Data(); clearTimeout(timeout); if (cur - start \u0026gt;= mustRun){ func.apply(context, args); start = cur; } else { timeout = setTimeout(func, wait); } } }   34 深拷贝   简单深拷贝：JSON序列化和反序列化\nfunction deepCopy(obj){ let __obj = JSON.stringify(obj); return JSON.parse(_obj); }   递归方法：\nfunction deepCopy(obj){ let res; if (typeof obj === \u0026#39;Object\u0026#39;){ if (Array.isArray(obj)){ res = [] for (let i in obj){ res.push(deepCopy(obj[i])) } } else if (obj == null){ res = null; } else if (obj.constructor === \u0026#39;RegExp\u0026#39;){ res = obj; } else { res = {} for (let i in obj){ res[i] = deepCopy(obj[i]) } } } else { res = obj; } return res; }   35 对象属性改变监听-Proxy   示例\nvar user = new Proxy({}, { set:function(target,key,value,receiver){ } })   36 变量提升和暂时性死区   变量提升：var定义变量，变量可以在声明前使用，值为undefined；let不会出现这个情况。\n  暂时性死区TDZ：只要一进入当前作用域，所要使用的变量就已经存在了，但是不可获取，只有等待变量声明的那一行代码出现，才可以获取和使用该变量。\n只要块级作用域内存在let和const命令，它所声明的变量就会绑定这个区域，不再受外部影响。\n  37 箭头函数   基本语法\nlet func = value=\u0026gt;value; //aka let func = function(value){ return value; };   与普通函数的区别\n 箭头函数没有this，如果普通函数包含箭头函数，那么this访问的就是最近一层普通函数的this 箭头函数是匿名函数，不能作为构造函数，不能使用new 箭头函数没有自己的arguments参数，虽然有name属性但是是空字符串，用\u0026hellip;扩展运算符。 箭头函数通过call()或apply()方法调用一个函数时，只传入了一个参数，对this并没有影响。 箭头函数没有原型属性prototype    38 原型链   原型：prototype，是一个对象，作用是共享属性和方法\n  原型链：原型与原型层层连接的过程即为原型链\n假设B继承了A，b是B的实例，那么就有以下关系：\n（1）\nb.__proto__ = B.prototype （2）B.prototype.constructor = B，A.prototype.constructor = A\n（3）\nB.__proto__ = A （4）\nB.prototype.__proto__ = A.prototype   39 ES6新特性  let（解决了变量提升）、 const常量，块级作用域（暂时性死区）。 模板字符串：“xxx${}” 箭头函数 对象，数组解构赋值 for in和for of class类 extend类继承  40 垂直居中的方法  margin：auto，left、right、top、bottom全设为0 display：flex，align-items:center，justify-content:center;  41 前端性能优化  降低请求量：合并资源、减少HTTP请求数、minify/gzip压缩，webP，懒加载 加快请求速度：预解析DNS、减少域名数、并行加载、CDN分发 缓存：HTTP协议缓存请求、离线缓存manifest、离线数据缓存localStorage 渲染：JS/CSS优化，加载顺序，服务端渲染，pipeline  42 get和post的区别  get参数通过url传递，post放在request body中 get请求在url中传递的参数有长度限制，post没有 get参数暴露在url，不安全。 get请求只能进行url编码，post支持多种编码方式 get请求浏览器会主动缓存。 get请求参数会被完整保留在浏览历史记录。 get用来获取资源，post用来增加或更新资源。  43 web worker 在HTML页面中，如果在执行脚本时，页面的状态是不可响应的，直到脚本执行完成后，页面才变成可响应。web worker是运行在后台的js，独立于其他脚本，不会影响页面你的性能。并且通过postMessage将结果回传到主线程。这样在进行复杂操作的时候，就不会阻塞主线程了。\n如何创建web worker：\n检测浏览器对于web worker的支持性\n创建web worker文件（js，回传函数等）\n创建web worker对象\n44 浮动清除  overflow:hidden/auto 给浮动的元素的容器添加浮动  45 CSS选择器 ID选择器、Class选择器、标签选择器、伪元素选择器、伪类选择器\n优先级：\n 引入了同类的选择器：排在后面的样式属性优先 引入了不同的选择器：id\u0026gt;class\u0026gt;标签  ","date":"2021-04-27T00:00:00Z","image":"https://cdn.jsdelivr.net/gh/PKUcoldkeyboard/image-hosting@master/20210503/lake-5538757_1920.2fnhpht9u2vw.jpg","permalink":"https://cuterwrite.top/p/web-development-1/","title":"前端开发知识点复习-基础篇"},{"content":"Table of Contents generated with DocToc\n 一、操作系统  1、进程与线程的区别 2、进程间的通信的几种方式 3、线程同步的方式 4、进程同步的方式 5、死锁  5.1、死锁的定义 5.2、死锁必要条件 5.3、死锁处理   6、进程的状态 7、进程调度算法 8、虚拟内存 9、页面置换算法 10、分页与分段的区别   二、计算机网络  1、计算机网络体系结构  1.1、五层协议 1.2、OSI七层协议   2、UDP和TCP的特点 3、UDP首部格式 4、TCP首部格式 5、TCP三次握手 6、TCP四次挥手 7、TCP可靠传输 8、TCP滑动窗口 9、TCP 流量控制 10、TCP 拥塞控制 11、域名系统 12、FTP协议 13、DHCP协议 14、SSH协议 15、SMTP协议 16、Web页面请求过程  16.1. DHCP 配置主机信息 16.2. ARP 解析 MAC 地址 16.3. DNS 解析域名 16.4. HTTP 请求页面      一、操作系统 1、进程与线程的区别   进程是对运行时程序的封装，是系统进行资源调度和分配的的基本单位，实现了操作系统的并发；\n  线程是进程的子任务，是CPU调度和分派的基本单位，用于保证程序的 实时性，实现进程内部的并发；\n  一个程序至少有一个进程，一个进程至少有一个线程，线程依赖于进程而存在；\n  进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。\n  2、进程间的通信的几种方式  管道（pipe）及命名管道（named pipe）：管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信； 信号（signal）：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生； 消息队列：消息队列是消息的链接表，它克服了上两种通信方式中信号量有限的缺点，具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息； 共享内存：可以说这是最有用的进程间通信方式。它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等； 信号量：主要作为进程之间及同一种进程的不同线程之间得同步和互斥手段； 套接字：这是一种更为一般得进程间通信机制，它可用于网络中不同机器之间的进程间通信，应用非常广泛。  3、线程同步的方式  互斥量 Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问 信号量 Semphare：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量 事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作  4、进程同步的方式  临界区：对临界资源进行访问的那段代码称为临界区。为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。 同步与互斥 信号量 管程：有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。管程引入了 条件变量 以及相关的操作：wait() 和 signal() 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。  5、死锁 5.1、死锁的定义 在两个或者多个并发进程中，如果每个进程持有某种资源而又等待其它进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。通俗的讲，就是两个或多个进程无限期的阻塞、相互等待的一种状态。\n5.2、死锁必要条件  互斥：每个资源要么已经分配给了一个进程，要么就是可用的。 占有和等待：已经得到了某个资源的进程可以再请求新的资源。 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。  5.3、死锁处理   鸵鸟策略：把头埋在沙子里，假装根本没发生问题。因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。\n  死锁检测与死锁恢复：不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。\n 每种类型一个资源的死锁检测：通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。 每种类型多个资源的死锁检测：每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。  寻找一个没有标记的进程 Pi，它所请求的资源小于等于 A。 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。 如果没有这样一个进程，算法终止。      死锁恢复：在程序运行之前预防发生死锁。\n 破坏互斥条件 破坏占有和等待条件 破坏不可抢占条件 破坏环路等待条件    死锁避免：在程序运行时避免发生死锁。\n  安全状态：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。\n  银行家算法：检查一个状态是否安全的算法如下：\n 查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。 重复以上两步，直到所有进程都标记为终止，则状态是安全的。  如果一个状态不是安全的，需要拒绝进入这个状态。\n    6、进程的状态  ready running waiting 只有ready和running可以相互转换，其它都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。 阻塞状态是缺少需要的资源从running状态转换而来，但是该资源不包括CPU时间，缺少CPU时间会从running变成ready。  7、进程调度算法  先来先服务 first-come first-serverd（FCFS）：非抢占式的调度算法，按照请求的顺序进行调度。有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。 短作业优先 shortest job first（SJF）：非抢占式的调度算法，按估计运行时间最短的顺序进行调度。长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。 最短剩余时间优先 shortest remaining time next（SRTN）：最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。 时间片轮转：将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。 优先级调度：每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。 多级反馈队列：可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。  8、虚拟内存 虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。\n为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。\n9、页面置换算法  OPT LRU LFU FIFO  10、分页与分段的区别   对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。\n  地址空间的维度：分页是一维地址空间，分段是二维的。\n  大小是否可以改变：页的大小不可变，段的大小可以动态改变。\n  出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。\n  二、计算机网络 1、计算机网络体系结构 1.1、五层协议  应用层 运输层 网络层 数据链路层 物理层  1.2、OSI七层协议  应用层：为特定应用程序提供数据传输服务 表示层：数据压缩、加密以及数据描述 会话层：建立和管理回话 运输层：提供的是进程间的通用数据传输服务。 网络层：为主机间提供数据传输服务 数据链路层：主机之间可以有很多链路，链路层协议就是为同一链路的节点提供服务。数据链路层把网络层传来的分组封装成帧。 物理层：尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异。  2、UDP和TCP的特点  用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。 传输控制协议 TCP（Transmission Control Protocol）是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。  3、UDP首部格式 首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。\n4、TCP首部格式  序号 ：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。 确认号 ：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。 数据偏移 ：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。 确认 ACK ：当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。 同步 SYN ：在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。 终止 FIN ：用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。 窗口 ：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。  5、TCP三次握手 假设 A 为客户端，B 为服务器端。\n 首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。 A 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。 B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。 A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。 B 收到 A 的确认后，连接建立。  三次握手的原因\n第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。\n客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。\n6、TCP四次挥手 以下描述不讨论序号和确认号，因为序号和确认号的规则比较简单。并且不讨论 ACK，因为 ACK 在连接建立之后都为 1。\n  A 发送连接释放报文，FIN=1。\n  B 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。\n  当 B 不再需要连接时，发送连接释放报文，FIN=1。\n  A 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接。\n  B 收到 A 的确认后释放连接。\n  四次挥手的原因\n客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。\nTIME_WAIT\n客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由：\n 确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。  7、TCP可靠传输 TCP 使用超时重传来实现可靠传输：如果一个已经发送的报文段在超时时间内没有收到确认，那么就重传这个报文段。\n8、TCP滑动窗口 窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。\n发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。\n接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。\n9、TCP 流量控制 流量控制是为了控制发送方发送速率，保证接收方来得及接收。\n接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。\n10、TCP 拥塞控制 如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。\nTCP 主要通过四个算法来进行拥塞控制：慢开始、拥塞避免、快重传、快恢复。\n发送方需要维护一个叫做拥塞窗口（cwnd）的状态变量，注意拥塞窗口与发送方窗口的区别：拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口。\n为了便于讨论，做如下假设：\n 接收方有足够大的接收缓存，因此不会发生流量控制； 虽然 TCP 的窗口基于字节，但是这里设窗口的大小单位为报文段。  1、慢开始与拥塞避免\n发送的最初执行慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 \u0026hellip;\n注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh，当 cwnd \u0026gt;= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。\n如果出现了超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始。\n2、快重传与快恢复\n在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1和 M2，此时收到 M4，应当发送对 M2的确认。\n在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M2，则 M3丢失，立即重传 M3。\n在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。\n慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。\n11、域名系统 DNS 是一个分布式数据库，提供了主机名和 IP 地址之间相互转换的服务。这里的分布式数据库是指，每个站点只保留它自己的那部分数据。\n域名具有层次结构，从上到下依次为：根域名、顶级域名、二级域名。\nDNS 可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。大多数情况下 DNS 使用 UDP 进行传输，这就要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。在两种情况下会使用 TCP 进行传输：\n 如果返回的响应超过的 512 字节（UDP 最大只支持 512 字节的数据）。 区域传送（区域传送是主域名服务器向辅助域名服务器传送变化的那部分数据）。  12、FTP协议 FTP 使用 TCP 进行连接，它需要两个连接来传送一个文件：\n 控制连接：服务器打开端口号 21 等待客户端的连接，客户端主动建立连接后，使用这个连接将客户端的命令传送给服务器，并传回服务器的应答。 数据连接：用来传送一个文件数据。  根据数据连接是否是服务器端主动建立，FTP 有主动和被动两种模式：\n 主动模式：服务器端主动建立数据连接，其中服务器端的端口号为 20，客户端的端口号随机，但是必须大于 1024，因为 0~1023 是熟知端口号。 被动模式：客户端主动建立数据连接，其中客户端的端口号由客户端自己指定，服务器端的端口号随机。  主动模式要求客户端开放端口号给服务器端，需要去配置客户端的防火墙。被动模式只需要服务器端开放端口号即可，无需客户端配置防火墙。但是被动模式会导致服务器端的安全性减弱，因为开放了过多的端口号。\n13、DHCP协议 DHCP (Dynamic Host Configuration Protocol) 提供了即插即用的连网方式，用户不再需要手动配置 IP 地址等信息。\nDHCP 配置的内容不仅是 IP 地址，还包括子网掩码、网关 IP 地址。\nDHCP 工作过程如下：\n 客户端发送 Discover 报文，该报文的目的地址为 255.255.255.255:67，源地址为 0.0.0.0:68，被放入 UDP 中，该报文被广播到同一个子网的所有主机上。如果客户端和 DHCP 服务器不在同一个子网，就需要使用中继代理。 DHCP 服务器收到 Discover 报文之后，发送 Offer 报文给客户端，该报文包含了客户端所需要的信息。因为客户端可能收到多个 DHCP 服务器提供的信息，因此客户端需要进行选择。 如果客户端选择了某个 DHCP 服务器提供的信息，那么就发送 Request 报文给该 DHCP 服务器。 DHCP 服务器发送 Ack 报文，表示客户端此时可以使用提供给它的信息。  14、SSH协议 TELNET 用于登录到远程主机上，并且远程主机上的输出也会返回。\nTELNET 可以适应许多计算机和操作系统的差异，例如不同操作系统系统的换行符定义。\n15、SMTP协议 一个电子邮件系统由三部分组成：用户代理、邮件服务器以及邮件协议。\n邮件协议包含发送协议和读取协议，发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。\nSMTP 只能发送 ASCII 码，而互联网邮件扩充 MIME 可以发送二进制文件。MIME 并没有改动或者取代 SMTP，而是增加邮件主体的结构，定义了非 ASCII 码的编码规则。\nPOP3 的特点是只要用户从服务器上读取了邮件，就把该邮件删除。但最新版本的 POP3 可以不删除邮件。\nIMAP 协议中客户端和服务器上的邮件保持同步，如果不手动删除邮件，那么服务器上的邮件也不会被删除。IMAP 这种做法可以让用户随时随地去访问服务器上的邮件。\n16、Web页面请求过程 16.1. DHCP 配置主机信息  假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。 主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。 该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。 该数据报则被放置在 MAC 帧中，该帧具有目的地址 FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:FF，将广播到与交换机连接的所有设备。 连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。 该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。 主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。  16.2. ARP 解析 MAC 地址   主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。\n  主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。\n  该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。\n  该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。\n  DHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。\n  主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址（FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:\u0026lt;zero-width space\u0026gt;FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。\n  网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。\n  16.3. DNS 解析域名   知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。\n  网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。\n  因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。\n  到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。\n  找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。\n  16.4. HTTP 请求页面  有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。 在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。 HTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。 连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。 HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。 浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。   本文转载自：https://github.com/CyC2018/CS-Notes，用于个人复习。\n","date":"2021-04-22T00:00:00Z","image":"https://cdn.jsdelivr.net/gh/PKUcoldkeyboard/image-hosting@master/20210503/rocky-coast-5059912_1920.5upaeily96k0.jpg","permalink":"https://cuterwrite.top/p/interview-help/","title":"计算机基础知识点总结（操作系统+计算机网络）"},{"content":"Table of Contents generated with DocToc\n 1、命令返回值 2、多数据库 3、命令大全  1、通用命令  keys pattern exists key del key type key   2、字符串类型  简介 set key value / get key incr key incrby key increment decr key decrby key decrement incrbyfloat key increment append key value strlen key mget key / mset key1 value1 \u0026hellip; 位操作 使用场景   3、hash类型  简介 hset key field value hget key field hmset key field value hmget key field hgetall key hexists key field hsetnx key field value hincrby key field increment hdel key field 其他命令 使用场景   4、list类型  简介 lpush key value1\u0026hellip; rpush key value1\u0026hellip; lpop key rpop key llen key lrange key start stop lrem key count value lindex key index lset key index value ltrim key start end linsert key before|after pivot value rpoplpush source destination 使用场景   5、set类型  简介 sadd key member srem key member smembers sismember key member sdiff key1 key2 \u0026hellip; sinter key1 key2\u0026hellip; sunion key1 key2\u0026hellip; scard key sdiffstore/sinterstore/sunionstore destination key1 key2\u0026hellip; srandmember key count spop 使用场景   6、zset类型  简介 zadd key score member zscore key member zrange key start stop [withscores] zrangebyscore key min max [withscores] limit offset count zrevrangebyscore key max min [withscores] limit offset count zincrby key increment member zcard key zcount key min max zrem key member1 \u0026hellip; zremrangebyranke key start stop zremrangebyscore key min max zrank key member zrevrank key member      1、命令返回值  状态回复  OK：成功 PONG：响应PING   错误回复：命令不存在或者命令格式有误  Error Unknown command   整数回复：  INCR命令：返回递增后的键值 DBSIZE命令：返回键的数量   字符串回复：  请求键的值或者请求一个其他类型键中的某个元素   多行字符串回复：  请求非字符串类型键的元素列表 Keys (Pattern)：返回数据库中符合指定规则的键名    2、多数据库  一个Redis实例提供了多个用来存储数据的字典，客户端可以指定数据存储在哪个字典中。 数据库默认从0开始递增命名，默认支持16个数据库（DB0，DB1，\u0026hellip;，DB15） 不支持自定义数据库名字，也不支持单独设置访问密码  3、命令大全 1、通用命令 keys pattern 获得符合规则的键名列表，支持？、*、[]、\\x四种通配符\n keys命令会遍历所有键，不建议在生产环境中使用 命令不区分大小写  exists key  如果键存在返回1，否则返回0  del key  删除一个或多个键，返回删除的键的个数  type key  获得键值的数据类型  2、字符串类型 简介  字符串类型是Redis中最基本的数据类型，它能存储任何形式的字符串，包括二进制数据，可以存储邮箱、JSON、或者一张图片，允许存储的最大容量是512MB  set key value / get key  赋值与取值  incr key  递增数字，让当前键值递增，并返回递增后的值 如果key不存在时会默认键值为0  incrby key increment  增加指定的整数  decr key  同上  decrby key decrement  同上  incrbyfloat key increment  增加指定浮点数  append key value  尾部追加  strlen key  字符串长度  mget key / mset key1 value1 \u0026hellip;  同时获取/设置多个键值  位操作  getbit key offset setbit key offset value bitcount key bittop  使用场景  文章访问量统计：为每篇文章使用一个名为post:文h章ID:page.view的键来记录文章的访问量，每次访问文章的时候使用incr命令。（键命名建议：“对象类型：对象ID：对象属性”） 生成自增ID：对于每一类对象使用名为对象类型：count的键来存储当前类型对象的数量（如users:count），每次新增一个对象时都使用incr命令，返回值就是该新增对象的ID。 存储文章数据：JSON存储  3、hash类型 简介  散列类型适合存储对象：使用对象类别和ID构成键名，使用字段表示属性，字段值则存储属性值。一个键最多存2^32 - 1个元素  hset key field value  hset car price 500  hget key field  hget car price  hmset key field value hmget key field hgetall key hexists key field hsetnx key field value   当字段不存在时赋值\n  原子操作，线程安全\n  hincrby key field increment hdel key field 其他命令  hkeys hvals hlen  使用场景  存储文章数据 存储文章缩略名：使用slug.to.id的键来存储文章缩略名和ID之间的映射关系。这样就可以用hexists判断缩略名是否存在，使用hget命令来获取缩略名对应的文章ID  4、list类型 简介  可以存储一个有序的字符串列表，常用操作是向列表两端添加元素 底层：双向链表，添加复杂度O（1） 适用场景：只关心最新的内容 一个键最多存2^32 - 1个元素  lpush key value1\u0026hellip; rpush key value1\u0026hellip; lpop key rpop key llen key lrange key start stop  获取列表片段（两边都是闭区间） 支持负索引（与python类似） 0，-1会返回所有元素 start \u0026gt; stop：返回空 stop \u0026gt; len：返回start,start + len  lrem key count value  删除列表中前count个值为value的元素，返回值是实际删除的元素个数 count\u0026gt;0时，从列表左边开始删除 count\u0026lt;0时，从列表右边开始删除 count=0时，删除所有  lindex key index  索引取值，支持负数  lset key index value  索引赋值  ltrim key start end  删除指定索引外的全部值  linsert key before|after pivot value  首先查找pivot，然后插入其前面或后面  rpoplpush source destination  将一个元素转到另一个列表  使用场景  存储文章ID列表 存储评论列表  5、set类型 简介  无序、唯一 最多2^32 - 1个元素 常用操作：插入、删除、判断某个元素是否存在、交集、并集、差集  sadd key member srem key member smembers  返回所有元素  sismember key member   判断元素是否在集合中\n  O（1）\n  sdiff key1 key2 \u0026hellip;  求差集（ key1 - key2）  sinter key1 key2\u0026hellip;  求交集  sunion key1 key2\u0026hellip;  求并集  scard key  获取元素个数  sdiffstore/sinterstore/sunionstore destination key1 key2\u0026hellip;  存储集合操作的结果  srandmember key count  count\u0026gt;0时，获取不重复的随机count个元素 count\u0026lt;0时，获取可能重复的随机count个元素  spop  随机选择一个元素弹出  使用场景  存储文章标签 通过标签搜索文章  6、zset类型 简介  有序 唯一 可以获取某一范围的袁旭 底层：散列表和跳表，读取速度为O(logn)  zadd key score member  支持整数、双精度浮点数，甚至-inf和+inf 可以修改score  zscore key member zrange key start stop [withscores]   获得排名在某个范围的元素\n  可以添加分数\n  复杂度为O(logn + m)\n  zrangebyscore key min max [withscores] limit offset count  获得指定分数范围的元素，两边是闭区间 支持inf 数字前添加左圆括号表示开区间 可以用limit限制返回的个数  zrevrangebyscore key max min [withscores] limit offset count  同上，改成降序  zincrby key increment member  增加某个元素的分数  zcard key  元素数量  zcount key min max  分数范围内个数  zrem key member1 \u0026hellip; zremrangebyranke key start stop  根据排名范围删除元素  zremrangebyscore key min max  根据分数范围删除元素  zrank key member  获取元素排名  zrevrank key member  降序排名  ","date":"2021-04-07T00:00:00Z","image":"https://cdn.jsdelivr.net/gh/PKUcoldkeyboard/image-hosting@master/20210503/groningen-5372387_1920.jhh1ofhqnjs.jpg","permalink":"https://cuterwrite.top/p/redis-1/","title":"Redis入门"},{"content":"Table of Contents generated with DocToc\n Spring Cloud alibaba笔记  SOA与微服务的区别： Spring Cloud Alibaba与Spring Cloud Netflix的对比 什么是Spring Boot？ IOC/DI（控制反转与依赖注入） Spring发展过程 自动装配的实现 手写实现一个Starter  1 Starter的功能 2 Starter的命名规范 3 实现基于Redis的Starter   Apache Dubbo Zookeeper Dubbo集成Zookeeper  1 需要解决的问题 2 实现步骤 3 原理 4 实战Dubbo Spring Cloud   Dubbo的高级应用  1 集群容错 2 负载均衡 3 服务降级   主机绑定规则 Dubbo源码分析  1 核心点 2 生成IDE工程的命令 3 SPI(Service Provider Interface) 4 Dubbo中的SPI思想 5 Dubbo中的SPI原理 6 自适应扩展点 7 Protocol自适应扩展点源码 8 IOC 9 AOP 10 Dubbo集成Spring机制（略）   什么是Nacos？  1 关键特性 2 Nacos集群   搭建Nacos注册中心的注意点 Nacos实现原理  1 模块组成 2 注册中心的原理 3 Nacos源码（略）   Nacos实现统一配置管理  1 Nacos集成Spring Boot 2 Nacos集成Spring Cloud 3 动态更新配置 4 基于DataID配置yaml的文件扩展名 5 不同环境的配置切换 6 自定义Namespace和Group   Nacos Config实现原理（略） Spring Cloud加载配置的原理（略） Nacos源码（略） Sentinel限流及熔断  1 服务限流的作用及实现 2 服务熔断和降级 3 Sentinel的特性 4 Sentinel的组成： 5 Sentinel基本应用： 6 Sentinel资源保护规则  1 QPS流量控制行为   7 Sentinel实现服务熔断   Sentinel集成Spring Cloud 基于Sentinel Dashboard来实现流控配置 Sentinel自定义URL限流异常 Sentinel对URL资源清洗 Sentinel集成Nacos实现动态流控规则 Sentinel集成Nacos实现规则同步  1 Sentinel Dashboard源码修改： 2 Sentinel Dashboard规则同步   Sentinel集成Dubbo实现限流  * 1 Dubbo服务接入Sentinel Dashboard 2 Dubbo服务限流规则   Sentinel热点限流  1 热点参数限流的使用 2 @SentinelResource 3 热点参数规则说明   Sentinel的工作原理（略） Spring Cloud Sentinel工作原理（略） Sentinel核心源码分析（略）  1 限流的源码实现 2 实时指标数据统计 3 服务降级的实现原理   什么是分布式事务？  1 分布式事务问题的理论模型  1 X/Open分布式模型 2 两阶段提交协议 3 三阶段提交协议 4 CAP定理和BASE理论   2 分布式事务问题的常见解决方案  1 TCC补偿性方案 2 基于可靠性消息的最终一致性方案 3 最大努力通知型   3 分布式事务框架Seata  1 AT模式 2 Saga模式        Spring Cloud alibaba笔记 SOA与微服务的区别：  SOA关注的是服务的重用性及解决信息孤岛问题 微服务关注的是解耦，虽然解耦和可重用性从特定的角度来看是一样的，但本质上是有区别的，解耦是降低业务之间的耦合度，而重用性关注的是服务的复用。 微服务会更多地关注在DevOps的持续交付上，因为服务粒度细化之后使得开发运维变得更加重要，因此微服务与容器化技术的结合更加紧密。  Spring Cloud Alibaba与Spring Cloud Netflix的对比  Alibaba开源组件在没有织入Spring Cloud生态之前，已经在各大公司广泛应用，所以容易实现技术整合及迁移。 Alibaba开源组件在服务治理上和处理高并发的能力上有天然的优势。  什么是Spring Boot？ 帮助开发者快速构建一个基于Spring Framework及Spring生态体系的应用解决方案，也是对于“约定优于配置”理念的最佳实践。\nIOC/DI（控制反转与依赖注入）  IOC：把对象的生命周期托管到Spring容器中，而反转是指对象的获取方式被反转了。 当使用IOC容器之后，客户端类不需要通过new来创建这些对象，而是直接从IOC容器中获得。早期的Spring中，主要通过XML的方式来定义Bean，Spring会解析XML文件，把定义的Bean转载到IOC容器中。 DI：IOC容器在运行期间，动态地把某种依赖关系注入组件中。 DI的三种方法：接口注入、构造方法注入、setter方法注入；目前是基于注解的形式：有@Autowired、@Inject和@Resource  Spring发展过程  J2EE的EJB时代 Spring XML配置文件时代 JavaConfig的无配置化注入时代 Spring Boot时代：约定优于配置，核心为：  Starter组件：开箱即用 自动装配：自动根据上下文完成Bean的装配 Actuator：应用监控 Spring Boot CLI：脚手架    自动装配的实现   实现原理：@EnableAutoConfiguration，这个注解的声明在启动类注解@SpringBootApplication内。进一步又涉及到@Enable注解（本质上是对@Configuration和@Bean的封装）；使用Enable注解后，Spring会解析到@Import导入的配置类，从而根据这个配置类中的描述来实现Bean的装配。\n  例子：可以直接使用@Autowired来注入redisTemplate实例。\n  EnableAutoConfiguration的原理\n@Import：导入一个AutoConfigurationImportSelector类。\n@AutoConfigurationPackage：把使用了该注解的类所在的类所在的包及子包下所有组件扫描到Spring IoC容器中\n  AutoConfigurationImportSelector：是ImportSelector的实现类，只有一个selectImports抽象方法，并且返回一个String数组，在这个数组中可以指定需要装配到IOC容器的类，当@Import中导入一个ImportSelectord的实现类后，会把该实现类中返回的Class名称都装载到IOC容器中。\n  ImportSelector与@Configuration的区别：前者可以实现批量装配，并且还可以通过逻辑处理来实现Bean的选择性装配，也就是根据上下文来决定哪些类能够被IOC容器初始化。\n  自动装配原理总结：\n 通过@Import(AutoConfigurationImportSelector)实现配置类的导入 AutoConfigurationImportSelector类实现了ImportSelector接口，重写了方法selectImports，用于实现选择性批量配置类的装配。 通过Spring提供的SpringFactoriesLoader机制，扫描classpath路径下的META-INF/spring.factories，读取需要实现自动装配的配置类。 通过条件筛选的方式，把不符合条件的配置类移除，最终完成自动装配。    @Conditional条件装配\n是Spring Framework提供的一个核心注解，这个注解的作用是提供自动装配的条件约束，一般与@Configuration和**@Bean**配合使用。\n简单来说，Spring在解析@Configuration配置类时，如果该配置类增加了@Conditional注解，那么就会根据该注解配置的条件来决定是否要实现Bean的装配。\n@Configuration public class ConditionConfig { @Bean @Conditional(GpCondition.class) public ThirdClass thirdClass() { return new ThirdClass(); } } 表示：如果GpCondition类中的matches返回true，则装载ThirdClass这个类。\n  @Conditional在Spring Boot中的扩展\n常用装配注解：\n@ConditionalOnBean\n@ConditionalOnMissingBean\n@ConditionalOnResource\n@ConditionalOnProperties\n  spring-autoconfigure-metadata\n用于实现批量自动装配条件配置，作用和@Conditional一致，只是把这些条件配置放在了配置文件中。\n两个条件：\n（1）配置文件的路径和名称必须是/META-INF/spring-autoconfigure-metadata.properties\n（2）配置文件中key的配置格式：自动配置类的类全路径名.条件=值\n好处：有效降低Spring Boot的启动时间，通过这种过滤方式可以减少配置类的加载数量，因为这个过滤发生在配置类的装载之前，所以它可以降低Spring Boot启动时装载Bean的耗时。\n  手写实现一个Starter 1 Starter的功能  涉及相关组件的Jar包依赖 自动实现Bean的装配 自动声明并且加载application.properties文件中的属性配置。  2 Starter的命名规范 Starter的命名主要分为官方命名和自定义组件命名两类，这种命名格式不是强制性的，也是一种约定俗成的方式。\n 官方命名格式：spring-boot-starter-模块名称 自定义命名格式：模块名称-spring-boot-starter  3 实现基于Redis的Starter  创建一个工程，命名为redis-spring-boot-starter 添加Jar包依赖 定义属性类，实现在application.properties中配置Redis的连接参数，使用@ConfigurationProperties，把当前类中的属性和配置文件中的配置进行绑定，并且规定前缀。 定义需要自动装配的配置类，主要就是把RedissonClient装配到IOC容器中。  Apache Dubbo   什么是Dubbo：一个分布式服务框架，主要实现多个系统之间的高性能、透明化调用，简单来说就是一个RPC框架，但是和普通的RPC框架不同，它提供了服务治理功能，比如服务注册、监控、路由、容错等。\n  服务提供者开发流程：\n 创建一个普通的Maven工程provider，并创建两个模块：api和provider，其中provider是一个Spring Boot工程 在api模块中定义接口，并且通过mvn install安装到本地仓库 在provider模块的pom文件中引入api和dubbo组件。 在provider中实现接口，并且使用@DubboService注解发布服务 在application.properties文件（或yml）中添加Dubbo服务的配置信息，包括application.name、protocal.name、protocol.port和registry.address 启动Spring Boot    服务调用者的开发流程：\n 创建一个Spring Boot项目consumer，添加Jar包依赖（Dubbo和api） 在application.properties中配置dubbo.application.name 使用@DubboReference注解获取一个远程代理对象。    Zookeeper   Zookeeper是一个高性能的分布式协调中间件，基于Java编写。\n  Zookeeper的数据结构：数据模型和分布式文件系统类似，是一种层次化的属性结构，区别是：Zookeeper的数据是结构化存储的，并没有在物理上体现出文件和目录。Zookeeper树中的每个节点被称为Znode，Znode维护了一个stat状态信息，其中包含数据变化的时间和版本等。并且每个Znode可以设置一个value值，Zookeeper并不用于通用的数据库或者大容量的对象存储，它只是管理和协调有关的数据，所以value的数据大小不建议设置得非常大，否则会带来更大的网络开销。Zookeeper上的每一个节点的数据都是允许读和写的，读表示指定获得Znode上的value数据，写表示修改Znode上的value数据。另外，节点的创建规则和文件系统中文件的创建规则类似，必须按照层次创建。例如：创建/node/node1/node1-1，先要创建/node/node1这两个层次节点。\n  Zookeeper的特性：Znode在被创建后，需要指定节点的类型，节点类型分为：\n  Watcher机制：\n  Znode的订阅/通知机制：当Znode节点状态发生变化时或者Zookeeper客户端连接状态发生变化时，会触发事件通知。这个机制在服务注册与发现中，针对服务调用者及时感知到服务提供者的变化提供了非常好的解决方案。\n  Zookeeper提供的Java API中，提供了三种机制来针对Znode进行注册监听，分别是：\n  常用应用场景分析\n 分布式锁：（1）多线程中Synchronized和Lock用于解决共享资源访问的数据安全性问题，但范围是线程级别的。（2）在分布式架构中，多个进程对同一个共享资源的访问，也存在数据安全性问题，因此也需要使用锁的形式来解决这类问题，而解决分布式环境下多进程对于共享资源访问带来的安全性问题的方案就是使用分布式锁。锁的本质是排他性，也就是避免同一时刻多个进程同时访问某一个共享资源。（3）如果使用Zookeeper实现分布式锁来达到排他性的目的，只需要用到节点的特性：临时节点，以及同级节点的唯一性。（4）具体实现：a.获得锁的过程：所有客户端可以去Zookeeper服务器上/Exclusive_Locks节点下创建一个临时节点/lock。Zookeeper基于同级节点的唯一性，会保证所有客户端中只有一个客户端能创建成功，创建成功的客户端获得了排它锁，没有获得锁的客户端就需要通过Watcher机制监听/Exclusive_Locks节点下子节点的变更事件，用于实时监听/lock节点的变化情况以作出反应。 b.释放锁的过程：①获得锁的客户端因为异常断开了和服务端的连接，临时节点会自动删除。②获得锁的客户端执行完业务逻辑后，主动删除创建的lock节点。 Master选举：分布式系统中的集群模式，某一机器宕机后，其他节点会接替故障节点继续工作。（1）Zookeeper有两种方式来实现Master选举的场景。假设集群中有3个节点，需要选举出Master，那么三个节点同时去Zookeeper服务器上创建一个临时节点/master-election，由于节点的唯一性，只会有一个客户端创建成功，创建成功就称为Master。同时，其他没有创建成功的客户端，针对该节点注册Watcher事件，监控master，一旦/master-election节点被删除，其他客户端重新发起master选举。（2）方法二：利用临时有序节点的特性来实现。所有参与选举的节点在/master节点下创建一个临时有序节点，编号最小的节点表示master，后续的节点监听上一个节点的删除事件，用于触发重新选举。      Dubbo集成Zookeeper 1 需要解决的问题  服务动态上下线感知：服务调用者要感知到服务提供者上下线的变化。 负载均衡  2 实现步骤  在provider模块中添加Zookeeper相关依赖 修改application.properties配置文件，修改dubbo的registry-addr为zookeeper服务器的地址，表示当前Dubbo服务需要注册到Zookeeper上。 consumer只需要修改application.properties，设置dubbo的registry-addr即可  3 原理   Dubbo服务注册到Zookeeper上之后，可以在Zookeeper服务器上看到图下所示的树形结构。\n  其中URL是临时节点，其他皆为持久化节点，如果注册该节点的服务器下线了，那么这个服务器的URL地址就会被移除。\n  当Dubbo服务消费者启动时，会对/providers下的子节点注册Watcher监听，这样就可以感知到服务提供方的上下线变化，从而防止请求发送到已经下线的服务器造成访问失败。同时，服务消费者会在/consumers下写入自己的URL，这样可以在监控平台上看到某个Dubbo服务正在被哪些服务调用。最重要的是，如果服务消费者需要调用一个服务，那么它会先去/providers路径下获得所有该服务的提供方URL列表，然后通过负载均衡算法计算出一个地址进行远程访问。\n  此外，Dubbo还可以针对不同的情况实现以下功能：\n 基于临时节点的特性，当服务器宕机或者下线时，注册中心会自动删除该服务提供者的信息。 注册中心重启时，Dubbo能自动恢复注册数据及订阅请求。 为了保证节点操作的安全性，Zookeeper提供了ACL权限控制，在Dubbo中可以通过register.username和password来设置节点的验证信息。 注册中心默认的根节点为/dubbo，如果需要针对不同环境设置不同的根节点，可以使用registry.group修改根节点名称。    4 实战Dubbo Spring Cloud  创建service-provider工程，创建两个子模块api和provider，前者为maven工程，后者为Spring Boot工程 在api中声明接口，并执行mvn install 在provider中添加api、Spring Boot、Spring Cloud和Spring Cloud Alibaba相关组件的依赖。（包括spring-cloud-starter、spring-cloud-starter-dubbo、api、discovery） 在父pom中显示声明dependencyManagement配置版本。 在provider中创建接口的实现类，并且声明@DubboService 在application.properties中配置Dubbo相关信息。 启动provider服务。 创建consumer，依赖与provider类似，同样在application.properties中配置Dubbo相关信息。注意：dubbo-cloud-subscribed-services表示服务调用者订阅的服务提供方的应用名称列表，如果有多个应用名称，可以通过\u0026quot;,\u0026ldquo;分开，默认值为“*” 使用@DubboReference消费服务，启动即可。  Dubbo的高级应用 1 集群容错 Dubbo默认提供6种容错模式，默认为Failover Cluster，此外可以根据实际需求自行扩展。\n 配置方式：在@DubboService中增加参数cluster=\u0026ldquo;failfast\u0026quot;即可。 推荐：查询语句容错策略建议使用默认的Failover Cluster，而增删改操作建议使用Failfast Cluster或者使用Failover Cluster(retries=0)，防止出现数据重复添加等其他问题！建议在设计接口的时候把查询接口方法单独做成一个接口提供查询。  2 负载均衡 Dubbo提供了4种负载均衡策略，默认为random，也可以自行扩展（基于SPI机制）。\n3 服务降级 服务降级是一种系统保护策略，当服务器访问压力较大时，可以根据当前业务情况对不重要的服务进行降级，以保证核心业务的正常运行。所谓的降级，就是把一些非必要的功能在流量较大的时间段暂时关闭，比如在双十一大促时，淘宝会把查看历史订单、商品评论等功能关闭。\n降级的分类：\n 是否自动化：人工降级、自动降级 功能划分：读服务降级和写服务降级  自动降级更多来自于系统出现某些异常时自动触发“兜底的流畅”，比如：\n 故障降级：调用的远程服务挂了，网络故障或者RPC服务返回异常。这类情况在业务情况下可以通过设置兜底数据响应给客户端。 限流降级：为了保护系统不被压垮，在系统中会针对核心业务进行限流，当请求流量达到阈值时，后续的请求会被拦截。  Dubbo提供了一种Mock配置来实现服务降级，也就是当服务提供方出现网络异常无法访问时，客户端不抛出异常，步骤如下：\n 在consumer中创建MockService，这个类只需要实现降级的接口即可，重写接口中的抽象方法实现本地数据的返回。 在@DubboReference中增加mock参数，制定MockService的位置。 在不启动Dubbo服务或者服务端的返回值超过默认的超时时间时，得到的数据就是MockService中的数据。  主机绑定规则 主机绑定表示的是Dubbo服务对外发布的IP地址，默认情况下Dubbo会按照以下顺序来查找并绑定主机IP地址。\n  查找环境变量DUBBO_IP_TO_BIND属性配置的IP地址。\n  查找dubbo.protocol.host属性的IP地址，默认是空，如果没有配置或者IP地址不合法则继续查找。\n  通过LocalHost.getHostAddress获取本机IP地址，获取失败则继续。\n  如果配置了注册中心的地址，则使用Socket通信连接到注册中心的地址后，使用for循环通过socket.getLocalAddress().getHostAddress()扫描各个网卡来获取网卡IP的地址。\n  建议：通过dubbo.protocal.host设置主机地址，防止注册错误的IP地址，使服务消费者无法调用。\n  docker部署解决方案：使用\u0026ndash;net=host绑定网络，然后配置application.yml\n配置inetutils下的两个参数\n  Dubbo源码分析 1 核心点  SPI机制 自适应扩展点 IOC和AOP Dubbo如何与Spring集成。  2 生成IDE工程的命令  mvn idea:idea mvn eclipse:eclipse  3 SPI(Service Provider Interface)  自适应扩展点：AdaptiveExtension 指定名称扩展点：Extension(name) 激活扩展点：ActivateExtension(url,key)  SPI是JDK内置的一种服务提供发现机制，主要用于服务的扩展实现。SPI机制在很多场景中都有运用，比如数据库连接，JDK提供了Driver接口，这个驱动类由不同的数据库厂商来实现，然后JDK利用SPI机制从classpath下找到相应的驱动来获得指定数据库的连接。这种插拔式的扩展加载方式，也同样遵循一定的协议约定，比如所有的扩展点必须要放在resources/META-INF/services目录下，SPI机制会默认扫描这个路径下的属性文件以完成加载。\n4 Dubbo中的SPI思想 Dubbo或者SpringFactoriesLoader并没有使用JDK内置的SPI机制，只是利用了SPI的思想。Dubbo SPI的相关逻辑被封装在了ExtensionLoader类中，通过ExtensionLoader我们可以加载指定的实现类。\nDubbo的SPI扩展有两个规则：\n 和JDK内置的SPI一样，需要在resources目录下创建任一目录结构：META-INF/dubbo、META-INF/dubbp/internal、META-INF/services，在对应的目录下创建以接口全路径名命名的文件，Dubbo会去三个目录下加载相应扩展点。 文件内容和JDK内置的SPI不一样，内容是key-value形式的数据，key是一个字符串，value是一个对应扩展点的实现，这样的方式可以按照需要加载指定的实现类。  实现步骤如下：\n 在一个依赖了Dubbo框架的工程中，创建一个扩展点及一个实现。其中，扩展点需要声明@SPI注解。 在resources/META-INF/dubbo目录下创建以SPI接口命名的文件 使用ExtensionLoader.getExtensionLoader.getExtension(key)获得指定名称的扩展点实现。  5 Dubbo中的SPI原理 （1）ExtensionLoader.getExtensionLoader：这个方法用于返回一个ExtensionLoader实例，逻辑如下：\n 先从缓存中获取与扩展类对应的ExtensionLoader 缓存未命中，则创建一个新的实例，保存到eEXTENXION_LOADERS集合中缓存起来。 在ExtensionLoader构造方法中，初始化一个objectFactory  （2）getExtension：这个方法用于根据指定名称获取对应的扩展点并返回。\n name用于参数的判断，如果name=\u0026ldquo;true\u0026rdquo;，则返回一个默认的扩展实现。 创建一个Holder对象，用户缓存该扩展点的实例。 如果缓存中不存在，则通过createExtension(name)创建一个扩展点。  （3）createExtension()：去指定的路径下查找name对应的扩展点的实现。\n 通过getExtensionClasses().get(name)获取一个扩展类 通过反射实例化之后缓存到EXTENSION_INSTANCES集合中。 injectExtension实例依赖注入 把扩展类对象通过Wrapper进行包装。  （4）getExtensionClasses()\n 从缓存中换取已经被加载的扩展类 如果缓存未命中，则调用loadExtensionClasses加载扩展类。  （5）loadExtensionClasses()\n 通过cacheDefaultExtensionName方法获取当且扩展接口的默认扩展对象，并且缓存。 调用loadDirectory方法加载指定文件目录下的配置文件。  （6）cacheDefaultExtensionName()\n 获得指定扩展接口的@SPI注解 得到@SPI注解中的名字，保存到cacheDefaultName属性中。  6 自适应扩展点 Adaptive Extension：能够根据上下文动态匹配一个扩展类，使用方式如下：\nExtensionLoader.getExtensionLoader(class).getAdaptiveExtension(); 自适应扩展点通过@Adaptive注解声明，有两种使用方式\n（1）@Adaptive注解定义在类上面，表示当前类为自适应扩展点。\n（2）@Adaptive注解定义上方法层面，会通过动态代理的方式生成一个动态字节码，进行自适应匹配。\n7 Protocol自适应扩展点源码 ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension(); 首先是getExtensionLoader：\n（1）从缓存中获取自适应扩展点实例。\n（2）如果缓存未命中，则通过createAdaptiveExtension创建自适应扩展点。\n然后是createAdaptiveExtension：\n（1）getAdaptiveExtensionClass：获取一个自适应扩展类的实例。\n（2）injectExtension完成依赖注入。\n接着是getAdaptiveExtensionClass：\n（1）通过getExtensionClasses方法加载当前传入类型的所有扩展点，缓存在一个集合中。\n（2）如果cachedAdaptiveClass为空，则调用createAdaptiveExtensionClass进行创建。\n8 IOC 上文中的injectExtension就是依赖注入的实现，整体逻辑为：\n（1）遍历被加载的扩展类中的所有set方法。\n（2）得到set方法中的参数类型，如果参数类型是对象类型，则获得这个set方法中的属性名称。\n（3）使用自适应扩展点加载该属性名称对应的扩展类。\n（4）调用set完成赋值。\n简单来说，injectExtension方法的主要功能是，如果当前加载的扩展类中存在一个成员对象，并且为它提供了set方法，那么就会通过自适应扩展点进行加载并赋值。\n9 AOP 面向切面编程，意图是把业务逻辑和功能逻辑分离，然后在运行期间或者类加载期间进行织入，可以降低代码的复杂性，以及提高重用性。\ninstance = injectExtension((T)WrapperClass.getConstructor(type).newInstance(instance)); 这段代码分别用到了依赖注入和AOP，AOP体现在基于Wrapper装饰器类实现对原有的扩展类instance进行包装。\n10 Dubbo集成Spring机制（略） p89\n什么是Nacos？ Nacos致力于解决微服务中的统一配置、服务注册与发现等问题。它提供了一组简单易用的特性集，帮助开发者快速实现动态服务发现、服务配置、服务元数据以及流量管理。\n1 关键特性   服务发现和服务健康监测\nNacos基于DNS和基于RPC的服务发现。服务提供者通过原生SDK、OpenAPI或一个独立的Agent TODO注册Service后，服务消费者可以使用DNS或HTTP\u0026amp;API查找和发现服务。\nNacos提供对服务的实时的健康检查，阻止向不健康的主机或服务实例发送请求。Nacos支持传输层（PING或TCP）和应用层（如HTTP、MYSQL、用户自定义）的健康检查。对于复杂的云环境和网络拓扑环境（如VPC、边缘网络等）服务的健康检查，Nacos提供了agent上报和服务端主动监测两种健康检查模式。Nacos还提供了统一的健康检查仪表盘。\n  动态配置服务\n业务服务一般都会维护一个本地配置文件，然后把一些常量配置到这个文件中。这种方式在某些场景会存在某些问题，比如配置变更时需要重新部署应用。而动态配置服务可以以中心化、外部化和动态化的方式管理所有环境的应用配置和服务配置。\n  动态DNS服务\n支持权重路由，让开发者更容易实现中间层负载均衡、更灵活的路由策略、流量控制，以及数据中心内网的简单DNS服务。\n  服务及其元数据管理\n  2 Nacos集群 包含一个Leader节点和多个Follower节点。\n数据一致性算法采用的Raft（Etcd、Redis哨兵选举也是这个算法）\n3个或3个以上Nacos节点才能构成集群。\n搭建Nacos注册中心的注意点  dubbo.scan.base-packages功能等同于@DubboComponentScan dubbo.registry.address：Dubbo服务注册中心的配置地址，它的值spring-cloud://url表示挂载到Spring Cloud注册中心，不配置的话会提示没有配置注册中心的错误。 spring.cloud.nacos.discovery.server-addr：Nacos服务注册中心的地址。  Nacos实现原理 1 模块组成  Provider App Consumer App Name Server Nacos Server Nacos Console  整体来说，服务提供者通过Virtual IP访问Nacos Server高可用集群，基于Open API完成服务的注册和服务的查询。Nacos Server本身可以支持主备模式，所以底层会采用数据一致性算法来完成主从节点的整体同步。服务消费者也是如此。\n2 注册中心的原理 服务注册的功能主要体现在：\n 服务实例在启动时注册到服务注册表，并在关闭时注销。（Open API） 服务消费者查询服务注册表，获得可用实例。 服务注册中心需要调用服务实例的健康检查API来验证它是否能够处理请求。（心跳机制）  3 Nacos源码（略）  服务注册 服务地址的获取 服务地址变化的感知  Nacos实现统一配置管理 各个应用自己独立维护本地配置方式的不足：\n1 Nacos集成Spring Boot  在application.properties中配置nacos.config.server-addr 创建NacosConfigController，用于从Nacos Server动态读取配置。 @NacosPropertiesSource：用于加载dataId为example的配置源，autoRefreshed表示开启自动更新。 @NacosValue：设置属性的值，其中info表示key，而Local Hello World表示默认值。也就是说如果key不存在，则使用默认值。这是一种高可用的策略。  2 Nacos集成Spring Cloud  spring.cloud.nacos.config.prefix表示Nacos配置中心上的DataID的前缀。 spring.cloud.nacos.config.server-addr表示Nacos配置中心的地址。 在Nacos Console创建配置 在启动类中，读取配置中心的数据。 注意坑：配置文件必须用bootstrap.yml这个名称，因为bootstrap加载顺序优于application，因为需要在bootstrap配置文件中添加连接到配置中心的配置属性来加载外部配置中心的配置信息。  3 动态更新配置 通过一个while循环不断读取info属性，当info属性发生变化时，控制台可以监听到。\n4 基于DataID配置yaml的文件扩展名 DataID默认规则是${prefix}-${spring.profile.active}.${file-extension}\n 在默认情况下，会去Nacos服务器上加载DataID以${spring.application.name}.${file-extension:properties}为前缀的基础配置。例如：在不通过spring.cloud.nacos.config.prefix指定DataID时，会默认读取DataID为nacos-config-demo.properties的配置信息。 如果明确指定了spring.cloud.nacos.config.prefix，则会加载DataID为指定值的配置。 spring.profile.active表示多环境支持。  在实际应用中，如果使用YAML格式配置，则需要声明spring.cloud.nacos.config.file-extension=yaml\n5 不同环境的配置切换 Spring Boot多环境支持配置步骤如下：\n 在resource目录下根据不同环境创建不同的配置：  application-dev.properties application-test.properties application-prod.properties   定义一个application.properties默认配置，在该配置中通过spring.profile.active=${env}来指定使用哪个环境的配置，如果${env}的值为prod，表示使用prod环境。 也可以通过设置 VM Options=-Dspring.profiles.active=prod来指定。  Nacos Config配置步骤如下：\n 在bootstrap.properties中声明spring.profiles.active=prod 在Nacos控制台新增DataID为nacos-config-demo-prod.properties的配置项。  6 自定义Namespace和Group  Namespace：解决多环境及多租户数据的隔离问题。  使用：在bootstrap.properties里指定spring.cloud.nacos.config.namespace   Group：用于分组管理Data ID  使用：在bootstrap.properties里指定spring.cloud.nacos.config.group    Nacos Config实现原理（略）  获取配置 监听配置 发布配置 删除配置  分为两类：配置的CRUD和配置的动态监听\nSpring Cloud加载配置的原理（略） Nacos源码（略） Sentinel限流及熔断 1 服务限流的作用及实现 主要作用：损失一部分用户的可用性，为大部分用户提供稳定可靠的服务。\n  计算器算法：在制定周期内累加访问次数，当访问次数达到阈值时，触发限流策略。\n  滑动窗口算法：源于TCP拥塞控制，原理是在固定窗口中分割出多个小时间窗口，分别在每个小时间窗口中记录访问次数，然后根据时间将窗口往前滑动并删除过期的小时间窗口。最终只需要统计滑动窗口范围内所有小时间窗口总的计数即可。（Sentinel的原理）\n  令牌桶算法：每一个请求，都需要从令牌桶中获取一个令牌，如果没有获得令牌，则触发限流策略。\n特性：短时间内新增的流量系统能够正常处理。\n  漏桶限流算法：用于控制数据注入网络的速度，平滑网络上的突发流量。\n  2 服务熔断和降级 在微服务架构中，由于服务拆分粒度较细，会出现请求链路较长的情况，用户发起一个请求操作，需要调用多个微服务才能完成。\n雪崩效应：某个服务因为网络延迟或者请求超时等原因不可用时，就会导致当前请求阻塞，一旦某个链路上被依赖的服务不可用，很可能出现请求堆积而产生雪崩。\n所以，服务熔断就是用来解决这个问题的方案，它指的是当某个服务提供者无法正常为服务调用者提供服务时，为了防止整个系统出现雪崩效应，暂时将出现故障的接口隔离出来，断绝与外部接口的联系，当触发熔断后，后续一段时间内该服务调用者的请求都会直接失败，直至目标服务恢复正常。\n3 Sentinel的特性  丰富的应用场景：秒杀、消息削峰填谷、集群流量控制等。 实时监控 开源生态支持 SPI扩展点支持  4 Sentinel的组成：  核心库（Java客户端）：不依赖任何框架与库，能够运行于所有Java运行时环境。 控制台（Dashboard）  5 Sentinel基本应用： 步骤如下：\n（1）定义资源：限流保护的最基本元素，比如一个方法。\n（2）定义限流规则\n（3）检验规则是否生效\n限流规则：通过initFlowRules方法设置\n grade：限流阈值类型，有QPS模式和并发线程数模式。 count：限流阈值 resource：设置需要保护的资源  6 Sentinel资源保护规则 Sentinel支持多种保护规则：流量控制规则、熔断降级规则、系统保护规则、来源访问控制规则、热点参数规则。\n 限流规则：先通过FlowRules来定义限流规则，然后通过FlowRuleManager.loadRules来加载规则列表。  1 QPS流量控制行为 通过controlBehavior设置，包含：\n 直接拒接 Warm UP，冷启动 匀速排队 冷启动 + 匀速排队  7 Sentinel实现服务熔断 通过DegradeRule实现：\n grade：熔断策略，支持秒级RT、秒级异常比例、分钟异常数。默认是秒级RT。 timeWindow：熔断降级的时间窗口，单位为s。也就是出发熔断降级之后多长时间内自动熔断。 rtSlowRequestAmount：在RT模式下，1s内持续多少个请求的平均RT超出阈值后出发熔断，默认值是5 minRequestAmout：触发的异常熔断最小请求数，请求数小于该值时即使异常比例超出阈值也不会触发熔断，默认值是5.  三种熔断策略：\n 平均响应时间RT：如果1s内持续进来5个请求，对应的平均响应时间都超过了阈值(count，单位为ms)，那么在接下来的时间窗口内，对这个方法的调用都会自动熔断，抛出DegradeException 异常比例 最近一分钟异常数：如果timeWindow小于60s，则结束熔断状态后仍然可能再进入熔断状态。  Sentinel集成Spring Cloud 步骤如下：\n  创建项目，集成Spring Cloud依赖。\n  添加Sentinel依赖。\n  创建一个REST接口，并且通过@SentinelResource配置限流保护资源。\n  在上述代码中，配置限流资源有几种情况\n Sentinel starter在默认情况下会为所有的HTTP服务提供限流埋点，所以如果只想对HTTP服务进行限流，只需添加依赖即可。 如果想要对特定的方法进行限流或降级，则需要通过@SentinelResource注解来定义资源。 可以通过SphU.entry()方法来配置资源。    手动配置流控规则，可以借助Sentinel的InitFunc SPI扩展接口来实现，只需要实现自己的InitFunc接口，并在init方法中编写规则加载的逻辑即可。\n  基于Sentinel Dashboard来实现流控配置 步骤如下：\n  启动Sentinel Dashboard\n  在application.yml中增加以下配置\n  提供一个REST接口\n  进入Sentinel Dashboard中配置流控规则。\n  访问簇点链路，找到资源名称。\n  单机流控按钮设置流控规则\n  注意sentinel的坑：\nSentinel自定义URL限流异常 默认情况下，URL触发限流后会返回Blocked by Sentinel字符串\n在实际应用中，大都采用JSON格式，所以如果希望修改触发限流之后的返回结果形式，则可以通过自定义限流异常来处理，实现UrlBlockHandler并且重写blocked方法。\n还有一种场景，当触发限流后，希望跳转到一个降级页面，可以通过下面这个配置来实现。\nspring.cloud.sentinel.servlet.block-page={url}\nSentinel对URL资源清洗 Sentinel中HTTP服务的限流默认由Sentinel-Web-Servlet包中的CommonFilter来实现，这个Filter会把每个不同的URL都作为不同的资源来处理。\n举例：\n 限流统计不准确，实际需求是控制clean方法总的QPS，结果统计的是每个URL的QPS 导致Sentinel中资源数量过多，默认资源数量阈值为6000，对于多出的资源规则将不会生效。  针对这个问题可以通过URLCleaner接口来实现资源清洗，也就是对于/clean/{id}这个URL，我们可以统一归集到/clean/*资源下，具体代码如下：\nSentinel集成Nacos实现动态流控规则 Sentinel的理念是只需要开发者关注资源的定义，默认会对资源进行流控。当然我们还需要自定义流控规则，前面有两种方式：\n 通过FlowRuleManager.loadRules(List rules)手动加载流控规则 在Sentinel Dashboard上针对资源动态创建流控规则。  针对第一种方式，如果接入Sentinel Dashboard，那么同样支持动态修改流控规则。但是，这里会存在一个问题，基于Sentinel Dashboard所配置的流控规则，都是保存在内存中的，一旦应用重启，这些规则都会被清除。为了解决这个问题，Sentinel提供了动态数据源支持。\n目前，Sentinel支持Consul、Zookeeper、Redis、Nacos、Apollo、etcd等数据源的扩展，我们使用Nacos的方式来扩展。\n步骤如下：\n  添加Nacos数据源依赖包\n  创建一个REST接口用于测试。\n  在application.yml中添加数据源配置。\n配置说明：\nrule-type：flow、degrade、param-flow、gw-flow等\ndata-type：Spring Cloud Alibaba提供了JSON和XML两种格式。如果需要自定义，则可以将值配置为custom，并配置converter-class指向converter类。\n  登录Nacos控制台，创建流控配置规则，配置信息如下：\n  最后，登录Sentinel Dashboard，找到执行项目名称菜单下的“流控规则”，就可以看到在Nacos上所配置的流控规则已经被加载了。\n  当在Nacos控制台修改流控规则后，可以同步在Sentinel Dashboard上看到流控规则的变化。\n 注意：在Sentinel Dashboard上修改无法同步到Nacos上。    强烈建议：不要在Nacos上修改流控规则，因为这种修改的危险系数很高。这就意味着流控规则的管理应该集中在Sentinel Dashboard上，所以我们需要实现Sentinel Dashboard来动态维护规则并同步到Nacos上，目前官方还没有提供支持，但可以自己实现。\n  这里有一个坑：出现了空指针异常org.springframework.beans.factory.BeanCreationException: Error creating bean with name \u0026lsquo;ds1-sentinel-nacos-datasource\u0026rsquo;: FactoryBean threw exception on object creation; nested exception is java.lang.NullPointerException，出现原因是Spring-Cloud-Alibaba与Sentinel的版本对应不上，解决办法是把Spring Cloud Alibaba的版本升到2.2.5.RELEASE即可。\n  Sentinel集成Nacos实现规则同步 Sentinel Dashboard的“流控规则”下的所有操作，都会调用Sentinel源码中的FlowControllerV1类，这个类包含流控规则本地化的CRUD\n另外，在com.alibaba.csp.sentinel.dashboard.controller.v2包下存在一个FlowControllerV2类，这个类同样提供流控规则的CRUD，和V1版本不同的是，它可以实现指定数据源的规则拉取和同步。\nFlowControllerV2依赖以下两个非常重要的类\n DynamicRuleProvider：动态规则的拉取，从指定数据源中获取流控规则后在Sentinel Dashboard中展示。 DynamicRulePublisher：动态规则的发布，将在Sentinel Dashboard中修改的规则同步到指定数据源中。  这里我们扩展这两个类，然后集成Nacos来实现Sentinel Dashboard规则的同步。\n1 Sentinel Dashboard源码修改： 具体步骤如下：\n  打开sentinel-dashboard工程，在pom.xml中把sentinel-datasource-nacos依赖的scope注释掉。\n  修改resouces/app/scripts/directives/sidebar/sidebar.html文件下的代码，将dashboard.flowV1改成dashboard.flow\n修改之后，会调用FlowControllerV2中的接口。\n  在com.alibaba.csp.sentinel.dashboard.rule包中创建一个nacos包，并创建一个类用来加载外部化配置。\n  创建一个Nacos配置类NacosConfiguration\n 注入Converter转换器，将FlowRuleEntity转化为FlowRule，以及反向转化。 注入Nacos配置服务ConfigService    创建一个常量类NacosConstants，分别表示默认的GROUP_ID和DATA_ID的后缀。\n  实现动态从Nacos配置中心获取流控规则。\n  创建一个流控规则发布类，在Sentinel Dashboard上修改完配置后，需要调用该发布方法将数据持久化到Nacos中。\n  修改FlowControllerV2类，将上面配置的两个类注入进来，表示规则的拉取和规则的发布统一用我们前面自定义的两个实例。\n  在application.properties文件中添加nacos服务端的配置信息。\n  将代码打包成一个fat jar\n  详见https://blog.csdn.net/weixin_42073629/article/details/107117433 或者test包中的nacos代码\n  2 Sentinel Dashboard规则同步 应用程序需要修改的地方比较少，只需注意配置文件中data-id的命名要以-sentinel-flow结尾即可。\nSentinel集成Dubbo实现限流 Sentinel提供了与Dubbo整合的模块Sentinel Apache Dubbo Adapter，可以针对服务提供者和服务消费者进行流控，在使用的时候，只需要添加以下依赖。\n添加后该依赖后，Dubbo服务中的接口和方法（包括服务端和消费端）就会成为Sentinel中的资源，只需针对指定资源配置流控规则就可以实现Sentinel流控功能。\nSentinel Apache Dubbo Adapter实现限流的核心原理是基于Dubbo的SPI机制实现Filter扩展，Dubbo的Filter机制是专门为服务提供者和服务消费者调用过程进行拦截设计的，每次执行远程方法，该拦截都会被执行。\n同时，Sentinel Apache Dubbo Adapter还可以自定义开启或者关闭某个Filter的功能，下面表示关闭消费端的过滤器。\n 1 Dubbo服务接入Sentinel Dashboard   引入sentinel-transport-simple-http依赖\n  添加启动参数\n  登录Sentinel Dashboard之后，进入“簇点链路”，就可以看到资源信息。\n  需要注意的是，限流可以通过服务接口或服务方法设置\n 服务接口：resourceName为接口的全限定名（包+接口名） 服务方法：resourceName为接口全限定名：方法名（包+接口名:方法名）    2 Dubbo服务限流规则 两种方式\n Sentinel Dashboard FlowRuleManager.loadRules(List rules)  Sentinel Apache Dubbo Adapter组件中没有实现规则持久化，因此有以下步骤来支持：\n 在dubbo服务中添加sentinel-datasource-nacos依赖 通过Sentinel提供的InitFunc扩展点，实现Nacos数据源的配置   访问Sentinel Dashboard，在针对某个资源创建流控规则时，这个规则会同步保存到Nacos的配置中心，而当Nacos配置中心发生变化时，会触发事件机制通知Dubbo应用重新加载流控规则。  Sentinel热点限流 热点数据表示经常访问的数据，在有限场景中我们希望针对这些访问频次非常高的数据进行限流，比如针对一段时间内频繁访问的用户ID地址进行限流，或者针对频繁访问的某个用户ID进行限流。\nSentinel提供了热点参数限流的规则，它是一种特殊的限流，在普通限流的基础上对同一个受保护的资源区根据请求中的参数分别处理，该策略只对包含热点参数的资源调用生效。热点限流在以下场景使用较多：\n 服务网关层：例如防止网络爬虫和恶意攻击，一种常用方法就是限制爬虫的IP地址。 写数据的服务：例如业务系统提供写数据的服务，数据会写入数据库之类的存储系统。存储系统的底层会加锁写磁盘上的文件，部分存储系统会将某一类数据写入同一个文件中。如果底层写同一文件，会出现抢占锁的情况，导致出现大量超时和失败。出现这种情况时一般有两种解决方法：修改存储设计、对热点参数限流。  Sentinel通过LRU策略结合滑动窗口机制来实现热点参数的统计，其中LRU策略可以统计单位时间内最常访问的热点数据，滑动窗口机制可以协助统计每个参数的QPS。\n1 热点参数限流的使用  引用热点参数限流依赖包sentinel-parameter-flow-control 接下来创建一个REST接口，并定义限流埋点，此处针对参数ID配置热点限流规则。 针对不同的热点参数，需要通过SphU.entry(resourceName,EntryType.IN,1,id)方法设置，其最后一个参数是一个数组，有多个热点参数就按照次序依次传入，该配置表示后续会针对该参数进行热点限流。 通过ParamFlowRuleManager.loadRules加载热点参数规则。  2 @SentinelResource 如果是通过@SentinelResource注解来定义资源，当注解所配置得方法上有参数时，Sentinel会把这些参数传入SphU.entry中\n3 热点参数规则说明  durationInSec：统计窗口时间长度，单位为s maxQueueingTimeMS：最长排队等待时长，只有当流控为controlBehavior设置为匀速排队模式时生效。 paramIdx：热点参数的索引，属于必填项，对应的是SphU.entry中的参数索引位置。 paramFlowItemList：针对指定参数值单独设置限流阈值，不受count阈值的限制。  Sentinel的工作原理（略）  工作流程：由各个Slot插槽组成（责任链模式） p229  Spring Cloud Sentinel工作原理（略）  starter自动装配 p232  Sentinel核心源码分析（略）  sentinel-adapter sentinel-core sentinel-dashboard sentinel-demo sentinel-extension sentinel-transport  1 限流的源码实现 2 实时指标数据统计 3 服务降级的实现原理 什么是分布式事务？ 事务：作为单个逻辑工作单元执行的多个数据库操作，要么同时成功，要么同时失败，必须满足ACID特性。（单库多表）\n在微服务架构下，随着业务服务的拆分及数据库的拆分，举例说，订单和库存分别拆分成两个独立的数据库，当客户端发起一个下单操作，需要在订单服务对应的数据库创建订单，同时基于RPC通信调用库存服务完成商品库存的扣减。\n这样，原来的单库事务操作就变成了多个数据库的事务操作 =\u0026gt; 数据不一致问题。\n1 分布式事务问题的理论模型 核心原因：存储资源的分布性\n在实际应用中，应该尽可能从设计层面去避免分布式事务的问题。\n1 X/Open分布式模型 X/Open DTP是X/Open这个组织定义的一套分布式事务的标准。这个标准提出了两阶段提交（2PC，2-phase-commit）来保证分布式事务的完整性。X/Open DTP包含以下三种角色。\n AP：Application RM：Resource Manager TM：Transaction Manager  如果TM需要能够管理多个数据库的事务，则实现步骤如下：\n 配置TM，把多个RM注册到TM，相当于TM注册RM作为数据源。 AP从TM管理的RM中获取连接，如果RM是数据库则获取JDBC连接。 AP向TM发起一个全局事务，生成全局事务ID（XID），XID会通知各个RM。 AP通过第二步获得的连接直接操作RM完成数据库操作。这时，AP在每次操作会把XID传递给RM。 AP结束全局事务，TM会通知各个RM全局事务结束。 根据各个RM的事务执行结果，执行提交或者回滚操作。  其中，TM和多个RM之间的事务控制，是基于XA协议来完成的。目前Oracle、MySQL、DB2都实现了XA接口，因此都能作为RM。\n2 两阶段提交协议 第一阶段：事务的准备阶段\n第二阶段：事务的提交或回滚阶段\n这两个阶段都是由事务管理器发起的，流程如下：\n 准备阶段：TM通知RM准备分支事务，记录事务日志，并告知TM的准备结果。 提交/回滚阶段：如果所有的RM在准备阶段都明确返回成功，TM向所有RM发起提交指令完成数据的变更；反之，则TM向所有RM发送回滚指令。  然而，它并不是完美的，也有缺点：\n 同步阻塞：所有RM都是事务阻塞型的，对于任何一次指令都必须要有明确的响应才能进行下一步，否则会处于阻塞状态。 过于保守：任何一个节点失败都会导致数据回滚。 TM的单点故障：如果TM在第二阶段故障，则所有RM会一直处于锁定状态。 “脑裂”导致数据不一致问题：在第二阶段中，TM向所有RM发送commit请求后，发生局部网络异常导致只有一部分RM接受到commit，剩余未收到请求的则没提交，导致数据出现不一致问题。  3 三阶段提交协议 利用超时机制解决了同步阻塞的问题\n CanCommit（询问阶段）：TM向RM发送事务执行请求，询问是否可以完成指令，参与者只需回答是或者不是即可，不需要做真正的事务操作，这个阶段会有超时中止机制。 PreCommit（准备阶段）：TM根据RM的反馈结果决定是否继续，如果在询问阶段所有RM都能执行操作，则TM向所有RM发送PreCommit请求，RM收到请求后写redo和undo日志，执行事务操作但是不提交事务，然后返回ACK响应等待TM的下一步通知。如果询问阶段任意参与者返回不能执行操作的结果，则TM发送事务中断请求。 DoCommit（提交或回滚阶段）：根据上一步骤的执行结果，如果每个RM都返回成功，则TM发送事务提交指令，反之则中止。  三阶段提交协议与二阶段提交协议的区别\n 增加了一个CanCommit阶段，可以尽早发现无法执行操作而中止后续的行为。 在准备阶段之后，TM和RM都引入超时机制，一旦超时，TM和RM会继续提交事务，并且认为处于成功状态，因为这种情况下事务默认为成功的可能性比较大。  实际上，一旦超时，在三阶段提交协议下仍然可能出现数据不一致的问题，当然概率是比较小的。另外，最大的好处是基于超时机制来避免资源的永久锁定。\n4 CAP定理和BASE理论 XA协议：二阶段提交和三阶段提交，数据一致性强，但可用性低。\nCAP定理：布鲁尔定理，指在分布式系统中不可能同时满足一致性C、可用性A、分区容错性P，最多同时满足两个。\n C：数据在多个副本中要保持强一致 A：系统对外提供的服务必须一直处于可用状态。 P：在分布式系统中遇到任何网络分区故障，系统仍然能够正常对外提供服务。  在分布式系统中，要么满足CP，要么满足AP，不可能实现CAP或者CA，因为网络通信不是绝对可靠的。\n AP：放弃强一致性，实现最终的一致。（很多互联网公司的主要选择） CP：放弃高可用性，实现强一致性。（2PC和3PC，存在问题：用户完成一个操作可能会等待较长的时间，用户体验差）  BASE理论：由于CAP中CA不可兼得衍生出来的一种新的思想。核心思想是：牺牲数据的强一致性来获得高可用性，有三个特性：\n Basically Avaliable（基本可用）：分布式系统出现故障时，允许损失一部分功能的可用性，保证核心功能的可用。 Soft State（软状态）：允许系统中的数据存在中间状态，这个状态不影响系统的可用性，也就是允许系统中不同节点的数据副本之间的同步存在延时。 Eventually Consistent（最终一致性）：中间状态的数据在经过一段时间之后，会达到一个最终的数据一致性。  2 分布式事务问题的常见解决方案 1 TCC补偿性方案 TCC（Try-Confirm-Cancel）是一种比较成熟的分布式数据一致性解决方案，它实际上是把一个完整的业务拆分为如下三个步骤\n Try：这个阶段主要是对数据的校验或者资源的预留。 Confirm：确定真正执行的任务，只操作Try阶段预留的资源。 Cancel：取消执行，释放Try阶段预留的资源。  本质：二阶段提交的思想，第一阶段通过Try准备，第二阶段通过Confirm/Cancel\n2 基于可靠性消息的最终一致性方案 基于可靠性消息的最终一致性方案是互联网公司比较常用的分布式数据一致性解决方案，它主要利用消息中间件（Kafka、RocketMQ或RabbitMQ）的可靠性机制来实现数据一致性的投递。\n总结：消费者没有向消息中间件服务器发送确认之前，这个消息会被重复投递，确保消息的可靠性消费。\n3 最大努力通知型 与基于可靠性消息的最终一致性方案实现类似，是一种比较简单的柔性事务解决方案。\n如果没有返回一个消息确认时，则不断进行重试，直到收到一个消息确认或者达到最大重试次数。\n3 分布式事务框架Seata 提供了AT、TCC、Saga和XA四种事务模式。\n1 AT模式 Seata最主推的分布式事务解决方案，基于XA演进而来，分为TM、RM和TC，TC作为Seata的服务器独立部署。\n2 Saga模式 又称长事务解决方案，主要描述的是在没有2PC的情况下如何解决分布式事务问题。其核心思想是：把一个业务流程中的长事务拆分为多个本地短事务，业务流程中的每个参与者都提交真实提交给本地段事务，当其中一个参与者失败，则通过补偿机制补偿前面已经成功的参与者。\n两种补偿恢复方式：\n 向后恢复：如果任一子事务失败，则撤销执行结果。 向前恢复：不进行补偿，而是对失败的事务进行redo，这种方式比较适合于事务必须要执行成功的场景。  优点：\n 一阶段直接提交本地事务 没有锁等待，性能较高 在事件驱动的模式下，短事务可以异步执行。 补偿机制的实现比较简单。  缺点：不提供原子性和隔离性支持\n协调模式：\n 事件/编排式 命令/协同式  ","date":"2021-04-07T00:00:00Z","image":"https://cdn.jsdelivr.net/gh/PKUcoldkeyboard/image-hosting@master/20210503/dolomites-5076492_1920.5srkr3iefto0.jpg","permalink":"https://cuterwrite.top/p/spring-cloud-alibaba-1/","title":"Spring Cloud Alibaba笔记"}]