<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>SIMD on Cuterwrite's Blog</title><link>https://cuterwrite.top/en/tags/simd/</link><description>Recent content in SIMD on Cuterwrite's Blog</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>cuterwrite</copyright><lastBuildDate>Tue, 13 Aug 2024 22:44:00 +0000</lastBuildDate><atom:link href="https://cuterwrite.top/en/tags/simd/index.xml" rel="self" type="application/rss+xml"/><item><title>Arm Matrix Acceleration: Scalable Matrix Extension SME</title><link>https://cuterwrite.top/en/p/arm-sme-for-performance/</link><pubDate>Tue, 13 Aug 2024 22:44:00 +0000</pubDate><guid>https://cuterwrite.top/en/p/arm-sme-for-performance/</guid><description>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-14_117622407_p0_master1200.webp" alt="Featured image of post Arm Matrix Acceleration: Scalable Matrix Extension SME" />&lt;h1 id="arm-matrix-acceleration-scalable-matrix-extension-sme">
&lt;a href="#arm-matrix-acceleration-scalable-matrix-extension-sme" class="header-anchor">#&lt;/a>
Arm Matrix Acceleration: Scalable Matrix Extension SME
&lt;/h1>
&lt;h2 id="1-sme-introduction">
&lt;a href="#1-sme-introduction" class="header-anchor">#&lt;/a>
1. SME Introduction
&lt;/h2>
&lt;p>Scalable Matrix Extension SME is built on the basis of Scalable Vector Extensions (SVE and SVE2) and adds the capability to efficiently handle matrices. The main features include:&lt;/p>
&lt;ul>
&lt;li>Calculate the SVE vector&amp;rsquo;s outer product&lt;/li>
&lt;li>Matrix tile storage&lt;/li>
&lt;li>Loading, storing, inserting, and extracting tile vectors (including dynamic transposition)&lt;/li>
&lt;li>Streaming SVE mode&lt;/li>
&lt;/ul>
&lt;p>The table below summarizes the main features of SME, SVE, and SVE2:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>SME&lt;/th>
&lt;th>SVE&lt;/th>
&lt;th>SVE2&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Streaming SVE Mode&lt;/td>
&lt;td>NEON DSP++&lt;/td>
&lt;td>Scalable Vector&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Dynamic Matrix Transpose&lt;/td>
&lt;td>Multi-Precision Arithmetic&lt;/td>
&lt;td>Per-Lane Predication&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Vector Cross Product&lt;/td>
&lt;td>Match Detection and Histogram&lt;/td>
&lt;td>Gather-load and Scatter-store&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Load, store, insert, and extract matrix vectors&lt;/td>
&lt;td>Non-temporal scatter/gather&lt;/td>
&lt;td>Predict vectorization&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>Bitwise Permute&lt;/td>
&lt;td>ML Extension (FP16 + DOT)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>AE, SHA3, SM4, Crypto&lt;/td>
&lt;td>V8.6 BF16, FP and Int8 support&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>SME has defined the following new features:&lt;/p>
&lt;ul>
&lt;li>New architecture state, can be used to store two-dimensional matrix tile&lt;/li>
&lt;li>Streaming SVE mode, supports SVE2 instructions where the execution vector length matches the tile length.&lt;/li>
&lt;li>New instruction to accumulate (or decrement) the outer product of two vectors into a matrix tile.&lt;/li>
&lt;li>New load, store, and move instructions: Vectors can be written to a row or column of a matrix tile, or a row or column of a matrix tile can be read into a vector.&lt;/li>
&lt;/ul>
&lt;p>Similar to SVE2, SME is also an extension that supports scalable vector length, enabling vector length agnosticism (VLA), per-lane predication, predication-driven loop control, and management functions.&lt;/p>
&lt;h2 id="2-streaming-sve-mode">
&lt;a href="#2-streaming-sve-mode" class="header-anchor">#&lt;/a>
2. Streaming SVE mode
&lt;/h2>
&lt;p>SME introduced the Streaming SVE mode, which implements a subset of the SVE2 instruction set and adds new SME-specific instructions.&lt;/p>
&lt;p>Streaming SVE mode supports high-throughput streaming data processing for large datasets, and streaming data usually has simple loop control flow and limited conditionality.&lt;/p>
&lt;p>In Non-streaming SVE mode, the complete SVE2 instruction set is supported, typically handling complex data structures and complex judgments.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-14_3443.webp"
alt="Streaming SVE Mode and Non-streaming SVE Mode" width="80%" loading="lazy">&lt;figcaption>
&lt;h4>Streaming SVE Mode and Non-streaming SVE Mode&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>Most SME instructions are only available in Streaming SVE mode. The streaming vector length (SVL) in Streaming SVE mode may differ from the non-streaming vector length (NSVL).&lt;/p>
&lt;p>The expectation is: SVL should be longer than or equal to NSVL, that is, SVL &amp;gt;= NSVL. For example, the length of NSVL can be 128-bit, while the length of SVL can be 512-bit.&lt;/p>
&lt;p>The SVL of SME can be 128-bit, 256-bit, 512-bit, 1024-bit, or 2048-bit. SVL needs to be a power of 2, and NSVL needs to be a multiple of 128.&lt;/p>
&lt;p>Similar to SVE2, the software can control the &lt;code>SMCR_ELx.LEN&lt;/code> register bit to set the effective SVL length that EL1, EL2, EL3 want to use (it can be set shorter than the SVL supported by the hardware).&lt;/p>
&lt;p>For more information on the Streaming SVE mode, refer to section B1.4.6 of the Arm Architecture Reference Manual (A-profile architecture).&lt;/p>
&lt;h2 id="3-switch-between-non-streaming-and-streaming-sve-modes">
&lt;a href="#3-switch-between-non-streaming-and-streaming-sve-modes" class="header-anchor">#&lt;/a>
3. Switch between Non-streaming and Streaming SVE modes
&lt;/h2>
&lt;p>If the CPU hardware implementation supports both Streaming SVE mode of SME and Non-streaming SVE mode of SVE2, applications can dynamically switch between these two operation modes based on their needs.&lt;/p>
&lt;p>Provide an independent operating mode for SME, allowing CPU hardware implementations to offer different vector lengths for the same application. For example, a CPU hardware implementation can choose to support a longer Streaming SVE mode vector length and optimize the hardware for stream operations suitable for high throughput.&lt;/p>
&lt;p>Applications can easily switch dynamically between Streaming SVE mode and Non-streaming SVE mode. The &lt;code>PSTATE.{SM, ZA}&lt;/code> bits introduced by SME can enable and disable Streaming SVE mode and SME ZA storage:&lt;/p>
&lt;ul>
&lt;li>SM: Enable and disable Streaming SVE mode&lt;/li>
&lt;li>ZA: Enable and disable ZA storage access&lt;/li>
&lt;/ul>
&lt;p>You can use the &lt;code>MSR/MRS&lt;/code> instructions to operate the Streaming Vector Control Register (SVCR) to set and read the &lt;code>PSTATE.{SM, ZA}&lt;/code> bits, with specific operations as follows:&lt;/p>
&lt;ul>
&lt;li>&lt;code>MSR SVCRSM, #&amp;lt;imm&amp;gt; MSR SVCRSM, #&lt;/code>&lt;/li>
&lt;li>&lt;code>MSR SVCRZA, #&amp;lt;imm&amp;gt;&lt;/code>&lt;/li>
&lt;li>&lt;code>MSR SVCRSMZA, #&amp;lt;imm&amp;gt;&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>The SMSTART instruction is an alias for the &lt;code>MSR&lt;/code> instruction that sets &lt;code>PSTATE.SM&lt;/code> and &lt;code>PSTATE.ZA&lt;/code>.&lt;/p>
&lt;ul>
&lt;li>&lt;code>SMSTART&lt;/code>: Simultaneously enable Streaming SVE mode and ZA storage access&lt;/li>
&lt;li>&lt;code>SMSTART SM&lt;/code>: Enable Streaming SVE mode&lt;/li>
&lt;li>&lt;code>SMSTART ZA&lt;/code>: Enable ZA storage access&lt;/li>
&lt;/ul>
&lt;p>The SMSTOP instruction is an alias for the &lt;code>MSR&lt;/code> instruction that clears &lt;code>PSTATE.SM&lt;/code> and &lt;code>PSTATE.ZA&lt;/code>.&lt;/p>
&lt;ul>
&lt;li>&lt;code>SMSTOP&lt;/code>: Simultaneously disable Streaming SVE mode and ZA storage access&lt;/li>
&lt;li>&lt;code>SMSTOP SM&lt;/code>: Disable Streaming SVE mode&lt;/li>
&lt;li>&lt;code>SMSTOP ZA&lt;/code>: Disable ZA storage access&lt;/li>
&lt;/ul>
&lt;p>The diagram below shows how the application switches between Streaming SVE mode and Non-streaming SVE mode:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-15_Scalable_Matrix_p1.webp"
alt="Application switching Streaming SVE mode and Non-streaming SVE mode" width="50%" loading="lazy">&lt;figcaption>
&lt;h4>Application switching Streaming SVE mode and Non-streaming SVE mode&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>For more information on switching between Streaming SVE mode and Non-Streaming SVE mode using SMSTART and SMSTOP, please refer to sections C6.2.327 and C6.2.328 of the Arm Architecture Reference Manual on A-profile architecture.&lt;/p>
&lt;h2 id="4-sme-architecture-status">
&lt;a href="#4-sme-architecture-status" class="header-anchor">#&lt;/a>
4. SME Architecture Status
&lt;/h2>
&lt;p>Similar to SVE2, in Streaming SVE mode, it has &lt;code>Z0-Z31&lt;/code> vector registers and &lt;code>P0-P15&lt;/code> predicate registers.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-15_4130_ARM2799_3_Scalable_Matrix_p1.webp"
alt="Streaming mode registers" width="70%" loading="lazy">
&lt;/figure>
&lt;p>The lowest numbered SVE vector register &lt;code>Zn&lt;/code> also holds fixed-length &lt;code>Vn&lt;/code>, &lt;code>Qn&lt;/code>, &lt;code>Dn&lt;/code>, &lt;code>Sn&lt;/code>, &lt;code>Hn&lt;/code>, and &lt;code>Bn&lt;/code> registers.&lt;/p>
&lt;p>When entering Streaming SVE mode (&lt;code>PSTATE.SM&lt;/code> changes from 0 to 1) or exiting Streaming SVE mode (&lt;code>PSTATE.SM&lt;/code> changes from 1 to 0), all these registers will be zeroed.&lt;/p>
&lt;p>Most non-streaming SVE2 instructions can be used in Streaming SVE mode, but &lt;strong>may use different vector lengths&lt;/strong> (streaming mode uses VSL length, non-streaming mode uses NVSL length). The &lt;code>RDSVL&lt;/code> instruction can be used to read the current effective vector length VL.&lt;/p>
&lt;pre>&lt;code class="language-armasm">// Read multiple of Streaming SVE vector register size to Xd
RDSVL &amp;lt;Xd&amp;gt;, #&amp;lt;imm&amp;gt;
&lt;/code>&lt;/pre>
&lt;blockquote class="alert-blockquote alert-note">
&lt;p class="alert-heading">
&lt;svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16">
&lt;path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z">&lt;/path>
&lt;/svg>
&lt;span>Note&lt;/span>
&lt;/p>
&lt;p>Because SME supports Vector Length Agnostic (VLA), in Streaming SVE mode, software rarely needs to explicitly read the SVL vector length. In Non-streaming SVE mode, the RDSVL instruction is usually used to determine the value of SVL.&lt;/p>
&lt;/blockquote>
&lt;h2 id="5-za-array">
&lt;a href="#5-za-array" class="header-anchor">#&lt;/a>
5. ZA array
&lt;/h2>
&lt;p>The newly introduced ZA (Z Array, ZA Storage) in SME is a two-dimensional (2D) square array with a size of SVL x SVL. It is called Z Array because the length of its rows and columns is consistent with the Zn registers in Streaming SVE mode.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-15_4314_ARM2799_4_Scalable_Matrix_p1.webp"
alt="ZA array" width="50%" loading="lazy">&lt;figcaption>
&lt;h4>ZA array&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>For example: If the vector length in Streaming SVE mode is 256-bit, i.e., the length of the Zn register is 256-bit, then the size of ZA is 256/8 bytes x 256/8 bytes.&lt;/p>
&lt;p>The ZA array can be accessed in the following way:&lt;/p>
&lt;ul>
&lt;li>ZA array vector access&lt;/li>
&lt;li>ZA tiles&lt;/li>
&lt;li>ZA tile slices&lt;/li>
&lt;/ul>
&lt;h3 id="51-za-array-vector-access">
&lt;a href="#51-za-array-vector-access" class="header-anchor">#&lt;/a>
5.1 ZA array vector access
&lt;/h3>
&lt;p>A row of the ZA array can be accessed as a vector of SVL length, and this vector can contain elements with data type lengths of 8-bit, 16-bit, 32-bit, 64-bit, or 128-bit, such as 32-bit fp32 floating-point numbers.&lt;/p>
&lt;pre>&lt;code class="language-c">ZA.B[N], ZA.H[N], ZA.S[N], ZA.D[N], ZA.Q[N]
&lt;/code>&lt;/pre>
&lt;p>Among them, &lt;code>B, H, S, D, Q&lt;/code> represent 8-bit, 16-bit, 32-bit, 64-bit, 128-bit, respectively.&lt;/p>
&lt;p>The number of ZA array vectors is the same as the number of bytes in SVL. For example, if SLV is 256-bit, then the number of ZA array vectors is 32, and the range of N is from 0 to 31.&lt;/p>
&lt;p>To support context switching, SME introduces new &lt;code>LDR&lt;/code> and &lt;code>STR&lt;/code> instructions for loading and storing a ZA array vector from memory.&lt;/p>
&lt;pre>&lt;code class="language-armasm">LDR ZA[&amp;lt;Wv&amp;gt;, &amp;lt;imm&amp;gt;], [&amp;lt;Xn|SP&amp;gt;{, #&amp;lt;imm&amp;gt;, MUL VL}]
STR ZA[&amp;lt;Wv&amp;gt;, &amp;lt;imm&amp;gt;], [&amp;lt;Xn|SP&amp;gt;{, #&amp;lt;imm&amp;gt;, MUL VL}]
&lt;/code>&lt;/pre>
&lt;h3 id="52-za-tiles">
&lt;a href="#52-za-tiles" class="header-anchor">#&lt;/a>
5.2 ZA tiles
&lt;/h3>
&lt;p>ZA tile is a square two-dimensional submatrix within ZA. The width of a ZA tile is always SVL, which is the same as the width of the ZA array.&lt;/p>
&lt;p>How many usable ZA tiles ZA can be divided into is determined by the size of the data type of the elements:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Element Data Type Size&lt;/th>
&lt;th>Tile Quantity&lt;/th>
&lt;th>Tile Name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>8-bit&lt;/td>
&lt;td>1&lt;/td>
&lt;td>ZA0.B&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>16-bit&lt;/td>
&lt;td>2&lt;/td>
&lt;td>ZA0.H-ZA1.H&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>32-bit&lt;/td>
&lt;td>4&lt;/td>
&lt;td>ZA0.S-ZA3.S&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>64-bit&lt;/td>
&lt;td>8&lt;/td>
&lt;td>ZA0.D-ZA7.D&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>128-bit&lt;/td>
&lt;td>16&lt;/td>
&lt;td>ZA0.Q-ZA15.Q&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ul>
&lt;li>When the element data type is 8-bit, ZA can only be accessed as a ZA tile (ZA0.B).&lt;/li>
&lt;li>When the element data type is 16-bit, ZA can be accessed as 2 ZA tiles (ZA0.H and ZA1.H).&lt;/li>
&lt;li>When the element data type is 32-bit, ZA can be accessed as 4 ZA tiles (ZA0.S to ZA3.S).&lt;/li>
&lt;li>When the element data type is 64-bit, ZA can be accessed as 8 ZA tiles (ZA0.D to ZA7.D).&lt;/li>
&lt;li>When the element data type is 128-bit, ZA can be accessed as 16 ZA tiles (ZA0.Q to ZA15.Q).&lt;/li>
&lt;/ul>
&lt;p>For example, if SVL is 256-bit and the element data type size is 8-bit, then ZA can be considered as ZA0.B, or it can be seen as 32 vectors (32 rows, each row size is 32 x 8-bit, i.e., 32 elements per row).&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-15_ZA0B.webp"
alt="ZA0.B" width="50%" loading="lazy">
&lt;/figure>
&lt;p>If SVL is 256-bit and the element data type size is 16-bit, then ZA can be considered as 2 ZA tiles (ZA0.H and ZA1.H), with each tile considered as 16 vectors (16 rows, each row size is 16 x 16-bit, i.e., 16 elements per row).&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-15_ZA0H_ZA1H.webp"
alt="ZA0.H and ZA1.H" width="40%" loading="lazy">
&lt;/figure>
&lt;p>The advantage of doing this is to fully utilize ZA storage. In practical applications, for example, when the SVL is 256-bit, the element data type size is 32-bit, and the size of ZA is 256-bit x 256-bit, &lt;strong>to perform an outer product operation on vectors in two Z registers&lt;/strong>, the outer product result is a 2D array of 8 x 8 floating-point numbers. This outer product only requires 1/4 of the storage space of ZA. By dividing ZA into 4 ZA tiles, ZA storage can be fully utilized.&lt;/p>
&lt;h3 id="53-za-tile-slices">
&lt;a href="#53-za-tile-slices" class="header-anchor">#&lt;/a>
5.3 ZA tile slices
&lt;/h3>
&lt;p>A ZA tile can be accessed as a whole or in the form of individual ZA tile slices.&lt;/p>
&lt;p>When accessed as a whole, instructions can be accessed using the name of the tile:&lt;/p>
&lt;pre>&lt;code class="language-text">ZA0.B, ZA0.H-ZA1.H, ZA0.S-ZA3.S, ZA0.D-ZA7.D or ZA0.Q-ZA15.Q
&lt;/code>&lt;/pre>
&lt;p>A ZA tile slice is a one-dimensional array composed of &lt;strong>continuous elements in the horizontal or vertical direction of its ZA tile&lt;/strong>, that is, a row or a column in the ZA tile.&lt;/p>
&lt;p>Accessing a vector of a ZA tile is reading and writing a ZA tile slice:&lt;/p>
&lt;ul>
&lt;li>Horizontal or vertical ZA tile slice access is indicated by the &lt;code>H&lt;/code> or &lt;code>V&lt;/code> suffix following the ZA tile name.&lt;/li>
&lt;li>A specific ZA tile slice is represented by an index, indicated by the slice index &lt;code>[N]&lt;/code> following the ZA tile name.&lt;/li>
&lt;/ul>
&lt;p>For example, if the SVL is 128 bits and the element data type size is 8-bit, then its horizontal and vertical ZA tile slice can be represented as shown in the figure below:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-15_6724_ARM2799_7_Scalable_Matrix_p1.webp"
alt="ZA tile slices" width="50%" loading="lazy">
&lt;/figure>
&lt;p>For example, if the SVL is 128 bits and the element data type size is 16-bit, then its horizontal and vertical ZA tile slice can be represented as shown in the figure below:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-15_6888_ARM2799_8_Scalable_Matrix_p1.webp"
alt="ZA tile slices" width="50%" loading="lazy">
&lt;/figure>
&lt;p>In order to improve the efficiency of hardware access to ZA tile and ZA tile slices, the ZA tile slices of a ZA tile are interleaved.&lt;/p>
&lt;p>The image below shows an example of this interleaved arrangement. In this example, SVL is 256 bits, and the element data type size is 16 bits. This means that ZA can be viewed as two ZA tiles (ZA0H and ZA1H) and has interleaved horizontal tile slices:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-15_4885_SME_interleave.webp"
alt="ZA tile slices" width="auto" loading="lazy">
&lt;/figure>
&lt;p>The figure below shows a mixed view of the horizontal and vertical ZA tile slice sizes for different element data types:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-15_7673_SME_V_H.webp"
alt="ZA tile slices" width="auto" loading="lazy">
&lt;/figure>
&lt;p>The left columns show the different processing methods for each row of the ZA memory.&lt;/p>
&lt;p>Set SIZE as the size of vector elements, where SIZE is 1, 2, 4, 8, 16, representing data types B, H, S, D, or Q, respectively.&lt;/p>
&lt;p>Set NUM_OF_ELEMENTS as the number of elements in the vector, i.e., bytes_of(SVL)/SIZE.&lt;/p>
&lt;p>Horizontal tile slice, &lt;code>ZAnH.&amp;lt;B|H|S|D|Q&amp;gt;[m]&lt;/code> accesses a vector that contains a whole row (m x SIZE + n) in ZA storage. The vector contains elements of data type B, H, S, D, or Q.&lt;/p>
&lt;p>Vertical tile slice, &lt;code>ZAnV.&amp;lt;B|H|S|D|Q&amp;gt;[m] &lt;/code> accesses a vector that contains the entire column (m x SIZE) in ZA storage. This vector contains elements of data type B, H, S, D, or Q.&lt;/p>
&lt;p>&lt;code>ZAnV.[m]&lt;/code> accesses a vector containing column (m x SIZE) and row elements (i x SIZE + n), where i ranges from 0 to NUM_OF_ELEMENTS-1. This vector contains elements of data types B, H, S, D, or Q.&lt;/p>
&lt;p>Be careful with overlapping when applying mixed element data type sizes and horizontal and vertical tile slices.&lt;/p>
&lt;p>For more information on ZA Array, ZA array vectors, tile, and tile slices, refer to sections B1.4.8 to B1.4.12 of the Arm Architecture Reference Manual for the A-profile architecture.&lt;/p>
&lt;h2 id="6-instructions-supported-in-steaming-sve-mode">
&lt;a href="#6-instructions-supported-in-steaming-sve-mode" class="header-anchor">#&lt;/a>
6. Instructions supported in Steaming SVE mode
&lt;/h2>
&lt;p>Some instructions have limitations in Streaming SVE mode:&lt;/p>
&lt;ul>
&lt;li>Some SVE/SVE2 instructions become illegal to execute
&lt;ul>
&lt;li>Gather-load and Scatter-store instructions&lt;/li>
&lt;li>Use the SVE2 instruction of the First Fault register&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Most NEON instructions become UNDEFINED&lt;/li>
&lt;/ul>
&lt;p>For more information about instructions affected by the Streaming SVE mode, please refer to the document &amp;ldquo;Arm Architecture Reference Manual.&amp;rdquo;&lt;/p>
&lt;p>SME has added several new instructions, including:&lt;/p>
&lt;ul>
&lt;li>Matrix outer product and accumulate or subtract instructions, including FMOPA, UMOPA, and BFMOPA.
&lt;ul>
&lt;li>SVE2 vector registers (Z0-Z31) serve as the row and column inputs for outer product operations.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>ZA storage stores the output results of the two-dimensional matrix tile.&lt;/li>
&lt;li>Instructions for performing addition operations with the SVE2 Z vector and the rows or columns of ZA&lt;/li>
&lt;li>Instruction for clearing ZA tiles&lt;/li>
&lt;li>Added some instructions that can be used in both Streaming and Non-streaming modes.&lt;/li>
&lt;/ul>
&lt;h2 id="7-sme-directive">
&lt;a href="#7-sme-directive" class="header-anchor">#&lt;/a>
7. SME Directive
&lt;/h2>
&lt;p>The main SME commands for operating ZA storage include:&lt;/p>
&lt;ul>
&lt;li>Calculate the cross product of two vectors, and then accumulate or decrement, and place the result into an instruction of a ZA tile.&lt;/li>
&lt;li>Instructions to store or load SVE vectors (Z registers) into or from rows or columns of the ZA tile&lt;/li>
&lt;li>In the horizontal or vertical direction, an SVE vector and ZA tile addition instruction&lt;/li>
&lt;li>An instruction to add a multiple of the vector length in Streaming SVE mode to a scalar register&lt;/li>
&lt;/ul>
&lt;h3 id="71-outer-product-and-accumulate-or-subtract-instructions">
&lt;a href="#71-outer-product-and-accumulate-or-subtract-instructions" class="header-anchor">#&lt;/a>
7.1 Outer Product and Accumulate or Subtract Instructions
&lt;/h3>
&lt;p>In order to help understand outer product and accumulate or subtract instructions, let&amp;rsquo;s see how to use the outer product operation to perform matrix multiplication.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-16_2313_Picture1_png-1280x960.webp"
alt="Outer product" width="auto" loading="lazy">
&lt;/figure>
&lt;p>Calculating the outer product of two vectors a and b will yield a result matrix C containing the outer product:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-16_1665_Picture2_png-1280x960.webp"
alt="Outer product" width="auto" loading="lazy">
&lt;/figure>
&lt;p>Now consider the matrix multiplication operation of two matrices a and b:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-16_8117_Picture3_png-1280x960.webp"
alt="Matrix multiplication" width="auto" loading="lazy">
&lt;/figure>
&lt;p>This matrix multiplication can be achieved by calculating two outer product operations and accumulating the two resulting matrices (which is the commonly used handwritten calculation method), as shown in the diagram below:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-16_3731_Picture4_png-1280x960.webp"
alt="Matrix multiplication with outer product" width="auto" loading="lazy">
&lt;/figure>
&lt;p>SME introduced efficient outer product and accumulate or subtract instructions for the following data types:&lt;/p>
&lt;ul>
&lt;li>8-bit, 16-bit integers&lt;/li>
&lt;li>FP16, BF16, FP32, and FP64 floating point numbers&lt;/li>
&lt;/ul>
&lt;p>These instructions calculate the outer product of two vectors in two Z vector registers (Zn and Zm), accumulate or subtract the resulting array with the existing data in a ZA tile (ZAda), and store the result in the same ZA tile (ZAda). Each source vector is independently predicated by the corresponding control predicate registers (Pn and Pm).&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Output Array&lt;/th>
&lt;th>Input Vector&lt;/th>
&lt;th>Description&lt;/th>
&lt;th>Example&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>INT32&lt;/td>
&lt;td>INT8, INT8&lt;/td>
&lt;td>Store the sum of the outer products of four INT8s into each INT32 element&lt;/td>
&lt;td>SMOPA or SMOPS or UMOPA or UMOPS: Signed or unsigned integer outer product sum, and accumulate or subtract. For example: &lt;code>UMOPS &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.B, &amp;lt;Zm&amp;gt;.B&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>INT32&lt;/td>
&lt;td>INT16, INT16&lt;/td>
&lt;td>Store the sum of the outer product of two INT16 in each INT32 element&lt;/td>
&lt;td>SMOPA or SMOPS or UMOPA or UMOPS: Signed or unsigned integer outer product sum, and accumulate or subtract. For example: &lt;code>UMOPS &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.H, &amp;lt;Zm&amp;gt;.H&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>INT64&lt;/td>
&lt;td>INT16, INT16&lt;/td>
&lt;td>If FEAT_SME_I16I64 is implemented, the sum of the outer products of four INT16s is stored in each INT64 element&lt;/td>
&lt;td>SMOPA or SMOPS or UMOPA or UMOPS: signed or unsigned integer outer product sum, and accumulate or subtract. For example: &lt;code>UMOPS &amp;lt;ZAda&amp;gt;.D, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.H, &amp;lt;Zm&amp;gt;.H&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>FP32&lt;/td>
&lt;td>BF16, BF16&lt;/td>
&lt;td>Store the sum of two BF16 outer products into each FP32 element&lt;/td>
&lt;td>BFMOPA or BFMOPS: BFloat16 outer product sum, with accumulation or subtraction. For example: &lt;code>BFMOPS &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.H, &amp;lt;Zm&amp;gt;.H&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>FP32&lt;/td>
&lt;td>FP16, FP16&lt;/td>
&lt;td>Store the sum of two FP16 outer products into each FP32 element&lt;/td>
&lt;td>FMOPA or FMOPS: Half-precision floating-point outer product sum, and accumulate or subtract. For example: &lt;code>FMOPS &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.H, &amp;lt;Zm&amp;gt;.H&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>FP32&lt;/td>
&lt;td>FP32, FP32&lt;/td>
&lt;td>Simple FP32 outer product&lt;/td>
&lt;td>FMOPA or FMOPS: Floating-point outer product and accumulate or subtract. For example: &lt;code>FMOPS &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.S, &amp;lt;Zm&amp;gt;.S&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>FP64&lt;/td>
&lt;td>FP64, FP64&lt;/td>
&lt;td>If FEAT_SME_F64F64 is implemented, perform a simple FP64 outer product&lt;/td>
&lt;td>FMOPA or FMOPS: Floating point outer product and accumulate or subtract. For example: &lt;code>FMOPS &amp;lt;ZAda&amp;gt;.D, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.D, &amp;lt;Zm&amp;gt;.D&lt;/code>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h4 id="711-fp32-fp64-outer-product-and-accumulate-or-subtract-instructions">
&lt;a href="#711-fp32-fp64-outer-product-and-accumulate-or-subtract-instructions" class="header-anchor">#&lt;/a>
7.1.1 FP32, FP64 outer product and accumulate or subtract instructions
&lt;/h4>
&lt;p>Instructions where the input vectors and output arrays have the same data type (FP32, FP64) are relatively simple.&lt;/p>
&lt;p>The following example demonstrates FP32 type outer product with accumulation or subtraction instructions.&lt;/p>
&lt;pre>&lt;code class="language-armasm">FMOPA &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.S, &amp;lt;Zm&amp;gt;.S
FMOPS &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.S, &amp;lt;Zm&amp;gt;.S
&lt;/code>&lt;/pre>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-16_3613751670-667e5f923c64.webp"
alt="FMOPA and FMOPS" width="auto" loading="lazy">
&lt;/figure>
&lt;p>In this example, assuming the SVL vector length is 128, &lt;code>Zn.S&lt;/code> and &lt;code>Zm.S&lt;/code> contain vectors composed of 4 FP32 numbers, this instruction calculates the outer product of &lt;code>Zn.S&lt;/code> and &lt;code>Zm.S&lt;/code>, the result of the outer product is the gray matrix in the figure, then accumulates or subtracts this outer product result with the existing values in the ZA tile &lt;code>ZAda.S&lt;/code>, and stores the result in the same ZA tile.&lt;/p>
&lt;h4 id="712-fp16-bf16-int16-int8-i16i64-type-outer-product-and-accumulate-or-subtract-instructions">
&lt;a href="#712-fp16-bf16-int16-int8-i16i64-type-outer-product-and-accumulate-or-subtract-instructions" class="header-anchor">#&lt;/a>
7.1.2 FP16, BF16, INT16, INT8, I16I64 type outer product and accumulate or subtract instructions
&lt;/h4>
&lt;p>Because these instructions will expand the data type of the calculation results, these operations are not as straightforward as the previous FP32 and FP64 type instructions.&lt;/p>
&lt;ul>
&lt;li>BF16 instruction calculates the outer product of two BF16s, expands the result type to FP32, and then destructively adds or subtracts the result with the target tile.&lt;/li>
&lt;li>INT8 instructions compute the sum of the outer product of four INT8s, expanding the result type to INT32, and then perform destructive addition or subtraction of the result with the target tile.&lt;/li>
&lt;li>INT16 instruction calculates the outer product sum of two INT16s, expands the result type to INT32, and then performs a destructive add or subtract with the target tile.&lt;/li>
&lt;li>FP16 instructions calculate the sum of the outer product of two FP16s, expand the result type to FP32, and then perform destructive addition or subtraction of the result with the target tile.&lt;/li>
&lt;li>If FEAT_SME_I16I64 is implemented, the I16I64 instruction calculates the sum of the outer products of four INT16s, expands the result type to INT64, and then destructively adds or subtracts the result with the target tile.&lt;/li>
&lt;/ul>
&lt;p>The following example demonstrates the operation of the INT8 UMOPA instruction with an SVL vector length of 128:&lt;/p>
&lt;pre>&lt;code class="language-armasm">UMOPA &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.B, &amp;lt;Zm&amp;gt;.B
&lt;/code>&lt;/pre>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-16_1030_Picture6_png-1280x960.webp"
alt="INT8 UMOPA" width="auto" loading="lazy">
&lt;/figure>
&lt;p>Each input register (&lt;code>Zn.B&lt;/code>, &lt;code>Zm.B&lt;/code>) is treated as a matrix containing 4x4 elements, which can be seen as blocks composed of 4 consecutive elements (as marked by the red lines in the diagram) that have been transposed.&lt;/p>
&lt;p>In this example, because the SVL vector length is 128-bit:&lt;/p>
&lt;ul>
&lt;li>The first source vector &lt;code>Zn.B&lt;/code> contains a 4x4 submatrix of unsigned 8-bit integers.&lt;/li>
&lt;li>The second source vector &lt;code>Zm.B&lt;/code>, contains a 4x4 submatrix of unsigned 8-bit integers.&lt;/li>
&lt;li>UMOPA instruction calculates the sum of the 4x4 expanded 32-bit integer outer product, then destructively accumulates the integers in the target tile (ZAda).&lt;/li>
&lt;/ul>
&lt;p>More generally, the UMOPA instruction multiplies submatrices from the first source vector with submatrices from the second source vector. Each source vector contains a submatrix of unsigned 8-bit integers of size (SVL/32) x 4. The resulting (SVL/32) x (SVL/32) expanded 32-bit integer outer product is then destructively added to a 32-bit integer target tile.&lt;/p>
&lt;p>The following example demonstrates the operation of a BF16 BFMOPA with an SVL of 128-bit:&lt;/p>
&lt;pre>&lt;code class="language-armasm">BFMOPA &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.H, &amp;lt;Zm&amp;gt;.H
&lt;/code>&lt;/pre>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-16_6545_Picture7_png-1280x960.webp"
alt="BF16 BFMOPA" width="auto" loading="lazy">
&lt;/figure>
&lt;p>In this example, because the SVL vector length is 128-bit:&lt;/p>
&lt;ul>
&lt;li>The first source vector &lt;code>Zn.H&lt;/code>, contains a 4x2 submatrix of BF16 integers, which is expanded into single-precision floating-point numbers.&lt;/li>
&lt;li>The second source vector &lt;code>Zm.H&lt;/code>, contains a 2x4 submatrix of a BF16 integer, which is expanded into a single-precision floating-point number.&lt;/li>
&lt;li>BMOPA instruction calculates the sum of a 4x4 single-precision outer product, and then destructively accumulates it with the single-precision floating-point numbers in the target tile (ZAda).&lt;/li>
&lt;/ul>
&lt;p>More generally speaking, the BFMOPA instruction expands the type of the (SVL/32) x2 BF16 submatrix stored in the first source vector to single precision, expands the type of the 2x (SVL/32) BF16 submatrix stored in the second source vector to single precision, and multiplies these two submatrices. Then, the resulting (SVL/32) x (SVL/32) single-precision outer product is destructively added to a single-precision target tile.&lt;/p>
&lt;p>The following table shows the number of MACs (Multiply-Accumulate) for the corresponding data type performed by an outer product and accumulate or subtract instruction for several data types and SVL lengths:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>128-bit&lt;/th>
&lt;th>256-bit&lt;/th>
&lt;th>512-bit&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>FP32&lt;/td>
&lt;td>16&lt;/td>
&lt;td>64&lt;/td>
&lt;td>256&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>FP64&lt;/td>
&lt;td>4&lt;/td>
&lt;td>16&lt;/td>
&lt;td>64&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>INT8&lt;/td>
&lt;td>64&lt;/td>
&lt;td>256&lt;/td>
&lt;td>1024&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>INT16&lt;/td>
&lt;td>32&lt;/td>
&lt;td>128&lt;/td>
&lt;td>512&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>BF16&lt;/td>
&lt;td>32&lt;/td>
&lt;td>128&lt;/td>
&lt;td>512&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>FP16&lt;/td>
&lt;td>32&lt;/td>
&lt;td>128&lt;/td>
&lt;td>512&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="72-sme-instructions-with-predication">
&lt;a href="#72-sme-instructions-with-predication" class="header-anchor">#&lt;/a>
7.2 SME Instructions with Predication
&lt;/h3>
&lt;p>Each source vector can be independently predicated by its corresponding control predicate register:&lt;/p>
&lt;ul>
&lt;li>Outer product and accumulate or subtract instructions use Pn/M and Pn/M (without /Z form): Inactive source elements are treated as having a value of 0.&lt;/li>
&lt;li>Slice move command uses Pg/M: The Inactive elements in the target slice remain unchanged.&lt;/li>
&lt;li>Tile slice load instruction uses Pg/Z: Inactive elements in the target tile slice are set to 0.&lt;/li>
&lt;li>Tile slice store instruction uses Pg: Inactive elements that will not be written to memory.&lt;/li>
&lt;/ul>
&lt;p>Predication makes it easier to handle cases where the dimensions of the matrix are not a multiple of SVL.&lt;/p>
&lt;p>For example, the instructions in the image below:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-16_2656_Picture12_png-600x0.webp"
alt="SME prediction" width="auto" loading="lazy">
&lt;/figure>
&lt;p>The input vector &lt;code>Z0&lt;/code> is predicated by &lt;code>P0&lt;/code>, &lt;code>Z1&lt;/code> is predicated by &lt;code>P1&lt;/code>.&lt;/p>
&lt;p>In this example:&lt;/p>
&lt;ul>
&lt;li>SVL vector length is 512-bit.&lt;/li>
&lt;li>The Z register contains a vector of 16 FP32 numbers.&lt;/li>
&lt;li>The last two elements in &lt;code>P0&lt;/code> are inactive.&lt;/li>
&lt;li>The last element in &lt;code>P1&lt;/code> is inactive.&lt;/li>
&lt;/ul>
&lt;p>This instruction updates (16-2) x (16-1) FP32 elements in &lt;code>ZA0.S&lt;/code>, because &lt;code>Pn/M&lt;/code> is used, the remaining elements in &lt;code>ZA0.S&lt;/code> remain unchanged.&lt;/p>
&lt;p>The figure below shows more examples of predicated outer products with accumulation or subtraction. The underlined text in the figure indicates the parts of the calculation affected by inactive predicate elements.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-16_2072_Picture14_png-1280x960.webp"
alt="SME prediction FMOPA" width="auto" loading="lazy">
&lt;/figure>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-16_3513_Picture16_png-1280x960.webp"
alt="SME prediction UMOPA" width="auto" loading="lazy">
&lt;/figure>
&lt;h3 id="73-za-tile-and-addition-operation-with-a-z-vector">
&lt;a href="#73-za-tile-and-addition-operation-with-a-z-vector" class="header-anchor">#&lt;/a>
7.3 ZA tile and addition operation with a Z vector
&lt;/h3>
&lt;p>SME includes instructions to add a vector to the rows or columns of a ZA tile, and these instructions also support predication.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Instruction&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>ADDHA&lt;/td>
&lt;td>Add the source vector to each horizontal slice of the ZA tile&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ADDVA&lt;/td>
&lt;td>Add the source vector to each vertical slice of the ZA tile&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>For example:&lt;/p>
&lt;pre>&lt;code class="language-armasm">ADDHA ZA0.S, P0/M, P1/M, Z1.S
&lt;/code>&lt;/pre>
&lt;p>Will perform the following actions:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-16_ARM2799_9_Scalable_Matrix_p2_png-1200x0.webp"
alt="SME ADDHA" width="auto" loading="lazy">
&lt;/figure>
&lt;p>This ADDHA instruction adds each element of the source vector Z1 to the corresponding active element of each horizontal slice of the ZA0.S tile.&lt;/p>
&lt;p>Elements in a Tile are predicated by a pair of governing predicates. An element in a horizontal slice can be considered active under the following conditions:&lt;/p>
&lt;ul>
&lt;li>It is TRUE for the element corresponding to the second governing predicate, and&lt;/li>
&lt;li>It corresponds to TRUE at the row number of the first governing predicate&amp;rsquo;s horizontal slice, and the inactive elements in the target tile remain unchanged.&lt;/li>
&lt;/ul>
&lt;h3 id="74-tile-load-store-move-instructions">
&lt;a href="#74-tile-load-store-move-instructions" class="header-anchor">#&lt;/a>
7.4 Tile load, store, move instructions
&lt;/h3>
&lt;p>SME tile load, store, move instructions can:&lt;/p>
&lt;ul>
&lt;li>Read data from memory and place it into a row or column of the ZA tile&lt;/li>
&lt;li>Write the row or column of the ZA tile into memory&lt;/li>
&lt;li>Move the row of the ZA tile to the SVE Z vector register&lt;/li>
&lt;li>Move the SVE Z vector register to a ZA tile row or column&lt;/li>
&lt;/ul>
&lt;h4 id="741-tile-slice-load-and-store-instructions">
&lt;a href="#741-tile-slice-load-and-store-instructions" class="header-anchor">#&lt;/a>
7.4.1 Tile slice load and store instructions
&lt;/h4>
&lt;p>The LD1B, LD1H, LD1S, LD1D, and LD1Q instructions load consecutive memory values into a ZA tile slice with 8-bit, 16-bit, 32-bit, 64-bit, or 128-bit elements, respectively.&lt;/p>
&lt;p>The ST1B, ST1H, ST1S, ST1D, and ST1Q instructions store a ZA tile slice containing 8-bit, 16-bit, 32-bit, 64-bit, or 128-bit elements, respectively, into contiguous memory.&lt;/p>
&lt;p>These instructions also support predication, for example:&lt;/p>
&lt;pre>&lt;code class="language-armasm">LD1B ZA0H.B[W0, #imm], P0/Z, [X1, X2]
&lt;/code>&lt;/pre>
&lt;p>This LD1B instruction performs a predicated continuous byte read, reading data from memory at address (X1+X2) into the horizontal tile slice in ZA0 at row number (W0+imm). Inactive elements in the target tile slice are set to 0.&lt;/p>
&lt;pre>&lt;code class="language-armasm">ST1H ZA1V.H[W0, #imm], P2, [X1, X2, LSL #1]
&lt;/code>&lt;/pre>
&lt;p>This ST1H instruction executes a predicated continuous halfword store operation, storing the vertical tile slice in ZA1 with the column number (W0+imm) to the memory address (X1+X2*2), and elements that are inactive in the tile slice are not written to memory.&lt;/p>
&lt;h4 id="742-tile-slice-move-instruction">
&lt;a href="#742-tile-slice-move-instruction" class="header-anchor">#&lt;/a>
7.4.2 Tile slice move instruction
&lt;/h4>
&lt;p>The MOV instruction (alias for the MOVA instruction) moves the value of a Z vector register to a ZA tile slice, or moves the value from a ZA tile slice to a Z vector register. This instruction operates on a single horizontal or vertical tile slice of a ZA tile with a specified element size. The row number/column number of the slice is specified by the slice&amp;rsquo;s retrieval register plus an immediate offset. Inactive elements in the target slice remain unchanged.&lt;/p>
&lt;p>For example:&lt;/p>
&lt;pre>&lt;code class="language-armasm">MOV ZA0H.B[W0, #imm], P0/M, Z0.B
&lt;/code>&lt;/pre>
&lt;p>Or&lt;/p>
&lt;pre>&lt;code class="language-armasm">MOVA ZA0H.B[W0, #imm], P0/M, Z0.B
&lt;/code>&lt;/pre>
&lt;p>This instruction moves the values in vector register &lt;code>Z0.B&lt;/code> to the horizontal ZA tile slice &lt;code>ZA0H.B[W0,#imm]&lt;/code>, using &lt;code>P0&lt;/code> as the predication register. Inactive elements in the target tile slice remain unchanged.&lt;/p>
&lt;h3 id="75-za-array-vector-loadstore-instructions">
&lt;a href="#75-za-array-vector-loadstore-instructions" class="header-anchor">#&lt;/a>
7.5 ZA array vector load/store instructions
&lt;/h3>
&lt;p>SME LDR instruction reads data from memory into a ZA array vector, SME STR instruction stores the values from a ZA array vector into memory.
These instructions do not have predication functionality. They are primarily for saving/restoring ZA storage during software context switching. SME LDR/STR instructions can also be used in Non-streaming SVE mode when PSTATE.ZA is enabled.
For example, the ZA array vector in the following STR instruction is specified by a vector selection register Wv (scalar register W) plus an optional immediate number (Wv+Imm). The address for accessing memory is: a scalar register as the base, plus the same optional immediate offset multiplied by the current vector length in bytes.&lt;/p>
&lt;pre>&lt;code class="language-armasm">STR ZA[&amp;lt;Wv&amp;gt;, &amp;lt;imm&amp;gt;], [&amp;lt;Xn|SP&amp;gt;{, #&amp;lt;imm&amp;gt;, MUL VL}]
&lt;/code>&lt;/pre>
&lt;h3 id="76-za-tile-clear-instruction">
&lt;a href="#76-za-tile-clear-instruction" class="header-anchor">#&lt;/a>
7.6 ZA tile clear instruction
&lt;/h3>
&lt;p>SME ZERO instruction can clear a group of 64-bit ZA tile:&lt;/p>
&lt;pre>&lt;code class="language-armasm">ZERO { &amp;lt;mask&amp;gt;}
&lt;/code>&lt;/pre>
&lt;p>The ZERO instruction can zero out up to 8 ZA tiles named &lt;code>ZA0.D&lt;/code> to &lt;code>ZA8.D&lt;/code>. The tiles to be zeroed are specified by the mask in the instruction, while the remaining tiles remain unchanged.&lt;/p>
&lt;p>This instruction can also be used in Non-streaming SVE mode when &lt;code>PSTATE.ZA&lt;/code> is enabled.&lt;/p>
&lt;p>If you want to clear the entire ZA array, you can use an instruction alias, &lt;code>ZERO {ZA}&lt;/code>.&lt;/p>
&lt;h3 id="77-new-sve2-instructions">
&lt;a href="#77-new-sve2-instructions" class="header-anchor">#&lt;/a>
7.7 New SVE2 Instructions
&lt;/h3>
&lt;p>The SME architecture extension has added some new SVE2 instructions, which can also be used in PE that implements SVE2 when in Non-streaming SVE mode. These instructions include:&lt;/p>
&lt;ul>
&lt;li>Select a predicate register or an all-false Predicate select instruction&lt;/li>
&lt;li>Reverse 64-bit double word element instruction&lt;/li>
&lt;li>Signed/Unsigned clamp to smaller/larger value vector instructions&lt;/li>
&lt;/ul>
&lt;p>The following introduces the Predicate select instruction.&lt;/p>
&lt;h4 id="771-psel-instruction">
&lt;a href="#771-psel-instruction" class="header-anchor">#&lt;/a>
7.7.1 PSEL Instruction
&lt;/h4>
&lt;p>PSEL instruction selects a predicate register or all-false to the target predicate register, as follows:&lt;/p>
&lt;pre>&lt;code class="language-armasm">PSEL &amp;lt;Pd&amp;gt;, &amp;lt;Pn&amp;gt;, &amp;lt;Pm&amp;gt;.&amp;lt;T&amp;gt;[&amp;lt;Wv&amp;gt;, &amp;lt;imm&amp;gt;]
&lt;/code>&lt;/pre>
&lt;p>If the element specified in the second source predicate register (Pm) is True, this instruction places the content of the first source predicate register (Pn) into the destination predicate register (Pd), otherwise, it sets the value of the destination predicate register to all false.
For example, the following instruction, assuming the value of W12 is 0:&lt;/p>
&lt;pre>&lt;code class="language-armasm">PSEL P0, P1, P2.B[W12, #0]
&lt;/code>&lt;/pre>
&lt;p>The [0]th element of the second source predicate register [W12+0] is False, so the target register P0 is set to all 0 (all-false), as shown in the figure below:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-16_4401_Picture10_png-1280x960.webp"
alt="SME PSEL" width="auto" loading="lazy">
&lt;/figure>
&lt;p>Now look at the following instruction, still assuming the value of W12 is 0, but this time the immediate offset is 1:&lt;/p>
&lt;pre>&lt;code class="language-armasm">PSEL P0, P1, P2.B[W12, #1]
&lt;/code>&lt;/pre>
&lt;p>The [1] element of the second source predicate register [W12+1] is True, therefore select the value of the first source predicate register to the destination register P0, as shown in the diagram below:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-16_0116_Picture11_png-1280x960.webp"
alt="SME PSEL" width="auto" loading="lazy">
&lt;/figure>
&lt;h2 id="references">
&lt;a href="#references" class="header-anchor">#&lt;/a>
References
&lt;/h2>
&lt;ul>
&lt;li>&lt;a class="link" href="https://community.arm.com/arm-community-blogs/b/architectures-and-processors-blog/posts/arm-scalable-matrix-extension-introduction" target="_blank" rel="noopener" >Arm Scalable Matrix Extension (SME) Introduction
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/li>
&lt;li>&lt;a class="link" href="https://community.arm.com/arm-community-blogs/b/architectures-and-processors-blog/posts/arm-scalable-matrix-extension-introduction-p2" target="_blank" rel="noopener" >Arm Scalable Matrix Extension (SME) Instructions
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/li>
&lt;/ul></description></item><item><title>Arm Performance Optimization: Scalable Vector Extension SVE</title><link>https://cuterwrite.top/en/p/arm-sve-for-performance/</link><pubDate>Sun, 11 Aug 2024 02:13:00 +0000</pubDate><guid>https://cuterwrite.top/en/p/arm-sve-for-performance/</guid><description>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-29_117622464_p0_master1200.webp" alt="Featured image of post Arm Performance Optimization: Scalable Vector Extension SVE" />&lt;h1 id="arm-performance-optimization-scalable-vector-extension-sve">
&lt;a href="#arm-performance-optimization-scalable-vector-extension-sve" class="header-anchor">#&lt;/a>
ARM Performance Optimization: Scalable Vector Extension SVE
&lt;/h1>
&lt;h2 id="1-sve-introduction">
&lt;a href="#1-sve-introduction" class="header-anchor">#&lt;/a>
1. SVE Introduction
&lt;/h2>
&lt;p>After the Neon architecture extension with a fixed 128-bit vector length instruction set, Arm designed the Scalable Vector Extension (SVE) as the next-generation SIMD extension for AArch64. SVE introduces the scalable concept, allowing flexible vector length implementations and providing a range of possible values in CPU implementations. The vector length can vary from a minimum of 128 bits to a maximum of 2048 bits, in increments of 128 bits. &lt;strong>The SVE design ensures that the same application can run on different SVE-supporting implementations without recompiling the code&lt;/strong>. SVE enhances the architecture&amp;rsquo;s applicability to high-performance computing (HPC) and machine learning (ML) applications, which require very large amounts of data processing. SVE2 is a superset of SVE and Neon. SVE2 allows the use of more functional domains in data-level parallelism. SVE2 inherits the concepts, vector registers, and operation principles of SVE. SVE and SVE2 define 32 scalable vector registers. Chip partners can choose an appropriate vector length design implementation, with hardware varying between 128 bits and 2048 bits (in increments of 128 bits). The advantage of SVE and SVE2 is that only one vector instruction set uses scalable variables.&lt;/p>
&lt;p>The SVE design philosophy allows developers to write and build software once, and then run the same binary on different AArch64 hardware with various SVE vector length implementations. The portability of the binary means developers do not need to know the vector length implementation of their system. This eliminates the need to rebuild the binary, making the software easier to port. In addition to scalable vectors, SVE and SVE2 also include:&lt;/p>
&lt;ul>
&lt;li>per-lane predication&lt;/li>
&lt;li>Gather Load/Scatter Store&lt;/li>
&lt;li>Speculative Vectorization&lt;/li>
&lt;/ul>
&lt;p>These features help vectorize and optimize loops when dealing with large datasets.&lt;/p>
&lt;p>The main difference between SVE2 and SVE lies in the functional coverage of the instruction set. SVE is specifically designed for HPC and ML applications. SVE2 extends the SVE instruction set to enable accelerated data processing in areas beyond HPC and ML. The SVE2 instruction set can also accelerate common algorithms used in the following applications:&lt;/p>
&lt;ul>
&lt;li>Computer Vision&lt;/li>
&lt;li>Multimedia&lt;/li>
&lt;li>LTE Basic Processing&lt;/li>
&lt;li>Genomics&lt;/li>
&lt;li>In-memory database&lt;/li>
&lt;li>Web Service&lt;/li>
&lt;li>General software&lt;/li>
&lt;/ul>
&lt;p>SVE and SVE2 both support collecting and processing large amounts of data. SVE and SVE2 are not extensions of the Neon instruction set. Instead, SVE and SVE2 are redesigned to offer better data parallelism than Neon. However, the hardware logic of SVE and SVE2 covers the implementation of Neon hardware. When a microarchitecture supports SVE or SVE2, it also supports Neon. To use SVE and SVE2, the software running on that microarchitecture must first support Neon.&lt;/p>
&lt;h2 id="2-sve-architecture-basics">
&lt;a href="#2-sve-architecture-basics" class="header-anchor">#&lt;/a>
2. SVE Architecture Basics
&lt;/h2>
&lt;p>This section introduces the basic architectural features shared by SVE and SVE2. Like SVE, SVE2 is also based on scalable vectors. In addition to the existing register file provided by Neon, SVE and SVE2 add the following registers:&lt;/p>
&lt;ul>
&lt;li>32 scalable vector registers, &lt;code>Z0-Z31&lt;/code>&lt;/li>
&lt;li>16 scalable Predicate registers, &lt;code>P0-P15&lt;/code>
&lt;ul>
&lt;li>1 First Fault Predicate register, &lt;code>FFR&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Scalable Vector System Control Register, &lt;code>ZCR_ELx&lt;/code>&lt;/li>
&lt;/ul>
&lt;h3 id="21-scalable-vector-registers">
&lt;a href="#21-scalable-vector-registers" class="header-anchor">#&lt;/a>
2.1 Scalable Vector Registers
&lt;/h3>
&lt;p>Scalable vector registers &lt;code>Z0-Z31&lt;/code> can be implemented in microarchitecture as 128-2048 bits. The lowest 128 bits are shared with Neon&amp;rsquo;s fixed 128-bit vectors &lt;code>V0-V31&lt;/code>.&lt;/p>
&lt;p>The image below shows scalable vector registers &lt;code>Z0-Z31&lt;/code>:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-13_Z-register.webp"
alt="Z Registers-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Scalable Vector Registers Z0-Z31&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>Scalable Vector:&lt;/p>
&lt;ul>
&lt;li>Can accommodate 64, 32, 16, and 8-bit elements&lt;/li>
&lt;li>Supports integer, double precision, single precision, and half precision floating-point elements&lt;/li>
&lt;li>The vector length can be configured for each exception level (EL)&lt;/li>
&lt;/ul>
&lt;h3 id="22-scalable-predicate-register">
&lt;a href="#22-scalable-predicate-register" class="header-anchor">#&lt;/a>
2.2 Scalable Predicate Register
&lt;/h3>
&lt;p>In order to control which active elements participate in operations, Predicate registers (abbreviated as P registers) are used as masks in many SVE instructions, which also provides flexibility for vector operations. The figure below shows the scalable Predicate registers &lt;code>P0-P15&lt;/code>:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-13_Predicate-register.webp"
alt="P Register-2024-08-12" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Scalable Predicate Registers P0-P15&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>The P register is typically used as a bitmask for data manipulation:&lt;/p>
&lt;ul>
&lt;li>Each P register is 1/8 the length of a Z register&lt;/li>
&lt;li>&lt;code>P0-P7&lt;/code> are used for loading, storing, and arithmetic operations&lt;/li>
&lt;li>&lt;code>P8-P15&lt;/code> used for loop management&lt;/li>
&lt;li>FFR is a special P register set by the first-fault vector load and store instructions, used to indicate the success of load and store operations for each element. FFR is designed to support speculative memory access, making vectorization easier and safer in many cases.&lt;/li>
&lt;/ul>
&lt;h3 id="23-scalable-vector-system-control-register">
&lt;a href="#23-scalable-vector-system-control-register" class="header-anchor">#&lt;/a>
2.3 Scalable Vector System Control Register
&lt;/h3>
&lt;p>The figure below shows the Scalable Vector System Control Register &lt;code>ZCR_ELx&lt;/code>:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-13_ZCR_Elx.webp"
alt="ZCR_Elx-2024-08-12" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Scalable Vector System Control Register ZCR_Elx&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>Scalable Vector System Control Register indicates SVE implementation features:&lt;/p>
&lt;ul>
&lt;li>&lt;code>ZCR_Elx.LEN&lt;/code> field is used for the vector length of the current and lower anomaly levels.&lt;/li>
&lt;li>Most bits are currently reserved for future use.&lt;/li>
&lt;/ul>
&lt;h3 id="24-sve-assembly-syntax">
&lt;a href="#24-sve-assembly-syntax" class="header-anchor">#&lt;/a>
2.4 SVE Assembly Syntax
&lt;/h3>
&lt;p>The SVE assembly syntax format consists of an opcode, destination register, P register (if the instruction supports a Predicate mask), and input operands. The following instruction example will detail this format.&lt;/p>
&lt;p>Example 1:&lt;/p>
&lt;pre>&lt;code class="language-armasm">LDFF1D {&amp;lt;Zt&amp;gt;.D}, &amp;lt;Pg&amp;gt;/Z, [&amp;lt;Xn|SP&amp;gt;, &amp;lt;Zm&amp;gt;.D, LSL #3]
&lt;/code>&lt;/pre>
&lt;p>Among them:&lt;/p>
&lt;ul>
&lt;li>&lt;code>&amp;lt;Zt&amp;gt;&lt;/code> is the Z register, &lt;code>Z0-Z31&lt;/code>&lt;/li>
&lt;li>&lt;code>&amp;lt;Zt&amp;gt;&lt;/code>.D and &lt;code>&amp;lt;Zm&amp;gt;&lt;/code>.D specify the element type of the target and operand vectors, without needing to specify the number of elements.&lt;/li>
&lt;li>&lt;code>&amp;lt;Pg&amp;gt;&lt;/code> is the P register, &lt;code>P0-P15&lt;/code>&lt;/li>
&lt;li>&lt;code>&amp;lt;Pg&amp;gt;/Z&lt;/code> is to zero the P register.&lt;/li>
&lt;li>&lt;code>&amp;lt;Zm&amp;gt;&lt;/code> specifies the offset for the Gather Load address mode.&lt;/li>
&lt;/ul>
&lt;p>Example 2:&lt;/p>
&lt;pre>&lt;code class="language-armasm">ADD &amp;lt;Zdn&amp;gt;.&amp;lt;T&amp;gt;, &amp;lt;Pg&amp;gt;/M, &amp;lt;Zdn&amp;gt;.&amp;lt;T&amp;gt;, &amp;lt;Zm&amp;gt;.&amp;lt;T&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>Among them:&lt;/p>
&lt;ul>
&lt;li>&lt;code>&amp;lt;Pg&amp;gt;/M&lt;/code> is the merge P register.&lt;/li>
&lt;li>&lt;code>&amp;lt;Zdn&amp;gt;&lt;/code> is both the destination register and one of the input operands. The instruction syntax shows &lt;code>&amp;lt;Zdn&amp;gt;&lt;/code> in both places for convenience. In the assembly encoding, for simplification, they are only encoded once.&lt;/li>
&lt;/ul>
&lt;p>Example 3:&lt;/p>
&lt;pre>&lt;code class="language-armasm">ORRS &amp;lt;Pd&amp;gt;.B, &amp;lt;Pg&amp;gt;.Z, &amp;lt;Pn&amp;gt;.B, &amp;lt;Pm&amp;gt;.B
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;code>S&lt;/code> is the new interpretation of the P register condition flags &lt;code>NZCV&lt;/code>.&lt;/li>
&lt;li>&lt;code>&amp;lt;Pg&amp;gt;&lt;/code> controls the P register to act as a bitmask in the example operation.&lt;/li>
&lt;/ul>
&lt;h3 id="25-sve-architecture-features">
&lt;a href="#25-sve-architecture-features" class="header-anchor">#&lt;/a>
2.5 SVE Architecture Features
&lt;/h3>
&lt;p>SVE includes the following key architectural features:&lt;/p>
&lt;ul>
&lt;li>per-lane predication&lt;/li>
&lt;/ul>
&lt;p>In order to allow flexible operations on selected elements, SVE introduces 16 P registers, &lt;code>P0-P15&lt;/code>, to indicate valid operations on vector active channels. For example:&lt;/p>
&lt;pre>&lt;code class="language-armasm">ADD Z0.D, P0/M, Z0.D, Z1.D
&lt;/code>&lt;/pre>
&lt;p>Add the active elements &lt;code>Z0&lt;/code> and &lt;code>Z1&lt;/code> and place the result in &lt;code>Z0&lt;/code>. &lt;code>P0&lt;/code> indicates which elements of the operands are active and inactive. The &lt;strong>M&lt;/strong> following &lt;code>P0&lt;/code> stands for Merging, meaning the inactive elements of &lt;code>Z0&lt;/code> will retain their initial values after the &lt;code>ADD&lt;/code> operation. If &lt;strong>Z&lt;/strong> follows &lt;code>P0&lt;/code>, the inactive elements will be zeroed, and the inactive elements of the destination register will be zeroed after the operation.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-13_Per-lane_Predication.webp"
alt="Per-lane_Predication-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Per-lane predication merging&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>If &lt;strong>\Z&lt;/strong> is used, the inactive elements will be zeroed, and the inactive elements of the target register will be zeroed after the operation. For example&lt;/p>
&lt;pre>&lt;code class="language-armasm">CPY Z0.B, P0/Z, #0xFF
&lt;/code>&lt;/pre>
&lt;p>Indicates that the signed integer 0xFF will be copied to the active channel of &lt;code>Z0&lt;/code>, while the inactive channels will be cleared.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-13_Per-lane_Predicate_Zeroing.webp"
alt="Per-lane_Predicate_Zeroing-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Per-lane predication zeroing&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;blockquote class="alert-blockquote alert-note">
&lt;p class="alert-heading">
&lt;svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16">
&lt;path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z">&lt;/path>
&lt;/svg>
&lt;span>Note&lt;/span>
&lt;/p>
&lt;p>Not all instructions have the Predicate option. Additionally, not all Predicate operations have both merge and zeroing options. You must refer to the &lt;a class="link" href="https://developer.arm.com/documentation/ddi0487/latest/t" target="_blank" rel="noopener" >AArch64 SVE Supplement
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
to understand the specification details of each instruction.&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>Gather Load and Scatter Store&lt;/li>
&lt;/ul>
&lt;p>The addressing modes in SVE allow vectors to be used as base addresses and offsets in Gather Load and Scatter Store instructions, which enables access to non-contiguous memory locations. For example:&lt;/p>
&lt;pre>&lt;code class="language-armasm">LD1SB Z0.S, P0/Z, [Z1.S] // Gather Load signed bytes from memory addresses generated by the 32-bit vector base address Z1 into the active 32-bit elements of Z0.
LD1SB Z0.D, P0/Z, [X0, Z1.D] // Gather Load signed bytes from memory addresses generated by the 64-bit scalar base address X0 plus the vector index in Z1.D into the active elements of Z0.
&lt;/code>&lt;/pre>
&lt;p>The following example shows the load operation &lt;code>LD1SB Z0.S, P0/Z, [Z1.S]&lt;/code>, where &lt;code>P0&lt;/code> contains all true elements, and &lt;code>Z1&lt;/code> contains scattered addresses. After loading, the least significant byte of each element in &lt;code>Z0.S&lt;/code> will be updated with data fetched from scattered memory locations.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-13_gather-load_and_scatter_store_example.webp"
alt="gather-load_and_scatter_store_example-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Gather-load and Scatter-store Example&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;ul>
&lt;li>Loop control and management of the P register driver&lt;/li>
&lt;/ul>
&lt;p>As a key feature of SVE, the P register not only flexibly controls individual elements of vector operations but also enables P register-driven loop control. P register-driven loop control and management make loop control efficient and flexible. This feature eliminates the overhead of extra loop heads and tails for processing partial vectors by registering active and inactive element indices in the P register. P register-driven loop control and management mean that in the subsequent loop iterations, only active elements will perform the intended operations. For example:&lt;/p>
&lt;pre>&lt;code class="language-armasm">WHILEL0 P0.S, x8, x9 // Generate a predicate in P0, starting from the lowest numbered element, true when the incremented value of the first unsigned scalar operand X8 is less than the second scalar operand X9, then false until the highest numbered element.
B.FIRST Loop_start // B.FIRST (equivalent to B.MI) or B.NFRST (equivalent to B.PL) is usually used to branch based on the test result of the above instruction, determining whether the first element of P0 is true or false as the condition to end or continue the loop.
&lt;/code>&lt;/pre>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-13_Predicate-driver_loop_control_and_management_example.webp"
alt="Predicate-driver_loop_control_and_management_example-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Example of loop control and management driven by P register&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;ul>
&lt;li>Vector partitioning for speculation in software management&lt;/li>
&lt;/ul>
&lt;p>Speculative loading can pose challenges for memory reading of traditional vectors, &lt;strong>if errors occur in certain elements during the reading process, it is difficult to reverse the load operation and track which elements failed to load&lt;/strong>. Neon does not allow speculative loading. To allow speculative loading of vectors (e.g., LDRFF), SVE introduces the first-fault vector load instruction. To allow vector access across invalid pages, SVE also introduces the FFR register. &lt;strong>When using the first-fault vector load instruction to load into an SVE vector, the FFR register updates with the success or failure result of each element&amp;rsquo;s load&lt;/strong>. When a load error occurs, FFR immediately registers the corresponding element, registers the remaining elements as 0 or false, and does not trigger an exception. Typically, the RDFFR instruction is used to read the FFR status. The RDFFR instruction ends iteration when the first element is false. If the first element is true, the RDFFR instruction continues iteration. The length of FFR is the same as the P vector. This value can be initialized using the SETFFR instruction. The following example uses LDFF1D to read data from memory, and FFR is updated accordingly:&lt;/p>
&lt;pre>&lt;code class="language-armasm">LDFF1D Z0.D, P0/Z, [Z1.D, #0] // Use the first-fault behavior to gather doublewords from the memory address generated by vector base address Z1 plus 0, loading into the active elements of Z0. Inactive elements do not read device memory or trigger a fault, and are set to zero in the destination vector. A successful load from valid memory sets the corresponding element in the FFR to true. The first-fault load sets the corresponding element and the remaining elements in the FFR to false or 0.
&lt;/code>&lt;/pre>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-13_Vector-partioning-for-software-managed-speculation-example.webp"
alt="Vector-partioning-for-software-managed-speculation-example-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Example of Vector Partitioning for Software-Managed Speculation&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;ul>
&lt;li>Extended floating point and horizontal reduction&lt;/li>
&lt;/ul>
&lt;p>In order to allow efficient reduction operations in vectors and meet different precision requirements, SVE enhances floating-point and horizontal reduction operations. These instructions may have a sequential (low to high) or tree-based (pairwise) floating-point reduction order, where the order of operations may lead to different rounding results. These operations require a trade-off between reproducibility and performance. For example:&lt;/p>
&lt;pre>&lt;code class="language-armasm">FADDA D0, P0/M, D1, Z2.D // Perform a floating-point addition strict-order reduction from the low to high elements of the source vector, accumulating the result into the SIMD&amp;amp;FP scalar register. This example instruction adds D1 to all active elements of Z2.D and stores the result into scalar register D0. Vector elements are processed in strict order from low to high, with scalar source D1 providing the initial value. Inactive elements in the source vector are ignored. FADDV performs a recursive pairwise reduction and stores the result into the scalar register.
&lt;/code>&lt;/pre>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-13_Extended_Floating-poing-and-horizontal-reductions-example.webp"
alt="Extended_Floating-poing-and-horizontal-reductions-example-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Extended Floating-point and Horizontal Reductions Example&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;h2 id="3-new-features-of-sve2">
&lt;a href="#3-new-features-of-sve2" class="header-anchor">#&lt;/a>
3. New Features of SVE2
&lt;/h2>
&lt;p>This section introduces the features added by SVE2 to the Arm AArch64 architecture. To achieve scalable performance, SVE2 is built on SVE, allowing vectors to reach up to 2048 bits.&lt;/p>
&lt;p>In SVE2, many instructions that replicate existing instructions in Neon have been added, including:&lt;/p>
&lt;ul>
&lt;li>Converted Neon integer operations, for example, Signed Absolute Difference Accumulate (SAB) and Signed Halving Add (SHADD).&lt;/li>
&lt;li>Converted Neon extensions, narrowing and paired operations, for example, Unsigned Add Long - Bottom (UADDLB) and Unsigned Add Long - Top (UADDLT).&lt;/li>
&lt;/ul>
&lt;p>The order of element processing has changed. SVE2 processes interleaved even and odd elements, while Neon processes the low half and high half elements of narrow or wide operations. The diagram below illustrates the difference between Neon and SVE2 processing:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-13_transformed_neon_widen_narraow_pairwise_operations.webp"
alt="transformed_neon_widen_narraow_pairwise_operations-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Comparison of Transformed Neon Narrow or Wide Operations&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;ul>
&lt;li>Complex number operations, such as complex integer multiplication-accumulation with rotation (CMLA).&lt;/li>
&lt;li>Multi-precision arithmetic, used for large integer arithmetic and cryptography, for example, carry-in long addition - bottom (ADCLB), carry-in long addition - top (ADCLT) and SM4 encryption and decryption (SM4E).&lt;/li>
&lt;/ul>
&lt;p>For backward compatibility, the latest architecture requires Neon and VFP. Although SVE2 includes some features of SVE and Neon, SVE2 does not preclude the presence of Neon on the chip.&lt;/p>
&lt;p>SVE2 supports optimization for emerging applications beyond the HPC market, such as in machine learning (ML) (UDOT instructions), computer vision (TBL and TBX instructions), baseband networks (CADD and CMLA instructions), genomics (BDEP and BEXT instructions), and servers (MATCH and NMATCH instructions).&lt;/p>
&lt;p>SVE2 enhances the overall performance of general-purpose processors in handling large volumes of data, without the need for additional off-chip accelerators.&lt;/p>
&lt;h2 id="4-using-sve-programming">
&lt;a href="#4-using-sve-programming" class="header-anchor">#&lt;/a>
4. Using SVE programming
&lt;/h2>
&lt;p>This section introduces software tools and libraries that support SVE2 application development. This section also explains how to develop applications for targets that support SVE2, run the application on hardware that supports SVE2, and simulate the application on any Armv8-A hardware.&lt;/p>
&lt;h3 id="41-software-and-library-support">
&lt;a href="#41-software-and-library-support" class="header-anchor">#&lt;/a>
4.1 Software and Library Support
&lt;/h3>
&lt;p>To build SVE or SVE2 applications, you must choose a compiler that supports SVE and SVE2 features.&lt;/p>
&lt;ul>
&lt;li>GNU tools version 8.0+ supports SVE.&lt;/li>
&lt;li>&lt;a class="link" href="https://developer.arm.com/tools-and-software/server-and-hpc/compile/arm-compiler-for-linux" target="_blank" rel="noopener" >Arm Compiler for Linux
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
Version 18.0+ supports SVE, Version 20.0+ supports SVE and SVE2.&lt;/li>
&lt;li>Both GNU and Arm Compiler for Linux compilers support optimizing C/C++/Fortran code.&lt;/li>
&lt;li>LLVM (open-source Clang) version 5 and above includes support for SVE, and version 9 and above includes support for SVE2. To find out which SVE or SVE2 features are supported by each version of the LLVM tools, please refer to the &lt;a class="link" href="https://developer.arm.com/tools-and-software/open-source-software/developer-tools/llvm-toolchain/sve-support" target="_blank" rel="noopener" >LLVM toolchain SVE support page
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
.&lt;/li>
&lt;/ul>
&lt;p>&lt;a class="link" href="https://developer.arm.com/Tools%20and%20Software/Arm%20Performance%20Libraries" target="_blank" rel="noopener" >Arm Performance Libraries
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
are highly optimized for mathematical routines and can be linked to your applications. Arm Performance Libraries version 19.3+ supports SVE&amp;rsquo;s math library.&lt;/p>
&lt;p>Arm Compiler for Linux is part of Arm Allinea Studio, including Arm C/C++ Compiler, Arm Fortran Compiler, and Arm Performance Libraries.&lt;/p>
&lt;h3 id="42-how-to-program-using-sve2">
&lt;a href="#42-how-to-program-using-sve2" class="header-anchor">#&lt;/a>
4.2 How to Program Using SVE2
&lt;/h3>
&lt;p>There are several methods to write or generate SVE and SVE2 code. In this section, we will explore some of these methods.&lt;/p>
&lt;p>To write or generate SVE and SVE2 code, you can:&lt;/p>
&lt;ul>
&lt;li>Write SVE assembly code&lt;/li>
&lt;li>Programming with SVE intrinsics&lt;/li>
&lt;li>Automatic vectorization&lt;/li>
&lt;li>Use SVE optimization library&lt;/li>
&lt;/ul>
&lt;p>Let&amp;rsquo;s take a closer look at these four options.&lt;/p>
&lt;h4 id="421-write-sve-assembly-code">
&lt;a href="#421-write-sve-assembly-code" class="header-anchor">#&lt;/a>
4.2.1 Write SVE assembly code
&lt;/h4>
&lt;p>You can write SVE instructions as inline assembly in C/C++ code, or as a complete function in assembly source code. For example:&lt;/p>
&lt;pre>&lt;code class="language-armasm">```assembly
.globl subtract_arrays // -- Begin function
.p2align 2
.type subtract_arrays, @function
subtract_arrays: // @subtract_arrays
.cfi_startproc
// %bb.0:
orr w9, wzr, #0x400
mov x8, xzr
whilelo p0.s, xzr, x9
.LBB0_1: // =&amp;gt;This Inner Loop Header: Depth=1
ld1w { z0.s }, p0/z, [x1, x8, lsl #2]
ld1w { z1.s }, p0/z, [x2, x8, lsl #2]
sub z0.s, z0.s, z1.s
st1w { z0.s }, p0, [x0, x8, lsl #2]
incw x8
whilelo p0.s, x8, x9
b.mi .LBB0_1
// %bb.2:
ret
.Lfunc_end0:
.size subtract_arrays, .Lfunc_end0-subtract_arrays
.cfi_endproc
&lt;/code>&lt;/pre>
&lt;p>If you write functions that mix high-level language and assembly language, you must be familiar with the &lt;a class="link" href="https://developer.arm.com/documentation/ihi0036/latest/" target="_blank" rel="noopener" >Application Binary Interface (ABI)
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
standards updated for SVE. The &lt;a class="link" href="https://developer.arm.com/documentation/ihi0055/latest" target="_blank" rel="noopener" >Arm Architecture Procedure Call Standard (AAPCS)
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
specifies data types and register allocation, and is most relevant to assembly programming. AAPCS requires:&lt;/p>
&lt;ul>
&lt;li>&lt;code>Z0-Z7&lt;/code> and &lt;code>P0-P3&lt;/code> are used to pass scalable vector parameters and results.&lt;/li>
&lt;li>&lt;code>Z8-Z15&lt;/code> and &lt;code>P4-P15&lt;/code> are callee-saved.&lt;/li>
&lt;li>All other vector registers (&lt;code>Z16-Z31&lt;/code>) may be corrupted by the called function, and the calling function is responsible for backing up and restoring them when necessary.&lt;/li>
&lt;/ul>
&lt;h4 id="422-using-sve-instruction-functions-intrinsics">
&lt;a href="#422-using-sve-instruction-functions-intrinsics" class="header-anchor">#&lt;/a>
4.2.2 Using SVE Instruction Functions (Intrinsics)
&lt;/h4>
&lt;p>SVE intrinsic functions are functions supported by the compiler that can be replaced with corresponding instructions. Programmers can directly call instruction functions in high-level languages such as C and C++. The ACLE (Arm C Language Extensions) for SVE defines which SVE intrinsic functions are available, their parameters, and their functionality. A compiler that supports ACLE can replace intrinsics with mapped SVE instructions during compilation. To use ACLE intrinsics, you must include the header file &lt;code>arm_sve.h&lt;/code>, which contains a list of vector types and intrinsic functions (for SVE) that can be used in C/C++. Each data type describes the size and data type of the elements in the vector:&lt;/p>
&lt;ul>
&lt;li>&lt;code>svint8_t svuint8_t&lt;/code>&lt;/li>
&lt;li>&lt;code>svint16_t svuint16_t svfloat16_t&lt;/code>&lt;/li>
&lt;li>&lt;code>svint32_t svuint32_t svfloat32_t&lt;/code>&lt;/li>
&lt;li>&lt;code>svint64_t svuint64_t svfloat64_t&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>For example, &lt;code>svint64_t&lt;/code> represents a 64-bit signed integer vector, &lt;code>svfloat16_t&lt;/code> represents a half-precision floating-point vector.&lt;/p>
&lt;p>The following example C code has been manually optimized using SVE intrinsics:&lt;/p>
&lt;pre>&lt;code class="language-c">// intrinsic_example.c
#include &amp;lt;arm_sve.h&amp;gt;
svuint64_t uaddlb_array(svuint32_t Zs1, svuint32_t Zs2)
{
// widening add of even elements
svuint64_t result = svaddlb(Zs1, Zs2);
return result;
}
&lt;/code>&lt;/pre>
&lt;p>The source code that includes the &lt;code>arm_sve.h&lt;/code> header file can use SVE vector types, just like data types can be used for variable declarations and function parameters. To compile the code using the Arm C/C++ compiler and target the Armv8-A architecture that supports SVE, use:&lt;/p>
&lt;pre>&lt;code class="language-bash">armclang -O3 -S -march=armv8-a+sve2 -o intrinsic_example.s intrinsic_example.c
&lt;/code>&lt;/pre>
&lt;p>This command generates the following assembly code:&lt;/p>
&lt;pre>&lt;code class="language-armasm">// instrinsic_example.s
uaddlb_array: // @uaddlb_array
.cfi_startproc
// %bb.0:
uaddlb z0.d, z0.s, z1.s
ret
&lt;/code>&lt;/pre>
&lt;h4 id="423-automatic-vectorization">
&lt;a href="#423-automatic-vectorization" class="header-anchor">#&lt;/a>
4.2.3 Automatic Vectorization
&lt;/h4>
&lt;p>C/C++/Fortran compilers (for example, the native &lt;a class="link" href="https://developer.arm.com/tools-and-software/server-and-hpc/compile/arm-compiler-for-linux" target="_blank" rel="noopener" >Arm Compiler for Linux
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
for the Arm platform and the GNU compiler) support vectorization of C, C++, and Fortran loops using SVE or SVE2 instructions. To generate SVE or SVE2 code, choose the appropriate compiler options. For example, one option to enable SVE2 optimization using armclang is &lt;code>-march=armv8-a+sve2&lt;/code>. If you want to use the SVE version of the library, combine &lt;code>-march=armv8-a+sve2&lt;/code> with &lt;code>-armpl=sve&lt;/code>.&lt;/p>
&lt;h4 id="424-using-svesve2-to-optimize-libraries">
&lt;a href="#424-using-svesve2-to-optimize-libraries" class="header-anchor">#&lt;/a>
4.2.4 Using SVE/SVE2 to Optimize Libraries
&lt;/h4>
&lt;p>Use libraries highly optimized for SVE/SVE2, such as &lt;a class="link" href="https://developer.arm.com/Tools%20and%20Software/Arm%20Performance%20Libraries" target="_blank" rel="noopener" >Arm Performance Libraries
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
and Arm Compute Libraries. Arm Performance Libraries contain highly optimized implementations of mathematical functions optimized for BLAS, LAPACK, FFT, sparse linear algebra, and libamath. To be able to link any Arm Performance Libraries function, you must install Arm Allinea Studio and include armpl.h in your code. To build applications using Arm Compiler for Linux and Arm Performance Libraries, you must specify &lt;code>-armpl=&amp;lt;arg&amp;gt;&lt;/code> on the command line. If you are using GNU tools, you must include the Arm Performance Libraries installation path in the linker command line with &lt;code>-L&amp;lt;armpl_install_dir&amp;gt;/lib&lt;/code> and specify the GNU option equivalent to the Arm Compiler for Linux &lt;code>-armpl=&amp;lt;arg&amp;gt;&lt;/code> option, which is &lt;code>-larmpl_lp64&lt;/code>. For more information, please refer to the Arm Performance Libraries Getting Started Guide.&lt;/p>
&lt;h3 id="43-how-to-run-svesve2-programs">
&lt;a href="#43-how-to-run-svesve2-programs" class="header-anchor">#&lt;/a>
4.3 How to run SVE/SVE2 programs
&lt;/h3>
&lt;p>If you do not have access to SVE hardware, you can use models or simulators to run the code. You can choose from the following models and simulators:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>QEMU&lt;/strong>: Cross-compilation and native models, supporting modeling on Arm AArch64 platforms with SVE.&lt;/li>
&lt;li>&lt;strong>Fast Models&lt;/strong>: Cross-platform models that support modeling on Arm AArch64 platforms with SVE running on x86-based hosts. Architecture Envelope Model (AEM) with SVE2 support is only available to major partners.&lt;/li>
&lt;li>&lt;strong>Arm Instruction Emulator (ArmIE)&lt;/strong>: Runs directly on the Arm platform. Supports SVE and supports SVE2 from version 19.2+.&lt;/li>
&lt;/ul>
&lt;h2 id="5-acle-intrinsics">
&lt;a href="#5-acle-intrinsics" class="header-anchor">#&lt;/a>
5. ACLE Intrinsics
&lt;/h2>
&lt;h3 id="51-acle-introduction">
&lt;a href="#51-acle-introduction" class="header-anchor">#&lt;/a>
5.1 ACLE Introduction
&lt;/h3>
&lt;p>ACLE (Arm C Language Extensions) is used in C and C++ code to support Arm features through intrinsics and other characteristics.&lt;/p>
&lt;ul>
&lt;li>ACLE (ARM C Language Extensions) extends the C/C++ language with Arm-specific features.
&lt;ul>
&lt;li>Predefined macros: &lt;code>__ARM_ARCH_ISA_A64&lt;/code>, &lt;code>__ARM_BIG_ENDIAN&lt;/code>, etc.&lt;/li>
&lt;li>Internal functions: &lt;code>__clz(uint32_t x)&lt;/code>, &lt;code>__cls(uint32_t x)&lt;/code>, etc.&lt;/li>
&lt;li>Data types: SVE, NEON, and FP16 data types.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>ACLE support for SVE uses ACLE for variable-length vector (VLA) programming.
&lt;ul>
&lt;li>Almost every SVE instruction has a corresponding intrinsic function.&lt;/li>
&lt;li>Data type used to represent size-agnostic vectors used by SVE intrinsics.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Applicable scenarios for the following users:
&lt;ul>
&lt;li>Users who wish to manually adjust SVE code.&lt;/li>
&lt;li>Users who wish to adapt or manually optimize applications and libraries.&lt;/li>
&lt;li>Users who need low-level access to Arm targets.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="52-how-to-use-acle">
&lt;a href="#52-how-to-use-acle" class="header-anchor">#&lt;/a>
5.2 How to use ACLE
&lt;/h3>
&lt;ul>
&lt;li>Include header files
&lt;ul>
&lt;li>&lt;code>arm_acle.h&lt;/code>: Core ACLE&lt;/li>
&lt;li>&lt;code>arm_fp16.h&lt;/code>: Add FP16 data type.
&lt;ul>
&lt;li>The target platform must support FP16, i.e., &lt;code>march=armv8-a+fp16&lt;/code>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>arm_neon.h&lt;/code>: Add NEON Intrinsics and data types.
&lt;ul>
&lt;li>The target platform must support NEON, i.e., &lt;code>march=armv8-a+simd&lt;/code>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>arm_sve.h&lt;/code>: Add SVE Intrinsics and data types.
&lt;ul>
&lt;li>The target platform must support SVE, i.e., &lt;code>march=armv8-a+sve&lt;/code>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="53-sve-acle">
&lt;a href="#53-sve-acle" class="header-anchor">#&lt;/a>
5.3 SVE ACLE
&lt;/h3>
&lt;ul>
&lt;li>The first thing to do is to include the header files&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-c">#include &amp;lt;arm_sve.h&amp;gt;
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>VLA data type
&lt;ul>
&lt;li>&lt;code>svfloat64_t&lt;/code>, &lt;code>svfloat16_t&lt;/code>, &lt;code>svuint32_t&lt;/code>, etc.&lt;/li>
&lt;li>Naming convention: &lt;code>sv&amp;lt;datatype&amp;gt;&amp;lt;datasize&amp;gt;_t&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Prediction
&lt;ul>
&lt;li>Merge: &lt;code>_m&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Reset: &lt;code>_z&lt;/code>&lt;/li>
&lt;li>Uncertain: &lt;code>_x&lt;/code>&lt;/li>
&lt;li>Data type of P register: &lt;code>svbool_t&lt;/code>&lt;/li>
&lt;li>Use generics for function overloading, for example, the function &lt;code>svadd&lt;/code> will automatically select the corresponding function based on the parameter type.&lt;/li>
&lt;li>Function naming convention: &lt;code>svbase[disambiguator][type0][type1]...[predication]&lt;/code>
&lt;ul>
&lt;li>base refers to basic operations, such as &lt;code>add&lt;/code>, &lt;code>mul&lt;/code>, &lt;code>sub&lt;/code>, etc.&lt;/li>
&lt;li>disambiguator is used to distinguish different variants of the same basic operation.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>typeN specifies the type of vector and P register.&lt;/li>
&lt;li>predication specifies the handling method for inactive elements.
&lt;ul>
&lt;li>For example: &lt;code>svfloat64_t svld1_f64&lt;/code>, &lt;code>svbool_t svwhilelt_b8&lt;/code>, &lt;code>svuint32_t svmla_u32_z&lt;/code>, &lt;code>svuint32_t svmla_u32_m&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="54-common-sve-intrinsics">
&lt;a href="#54-common-sve-intrinsics" class="header-anchor">#&lt;/a>
5.4 Common SVE Intrinsics
&lt;/h3>
&lt;ul>
&lt;li>Predicate
&lt;ul>
&lt;li>Predicate is a vector of type bool, used to control whether the corresponding position in the vector participates in the computation during the process.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>svbool_t pg = svwhilelt_b32(i, num)&lt;/code> generates a predicate for (i, i + 1, i + 2, &amp;hellip;, i + vl - 1) &amp;lt; num
&lt;ul>
&lt;li>&lt;code>svbool_t pg = svptrue_b32()&lt;/code> generates a predicate that is all true&lt;/li>
&lt;li>Among them, b32 corresponds to processing 32-bit data (int/float), in addition, there are also intrinsics corresponding to b8, b16, b64.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Memory data access
&lt;ul>
&lt;li>&lt;code>svld1(pg, *base)&lt;/code>: Load contiguous vector from address base.&lt;/li>
&lt;li>&lt;code>svst1(pg, *base, vec)&lt;/code>: Store the vector vec into the address base.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>svld1_gather_index(pg, *base, vec_index)&lt;/code>: Load the data corresponding to the vector index from the address base.&lt;/li>
&lt;li>&lt;code>svst1_scatter_index(pg, *base, vec_index, vec)&lt;/code>: Store data from vector vec to the positions corresponding to the vector indices.&lt;/li>
&lt;li>Basic calculation
&lt;ul>
&lt;li>&lt;code>svadd_z(pg, sv_vec1, sv_vec2)&lt;/code>&lt;/li>
&lt;li>&lt;code>svadd_m(pg, sv_vec1, sv_vec2)&lt;/code>&lt;/li>
&lt;li>&lt;code>svadd_x(pg, sv_vec1, sv_vec2)&lt;/code>&lt;/li>
&lt;li>&lt;code>svadd_x(pg, sv_vec1, x)&lt;/code>&lt;/li>
&lt;li>Among them, &lt;code>_z&lt;/code> indicates setting the position where pg is false to zero, &lt;code>_m&lt;/code> indicates retaining the original value, and &lt;code>_x&lt;/code> indicates uncertainty (any value is possible).&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>The second operand can be scalar data.&lt;/li>
&lt;li>&lt;code>svmul&lt;/code>, &lt;code>svsub&lt;/code>, &lt;code>svsubr&lt;/code>, &lt;code>svdiv&lt;/code>, &lt;code>svdivr&lt;/code>: Among them, &lt;code>svsubr&lt;/code> swaps the position of the subtrahend and the minuend compared to &lt;code>svsub&lt;/code>.&lt;/li>
&lt;li>Others&lt;/li>
&lt;li>&lt;code>svdup_f64(double x)&lt;/code>: Generate a vector with all elements being x.
&lt;ul>
&lt;li>&lt;code>svcntd()&lt;/code>: Returns the vector length of 64-bit data: &lt;code>svcntb&lt;/code> corresponds to 8 bits, &lt;code>svcnth&lt;/code> corresponds to 16 bits, &lt;code>svcntw&lt;/code> corresponds to 32 bits.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="55-sve-structure-intrinsics">
&lt;a href="#55-sve-structure-intrinsics" class="header-anchor">#&lt;/a>
5.5 SVE Structure Intrinsics
&lt;/h3>
&lt;p>For corresponding structure data, SVE provides some special intrinsics, such as: &lt;code>svld3&lt;/code>, &lt;code>svget3&lt;/code>, &lt;code>svset3&lt;/code>, &lt;code>svst3&lt;/code>, etc. These intrinsics are used for processing structure data.&lt;/p>
&lt;p>For example, for the particle structure:&lt;/p>
&lt;pre>&lt;code class="language-c">typedef struct {
float x;
float y;
float z;
} Particle;
&lt;/code>&lt;/pre>
&lt;p>You can use &lt;code>svld3&lt;/code> to load all the data in the structure as a group of 3 vectors, and then use &lt;code>svget3&lt;/code> to extract a vector from the group of 3 vectors, where the value of index 0, 1, 2 corresponds to x, y, z respectively.&lt;/p>
&lt;pre>&lt;code class="language-c">Particle *ps;
float factor = 2.2;
// Initialization part omitted
for (int i = 0; i &amp;lt; num; i += svcntw()) {
svbool_t pg = svwhilelt_b32(i, num);
svfloat32x3_t sv_ps = svld3(pg, (float32_t *)&amp;amp;ps[i]);
svfloat32_t sv_ps_x = svget3(sv_ps, 0);
svfloat32_t sv_ps_y = svget3(sv_ps, 1);
// Perform calculation
sv_ps_x = svmul_x(pg, sv_ps_x, factor);
sv_ps_y = svmul_x(pg, sv_ps_y, factor);
// Save results
sv_ps = svset3(sv_ps, 0, sv_ps_x);
sv_ps = svset3(sv_ps, 1, sv_ps_y);
svst3(pg, (float32_t *)&amp;amp;ps[i], sv_ps);
}
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;code>svld3(pg, *base)&lt;/code>: Load all data in the structure as a group of 3 vectors; where base is the address of the 3-element structure array.&lt;/li>
&lt;li>&lt;code>svget3(tuple, index)&lt;/code>: Extract a vector from a group of 3 vectors; the value of index is 0, 1, or 2.&lt;/li>
&lt;li>&lt;code>svset3(tuple, index, vec)&lt;/code>: Set one vector in a group of 3 vectors; the value of index is 0, 1, or 2.&lt;/li>
&lt;li>&lt;code>svst3(pg, *base, vec)&lt;/code>: Store a group of 3 vectors into a structure; where base is the address of an array of structures with 3 elements.&lt;/li>
&lt;/ul>
&lt;h3 id="56-sve-condition-selection">
&lt;a href="#56-sve-condition-selection" class="header-anchor">#&lt;/a>
5.6 SVE Condition Selection
&lt;/h3>
&lt;p>SVE provides methods such as &lt;code>svcmplt&lt;/code>, &lt;code>svcompact&lt;/code>, &lt;code>svcntp_b32&lt;/code>, etc., which can select elements to retain in the vector based on conditions.&lt;/p>
&lt;p>For example, for non-vectorized code:&lt;/p>
&lt;pre>&lt;code class="language-c">for (int i = 0; i &amp;lt; num; i++) {
float tmp = provided[i];
if (tmp &amp;lt; mark) {
selected[count++] = tmp;
if (count &amp;gt;= maxSize) {
break;
}
}
}
&lt;/code>&lt;/pre>
&lt;p>The purpose of this code is to select elements from the provided array that are less than mark and store them in the selected array until the selected array is full.&lt;/p>
&lt;p>Rewrite with SVE Intrinsic:&lt;/p>
&lt;pre>&lt;code class="language-c">for (int i = 0; i &amp;lt; num; i += svcntw()) {
svbool_t pg = svwhilelt_b32(i, num);
svfloat32_t sv_tmp = svld1(pg, &amp;amp;provided[i]);
svbool_t pg_sel = svcmplt(pg, sv_tmp, mark);
sv_tmp = svcompact(pg_sel, sv_tmp);
svst1(pg, &amp;amp;selected[count], sv_tmp);
count += svcntp_b32(pg, pg_sel);
if (count &amp;gt;= maxSize) {
break;
}
}
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;code>svcmplt(pg, vec1, vec2)&lt;/code>: Compare the size of two vectors, returning a predicate indicating the positions in vec1 that are less than vec2.&lt;/li>
&lt;li>&lt;code>svcompact(pg, sv_tmp)&lt;/code>: Compress the vector, move the data with &lt;code>pg&lt;/code> as active to the lower positions of the vector in order, and set the remaining positions to zero.&lt;/li>
&lt;li>&lt;code>svcntp_b32(pg, pg2)&lt;/code>: Returns the number of active elements in pg2&lt;/li>
&lt;li>This code first loads the data from the provided array into sv_tmp, then uses &lt;code>svcmplt&lt;/code> to generate a predicate indicating the positions less than mark. Next, it uses &lt;code>svcompact&lt;/code> to compress sv_tmp, obtaining the data less than mark, and then stores it into the selected array using &lt;code>svst1&lt;/code>. Finally, it uses &lt;code>svcntp_b32&lt;/code> to count the number of active elements and update count.&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-13_compact.webp"
alt="compact-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>svcompact schematic diagram (256-bit vector)&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>Due to the compact operation, the selected array stores new data less than mark continuously from the count position, and the remaining positions are set to zero.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-08-13_svst1.webp"
alt="svst1-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>svst1 schematic diagram (256-bit vector)&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;h3 id="57-sve-vectorized-loop-interleaving">
&lt;a href="#57-sve-vectorized-loop-interleaving" class="header-anchor">#&lt;/a>
5.7 SVE Vectorized Loop Interleaving
&lt;/h3>
&lt;p>The vectorized loop interleaving implemented by SVE Intrinsic can greatly reduce the number of times vectors are read compared to compiler auto vectorization.&lt;/p>
&lt;p>For example, for non-vectorized code:&lt;/p>
&lt;pre>&lt;code class="language-c">for (int j = offset; j &amp;lt; outerLen - offset; j++) {
int m2index = (j - offset) * innerLen;
int m1index = m2index + innerLen;
int m0index = m1index + innerLen;
int p1index = m0index + innerLen;
int p2index = p1index + innerLen;
for (int i = 0; i &amp;lt; innerLen; i++) {
res[m0index + i] = m2factor * field[m2index + i] +
m1factor * field[m1index + i] +
m0factor * field[m0index + i] +
p1factor * field[p1index + i] +
p2factor * field[p2index + i];
}
}
&lt;/code>&lt;/pre>
&lt;p>After the compiler automatically vectorizes the code, each iteration requires reading data from five different vectors, resulting in low efficiency.&lt;/p>
&lt;p>Rewrite with SVE Intrinsic:&lt;/p>
&lt;pre>&lt;code class="language-c">for (int i = 0; i &amp;lt; innerLen; i += svcntd()) {
svbool_t pg = svwhilelt_b32(i, innerLen);
int dataIndex = i;
svfloat64_t jm2Field = svld1(pg, &amp;amp;field[dataIndex]);
dataIndex += innerLen;
svfloat64_t jm1Field = svld1(pg, &amp;amp;field[dataIndex]);
dataIndex += innerLen;
svfloat64_t jm0Field = svld1(pg, &amp;amp;field[dataIndex]);
dataIndex += innerLen;
svfloat64_t jp1Field = svld1(pg, &amp;amp;field[dataIndex]);
for (int j = offset; j &amp;lt; outerLen - offset; j += 1) {
svfloat64_t jp2Field = svld1(pg, &amp;amp;field[(j + offset) * innerLen + i]);
svfloat64_t svRes = svmul_x(pg, jm2Field, m2factor);
svRes = svmad_x(pg, jm1Field, m1factor, svRes);
svRes = svmad_x(pg, jm0Field, m0factor, svRes);
svRes = svmad_x(pg, jp1Field, p1factor, svRes);
svRes = svmad_x(pg, jp2Field, p2factor, svRes);
svst1(pg, &amp;amp;res[j * innerLen + 1], svRes);
jm2Field = jm1Field;
jm1Field = jm0Field;
jm0Field = jp1Field;
jp1Field = jp2Field;
}
}
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;code>svmad_x(pg, vec1, vec2, vec3)&lt;/code>: Calculates vec1 * vec2 + vec3, returns a vector.&lt;/li>
&lt;li>This code only needs to read one vector per iteration, greatly reducing the number of vector reads.&lt;/li>
&lt;/ul>
&lt;h2 id="references">
&lt;a href="#references" class="header-anchor">#&lt;/a>
References
&lt;/h2>
&lt;ol>
&lt;li>&lt;a class="link" href="https://developer.arm.com/-/media/Arm%20Developer%20Community/PDF/102340_0001_02_en_introduction-to-sve2.pdf?revision=b208e56b-6569-4ae2-b6f3-cd7d5d1ecac3" target="_blank" rel="noopener" >Introduction to SVE2
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/li>
&lt;li>&lt;a class="link" href="https://www.stonybrook.edu/commcms/ookami/support/_docs/5%20-%20Advanced%20SVE.pdf" target="_blank" rel="noopener" >SVE Deep Dive
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/li>
&lt;li>&lt;a class="link" href="https://arm-software.github.io/acle/main/acle.html" target="_blank" rel="noopener" >Arm C Language Extensions
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/li>
&lt;/ol></description></item></channel></rss>