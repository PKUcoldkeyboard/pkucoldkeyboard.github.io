<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Computer Networks on Cuterwrite's Blog</title><link>https://cuterwrite.top/en/tags/computer-network/</link><description>Recent content in Computer Networks on Cuterwrite's Blog</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>cuterwrite</copyright><lastBuildDate>Wed, 26 Jun 2024 23:55:00 +0000</lastBuildDate><atom:link href="https://cuterwrite.top/en/tags/computer-network/index.xml" rel="self" type="application/rss+xml"/><item><title>RDMA: Memory Window</title><link>https://cuterwrite.top/en/p/rdma-memory-window/</link><pubDate>Wed, 26 Jun 2024 23:55:00 +0000</pubDate><guid>https://cuterwrite.top/en/p/rdma-memory-window/</guid><description>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-16_116373724_p0_master1200.webp" alt="Featured image of post RDMA: Memory Window" />&lt;h1 id="memory-window-of-rdma">
&lt;a href="#memory-window-of-rdma" class="header-anchor">#&lt;/a>
Memory Window of RDMA
&lt;/h1>
&lt;p>&lt;strong>This article welcomes non-commercial reprints, please indicate the source when reprinting.&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>Statement: For collection only, for easier reading.&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/353590347">&lt;cite>Zhihu Column: 14. RDMA Memory Window&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>&lt;strong>This article is the 14th in the &amp;ldquo;RDMA Talk&amp;rdquo; column. Welcome to repost, please indicate the source when reposting.&lt;/strong>&lt;/p>
&lt;p>In the article &lt;a class="link" href="https://cuterwrite.top/en/p/rdma-mr/" >【RDMA Memory Region】
&lt;/a>
, we introduced Memory Region, which is a special memory area registered by the user: on one hand, its contents will not be swapped to the hard disk, and on the other hand, the RDMA network card records its address translation relationship, allowing the hardware to find the corresponding physical address after obtaining the virtual address specified by the user in the WR.&lt;/p>
&lt;p>In this article, we will explain the concept of Memory Window, which is a more flexible memory management unit based on Memory Region. Besides the concept of MW, this article will also provide a more detailed introduction to some memory-related concepts in the RDMA field, such as L_Key/R_Key, etc. It is recommended to read this article in conjunction with &lt;a class="link" href="https://cuterwrite.top/en/p/rdma-mr/" >【RDMA Memory Region】
&lt;/a>
for better understanding, and it is suggested that readers review it first.&lt;/p>
&lt;h2 id="what-is-memory-window">
&lt;a href="#what-is-memory-window" class="header-anchor">#&lt;/a>
What is Memory Window
&lt;/h2>
&lt;p>Memory Window, abbreviated as MW, can be translated into Chinese as 内存窗口. It is an RDMA resource requested by the user to allow a remote node to access the local memory area. Each MW is bound (referred to as bind) to an already registered MR, but compared to MR, it can provide more flexible permission control. MW can be roughly understood as a subset of MR, and many MWs can be divided from one MR, each MW can set its own permissions. The relationship between MW and MR is shown in the following diagram:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-28_12_1.webp"
alt="2024-06-28_12_1" width="30%" loading="lazy">&lt;figcaption>
&lt;h4>The relationship between MR and MW&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;h2 id="memory-access-permission-control">
&lt;a href="#memory-access-permission-control" class="header-anchor">#&lt;/a>
Memory access permission control
&lt;/h2>
&lt;p>To explain why MW is designed, let&amp;rsquo;s first discuss the access control involved in both MR and MW.&lt;/p>
&lt;h3 id="mrmw-permissions-configuration">
&lt;a href="#mrmw-permissions-configuration" class="header-anchor">#&lt;/a>
MR/MW permissions configuration
&lt;/h3>
&lt;p>The permissions here refer to the local/remote node, for the read/write permissions of the local memory, they form four combinations:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>Local End&lt;/th>
&lt;th>Remote End&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Read&lt;/td>
&lt;td>Local Read&lt;/td>
&lt;td>Remote Read&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Write&lt;/td>
&lt;td>Local Write&lt;/td>
&lt;td>Remote Write&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Apart from these four types of permissions, there are also Atomic permissions, etc., which are not within the scope of this article.&lt;/p>
&lt;p>Among the four types of permissions in the table, the lowest is Local Read, which is a permission that users must grant to MR/MW because if a piece of memory is inaccessible to local users, it loses its meaning. Additionally, there is a restriction: if an MR needs to be configured with Remote Write or the not-yet-introduced Remote Atomic permissions, it must also be configured with Local Write permissions. Under this constraint, each MR or MW can configure permissions as needed. For example, if an MR we registered needs to allow remote nodes to write data but not read, we enable the Remote Write permission and disable the Remote Read permission. In this way, when the HCA (network card) receives a WRITE request initiated by the peer for a certain address within the range of this MR, it can allow it; however, when the HCA receives a READ operation from the peer on this MR, it will reject the request and return an error message to the peer.&lt;/p>
&lt;h3 id="memory-key">
&lt;a href="#memory-key" class="header-anchor">#&lt;/a>
Memory Key
&lt;/h3>
&lt;p>The above access permission configuration cannot prevent malicious users from accessing local or remote memory. For example, if a node grants Remote Write permission to a memory region, wouldn&amp;rsquo;t any remote node (process) be able to write to this region as long as it provides the correct address information? Therefore, the IB specification designed the Memory Key, which can be simply understood as a key mechanism for accessing MR. Only with the correct key can one open the door to MR/MW.&lt;/p>
&lt;p>Key is a string of numbers, consisting of two parts: a 24-bit Index and an 8-bit Key:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-28_12_2.webp"
alt="2024-06-28_12_2" width="60%" loading="lazy">&lt;figcaption>
&lt;h4>Composition of L_Key/R_Key&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>Among them, Index is used by HCA for quick indexing to local virtual-to-physical address translation tables and other MR-related information, while Key is used to verify the legality of the entire field to prevent unauthorized users from arbitrarily passing the Index.&lt;/p>
&lt;p>Memory Key is divided into two types according to their usage, Local Key and Remote Key:&lt;/p>
&lt;h4 id="l_key">
&lt;a href="#l_key" class="header-anchor">#&lt;/a>
L_Key
&lt;/h4>
&lt;p>Local Key, associated with an MR, is used for HCA to access local memory. When a process on the local side attempts to use memory of an already registered MR, the HCA will verify the L_Key it passes. It uses the index in the L_Key to look up the address translation table, translates the virtual address into a physical address, and then accesses the memory.&lt;/p>
&lt;p>In the article &lt;a class="link" href="https://cuterwrite.top/en/p/rdma-shared-receive-queue/" >【RDMA Shared Receive Queue】
&lt;/a>
, we described sge, which consists of a starting address, length, and key. When users fill out a WR, if they need the HCA to access the local memory, they need to describe the memory block through a linked list of sge (sgl). Here, the key in the sge is filled with L_Key, which are key1 and key3 in the diagram below, representing the L_Key of MR1 and MR2, respectively. Without L_Key, any local user process could direct the hardware to access the contents of other locally registered MRs, and the hardware would find it difficult to efficiently translate virtual addresses to physical addresses.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-28_12_3.webp"
alt="2024-06-28_12_3" width="50%" loading="lazy">&lt;figcaption>
&lt;h4>The function of L_Key&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;h4 id="r_key">
&lt;a href="#r_key" class="header-anchor">#&lt;/a>
R_Key
&lt;/h4>
&lt;p>Remote Key, associated with an MR or MW, is used for a remote node to access local memory. When a remote node attempts to access local memory, on one hand, the local HCA will verify whether the R_Key is valid, and on the other hand, it will use the index in the R_Key to check the address translation table, translating the virtual address into a physical address and then accessing the memory.&lt;/p>
&lt;p>For any RDMA operation (i.e., Write/Read/Atomic), the user must carry the remote memory region&amp;rsquo;s R_Key in the WR.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-28_12_4.webp"
alt="2024-06-28_12_4" width="70%" loading="lazy">&lt;figcaption>
&lt;h4>The Function of R_Key&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>The IB specification ensures that MR can be accessed correctly and safely according to the user&amp;rsquo;s expectations through the two mechanisms mentioned above. We use a metaphor to summarize the content related to MR/MW permission control:&lt;/p>
&lt;p>A equipped their room (MR) with two keys (Memory Key), one for personal use (L_Key), and the other key (R_Key) was sent to B (can be via any communication method). B can open the door when A is not home (the local CPU does not perceive the remote node&amp;rsquo;s RDMA operations on local memory) using the key (R_Key). After opening the door, B might only be able to view the room&amp;rsquo;s arrangement through glass (A only granted remote read permission for this MR), or enter the room and find it completely dark, unable to see anything, but can place items in the room (A only granted remote write permission for this MR), and of course, it is also possible that there&amp;rsquo;s no glass and the lights are on (remote read and write permissions were granted simultaneously).&lt;/p>
&lt;h2 id="why-have-mw">
&lt;a href="#why-have-mw" class="header-anchor">#&lt;/a>
Why have MW
&lt;/h2>
&lt;p>In short, the purpose of designing MW is to control remote memory access permissions more flexibly.&lt;/p>
&lt;p>In the article &lt;a class="link" href="https://cuterwrite.top/en/p/rdma-mr/" >【RDMA 之 Memory Region】
&lt;/a>
, we introduced the process of user registering MR, which requires transitioning from user mode to kernel mode, calling the function provided by the kernel to pin the memory (to prevent paging), and then creating a virtual-physical address mapping table and issuing it to the hardware.&lt;/p>
&lt;p>Because MR is managed by the kernel, if a user wants to modify the information of an existing MR, for example, if I want to revoke the remote write permission of a certain MR, leaving only the remote read permission; or if I want to invalidate an R_Key that was previously authorized to a remote node, the user needs to use the Reregister MR interface to make modifications. This interface is equivalent to first Deregister MR and then Register MR. &lt;strong>The above process requires transitioning to kernel mode to complete, and this process is time-consuming.&lt;/strong>&lt;/p>
&lt;p>Unlike MR, which requires permission modification through the control path, &lt;strong>MW can be dynamically bound to an already registered MR through the data path (i.e., directly issuing WR to the hardware from user space) after creation, and simultaneously set or change its access permissions. This process is much faster than re-registering MR&lt;/strong>.&lt;/p>
&lt;p>In order for a piece of memory to be capable of RDMA WRITE/READ operations by a remote node, we have two methods: registering an MR and registering an MW and then binding it to an already registered MR. Both will generate an R_Key to provide to the remote node. The first method has simpler preparation steps but is less flexible, and once registered, modifications are relatively troublesome. The second method involves additional steps of registering an MW and binding the MW to an MR compared to the first method, but it allows for convenient and quick control over remote access permissions.&lt;/p>
&lt;h2 id="the-relationship-between-mw-and-mr-permissions">
&lt;a href="#the-relationship-between-mw-and-mr-permissions" class="header-anchor">#&lt;/a>
The relationship between MW and MR permissions
&lt;/h2>
&lt;p>Perhaps some readers might think, when configuring their permissions during MR application, and when MW is bound to MR, their permissions are also configured, what is the relationship between these two permissions? The IB specification has a dedicated section on this in 10.6.7.2.2:&lt;/p>
&lt;blockquote>
&lt;p>When binding a Memory Window, a Consumer can request any combination of remote access rights for the Window. However, if the associated Region does not have local write access enabled and the Consumer requests remote write or remote atomic access for the Window, the Channel Interface must return an error either at bind time or access time.&lt;/p>
&lt;/blockquote>
&lt;p>In summary, &lt;strong>if you want to configure remote write or remote atomic operation (Atomic) permissions for MW, then the MR it is bound to must have local write permissions. In other cases, the permissions of the two do not interfere with each other&lt;/strong>: remote users using MW must follow the permission configuration of MW; remote users using MR must follow the permission configuration of MR.&lt;/p>
&lt;h2 id="user-interface">
&lt;a href="#user-interface" class="header-anchor">#&lt;/a>
User Interface
&lt;/h2>
&lt;p>As usual, when it comes to user interfaces, we classify them according to control paths and data paths:&lt;/p>
&lt;h3 id="control-path">
&lt;a href="#control-path" class="header-anchor">#&lt;/a>
Control path
&lt;/h3>
&lt;p>MW supports addition, deletion, and search, but cannot be directly modified:&lt;/p>
&lt;h4 id="create---allocate-mw">
&lt;a href="#create---allocate-mw" class="header-anchor">#&lt;/a>
Create - Allocate MW
&lt;/h4>
&lt;p>Apply for MW, mainly to create the software structure related to MW and prepare the hardware. The user needs to specify the type of MW introduced later in the text. This interface will generate a handle for the Memory Window, which the user can use to refer to this MW in the future.&lt;/p>
&lt;p>Note that at this time MW is not bound to MR and is in a state that cannot be accessed remotely.&lt;/p>
&lt;h4 id="delete---deallocate-mw">
&lt;a href="#delete---deallocate-mw" class="header-anchor">#&lt;/a>
Delete - Deallocate MW
&lt;/h4>
&lt;p>Unregister MW. It&amp;rsquo;s easy to understand, just destroy the related resources.&lt;/p>
&lt;h4 id="query---query-mw">
&lt;a href="#query---query-mw" class="header-anchor">#&lt;/a>
Query - Query MW
&lt;/h4>
&lt;p>Query MW information, including R_Key and its status, MW type, and PD, etc.&lt;/p>
&lt;p>It needs to be emphasized again that although this Verbs is described in the IB specification, the related API has not been implemented in the RDMA software stack. There are quite a few Verbs interfaces in similar situations. The RDMA software stack is based on practicality, and interfaces without user demand are generally not implemented.&lt;/p>
&lt;h3 id="data-path">
&lt;a href="#data-path" class="header-anchor">#&lt;/a>
Data path
&lt;/h3>
&lt;p>MW has a unique set of interfaces in the data path, divided into Bind and Invalidate categories:&lt;/p>
&lt;h4 id="bind">
&lt;a href="#bind" class="header-anchor">#&lt;/a>
Bind
&lt;/h4>
&lt;p>Bind(ing) means &amp;ldquo;binding,&amp;rdquo; which refers to associating an MW with a specified range of an already registered MR and configuring certain read and write permissions. The result of binding will generate an R_key, which the user can pass to a remote node for remote access. Note that an MW can be bound multiple times, and multiple MWs can be bound to a single MR. If an MR still has bound MWs, then this MR cannot be deregistered.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-28_12_5.webp"
alt="2024-06-28_12_5" width="90%" loading="lazy">&lt;figcaption>
&lt;h4>Bind&amp;#39;s Software and Hardware Interaction&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>There are two ways to bind: one is to call the Post Send interface to issue a Bind MW WR, and the other is to call the Bind MW interface.&lt;/p>
&lt;ul>
&lt;li>Post Send Bind MW WR&lt;/li>
&lt;/ul>
&lt;p>In the previous text, we discussed that compared to MR, the biggest advantage of MW is the ability to quickly configure permissions from the data path. Post Send Bind MW WR operation refers to the user issuing a WR to the SQ through the post send interface (such as ibv_post_send()), where the operation type of this WR (such as SEND/RDMA WRITE/RDMA READ) is specified as BIND MW. Additionally, the WR carries information about the permissions and the range of the MR to be bound. Unlike other WRs, after issuing a Bind MW WR, the hardware does not send any packets but instead binds the MW to the specified MR.&lt;/p>
&lt;p>This method is only applicable to Type 2 MW introduced later.&lt;/p>
&lt;ul>
&lt;li>Bind MW&lt;/li>
&lt;/ul>
&lt;p>Although this is an independent interface, it is actually an additional layer encapsulated outside Post Send Bind MW WR. The user provides the relevant information for MW binding, including permissions and the information of the MR to be bound. The driver is responsible for assembling and issuing the WR to the hardware. After the interface succeeds, the newly generated R_Key will be returned to the user.&lt;/p>
&lt;p>This method is only applicable to Type 1 MW introduced later.&lt;/p>
&lt;p>The relationship between the above two operations is as follows:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-28_12_6.webp"
alt="2024-06-28_12_6" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>The relationship between two types of Bind operations&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;h4 id="invalidation">
&lt;a href="#invalidation" class="header-anchor">#&lt;/a>
Invalidation
&lt;/h4>
&lt;p>Invalidate means invalidation, referring to the operation where a user sends a WR with an Invalidate opcode to the hardware to invalidate an R_Key.&lt;/p>
&lt;p>&lt;strong>It is important to emphasize that the object of the Invalidate operation is the R_Key, not the MW itself. The effect after Invalidate is that the remote user can no longer use this R_Key to access the corresponding MW, but the MW resource still exists, and new R_Keys can still be generated for remote use in the future.&lt;/strong>&lt;/p>
&lt;p>The Invalidate operation can only be used for Type 2 MW introduced below.&lt;/p>
&lt;p>According to the different initiators of the Invalidate operation, it can be further divided into two types:&lt;/p>
&lt;ul>
&lt;li>Local Invalidate&lt;/li>
&lt;/ul>
&lt;p>Invalid local operation. If a higher-level user wants to revoke the R_Key permissions of a certain remote user without reclaiming MW resources, they can issue a Local Invalidate operation to the SQ. After the hardware receives it, it will modify the configuration of the corresponding MR. After successful execution, if the remote user holding this R_Key attempts to perform RDMA operations on the MW, the local hardware will reject it and return an error.&lt;/p>
&lt;p>Because it is a local operation, the hardware will not send a message to the link after receiving this WR.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-28_12_7.webp"
alt="2024-06-28_12_7" width="60%" loading="lazy">&lt;figcaption>
&lt;h4>Software and Hardware Interaction of Local Invalidate Operation&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;ul>
&lt;li>Remote Invalidate&lt;/li>
&lt;/ul>
&lt;p>Remote invalid operation. When a remote user no longer uses an R_Key, they can proactively send a message to allow the local end to reclaim this R_Key. The remote user issues a WR with this operation code to the SQ, and once the hardware receives it, it will assemble a message and send it to the local end. After the local hardware receives the remote&amp;rsquo;s Remote Invalidate operation, it will set the corresponding R_Key to an unusable state. Just like Local Invalidate, thereafter the remote end will not be able to use this R_Key to perform RDMA operations on the corresponding MW.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-28_12_8.webp"
alt="2024-06-28_12_8" width="90%" loading="lazy">&lt;figcaption>
&lt;h4>Remote Invalidate operation&amp;#39;s software and hardware interaction&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;h2 id="type-of-mw">
&lt;a href="#type-of-mw" class="header-anchor">#&lt;/a>
Type of MW
&lt;/h2>
&lt;p>According to different implementations and application scenarios, the IB specification classifies MW:&lt;/p>
&lt;h3 id="type-1">
&lt;a href="#type-1" class="header-anchor">#&lt;/a>
Type 1
&lt;/h3>
&lt;p>Type 1 MW is associated with a PD and a QP, and it is not bound to a QP, so it will not affect the destruction of a QP under the same PD.&lt;/p>
&lt;p>The key field of the R_Key for Type 1 MW is controlled by the driver and hardware. Here, &amp;ldquo;controlled&amp;rdquo; means that the key is allocated by the driver and hardware, not by the upper-level user. This is also the reason mentioned earlier that Type 1 MW cannot perform the Invalidate operation. If a user of Type 1 MW wants to invalidate an R_Key, they can bind this MW again through the Bind MW interface. The hardware or driver will automatically allocate a new key field for the R_Key, and the original R_Key will become invalid.&lt;/p>
&lt;p>In addition, if a user temporarily wants to unbind an MW from any MR but still wants to retain the related resources instead of destroying this MW, they can achieve this by calling the Bind MW interface and setting the MW length to 0.&lt;/p>
&lt;p>The IB specification allows multiple Type 1 MWs to be bound to the same MR, and their ranges can overlap.&lt;/p>
&lt;h3 id="type-2">
&lt;a href="#type-2" class="header-anchor">#&lt;/a>
Type 2
&lt;/h3>
&lt;p>Type 2 MW grants users greater freedom, with the key field segment of the R_Key controlled by the user, allowing them to allocate it as they wish. As mentioned earlier, users perform binding through the Post Send Bind MW WR operation, and this process does not return an R_Key. Users must remember the index from the Allocate MW operation and combine it with their chosen 8-bit key to form the R_Key and send it to the peer.&lt;/p>
&lt;p>The user can invalidate an R_Key through the Invalidate operation introduced earlier. If you want to assign a new R_Key to the MW, you must first invalidate the previous R_Key through the Invalidate operation.&lt;/p>
&lt;p>Unlike Type 1, Type 2&amp;rsquo;s MW does not support 0-length binding.&lt;/p>
&lt;p>The IB specification also allows multiple Type 2s to be bound to the same MR, and the ranges can overlap.&lt;/p>
&lt;p>In addition, based on different binding relationships, Type 2 can be further divided into two implementation methods, with their differences lying solely in the binding relationship with QP.&lt;/p>
&lt;h4 id="type-2a">
&lt;a href="#type-2a" class="header-anchor">#&lt;/a>
Type 2A
&lt;/h4>
&lt;p>Associated with a QP through QPN, meaning that when remote access occurs within this MW range, in addition to the R_Key, the correct QPN must also be specified. If a QP has a bound Type 2A MW, then this QP cannot be destroyed.&lt;/p>
&lt;h4 id="type-2b">
&lt;a href="#type-2b" class="header-anchor">#&lt;/a>
Type 2B
&lt;/h4>
&lt;p>By associating a QP with QPN and PD, there is an additional PD verification compared to Type 2A. When the remote end accesses the memory of the MW through RDMA operations, besides the QPN needing to be correct, the PD specified for the local QP must also be the same as the PD bound to this MW. Additionally, unlike Type 2A, a QP can be destroyed even if there is still a Type 2B MW binding relationship.&lt;/p>
&lt;p>The introduction in the original IB specification is relatively scattered, so let&amp;rsquo;s briefly summarize the similarities and differences of several MWs:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>Type 1&lt;/th>
&lt;th>Type 2A&lt;/th>
&lt;th>Type 2B&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Correlation&lt;/td>
&lt;td>PD&lt;/td>
&lt;td>QP&lt;/td>
&lt;td>PD + QP&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>R_Key&amp;rsquo;s key field ownership&lt;/td>
&lt;td>Driver + Hardware&lt;/td>
&lt;td>User&lt;/td>
&lt;td>User&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Binding Method&lt;/td>
&lt;td>Bind MW After binding, the previous R_Key automatically becomes invalid&lt;/td>
&lt;td>Post Send Bind MWWR Before binding, the previous R_Key needs to be invalidated&lt;/td>
&lt;td>Post Send Bind MWWR Before binding, the previous R_Key needs to be invalidated&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Is zero length supported&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>No&lt;/td>
&lt;td>No&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Supports Invalidate&lt;/td>
&lt;td>No&lt;/td>
&lt;td>Yes&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Can the associated QP be destroyed&lt;/td>
&lt;td>-&lt;/td>
&lt;td>No&lt;/td>
&lt;td>Yes&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>In addition, the IB specification also provides the following descriptions for the above types: HCA must implement Type 1 MW, and can optionally choose to implement either Type 2A or 2B. Type 1 and Type 2 MW can be simultaneously associated with the same MR. Since I have not encountered many applications using MW, I cannot clearly explain in which scenarios each type of MW should be used. If readers have insights on this topic, they are welcome to share and discuss.&lt;/p>
&lt;p>Alright, MW will be discussed up to here, and this concludes the introduction of common resources in RDMA technology.&lt;/p>
&lt;p>Given that devices generally supporting RDMA are quite expensive, in the next article I will introduce how to conduct some programming experiments through software-simulated devices—namely Soft-RoCE.&lt;/p>
&lt;h2 id="ib-specification-related-chapters">
&lt;a href="#ib-specification-related-chapters" class="header-anchor">#&lt;/a>
IB specification related chapters
&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>3.5.3 Memory Keys Introduction&lt;/p>
&lt;/li>
&lt;li>
&lt;p>9.4.1.1 Invalidate Operation&lt;/p>
&lt;/li>
&lt;li>
&lt;p>10.6.7 Permission Management&lt;/p>
&lt;/li>
&lt;li>
&lt;p>11.2.10.9~12 Related Verbs Introduction&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="reference-document">
&lt;a href="#reference-document" class="header-anchor">#&lt;/a>
Reference document
&lt;/h2>
&lt;p>[1] IB Specification Vol 1-Release-1.4&lt;/p>
&lt;p>[2] Linux Kernel Networking - Implementation and Theory. Chapter 13&lt;/p></description></item><item><title>RDMA: Shared Receive Queue</title><link>https://cuterwrite.top/en/p/rdma-shared-receive-queue/</link><pubDate>Wed, 26 Jun 2024 23:34:00 +0000</pubDate><guid>https://cuterwrite.top/en/p/rdma-shared-receive-queue/</guid><description>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-16_116373922_p0_master1200.webp" alt="Featured image of post RDMA: Shared Receive Queue" />&lt;h1 id="shared-receive-queue-in-rdma">
&lt;a href="#shared-receive-queue-in-rdma" class="header-anchor">#&lt;/a>
Shared Receive Queue in RDMA
&lt;/h1>
&lt;p>&lt;strong>This article welcomes non-commercial reprints, please indicate the source when reprinting.&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>Statement: For collection only, for easy reading.&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/279904125">&lt;cite>Zhihu Column: 11. RDMA Shared Receive Queue&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>We briefly introduced the concept of SRQ in &lt;a class="link" href="https://cuterwrite.top/en/p/rdma-element/" >【3. Basic Elements of RDMA】
&lt;/a>
. This article will take you through more details about SRQ.&lt;/p>
&lt;h2 id="basic-concepts">
&lt;a href="#basic-concepts" class="header-anchor">#&lt;/a>
Basic Concepts
&lt;/h2>
&lt;h3 id="what-is-srq">
&lt;a href="#what-is-srq" class="header-anchor">#&lt;/a>
What is SRQ?
&lt;/h3>
&lt;p>The full name is Shared Receive Queue, literally translated as a shared receive queue. We know that the basic unit of RDMA communication is QP, and each QP consists of a send queue SQ and a receive queue RQ.&lt;/p>
&lt;p>SRQ is designed by the IB protocol to save resources for the receiver. We can share an RQ with all associated QPs, and this shared RQ is called an SRQ. When a QP associated with it wants to post a receive WQE, it is filled into this SRQ. Then, whenever the hardware receives data, it stores the data in the specified location based on the content of the next WQE in the SRQ.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-28_11_1.webp"
alt="2024-06-28_11_1" width="80%" loading="lazy">
&lt;/figure>
&lt;h3 id="why-use-srq">
&lt;a href="#why-use-srq" class="header-anchor">#&lt;/a>
Why use SRQ
&lt;/h3>
&lt;p>Under normal circumstances, the number of tasks we issue to SQ is far greater than the number of tasks issued to RQ. Why is that? Please first recall which types of operations use SQ and which use RQ.&lt;/p>
&lt;p>SEND/WRITE/READ all require the communication initiator to issue a WR to the SQ, and only the RECV operation paired with SEND requires the communication responder to issue a WR to the RQ (the Write operation with immediate value will also consume Receive WR, which we haven&amp;rsquo;t discussed yet). As we know, the SEND-RECV pair of operations is usually used for transmitting control information, while WRITE and READ are the main operations for performing large amounts of remote memory read and write operations, so naturally, the usage rate of SQ is much higher than that of RQ.&lt;/p>
&lt;p>Each queue is an entity, occupying memory and on-chip storage space of the network card. In commercial scenarios, the number of QPs can reach hundreds of thousands or even higher, which places high demands on memory capacity. Memory is bought with hard-earned money, and SRQ is a mechanism designed by the IB protocol to save user memory.&lt;/p>
&lt;p>Let&amp;rsquo;s take a look at the official explanation in the agreement for why SRQ is used (Section 10.2.9.1):&lt;/p>
&lt;blockquote>
&lt;p>Without SRQ, an RC, UC or UD Consumer must post the number of receive WRs necessary to handle incoming receives on a given QP. If the Consumer cannot predict the incoming rate on a given QP, because, for example, the connection has a bursty nature, the Consumer must either: post a sufficient number of RQ WRs to handle the highest incoming rate for each connection, or, for RC, let message flow control cause the remote sender to back off until local Consumer posts more WRs.&lt;/p>
&lt;p>• Posting sufficient WRs on each QP to hold the possible incoming rate, wastes WQEs, and the associated Data Segments, when the Receive Queue is inactive. Furthermore, the HCA doesn’t provide a way of reclaiming these WQEs for use on other connections.&lt;/p>
&lt;p>• Letting the RC message flow control cause the remote sender to back off can add unnecessary latencies, especially if the local Consumer is unaware that the RQ is starving.&lt;/p>
&lt;/blockquote>
&lt;p>In simple terms, without SRQ, because the receiver of RC/UC/UD does not know how much data the other end will send and when it will arrive, it must prepare for the worst-case scenario, preparing for the possibility of receiving a large amount of data suddenly, which means issuing a sufficient number of receive WQEs to the RQ. Additionally, the RC service type can use flow control mechanisms to exert backpressure on the sender, essentially telling the other end &amp;ldquo;I don&amp;rsquo;t have enough RQ WQEs here,&amp;rdquo; so the sender will temporarily slow down or stop sending data.&lt;/p>
&lt;p>However, as we mentioned earlier, the first method, being prepared for the worst-case scenario, often results in a large number of RQ WQEs being idle and unused, which is a significant waste of memory. Although the second method doesn&amp;rsquo;t require issuing as many RQ WQEs, flow control comes at a cost, which is the increased communication latency.&lt;/p>
&lt;p>And SRQ solves the above problem by allowing many QPs to share receive WQEs (as well as memory space for storing data). When any QP receives a message, the hardware will take a WQE from the SRQ, store the received data according to its content, and then the hardware will return the completion information of the receive task to the corresponding upper-level user through the Completion Queue.&lt;/p>
&lt;p>Let&amp;rsquo;s take a look at how much memory can be saved by using SRQ compared to using a standard RQ&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>:&lt;/p>
&lt;p>Assume that there are N pairs of QP on the node receiving data, and each QP may receive a consecutive M messages at random times (each message consumes a WQE from an RQ),&lt;/p>
&lt;ul>
&lt;li>If SRQ is not used, the user needs to issue N * M RQ WQEs in total.&lt;/li>
&lt;li>If using SRQ, the user only needs to issue K * M RQ WQEs, where K is much smaller than N.&lt;/li>
&lt;/ul>
&lt;p>This K can be configured by the user according to the business needs. If there is a large amount of concurrent reception, then set K to a larger value; otherwise, setting K to a single digit is sufficient to handle general situations.&lt;/p>
&lt;p>We have saved a total of (N - K) * M RQ WQEs, and RQ WQEs themselves are not very large, approximately a few KB in size, which doesn&amp;rsquo;t seem to take up much memory. However, as mentioned earlier, what is actually saved is the &lt;strong>memory space used to store data&lt;/strong>, which is a significant amount of memory. We will use a diagram to illustrate:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-28_11_2.webp"
alt="2024-06-28_11_2" width="80%" loading="lazy">
&lt;/figure>
&lt;p>In the above diagram, there are two RQ WQEs in the SRQ. Let&amp;rsquo;s take a look at the contents of an RQ WQE, which are composed of several SGEs (Scatter/Gather Elements). Each SGE consists of a memory address, length, and key. With a starting address and length, an SGE can point to a contiguous memory region, and multiple SGEs can represent multiple discrete contiguous memory blocks. We refer to multiple SGEs as an SGL (Scatter/Gather List). SGEs are ubiquitous in the IB software protocol stack (and indeed very common throughout Linux), allowing very large memory regions to be represented with minimal space. IB users use SGEs to specify send and receive areas.&lt;/p>
&lt;p>You can simply estimate the size of the memory region each sge can point to. The length is a 32-bit unsigned integer, which can represent 4GB of space. Assuming an RQ WQE can hold a maximum of 256 sge, then an RQ WQE would be a total of 1TB. Of course, in reality, it cannot be that large, this is just to intuitively inform the reader of the potential memory space an RQ WQE might occupy.&lt;/p>
&lt;h3 id="srqc">
&lt;a href="#srqc" class="header-anchor">#&lt;/a>
SRQC
&lt;/h3>
&lt;p>That is SRQ Context. Like QPC, SRQC is used to inform the hardware about attributes related to SRQ, including depth, WQE size, and other information, which will not be elaborated on in this article.&lt;/p>
&lt;h3 id="srqn">
&lt;a href="#srqn" class="header-anchor">#&lt;/a>
SRQN
&lt;/h3>
&lt;p>That is SRQ Number. Like QP, there may be multiple SRQs in each node. To identify and distinguish these SRQs, each SRQ has a serial number, called SRQN.&lt;/p>
&lt;h3 id="pd-of-srq">
&lt;a href="#pd-of-srq" class="header-anchor">#&lt;/a>
PD of SRQ
&lt;/h3>
&lt;p>In &lt;a class="link" href="https://cuterwrite.top/en/p/rdma-protection-domain/" >【7. RDMA Protection Domain】
&lt;/a>
, we introduced the concept of Protection Domain, which is used to isolate different RDMA resources. Each SRQ must specify its own PD, which can be the same as the PD of its associated QP, or it can be different; SRQs can also use the same PD.&lt;/p>
&lt;p>If a packet is received while using SRQ, it will only be properly received if the MR and SRQ being accessed are under the same PD; otherwise, an immediate error will occur.&lt;/p>
&lt;h2 id="asynchronous-event">
&lt;a href="#asynchronous-event" class="header-anchor">#&lt;/a>
Asynchronous event
&lt;/h2>
&lt;p>In the article &lt;a class="link" href="https://cuterwrite.top/en/p/rdma-completion-queue/" >【10. RDMA Completion Queue】
&lt;/a>
, we introduced that the IB protocol classifies error types into immediate errors, completion errors, and asynchronous errors based on the method of error reporting. Among them, asynchronous errors are similar to interrupts/events, so we sometimes refer to them as asynchronous events. Each HCA registers an event handling function specifically for handling asynchronous events. Upon receiving an asynchronous event, the driver performs the necessary processing and further reports it to the user.&lt;/p>
&lt;p>There is a special asynchronous event regarding SRQ, used to promptly notify upper-level users of the SRQ status, namely the SRQ Limit Reached event.&lt;/p>
&lt;h3 id="srq-limit">
&lt;a href="#srq-limit" class="header-anchor">#&lt;/a>
SRQ Limit
&lt;/h3>
&lt;p>SRQ can set a watermark/threshold, when the number of remaining WQEs in the queue is less than the watermark, this SRQ will report an asynchronous event. It reminds the user &amp;ldquo;The WQEs in the queue are about to run out, please issue more WQEs to prevent having no place to receive new data.&amp;rdquo; This watermark/threshold is called the SRQ Limit, and the reported event is called SRQ Limit Reached.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-28_11_3.webp"
alt="2024-06-28_11_3" width="30%" loading="lazy">
&lt;/figure>
&lt;p>Because the SRQ is shared by multiple QPs, if the depth is relatively small, it is very likely that the WQE inside will suddenly run out. Therefore, the protocol is designed with this mechanism to ensure that users can promptly intervene in situations where the WQE is insufficient.&lt;/p>
&lt;p>After reporting an asynchronous event, the value of SRQ Limit will be reset to 0 by the hardware (presumably to prevent continuously reporting asynchronous events to the upper layer). Of course, users can choose not to use this mechanism by simply setting the value of SRQ Limit to 0.&lt;/p>
&lt;h2 id="user-interface">
&lt;a href="#user-interface" class="header-anchor">#&lt;/a>
User interface
&lt;/h2>
&lt;h3 id="control-surface">
&lt;a href="#control-surface" class="header-anchor">#&lt;/a>
Control surface
&lt;/h3>
&lt;p>Still the old four types—&amp;ldquo;Add, Delete, Modify, Query&amp;rdquo;:&lt;/p>
&lt;ul>
&lt;li>Create SRQ&lt;/li>
&lt;/ul>
&lt;p>When creating an SRQ, similar to a QP, all software and hardware resources related to the SRQ are allocated. For example, the driver will request an SRQN, allocate space for the SRQC, and fill in the configuration. When creating an SRQ, you must also specify the depth of each SRQ (how many WQEs it can store) and the maximum number of sges per WQE.&lt;/p>
&lt;ul>
&lt;li>Destroy SRQ&lt;/li>
&lt;/ul>
&lt;p>Destroy all related software and hardware resources of SRQ.&lt;/p>
&lt;ul>
&lt;li>Modify SRQ&lt;/li>
&lt;/ul>
&lt;p>In addition to attributes such as SRQ depth, the value of SRQ Limit is also set through this interface. Because the value of the watermark is cleared every time an SRQ Limit Reached event occurs, the user needs to call Modify SRQ to reset the watermark each time.&lt;/p>
&lt;ul>
&lt;li>Query SRQ&lt;/li>
&lt;/ul>
&lt;p>It is usually used to query the configuration of the waterline.&lt;/p>
&lt;h3 id="data-surface">
&lt;a href="#data-surface" class="header-anchor">#&lt;/a>
Data surface
&lt;/h3>
&lt;h3 id="post-srq-receive">
&lt;a href="#post-srq-receive" class="header-anchor">#&lt;/a>
Post SRQ Receive
&lt;/h3>
&lt;p>Just like Post Receive, it issues a receive WQE to the SRQ, which contains information about the memory block used as the receive buffer. It is important to note that the subject is SRQ and has nothing to do with QP. Currently, the user is not concerned with which QP this SRQ is associated with.&lt;/p>
&lt;h2 id="the-difference-between-srq-and-rq">
&lt;a href="#the-difference-between-srq-and-rq" class="header-anchor">#&lt;/a>
The difference between SRQ and RQ
&lt;/h2>
&lt;p>In terms of functionality, both SRQ and RQ are used to store received task requests, but due to the shared nature of SRQ, there are some differences between it and RQ.&lt;/p>
&lt;h3 id="state-machine">
&lt;a href="#state-machine" class="header-anchor">#&lt;/a>
State machine
&lt;/h3>
&lt;p>We introduced in &lt;a class="link" href="https://cuterwrite.top/en/p/rdma-queue-pair/" >【9. RDMA Queue Pair】
&lt;/a>
that QP has a complex state machine, and the sending and receiving capabilities of QP vary in different states. However, SRQ only has two states: non-error and error.&lt;/p>
&lt;p>Regardless of the state, users can issue WQEs to the SRQ. However, in an error state, the associated QP cannot receive data from this SRQ. Additionally, in an error state, users cannot query or modify the attributes of the SRQ.&lt;/p>
&lt;p>When a QP is in an error state, it can be returned to the RESET state through Modify QP, but for SRQ, it can only exit the error state by destroying it.&lt;/p>
&lt;h3 id="receiving-process">
&lt;a href="#receiving-process" class="header-anchor">#&lt;/a>
Receiving process
&lt;/h3>
&lt;p>For a QP, RQ and SRQ cannot be used simultaneously, one must be chosen. If a WQE is issued to the RQ of a QP that is already associated with SRQ, an immediate error will be returned.&lt;/p>
&lt;p>Let&amp;rsquo;s compare the reception processes of SRQ and RQ. The content of this section is a key point of this article, and I believe that after reading it, readers will have a more complete understanding of the SRQ mechanism.&lt;/p>
&lt;h3 id="rqs-receiving-process">
&lt;a href="#rqs-receiving-process" class="header-anchor">#&lt;/a>
RQ&amp;rsquo;s receiving process
&lt;/h3>
&lt;p>First, let&amp;rsquo;s revisit the receiving process of a regular RQ (for the complete process on the sender&amp;rsquo;s side, please read &lt;a class="link" href="https://cuterwrite.top/en/p/rdma-op/" >【4. RDMA Operation Types】
&lt;/a>
):&lt;/p>
&lt;ol start="0">
&lt;li>
&lt;p>Create QP.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Through the Post Recv interface, the user submits receive WQE to the RQ of QP2 and QP3, respectively. The WQE contains information about which memory region to place the received data.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The hardware receives the data.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Hardware discovery is sent to QP3, then WQE1 is taken from QP3&amp;rsquo;s RQ, and the received data is placed in the memory area specified by WQE1.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>After the hardware completes data storage, it generates a CQE to CQ3 associated with RQ of QP3, reporting task completion information.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The user retrieves WC (CQE) from CQ3, and then takes data from the specified memory area.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The hardware receives the data.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The hardware discovery is sent to QP2, then WQE1 is extracted from the RQ of QP2, and the received data is placed in the memory area specified by WQE1.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>After the hardware completes data storage, it generates a CQE for CQ2 associated with RQ of QP2, reporting task completion information.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The user retrieves WC (CQE) from CQ2, and then takes data from the specified memory area.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-28_11_4.webp"
alt="2024-06-28_11_4" width="90%" loading="lazy">
&lt;/figure>
&lt;h3 id="srqs-reception-process">
&lt;a href="#srqs-reception-process" class="header-anchor">#&lt;/a>
SRQ&amp;rsquo;s reception process
&lt;/h3>
&lt;p>And the SRQ receiving process has some differences:&lt;/p>
&lt;ol start="0">
&lt;li>
&lt;p>Create SRQ1, and create QP2 and QP3, both associated with SRQ1.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Through the Post SRQ Recv interface, the user issues two receive WQEs to SRQ1, containing information about which memory region to place the received data.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Hardware receives data.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The hardware discovery is sent to QP3, extracting the first WQE from SRQ1 (now it is WQE1), and storing the received data according to the content of the WQE.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>Each WQE in the SRQ is &amp;ldquo;ownerless&amp;rdquo;, not associated with any QP. The hardware sequentially takes out the WQE according to the queue order and places the data inside.&lt;/p>
&lt;/blockquote>
&lt;ol start="4">
&lt;li>
&lt;p>The hardware discovers that the CQ associated with QP3&amp;rsquo;s RQ is CQ3, so it generates a CQE in it.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The user retrieves the CQE from CQ3 and takes data from the specified memory area.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>Attentive readers may ask, when a user issues a WR, each WR specifies some memory regions for storing data in the future. However, an SRQ is a pool where each WQE points to several different memory regions. After the user receives a WC in the CQ corresponding to a certain QP, how do they know where the received data has been stored?&lt;/p>
&lt;p>There is actually wr_id information in the WC, informing the user of which WR (WQE) designated memory area the data is placed in. Since the WR is issued by the user, the user naturally knows its specific location.&lt;/p>
&lt;/blockquote>
&lt;ol start="6">
&lt;li>
&lt;p>Hardware received data&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The hardware discovery is sent to QP2, and the first WQE is taken from SRQ1 (now it is WQE2), and the received data is stored according to the content of the WQE.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The hardware discovers that the CQ associated with QP2&amp;rsquo;s RQ is CQ2, so a CQE is generated in it.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The user takes out the CQE from CQ2 and retrieves data from the specified memory area.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-28_11_5.webp"
alt="2024-06-28_11_5" width="90%" loading="lazy">
&lt;/figure>
&lt;h2 id="summary">
&lt;a href="#summary" class="header-anchor">#&lt;/a>
Summary
&lt;/h2>
&lt;p>This text first introduces the basic concept of SRQ, followed by its design purpose, related mechanisms, and user interface. Finally, it compares the SRQ receiving process with RQ. In actual business, the usage rate of SRQ is quite high, and it is hoped that readers can gain a deep understanding.&lt;/p>
&lt;p>Let&amp;rsquo;s stop here, thank you for reading. In the next article, I will introduce the Memory Window.&lt;/p>
&lt;h2 id="relevant-sections-of-the-agreement">
&lt;a href="#relevant-sections-of-the-agreement" class="header-anchor">#&lt;/a>
Relevant sections of the agreement
&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>10.2.9 The design concept of SRQ and related operations&lt;/p>
&lt;/li>
&lt;li>
&lt;p>10.2.3 PD of SRQ and QP&lt;/p>
&lt;/li>
&lt;li>
&lt;p>10.8.2 The relationship between QP associated with SRQ and QP not using SRQ&lt;/p>
&lt;/li>
&lt;li>
&lt;p>10.8.5 SRQ related returns WC&lt;/p>
&lt;/li>
&lt;li>
&lt;p>11.5.2.4 Asynchronous Events&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="other-references">
&lt;a href="#other-references" class="header-anchor">#&lt;/a>
Other references
&lt;/h2>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>Linux Kernel Networking - Implementation and Theory. Chapter 13. Shared Receive Queue&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>RDMA: Completion Queue</title><link>https://cuterwrite.top/en/p/rdma-completion-queue/</link><pubDate>Wed, 26 Jun 2024 23:11:00 +0000</pubDate><guid>https://cuterwrite.top/en/p/rdma-completion-queue/</guid><description>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-16_116903369_p0_master1200.webp" alt="Featured image of post RDMA: Completion Queue" />&lt;h1 id="rdmas-completion-queue">
&lt;a href="#rdmas-completion-queue" class="header-anchor">#&lt;/a>
RDMA&amp;rsquo;s Completion Queue
&lt;/h1>
&lt;p>&lt;strong>This article welcomes non-commercial reproduction, please indicate the source.&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>Statement: For collection only, for easy reading&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/259650980">&lt;cite>Zhihu Column: 10. RDMA Completion Queue&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>We have briefly introduced CQ in previous articles, and this article will delve deeper into some of its details. Before reading this article, readers can first review this article: &lt;a class="link" href="https://cuterwrite.top/en/p/rdma-element/" >【“3. RDMA Basic Elements”】
&lt;/a>
.&lt;/p>
&lt;h2 id="basic-concepts">
&lt;a href="#basic-concepts" class="header-anchor">#&lt;/a>
Basic Concepts
&lt;/h2>
&lt;p>Let&amp;rsquo;s first review the function of CQ. CQ stands for Completion Queue, and its function is opposite to that of WQ (SQ and RQ). The hardware uses CQE/WC in the CQ to inform the software about the completion status of a certain WQE/WR. A reminder to readers: for upper-layer users, WC is generally used, while for drivers, it is generally referred to as CQE. This article does not distinguish between the two.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-27_10_1.webp"
alt="2024-06-27_10_1" width="80%" loading="lazy">
&lt;/figure>
&lt;p>CQE can be regarded as a &amp;ldquo;report&amp;rdquo; that specifies the execution status of a certain task, including:&lt;/p>
&lt;ul>
&lt;li>Which task specified by which WQE of which QP was completed this time (QP Number and WR ID)&lt;/li>
&lt;li>What operation was performed in this task (Opcode operation type)&lt;/li>
&lt;li>This task executed successfully/failed, the reason for failure is XXX (Status and error code)&lt;/li>
&lt;li>&amp;hellip;&lt;/li>
&lt;/ul>
&lt;p>Whenever the hardware completes processing a WQE, a CQE is generated and placed in the CQ queue. If a CQE corresponding to a WQE is not generated, then this WQE will always be considered as not yet processed. What does this mean?&lt;/p>
&lt;ul>
&lt;li>Operations involving fetching data from memory (SEND and WRITE)&lt;/li>
&lt;/ul>
&lt;p>Before generating a CQE, the hardware may not have sent the message yet, may be in the process of sending the message, or the peer may have received the correct message. Since the memory region is allocated before sending, the upper-level software must consider this memory region still in use before receiving the corresponding CQE and cannot release all related memory resources.&lt;/p>
&lt;ul>
&lt;li>Operations involving storing data in memory (RECV and READ)&lt;/li>
&lt;/ul>
&lt;p>Before the CQE is generated, it is possible that the hardware has not started writing data, it is possible that only half of the data has been written, or it is possible that a data verification error has occurred. Therefore, before the upper-layer software receives the CQE, the contents of the memory area used to store the received data are unreliable.&lt;/p>
&lt;p>In summary, the user must obtain the CQE and confirm its content before considering the message sending and receiving task complete.&lt;/p>
&lt;h3 id="when-was-it-generated">
&lt;a href="#when-was-it-generated" class="header-anchor">#&lt;/a>
When was it generated?
&lt;/h3>
&lt;p>We will explain separately according to the service type (this article only discusses RC and UD) and the operation type, because the timing and meaning of generating CQE are different in different situations. Readers are advised to review the 4th article &lt;a class="link" href="https://cuterwrite.top/en/p/rdma-op/" >&amp;ldquo;4. Basic RDMA Operations&amp;rdquo;
&lt;/a>
and the 5th article &lt;a class="link" href="https://cuterwrite.top/en/p/rdma-service-types/" >&amp;ldquo;5. Basic RDMA Service Types&amp;rdquo;
&lt;/a>
.&lt;/p>
&lt;ul>
&lt;li>Reliable Service Type (RC)&lt;/li>
&lt;/ul>
&lt;p>The previous article mentioned that &lt;strong>reliability means that the sender is concerned that the message sent can be accurately received by the receiver&lt;/strong>, which is ensured through mechanisms such as ACK, checksum, and retransmission.&lt;/p>
&lt;ul>
&lt;li>SEND&lt;/li>
&lt;/ul>
&lt;p>SEND operation requires hardware to fetch data from memory, then assemble it into packets to send to the other end through a physical link. For SEND, the Client side generates a CQE indicating &lt;strong>the other end has received the data accurately&lt;/strong>, after the other end&amp;rsquo;s hardware receives and verifies the data, it will reply with an ACK packet to the sender. Only after the sender receives this ACK will a CQE be generated, thus informing the user that the task has been successfully executed. As shown in the figure, the left Client side generates the CQE for this task at the position marked by the red dot.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-27_10_2.webp"
alt="2024-06-27_10_2" width="50%" loading="lazy">
&lt;/figure>
&lt;ul>
&lt;li>RECV&lt;/li>
&lt;/ul>
&lt;p>The RECV operation requires the hardware to place the received data into the memory area specified in the user&amp;rsquo;s WQE. After completing the checksum and data storage actions, the hardware will generate a CQE, as shown on the right side of the above figure on the server side.&lt;/p>
&lt;ul>
&lt;li>WRITE&lt;/li>
&lt;/ul>
&lt;p>For the Client side, WRITE operation and SEND operation are the same, the hardware will fetch data from memory and wait for the peer to reply with an ACK before generating a CQE. The difference is that because WRITE is an RDMA operation, the peer CPU is not aware of it, and naturally the user is not aware of it either, so the diagram above becomes like this:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-27_10_3.webp"
alt="2024-06-27_10_3" width="50%" loading="lazy">
&lt;/figure>
&lt;ul>
&lt;li>READ&lt;/li>
&lt;/ul>
&lt;p>READ and RECV are somewhat similar. After the Client initiates a READ operation, the other side will reply with the data we want to read. Then, after verifying that there are no issues, the data will be placed in the specified location in the WQE. After completing the above actions, a CQE will be generated on our side. READ is also an RDMA operation, which is not perceived by the other side&amp;rsquo;s user, and naturally, no CQE is generated. In this situation, the diagram becomes like this:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-27_10_4.webp"
alt="2024-06-27_10_4" width="50%" loading="lazy">
&lt;/figure>
&lt;ul>
&lt;li>Unreliable Service Type (UD)&lt;/li>
&lt;/ul>
&lt;p>Because unreliable service types lack retransmission and acknowledgment mechanisms, generating a CQE indicates that the hardware &lt;strong>has already sent out the data specified by the corresponding WQE&lt;/strong>. It was previously mentioned that UD only supports SEND-RECV operations and does not support RDMA operations. Therefore, for both ends of the UD service, the timing for CQE generation is as shown in the figure below:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-27_10_5.webp"
alt="2024-06-27_10_5" width="50%" loading="lazy">
&lt;/figure>
&lt;h3 id="the-correspondence-between-wq-and-cq">
&lt;a href="#the-correspondence-between-wq-and-cq" class="header-anchor">#&lt;/a>
The correspondence between WQ and CQ
&lt;/h3>
&lt;p>&lt;strong>Each WQ must be associated with a CQ, and each CQ can be associated with multiple SQs and RQs.&lt;/strong>&lt;/p>
&lt;p>The so-called &amp;ldquo;association&amp;rdquo; here refers to the fact that all CQEs corresponding to a WQ&amp;rsquo;s WQEs will be placed by the hardware into the bound CQ. It&amp;rsquo;s important to note that the SQ and RQ belonging to the same QP can each be associated with different CQs. As shown in the diagram below, both the SQ and RQ of QP1 are associated with CQ1, while the RQ of QP2 is associated with CQ1 and the SQ is associated with CQ2.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-27_10_6.webp"
alt="2024-06-27_10_6" width="auto" loading="lazy">
&lt;/figure>
&lt;p>Because each WQ must be associated with a CQ, the user needs to create the CQ in advance before creating the QP, and then specify which CQ will be used by the SQ and RQ respectively.&lt;/p>
&lt;p>&lt;strong>The WQEs in the same WQ correspond to CQEs that are ordered&lt;/strong>&lt;/p>
&lt;p>The hardware retrieves WQEs from a certain WQ (SQ or RQ) and processes them in a &amp;ldquo;First In, First Out&amp;rdquo; FIFO order, and when placing CQEs in the CQ associated with WRs, it also follows the order in which these WQEs were placed in the WQ. Simply put, whoever is placed in the queue first is completed first. This process is shown in the diagram below:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-27_10_7.webp"
alt="2024-06-27_10_7" width="auto" loading="lazy">
&lt;/figure>
&lt;p>It should be noted that the use of SRQ and the RQ in RD service type are both non-order-preserving, which will not be discussed in this article.&lt;/p>
&lt;p>&lt;strong>The WQEs in different WQs are not ordered with respect to their corresponding CQEs.&lt;/strong>&lt;/p>
&lt;p>In the previous text, we mentioned that a CQ might be shared by multiple WQs. In this case, the order of generation for the CQEs corresponding to these WQEs cannot be guaranteed. As shown in the figure below (the WQE number indicates the order of issuance, i.e., 1 is issued first, and 6 is issued last):&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-27_10_8.webp"
alt="2024-06-27_10_8" width="auto" loading="lazy">
&lt;/figure>
&lt;p>The above description actually also includes the situation of &amp;ldquo;WQE in SQ and RQ of the same QP, their corresponding CQE is not ordered.&amp;rdquo; This is actually quite easy to understand. SQ and RQ, one is responsible for actively initiating tasks, and the other for passively receiving tasks. They can be considered as channels in two different directions and naturally should not affect each other. Suppose the user first issues a Receive WQE and then a Send WQE for the same QP. It can&amp;rsquo;t be that if the peer doesn&amp;rsquo;t send a message to the local end, the local end cannot send a message to the peer, right?&lt;/p>
&lt;p>In this case, since the order in which CQEs are generated is not related to the order in which WQEs are obtained, how do the upper-level application and driver know which WQE the received CQE is associated with? It&amp;rsquo;s actually quite simple, &lt;strong>the CQE indicates the number of the WQE it corresponds to&lt;/strong>.&lt;/p>
&lt;p>Additionally, it should be noted that even when multiple WQs share a single CQ, &amp;ldquo;WQEs in the same WQ have their corresponding CQEs ordered&amp;rdquo; is always guaranteed. This means that the CQEs corresponding to WQE 1, 3, and 4 belonging to WQ1 in the above diagram are generated in sequence, and the same applies to WQE 2, 5, and 6 belonging to WQ2.&lt;/p>
&lt;h3 id="cqc">
&lt;a href="#cqc" class="header-anchor">#&lt;/a>
CQC
&lt;/h3>
&lt;p>Just like QP, CQ is merely a queue memory space for storing CQEs. Apart from knowing the starting address, the hardware is essentially unaware of this area. Therefore, it is necessary to agree on a format with the software in advance, and then the driver will allocate memory and fill in the basic information of the CQ in this memory according to the format for the hardware to read. This memory is the CQC. The CQC contains information such as the capacity size of the CQ, the sequence number of the currently processed CQE, and so on. So by slightly modifying the QPC diagram, you can represent the relationship between CQC and CQ:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-27_10_9.webp"
alt="2024-06-27_10_9" width="auto" loading="lazy">
&lt;/figure>
&lt;h3 id="cqn">
&lt;a href="#cqn" class="header-anchor">#&lt;/a>
CQN
&lt;/h3>
&lt;p>CQ Number is the CQ&amp;rsquo;s identifier, used to distinguish different CQs. CQ does not have special reserved numbers like QP0 and QP1, which will not be further elaborated in this article.&lt;/p>
&lt;h2 id="complete-error">
&lt;a href="#complete-error" class="header-anchor">#&lt;/a>
Complete error
&lt;/h2>
&lt;p>There are three types of errors in the IB protocol: immediate error, Completion Error, and Asynchronous Errors.&lt;/p>
&lt;p>Immediate error refers to &amp;ldquo;immediately stop the current operation and return an error to the upper-level user&amp;rdquo;; completion error refers to &amp;ldquo;return the error information to the upper-level user via CQE&amp;rdquo;; whereas asynchronous error refers to &amp;ldquo;report to the upper-level user through an interrupt event.&amp;rdquo; It might still be a bit abstract, so let&amp;rsquo;s give an example to illustrate under what circumstances these two types of errors might occur:&lt;/p>
&lt;ul>
&lt;li>The user passed an illegal opcode when sending a Post Send, for example, trying to use RDMA WRITE operation during UD.&lt;/li>
&lt;/ul>
&lt;p>Result: Immediate error generated (some manufacturers may generate a completion error in this situation)&lt;/p>
&lt;p>Generally, in this situation, the driver will directly exit the post send process and return an error code to the upper-level user. Note that at this point, the WQE has not yet been issued to the hardware before returning.&lt;/p>
&lt;ul>
&lt;li>The user issued a WQE with the operation type SEND, but did not receive an ACK from the other party for a long time.&lt;/li>
&lt;/ul>
&lt;p>Result: Generation completed with error&lt;/p>
&lt;p>Because the WQE has already reached the hardware, the hardware will generate the corresponding CQE, which contains error details of the timeout unresponse.&lt;/p>
&lt;ul>
&lt;li>Multiple WQEs were issued in user mode, so the hardware generated multiple CQEs, but the software did not retrieve the CQEs from the CQ, causing the CQ to overflow.
Result: Generate asynchronous error&lt;/li>
&lt;/ul>
&lt;p>Because the software has not fetched the CQE, it naturally will not obtain information from the CQE. At this time, the IB framework will call the event handler function registered by the software to notify the user to handle the current error.&lt;/p>
&lt;p>From this, it can be seen that they are all ways for the lower layer to report errors to the upper layer users, only the timing of their occurrence is different. In the IB protocol, it is specified which method should be used to report errors in different situations. For example, in the diagram below, for modifying illegal parameters during the Modify QP process, an immediate error should be returned.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-27_10_10.webp"
alt="2024-06-27_10_10" width="auto" loading="lazy">
&lt;/figure>
&lt;p>The focus of this text is on CQ, so after introducing the error types, we will take a closer look at completion errors. Completion errors are reported by the hardware through filling error codes in the CQE. A communication process requires the participation of a requester and a responder, and the specific error causes are divided into local and remote. Let&amp;rsquo;s first take a look at the stage at which error detection is performed (the figure below is a redrawn version of Figure 118 in the IB protocol):&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-27_10_11.webp"
alt="2024-06-27_10_11" width="auto" loading="lazy">
&lt;/figure>
&lt;p>There are two error detection points for the Requester:&lt;/p>
&lt;ol>
&lt;li>Local error detection&lt;/li>
&lt;/ol>
&lt;p>Check the WQE in the SQ, if an error is detected, directly generate a CQE from the local error checking module to the CQ, and no data will be sent to the responder; if there is no error, send the data to the peer.&lt;/p>
&lt;ol start="2">
&lt;li>Remote Error Detection&lt;/li>
&lt;/ol>
&lt;p>Detect whether the response side&amp;rsquo;s ACK is abnormal. ACK/NAK is generated by the peer&amp;rsquo;s local error detection module after detection, and it contains whether there is an error on the response side and the specific type of error. Regardless of whether there is an issue with the remote error detection result, a CQE will be generated in the CQ.&lt;/p>
&lt;p>Responder&amp;rsquo;s error detection point is only one:&lt;/p>
&lt;ol>
&lt;li>Local error detection&lt;/li>
&lt;/ol>
&lt;p>In fact, what is detected is whether there is an issue with the peer message, which is also referred to as &amp;ldquo;local&amp;rdquo; error detection in the IB protocol. If an error is detected, it will be reflected in the ACK/NAK message sent back to the peer and will generate a CQE locally.&lt;/p>
&lt;p>It should be noted that the generation of ACK and remote error detection mentioned above is only applicable to connection-oriented service types. Connectionless service types, such as UD type, do not care whether the peer receives it, and the receiver will not generate an ACK. Therefore, a CQE will definitely be generated after the local error detection of the Requester, regardless of whether there is a remote error.&lt;/p>
&lt;p>Then we will briefly introduce several common completion errors:&lt;/p>
&lt;ul>
&lt;li>RC service type SQ completion error&lt;/li>
&lt;li>Local Protection Error
&lt;ul>
&lt;li>Local protection domain error. The data memory address specified in the local WQE is invalid for the MR, meaning the user is attempting to use data from an unregistered memory region.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Remote Access Error
&lt;ul>
&lt;li>Remote permission error. The local end does not have permission to read/write the specified remote memory address.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Transport Retry Counter Exceeded Error
&lt;ul>
&lt;li>Retransmission limit exceeded error. The peer has not responded with the correct ACK, causing multiple retransmissions from this end, exceeding the preset number of times.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>RC service type RQ completion error&lt;/li>
&lt;li>Local Access Error
&lt;ul>
&lt;li>Local access error. Indicates that the peer attempted to write to a memory area it does not have permission to write to.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Local Length Error
&lt;ul>
&lt;li>Local length error. The local RQ does not have enough space to receive the data sent by the peer.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>For a complete list of error types, please refer to Section 10.10.3 of the IB protocol.&lt;/p>
&lt;h2 id="user-interface">
&lt;a href="#user-interface" class="header-anchor">#&lt;/a>
User interface
&lt;/h2>
&lt;p>Like QP, we still introduce the interface provided by the IB protocol to the upper layer regarding CQ from the communication preparation phase (control plane) and the communication execution phase (data plane).&lt;/p>
&lt;h3 id="control-surface">
&lt;a href="#control-surface" class="header-anchor">#&lt;/a>
Control surface
&lt;/h3>
&lt;p>Just like QP, there are still the four types of &amp;ldquo;add, delete, modify, and query,&amp;rdquo; but perhaps because for CQ, the upper-layer users are resource users rather than managers, they can only read data from CQ and cannot write data. Therefore, the configurable parameter open to users is only the &amp;ldquo;CQ specification.&amp;rdquo;&lt;/p>
&lt;ul>
&lt;li>Create CQ&lt;/li>
&lt;/ul>
&lt;p>When creating, the user must specify the size of the CQ, i.e., how many CQEs it can store. Additionally, the user can provide a pointer to a callback function that is triggered after a CQE is generated (this will be discussed later). The kernel-mode driver will configure other related parameters and fill them into the CQC, as agreed with the hardware, to inform the hardware.&lt;/p>
&lt;ul>
&lt;li>Destroy CQ&lt;/li>
&lt;/ul>
&lt;p>Release a CQ hardware and software resource, including CQ itself and CQC, and naturally, CQN will also become invalid.&lt;/p>
&lt;ul>
&lt;li>Resize CQ&lt;/li>
&lt;/ul>
&lt;p>The name here is slightly different because CQ only allows users to modify the size of the specifications, so Resize is used instead of Modify.&lt;/p>
&lt;ul>
&lt;li>Query CQ&lt;/li>
&lt;/ul>
&lt;p>Query the current specifications of CQ, as well as the callback function pointer used for notifications.&lt;/p>
&lt;blockquote>
&lt;p>By comparing RDMA specifications and software protocol stacks, it can be found that many verbs interfaces are not implemented according to the specifications. Therefore, if readers find discrepancies between the software API and the protocol, there is no need to be puzzled, as RDMA technology itself is still evolving, and the software framework is in an active state of updates. If you are more concerned with programming implementation, please refer to the API documentation of the software protocol stack; if you are more concerned with academic research, please refer to the RDMA specifications.&lt;/p>
&lt;/blockquote>
&lt;h3 id="data-surface">
&lt;a href="#data-surface" class="header-anchor">#&lt;/a>
Data surface
&lt;/h3>
&lt;p>CQE is the medium through which hardware conveys information to software. Although the software knows under what circumstances a CQE will be generated, it does not know exactly when the hardware will place the CQE into the CQ. In the fields of communication and computing, this mode where the receiver does not know when the sender will send is called &amp;ldquo;asynchronous&amp;rdquo;. Let&amp;rsquo;s first take an example of a network card and then explain how a user can obtain a CQE (WC) through the data plane interface.&lt;/p>
&lt;p>After the network card receives a data packet, how to let the CPU know about this and process the packet, there are two common modes:&lt;/p>
&lt;ul>
&lt;li>Interrupt mode&lt;/li>
&lt;/ul>
&lt;p>When the amount of data is small, or when there are frequent sporadic data exchanges, it is suitable to use the interrupt mode—meaning the CPU is usually doing other tasks, and when the network card receives a data packet, it will report an interrupt to interrupt the current task of the CPU, and the CPU will switch to handle the data packet (such as parsing the various layers of the TCP/IP protocol stack). After processing the data, the CPU jumps back to the task before the interrupt to continue execution.&lt;/p>
&lt;p>Each interrupt requires saving the context, which means saving the current values of various registers, local variables, etc., to the stack, and then restoring the context (popping from the stack) upon return. This itself incurs overhead. If the business load is heavy and the network card is constantly receiving packets, the CPU will continuously receive interrupts, and the CPU will be busy with interrupt switching, causing other tasks to not be scheduled.&lt;/p>
&lt;ul>
&lt;li>Polling mode&lt;/li>
&lt;/ul>
&lt;p>So in addition to interrupt mode, the network card also has a polling mode, where received packets are first placed in the buffer, and the CPU periodically checks whether the network card has received data. If there is data, it takes the data from the buffer for processing; if not, it continues to handle other tasks.&lt;/p>
&lt;p>By comparing interrupt modes, we can find that although the polling mode requires the CPU to check at intervals, which brings some overhead, using polling mode when the business is busy can greatly reduce the number of context switches for interrupts, thereby reducing the CPU&amp;rsquo;s burden.&lt;/p>
&lt;p>The current network cards generally use a combination of interrupt and polling, which dynamically switches based on business load.&lt;/p>
&lt;p>In the RDMA protocol, a CQE is equivalent to a data packet received by the network card, and the RDMA hardware passes it to the CPU for processing. The RDMA framework defines two types of interfaces for the upper layer, namely poll and notify, corresponding to polling and interrupt modes.&lt;/p>
&lt;h3 id="poll-completion-queue">
&lt;a href="#poll-completion-queue" class="header-anchor">#&lt;/a>
Poll completion queue
&lt;/h3>
&lt;p>Very straightforward, poll means polling. After the user calls this interface, the CPU will periodically check if there are fresh CQEs in the CQ. If there are, it will extract this CQE (note that once extracted, the CQE is &amp;ldquo;consumed&amp;rdquo;), parse the information within, and return it to the upper-level user.&lt;/p>
&lt;h3 id="solicitud-de-notificación-de-finalización">
&lt;a href="#solicitud-de-notificaci%c3%b3n-de-finalizaci%c3%b3n" class="header-anchor">#&lt;/a>
Solicitud de notificación de finalización
&lt;/h3>
&lt;p>Literally translated, it is a request completion notification. After the user calls this interface, it is equivalent to registering an interrupt with the system. This way, when the hardware places a CQE into the CQ, it will immediately trigger an interrupt to the CPU. The CPU will then stop its current work to retrieve the CQE, process it, and return it to the user.&lt;/p>
&lt;p>Similarly, which of these two interfaces to use depends on the user&amp;rsquo;s requirements for real-time performance and the actual busyness of the business.&lt;/p>
&lt;p>Thank you for reading, that concludes the introduction to CQ. In the next article, I plan to discuss SRQ in detail.&lt;/p>
&lt;h2 id="relevant-sections-of-the-agreement">
&lt;a href="#relevant-sections-of-the-agreement" class="header-anchor">#&lt;/a>
Relevant sections of the agreement
&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>9.9 CQ Error Detection and Recovery&lt;/p>
&lt;/li>
&lt;li>
&lt;p>10.2.6 The relationship between CQ and WQ&lt;/p>
&lt;/li>
&lt;li>
&lt;p>10.10 Error Types and Their Handling&lt;/p>
&lt;/li>
&lt;li>
&lt;p>11.2.8 CQ Related Control Plane Interface&lt;/p>
&lt;/li>
&lt;li>
&lt;p>11.4.2 CQ related data surface interface&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="other-references">
&lt;a href="#other-references" class="header-anchor">#&lt;/a>
Other references
&lt;/h2>
&lt;p>[1] Linux Kernel Networking - Implement and Theory. Chapter 13. Completion Queue&lt;/p></description></item><item><title>RDMA: Queue Pair</title><link>https://cuterwrite.top/en/p/rdma-queue-pair/</link><pubDate>Tue, 25 Jun 2024 02:21:00 +0000</pubDate><guid>https://cuterwrite.top/en/p/rdma-queue-pair/</guid><description>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-16_116342820_p0_master1200.webp" alt="Featured image of post RDMA: Queue Pair" />&lt;h1 id="queue-pair-of-rdma">
&lt;a href="#queue-pair-of-rdma" class="header-anchor">#&lt;/a>
Queue Pair of RDMA
&lt;/h1>
&lt;p>&lt;strong>This article welcomes non-commercial reposting, please indicate the source.&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>Statement: For collection only, for convenient reading&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/195757767">&lt;cite>Zhihu Column: 9. Basic RDMA Service Types&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;h2 id="queue-pair">
&lt;a href="#queue-pair" class="header-anchor">#&lt;/a>
Queue Pair
&lt;/h2>
&lt;p>We have previously provided a brief introduction to the concept of QP in the article &lt;a class="link" href="https://cuterwrite.top/en/p/rdma-element/" >&amp;ldquo;3. Basic Elements of RDMA&amp;rdquo;
&lt;/a>
. This article will delve deeper into some details about QP.&lt;/p>
&lt;h2 id="review-of-basic-concepts">
&lt;a href="#review-of-basic-concepts" class="header-anchor">#&lt;/a>
Review of Basic Concepts
&lt;/h2>
&lt;p>First, let&amp;rsquo;s briefly review the basic knowledge about QP:&lt;/p>
&lt;p>According to the description in the IB protocol, QP is a virtual interface between hardware and software. QP is a queue structure that sequentially stores tasks (WQE) issued by software to hardware. The WQE contains information such as where to retrieve data, how long the data is, and to which destination it should be sent.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-26_9_1.webp"
alt="2024-06-26_9_1" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Concept of QP&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>Each QP is independent and isolated from each other through PD, so a QP can be regarded as a resource exclusively used by a certain user, and a user can also use multiple QPs simultaneously.&lt;/p>
&lt;p>QP has many types of services, including RC, UD, RD, and UC, etc. All source QPs and destination QPs must be of the same type to interact with each other.&lt;/p>
&lt;p>Although the IB protocol refers to QP as a &amp;ldquo;virtual interface,&amp;rdquo; it is tangible:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>On the hardware side, a QP is a storage space containing several WQEs. The IB network card reads the contents of the WQEs from this space and accesses the memory to store or retrieve data according to the user&amp;rsquo;s expectations. As for whether this storage space is memory space or on-chip storage space of the IB network card, the IB protocol does not impose restrictions, and each manufacturer has its own implementation.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>In software, QP is a data structure maintained by the driver of the IB network card, which contains the address pointer of the QP and some related software attributes.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="qpc">
&lt;a href="#qpc" class="header-anchor">#&lt;/a>
QPC
&lt;/h3>
&lt;p>In the article &lt;a class="link" href="https://cuterwrite.top/en/p/rdma-service-types/" >&amp;ldquo;5. RDMA Basic Service Types&amp;rdquo;
&lt;/a>
, we mentioned that QPC stands for Queue Pair Context, which is used to store properties related to QP. The driver does store the software properties of QP, so if we can store QP properties in software, why do we still use QPC?&lt;/p>
&lt;p>This is because &lt;strong>QPC is mainly for hardware viewing and is also used to synchronize QP information between software and hardware.&lt;/strong>&lt;/p>
&lt;p>We have mentioned that the entity of a QP on hardware is merely a segment of storage space, and the hardware knows nothing beyond the starting address and size of this space, not even the service type of this QP. There is also a lot of other important information, such as a QP containing several WQEs. How does the hardware know how many there are and which one it should currently process?&lt;/p>
&lt;p>All of the above information can be structured into a data structure by the software, and memory space can be allocated for it. However, the software only sees virtual addresses, and these memory spaces are physically discrete; the hardware does not know where this data is stored. Therefore, the software needs to pre-allocate a large contiguous space through the operating system, namely QPC, to present this information to the hardware. The network card and its accompanying driver program have pre-agreed on what content is included in the QPC, how much space each content occupies, and in what order they are stored. This way, the driver and hardware can read and write the status and other information of the QP through this QPC space.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-26_9_2_QPC.webp"
alt="2024-06-26_9_2" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>The concept of QPC&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>As shown in the figure above, the hardware actually only needs to know the address 0x12350000 of the QPC, because it can parse the contents of the QPC to determine the position of the QP, the QP sequence number, the QP size, and other information. Consequently, it can locate the QP and determine which WQE to process. Different manufacturers may have some variations in implementation, but the general principle is like this.&lt;/p>
&lt;p>There are many Context concepts in the IB software stack, in addition to QPC, there are also Device Context, SRQC, CQC, EQC (Event Queue Context), etc. Their functions are similar to QPC, all used to record and synchronize the related attributes of certain resources.&lt;/p>
&lt;h3 id="qp-number">
&lt;a href="#qp-number" class="header-anchor">#&lt;/a>
QP Number
&lt;/h3>
&lt;p>Referred to as QPN, which is the number of each QP. The IB protocol specifies using $2^{24}$ bits to represent QPN, meaning each node can simultaneously use up to $2^{24}$ QPs, which is already a very large number and almost impossible to exhaust. Each node maintains its own set of QPNs independently, meaning QPs with the same number can exist on different nodes.&lt;/p>
&lt;p>The concept of QPN itself is very simple, but there are two special reserved numbers that require extra attention:&lt;/p>
&lt;h4 id="qp0">
&lt;a href="#qp0" class="header-anchor">#&lt;/a>
QP0
&lt;/h4>
&lt;p>QP with ID 0 is used for the Subnet Management Interface (SMI), which is used to manage all nodes in the subnet. To be honest, I haven&amp;rsquo;t figured out the purpose of this interface yet, so let&amp;rsquo;s put it aside for now.&lt;/p>
&lt;h4 id="qp1">
&lt;a href="#qp1" class="header-anchor">#&lt;/a>
QP1
&lt;/h4>
&lt;p>QP numbered 1 is used for the General Service Interface (GSI), which is a set of management services, the most well-known of which is CM (Communication Management). It is a method used to exchange necessary information before formally establishing a connection between the communication nodes. Its details will be elaborated in a later article.&lt;/p>
&lt;p>This is the reason why QP0 and QP1 did not appear in the diagram about QP in our previous article. All other QPs besides these two are regular QPs. When a user creates a QP, the driver or hardware will assign a QPN to this new QP, and generally, QPNs are assigned sequentially like 2, 3, 4. After a QP is destroyed, its QPN will be reclaimed and allocated to other newly created QPs at an appropriate time.&lt;/p>
&lt;h2 id="user-interface">
&lt;a href="#user-interface" class="header-anchor">#&lt;/a>
User interface
&lt;/h2>
&lt;p>We classify and introduce user interfaces from the control plane and data plane perspectives. The control plane refers to the user&amp;rsquo;s configuration of a certain resource, which is generally done before the actual data transmission; whereas the data plane naturally involves operations during the actual data transmission process.&lt;/p>
&lt;h3 id="control-surface">
&lt;a href="#control-surface" class="header-anchor">#&lt;/a>
Control surface
&lt;/h3>
&lt;p>Readers who have encountered algorithms should all understand that the nodes of a linked list involve four operations: &amp;ldquo;add, delete, modify, and search.&amp;rdquo; The nodes of a linked list are a memory area and a type of software resource.&lt;/p>
&lt;p>&amp;ldquo;Increase&amp;rdquo; means requesting a piece of memory from the operating system to store data. The system will allocate a space in memory and mark it as &amp;ldquo;in use by process XX,&amp;rdquo; and other unauthorized processes will not be able to overwrite or even read this memory space.&lt;/p>
&lt;p>&amp;ldquo;Delete&amp;rdquo; means notifying the operating system that I am no longer using this space, and it can be marked as &amp;ldquo;unused&amp;rdquo; and made available for other processes to use.&lt;/p>
&lt;p>&amp;ldquo;Modify&amp;rdquo; means to write, i.e., to change the contents of this memory area.&lt;/p>
&lt;p>&amp;ldquo;Query&amp;rdquo; means read, that is, to obtain the content of this memory area.&lt;/p>
&lt;p>QP, as one of the most important resources in RDMA technology, is no different from a linked list in its lifecycle:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Operation&lt;/th>
&lt;th>Linked List Node&lt;/th>
&lt;th>QP&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Increase&lt;/td>
&lt;td>struct ListNode *node = malloc(sizeof(struct ListNode *));&lt;/td>
&lt;td>Create QP&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Delete&lt;/td>
&lt;td>free(node);&lt;/td>
&lt;td>Destroy QP&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Modify&lt;/td>
&lt;td>node-&amp;gt;val = xxx;&lt;/td>
&lt;td>Modify QP&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Check&lt;/td>
&lt;td>xxx = node-&amp;gt;val;&lt;/td>
&lt;td>Query QP&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>These four operations are actually the Verbs (RDMA&amp;rsquo;s API for upper-layer applications) that provide several interfaces to upper-layer users on the control plane:&lt;/p>
&lt;h4 id="create-qp">
&lt;a href="#create-qp" class="header-anchor">#&lt;/a>
Create QP
&lt;/h4>
&lt;p>Create a QP&amp;rsquo;s hardware and software resources, including the QP itself and the QPC. When the user creates it, they will input a series of initialization attributes, including the service type of the QP, the number of WQEs that can be stored, and other information.&lt;/p>
&lt;h4 id="destroy-qp">
&lt;a href="#destroy-qp" class="header-anchor">#&lt;/a>
Destroy QP
&lt;/h4>
&lt;p>Release all software and hardware resources of a QP, including the QP itself and the QPC. After destroying the QP, the user will no longer be able to index this QP through QPN.&lt;/p>
&lt;h4 id="modify-qp">
&lt;a href="#modify-qp" class="header-anchor">#&lt;/a>
Modify QP
&lt;/h4>
&lt;p>Modify certain attributes of a QP, such as the state of the QP, the MTU of the path, etc. This modification process includes both the modification of software data structures and the modification of the QPC.&lt;/p>
&lt;h4 id="query-qp">
&lt;a href="#query-qp" class="header-anchor">#&lt;/a>
Query QP
&lt;/h4>
&lt;p>Query the current status and some attributes of a QP. The data queried comes from the driver and the content of the QPC.&lt;/p>
&lt;p>These four operations all have corresponding Verbs interfaces, similar to &lt;code>ibv_create_qp()&lt;/code> form, which we can directly call when writing the APP. More details about the upper-level API will be introduced later.&lt;/p>
&lt;h2 id="data-surface">
&lt;a href="#data-surface" class="header-anchor">#&lt;/a>
Data surface
&lt;/h2>
&lt;p>In terms of data, a QP actually has only two interfaces to the upper layer, used to fill in send and receive requests in the QP. &lt;strong>Here, &amp;ldquo;send&amp;rdquo; and &amp;ldquo;receive&amp;rdquo; do not refer to sending and receiving data, but rather the &amp;ldquo;initiator&amp;rdquo; (Requestor) and &amp;ldquo;responder&amp;rdquo; (Responser) in a communication process.&lt;/strong>&lt;/p>
&lt;p>In behavior, the software fills a WQE (called WR at the application layer) into the QP, requesting the hardware to perform an action. Therefore, both behaviors are called &amp;ldquo;Post XXX Request,&amp;rdquo; meaning issuing an XXX request.&lt;/p>
&lt;h3 id="send-request">
&lt;a href="#send-request" class="header-anchor">#&lt;/a>
Send Request
&lt;/h3>
&lt;p>To emphasize again, Post Send itself does not mean that the operation type of this WQE is Send, but indicates that this WQE belongs to the initiator of the communication. The WQE/WR filled into the QP in this process can be a Send operation, RDMA Write operation, or RDMA Read operation, etc.&lt;/p>
&lt;p>The user needs to prepare the data buffer, destination address, and other information in advance, then call the interface to pass the WR to the driver, and the driver will fill the WQE into the QP.&lt;/p>
&lt;h3 id="post-receive-request">
&lt;a href="#post-receive-request" class="header-anchor">#&lt;/a>
Post Receive Request
&lt;/h3>
&lt;p>The usage scenarios for Post Recv are relatively fewer, generally only executed on the receiving end of the Send-Recv operation. The receiving end needs to prepare the buffer for receiving data in advance and inform the hardware of the buffer address and other information in the form of a WQE.&lt;/p>
&lt;h2 id="qp-state-machine">
&lt;a href="#qp-state-machine" class="header-anchor">#&lt;/a>
QP state machine
&lt;/h2>
&lt;p>Speaking of the state of QP, we have to bring out the following image (taken from section 10.3.1 of the IB protocol):&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-26_9_3.webp"
alt="2024-06-26_9_3" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>QP State Machine&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>The so-called state machine describes the different states of an object and the conditions that trigger transitions between states. Designing a state machine for an object can make the lifecycle of this object very clear, and in implementation, it will also make the logic more coherent.&lt;/p>
&lt;p>For QP, the IB specification also designs several states for it. The functions of a QP in different states vary. For example, only after entering the Ready to Send state can the QP perform Post Send data operations. State transitions between normal states (in green) are actively triggered by the user through the Modify QP user interface introduced above; whereas error states (in red) often automatically transition after an error occurs. When a QP is in an error state, it cannot perform normal operations and needs to be reconfigured to a normal state by the upper layer through Modify QP.&lt;/p>
&lt;p>In the above diagram, we only focus on the part of QP. EE (End-to-End Context) is a concept specifically used for RD service types, which we will not cover for now. We enter this state diagram through the Create QP interface and exit this state diagram through the Destroy QP interface.&lt;/p>
&lt;p>QP has the following states, we will only introduce some important points:&lt;/p>
&lt;h3 id="rst-reset">
&lt;a href="#rst-reset" class="header-anchor">#&lt;/a>
RST (Reset)
&lt;/h3>
&lt;p>Reset state. When a QP is created through Create QP, it is in this state. The related resources have already been allocated, but this QP cannot do anything at the moment. It cannot receive WQEs issued by the user, nor can it receive messages from a QP on the peer end.&lt;/p>
&lt;h3 id="initinitialized">
&lt;a href="#initinitialized" class="header-anchor">#&lt;/a>
INIT（Initialized）
&lt;/h3>
&lt;p>Initialized state. In this state, the user can issue Receive WR to this QP via Post Receive, but the received messages will not be processed and will be silently discarded; if the user issues a Post Send WR, an error will occur.&lt;/p>
&lt;h3 id="rtrready-to-receive">
&lt;a href="#rtrready-to-receive" class="header-anchor">#&lt;/a>
RTR（Ready to Receive）
&lt;/h3>
&lt;p>Ready to receive status. Based on the INIT state, RQ can function normally, meaning it can move data to the specified memory location according to the instructions in the received message&amp;rsquo;s WQE. In this state, SQ still cannot function.&lt;/p>
&lt;h3 id="rts-ready-to-send">
&lt;a href="#rts-ready-to-send" class="header-anchor">#&lt;/a>
RTS (Ready to Send)
&lt;/h3>
&lt;p>Ready to send status. Based on RTR, SQ can work normally, meaning the user can perform Post Send, and the hardware will also send the data according to the content of SQ. Before entering this state, QP must have already established a connection with the peer.&lt;/p>
&lt;h3 id="sqd-send-queue-drain">
&lt;a href="#sqd-send-queue-drain" class="header-anchor">#&lt;/a>
SQD (Send Queue Drain)
&lt;/h3>
&lt;p>SQ emptying state. As the name suggests, this state will process all the existing unprocessed WQEs in the SQ queue. At this time, the user can still submit new WQEs, but these WQEs will be processed only after all the old WQEs have been processed.&lt;/p>
&lt;h3 id="sqer-send-queue-error">
&lt;a href="#sqer-send-queue-error" class="header-anchor">#&lt;/a>
SQEr (Send Queue Error)
&lt;/h3>
&lt;p>SQ error state. When a Send WR encounters a completion error (i.e., an error reported to the driver by the hardware through CQE), it causes the QP to enter this state.&lt;/p>
&lt;h3 id="err-error">
&lt;a href="#err-error" class="header-anchor">#&lt;/a>
ERR (Error)
&lt;/h3>
&lt;p>Error state. If an error occurs in other states, they may enter this state. In the Error state, the QP will stop processing WQE, and any WQE that is halfway processed will also stop. The upper layer needs to switch the QP back to the initial RST state after fixing the error.&lt;/p>
&lt;h2 id="summary">
&lt;a href="#summary" class="header-anchor">#&lt;/a>
Summary
&lt;/h2>
&lt;p>This article first reviews some important basic concepts of QP, then explains QPC, QPN, and other concepts closely related to QP, and finally introduces the interfaces commonly used by users to operate QP and the QP state machine. I believe that after reading this article, readers will have a deeper understanding of QP.&lt;/p>
&lt;p>In fact, as a core concept of RDMA, there is a lot of content regarding QP, and this article cannot cover everything. I will gradually complete the related content in future articles. For example, the concept of QKey will be explained in detail in subsequent articles dedicated to various Keys.&lt;/p>
&lt;p>Alright, this is the end of the article. Thank you for reading. A preview of the next article will provide a detailed explanation of CQ.&lt;/p>
&lt;h2 id="relevant-sections-of-the-agreement">
&lt;a href="#relevant-sections-of-the-agreement" class="header-anchor">#&lt;/a>
Relevant sections of the agreement
&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>3.5.1 10.2.4 Basic Concepts of QP&lt;/p>
&lt;/li>
&lt;li>
&lt;p>10.3 QP State Machine&lt;/p>
&lt;/li>
&lt;li>
&lt;p>10.2.5 Software interfaces related to QP&lt;/p>
&lt;/li>
&lt;li>
&lt;p>11.4 Post Send Post Recv&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>RDMA: Address Handle</title><link>https://cuterwrite.top/en/p/rdma-address-handle/</link><pubDate>Sat, 15 Jun 2024 01:00:00 +0000</pubDate><guid>https://cuterwrite.top/en/p/rdma-address-handle/</guid><description>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-16_116373922_p9_master1200.webp" alt="Featured image of post RDMA: Address Handle" />&lt;h1 id="rdmas-address-handle">
&lt;a href="#rdmas-address-handle" class="header-anchor">#&lt;/a>
RDMA&amp;rsquo;s Address Handle
&lt;/h1>
&lt;p>&lt;strong>This article welcomes non-commercial reprints, please indicate the source when reprinting.&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>Statement: For collection only, for easy reading&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/163552044">&lt;cite>Zhihu Column: 8. RDMA Address Handle&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>It has already been introduced that the basic unit of RDMA communication is the QP. Let&amp;rsquo;s consider a question: Suppose a QP on node A wants to exchange information with a QP on node B. Besides knowing the QP number—QPN—of node B, what other information is needed? It should be noted that the QPN is a number maintained independently by each node and is not unique across the entire network. For instance, if QP 3 on A wants to communicate with QP 5 on B, there is not just one QP5 in the network; many nodes might have their own QP 5. Therefore, we can naturally think of the need to find a way for each node to have a unique identifier.&lt;/p>
&lt;p>In the traditional TCP-IP protocol stack, the well-known IP address is used to identify each node at the network layer. In the IB protocol, this identifier is called the &lt;strong>GID (Global Identifier)&lt;/strong>, which is a 128-bit sequence. This article will not discuss GID in detail and will introduce it later.&lt;/p>
&lt;h2 id="what-is-ah">
&lt;a href="#what-is-ah" class="header-anchor">#&lt;/a>
What is AH
&lt;/h2>
&lt;p>AH stands for Address Handle. I couldn&amp;rsquo;t think of a particularly suitable Chinese translation, so let&amp;rsquo;s directly translate it as &amp;ldquo;地址句柄&amp;rdquo; for now. The address here refers to a set of information used to locate a remote node. In the IB protocol, the address refers to information such as GID, port number, etc. As for the so-called handle, we can understand it as a pointer to an object.&lt;/p>
&lt;p>Does everyone still remember that there are four basic service types in the IB protocol—RC, UD, RD, and UC, with RC and UD being the most commonly used. The characteristic of RC is that a reliable connection is established between the QPs of two nodes, and once the connection is established, it is not easily changed. The information of the peer is stored in the QP Context when creating the QP.&lt;/p>
&lt;p>As for UD, there is no connection relationship between QPs. The user can fill in the peer&amp;rsquo;s address information in the WQE for whoever they want to send to. &lt;strong>The user does not directly fill the peer&amp;rsquo;s address information into the WQE but prepares an &amp;ldquo;address book&amp;rdquo; in advance, specifying the peer node&amp;rsquo;s address information each time through an index, which is the AH.&lt;/strong>&lt;/p>
&lt;p>The concept of AH can be roughly represented by the diagram below:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-16_8_1.webp"
alt="2024-06-16_8_1" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Address Handle Function Diagram&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>For each destination node, a corresponding AH will be created at this end, and the same AH can be shared by multiple QPs.&lt;/p>
&lt;h2 id="the-role-of-ah">
&lt;a href="#the-role-of-ah" class="header-anchor">#&lt;/a>
The role of AH
&lt;/h2>
&lt;p>Before each communication of the UD service type, the user needs to first use the interface provided by the IB framework to &lt;strong>create an AH for each possible peer node&lt;/strong>, then these AHs are driven into a &amp;ldquo;secure&amp;rdquo; area, and an index (pointer/handle) is returned to the user. When the user actually issues a WR (Work Request), they just need to pass in this index.&lt;/p>
&lt;p>The above process is shown in the diagram below. Node A receives a task from the user to exchange data using its QP4 with Node B&amp;rsquo;s QP3 (specified through AH):&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-16_8_2.webp"
alt="2024-06-16_8_2" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>UD service type uses AH to specify peer node&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>The IB protocol does not explain why AH is used. I believe there are three reasons for defining the concept of AH:&lt;/p>
&lt;ol>
&lt;li>Ensure the destination address is available, improve efficiency&lt;/li>
&lt;/ol>
&lt;p>Due to the connectionless nature of UD, users can directly specify the destination through WR in user mode. However, if users are allowed to fill in address information at will, and then hardware packages the data according to this information, it may lead to problems. For example, there is a scenario like this: a user tells the hardware through WR to send data to port Z of a node with GID X and MAC address Y. However, X, Y, and Z may not be a valid combination, or a node with GID X may not even exist in the network, and the hardware is unable to verify this content, so it can only obediently package and send the data. This results in the unnecessary sending of a data packet to an invalid destination.&lt;/p>
&lt;p>And preparing the address information in advance can avoid the above situation. When the user creates AH, they will enter kernel mode. If the parameters passed by the user are valid, the kernel will store this destination node information, generate a pointer, and return it to the user; if the parameters passed by the user are invalid, AH creation will fail. This process ensures that the address information is valid. The user can quickly specify the destination node through the pointer, speeding up the data interaction process.&lt;/p>
&lt;p>Some may ask, since the kernel is trusted, why not switch to kernel mode to verify the address information passed by the user when sending data? Please do not forget where one of the major advantages of RDMA technology lies—the data flow can go directly from user space to hardware, completely bypassing the kernel, thus avoiding the overhead of system calls and copying. If the legality of the address has to be checked every time data is sent, it will inevitably reduce the communication rate.&lt;/p>
&lt;ol start="2">
&lt;li>Hide underlying address details from the user&lt;/li>
&lt;/ol>
&lt;p>When the user creates AH, they only need to provide information such as gid, port number, static rate, etc., while other address information required for communication (mainly MAC addresses) is resolved by the kernel driver through querying the system neighbor table and other methods. There is no need to expose this additional information to the user layer.&lt;/p>
&lt;ol start="3">
&lt;li>You can use PD to manage the destination address.&lt;/li>
&lt;/ol>
&lt;p>In the previous text, when we introduced protection domains, we mentioned that besides QP and MR, AH is also resource partitioned by PD. Once the software entity AH is defined, we can isolate and manage all destinations reachable by QP.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/2024-06-16_8_3.webp"
alt="2024-06-16_8_3" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Use PD to isolate AH&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>For example, in the image above, AH1~3 can only be used by QP3 and QP9 under the same PD, while AH4 can only be used by QP5.&lt;/p>
&lt;h2 id="relevant-sections-of-the-agreement">
&lt;a href="#relevant-sections-of-the-agreement" class="header-anchor">#&lt;/a>
Relevant sections of the agreement
&lt;/h2>
&lt;p>There is not much coverage about AH in the agreement, and there is not even a chapter dedicated to introducing its concept:&lt;/p>
&lt;p>[1] 9.8.3 What components make up the destination address in UD service type: including AH, QPN, and Q_key&lt;/p>
&lt;p>[2] 10.2.2.2 Relevant Considerations for the Destination Address&lt;/p>
&lt;p>[3] 11.2.2.1 AH Related Verbs Interface&lt;/p>
&lt;p>AH is introduced here, thank you for reading. In the next article, I plan to describe more details about QP.&lt;/p></description></item><item><title>RDMA: Protection Domain</title><link>https://cuterwrite.top/en/p/rdma-protection-domain/</link><pubDate>Thu, 18 Apr 2024 21:42:00 +0000</pubDate><guid>https://cuterwrite.top/en/p/rdma-protection-domain/</guid><description>&lt;img src="https://cloud.cuterwrite.fun/img/d31a474af07682028ca085f871bc5d07195413-2024-04-19.webp" alt="Featured image of post RDMA: Protection Domain" />&lt;h1 id="protection-domain-in-rdma">
&lt;a href="#protection-domain-in-rdma" class="header-anchor">#&lt;/a>
Protection Domain in RDMA
&lt;/h1>
&lt;p>&lt;strong>This article welcomes non-commercial reproduction, please indicate the source when reproducing.&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>Statement: For collection only, for easy reading&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/159493100">&lt;cite>Zhihu Column: 7. RDMA and Protection Domain&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>In the previous text, we briefly introduced some of the most common resources in RDMA, including various Queues and the concept of MR, among others. MR is used to control and manage HCA&amp;rsquo;s access rights to local and remote memory, ensuring that the HCA can only read and write to memory regions that the user has registered after obtaining the correct Key. To better ensure security, the IB protocol also introduced the concept of Protection Domain (PD) to ensure mutual isolation among RDMA resources. This article will introduce the concept of PD.&lt;/p>
&lt;h2 id="what-is-pd">
&lt;a href="#what-is-pd" class="header-anchor">#&lt;/a>
What is PD?
&lt;/h2>
&lt;p>PD stands for Protection Domain. The concept of a domain is often seen, from mathematical &amp;ldquo;real number fields&amp;rdquo; and &amp;ldquo;complex number fields&amp;rdquo; to geographical &amp;ldquo;airspace&amp;rdquo; and &amp;ldquo;sea area,&amp;rdquo; representing a space/range. In RDMA, a PD is like a &amp;ldquo;container&amp;rdquo; that holds various resources (QP, MR, etc.), bringing these resources under its protection to prevent unauthorized access. Multiple protection domains can be defined within a node, and the resources contained within each PD are isolated from each other and cannot be used together.&lt;/p>
&lt;p>The concept is still somewhat abstract, let&amp;rsquo;s take a look at what role PD plays and what specific problems it solves.&lt;/p>
&lt;h2 id="the-function-of-pd">
&lt;a href="#the-function-of-pd" class="header-anchor">#&lt;/a>
The function of PD
&lt;/h2>
&lt;p>A user may create multiple QPs and multiple MRs, and each QP may establish connections with different remote QPs, as shown in the diagram below (gray arrows indicate the connection relationships between QPs):&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/7_1-2024-04-19.webp"
alt="7_1-2024-04-19" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Figure 1: RDMA Resources Without PD Concept&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>Since there is no binding relationship between MR and QP, this means that once a remote QP establishes a connection with a local QP and the conditions for communication are met, theoretically, as long as the remote node knows the VA and R_key (it can even keep guessing until it gets a valid pair of values), it can access the contents of an MR on the local node.&lt;/p>
&lt;p>In general, the virtual address VA of MR and the key R_Key are difficult to guess, which already ensures a certain level of security. However, to better protect the data in memory and further isolate and divide the permissions of various resources, we have defined PD in each node, as shown in the diagram below.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/7_2-2024-04-19.webp"
alt="7_2-2024-04-19" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Figure 2: RDMA resources when adding the PD concept&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>In the diagram, Node 0 has two PDs, with 3 QPs and 2 MRs divided into two groups. Additionally, Node 1 and Node 2 each have a PD containing all QPs and MRs. The resources in the two PDs on Node 0 cannot be used together, meaning QP3 and QP9 cannot access the data of MR1, and QP6 cannot access the data of MR0. If we specify the hardware to use QP3 and MR1 during data transmission, the hardware will verify that they do not belong to the same PD and return an error.&lt;/p>
&lt;p>For the remote node, Node1 can only access Node0&amp;rsquo;s memory through QP3 connected via QP8. However, because Node0&amp;rsquo;s QP3 is &amp;ldquo;encircled&amp;rdquo; in the protection domain PD0, Node1&amp;rsquo;s QP8 can only access the memory corresponding to MR0, &lt;strong>and cannot access the data in MR1 under any circumstances&lt;/strong>. This is restricted from two aspects:&lt;/p>
&lt;ol>
&lt;li>Node 1&amp;rsquo;s QP8 is only connected to Node 0&amp;rsquo;s QP3, and cannot access memory through Node 0&amp;rsquo;s QP6.&lt;/li>
&lt;li>MR1 and QP3 of Node 0 belong to different PDs, so even if QP8 of Node 1 obtains the VA and R_key of MR1, the hardware will refuse to provide service due to different PDs.&lt;/li>
&lt;/ol>
&lt;p>As mentioned at the beginning of this article, a PD is like a container that protects some RDMA resources, isolating them from each other to enhance security. In fact, RDMA includes not only resources like QP and MR, but also Address Handle, Memory Window, etc., which are also isolated and protected by PD, as will be introduced later.&lt;/p>
&lt;h2 id="how-to-use-pd">
&lt;a href="#how-to-use-pd" class="header-anchor">#&lt;/a>
How to use PD
&lt;/h2>
&lt;p>Still looking at the above diagram, we notice that Node 0 has two PDs for resource isolation, whereas Node 1 and Node 2 have only one PD containing all the resources.&lt;/p>
&lt;p>The reason I draw it this way is to illustrate that the number of PDs divided on a node is entirely up to the user. &lt;strong>If you want to enhance security, then each QP connected to a remote node and the MR provided for remote access should be isolated as much as possible by dividing PDs. If higher security is not a concern, then creating one PD that encompasses all resources is also acceptable.&lt;/strong>&lt;/p>
&lt;p>The IB protocol specifies: &lt;strong>Each node must have at least one PD, each QP must belong to a PD, and each MR must also belong to a PD&lt;/strong>.&lt;/p>
&lt;p>So how is the inclusion relationship of PD reflected in the software? It itself has a software entity (structure) that records some information about this protection domain. Before users create resources like QP and MR, they must first create a PD through the interface of the IB framework to get its pointer/handle. Then, when creating QP and MR, this PD&amp;rsquo;s pointer/handle needs to be passed in, and PD information will be included in QP and MR. When the hardware sends and receives packets, it will verify the PD of QP and MR. I will introduce more about the software protocol stack in later articles.&lt;/p>
&lt;p>Additionally, it is important to emphasize that &lt;strong>PD is a local concept and only exists within the node&lt;/strong>, it is not visible to other nodes; whereas MR is visible to both the local and remote ends.&lt;/p>
&lt;p>For everyone&amp;rsquo;s convenience in referencing and learning, I will list the protocol sections involved in the articles. I will also supplement the previous content when I have time.&lt;/p>
&lt;h2 id="pd-related-protocol-chapter">
&lt;a href="#pd-related-protocol-chapter" class="header-anchor">#&lt;/a>
PD related protocol chapter
&lt;/h2>
&lt;ul>
&lt;li>Basic concepts and functions of 3.5.5 PD&lt;/li>
&lt;li>10.2.3 introduces the relationship between PD and some other RDMA resources, as well as the software interfaces related to PD.&lt;/li>
&lt;li>10.6.3.5 Emphasize again the relationship between PD, MR, and QP.&lt;/li>
&lt;li>11.2.1.5 Detailed introduction to the Verbs interface of PD, including functions, input parameters, output parameters, and return values, etc.&lt;/li>
&lt;/ul>
&lt;p>Alright, that concludes the introduction to PD. In the following text, I will introduce the concept of Address Handle used for UD service types.&lt;/p></description></item><item><title>RDMA: Memory Region</title><link>https://cuterwrite.top/en/p/rdma-mr/</link><pubDate>Wed, 03 Apr 2024 16:17:00 +0000</pubDate><guid>https://cuterwrite.top/en/p/rdma-mr/</guid><description>&lt;img src="https://cloud.cuterwrite.fun/img/8fa232626b76940fddc8cc52a49c49e9195413-2024-04-04.webp" alt="Featured image of post RDMA: Memory Region" />&lt;h1 id="memory-region-of-rdma">
&lt;a href="#memory-region-of-rdma" class="header-anchor">#&lt;/a>
Memory Region of RDMA
&lt;/h1>
&lt;p>&lt;strong>This article welcomes non-commercial reproduction, please indicate the source.&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>Statement: For collection only, for easy reading&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/156975042">&lt;cite>Zhihu Column: 6. RDMA Memory Region&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>We assume a scenario and also take the opportunity to review the RDMA WRITE operation process:&lt;/p>
&lt;p>As shown in the figure below, Node A wants to write a piece of data into Node B&amp;rsquo;s memory via the IB protocol. The upper-layer application issues a WQE to the RDMA network card of the local node. The WQE contains information such as source memory address, destination memory address, data length, and key. Then the hardware retrieves the data from memory, packages it, and sends it to the remote network card. After Node B&amp;rsquo;s network card receives the data, it parses the destination memory address and writes the data into the local node&amp;rsquo;s memory.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/6_1-2024-04-04.webp"
alt="6_1-2024-04-04" width="auto" loading="lazy">
&lt;/figure>
&lt;p>So the question arises, the addresses provided by the APP are all virtual addresses (Virtual Address, referred to as VA below), which need to be converted by the MMU to obtain the real physical address (Physical Address, referred to as PA below). &lt;strong>How does our RDMA network card obtain the PA to fetch data from memory&lt;/strong>? Even if the network card knows where to fetch the data, &lt;strong>if a user maliciously specifies an illegal VA, wouldn&amp;rsquo;t the network card possibly be &amp;ldquo;instructed&amp;rdquo; to read and write critical memory&lt;/strong>?&lt;/p>
&lt;p>To solve the above problem, the IB protocol proposed the concept of MR.&lt;/p>
&lt;h2 id="what-is-mr">
&lt;a href="#what-is-mr" class="header-anchor">#&lt;/a>
What is MR
&lt;/h2>
&lt;p>MR stands for Memory Region, which refers to a region designated by the RDMA software layer in memory for storing transmitted and received data. In the IB protocol, after a user requests a memory region for storing data, they must register the MR by calling the API provided by the IB framework to allow the RDMA network card to access this memory region. As can be seen from the diagram below, MR is just a special piece of memory:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/6_2-2024-04-04.webp"
alt="6_2-2024-04-04" width="auto" loading="lazy">
&lt;/figure>
&lt;p>When describing the IB protocol, we usually refer to the RDMA hardware as &lt;strong>HCA (Host Channel Adapter)&lt;/strong>. The IB protocol defines it as &amp;ldquo;an IB device in processors and I/O units capable of generating and consuming packets.&amp;rdquo; To remain consistent with the protocol, we will refer to the hardware part as HCA in this and subsequent articles.&lt;/p>
&lt;h2 id="why-register-mr">
&lt;a href="#why-register-mr" class="header-anchor">#&lt;/a>
Why register MR
&lt;/h2>
&lt;p>Let&amp;rsquo;s take a look at how MR addresses the two questions raised at the beginning of this article:&lt;/p>
&lt;h3 id="1-register-mr-to-achieve-virtual-to-physical-address-translation">
&lt;a href="#1-register-mr-to-achieve-virtual-to-physical-address-translation" class="header-anchor">#&lt;/a>
1. Register MR to achieve virtual-to-physical address translation
&lt;/h3>
&lt;p>We all know that an APP can only see virtual addresses, and it will directly pass the VA to the HCA in the WQE (including both the source VA on the local end and the destination VA on the remote end). Modern CPUs have the &amp;ldquo;tool&amp;rdquo; of MMU and page tables to perform the conversion between VA and PA, while the HCA is either directly connected to the bus or connected to the bus after address translation through IOMMU/SMMU. It cannot &amp;ldquo;understand&amp;rdquo; the real physical memory address corresponding to the VA provided by the APP.&lt;/p>
&lt;p>So during the process of registering MR, the hardware will create and fill a VA to PA mapping table in memory, so that when needed, VA can be converted to PA by looking up the table. Let&amp;rsquo;s provide a specific example to explain this process:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/6_3-2024-04-04.webp"
alt="6_3-2024-04-04" width="auto" loading="lazy">
&lt;/figure>
&lt;p>Now assume that the node on the left initiates an RDMA WRITE operation to the node on the right, directly writing data into the memory area of the right node. Assume that both ends in the diagram have already completed the registration of MR, which corresponds to the &amp;ldquo;data Buffer&amp;rdquo; in the diagram, and have also created the VA-&amp;gt;PA mapping table.&lt;/p>
&lt;ul>
&lt;li>First, this end&amp;rsquo;s APP will issue a WQE to the HCA, informing the HCA of the virtual address of the local buffer used to store the data to be sent, as well as the virtual address of the peer data buffer that will be written to.&lt;/li>
&lt;li>This end HCA queries the VA-&amp;gt;PA mapping table to obtain the physical address of the data to be sent, then retrieves the data from memory, assembles the data packet, and sends it out.&lt;/li>
&lt;li>The remote HCA received the packet and parsed the destination VA from it.&lt;/li>
&lt;li>The peer HCA uses the VA-&amp;gt;PA mapping table stored in local memory to find the real physical address, verifies the permissions, and then stores the data in memory.&lt;/li>
&lt;/ul>
&lt;p>Emphasize once again, for the right-side node, &lt;strong>whether it&amp;rsquo;s address translation or writing to memory, it does not require any involvement of its CPU&lt;/strong>.&lt;/p>
&lt;h3 id="2-mr-can-control-hcas-access-to-memory-permissions">
&lt;a href="#2-mr-can-control-hcas-access-to-memory-permissions" class="header-anchor">#&lt;/a>
2. MR can control HCA&amp;rsquo;s access to memory permissions
&lt;/h3>
&lt;p>Because the memory address accessed by the HCA comes from the user, if the user provides an illegal address (such as system memory or memory used by another process), HCA reading or writing to it may cause information leakage or memory corruption. Therefore, we need a mechanism to ensure that HCA can only access authorized and safe memory addresses. In the IB protocol, during the preparation stage for data interaction, the APP needs to perform the action of registering MR.&lt;/p>
&lt;p>When a user registers MR, two keys are generated—L_KEY (Local Key) and R_KEY (Remote Key). Although they are called keys, their entities are actually just a sequence. They will be used to ensure access permissions for the local and remote memory regions, respectively. The following two diagrams are schematic representations describing the functions of L_Key and R_Key:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/6_4-2024-04-04.webp"
alt="6_4-2024-04-04" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>L_Key&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/6_5-2024-04-04.webp"
alt="6_5-2024-04-04" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>R_Key&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>Here, everyone might have a question: how does this end know the available VA and the corresponding R_Key of the peer node? In fact, before the actual RDMA communication, both nodes establish a link through some means (it could be a Socket connection or a CM connection) and exchange some necessary information for RDMA communication (VA, Key, QPN, etc.) through this link. We call this process &amp;ldquo;link establishment&amp;rdquo; and &amp;ldquo;handshake.&amp;rdquo; I will introduce this in detail in the following articles.&lt;/p>
&lt;p>In addition to the two points above, registering MR has another important function:&lt;/p>
&lt;h3 id="3-mr-can-avoid-page-swapping">
&lt;a href="#3-mr-can-avoid-page-swapping" class="header-anchor">#&lt;/a>
3. MR can avoid page swapping
&lt;/h3>
&lt;p>Because physical memory is limited, the operating system uses a paging mechanism to temporarily save the unused memory contents of a process to the hard drive. When the process needs to use it, a page fault interrupt is used to move the contents from the hard drive back to memory, and this process almost inevitably causes the VA-PA mapping relationship to change.&lt;/p>
&lt;p>Since HCA often bypasses the CPU to read and write to the physical memory areas pointed to by the VA provided by the user, if the VA-PA mapping relationship changes, then the VA-&amp;gt;PA mapping table mentioned earlier will lose its significance, and HCA will be unable to find the correct physical address.&lt;/p>
&lt;p>In order to prevent the VA-PA mapping relationship from changing due to page swapping, the memory is &amp;ldquo;Pinned&amp;rdquo; when registering MR (also known as &amp;ldquo;page locking&amp;rdquo;), which means locking the VA-PA mapping relationship. In other words, this MR memory area will remain in physical memory without being swapped out until the communication is completed, and the user actively deregisters this MR.&lt;/p>
&lt;p>Alright, we have now finished introducing the concept and function of MR. In the next article, I will introduce the concept of PD (Protection Domain).&lt;/p>
&lt;h2 id="code-example">
&lt;a href="#code-example" class="header-anchor">#&lt;/a>
Code example
&lt;/h2>
&lt;p>Below is a simple RDMA program demonstrating how to register MR:&lt;/p>
&lt;pre>&lt;code class="language-c">#include &amp;lt;infiniband/verbs.h&amp;gt;
int main() {
// Omit initialization process...
struct ibv_mr *mr;
mr = ibv_reg_mr(pd, buf, 1024, IBV_ACCESS_LOCAL_WRITE |
IBV_ACCESS_REMOTE_WRITE);
// Get L_Key and R_Key
uint32_t lkey = mr-&amp;gt;lkey;
uint32_t rkey = mr-&amp;gt;rkey;
// Omit other code...
}
&lt;/code>&lt;/pre></description></item><item><title>RDMA Basic Service Types</title><link>https://cuterwrite.top/en/p/rdma-service-types/</link><pubDate>Sun, 25 Feb 2024 22:04:01 +0000</pubDate><guid>https://cuterwrite.top/en/p/rdma-service-types/</guid><description>&lt;img src="https://cloud.cuterwrite.fun/img/f71da3ec40dd74648e15471d47ba3b84195413_crop-2024-02-26.webp" alt="Featured image of post RDMA Basic Service Types" />&lt;h1 id="rdma-basic-service-types">
&lt;a href="#rdma-basic-service-types" class="header-anchor">#&lt;/a>
RDMA Basic Service Types
&lt;/h1>
&lt;p>&lt;strong>This article welcomes non-commercial reprints, please indicate the source when reprinting.&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>Statement: For collection only, for convenient reading&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/144099636">&lt;cite>Zhihu Column: 5. Basic RDMA Service Types&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>In the article &lt;a class="link" href="https://cuterwrite.top/en/p/rdma-element/" >【“3. RDMA Basic Elements”】
&lt;/a>
, we mentioned that &lt;strong>the basic communication unit of RDMA is QP&lt;/strong>, and there are many communication models based on QP, which we refer to as &amp;ldquo;service types&amp;rdquo; in the field of RDMA. The IB protocol describes a service type through two dimensions: &amp;ldquo;reliable&amp;rdquo; and &amp;ldquo;connected&amp;rdquo;.&lt;/p>
&lt;h2 id="reliable">
&lt;a href="#reliable" class="header-anchor">#&lt;/a>
Reliable
&lt;/h2>
&lt;p>Reliability in communication refers to ensuring that the sent data packets can be properly received through some mechanisms. In the IB protocol, reliable service is described as follows:&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Reliable Service&lt;/strong> provides a guarantee that messages are delivered from a requester to a responder at most once, in order and without corruption.&lt;/p>
&lt;/blockquote>
&lt;p>&amp;ldquo;Reliable service ensures that information is transmitted at most once between the sender and receiver, and it can guarantee that it is completely received in the order it was sent.&amp;rdquo;&lt;/p>
&lt;p>IB ensures reliability through the following three mechanisms:&lt;/p>
&lt;h2 id="response-mechanism">
&lt;a href="#response-mechanism" class="header-anchor">#&lt;/a>
Response mechanism
&lt;/h2>
&lt;p>Suppose A sends a data packet to B, how can A know that B has received it? Naturally, B replies with a &amp;ldquo;I have received it&amp;rdquo; message to A. In the field of communications, we generally refer to this reply as an acknowledgment packet or ACK. In the reliable service type of the IB protocol, an acknowledgment mechanism is used to ensure that the data packet is received by the other party. In the reliable service type of IB, the receiver does not have to reply to every packet; it can also reply with an ACK for multiple packets at once. We will discuss this further later.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/ib_ack-2024-02-26.webp"
alt="ib_ack-2024-02-26" width="auto" loading="lazy">
&lt;/figure>
&lt;h2 id="data-validation-mechanism">
&lt;a href="#data-validation-mechanism" class="header-anchor">#&lt;/a>
Data validation mechanism
&lt;/h2>
&lt;p>This is relatively easy to understand. The sender will use a certain algorithm to obtain a checksum for the Header and Payload (the actual data to be sent and received) and place it at the end of the data packet. When the receiving end receives the data packet, it will also use the same algorithm to calculate the checksum and then compare it with the checksum in the data packet. If they do not match, it indicates that the data contains errors (usually caused by link issues), and the receiving end will discard this data packet. The IB protocol uses CRC for checksum, and this article does not provide an in-depth introduction to CRC.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/crc-2024-02-26.png"
alt="crc-2024-02-26" width="auto" loading="lazy">
&lt;/figure>
&lt;h2 id="order-preserving-mechanism">
&lt;a href="#order-preserving-mechanism" class="header-anchor">#&lt;/a>
Order-preserving mechanism
&lt;/h2>
&lt;p>In-order delivery refers to ensuring that data packets sent first over the physical link are received by the recipient before later sent packets. Some services have strict requirements on the order of data packets, such as voice or video. The IB protocol includes the concept of PSN (Packet Sequence Number), meaning each packet has an incrementing number. PSN can be used to detect packet loss; for example, if the receiver gets 1 but receives 3 without having received 2, it will consider an error occurred during transmission and will send a NAK back to the sender, requesting the retransmission of the lost packet.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/psn-2024-02-26.webp"
alt="psn-2024-02-26" width="auto" loading="lazy">
&lt;/figure>
&lt;p>Unreliable service, without the above mechanisms to ensure that packets are received correctly, belongs to the type of service that is &amp;ldquo;just send it out, I don&amp;rsquo;t care if it is received or not.&amp;rdquo;&lt;/p>
&lt;h2 id="connection-and-datagram">
&lt;a href="#connection-and-datagram" class="header-anchor">#&lt;/a>
Connection and Datagram
&lt;/h2>
&lt;p>&lt;strong>Connection&lt;/strong> here refers to an abstract logical concept, which needs to be distinguished from a physical connection. Readers familiar with Sockets will certainly not be unfamiliar with this. A connection is a communication &amp;ldquo;pipeline.&amp;rdquo; Once the pipeline is established, the data sent from this end of the pipeline will definitely reach the other end along this pipeline.&lt;/p>
&lt;p>There are many definitions for &amp;ldquo;connection&amp;rdquo; or &amp;ldquo;connection-oriented&amp;rdquo;, some focus on ensuring the order of messages, some emphasize the uniqueness of the message delivery path, some highlight the need for software and hardware overhead to maintain the connection, and some overlap with the concept of reliability. Since this column is about introducing RDMA technology, let&amp;rsquo;s take a look at its description in section 3.2.2 of the IB protocol:&lt;/p>
&lt;blockquote>
&lt;p>IBA supports both connection-oriented and datagram service. For connected service, each QP is associated with exactly one remote consumer. In this case, the QP context is configured with the identity of the remote consumer’s queue pair. &amp;hellip; During the communication establishment process, this and other information is exchanged between the two nodes.&lt;/p>
&lt;/blockquote>
&lt;p>That is, &amp;ldquo;IBA supports both connection-oriented and datagram-based services. For connection-oriented services, each QP is associated with another remote node. In this case, the QP Context contains the QP information of the remote node. During the process of establishing communication, the two nodes exchange peer information, including the QP that will be used for communication later.&amp;rdquo;&lt;/p>
&lt;p>In the description above, Context is generally translated as 上下文. QP Context (abbreviated as QPC) can be simply understood as a table that records information related to a QP. We know that QP consists of two queues, and in addition to these two queues, we also need to record information about the QP in a table. This information may include the depth of the queues, the queue numbers, etc. We will elaborate on this later.&lt;/p>
&lt;p>It might still be a bit abstract, let&amp;rsquo;s use a diagram to explain:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/QPC-2024-02-26.webp"
alt="QPC-2024-02-26" width="auto" loading="lazy">
&lt;/figure>
&lt;p>The network cards of nodes A, B, and A, C are physically connected. A&amp;rsquo;s QP2 and B&amp;rsquo;s QP7, A&amp;rsquo;s QP4 and B&amp;rsquo;s QP2 have established a logical connection, or are &amp;ldquo;bound together.&amp;rdquo; &lt;strong>In the connection service type, each QP is connected to a unique other QP, meaning that the destination of each WQE issued by the QP is unique.&lt;/strong> For example, for each WQE issued by A&amp;rsquo;s QP2, the hardware can know through QPC that its destination is B&amp;rsquo;s QP7, and will send the assembled packet to B. Then B will store the data according to the RQ WQE issued by QP7; similarly, for each WQE issued by A&amp;rsquo;s QP4, A&amp;rsquo;s hardware knows that the data should be sent to Node C&amp;rsquo;s QP2.&lt;/p>
&lt;p>How is a &amp;ldquo;connection&amp;rdquo; maintained? Actually, it&amp;rsquo;s just a record inside the QPC. If A&amp;rsquo;s QP2 wants to disconnect from B&amp;rsquo;s QP7 and then &amp;ldquo;connect&amp;rdquo; with another QP, it only needs to modify the QPC. During the process of establishing a connection between two nodes, they exchange the QP Number that will be used later for data interaction, and then record it in the QPC respectively.&lt;/p>
&lt;p>&lt;strong>Datagram&lt;/strong> Contrary to connection, there is no need for a &amp;ldquo;pipeline establishment&amp;rdquo; step between the sender and receiver. As long as the sender can physically reach the receiver, it is possible to send to any receiving node from any path. The IB protocol defines it as follows:&lt;/p>
&lt;blockquote>
&lt;p>For datagram service, a QP is not tied to a single remote consumer, but rather information in the WQE identifies the destination. A communication setup process similar to the connection setup process needs to occur with each destination to exchange that information.&lt;/p>
&lt;p>&amp;ldquo;For datagram services, a QP will not be bound to a unique remote node but will specify the destination node through a WQE. Similar to connection-type services, the process of establishing communication requires both ends to exchange peer information, but for datagram services, this exchange process needs to be executed once for each destination node.&amp;rdquo;&lt;/p>
&lt;/blockquote>
&lt;p>Let&amp;rsquo;s take an example:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/Datagram-2024-02-26.webp"
alt="Datagram-2024-02-26" width="auto" loading="lazy">
&lt;/figure>
&lt;p>In the context of a datagram-type QP, it does not contain peer information, meaning each QP is not bound to another QP. &lt;strong>Each WQE issued to the hardware by the QP may point to a different destination&lt;/strong>. For example, the first WQE issued by QP2 of node A instructs to send data to QP3 of node C; while the next WQE may instruct the hardware to send to QP7 of node B.&lt;/p>
&lt;p>Like the connection service type, which remote QP the local QP can send data to is mutually informed in advance during the preparation stage through certain means. This is also the meaning of the above statement &amp;ldquo;the datagram service needs to perform this exchange process once for each destination node.&amp;rdquo;&lt;/p>
&lt;h2 id="service-type">
&lt;a href="#service-type" class="header-anchor">#&lt;/a>
Service type
&lt;/h2>
&lt;p>The two dimensions mentioned above combine in pairs to form the four basic service types of IB:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>Reliable&lt;/th>
&lt;th>Unreliable&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Connection&lt;/td>
&lt;td>RC (Reliable Connection)&lt;/td>
&lt;td>UC (Unreliable Connection)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Datagram&lt;/td>
&lt;td>RD (Reliable Datagram)&lt;/td>
&lt;td>UD (Unreliable Datagram)&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>RC and UD are the most applied and fundamental types of services, and we can analogize them to the TCP and UDP of the TCP/IP protocol stack&amp;rsquo;s transport layer, respectively.&lt;/p>
&lt;p>RC is used in scenarios with high requirements for data integrity and reliability, similar to TCP, because various mechanisms are needed to ensure reliability, so the overhead will naturally be higher. Additionally, since RC service types and each node need to maintain their own QP, assuming there are N nodes that need to communicate with each other, at least &lt;strong>N * (N - 1)&lt;/strong> QPs are required. QP and QPC themselves need to occupy network card resources or memory, and when there are many nodes, the consumption of storage resources will be very large.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/RC_Connect-2024-02-26.webp"
alt="RC_Connect-2024-02-26" width="auto" loading="lazy">
&lt;/figure>
&lt;p>UD hardware overhead is small and saves storage resources. For example, if N nodes need to communicate with each other, only &lt;strong>N&lt;/strong> QPs need to be created. However, reliability cannot be guaranteed, just like UDP. If users want to implement reliability based on the UD service type, they need to implement an application-layer reliable transmission mechanism based on the IB transport layer themselves.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/UD_Connect-2024-02-26.webp"
alt="UD_Connect-2024-02-26" width="auto" loading="lazy">
&lt;/figure>
&lt;p>In addition, there are RD and UC types, as well as more complex service types like XRC (Extended Reliable Connection) and SRD (Scalable Reliable Datagram), which we will describe in detail in the protocol analysis section.&lt;/p>
&lt;p>For more information on QP type selection, you can refer to the article &lt;a class="link" href="https://www.rdmamojo.com/2013/06/01/which-queue-pair-type-to-use/" target="_blank" rel="noopener" >Which Queue Pair type to use?
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
on RDMAmojo. Thanks to &lt;a class="link" href="https://www.zhihu.com/people/fc04fe143ad43b66fabb7050dadef923" target="_blank" rel="noopener" >@sinkinben
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
for pointing it out in the comments section.&lt;/p>
&lt;h2 id="code-example">
&lt;a href="#code-example" class="header-anchor">#&lt;/a>
Code example
&lt;/h2>
&lt;p>In RDMA programming, we can create a QP using the &lt;code>ibv_create_qp&lt;/code> function, where the &lt;code>qp_type&lt;/code> field in the &lt;code>struct ibv_qp_init_attr&lt;/code> structure is used to specify the service type of the QP. Below is a simple example code:&lt;/p>
&lt;pre>&lt;code class="language-c">struct ibv_qp_init_attr qp_init_attr;
qp_init_attr.qp_type = IBV_QPT_RC; // RC type
qp_init_attr.sq_sig_all = 1; // 1 means each WQE in SQ needs a corresponding CQE
qp_init_attr.send_cq = cq; // Send CQ
qp_init_attr.recv_cq = cq; // Receive CQ
qp_init_attr.cap.max_send_wr = 1024; // Depth of SQ
struct ibv_qp *qp = ibv_create_qp(pd, &amp;amp;qp_init_attr);
&lt;/code>&lt;/pre></description></item><item><title>RDMA Operation Types</title><link>https://cuterwrite.top/en/p/rdma-op/</link><pubDate>Sat, 24 Feb 2024 03:09:01 +0000</pubDate><guid>https://cuterwrite.top/en/p/rdma-op/</guid><description>&lt;img src="https://cloud.cuterwrite.fun/img/bcb5351691a864a6827138cf4c2e0642195413_crop-2024-02-25.webp" alt="Featured image of post RDMA Operation Types" />&lt;h1 id="rdma-operation-type">
&lt;a href="#rdma-operation-type" class="header-anchor">#&lt;/a>
RDMA operation type
&lt;/h1>
&lt;p>&lt;strong>This article welcomes non-commercial reprints, please indicate the source when reprinting.&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>Statement: For collection purposes only, for easier reading&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/142175657">&lt;cite>Zhihu Column: 4. RDMA Operation Types&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>In previous articles discussing RDMA communication processes, SEND-RECV has been mentioned frequently. However, it cannot really be called &amp;ldquo;RDMA&amp;rdquo;; it is merely an &amp;ldquo;upgraded version&amp;rdquo; of the traditional send-receive model with added zero-copy and protocol stack offloading. This type of operation does not fully leverage the entire capabilities of RDMA technology and is often used in scenarios where control information is exchanged between two ends. When it comes to sending and receiving large amounts of data, two RDMA-exclusive operations are more commonly used: WRITE and READ.&lt;/p>
&lt;p>Let&amp;rsquo;s first review the dual-end operations—SEND and RECV, and then introduce and compare the single-end operations—WRITE and READ.&lt;/p>
&lt;h2 id="send--recv">
&lt;a href="#send--recv" class="header-anchor">#&lt;/a>
SEND &amp;amp; RECV
&lt;/h2>
&lt;p>SEND and RECV are two different types of operations, but because if one end performs a SEND operation, the opposite end must perform a RECV operation, they are usually described together.&lt;/p>
&lt;p>Why is it called &amp;ldquo;dual-end operation&amp;rdquo;? Because &lt;strong>completing a communication process requires the participation of both ends&amp;rsquo; CPUs&lt;/strong>, and the receiving end needs to explicitly issue a WQE in advance. The diagram below is a schematic of a SEND-RECV operation process. The original image is from [1], and I have made some modifications.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/rdma-op-1-2024-02-25.webp"
alt="rdma-op-1-2024-02-25" width="auto" loading="lazy">
&lt;/figure>
&lt;p>In the previous section, we discussed how upper-layer applications issue tasks to hardware through WQE (WR). In SEND-RECV operations, not only does the sender need to issue WQE, but the receiver also needs to issue WQE to inform the hardware where to place the received data. The sender does not know where the sent data will be placed, so each time data is sent, the receiver must prepare the receive buffer in advance, and the receiver&amp;rsquo;s CPU will naturally be aware of this process.&lt;/p>
&lt;p>In order to compare the similarities and differences between SEND/RECV and WRITE/READ in the following text, we will supplement the memory read and write process in the SEND-RECV flow from the previous article, namely steps ④ in the diagram below — the sending-end hardware retrieves data from memory based on the WQE and encapsulates it into packets that can be transmitted on the link, and step ⑦ — the receiving-end hardware parses the packets and places the data into the specified memory area based on the WQE. Other steps will not be elaborated. Additionally, it is emphasized once again that the order of steps on the sending and receiving ends may not necessarily follow the order in the diagram. For example, the order of steps ⑧⑪⑫ and steps ⑨⑩ is not fixed.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/rdma-op-2-2024-02-25.webp"
alt="rdma-op-2-2024-02-25" width="auto" loading="lazy">
&lt;/figure>
&lt;p>The following will introduce the WRITE operation, and I believe everyone can understand it better after comparison.&lt;/p>
&lt;h2 id="write">
&lt;a href="#write" class="header-anchor">#&lt;/a>
WRITE
&lt;/h2>
&lt;p>WRITE is the full name of the RDMA WRITE operation, which is the behavior of actively writing to remote memory from the local end. Except for the preparation phase, the remote CPU does not need to participate and is not aware of when data is written or when the data reception is complete. Therefore, this is a single-end operation.&lt;/p>
&lt;p>Through the diagram below, we compare the differences between WRITE and SEND-RECV operations. In the preparation phase, this end obtains the &lt;strong>address&lt;/strong> and &amp;ldquo;&lt;strong>key&lt;/strong>&amp;rdquo; of a certain piece of available memory on the opposite end through data exchange, which is equivalent to obtaining read and write permissions for this piece of remote memory. After obtaining the permissions, this end can &lt;strong>directly read and write to this remote memory area&lt;/strong> as if accessing its own memory, which is the essence of RDMA—Remote Direct Memory Access.&lt;/p>
&lt;p>How are the destination address and key obtained in WRITE/READ operations? They can usually be obtained through the SEND-RECV operation we just discussed, because obtaining the key is ultimately allowed by the controller of the remote memory—the CPU. Although the preparation work is relatively complex, once the preparation is completed, RDMA can leverage its advantages to read and write large amounts of data. Once the remote CPU authorizes the memory for local use, it will no longer participate in the data transmission process, which frees the remote CPU and reduces communication latency.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/rdma-op-3-2024-02-25.webp"
alt="rdma-op-3-2024-02-25" width="auto" loading="lazy">
&lt;/figure>
&lt;p>It should be noted that this end reads and writes remote memory through &lt;strong>virtual addresses&lt;/strong>, making it very convenient for upper-layer applications to operate on it. The actual conversion of virtual addresses to physical addresses is performed by the RDMA network card. How this conversion is done will be introduced in subsequent articles.&lt;/p>
&lt;p>Ignoring the process of obtaining the key and addr during the preparation phase, we describe the process of a WRITE operation below. From now on, we will no longer refer to the local and remote ends as &amp;ldquo;sending&amp;rdquo; and &amp;ldquo;receiving&amp;rdquo; ends, but rather as &amp;ldquo;request&amp;rdquo; and &amp;ldquo;response&amp;rdquo; ends. This makes it more appropriate for describing both WRITE and READ operations and avoids ambiguity.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/rdma-op-4-2024-02-25.webp"
alt="rdma-op-4-2024-02-25" width="auto" loading="lazy">
&lt;/figure>
&lt;ol>
&lt;li>The requesting APP issues a WRITE task in the form of WQE (WR).&lt;/li>
&lt;li>Requesting hardware to fetch WQE from SQ and parse the information.&lt;/li>
&lt;li>The requester&amp;rsquo;s network card converts the virtual address in the WQE to obtain the physical address, then retrieves the data to be sent from memory, and assembles the data packet.&lt;/li>
&lt;li>The requesting end&amp;rsquo;s network card sends the data packet to the responding end&amp;rsquo;s network card through the physical link.&lt;/li>
&lt;li>The receiving end receives the data packet, parses the destination virtual address, converts it to a local physical address, parses the data, and places the data in the specified memory area.&lt;/li>
&lt;li>The responding end replies with an ACK message to the requesting end.&lt;/li>
&lt;li>After the network card on the requesting side receives the ACK, it generates a CQE and places it into the CQ.&lt;/li>
&lt;li>The requesting app obtains task completion information.&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>Note: Strictly speaking, at step 6 when ACK is replied, the RDMA network card can only guarantee that the Payload in the packet has been &amp;ldquo;temporarily stored,&amp;rdquo; but it cannot guarantee that the data has been placed in the destination memory. However, this does not affect our understanding of the sorting process. Thanks to @nekomii for the reminder.&lt;/p>
&lt;p>IB Spec. 9.7.5.1.6 ACKNOWLEDGE MESSAGE SCHEDULING Original text: &amp;ldquo;For SEND or RDMA WRITE requests, an ACK may be scheduled before data is actually written into the responder’s memory. The ACK simply indicates that the data has successfully reached the fault domain of the responding node. That is, the data has been received by the channel adapter and the channel adapter will write that data to the memory system of the responding node, or the responding application will at least be informed of the failure.&amp;rdquo;&lt;/p>
&lt;/blockquote>
&lt;h2 id="read">
&lt;a href="#read" class="header-anchor">#&lt;/a>
READ
&lt;/h2>
&lt;p>As the name suggests, READ and WRITE are opposite processes, with READ being the local end actively reading the remote memory. Like WRITE, the remote CPU does not need to participate and is not aware of the process of data being read from memory.&lt;/p>
&lt;p>The process of obtaining the key and virtual address is no different from WRITE. It is important to note that &lt;strong>the data requested by the &amp;ldquo;read&amp;rdquo; action&lt;/strong> is carried in the message replied by the other end.&lt;/p>
&lt;p>The following describes the process of a READ operation, note that it only differs from WRITE in direction and order of steps.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/rdma5-2024-02-25.webp"
alt="rdma5-2024-02-25" width="auto" loading="lazy">
&lt;/figure>
&lt;ol>
&lt;li>The requesting end APP issues a READ task in the form of WQE.&lt;/li>
&lt;li>The requesting network card retrieves the WQE from the SQ and parses the information.&lt;/li>
&lt;li>The requesting network card sends the READ request packet to the responding network card through the physical link.&lt;/li>
&lt;li>The receiving end receives the data packet, parses the destination virtual address, converts it into a local physical address, parses the data, and retrieves the data from the specified memory area.&lt;/li>
&lt;li>The receiving end hardware assembles the data into a reply packet and sends it to the physical link.&lt;/li>
&lt;li>The requesting hardware receives the data packet, parses and extracts the data, and then places it in the memory area specified by the READ WQE.&lt;/li>
&lt;li>The requester&amp;rsquo;s network card generates a CQE and places it in the CQ.&lt;/li>
&lt;li>The requesting APP obtains task completion information.&lt;/li>
&lt;/ol>
&lt;h2 id="summary">
&lt;a href="#summary" class="header-anchor">#&lt;/a>
Summary
&lt;/h2>
&lt;p>We abstract by ignoring various details, and RDMA WRITE and READ operations are simply utilizing the network card to complete the memory copy operation shown in the left diagram below. The copying process is completed by the RDMA network card through the network link; whereas local memory copying, as shown in the right diagram below, is completed by the CPU through the bus:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/rdma-op-6-2024-02-25.webp"
alt="rdma-op-6-2024-02-25" width="auto" loading="lazy">
&lt;/figure>
&lt;p>The words used in the RDMA standard to define the aforementioned operations are very appropriate, &amp;ldquo;receive&amp;rdquo; and &amp;ldquo;send&amp;rdquo; have the semantics of requiring active participation from the peer, while &amp;ldquo;read&amp;rdquo; and &amp;ldquo;write&amp;rdquo; are more like the semantics of the local end operating on a passive peer.&lt;/p>
&lt;p>By comparing SEND/RECV and WRITE/READ operations, we can find that WRITE/READ, which does not require the responding end&amp;rsquo;s CPU involvement during data transmission, has greater advantages. The drawback is that the requesting end needs to obtain read and write permissions for a section of memory on the responding end during the preparation phase. However, during actual data transmission, the power and time consumption of this preparation phase can be negligible. Therefore, RDMA WRITE/READ is the type of operation used for large data transfers, while SEND/RECV is usually used to transmit some control information.&lt;/p>
&lt;p>In addition to the types of operations introduced in this article, there are more complex types of operations such as ATOMIC, which will be analyzed in detail in the protocol interpretation section later. This concludes this article, and the next one will introduce the basic service types of RDMA.&lt;/p>
&lt;h2 id="code-example">
&lt;a href="#code-example" class="header-anchor">#&lt;/a>
Code example
&lt;/h2>
&lt;p>The operation types in this text are all issued through WQE. Below is a simple example demonstrating how to use libibverbs to create a QP and then issue a WRITE operation through WQE.&lt;/p>
&lt;pre>&lt;code class="language-c">#include &amp;lt;infiniband/verbs.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
int main() {
struct ibv_device **dev_list = ibv_get_device_list(NULL);
struct ibv_context *ctx = ibv_open_device(dev_list[0]);
struct ibv_pd *pd = ibv_alloc_pd(ctx);
struct ibv_cq *cq = ibv_create_cq(ctx, 10, NULL, NULL, 0);
struct ibv_qp *qp;
struct ibv_qp_init_attr qp_init_attr = {
.send_cq = cq,
.recv_cq = cq,
.qp_type = IBV_QPT_RC,
};
qp = ibv_create_qp(pd, &amp;amp;qp_init_attr);
struct ibv_mr *mr;
char *buf = malloc(1024);
mr = ibv_reg_mr(pd, buf, 1024, IBV_ACCESS_LOCAL_WRITE | IBV_ACCESS_REMOTE_WRITE);
struct ibv_sge sge = {
.addr = (uintptr_t)buf,
.length = 1024,
.lkey = mr-&amp;gt;lkey,
};
struct ibv_send_wr wr = {
.wr_id = 1,
.sg_list = &amp;amp;sge,
.num_sge = 1,
.opcode = IBV_WR_RDMA_WRITE,
.send_flags = IBV_SEND_SIGNALED,
};
struct ibv_send_wr *bad_wr;
ibv_post_send(qp, &amp;amp;wr, &amp;amp;bad_wr);
return 0;
}
&lt;/code>&lt;/pre>
&lt;h2 id="references">
&lt;a href="#references" class="header-anchor">#&lt;/a>
References
&lt;/h2>
&lt;p>[1] part1-OFA_Training_Sept_2016.pdf&lt;/p></description></item><item><title>RDMA Basic Elements</title><link>https://cuterwrite.top/en/p/rdma-element/</link><pubDate>Fri, 02 Feb 2024 01:01:01 +0000</pubDate><guid>https://cuterwrite.top/en/p/rdma-element/</guid><description>&lt;img src="https://cloud.cuterwrite.fun/img/73c30b990886bf6988c97858a3e16011195413_crop-2024-02-04.webp" alt="Featured image of post RDMA Basic Elements" />&lt;h1 id="rdma-basic-elements">
&lt;a href="#rdma-basic-elements" class="header-anchor">#&lt;/a>
RDMA Basic Elements
&lt;/h1>
&lt;p>&lt;strong>This article welcomes non-commercial reprints, please indicate the source.&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>Statement: For collection only, for easy reading&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/141267386">&lt;cite>Zhihu Column: 3. Basic Elements of RDMA&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>In RDMA technology, abbreviations are often used, which can easily confuse newcomers. The purpose of this article is to explain the most basic elements in RDMA and their meanings.&lt;/p>
&lt;p>I will write a table of common abbreviations at the front, so if you forget while reading, you can refer to it at the front.&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/v2-b6723caa5b291ee161d94fd8fd8ce09c_720w-2024-02-03.webp"
alt="v2-b6723caa5b291ee161d94fd8fd8ce09c_720w-2024-02-03" width="auto" loading="lazy">
&lt;/figure>
&lt;h2 id="wq">
&lt;a href="#wq" class="header-anchor">#&lt;/a>
WQ
&lt;/h2>
&lt;p>Work Queue, abbreviated as WQ, is one of the most important concepts in RDMA technology. WQ is a queue that stores work requests. To clearly explain what WQ is, we first introduce the elements in this queue, WQE (Work Queue Element).&lt;/p>
&lt;h3 id="wqe">
&lt;a href="#wqe" class="header-anchor">#&lt;/a>
WQE
&lt;/h3>
&lt;p>WQE can be considered a &amp;ldquo;task description,&amp;rdquo; which is a work request issued by software to hardware. This description contains the tasks that the software hopes the hardware will perform, as well as detailed information about the task. For example, a task might be like this: &amp;ldquo;I want to send data located at address 0x12345678 with a length of 10 bytes to the opposite node.&amp;rdquo; After receiving the task, the hardware will use DMA to fetch the data from memory, assemble the data packet, and then send it.&lt;/p>
&lt;p>The meaning of WQE should be quite clear, so what is the WQ we mentioned at the beginning? It is the &amp;ldquo;folder&amp;rdquo; used to store &amp;ldquo;task documents,&amp;rdquo; and the WQ can contain many WQEs. Readers with a basic understanding of data structures should know that a queue is a first-in-first-out data structure, which is very common in computer systems. We can use the diagram below to represent the relationship between WQ and WQE described above:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/v2-40c7e57f2760323c6b6665306e8f8896_720w-2024-02-03.webp"
alt="v2-40c7e57f2760323c6b6665306e8f8896_720w-2024-02-03" width="auto" loading="lazy">
&lt;/figure>
&lt;p>WQ This queue is always added to by the software with WQE (enqueue), and the hardware extracts WQE from it, which is the process of the software &amp;ldquo;issuing tasks&amp;rdquo; to the hardware. Why use a queue instead of a stack? Because the &amp;ldquo;store&amp;rdquo; and &amp;ldquo;retrieve&amp;rdquo; operations are performed separately by software and hardware, and it is necessary to ensure that user requests are processed in order. In RDMA technology, all communication requests must be notified to the hardware in the manner shown in the above diagram, which is often referred to as &amp;ldquo;Post&amp;rdquo;.&lt;/p>
&lt;h3 id="qp">
&lt;a href="#qp" class="header-anchor">#&lt;/a>
QP
&lt;/h3>
&lt;p>Queue Pair, abbreviated as QP, means &amp;ldquo;a pair&amp;rdquo; of WQ.&lt;/p>
&lt;h3 id="sq-and-rq">
&lt;a href="#sq-and-rq" class="header-anchor">#&lt;/a>
SQ and RQ
&lt;/h3>
&lt;p>Any communication process must have both sending and receiving ends. A QP is a combination of a send work queue and a receive work queue, which are referred to as the SQ (Send Queue) and RQ (Receive Queue) respectively. Let&amp;rsquo;s enrich the diagram above; the left side is the sending end, and the right side is the receiving end:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/v2-b89b321b8d1ae5ab6dcbaf8d6085f107_720w-2024-02-03.webp"
alt="v2-b89b321b8d1ae5ab6dcbaf8d6085f107_720w-2024-02-03" width="auto" loading="lazy">
&lt;/figure>
&lt;p>Why is WQ missing? SQ and RQ are both WQ, WQ just represents a unit that can store WQE, SQ and RQ are the instances.&lt;/p>
&lt;p>SQ is specifically used to store send tasks, and RQ is specifically used to store receive tasks. In a SEND-RECV process, the sender needs to place a WQE representing a send task into the SQ. Similarly, the receiver software needs to issue a WQE representing a receive task to the hardware so that the hardware knows where to place the received data in memory. The Post operation we mentioned earlier is called Post Send for SQ and Post Receive for RQ.&lt;/p>
&lt;p>It should be noted that in RDMA technology, &lt;strong>the basic unit of communication is QP&lt;/strong>, not the node. As shown in the figure below, for each node, each process can use several QPs, and each local QP can be &amp;ldquo;associated&amp;rdquo; with a remote QP. Saying &amp;ldquo;Node A sends data to Node B&amp;rdquo; is not sufficient to fully describe an RDMA communication; it should be more like &amp;ldquo;QP3 on Node A sends data to QP4 on Node C.&amp;rdquo;&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/v2-71b3b17ef8aec45d74ef9e4a42a69201_720w-2024-02-03.webp"
alt="v2-71b3b17ef8aec45d74ef9e4a42a69201_720w-2024-02-03" width="auto" loading="lazy">
&lt;/figure>
&lt;p>Each QP of every node has a unique number, called QPN (Queue Pair Number), which can uniquely identify a QP on a node.&lt;/p>
&lt;h3 id="srq">
&lt;a href="#srq" class="header-anchor">#&lt;/a>
SRQ
&lt;/h3>
&lt;p>Shared Receive Queue, abbreviated as SRQ, means a shared receive queue. The concept is easy to understand; it refers to a situation where several QPs share the same RQ, which we call SRQ. We will later learn that the use of RQ is far less than the use of SQ, and each queue consumes memory resources. When we need to use a large number of QPs, we can save memory through SRQ. As shown in the figure below, QP2~QP4 use the same RQ together:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/v2-4a21f2b1333877b4b0d97a1ca91d4096_720w-2024-02-03.webp"
alt="v2-4a21f2b1333877b4b0d97a1ca91d4096_720w-2024-02-03" width="auto" loading="lazy">
&lt;/figure>
&lt;h2 id="cq">
&lt;a href="#cq" class="header-anchor">#&lt;/a>
CQ
&lt;/h2>
&lt;p>Completion Queue, abbreviated as CQ, means completion queue. Similar to WQ, we first introduce the elements in the CQ queue — CQE (Completion Queue Element). CQE can be considered the opposite concept of WQE. If WQE is the &amp;ldquo;task list&amp;rdquo; issued by software to hardware, then CQE is the &amp;ldquo;task report&amp;rdquo; returned by hardware to software after completing the task. CQE describes whether a task was executed correctly or if an error was encountered, and if so, what the cause of the error was.&lt;/p>
&lt;p>And CQ is the container that carries CQE—a first-in-first-out queue. If we invert the diagram representing the relationship between WQ and WQE, we get the relationship between CQ and CQE:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/v2-31f9a407ab66381fbc557d8acc5573cb_720w-2024-02-03.webp"
alt="v2-31f9a407ab66381fbc557d8acc5573cb_720w-2024-02-03" width="auto" loading="lazy">
&lt;/figure>
&lt;p>Each CQE contains completion information for a certain WQE, and their relationship is shown in the diagram below:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/v2-701fa8eacb10c90c45b0241c75254a01_720w-2024-02-03.webp"
alt="v2-701fa8eacb10c90c45b0241c75254a01_720w-2024-02-03" width="auto" loading="lazy">
&lt;/figure>
&lt;p>Below, we put CQ and WQ (QP) together to see the interaction between software and hardware in a single SEND-RECV operation (the order of numbers in the diagram does not represent the actual sequence):&lt;/p>
&lt;blockquote>
&lt;p>2022/5/23: The order of the diagram and the subsequent list has been modified. The original item 2 &amp;ldquo;The receiving end hardware takes the task book from the RQ and prepares to receive data&amp;rdquo; has been moved to after &amp;ldquo;The receiving end receives data, verifies it, and then sends an ACK message back to the sender,&amp;rdquo; and the description has been modified. It is now item 6.&lt;/p>
&lt;p>The mistake I made here is that RQ and SQ are different; RQ is a &amp;ldquo;passive reception&amp;rdquo; process, and the hardware only consumes RQ WQE when it receives a Send packet (or a Write packet with an immediate value). Thanks to @连接改变世界 for the correction.&lt;/p>
&lt;/blockquote>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/v2-a8d38721903672037b27cc7e49ecee03_720w-2024-02-03.webp"
alt="v2-a8d38721903672037b27cc7e49ecee03_720w-2024-02-03" width="auto" loading="lazy">
&lt;/figure>
&lt;ol>
&lt;li>The receiving end APP issues a RECV task to the RQ in the form of WQE.&lt;/li>
&lt;li>The sending-end APP issues a SEND task to the SQ in the form of a WQE.&lt;/li>
&lt;li>The sending-end hardware retrieves the task list from the SQ, obtains the data to be sent from memory, and assembles the data packet.&lt;/li>
&lt;li>The sender&amp;rsquo;s network card sends the data packet to the receiver&amp;rsquo;s network card through the physical link.&lt;/li>
&lt;li>After the receiving end receives the data and verifies it, it sends an ACK message back to the sending end.&lt;/li>
&lt;li>The receiving-end hardware takes a work queue entry (WQE) from the RQ.&lt;/li>
&lt;li>The receiving end hardware places the data in the location specified by the WQE, then generates a &amp;ldquo;task report&amp;rdquo; CQE, and places it in the CQ.&lt;/li>
&lt;li>The receiving end APP obtains task completion information.&lt;/li>
&lt;li>After the network card at the sending end receives the ACK, it generates a CQE and places it into the CQ.&lt;/li>
&lt;li>The sending-end APP obtains task completion information.&lt;/li>
&lt;/ol>
&lt;blockquote class="alert-blockquote alert-note">
&lt;p class="alert-heading">
&lt;svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16">
&lt;path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z">&lt;/path>
&lt;/svg>
&lt;span>Note&lt;/span>
&lt;/p>
&lt;p>NOTE: One important point to note is that the example in the above diagram is the interaction flow of a reliable service type. If it is an unreliable service, there will be no ACK reply in step 5, and step 9 and subsequent steps will be triggered immediately after step 5. We will explain service types and the difference between reliable and unreliable in the article &amp;ldquo;Basic RDMA Service Types.&amp;rdquo;&lt;/p>
&lt;/blockquote>
&lt;p>At this point, through the two media, WQ and CQ, both ends of the software and hardware have jointly completed a transmission and reception process.&lt;/p>
&lt;h2 id="wr-and-wc">
&lt;a href="#wr-and-wc" class="header-anchor">#&lt;/a>
WR and WC
&lt;/h2>
&lt;p>After discussing several Queues, there are actually two concepts mentioned at the beginning of the article that have not been explained, namely WR and WC (not the abbreviation for Water Closet).&lt;/p>
&lt;p>WR stands for Work Request; WC stands for Work Completion. These two are actually &amp;ldquo;mappings&amp;rdquo; of WQE and CQE at the user level. Since the APP completes RDMA communication by calling the protocol stack interface, WQE and CQE themselves are not visible to the user and are concepts within the driver. What the user actually submits through the API is WR, and what is received is WC.&lt;/p>
&lt;p>WR/WC and WQE/CQE are the same concepts at different levels of entities, both being &amp;ldquo;task book&amp;rdquo; and &amp;ldquo;task report&amp;rdquo;. Therefore, we have added some content to the two diagrams mentioned earlier:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/v2-00b87c111a8e1701f96fbfb78e078b29_720w-2024-02-03.webp"
alt="v2-00b87c111a8e1701f96fbfb78e078b29_720w-2024-02-03" width="auto" loading="lazy">
&lt;/figure>
&lt;h2 id="code-example">
&lt;a href="#code-example" class="header-anchor">#&lt;/a>
Code example
&lt;/h2>
&lt;p>Finally, below is a simple example demonstrating how to use libibverbs to create a QP and then send data through this QP. This is a very simple example, just to give readers an intuitive understanding of the concepts mentioned above.&lt;/p>
&lt;pre>&lt;code class="language-c">#include &amp;lt;infiniband/verbs.h&amp;gt;
int main() {
struct ibv_context *ctx;
struct ibv_pd *pd;
struct ibv_cq *cq;
struct ibv_qp *qp;
struct ibv_mr *mr;
struct ibv_sge sge;
struct ibv_send_wr wr;
struct ibv_send_wr *bad_wr;
struct ibv_wc wc;
ctx = ibv_open_device();
pd = ibv_alloc_pd(ctx);
cq = ibv_create_cq(ctx, 100, NULL, NULL, 0);
qp = ibv_create_qp(pd, NULL, NULL);
mr = ibv_reg_mr(pd, buf, size, IBV_ACCESS_LOCAL_WRITE | IBV_ACCESS_REMOTE_WRITE);
sge.addr = (uintptr_t)buf;
sge.length = size;
sge.lkey = mr-&amp;gt;lkey;
wr.wr_id = 1;
wr.sg_list = &amp;amp;sge;
wr.num_sge = 1;
wr.opcode = IBV_WR_SEND;
wr.send_flags = IBV_SEND_SIGNALED;
wr.next = NULL;
ibv_post_send(qp, &amp;amp;wr, &amp;amp;bad_wr);
ibv_poll_cq(cq, 1, &amp;amp;wc);
return 0;
}
&lt;/code>&lt;/pre>
&lt;h2 id="summary">
&lt;a href="#summary" class="header-anchor">#&lt;/a>
Summary
&lt;/h2>
&lt;p>Alright, let&amp;rsquo;s use Figure 11 from section 3.2.1 of the IB protocol[1] to summarize the content of this article:&lt;/p>
&lt;figure>&lt;img src="https://cloud.cuterwrite.fun/img/v2-2107a9bf8230c45ad73aa5ff0b8626ff_720w-2024-02-03.webp"
alt="v2-2107a9bf8230c45ad73aa5ff0b8626ff_720w-2024-02-03" width="auto" loading="lazy">
&lt;/figure>
&lt;p>The user-mode WR is converted by the driver into a WQE and filled into the WQ. The WQ can be an SQ responsible for sending or an RQ responsible for receiving. The hardware will take out the WQE from each WQ and complete the sending or receiving task according to the requirements in the WQE. After the task is completed, a CQE will be generated for this task and filled into the CQ. The driver will take out the CQE from the CQ and convert it into a WC to return to the user.&lt;/p>
&lt;p>The introduction to the basic concepts ends here. The next article will introduce several common types of RDMA operations.&lt;/p>
&lt;h2 id="references">
&lt;a href="#references" class="header-anchor">#&lt;/a>
References
&lt;/h2>
&lt;p>[1] &amp;ldquo;IB Specification Vol 1-Release-1.3-2015-03-03&amp;rdquo;&lt;/p></description></item></channel></rss>