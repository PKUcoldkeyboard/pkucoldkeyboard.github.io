<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="Pure is a new programming model and runtime system designed to fully leverage shared memory within nodes in environments based on the Message Passing Interface (enhancing the utilization of idle core capabilities through tasks). Pure utilizes shared memory in two ways: (1) allowing ranks to steal work from each other while waiting for messages to arrive; (2) enabling high-performance message passing and collective operations between processes within a node using efficient lock-free data structures. Researchers evaluated the key message passing and collective features of Pure through micro benchmark tests and demonstrated that in CoMD molecular dynamics and miniAMR adaptive mesh refinement applications, Pure can achieve up to 2.1x application acceleration when scaling to 4096 ranks."><title>Notes: Pure - Improving Message Passing to Better Utilize Intra-Node Shared Memory</title>
<link rel=canonical href=https://cuterwrite.top/en/p/pure/><link rel=stylesheet href=/scss/style.min.9e9a820f30d9af5db6f416de7ab0f7a731a8bcab6669edcbd5a489a07906aa5d.css><meta property='og:title' content="Notes: Pure - Improving Message Passing to Better Utilize Intra-Node Shared Memory"><meta property='og:description' content="Pure is a new programming model and runtime system designed to fully leverage shared memory within nodes in environments based on the Message Passing Interface (enhancing the utilization of idle core capabilities through tasks). Pure utilizes shared memory in two ways: (1) allowing ranks to steal work from each other while waiting for messages to arrive; (2) enabling high-performance message passing and collective operations between processes within a node using efficient lock-free data structures. Researchers evaluated the key message passing and collective features of Pure through micro benchmark tests and demonstrated that in CoMD molecular dynamics and miniAMR adaptive mesh refinement applications, Pure can achieve up to 2.1x application acceleration when scaling to 4096 ranks."><meta property='og:url' content='https://cuterwrite.top/en/p/pure/'><meta property='og:site_name' content="Cuterwrite's Blog"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:published_time' content='2024-03-03T01:16:00+00:00'><meta property='article:modified_time' content='2024-03-03T01:16:00+00:00'><meta property='og:image' content='https://cuterwrite-1302252842.file.myqcloud.com/img/crop_e9af4c445d695be5002248c7c814c67d195413-2024-03-04.webp'><meta name=twitter:title content="Notes: Pure - Improving Message Passing to Better Utilize Intra-Node Shared Memory"><meta name=twitter:description content="Pure is a new programming model and runtime system designed to fully leverage shared memory within nodes in environments based on the Message Passing Interface (enhancing the utilization of idle core capabilities through tasks). Pure utilizes shared memory in two ways: (1) allowing ranks to steal work from each other while waiting for messages to arrive; (2) enabling high-performance message passing and collective operations between processes within a node using efficient lock-free data structures. Researchers evaluated the key message passing and collective features of Pure through micro benchmark tests and demonstrated that in CoMD molecular dynamics and miniAMR adaptive mesh refinement applications, Pure can achieve up to 2.1x application acceleration when scaling to 4096 ranks."><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://cuterwrite-1302252842.file.myqcloud.com/img/crop_e9af4c445d695be5002248c7c814c67d195413-2024-03-04.webp'><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><script async src=https://analytics.cuterwrite.top/uma.js data-website-id=b13594a2-4d15-4a4e-a020-5e3cc1d88c12 data-domains=cuterwrite.top></script><link rel=manifest href=/manifest.json></head><body class="article-page
line-numbers"><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/en/><img src=/img/avatar_hue4d14694a57c01a222a16c47db12c89c_369633_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>😉</span></figure><div class=site-meta><h1 class=site-name><a href=/en>Cuterwrite's Blog</a></h1><h2 class=site-description>Cuterwrite's tech blog, focusing on in-depth exploration and experience sharing in areas such as high-performance computing, operating systems, full-stack development, and artificial intelligence.</h2></div></header><ol class=menu-social><li><a href=https://analytics.cuterwrite.top/share/Ji0gm9OaLDk8gco7 target=_blank title=Analytics rel=me><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 5H7A2 2 0 005 7v12a2 2 0 002 2h10a2 2 0 002-2V7a2 2 0 00-2-2h-2"/><rect x="9" y="3" width="6" height="4" rx="2"/><path d="M9 17v-5"/><path d="M12 17v-1"/><path d="M15 17v-3"/></svg></a></li><li><a href=https://stats.uptimerobot.com/6NVhRHkSAQ target=_blank title=Uptime rel=me><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-chart-line"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 19h16"/><path d="M4 15l4-6 4 2 4-5 4 4"/></svg></a></li><li><a href=/index.xml target=_blank title=RSS rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-rss" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="5" cy="19" r="1"/><path d="M4 4a16 16 0 0116 16"/><path d="M4 11a9 9 0 019 9"/></svg></a></li><li><a href=https://github.com/PKUcoldkeyboard target=_blank title=GitHub rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://www.zhihu.com/people/kong-tiao-cheng-tai-lang-30-57 target=_blank title=zhihu rel=me><svg t="1705591931290" class="icon" viewBox="0 0 1280 1024" xmlns="http://www.w3.org/2000/svg" p-id="21048" width="32" height="32"><path d="M341.08 296.26v435.08l46.86.02 15.42 52.74 84.02-52.74h99.06V296.26H341.08zm195.5 387.86H480.7l-55.8 35.02-10.16-34.94-23.8-.08V343.5h145.64v340.62zM299.66 495.34H195c3.48-54.2 4.4-103.18 4.4-146.92h102.32s3.94-45.12-17.16-44.62h-177c6.98-26.24 15.74-53.32 26.24-81.34.0.0-48.14.0-64.54 43.14-6.78 17.8-26.42 86.28-61.4 156.24 11.78-1.28 50.74-2.36 73.68-44.42 4.22-11.78 5.02-13.32 10.28-29.06h57.74c0 21-2.4 133.76-3.36 146.88H41.66c-23.48.0-31.12 47.24-31.12 47.24H141.7C132.9 642.2 85.66 726.24.0 792.68c40.98 11.7 81.82-1.86 102-19.8.0.0 45.96-41.8 71.18-138.5L281.1 764.26s15.82-53.78-2.48-79.98c-15.16-17.84-56.12-66.12-73.58-83.62L175.8 623.9c8.72-27.96 13.98-55.1 15.74-81.34h123.3s-.18-47.24-15.18-47.24v.02zm824.04-3.2c41.66-51.28 89.96-117.14 89.96-117.14s-37.3-29.6-54.76-8.12c-12 16.3-73.66 96.4-73.66 96.4l38.46 28.86zM823.52 373.96c-18.02-16.5-51.82 4.26-51.82 4.26s79.04 110.08 82.24 114.9l38.92-27.46s-51.34-75.22-69.32-91.72h-.02zM1280 516.7c-39.56.0-261.82 1.86-262.12 1.86v-202c9.62.0 24.84-.8 45.7-2.4 81.76-4.82 140.26-8 175.54-9.62.0.0 24.44-54.38-1.18-66.88-6.14-2.36-46.34 9.16-46.34 9.16s-330.44 32.98-464.72 36.1c3.2 17.64 15.24 34.16 31.56 39.1 26.62 6.96 45.38 3.4 98.3 1.78 49.66-3.2 87.36-4.86 113.02-4.86v199.62H702.82s5.64 44.62 51.02 45.7h215.88V706.1c0 27.94-22.38 43.98-48.96 42.24-28.16.22-52.16-2.3-83.38-3.62 3.98 7.94 12.66 28.78 38.62 43.68 19.76 9.62 32.34 13.14 52.04 13.14 59.12.0 91.34-34.56 89.78-90.62V564.28h244.72c19.36.0 17.4-47.56 17.4-47.56l.06-.02z" fill="#707070" p-id="21049"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/en/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>主页 | Home</span></a></li><li><a href=/en/about/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>关于 | About</span></a></li><li><a href=/en/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>归档 | Archives</span></a></li><li><a href=/en/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>搜索 | Search</span></a></li><li><a href=https://cuterwrite.top/image-hosting target=_blank><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-album"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 4m0 2a2 2 0 012-2h12a2 2 0 012 2v12a2 2 0 01-2 2H6a2 2 0 01-2-2z"/><path d="M12 4v7l2-2 2 2V4"/></svg>
<span>图册 | Gallery</span></a></li><li><a href=https://draw.cuterwrite.top target=_blank><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-artboard"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M8 8m0 1a1 1 0 011-1h6a1 1 0 011 1v6a1 1 0 01-1 1H9a1 1 0 01-1-1z"/><path d="M3 8h1"/><path d="M3 16h1"/><path d="M8 3v1"/><path d="M16 3v1"/><path d="M20 8h1"/><path d="M20 16h1"/><path d="M8 20v1"/><path d="M16 20v1"/></svg>
<span>画板 | Canvas</span></a></li><li><a href=https://it-tools.tech target=_blank><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-tools"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M3 21h4L20 8a1.5 1.5.0 00-4-4L3 17v4"/><path d="M14.5 5.5l4 4"/><path d="M12 8 7 3 3 7l5 5"/><path d="M7 8 5.5 9.5"/><path d="M16 12l5 5-4 4-5-5"/><path d="M16 17l-1.5 1.5"/></svg>
<span>工具 | Tools</span></a></li><li class=menu-bottom-section><ol class=menu><li id=i18n-switch><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg>
<select name=language title=language onchange="window.location.href=this.selectedOptions[0].value"><option value=https://cuterwrite.top/>中文</option><option value=https://cuterwrite.top/en/ selected>English</option></select></li><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ul><li><a href=#citation>Citation</a></li><li><a href=#keywords>Keywords</a></li><li><a href=#summary>Summary</a></li><li><a href=#1-introduction>1. Introduction</a></li><li><a href=#2-pure-usage-example>2. Pure Usage Example</a></li><li><a href=#3-programming-model>3. Programming Model</a><ul><li><a href=#message-passing-and-collective-communication-operations>Message passing and collective communication operations</a></li><li><a href=#pure-task>Pure Task</a></li></ul></li><li><a href=#4-runtime-system>4. Runtime System</a><ul><li><a href=#rank-initialization-and-mapping>Rank initialization and mapping</a></li><li><a href=#spin-steal-waiting-loop-ssw-loop>Spin-Steal Waiting Loop (SSW-Loop)</a></li><li><a href=#implementation-instructions>Implementation Instructions</a></li><li><a href=#point-to-point-communication>Point-to-point communication</a></li><li><a href=#collective-communication>Collective communication</a></li><li><a href=#task-scheduler>Task Scheduler</a></li></ul></li><li><a href=#evaluation>Evaluation</a><ul><li><a href=#nas-dt-benchmark-results>NAS DT benchmark results</a></li><li><a href=#comd-and-miniamr-benchmarks>CoMD and miniAMR benchmarks</a></li><li><a href=#collective-communication-performance>Collective communication performance</a></li></ul></li><li><a href=#related-work>Related work</a></li><li><a href=#summary-1>Summary</a></li></ul></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/en/p/pure/><img src=https://cuterwrite-1302252842.file.myqcloud.com/img/crop_e9af4c445d695be5002248c7c814c67d195413-2024-03-04.webp loading=lazy alt="Featured image of post Notes: Pure - Improving Message Passing to Better Utilize Intra-Node Shared Memory"></a></div><div class=article-details><header class=article-category><a href=/en/categories/research/ style=background-color:#acb6d2;color:#fff>Research Related</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/en/p/pure/>Notes: Pure - Improving Message Passing to Better Utilize Intra-Node Shared Memory</a></h2><h3 class=article-subtitle>Pure is a new programming model and runtime system designed to fully leverage shared memory within nodes in environments based on the Message Passing Interface (enhancing the utilization of idle core capabilities through tasks). Pure utilizes shared memory in two ways: (1) allowing ranks to steal work from each other while waiting for messages to arrive; (2) enabling high-performance message passing and collective operations between processes within a node using efficient lock-free data structures. Researchers evaluated the key message passing and collective features of Pure through micro benchmark tests and demonstrated that in CoMD molecular dynamics and miniAMR adaptive mesh refinement applications, Pure can achieve up to 2.1x application acceleration when scaling to 4096 ranks.</h3></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>2024-03-03</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>11 minute read</time></div><div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-keyboard"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M2 6m0 2a2 2 0 012-2h16a2 2 0 012 2v8a2 2 0 01-2 2H4a2 2 0 01-2-2z"/><path d="M6 10v.01"/><path d="M10 10v.01"/><path d="M14 10v.01"/><path d="M18 10v.01"/><path d="M6 14v.01"/><path d="M18 14v.01"/><path d="M10 14l4 .01"/></svg>
<time class=article-time--wordcount>5325 words</time></div></footer><footer class=article-translations><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg><div><a href=https://cuterwrite.top/p/pure/ class=link>中文</a></div></footer></div></header><section class=article-content><h1 id=note-pure-improve-message-passing-to-better-utilize-shared-memory-within-nodes><a href=#note-pure-improve-message-passing-to-better-utilize-shared-memory-within-nodes class=header-anchor>#</a>
Note: Pure: Improve message passing to better utilize shared memory within nodes</h1><h2 id=citation><a href=#citation class=header-anchor>#</a>
Citation</h2><p>James Psota and Armando Solar-Lezama. 2024. Pure: Evolving Message Passing To Better Leverage Shared Memory Within Nodes. In Proceedings of the 29th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming (<strong>PPoPP &lsquo;24</strong>). Association for Computing Machinery, New York, NY, USA, 133–146. <a class=link href=https://doi.org/10.1145/3627535.3638503 target=_blank rel=noopener>https://doi.org/10.1145/3627535.3638503
<span style=white-space:nowrap><svg width=".8em" height=".8em" viewBox="0 0 21 21" xmlns="http://www.w3.org/2000/svg"><path d="m13 3 3.293 3.293-7 7 1.414 1.414 7-7L21 11V3z" fill="currentcolor"/><path d="M19 19H5V5h7l-2-2H5c-1.103.0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103.0 2-.897 2-2v-5l-2-2v7z" fill="currentcolor"/></span></a></p><h2 id=keywords><a href=#keywords class=header-anchor>#</a>
Keywords</h2><ul><li>Parallel programming model</li><li>Distributed runtime system</li><li>Task-based parallel model</li><li>Concurrent data structures</li><li>Lock-free data structure</li></ul><h2 id=summary><a href=#summary class=header-anchor>#</a>
Summary</h2><p>Pure is a new programming model and runtime system designed to fully utilize shared memory within nodes in environments based on the Message Passing Interface (enhancing task usage to leverage idle core capabilities). Pure leverages shared memory in two ways: (1) allowing ranks to steal work from each other while waiting for messages to arrive; (2) using efficient lock-free data structures to achieve high-performance message passing and collective operations among processes within a node. Researchers evaluated Pure&rsquo;s key message passing and collective features through micro benchmark tests and demonstrated that in CoMD molecular dynamics and miniAMR adaptive mesh refinement applications, Pure can achieve up to <strong>2.1x</strong> application speedup when scaling to 4096 ranks.</p><h2 id=1-introduction><a href=#1-introduction class=header-anchor>#</a>
1. Introduction</h2><p>In recent decades, the field of high-performance computing has transitioned from large vector computers to clusters composed of single processors interconnected through networks. MPI has become the de facto standard for parallel programming on distributed memory systems. With advancements in hardware, the emergence of multi-core clusters has allowed cores within nodes to share memory and communicate over networks, prompting the community to continually seek new paradigms to more efficiently utilize modern cluster resources. Currently, there are two main strategies: one is to maintain a unified MPI programming approach by improving the MPI runtime system to better utilize shared memory; the other is to adopt hybrid programming models like MPI+X, using shared memory parallelism within nodes while continuing to use MPI between nodes. <strong>However, these approaches may either be limited by the MPI standard&rsquo;s specifications on interface behavior, preventing performance maximization, or present challenges to programmers in managing two programming models.</strong></p><p>The community has tried many other methods, including the <strong>PGAS</strong> model, which provides a shared memory abstraction across clusters, and implicitly parallel programming languages like <strong>Legion</strong>, <strong>Chapel</strong>, and <strong>X10</strong>, which offer high-level abstractions and attempt to automatically and efficiently coordinate applications. Despite some progress, many modern HPC applications still rely on MPI. <strong>MPC</strong> and <strong>AMPI</strong> also attempt to improve performance by using threads as MPI Rank to leverage internal shared memory.</p><p>However, using only MPI methods often performs better than hybrid programming methods. This may be due to the limitations of the interface and the inability to fully utilize shared memory within nodes, causing MPI to fail to fully realize its potential performance. Therefore, the Pure system proposed in this article is built based on the MPI-everywhere method, breaking some traditional assumptions of MPI, more effectively utilizing shared memory, while avoiding the need for major restructuring of existing programs. Pure adopts a programming model similar to MPI, thus enabling the use of the existing MPI knowledge and application base of the HPC community.</p><p>The design inspiration for Pure comes from MPI, with its core programming model based on message passing, and optionally integrating task parallelism. Unlike MPI, Pure abandons the use of process-level ranks and the limitation of supporting legacy languages, opting instead to implement ranks using threads rather than traditional processes. This shift allows Pure to efficiently adopt lightweight lock-free synchronization mechanisms to coordinate between threads within the same node. Utilizing this threaded rank architecture, Pure constructs efficient intra-node collective operations and optimizes the performance of these operations through lock-free algorithms. Additionally, Pure supports running portions of parallel code blocks in the application as standard C++ lambda expressions, which can be executed automatically and concurrently by the current rank-holding thread as well as other idle ranks, all of which are automatically scheduled by the Pure Runtime system.</p><p>The optimization strategies proposed in the paper cover the following points:</p><ul><li>A lock-free messaging method suitable for the transmission of small messages and large data messages.</li><li>Lock-free data structure, used for efficient implementation of collective communication algorithms.</li><li>A lock-free task scheduler that allows idle threads to efficiently &ldquo;steal&rdquo; workloads from other threads.</li></ul><p>The author uses the standard C++ library to ensure the wide compatibility of Pure and demonstrates that Pure has a significant performance improvement compared to highly optimized MPI benchmarks. In addition, the author shows that the Pure programming model is semantically very similar to MPI, which means that migrating from existing applications to Pure is straightforward and simple, further demonstrated by the source-to-source conversion tool mpi2pure. Overall, the main contributions of the paper can be summarized as follows:</p><ol><li>A new programming model and runtime system have been proposed, which effectively combines message passing and task parallelism, and utilizes features of standard C++ to implement it.</li><li>Demonstrates how modern C++ supports more flexible parallel runtime system interfaces.</li><li>Describes a well-designed lock-free, multithreaded, and distributed runtime system that shows significant speed improvements over MPI within nodes.</li><li>It has been proven that by making minimal source code modifications to existing MPI applications, significant performance improvements can be achieved in micro benchmark tests and three real-world applications compared to state-of-the-art MPI implementations.</li></ol><h2 id=2-pure-usage-example><a href=#2-pure-usage-example class=header-anchor>#</a>
2. Pure Usage Example</h2><p>This section illustrates the use of Pure through a simple 1-D Stencil algorithm example. Although this example is simple, it clearly demonstrates the core concepts of Pure and its similarities with MPI, laying the foundation for developers to write more complex applications.</p><p>In the MPI version implementation code <code>rand_stencil_mpi</code>, the main computational work is performed in the function <code>random_work</code>. In simple terms, the <code>rand_stencil_mpi</code> function first enters a loop, iterating <code>iters</code> times, calculating <code>random_work</code> on each element of the array <code>a</code>. It is noteworthy that the execution time of <code>random_work</code> is variable and unknown, which introduces load imbalance. Moreover, <code>random_work</code> does not modify the contents of the array <code>a</code>, but instead updates the array <code>a</code> by averaging adjacent elements. Finally, the program uses <code>MPI_Send</code> and <code>MPI_Recv</code> to exchange the first and last elements of the <code>temp</code> array to compute the first and last elements of the array <code>a</code>. Due to the varying time required by <code>random_work</code>, some processing units will complete tasks early and sometimes become blocked while waiting for the slower sender in an <code>MPI_Recv</code> call.</p><figure><img src=https://cuterwrite-1302252842.file.myqcloud.com/img/1D_stencil-2024-03-14.webp alt=1D_stencil-2024-03-14 width=auto loading=lazy></figure><div class="notice notice-info"><div class=notice-title><svg t="1705940100069" class="icon notice-icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" p-id="6252" width="200" height="200"><path d="M512 64C264.6 64 64 264.6 64 512s200.6 448 448 448 448-200.6 448-448S759.4 64 512 64zm32 664c0 4.4-3.6 8-8 8h-48c-4.4.0-8-3.6-8-8V456c0-4.4 3.6-8 8-8h48c4.4.0 8 3.6 8 8v272zm-32-344c-26.5.0-48-21.5-48-48s21.5-48 48-48 48 21.5 48 48-21.5 48-48 48z" p-id="6253" fill="#fff"/></svg></div><p>Example 1: 1-D Stencil with Random Work, MPI Version</p></div><pre><code class=language-cpp>void rand_stencil_mpi(double* const a, size_t arr_sz, size_t iters, int my_rank,
                      int n_ranks) {
  double temp[arr_sz];
  for (auto it = 0; it &lt; iters; ++it) {
    for (auto i = 0; i &lt; arr_sz; ++i) {
      temp[i] = random_work(a[i]);
    }
    for (auto i = 1; i &lt; arr_sz - 1; ++i) {
      a[i] = (temp[i - 1] + temp[i] + temp[i + 1]) / 3.0;
    }
    if (my_rank &gt; 0) {
      MPI_Send(&amp;temp[0], 1, MPI_DOUBLE, my_rank - 1, 0, MPI_COMM_WORLD);
      double neighbor_hi_val;
      MPI_Recv(&amp;neighbor_hi_val, 1, MPI_DOUBLE, my_rank - 1, 0, MPI_COMM_WORLD,
               MPI_STATUS_IGNORE);
      a[0] = (neighbor_hi_val + temp[0] + temp[1]) / 3.0;
    }  // ends if not first rank
    if (my_rank &lt; n_ranks - 1) {
      MPI_Send(&amp;temp[arr_sz - 1], 1, MPI_DOUBLE, my_rank + 1, 0,
               MPI_COMM_WORLD);
      double neighbor_lo_val;
      MPI_Recv(&amp;neighbor_lo_val, 1, MPI_DOUBLE, my_rank + 1, 0, MPI_COMM_WORLD,
               MPI_STATUS_IGNORE);
      a[arr_sz - 1] =
          (temp[arr_sz - 2] + temp[arr_sz - 1] + neighbor_lo_val) / 3.0;
    }  // ends if not last rank
  }    // ends for all iterations
}
</code></pre><p>Example 2 demonstrates the Pure version that achieves the same functionality. There are some key differences. First, the message calling function interface is different, using the corresponding Pure message passing functions <code>pure_send_msg</code> and <code>pure_recv_msg</code>, instead of MPI calls, but the parameters are essentially the same as the corresponding MPI functions. The message passing semantics of Pure are similar to MPI: the sender&rsquo;s buffer is copied to the receiver&rsquo;s buffer. The main implementation difference is that Pure uses <strong>a lightweight message passing method within the node</strong>, resulting in lower latency for message passing within the node compared to MPI.</p><div class="notice notice-info"><div class=notice-title><svg t="1705940100069" class="icon notice-icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" p-id="6252" width="200" height="200"><path d="M512 64C264.6 64 64 264.6 64 512s200.6 448 448 448 448-200.6 448-448S759.4 64 512 64zm32 664c0 4.4-3.6 8-8 8h-48c-4.4.0-8-3.6-8-8V456c0-4.4 3.6-8 8-8h48c4.4.0 8 3.6 8 8v272zm-32-344c-26.5.0-48-21.5-48-48s21.5-48 48-48 48 21.5 48 48-21.5 48-48 48z" p-id="6253" fill="#fff"/></svg></div><p>Example 2: Pure Version</p></div><pre><code class=language-cpp>void rand_stencil_pure(double* a, const int arr_sz, const int n_iter,
                       const int my_rank, const int n_ranks) {
  double temp[arr_sz];
  PureTask rand_work_task = [a, temp, arr_sz, my_rank](
                                chunk_id_t start_chunk, chunk_id_t end_chunk,
                                std::optinal&lt;void&gt; cont_params) {
    auto [min_idx, max_idx] =
        pure_aligned_idx_range&lt;double&gt;(arr_sz, start_chunk, end_chunk);
    for (auto i = min_idx; i &lt; max_idx; i++) {
      temp[i] = random_work(a[i]);
    }
  };  // ends defining the Pure Task for rand_work_task
  for (auto it = 0; it &lt; n_iter; it++) {
    rand_work_task.execute();  // execute all chunks of rand_work_task
    for (auto i = 1; i &lt; arr_sz - 1; ++i) {
      a[i] = (temp[i - 1] + temp[i] + temp[i + 1]) / 3.0;
    }
    if (my_rank &gt; 0) {
      pure_send_msg(&amp;temp[0], 1, MPI_DOUBLE, my_rank - 1, 0, PURE_COMM_WORLD);
      double neighbor_hi_val;
      pure_recv_msg(&amp;neighbor_hi_val, 1, MPI_DOUBLE, my_rank - 1, 0,
                    PURE_COMM_WORLD);
      a[0] = (neighbor_hi_val + temp[0] + temp[1]) / 3.0;
    }  // ends if not first rank
    if (my_rank &lt; n_ranks - 1) {
      pure_send_msg(&amp;temp[arr_sz - 1], 1, MPI_DOUBLE, my_rank + 1, 0,
                    PURE_COMM_WORLD);
      double neighbor_lo_val;
      pure_recv_msg(&amp;neighbor_lo_val, 1, MPI_DOUBLE, my_rank + 1, 0,
                    PURE_COMM_WORLD);
      a[arr_sz - 1] =
          (temp[arr_sz - 2] + temp[arr_sz - 1] + neighbor_lo_val) / 3.0;
    }  // ends if not last rank
  }    // ends defining the Pure Task for rand_work_task
}
</code></pre><p>The more important difference is the addition of <strong>Pure Task</strong> in Pure, which uses a lambda expression defined with a set of specific parameters. It leverages the capture parameter feature of lambda, allowing variables external to the lambda body to be captured by value or reference and used when the lambda is executed. Pure Task can be viewed as a snippet of application code executed by the Pure Runtime system and can be executed concurrently through multithreading. Therefore, Pure tasks should be structured in a data-parallel-like form. Additionally, Pure Task requires the programmer to ensure thread safety.</p><p>In the above Pure implementation, programmers can use chunk ranges to describe concurrency. These subranges or chunks are passed to the Pure Task through the <code>start_chunk</code> and <code>end_chunk</code> parameters, and they are provided by the Pure Runtime system. The Pure Runtime system is responsible for ensuring that all work is completed smoothly. Since multiple different threads may be involved, the Pure Runtime system achieves this by tracking which chunks have been allocated and completed.</p><p>Secondly, programmers need to map the <code>start_chunk</code> and <code>end_chunk</code> parameters provided by the Pure Runtime system to specific content related to application computation. Here, the code uses the <code>pure_aligned_idx_range</code> helper function to convert them into loop subranges. This helper function takes cache lines into account, which helps avoid false sharing issues.</p><p>Due to random_work potentially causing uneven load distribution, some ranks may be idle while waiting for messages. The Pure task scheduler will automatically utilize these idle ranks to execute other pending Pure task blocks within the same node. Take the example of three ranks within the same node in the diagram below: <strong>rank 0</strong> is executing a Pure Task divided into 6 chunks, while <strong>rank 1</strong> and <strong>rank 2</strong> are blocked due to receiving messages.</p><figure><img src=https://cuterwrite-1302252842.file.myqcloud.com/img/timeline-2024-03-14.png alt=timeline-2024-03-14 width=auto loading=lazy><figcaption><h4>Example Pure code timeline diagram</h4></figcaption></figure><p>From the diagram, the following execution flow can be clearly seen:</p><ul><li>rank 0 begins processing the first chunk (chunk 0).</li><li>At the same time, rank 1 steals and executes the second chunk (chunk 1) in parallel.</li><li>The task scheduler then assigns the third chunk (chunk 2) to rank 0 and the fourth chunk (chunk 3) to rank 1.</li><li>rank 2 attempts to steal a task and successfully executes the fifth chunk (chunk 4). Due to the randomness of <code>random_work</code> execution, chunk 2 and chunk 4 might be time-consuming tasks.</li><li>rank 0 completed the processing of chunk 5, which is a smaller task block, and it finished before rank 2 completed chunk 4.</li><li>The task scheduler ensures that rank 0 does not finish execution before all chunks are completed. In fact, rank 0 has to wait until chunk 4 is completed before it can continue.</li><li>During the process of waiting for messages at rank 1 and rank 2, they will attempt to steal more chunks from any other available rank.</li><li>Thanks to the variable capture feature of lambda expressions, context information can be efficiently shared between different ranks.</li></ul><p>The experimental results show that on a single node configured with 32 ranks, the Pure version achieves a 10% performance improvement compared to the MPI version due to faster message passing and parallel execution of Pure Tasks. In scenarios with uneven load distribution, the acceleration ratio of Pure even exceeds 200%. Although the degree of these performance improvements is affected by load imbalance, in practical application scenarios, Pure still demonstrates significant performance enhancements. This is attributed to the capability of the Pure Runtime system, which can automatically detect and efficiently utilize underutilized computational resources.</p><h2 id=3-programming-model><a href=#3-programming-model class=header-anchor>#</a>
3. Programming Model</h2><p>The core of Pure&rsquo;s programming model is &ldquo;message passing combined with optional task parallelism.&rdquo; Semantically, Pure&rsquo;s message passing and collective communication operations are equivalent to MPI, with differences mainly in some syntactical details.</p><p>Although Pure uses threads within nodes, its rank namespace remains non-hierarchical across the entire cluster. During the execution cycle of a Pure program, the number of ranks remains unchanged.</p><p>The Pure application is written in C++ and runs using the SPMD (Single Program Multiple Data) model, achieving internal multithreading. On the same node, all ranks are implemented through kernel threads.</p><p><strong>It is important to note that Pure applications do not support global variables</strong>. Therefore, developers should remove global variables or use the <code>thread_local</code> keyword to limit the scope of variables, ensuring thread safety.</p><p>For applications with load imbalance issues, developers can use Pure Task in parts of the program that meet the following specific conditions:</p><ol><li>Compute-intensive hotspot areas.</li><li>Tasks that can be executed concurrently.</li></ol><h3 id=message-passing-and-collective-communication-operations><a href=#message-passing-and-collective-communication-operations class=header-anchor>#</a>
Message passing and collective communication operations</h3><p>In Pure, the <code>pure_send_msg</code> and <code>pure_recv_msg</code> functions correspond functionally to MPI&rsquo;s <code>MPI_Send</code> and <code>MPI_Recv</code>, and Pure also provides corresponding non-blocking versions.</p><p>Pure Runtime system ensures that all messages are delivered and in the order they are sent. Pure also implements a series of collective communication operations, including:</p><ul><li>Reduce</li><li>All-Reduce</li><li>Barrier</li><li>Broadcast</li></ul><p>In addition, Pure introduced the concept of a communication subgroup, allowing developers to further subdivide a communication subset into smaller subsets through the <code>pure_comm_split</code> function.</p><p>In order to use Pure, the application needs to be written using modern C++ standards, and it is recommended to compile using <code>std=c++11</code> or a higher version. Pure provides a Make-based build system that automatically configures appropriate compiler options and links to the Pure Runtime system (libpure), while defining a series of targets for debugging and performance analysis.</p><h3 id=pure-task><a href=#pure-task class=header-anchor>#</a>
Pure Task</h3><p>Pure Task allows developers to define the computational parts of an application and break them down into chunks that can be executed in parallel. These chunks can be automatically executed concurrently by the Pure Runtime system.</p><p>However, Pure Task is not necessary and is only recommended when a task can be divided into multiple smaller chunks and doing so helps alleviate load imbalance issues.</p><p>Pure Task is implemented through C++ Lambda expressions and synchronously executed when the <code>execute</code> method is called on the rank that owns the task. Each rank can only execute one Pure Task at a time. The variable capture feature of Lambda expressions allows different ranks to efficiently share context information when executing different chunks. Typically, a Pure Task is defined once during the application&rsquo;s runtime and then executed multiple times at each timestep or other iterations.</p><p>When defining a Pure Task, you need to specify the number of chunks and additional application parameters. Tasks should avoid interdependence; however, because they are fully executed during the <code>execute</code> call, they will not conflict with code outside of the tasks.</p><p>Pure Task contains an <code>execute</code> method, which accepts a parameter <code>per_exe_args</code> of type <code>optional&lt;void*></code>, used to pass additional arguments each time the task is executed. This is very useful when the input values of the task body change during consecutive executions. For example, a developer can pass a pointer to a local structure to the <code>execute</code> method.</p><p>The first two parameters of a Pure Task, <code>start_chunk</code> and <code>end_chunk</code>, are unsigned integers used to specify the range of chunks to execute. These chunks are allocated by the Pure Runtime system, ensuring that each chunk is executed only once, even if they may be executed concurrently.</p><p>Pure Task uses chunk ranges to provide flexibility to the scheduler, allowing multiple chunks to be allocated at once. The number of chunks is determined by the Pure task scheduler, but will not exceed the <code>PURE_MAX_TASK_CHUNKS</code> predefined in the Makefile.</p><p>Currently, the Pure Task interface requires manually mapping chunk numbers to array indices, which can be cumbersome when dealing with multidimensional arrays. Therefore, the future goal is to extend the interface to provide a more concise and higher-level interface similar to TBB&rsquo;s <code>parallel_for</code>.</p><p>Finally, developers need to ensure that the internal implementation of Pure Task is thread-safe to avoid mutual contention between chunks of the same task being executed concurrently. For example, in the CoMD molecular dynamics benchmark, the issue of multiple threads writing to the same memory location simultaneously needs to be addressed, and in such cases, an <code>std::atomic</code> array can be used to replace a regular <code>int</code> array.</p><h2 id=4-runtime-system><a href=#4-runtime-system class=header-anchor>#</a>
4. Runtime System</h2><p>The Pure runtime system is a dynamic library for multithreaded and distributed runtime, used to support the development of Pure applications. Developers need to include the <code>pure.h</code> header file when using it, compile with the C++17 standard, and link to the <code>libpure</code> library. The Pure runtime system can automatically find and exploit opportunities for overlapping execution between computation and communication operations, especially in cases of high communication latency.</p><p>The main functions of the Pure runtime system include:</p><ul><li>Initialize and configure the necessary processes and threads, start the application.</li><li>Communication and collective operations between ranks within the management node.</li><li>Manage internal memory buffers and data structures.</li><li>If a Pure Task is defined in the application, the runtime system is also responsible for scheduling and executing these tasks.</li></ul><h3 id=rank-initialization-and-mapping><a href=#rank-initialization-and-mapping class=header-anchor>#</a>
Rank initialization and mapping</h3><p>In Pure, rank is implemented as the kernel thread of an MPI process. In multi-node applications, Pure runs MPI to handle cross-node communication, whereas in single-node applications, MPI is not used. Nonetheless, Pure applications do not directly call MPI functions. Through Makefile configuration, a Pure program can start an MPI process on a node or NUMA node and create a corresponding number of threads based on the number of cores per node or NUMA node. For application developers, they only need to understand the non-hierarchical rank namespace, while underlying concepts such as nodes, threads, MPI processes, and communication latency are abstracted and transparent to the developers.</p><p>Pure supports flexible rank-to-node mapping strategies and defaults to using an SMP-style allocation strategy. Additionally, Pure supports custom rank mapping, including the use of CrayPAT rank reordering files. While these hardware-related details are invisible to developers, Pure internally utilizes this information to optimize key functionalities.</p><p>When a Pure application starts, the original <code>main</code> function of the application is not executed directly. Instead, the underlying MPI program calls the <code>main</code> function defined in the Pure runtime system, which is responsible for initializing Pure&rsquo;s core data structures. It then creates and binds threads, each executing an <code>original_main</code> function, which is a renamed version of the original <code>main</code> function from the application code. After the application completes execution, the <code>original_main</code> function returns to the Pure runtime system, which is responsible for completing the MPI cleanup and termination process.</p><h3 id=spin-steal-waiting-loop-ssw-loop><a href=#spin-steal-waiting-loop-ssw-loop class=header-anchor>#</a>
Spin-Steal Waiting Loop (SSW-Loop)</h3><p>When a Pure rank encounters a blocking event, such as waiting for a message to arrive, it will execute a mechanism called the <strong>Spin, Steal, Wait Loop (SSW-Loop)</strong> instead of simply entering an idle state. In this loop, the rank checks if the blocking condition is met, such as whether a message has arrived, and if not, it will attempt to steal tasks from other ranks. If a blocking rank can assist in completing tasks that other threads in its process are concurrently executing, it will participate in such assistance work.</p><p>Since threads are bound to specific CPUs and each rank runs only one application, Pure chooses to have ranks actively spin-wait rather than relinquish the CPU. The SSW-Loop gives ranks in computation &ldquo;polymorphism&rdquo;: they can act as computing nodes for the main program, assist other ranks in executing stolen task blocks, and then return to check their own blocking events.</p><p>Pure follows the strategy of prioritizing the stolen workload of the current rank and adheres to the scheduling principle of workload priority.</p><p>Unlike systems that use auxiliary threads to achieve workload stealing or communication, Pure is characterized by allowing application-level compute nodes to directly perform task stealing operations.</p><h3 id=implementation-instructions><a href=#implementation-instructions class=header-anchor>#</a>
Implementation Instructions</h3><p>Pure is written using the C++17 standard library. The Pure runtime system consists of about 21,000 lines of source code, and the Pure tools contain about 14,000 lines of source code. Pure has been tested in various environments, including laptops and clusters, and only requires a C++17 supporting compiler, a Unix-like operating system, and an MPI environment to run. The source code for Pure is publicly available on GitHub at the following link: <a class=link href=https://github.com/psota/pure target=_blank rel=noopener>https://github.com/psota/pure
<span style=white-space:nowrap><svg width=".8em" height=".8em" viewBox="0 0 21 21" xmlns="http://www.w3.org/2000/svg"><path d="m13 3 3.293 3.293-7 7 1.414 1.414 7-7L21 11V3z" fill="currentcolor"/><path d="M19 19H5V5h7l-2-2H5c-1.103.0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103.0 2-.897 2-2v-5l-2-2v7z" fill="currentcolor"/></span>
</a>.</p><h3 id=point-to-point-communication><a href=#point-to-point-communication class=header-anchor>#</a>
Point-to-point communication</h3><p>Pure provides blocking and non-blocking point-to-point message passing functionality, consistent with the message passing semantics of MPI.</p><p>Pure internally uses three different strategies for message passing, and the choice of strategy depends on the size of the message and whether the sender and receiver are located on the same node.</p><p>Pure allocates and reuses a persistent Channel object throughout the program&rsquo;s lifecycle, which is stored in the runtime system. The internal Channel Manager is responsible for mapping message parameters to the appropriate data structures and creating these structures as needed.</p><figure><img src=https://cuterwrite-1302252842.file.myqcloud.com/img/strategy-2024-03-15.webp alt=strategy-2024-03-15 width=auto loading=lazy><figcaption><h4>Pure Message Passing Strategy</h4></figcaption></figure><ul><li><strong>Short message (less than 8KB)</strong>:<ul><li>Use a lock-free circular queue (PureBufferQueue, PBQ), with acquire-release memory semantics. The sending thread copies the message to the PBQ when there is available space, and the receiving thread retrieves it when the message is ready.<ul><li>In short message passing, the overhead of copying is relatively small, allowing the sender to immediately perform other useful work after the call returns.</li></ul></li><li>Both sending and receiving threads use SSW-Loop to wait in order to achieve as much overlap of computation and communication as possible.</li><li>The slots for all messages are stored in a contiguous buffer, with pointer arithmetic ensuring that each slot is aligned with cache line boundaries, avoiding false sharing between sending and receiving threads.</li></ul></li><li><strong>Big Message (greater than or equal to 8KB)</strong>:<ul><li>A strategy similar to PBQ, but using a single memory copy directly from sender to receiver, inspired by the rendezvous mode of MPI.</li><li>Use a lock-free fixed-size circular buffer to store the receiver&rsquo;s receive call parameters.</li><li>The sender waits for a metadata queue item via SSW-Loop and then copies the message content directly to the receiver&rsquo;s buffer. The sender notifies the receiver that the transfer is complete by inserting the number of bytes transferred into the lock-free queue.</li></ul></li><li><strong>Cross-node message</strong><ul><li>Transparently use the MPI interface for message passing.</li><li>During Pure initialization, use a distributed consensus algorithm to create a <code>thread-rank-process-node</code> mapping data structure that maps Pure rank to MPI rank.</li><li>To ensure that the correct receiving thread on the receiving node can receive the message, encode the sending and receiving thread IDs in <code>MPI_TAG</code> to solve the multithreading routing problem.</li></ul></li></ul><h3 id=collective-communication><a href=#collective-communication class=header-anchor>#</a>
Collective communication</h3><p>The collective communication operations of Pure are semantically the same as MPI, but they are implemented within nodes using a bottom-up constructed data structure. This has shown significant performance improvements in both single-node and multi-node benchmarks, even though it still relies on MPI&rsquo;s collective operations for cross-node communication.</p><p>Pure uses a leader thread to coordinate the collective communication process, while other threads assist with computation and call MPI collective functions as needed.</p><ul><li>Pure uses a static leader election method, which is more efficient than the compare-and-swap based &ldquo;first-come&rdquo; method.</li></ul><p>The following is an example using All-Reduce, other collective communication operations have similar concepts.</p><p>For small data All-Reduce operations, Pure designed a concurrent data structure called Sequenced Per-Thread Dropbox (SPTD), providing an efficient lock-free mechanism for pairwise synchronization and optionally sharing data between leader threads and other non-leader threads.</p><figure><img src=https://cuterwrite-1302252842.file.myqcloud.com/img/SPTD-2024-03-15.webp alt=SPTD-2024-03-15 width=auto loading=lazy><figcaption><h4>Sequenced Per-Thread Dropbox (SPTD)</h4></figcaption></figure><p>This method draws on the flat-combinding technique, using thread 0 in the communicator as the leader thread.</p><ul><li>For small arrays not exceeding 2KB:<ul><li>Non-leader threads first copy data to SPTD, then synchronize with the leader thread, indicating that the input data is ready (using atomic sequence numbers instead of a shared atomic counter).</li></ul></li><li>The leader thread performs an element-wise Reduce operation on all input arrays.<ul><li>Each node&rsquo;s leader thread uses <code>MPI_Allreduce</code> to perform a global Reduce on local Reduce results.</li><li>Leader thread synchronization, non-leader threads copy the final Reduce result to a private buffer.</li></ul></li><li>All threads execute the SSW-Loop while waiting.</li><li>For large arrays exceeding 2KB, Reduce computation may become a performance bottleneck. Therefore, it is necessary for all threads to execute Reduce computation concurrently and read from or write to data directly from each thread&rsquo;s buffer through shared memory.<ul><li>Reduce work is divided into equally sized blocks to avoid false sharing and enable vectorized computation.</li></ul></li><li>Threads report readiness status using SPTD and mark computation completion with atomic sequence numbers.<ul><li>The leader thread calls <code>MPI_Allreduce</code> to perform an All-Reduce operation across nodes and propagates the final result through another atomic sequence number.</li></ul></li></ul><h3 id=task-scheduler><a href=#task-scheduler class=header-anchor>#</a>
Task Scheduler</h3><p>The Pure runtime system has meticulously designed a task scheduler that maintains an array named <code>active_tasks</code> in shared memory. This array stores a series of atomic pointers, each corresponding to a task being executed, and allocates an entry for each node and each rank in the system. These entries are initially set to <code>nullptr</code>, indicating that a task has not yet been assigned.</p><p>When a task is created and prepared for execution, the system initializes its state and updates the corresponding entry in the <code>active_tasks</code> array through an atomic operation to reflect that the task has been assigned. This update process ensures that the execution state of the task is visible to all threads in the system, allowing the task to be &ldquo;stolen&rdquo; by other threads.</p><p>During the execution of the task, the rank owning the task will begin executing a series of chunks, which are the subdivided work units of the task. Meanwhile, other threads will continuously check the <code>active_tasks</code> array during their SSL-Loop, using atomic load operations to look for executable non-empty tasks.</p><p>The execution of the task is coordinated by two atomic integers, <code>curr_chunk</code> and <code>chunks_done</code>. The owner rank of the task and the possible thief ranks will both run the same concurrent execution function. The thief threads will return after executing one chunk, while the owner thread will continue executing until all chunks are completed. By using the <code>fetch_add</code> operation, a thread can determine which chunk it should execute. If the value of <code>curr_chunk</code> has already exceeded the total number of chunks, the thread will stop executing.</p><p>Each time a chunk is successfully completed, the thread atomically increments the value of <code>chunks_done</code>. The owner thread updates its local storage to avoid cache misses. Finally, the owner rank will wait until all chunks are executed, ensuring the complete execution of the task.</p><p>It is worth noting that the task&rsquo;s chunk and the application&rsquo;s rank are executed on the same hardware thread. In Pure applications, each hardware thread is assigned to a specific rank. Although currently Pure does not utilize hardware accelerators (such as GPUs) to accelerate task execution, the designers believe that Pure&rsquo;s architecture is fully capable of supporting such acceleration.</p><p>The Pure task scheduler provides various execution modes and stealing algorithms to accommodate different execution needs. For example, the author implemented a single chunk execution mode and a guided self-scheduling mode, the latter being a work partitioning algorithm that prioritizes the allocation of larger work chunks followed by smaller ones. Additionally, the scheduler includes a NUMA-aware stealing mode, which prioritizes stealing tasks from threads on the same NUMA node, and a &ldquo;sticky&rdquo; stealing mode, allowing thief threads to return to tasks they recently stole that are still active. These features collectively ensure the efficiency and flexibility of task scheduling.</p><h2 id=evaluation><a href=#evaluation class=header-anchor>#</a>
Evaluation</h2><p>The performance evaluation of Pure was conducted on the Cori HPC cluster at Berkeley NERSC. This cluster consists of 2388 nodes, each configured with 2 sockets, 16 cores, and 128GB of memory, interconnected via Cray Aires. The experimental configuration enabled hyper-threading and adopted a 256-bit vector width. Two processes were run on each node, totaling 32 threads. The evaluation used the Intel compiler and Cray MPICH as the performance baseline.</p><h3 id=nas-dt-benchmark-results><a href=#nas-dt-benchmark-results class=header-anchor>#</a>
NAS DT benchmark results</h3><figure><img src=https://cuterwrite-1302252842.file.myqcloud.com/img/nasdt-2024-03-15.webp alt=nasdt-2024-03-15 width=auto loading=lazy></figure><ul><li>By optimizing the message-passing mechanism alone, Pure achieved a performance boost of 11% to 25%.</li><li>After introducing Pure Tasks, the performance acceleration ratio increased to 1.7 times to 2.6 times.</li><li>Auxiliary threads can slightly improve performance, but only if there are remaining unused CPU cores available. Here, except in the case of 80 ranks where 24 cores were idle, the CPU cores were fully utilized in other cases.</li></ul><h3 id=comd-and-miniamr-benchmarks><a href=#comd-and-miniamr-benchmarks class=header-anchor>#</a>
CoMD and miniAMR benchmarks</h3><figure><img src=https://cuterwrite-1302252842.file.myqcloud.com/img/benchmark-pure-2024-03-15.webp alt=benchmark-pure-2024-03-15 width=auto loading=lazy></figure><p>-In the CoMD molecular dynamics application, Pure outperforms using only MPI and MPI+OpenMP in terms of performance across all ranks, achieving speedups of 7% to 25% and 35% to 50% respectively, even in the absence of load imbalance.</p><ul><li>In the miniAMR adaptive mesh refinement application, Pure achieved at least a 20% and at most a 50% performance acceleration.</li></ul><h3 id=collective-communication-performance><a href=#collective-communication-performance class=header-anchor>#</a>
Collective communication performance</h3><figure><img src=https://cuterwrite-1302252842.file.myqcloud.com/img/benchmark-pure-msg-2024-03-15.webp alt=benchmark-pure-msg-2024-03-15 width=auto loading=lazy></figure><ul><li>Pure exhibits outstanding performance in collective communication operations, where its internal optimization mechanisms and data structure design allow Pure to demonstrate significant efficiency and advantages when handling large-scale parallel computing tasks.</li></ul><h2 id=related-work><a href=#related-work class=header-anchor>#</a>
Related work</h2><div class=table-wrapper><table><thead><tr><th style=text-align:center>Category</th><th style=text-align:left>Related Work</th><th style=text-align:left>Advantages of Pure</th></tr></thead><tbody><tr><td style=text-align:center>MPI</td><td style=text-align:left>1. Utilize shared memory within multi-core nodes to enhance performance; 2. XPMEM significantly enhances intra-node communication efficiency; 3. ch4 network library optimizes MPI shared memory communication; 4. Improved MPI collective communication algorithms; 5. DMAPP library is optimized for specific collective communications, but with many limitations; 6. Addressed the challenges of large-scale all-to-all collective communications; 7. One-sided message API achieves decoupling; 8. Optimized data movement and process synchronization</td><td style=text-align:left>1. Pure demonstrates excellent performance across all collective communications and load sizes; 2. Provides advanced communication-computation overlap mechanisms, surpassing traditional one-sided message API</td></tr><tr><td style=text-align:center>MPI Multithreading</td><td style=text-align:left>1. Supports multithreading within ranks in MPI_THREAD_MULTIPLE mode; 2. Most MPI implementations achieve thread safety through global locks, leading to performance bottlenecks; 3. MPI 4.0 introduces MPI+X method to enhance multithreading support; 4. Introduces the concepts of MPI Fine-points and Endpoints to support threading</td><td style=text-align:left>1. Pure emphasizes the importance of MPI calls in multithreaded code; 2. Provides a unified programming model to simplify the introduction of parallel tasks</td></tr><tr><td style=text-align:center>AMPI</td><td style=text-align:left>1. MPI compatible library based on Charm++; 2. Provides advanced parallel programming abstractions; 3. Achieves performance improvement with minimal code changes</td><td style=text-align:left>1. Pure outperforms AMIP in practical tests due to its optimized message passing and collective communication, as well as more refined and low-overhead load balancing strategies; 2. Compared to the thread-based model of AMIP SMP, Pure offers more efficient parallel processing</td></tr><tr><td style=text-align:center>PGAS language and parallel frameworks</td><td style=text-align:left>1. PGAS language provides an abstraction of global memory address space; 2. Chapel and X10 extend the PGAS approach, supporting local and remote asynchronous tasks; 3. HPX adds distributed operation support to the modern C++ standard; 4. Legion as a data center parallel programming system; 5. Frameworks like Kokkos, STAPL, BCL provide an abstraction layer between applications and hardware</td><td style=text-align:left>1. Similar to Pure, the PGAS model adopts the SPMD style to improve performance through locality reference; 2. Although these frameworks utilize modern C++ features, they usually require extensive rewriting of existing applications, whereas Pure offers a more direct optimization path</td></tr></tbody></table></div><h2 id=summary-1><a href=#summary-1 class=header-anchor>#</a>
Summary</h2><p>For decades, message passing has been regarded as the standard model for parallel programming due to its relative simplicity and performance advantages. However, this paper demonstrates that message passing and shared memory are not incompatible. In fact, by designing appropriate libraries, shared memory can be fully utilized without sacrificing most of the advantages of message passing.</p></section><footer class=article-footer><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer><script type=text/javascript src=/js/prism.js async></script><link rel=stylesheet href=https://libs.jshub.com/KaTeX/0.16.8/katex.min.css integrity="sha256-3574TpfThVfeAhg+I4+N39EJiLN3QUkuEsMVe8hWAR4=" crossorigin=anonymous><script src=https://libs.jshub.com/KaTeX/0.16.8/katex.min.js integrity="sha256-1PDqJcTMt5hrIp1kJ3lLcGPPMgmwN2z1pkv8TdeRjJU=" crossorigin=anonymous defer></script><script src=https://libs.jshub.com/KaTeX/0.16.8/contrib/auto-render.min.js integrity="sha256-nLjaz8CGwpZsnsS6VPSi3EO3y+KzPOwaJ0PYhsf7R6c=" crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/en/p/science-plot/><div class=article-image><img src=https://cuterwrite-1302252842.file.myqcloud.com/img/crop_ee40c9cb9e33ffe888365e66e0a104dc195413-2024-02-28.webp loading=lazy data-key=science-plot data-hash=https://cuterwrite-1302252842.file.myqcloud.com/img/crop_ee40c9cb9e33ffe888365e66e0a104dc195413-2024-02-28.webp></div><div class=article-details><h2 class=article-title>Scientific Research Chart Drawing</h2></div></a></article></div></div></aside><script src=https://unpkg.com/twikoo@1.6.39/dist/twikoo.all.min.js></script><div id=tcomment></div><style>.twikoo{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}:root[data-scheme=dark]{--twikoo-body-text-color-main:rgba(255, 255, 255, 0.9);--twikoo-body-text-color:rgba(255, 255, 255, 0.7)}.twikoo .el-input-group__prepend,.twikoo .tk-action-icon,.twikoo .tk-time,.twikoo .tk-comments-count{color:var(--twikoo-body-text-color)}.twikoo .el-input__inner,.twikoo .el-textarea__inner,.twikoo .tk-preview-container,.twikoo .tk-content,.twikoo .tk-nick,.twikoo .tk-send{color:var(--twikoo-body-text-color-main)}.twikoo .el-button{color:var(--twikoo-body-text-color)!important}.OwO .OwO-body{background-color:var(--body-background)!important;color:var(--body-text-color)!important}</style><script>twikoo.init({envId:"https://comment.cuterwrite.top",el:"#tcomment",lang:"zh-CN"})</script><footer class=site-footer><section class=copyright>&copy;
2021 -
2024 cuterwrite</section><section class=running-time>本博客已稳定运行
<span id=runningdays class=running-days></span></section><section class=totalcount>发表了25篇文章 ·
总计60.25k字</section><section class=powerby>Welcome to cuterwrite's blog!<br>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.27.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a><br><span>基于 <a href=https://github.com/CaiJimmy/hugo-theme-stack/tree/v3.27.0 target=_blank rel=noopener><b style=color:#9e8f9f>v3.27.0</b></a> 分支版本修改</span><br></section></footer><script>let s1="2021-4-17";s1=new Date(s1.replace(/-/g,"/"));let s2=new Date,timeDifference=s2.getTime()-s1.getTime(),days=Math.floor(timeDifference/(1e3*60*60*24)),hours=Math.floor(timeDifference%(1e3*60*60*24)/(1e3*60*60)),minutes=Math.floor(timeDifference%(1e3*60*60)/(1e3*60)),result=days+"天"+hours+"小时"+minutes+"分钟";document.getElementById("runningdays").innerHTML=result</script><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://libs.jshub.com/photoswipe/4.1.3/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://libs.jshub.com/photoswipe/4.1.3/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://libs.jshub.com/photoswipe/4.1.3/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://libs.jshub.com/photoswipe/4.1.3/photoswipe.min.css crossorigin=anonymous></main></div><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.font.im/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script><meta name=apple-mobile-web-app-capable content="yes"><meta name=theme-color content="#ffffff"><script>"serviceWorker"in navigator&&window.addEventListener("load",()=>{navigator.serviceWorker.register("/sw.js").then(e=>{console.log("Service worker registered with scope: ",e.scope)},e=>{console.log("Service worker registration failed: ",e)})})</script></body></html>