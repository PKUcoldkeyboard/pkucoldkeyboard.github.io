<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Cuterwrite's Blog</title><link>https://cuterwrite.top/post/</link><description>Recent content in Posts on Cuterwrite's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>cuterwrite</copyright><lastBuildDate>Wed, 26 Jun 2024 23:11:00 +0000</lastBuildDate><atom:link href="https://cuterwrite.top/post/index.xml" rel="self" type="application/rss+xml"/><item><title>RDMA 之 Completion Queue</title><link>https://cuterwrite.top/p/rdma-completion-queue/</link><pubDate>Wed, 26 Jun 2024 23:11:00 +0000</pubDate><guid>https://cuterwrite.top/p/rdma-completion-queue/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-16_116903369_p0_master1200.webp" alt="Featured image of post RDMA 之 Completion Queue" />&lt;h1 id="rdma-之-completion-queue">RDMA 之 Completion Queue&lt;/h1>
&lt;p>&lt;strong>本文欢迎非商业转载，转载请注明出处。&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>声明：仅用于收藏，便于阅读&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/259650980">&lt;cite>知乎专栏：10. RDMA 之 Completion Queue&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>我们曾经在前面的文章中简单介绍过 CQ，本文将更深入的讲解关于它的一些细节。阅读本文前，读者可以先温习一下这篇文章： &lt;a class="link" href="https://cuterwrite.top/p/rdma-element/" >“3. RDMA 基本元素”
&lt;/a>
。&lt;/p>
&lt;h2 id="基本概念">基本概念&lt;/h2>
&lt;p>我们先回顾下 CQ 的作用。CQ 意为完成队列，它的作用和 WQ（SQ 和 RQ）相反，硬件通过 CQ 中的 CQE/WC 来告诉软件某个 WQE/WR 的完成情况。再次提醒读者，对于上层用户来说一般用 WC，对于驱动程序来说，一般称为 CQE，本文不对两者进行区分。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-27_10_1.webp"
alt="2024-06-27_10_1" width="80%" loading="lazy">
&lt;/figure>
&lt;p>CQE 可以看作一份“报告”，其中写明了某个任务的执行情况，其中包括：&lt;/p>
&lt;ul>
&lt;li>本次完成了哪个 QP 的哪一个 WQE 指定的任务（QP Number 和 WR ID）&lt;/li>
&lt;li>本次任务执行了什么操作（Opcode 操作类型）&lt;/li>
&lt;li>本次任务执行成功/失败，失败原因是 XXX（Status 状态和错误码）&lt;/li>
&lt;li>&amp;hellip;&lt;/li>
&lt;/ul>
&lt;p>每当硬件处理完一个 WQE 之后，都会产生一个 CQE 放在 CQ 队列中。如果一个 WQE 对应的 CQE 没有产生，那么这个 WQE 就会一直被认为还未处理完，这意味着什么呢？&lt;/p>
&lt;ul>
&lt;li>涉及从内存中取数据的操作（SEND 和 WRITE）&lt;/li>
&lt;/ul>
&lt;p>在产生 CQE 之前，硬件可能还未发送消息，可能正在发送消息，可能对端有接收到正确的消息。由于内存区域是在发送前申请好的，所以上层软件收到对应的 CQE 之前，其必须认为这片内存区域仍在使用中，不能将所有相关的内存资源进行释放。&lt;/p>
&lt;ul>
&lt;li>涉及向内存中存放数据的操作（RECV 和 READ）&lt;/li>
&lt;/ul>
&lt;p>在产生 CQE 之前，有可能硬件还没有开始写入数据，有可能数据才写了一半，也有可能数据校验出错。所以上层软件在获得 CQE 之前，这段用于存放接收数据的内存区域中的内容是不可信的。&lt;/p>
&lt;p>总之，用户必须获取到 CQE 并确认其内容之后才能认为消息收发任务已经完成。&lt;/p>
&lt;h3 id="何时产生">何时产生&lt;/h3>
&lt;p>我们将按照服务类型（本篇只讲 RC 和 UD）和操作类型来分别说明，因为不同的情况产生 CQE 的时机和含义都不同，建议读者回顾第 4 篇和第 5 篇： &lt;a class="link" href="https://cuterwrite.top/p/rdma-op/" >“4. RDMA 基本操作”
&lt;/a>
、&lt;a class="link" href="https://cuterwrite.top/p/rdma-service-types/" >“5. RDMA 基本服务类型”
&lt;/a>
。&lt;/p>
&lt;ul>
&lt;li>可靠服务类型（RC）&lt;/li>
&lt;/ul>
&lt;p>前面的文章说过，&lt;strong>可靠意味着本端关心发出的消息能够被对端准确的接收&lt;/strong>，这是通过 ACK、校验和重传等机制保证的。&lt;/p>
&lt;ul>
&lt;li>SEND&lt;/li>
&lt;/ul>
&lt;p>SEND 操作需要硬件从内存中获取数据，然后组装成数据包通过物理链路发送到对端。对 SEND 来说，Client 端产生 CQE 表示&lt;strong>对端已准确无误的收到数据&lt;/strong>，对端硬件收到数据并校验之后，会回复 ACK 包给发送方。发送方收到这 ACK 之后才会产生 CQE，从而告诉用户这个任务成功执行了。如图所示，左侧 Client 端在红点的位置产生了本次任务的 CQE。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-27_10_2.webp"
alt="2024-06-27_10_2" width="50%" loading="lazy">
&lt;/figure>
&lt;ul>
&lt;li>RECV&lt;/li>
&lt;/ul>
&lt;p>RECV 操作需要硬件将收到的数据放到用户 WQE 中指定的内存区域，完成校验和数据存放动作后，硬件就会产生 CQE。如上图右侧 Server 端所示。&lt;/p>
&lt;ul>
&lt;li>WRITE&lt;/li>
&lt;/ul>
&lt;p>对于 Client 端来说，WRITE 操作和 SEND 操作是一样的，硬件会从内存中取出数据，并等待对端回复 ACK 后，才会产生 CQE。差别在于，因为 WRITE 是 RDMA 操作，对端 CPU 不感知，自然用户也不感知，所以上面的图变成了这样：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-27_10_3.webp"
alt="2024-06-27_10_3" width="50%" loading="lazy">
&lt;/figure>
&lt;ul>
&lt;li>READ&lt;/li>
&lt;/ul>
&lt;p>READ 和 RECV 有点像，Client 端发起 READ 操作后，对端会回复我们想读取的数据，然后本端校验没问题后，会把数据放到 WQE 中指定的位置。完成上述动作后，本端会产生 CQE。READ 同样是 RDMA 操作，对端用户不感知，自然也没有 CQE 产生。这种情况上图变成了这样：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-27_10_4.webp"
alt="2024-06-27_10_4" width="50%" loading="lazy">
&lt;/figure>
&lt;ul>
&lt;li>不可靠服务类型（UD）&lt;/li>
&lt;/ul>
&lt;p>因为不可靠的服务类型没有重传和确认机制，所以产生 CQE 表示硬件&lt;strong>已经将对应 WQE 指定的数据发送出去了&lt;/strong>。以前说过 UD 只支持 SEND-RECV 操作，不支持 RDMA 操作。所以对于 UD 服务的两端，CQE 产生时机如下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-27_10_5.webp"
alt="2024-06-27_10_5" width="50%" loading="lazy">
&lt;/figure>
&lt;h3 id="wq-和-cq-的对应关系">WQ 和 CQ 的对应关系&lt;/h3>
&lt;p>&lt;strong>每个 WQ 都必须关联一个 CQ，而每个 CQ 可以关联多个 SQ 和 RQ。&lt;/strong>&lt;/p>
&lt;p>这里的所谓“关联”，指的是一个 WQ 的所有 WQE 对应的 CQE，都会被硬件放到绑定的 CQ 中，需要注意同属于一个 QP 的 SQ 和 RQ 可以各自关联不同的 CQ。如下图所示，QP1 的 SQ 和 RQ 都关联了 CQ1，QP2 的 RQ 关联到了 CQ1、SQ 关联到了 CQ2。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-27_10_6.webp"
alt="2024-06-27_10_6" width="auto" loading="lazy">
&lt;/figure>
&lt;p>因为每个 WQ 必须关联一个 CQ，所以用户创建 QP 前需要提前创建好 CQ，然后分别指定 SQ 和 RQ 将会使用的 CQ。&lt;/p>
&lt;p>&lt;strong>同一个 WQ 中的 WQE，其对应的 CQE 间是保序的&lt;/strong>&lt;/p>
&lt;p>硬件是按照“先进先出”的 FIFO 顺序从某一个 WQ（SQ 或者 RQ）中取出 WQE 并进行处理的，而向 WR 关联的 CQ 中存放 CQE 时，也是遵从这些 WQE 被放到 WQ 中的顺序的。简单来说，就是谁先被放到队列里，谁就先被完成。该过程如下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-27_10_7.webp"
alt="2024-06-27_10_7" width="auto" loading="lazy">
&lt;/figure>
&lt;p>需要注意的是，使用 SRQ 的情况以及 RD 服务类型的 RQ 这两种情况是不保序的，本文中不展开讨论。&lt;/p>
&lt;p>&lt;strong>不同 WQ 中的 WQE，其对应的 CQE 间是不保序的&lt;/strong>&lt;/p>
&lt;p>前文中我们说过，一个 CQ 可能会被多个 WQ 共享。这种情况下，是不能保证这些 WQE 对应的 CQE 的产生顺序的。如下图所示（WQE 编号表示下发的次序，即 1 最先被下发，6 最后被下发）：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-27_10_8.webp"
alt="2024-06-27_10_8" width="auto" loading="lazy">
&lt;/figure>
&lt;p>上面的描述其实还包含了“同一个 QP 的 SQ 和 RQ 中的 WQE，其对应的 CQE 间是不保序的”的情况，这一点其实比较容易理解，SQ 和 RQ，一个负责主动发起的任务，一个负责被动接收的任务，它们本来就可以是认为是两条不同方向的通道，自然不应该相互影响。假设用户对同一个 QP 先下发了一个 Receive WQE，又下发一个 Send WQE，总不能对端不给本端发送消息，本端就不能发送消息给对端了吧？&lt;/p>
&lt;p>既然这种情况下 CQE 产生的顺序和获取 WQE 的顺序是不相关的，那么上层应用和驱动是如何知道收到的 CQE 关联的是哪个 WQE 呢？其实很简单，&lt;strong>CQE 中指明它所对应的 WQE 的编号&lt;/strong>就可以了。&lt;/p>
&lt;p>另外需要注意的是，即使在多个 WQ 共用一个 CQ 的情况下，“同一个 WQ 中的 WQE，其对应的 CQE 间是保序的”这一点也是一定能够保证的，即上图中的属于 WQ1 的 WQE 1、3、4 对应的 CQE 一定是按照顺序产生的，对于属于 WQ2 的 WQE 2、5、6 也是如此。&lt;/p>
&lt;h3 id="cqc">CQC&lt;/h3>
&lt;p>同 QP 一样，CQ 只是一段存放 CQE 的队列内存空间。硬件除了知道首地址以外，对于这片区域可以说是一无所知。所以需要提前跟软件约定好格式，然后驱动将申请内存，并按照格式把 CQ 的基本信息填写到这片内存中供硬件读取，这片内存就是 CQC。CQC 中包含了 CQ 的容量大小，当前处理的 CQE 的序号等等信息。所以把 QPC 的图稍微修改一下，就能表示出 CQC 和 CQ 的关系：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-27_10_9.webp"
alt="2024-06-27_10_9" width="auto" loading="lazy">
&lt;/figure>
&lt;h3 id="cqn">CQN&lt;/h3>
&lt;p>CQ Number，就是 CQ 的编号，用来区别不同的 CQ。CQ 没有像 QP0 和 QP1 一样的特殊保留编号，本文中不再赘述了。&lt;/p>
&lt;h2 id="完成错误">完成错误&lt;/h2>
&lt;p>IB 协议中有三种错误类型，立即错误（immediate error）、完成错误（Completion Error）以及异步错误（Asynchronous Errors)。&lt;/p>
&lt;p>立即错误的是“立即停止当前操作，并返回错误给上层用户”；完成错误指的是“通过 CQE 将错误信息返回给上层用户”；而异步错误指的是“通过中断事件的方式上报给上层用户”。可能还是有点抽象，我们来举个例子说明这两种错误都会在什么情况下产生：&lt;/p>
&lt;ul>
&lt;li>用户在 Post Send 时传入了非法的操作码，比如想在 UD 的时候使用 RDMA WRITE 操作。&lt;/li>
&lt;/ul>
&lt;p>结果：产生立即错误（有的厂商在这种情况会产生完成错误）&lt;/p>
&lt;p>一般这种情况下，驱动程序会直接退出 post send 流程，并返回错误码给上层用户。注意此时 WQE 还没有下发到硬件就返回了。&lt;/p>
&lt;ul>
&lt;li>用户下发了一个 WQE，操作类型为 SEND，但是长时间没有受到对方的 ACK。&lt;/li>
&lt;/ul>
&lt;p>结果：产生完成错误&lt;/p>
&lt;p>因为 WQE 已经到达了硬件，所以硬件会产生对应的 CQE，CQE 中包含超时未响应的错误详情。&lt;/p>
&lt;ul>
&lt;li>用户态下发了多个 WQE，所以硬件会产生多个 CQE，但是软件一直没有从 CQ 中取走 CQE，导致 CQ 溢出。
结果：产生异步错误&lt;/li>
&lt;/ul>
&lt;p>因为软件一直没取 CQE，所以自然不会从 CQE 中得到信息。此时 IB 框架会调用软件注册的事件处理函数，来通知用户处理当前的错误。&lt;/p>
&lt;p>由此可见，它们都是底层向上层用户报告错误的方式，只是产生的时机不一样而已。IB 协议中对不同情况的错误应该以哪种方式上报做了规定，比如下图中，对于 Modify QP 过程中修改非法的参数，应该返回立即错误。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-27_10_10.webp"
alt="2024-06-27_10_10" width="auto" loading="lazy">
&lt;/figure>
&lt;p>本文的重点在于 CQ，所以介绍完错误类型之后，我们着重来看一下完成错误。完成错误是硬件通过在 CQE 中填写错误码来实现上报的，一次通信过程需要发起端（Requester）和响应端（Responder）参与，具体的错误原因也分为本端和对端。我们先来看一下错误检测是在什么阶段进行的（下图对 IB 协议中 Figure 118 进行了重画）：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-27_10_11.webp"
alt="2024-06-27_10_11" width="auto" loading="lazy">
&lt;/figure>
&lt;p>Requester 的错误检测点有两个：&lt;/p>
&lt;ol>
&lt;li>本地错误检测&lt;/li>
&lt;/ol>
&lt;p>即对 SQ 中的 WQE 进行检查，如果检测到错误，就从本地错误检查模块直接产生 CQE 到 CQ，不会发送数据到响应端了；如果没有错误，则发送数据到对端。&lt;/p>
&lt;ol start="2">
&lt;li>远端错误检测&lt;/li>
&lt;/ol>
&lt;p>即检测响应端的 ACK 是否异常，ACK/NAK 是由对端的本地错误检测模块检测后产生的，里面包含了响应端是否有错误，以及具体的错误类型。无论远端错误检测的结果是否有问题，都会产生 CQE 到 CQ 中。&lt;/p>
&lt;p>Responder 的错误检测点只有一个：&lt;/p>
&lt;ol>
&lt;li>本地错误检测&lt;/li>
&lt;/ol>
&lt;p>实际上检测的是对端报文是否有问题，IB 协议也将其称为“本地”错误检测。如果检测到错误，则会体现在 ACK/NAK 报文中回复给对端，以及在本地产生一个 CQE。&lt;/p>
&lt;p>需要注意的是，上述的产生 ACK 和远端错误检测只对面向连接的服务类型有效，无连接的服务类型。比如 UD 类型并不关心对端是否收到，接收端也不会产生 ACK，所以在 Requester 的本地错误检测之后就一定会产生 CQE，无论是否有远端错误。&lt;/p>
&lt;p>然后我们简单介绍下几种常见的完成错误：&lt;/p>
&lt;ul>
&lt;li>RC 服务类型的 SQ 完成错误&lt;/li>
&lt;li>Local Protection Error
&lt;ul>
&lt;li>本地保护域错误。本地 WQE 中指定的数据内存地址的 MR 不合法，即用户试图使用一片未注册的内存中的数据。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Remote Access Error
&lt;ul>
&lt;li>远端权限错误。本端没有权限读/写指定的对端内存地址。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Transport Retry Counter Exceeded Error
&lt;ul>
&lt;li>重传超次错误。对端一直未回复正确的 ACK，导致本端多次重传，超过了预设的次数。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>RC 服务类型的 RQ 完成错误&lt;/li>
&lt;li>Local Access Error
&lt;ul>
&lt;li>本地访问错误。说明对端试图写入其没有权限写入的内存区域。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Local Length Error
&lt;ul>
&lt;li>本地长度错误。本地 RQ 没有足够的空间来接收对端发送的数据。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>完整的完成错误类型列表请参考 IB 协议的 10.10.3 节。&lt;/p>
&lt;h2 id="用户接口">用户接口&lt;/h2>
&lt;p>同 QP 一样，我们依然从通信准备阶段（控制面）和通信进行阶段（数据面）来介绍 IB 协议对上层提供的关于 CQ 的接口。&lt;/p>
&lt;h3 id="控制面">控制面&lt;/h3>
&lt;p>同 QP 一样，还是“增删改查”四种，但是可能因为对于 CQ 来说，上层用户是资源使用者而不是管理者，只能从 CQ 中读数据而不能写数据，所以对用户开放的可配的参数就只有“CQ 规格”一种。&lt;/p>
&lt;ul>
&lt;li>创建——Create CQ&lt;/li>
&lt;/ul>
&lt;p>创建的时候用户必须指定 CQ 的规格，即能够储存多少个 CQE，另外用户还可以填写一个 CQE 产生后的回调函数指针（下文会涉及）。内核态驱动会将其他相关的参数配置好，填写到跟硬件约定好的 CQC 中告知硬件。&lt;/p>
&lt;ul>
&lt;li>销毁——Destroy CQ&lt;/li>
&lt;/ul>
&lt;p>释放一个 CQ 软硬件资源，包含 CQ 本身及 CQC，另外 CQN 自然也将失效。&lt;/p>
&lt;ul>
&lt;li>修改——Resize CQ&lt;/li>
&lt;/ul>
&lt;p>这里名字稍微有点区别，因为 CQ 只允许用户修改规格大小，所以就用的 Resize 而不是 Modify。&lt;/p>
&lt;ul>
&lt;li>查询——Query CQ&lt;/li>
&lt;/ul>
&lt;p>查询 CQ 的当前规格，以及用于通知的回调函数指针。&lt;/p>
&lt;blockquote>
&lt;p>通过对比 RDMA 规范和软件协议栈，可以发现很多 verbs 接口并不是按照规范实现的。所以读者如果发现软件 API 和协议有差异时也无须感到疑惑，RDMA 技术本身一直还在演进，软件框架也处于活跃更新的状态。如果更关心编程实现，那么请以软件协议栈的 API 文档为准；如果更关心学术上的研究，那么请以 RDMA 规范为准。&lt;/p>
&lt;/blockquote>
&lt;h3 id="数据面">数据面&lt;/h3>
&lt;p>CQE 是硬件将信息传递给软件的媒介，虽然软件知道在什么情况下会产生 CQE，但是软件并不知道具体什么时候硬件会把 CQE 放到 CQ 中。在通信和计算机领域，我们把这种接收方不知道发送方什么时候发送的模式称为“异步”。我们先来举一个网卡的例子，再来说明用户如何通过数据面接口获取 CQE（WC）。&lt;/p>
&lt;p>网卡收到数据包后如何让 CPU 知道这件事，并进行数据包处理，有两种常见的模式：&lt;/p>
&lt;ul>
&lt;li>中断模式&lt;/li>
&lt;/ul>
&lt;p>当数据量较少，或者说偶发的数据交换较多时，适合采用中断模式——即 CPU 平常在做其他事情，当网卡收到数据包时，会上报中断打断 CPU 当前的任务，CPU 转而来处理数据包（比如 TCP/IP 协议栈的各层解析）。处理完数据之后，CPU 跳回到中断前的任务继续执行。&lt;/p>
&lt;p>每次中断都需要保护现场，也就是把当前各个寄存器的值、局部变量的值等等保存到栈中，回来之后再恢复现场（出栈），这本身是有开销的。如果业务负载较重，网卡一直都在接收数据包，那么 CPU 就会一直收到中断，CPU 将一直忙于中断切换，导致其他任务得不到调度。&lt;/p>
&lt;ul>
&lt;li>轮询模式&lt;/li>
&lt;/ul>
&lt;p>所以除了中断模式之外，网卡还有一种轮询模式，即收到数据包后都先放到缓冲区里，CPU 每隔一段时间会去检查网卡是否受到数据。如果有数据，就把缓冲区里的数据一波带走进行处理，没有的话就接着处理别的任务。&lt;/p>
&lt;p>通过对比中断模式我们可以发现，轮询模式虽然每隔一段时间需要 CPU 检查一次，带来了一定的开销，但是当业务繁忙的时候采用轮询模式能够极大的减少中断上下文的切换次数，反而减轻了 CPU 的负担。&lt;/p>
&lt;p>现在的网卡，一般都是中断+轮询的方式，也就是根据业务负载动态切换。&lt;/p>
&lt;p>在 RDMA 协议中，CQE 就相当于是网卡收到的数据包，RDMA 硬件把它传递给 CPU 去处理。RDMA 框架定义了两种对上层的接口，分别是 poll 和 notify，对应着轮询和中断模式。&lt;/p>
&lt;h3 id="poll-completion-queue">Poll completion queue&lt;/h3>
&lt;p>很直白，poll 就是轮询的意思。用户调用这个接口之后，CPU 就会定期去检查 CQ 里面是否有新鲜的 CQE，如果有的话，就取出这个 CQE（注意取出之后 CQE 就被“消耗”掉了），解析其中的信息并返回给上层用户。&lt;/p>
&lt;h3 id="request-completion-notification">Request completion notification&lt;/h3>
&lt;p>直译过来是请求完成通知，用户调用这个接口之后，相当于向系统注册了一个中断。这样当硬件将 CQE 放到 CQ 中后，会立即触发一个中断给 CPU，CPU 进而就会停止手上的工作取出 CQE，处理后返回给用户。&lt;/p>
&lt;p>同样的，这两种接口使用哪种，取决于用户对于实时性的要求，以及实际业务的繁忙程度。&lt;/p>
&lt;p>感谢阅读，CQ 就介绍到这里，下篇打算详细讲讲 SRQ。&lt;/p>
&lt;h2 id="协议相关章节">协议相关章节&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>9.9 CQ 错误检测和恢复&lt;/p>
&lt;/li>
&lt;li>
&lt;p>10.2.6 CQ 和 WQ 的关系&lt;/p>
&lt;/li>
&lt;li>
&lt;p>10.10 错误类型及其处理&lt;/p>
&lt;/li>
&lt;li>
&lt;p>11.2.8 CQ 相关控制面接口&lt;/p>
&lt;/li>
&lt;li>
&lt;p>11.4.2 CQ 相关数据面接口&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="其他参考资料">其他参考资料&lt;/h2>
&lt;p>[1] Linux Kernel Networking - Implement and Theory. Chapter 13. Completion Queue&lt;/p></description></item><item><title>RDMA 之 Queue Pair</title><link>https://cuterwrite.top/p/rdma-queue-pair/</link><pubDate>Tue, 25 Jun 2024 02:21:00 +0000</pubDate><guid>https://cuterwrite.top/p/rdma-queue-pair/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-16_116342820_p0_master1200.webp" alt="Featured image of post RDMA 之 Queue Pair" />&lt;h1 id="rdma-之-queue-pair">RDMA 之 Queue Pair&lt;/h1>
&lt;p>&lt;strong>本文欢迎非商业转载，转载请注明出处。&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>声明：仅用于收藏，便于阅读&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/195757767">&lt;cite>知乎专栏：9. RDMA 基本服务类型&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;h2 id="queue-pair">Queue Pair&lt;/h2>
&lt;p>我们曾经在 &lt;a class="link" href="https://cuterwrite.top/p/rdma-element/" >“3. RDMA 基本元素”
&lt;/a>
一文中简单的介绍了 QP 的概念，本文将更深入的讲解一些关于 QP 的细节。&lt;/p>
&lt;h2 id="基本概念回顾">基本概念回顾&lt;/h2>
&lt;p>首先我们来简单回顾下关于 QP 的基础知识：&lt;/p>
&lt;p>根据 IB 协议中的描述，QP 是硬件和软件之间的一个虚拟接口。QP 是队列结构，按顺序存储着软件给硬件下发的任务（WQE），WQE 中包含从哪里取出多长的数据，并且发送给哪个目的地等等信息。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-26_9_1.webp"
alt="2024-06-26_9_1" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>QP 的概念&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>每个 QP 间都是独立的，彼此通过 PD 隔离，因此一个 QP 可以被视为某个用户独占的一种资源，一个用户也可以同时使用多个 QP。&lt;/p>
&lt;p>QP 有很多种服务类型，包括 RC、UD、RD 和 UC 等，所有的源 QP 和目的 QP 必须为同一种类型才能进行数据交互。&lt;/p>
&lt;p>虽然 IB 协议将 QP 称为“虚拟接口”，但是它是有实体的：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>硬件上，QP 是一段包含着若干个 WQE 的存储空间，IB 网卡会从这段空间中读取 WQE 的内容，并按照用户的期望去内存中存取数据。至于这个存储空间是内存空间还是 IB 网卡的片内存储空间，IB 协议并未做出限制，每个厂商有各自的实现&lt;/p>
&lt;/li>
&lt;li>
&lt;p>软件上，QP 是一个由 IB 网卡的驱动程序所维护的数据结构，其中包含 QP 的地址指针以及一些相关的软件属性。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="qpc">QPC&lt;/h3>
&lt;p>&lt;a class="link" href="https://cuterwrite.top/p/rdma-service-types/" >“5. RDMA 基本服务类型”
&lt;/a>
一文中，我们曾经提到过 QPC 全称是 Queue Pair Context，用于存储 QP 相关属性。驱动程序里面是有储存 QP 的软件属性的，既然我们可以在软件里储存 QP 的属性，为什么还要用使用 QPC 呢？&lt;/p>
&lt;p>这是因为&lt;strong>QPC 主要是给硬件看的，也会用来在软硬件之间同步 QP 的信息。&lt;/strong>&lt;/p>
&lt;p>我们说过 QP 在硬件上的实体只是一段存储空间而已，硬件除了知道这段空间的起始地址和大小之外一无所知，甚至连这个 QP 服务类型都不知道。还有很多其他的重要信息，比如某个 QP 中包含了若干个 WQE，硬件怎么知道有多少个，当前应该处理第几个呢？&lt;/p>
&lt;p>所有上述的这些信息，软件是可以设计一定的数据结构并为其申请内存空间的，但是软件看到的都是虚拟地址，这些内存空间在物理上是离散的，硬件并不知道这些数据存放到了哪里。所以就需要软件通过操作系统提前申请好一大片连续的空间，即 QPC 来承载这些信息给硬件看。网卡及其配套的驱动程序提前约定好了 QPC 中都有哪些内容，这些内容分别占据多少空间，按照什么顺序存放。这样驱动和硬件就可以通过通过 QPC 这段空间来读写 QP 的状态等等信息。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-26_9_2_QPC.webp"
alt="2024-06-26_9_2" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>QPC 的概念&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>如上图所示，硬件其实只需要知道 QPC 的地址 0x12350000 就可以了，因为它可以解析 QPC 的内容，从而得知 QP 的位置，QP 序号，QP 大小等等信息。进而就能找到 QP，知道应该取第几个 WQE 去处理。不同的厂商可能实现有些差异，但是大致的原理就是这样。&lt;/p>
&lt;p>IB 软件栈中还有很多 Context 的概念，除了 QPC 之外，还有 Device Context，SRQC，CQC，EQC（Event Queue Context，事件队列上下文）等，它们的作用与 QPC 类似，都是用来在记录和同步某种资源的相关属性。&lt;/p>
&lt;h3 id="qp-number">QP Number&lt;/h3>
&lt;p>简称为 QPN，就是每个 QP 的编号。IB 协议中规定用 $2^{24}$ 个 bit 来表示 QPN，即每个节点最大可以同时使用 $2^{24}$ 个 QP，这已经是一个很大的数量了，几乎不可能用完。每个节点都各自维护着 QPN 的集合，相互之间是独立的，即不同的节点上可以存在编号相同的 QP。&lt;/p>
&lt;p>QPN 的概念本身非常简单，但是有两个特殊的保留编号需要额外注意一下：&lt;/p>
&lt;h4 id="qp0">QP0&lt;/h4>
&lt;p>编号为 0 的 QP 用于子网管理接口 SMI（Subnet Management Interface），用于管理子网中的全部节点，说实话我也还没搞清楚这个接口的作用，暂且按下不表。&lt;/p>
&lt;h4 id="qp1">QP1&lt;/h4>
&lt;p>编号为 1 的 QP 用于通用服务接口 GSI（General Service Interface），GSI 是一组管理服务，其中最出名的就是 CM（Communication Management），是一种在通信双方节点正式建立连接之前用来交换必须信息的一种方式。其细节将在后面的文章中专门展开介绍。&lt;/p>
&lt;p>这也就是我们之前的文章画的关于 QP 的图中，没有出现过 QP0 和 QP1 的原因了。这两个 QP 之外的其他 QP 就都是普通 QP 了。用户在创建 QP 的时候，驱动或者硬件会给这个新 QP 分配一个 QPN，一般的 QPN 都是 2、3、4 这样按顺序分配的。当 QP 被销毁之后，它的 QPN 也会被重新回收，并在合适的时候分配给其他新创建的 QP。&lt;/p>
&lt;h2 id="用户接口">用户接口&lt;/h2>
&lt;p>我们从控制层面和数据层面来分类介绍用户接口，控制面即用户对某种资源进行某种设置，一般都是在正式收发数据之前进行；而数据面自然就是真正的数据收发过程中进行的操作。&lt;/p>
&lt;h3 id="控制面">控制面&lt;/h3>
&lt;p>接触过算法的读者应该都了解，链表的节点涉及到“增、删、改、查”四个操作，链表的节点是一片内存区域，是一种软件资源。&lt;/p>
&lt;p>“增”即向操作系统申请一片内存用来存放数据，系统将在内存中划分一块空间，并将其标记为“已被进程 XX 使用”，其他没有权限的进程将无法覆盖甚至读取这片内存空间。&lt;/p>
&lt;p>“删”即通知操作系统，这片空间我不使用了，可以标记成“未使用”并给其它进程使用了。&lt;/p>
&lt;p>“改”就是写，即修改这片内存区域的内容。&lt;/p>
&lt;p>&amp;ldquo;查&amp;quot;就是读，即获取这片内存区域的内容。&lt;/p>
&lt;p>QP 作为 RDMA 技术中最重要的一种资源，在生命周期上与链表并无二致：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>操作&lt;/th>
&lt;th>链表节点&lt;/th>
&lt;th>QP&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>增&lt;/td>
&lt;td>struct ListNode *node = malloc(sizeof(struct ListNode *));&lt;/td>
&lt;td>Create QP&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>删&lt;/td>
&lt;td>free(node);&lt;/td>
&lt;td>Destroy QP&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>改&lt;/td>
&lt;td>node-&amp;gt;val = xxx;&lt;/td>
&lt;td>Modify QP&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>查&lt;/td>
&lt;td>xxx = node-&amp;gt;val;&lt;/td>
&lt;td>Query QP&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>这四种操作，其实就是 Verbs（RDMA 对上层应用的 API）在控制面上对上层用户提供给用户的几个接口：&lt;/p>
&lt;h4 id="create-qp">Create QP&lt;/h4>
&lt;p>创建一个 QP 的软硬件资源，包含 QP 本身以及 QPC。用户创建时会写传入一系列的初始化属性，包含该 QP 的服务类型，可以储存的 WQE 数量等信息&lt;/p>
&lt;h4 id="destroy-qp">Destroy QP&lt;/h4>
&lt;p>释放一个 QP 的全部软硬件资源，包含 QP 本身及 QPC。销毁 QP 后，用户将无法通过 QPN 索引到这个 QP。&lt;/p>
&lt;h4 id="modify-qp">Modify QP&lt;/h4>
&lt;p>修改一个 QP 的某些属性，比如 QP 的状态，路径的 MTU 等等。这个修改过程既包括软件数据结构的修改，也包括对 QPC 的修改。&lt;/p>
&lt;h4 id="query-qp">Query QP&lt;/h4>
&lt;p>查询一个 QP 当前的状态和一些属性，查询到的数据来源于驱动以及 QPC 的内容。&lt;/p>
&lt;p>这四种操作都有配套的 Verbs 接口，类似于 &lt;code>ibv_create_qp()&lt;/code> 这种形式，我们编写 APP 时直接调用就可以了。更多关于对上层的 API 的细节，我们将在后面专门进行介绍。&lt;/p>
&lt;h2 id="数据面">数据面&lt;/h2>
&lt;p>数据面上，一个 QP 对上层的接口其实只有两种，分别用于向 QP 中填写发送和接收请求。&lt;strong>这里的“发送”和“接收”并不是指的发送和接收数据，而是指的是一次通信过程的“发起方”（Requestor）和“接收方”（Responser）&lt;/strong>。&lt;/p>
&lt;p>在行为上都是软件向 QP 中填写一个 WQE（对应用层来说叫 WR），请求硬件执行一个动作。所以这两种行为都叫做“Post XXX Request”的形式，即下发 XXX 请求。&lt;/p>
&lt;h3 id="post-send-request">Post Send Request&lt;/h3>
&lt;p>再强调一下，Post Send 本身不是指这个 WQE 的操作类型是 Send，而是表示这个 WQE 属于通信发起方。这个流程中填写到 QP 中的 WQE/WR 可以是 Send 操作，RDMA Write 操作以及 RDMA Read 操作等。&lt;/p>
&lt;p>用户需要提前准备好数据缓冲区、目的地址等信息，然后调用接口将 WR 传给驱动，驱动再把 WQE 填写到 QP 中。&lt;/p>
&lt;h3 id="post-receive-request">Post Receive Request&lt;/h3>
&lt;p>Post Recv 的使用场景就相对比较少了，一般只在 Send-Recv 操作的接收端执行，接收端需要提前准备好接收数据的缓冲区，并将缓冲区地址等信息以 WQE 的形式告知硬件。&lt;/p>
&lt;h2 id="qp-状态机">QP 状态机&lt;/h2>
&lt;p>说到 QP 的状态，就不得不祭出下面这张图（取自 IB 协议 10.3.1 节）：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-26_9_3.webp"
alt="2024-06-26_9_3" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>QP 状态机&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>所谓状态机，就是描述一个对象的不同状态，以及触发状态间跳转的条件。为一个对象设计状态机可以使这个对象的生命周期变得非常明确，实现上也会使得逻辑更加清晰。&lt;/p>
&lt;p>对于 QP 来说，IB 规范也为其设计了几种状态，处于不同状态的 QP 的功能是有差异的，比如只有进入到 Ready to Send 状态之后，QP 才能够进行 Post Send 数据操作。正常状态（绿色的）之间的状态转换都是由用户通过上文介绍的 Modify QP 的用户接口来主动触发的；而错误状态（红色的）往往是出错之后自动跳转的，当一个 QP 处于错误状态之后就无法执行正常的业务了，就需要上层通过 Modify QP 将其重新配置到正常状态上。&lt;/p>
&lt;p>上图中我们只关注 QP 的部分，EE（End-to-End Context）是专门给 RD 服务类型使用的一个概念，我们暂不涉及。我们通过 Create QP 接口来进入这个状态图，通过 Destroy QP 接口来离开这个状态图。&lt;/p>
&lt;p>QP 有以下几种状态，我们仅介绍一下比较重要的点：&lt;/p>
&lt;h3 id="rstreset">RST（Reset）&lt;/h3>
&lt;p>复位状态。当一个 QP 通过 Create QP 创建好之后就处于这个状态，相关的资源都已经申请好了，但是这个 QP 目前什么都做不了，其无法接收用户下发的 WQE，也无法接受对端某个 QP 的消息。&lt;/p>
&lt;h3 id="initinitialized">INIT（Initialized）&lt;/h3>
&lt;p>已初始化状态。这个状态下，用户可以通过 Post Receive 给这个 QP 下发 Receive WR，但是接收到的消息并不会被处理，会被静默丢弃；如果用户下发了一个 Post Send 的 WR，则会报错。&lt;/p>
&lt;h3 id="rtrready-to-receive">RTR（Ready to Receive）&lt;/h3>
&lt;p>准备接收状态。在 INIT 状态的基础上，RQ 可以正常工作，即对于接收到的消息，可以按照其中 WQE 的指示搬移数据到指定内存位置。此状态下 SQ 仍然不能工作。&lt;/p>
&lt;h3 id="rtsready-to-send">RTS（Ready to Send）&lt;/h3>
&lt;p>准备发送状态。在 RTR 基础上，SQ 可以正常工作，即用户可以进行 Post Send，并且硬件也会根据 SQ 的内容将数据发送出去。进入该状态前，QP 必须已于对端建立好链接。&lt;/p>
&lt;h3 id="sqdsend-queue-drain">SQD（Send Queue Drain）&lt;/h3>
&lt;p>SQ 排空状态。顾名思义，该状态会将 SQ 队列中现存的未处理的 WQE 全部处理掉，这个时候用户还可以下发新的 WQE 下来，但是这些 WQE 要等到旧的 WQE 全处理之后才会被处理。&lt;/p>
&lt;h3 id="sqersend-queue-error">SQEr（Send Queue Error）&lt;/h3>
&lt;p>SQ 错误状态。当某个 Send WR 发生完成错误（即硬件通过 CQE 告知驱动发生的错误）时，会导致 QP 进入此状态。&lt;/p>
&lt;h3 id="errerror">ERR（Error）&lt;/h3>
&lt;p>即错误状态。其他状态如果发生了错误，都可能进入该状态。Error 状态时，QP 会停止处理 WQE，已经处理到一半的 WQE 也会停止。上层需要在修复错误后再将 QP 重新切换到 RST 的初始状态。&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>本文先回顾了 QP 的一些重要基本概念，然后讲解了 QPC、QPN 等 QP 强相关的概念，最后介绍了用户操作 QP 常用的接口以及 QP 状态机，相信本文过后读者一定对 QP 有了更深的了解。&lt;/p>
&lt;p>其实作为 RDMA 的核心概念，QP 的内容很多，本文难以全部囊括。我将在后面的文章中逐渐把相关的内容补全，比如 QKey 的概念将在后续专门介绍各种 Key 的文章中讲解。&lt;/p>
&lt;p>好了，本文就到这了，感谢阅读。预告下一篇文章将详细讲解 CQ。&lt;/p>
&lt;h2 id="协议相关章节">协议相关章节&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>3.5.1 10.2.4 QP 的基本概念&lt;/p>
&lt;/li>
&lt;li>
&lt;p>10.3 QP 状态机&lt;/p>
&lt;/li>
&lt;li>
&lt;p>10.2.5 QP 相关的软件接口&lt;/p>
&lt;/li>
&lt;li>
&lt;p>11.4 Post Send Post Recv&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>基于 Workbox 实现 Hugo 渐进式 Web 应用</title><link>https://cuterwrite.top/p/hugo-pwa/</link><pubDate>Tue, 18 Jun 2024 22:28:00 +0000</pubDate><guid>https://cuterwrite.top/p/hugo-pwa/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-16_116406967_p0_master1200.webp" alt="Featured image of post 基于 Workbox 实现 Hugo 渐进式 Web 应用" />&lt;h1 id="基于-workbox-实现-hugo-pwa">基于 Workbox 实现 Hugo PWA&lt;/h1>
&lt;p>最近给基于 &lt;a class="link" href="https://gohugo.io/" target="_blank" rel="noopener" >Hugo
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
搭建的博客添加了 PWA 功能，显著提升了加载速度和用户体验，甚至实现了离线访问。至于如何实现，那么你需要了解 &lt;strong>Progressive Web Apps (PWA)&lt;/strong>。&lt;/p>
&lt;h2 id="什么是-pwa">什么是 PWA&lt;/h2>
&lt;p>渐进式 Web 应用（Progressive Web Apps，简称 PWA）利用现代 Web API 和传统的渐进式增强策略，打造出跨平台的 Web 应用程序。这些应用无处不在，功能丰富，为用户带来媲美原生应用的体验。&lt;/p>
&lt;p>&lt;strong>PWA 的优势：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>⚡️ &lt;strong>更快的加载速度&lt;/strong>: PWA 可以缓存重要资源，即使网络状况不佳也能快速加载。&lt;/li>
&lt;li>✈️ &lt;strong>离线访问&lt;/strong>: PWA 可以缓存内容，让用户即使离线也能访问内容。&lt;/li>
&lt;li>🔔 &lt;strong>推送通知&lt;/strong>: 像原生应用一样，PWA 可以向用户发送推送通知，提高用户参与度。&lt;/li>
&lt;li>📱 &lt;strong>安装到主屏幕&lt;/strong>: 用户可以将你的应用添加到电脑或手机桌面，像原生应用一样浏览你的 Web 应用。&lt;/li>
&lt;/ul>
&lt;p>PWA 的实现原理是 &lt;strong>Service Worker&lt;/strong>。&lt;strong>Service Worker 是一种特殊的 JavaScript 资源，在浏览器后台独立运行，充当着网络浏览器和 Web 服务器之间的代理。它可以拦截和处理网络请求、缓存资源以及推送通知&lt;/strong>。&lt;/p>
&lt;p>主流的前端框架 Vue、React、Angular 都提供了相应的 PWA 插件。而对于 Hugo 这样的静态网站生成器，我们可以通过手动添加 &lt;a class="link" href="https://developer.chrome.com/docs/workbox" target="_blank" rel="noopener" >Workbox
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
来实现 PWA 功能。&lt;/p>
&lt;h2 id="workbox">Workbox&lt;/h2>
&lt;p>&lt;a class="link" href="https://developer.chrome.com/docs/workbox" target="_blank" rel="noopener" >Workbox
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
是由 Google Chrome 团队开发的一套模块，旨在简化常见的 Service Worker 路由和缓存操作。每个模块都针对 Service Worker 开发的特定方面进行了优化。Workbox 的目标是尽可能简化 Service Worker 的使用，同时在需要时灵活地满足复杂应用的需求。&lt;/p>
&lt;p>如果没有 Workbox，我们需要手动编写 Service Worker 来监听 fetch 事件、缓存资源并实现离线访问等功能。而 Workbox 提供了一套工具，可以帮助我们自动生成 Service Worker，并且内置了一些常用的缓存策略，使我们能够更加专注于业务逻辑。&lt;/p>
&lt;h2 id="配置-pwa">配置 PWA&lt;/h2>
&lt;p>在上一节中，我们了解了 PWA 的概念和优势，以及 Workbox 如何简化 Service Worker 的开发。接下来将一步步地给 Hugo 博客配置 PWA 功能。&lt;/p>
&lt;h3 id="注册-service-worker">注册 Service Worker&lt;/h3>
&lt;p>首先，我们需要在页面中注册 Service Worker。将以下代码段添加到你的 Hugo 主题的 &lt;code>layouts/partials/footer/custom.html&lt;/code> 文件中（其他主题可能需要根据文件结构进行调整）：&lt;/p>
&lt;pre>&lt;code class="language-javascript">&amp;lt;script&amp;gt;
// Check that service workers are registered
if ('serviceWorker' in navigator) {
// Use the window load event to keep the page load performant
window.addEventListener('load', () =&amp;gt; {
navigator.serviceWorker.register('/sw.js').then(reg =&amp;gt; {
console.log('Service worker registered with scope: ', reg.scope);
}, err =&amp;gt; {
console.log('Service worker registration failed: ', err);
});
});
}
&amp;lt;/script&amp;gt;
&lt;/code>&lt;/pre>
&lt;div class="notice notice-tip" >
&lt;div class="notice-title">&lt;svg t="1705945832245" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="19409" width="200" height="200">&lt;path d="M512 74.666667C270.933333 74.666667 74.666667 270.933333 74.666667 512S270.933333 949.333333 512 949.333333 949.333333 753.066667 949.333333 512 753.066667 74.666667 512 74.666667z m238.933333 349.866666l-2.133333 2.133334-277.333333 277.333333c-10.666667 10.666667-29.866667 12.8-42.666667 2.133333L426.666667 704l-149.333334-149.333333c-12.8-12.8-12.8-32 0-44.8 10.666667-10.666667 29.866667-12.8 42.666667-2.133334l2.133333 2.133334 125.866667 125.866666 253.866667-253.866666c10.666667-10.666667 29.866667-12.8 42.666666-2.133334l2.133334 2.133334c12.8 12.8 12.8 32 4.266666 42.666666z" fill="#ffffff" p-id="19410">&lt;/path>&lt;/svg>&lt;/div>&lt;p>注意： 在注册 Service Worker 之前，你需要先创建 &lt;code>sw.js&lt;/code> 文件，我们将在下一小节中完成这一步骤。&lt;/p>&lt;/div>
&lt;p>完成注册后，你可以在浏览器的开发者工具 (F12) 中的 &lt;strong>&amp;ldquo;Application&amp;rdquo; -&amp;gt; &amp;ldquo;Service Workers&amp;rdquo;&lt;/strong> 面板中查看 Service Worker 的注册状态。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-19_service-worker.webp"
alt="Service Worker" width="90%" loading="lazy">&lt;figcaption>
&lt;h4>Service Worker&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;h3 id="导入-workbox">导入 Workbox&lt;/h3>
&lt;p>在你的 Hugo 网站根目录下的 &lt;code>static&lt;/code> 文件夹中创建 &lt;code>sw.js&lt;/code> 文件。然后，在 &lt;code>sw.js&lt;/code> 文件中添加以下代码，使用 CDN 导入 Workbox：&lt;/p>
&lt;pre>&lt;code class="language-javascript">importScripts('https://cdn.bootcdn.net/ajax/libs/workbox-sw/7.1.0/workbox-sw.js');
&lt;/code>&lt;/pre>
&lt;h3 id="缓存策略">缓存策略&lt;/h3>
&lt;p>Workbox 提供了一些常用的缓存策略，如 &lt;code>CacheFirst&lt;/code>、&lt;code>NetworkFirst&lt;/code>、&lt;code>StaleWhileRevalidate&lt;/code> 等。这里先介绍几种常用的策略。&lt;/p>
&lt;h4 id="cacheonly-仅缓存">CacheOnly 仅缓存&lt;/h4>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-19_cache-6850d07d742bf_1440.webp"
alt="CacheOnly" width="90%" loading="lazy">&lt;figcaption>
&lt;h4>CacheOnly&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>强制响应来自缓存。&lt;/p>
&lt;pre>&lt;code class="language-javascript">workbox.routing.registerRoute(
new RegExp(regex),
new workbox.strategies.CacheOnly()
);
&lt;/code>&lt;/pre>
&lt;h4 id="networkonly-仅网络">NetworkOnly 仅网络&lt;/h4>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-19_network-48f46158a5575_1440.webp"
alt="NetworkOnly" width="90%" loading="lazy">&lt;figcaption>
&lt;h4>NetworkOnly&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>这种缓存策略强制要求所有请求都从网络获取最新数据，完全绕过缓存。&lt;/p>
&lt;pre>&lt;code class="language-javascript">workbox.routing.registerRoute(
new RegExp(regex),
new workbox.strategies.NetworkOnly()
);
&lt;/code>&lt;/pre>
&lt;h4 id="cachefirst-优先缓存">CacheFirst 优先缓存&lt;/h4>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-19_cache-falling-to-networ-f4c1aa5570621_1440.webp"
alt="CacheFirst" width="90%" loading="lazy">&lt;figcaption>
&lt;h4>CacheFirst&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>这种缓存策略以速度为优先，会首先尝试从缓存中获取响应，以尽快向用户显示内容。如果缓存中没有所需数据，它才会向网络发起请求获取数据。&lt;/p>
&lt;pre>&lt;code class="language-javascript">workbox.routing.registerRoute(
new RegExp(regex),
new workbox.strategies.CacheFirst()
);
&lt;/code>&lt;/pre>
&lt;h4 id="networkfirst-优先网络">NetworkFirst 优先网络&lt;/h4>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-19_network-falling-to-cache-39d267a044b35_1440.webp"
alt="NetworkFirst" width="90%" loading="lazy">&lt;figcaption>
&lt;h4>NetworkFirst&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>这种缓存策略优先使用最新数据，因此会首先尝试从网络获取响应。如果网络请求失败，例如用户离线或网络连接不稳定，它会回退使用缓存中的数据，确保用户仍然可以访问内容。&lt;/p>
&lt;pre>&lt;code class="language-javascript">workbox.routing.registerRoute(
new RegExp(regex),
new workbox.strategies.NetworkFirst()
);
&lt;/code>&lt;/pre>
&lt;h4 id="stalewhilerevalidate-读取缓存同时发起网络请求">StaleWhileRevalidate 读取缓存，同时发起网络请求&lt;/h4>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-19_cache-network-873b1ec5f25cc_1440.webp"
alt="StaleWhileRevalidate" width="90%" loading="lazy">&lt;figcaption>
&lt;h4>StaleWhileRevalidate&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>这种缓存策略优先返回缓存内容（如果有）。即使缓存内容有效，它也会在后台发起网络请求以获取最新数据，保证用户最终能看到最新内容。虽然这种策略能确保用户定期更新缓存，但也意味着每次请求都会产生网络流量，即使数据没有变化，也比较浪费带宽。&lt;/p>
&lt;pre>&lt;code class="language-javascript">workbox.routing.registerRoute(
new RegExp(regex),
new workbox.strategies.StaleWhileRevalidate()
);
&lt;/code>&lt;/pre>
&lt;h4 id="策略配置">策略配置&lt;/h4>
&lt;p>Workbox 不仅提供上述策略，还允许通过 cacheName、plugins 和 expiration 等配置项进行自定义。你可以通过定义要使用的插件来自定义路由行为。例如，你可以配置缓存名称、缓存有效期以及可缓存的响应状态码，如下所示：&lt;/p>
&lt;pre>&lt;code class="language-javascript">workbox.routing.registerRoute(
new RegExp(regex),
new workbox.strategies.CacheFirst({
cacheName: 'my-cache',
plugins: [
new workbox.expiration.ExpirationPlugin({
maxEntries: 60,
maxAgeSeconds: 30 * 24 * 60 * 60, // 30 Days
}),
new workbox.cacheableResponse.CacheableResponsePlugin({
statuses: [0, 200],
}),
],
})
);
&lt;/code>&lt;/pre>
&lt;h3 id="本站配置">本站配置&lt;/h3>
&lt;h4 id="全局配置">全局配置&lt;/h4>
&lt;p>以下是全局缓存配置：&lt;/p>
&lt;pre>&lt;code class="language-javascript">// 缓存版本号
let cacheVersion = '-240619';
// 最大条目数
const maxEntries = 100;
&lt;/code>&lt;/pre>
&lt;h4 id="twitto-配置">Twitto 配置&lt;/h4>
&lt;p>为了确保用户即使在离线状态下也能查看评论，Twitto 评论 API 采用了 &lt;code>NetworkFirst&lt;/code> 缓存策略。这意味着浏览器会优先尝试从网络获取最新数据，如果网络不可用，则使用缓存中的数据。&lt;/p>
&lt;pre>&lt;code class="language-javascript">workbox.routing.registerRoute(
new RegExp('^https://comment\.cuterwrite\.top'),
new workbox.strategies.NetworkFirst({
plugins: [
new workbox.expiration.ExpirationPlugin({
maxEntries: maxEntries,
maxAgeSeconds: 30 * 24 * 60 * 60,
}),
new workbox.cacheableResponse.CacheableResponsePlugin({
statuses: [0, 200],
}),
],
})
);
&lt;/code>&lt;/pre>
&lt;h4 id="rss-与-sitemap-配置">RSS 与 Sitemap 配置&lt;/h4>
&lt;p>为了确保用户始终获取最新的 RSS 和 Sitemap 数据，这些页面配置为仅使用网络策略 (&lt;code>NetworkOnly&lt;/code>)，不进行缓存。&lt;/p>
&lt;pre>&lt;code class="language-javascript">workbox.routing.registerRoute(
new RegExp('^https://cuterwrite\.top/(index|sitemap)\.xml'),
new workbox.strategies.NetworkOnly()
);
&lt;/code>&lt;/pre>
&lt;h4 id="html-配置">HTML 配置&lt;/h4>
&lt;p>为了在保证用户快速加载页面的同时，也能获取到最新内容，网站对 HTML 页面采用了 &lt;code>StaleWhileRevalidate&lt;/code> 缓存策略。这意味着浏览器会优先使用缓存中的页面进行展示，同时在后台向服务器发起请求，获取最新版本，并在下次请求时使用。&lt;/p>
&lt;pre>&lt;code class="language-javascript">workbox.routing.registerRoute(
new RegExp('.*\.html'),
new workbox.strategies.StaleWhileRevalidate({
cacheName: 'html-cache' + cacheVersion,
plugins: [
new workbox.expiration.ExpirationPlugin({
maxEntries: maxEntries,
maxAgeSeconds: 30 * 24 * 60 * 60,
}),
new workbox.cacheableResponse.CacheableResponsePlugin({
statuses: [0, 200],
}),
],
})
);
&lt;/code>&lt;/pre>
&lt;h4 id="google-fonts-配置">Google Fonts 配置&lt;/h4>
&lt;p>为了在保证字体文件更新的同时，也能利用缓存加速页面加载速度，网站对 Google Fonts 资源采用了 &lt;code>CacheFirst&lt;/code> 缓存策略，并设置了较长的缓存过期时间。&lt;/p>
&lt;pre>&lt;code class="language-javascript">workbox.routing.registerRoute(
new RegExp('.*\.(?:woff|woff2|ttf|otf|eot)'),
new workbox.strategies.StaleWhileRevalidate({
cacheName: 'google-fonts' + cacheVersion,
plugins: [
// 使用 expiration 插件实现缓存条目数目和时间控制
new workbox.expiration.ExpirationPlugin({
// 最大缓存条目数
maxEntries: maxEntries,
// 最长缓存时间 30 天
maxAgeSeconds: 30 * 24 * 60 * 60,
}),
// 使用 cacheableResponse 插件缓存状态码为 0 的请求
new workbox.cacheableResponse.CacheableResponsePlugin({
statuses: [0, 200],
}),
],
})
);
&lt;/code>&lt;/pre>
&lt;h4 id="cdn-配置">CDN 配置&lt;/h4>
&lt;p>为了最大程度地利用缓存加速页面加载速度，网站对来自常用 CDN 的资源采用了 &lt;code>CacheFirst&lt;/code> 缓存策略，并设置了较长的缓存过期时间。&lt;/p>
&lt;pre>&lt;code class="language-javascript">workbox.routing.registerRoute(
new RegExp('^https://(?:cdn\.bootcdn\.net|unpkg\.com|cdn\.jsdelivr\.net)'),
new workbox.strategies.CacheFirst({
cacheName: 'cdn' + cacheVersion,
fetchOptions: {
mode: 'cors',
credentials: 'omit',
},
plugins: [
new workbox.expiration.ExpirationPlugin({
maxEntries: maxEntries,
maxAgeSeconds: 30 * 24 * 60 * 60,
}),
],
})
);
&lt;/code>&lt;/pre>
&lt;h4 id="umani-网站统计配置">Umani 网站统计配置&lt;/h4>
&lt;p>为了确保网站统计数据的准确性，网站对 Umani 网站统计请求采用了 &lt;code>NetworkOnly&lt;/code> 策略，并使用 &lt;code>BackgroundSyncPlugin&lt;/code> 插件来实现即使在网络离线的情况下也能保证数据最终发送成功。&lt;/p>
&lt;pre>&lt;code class="language-javascript">workbox.routing.registerRoute(
new RegExp('^https://analytics\.cuterwrite\.top/uma'),
new workbox.strategies.NetworkOnly({
plugins: [
// 使用 background sync 插件实现后台同步
new workbox.backgroundSync.BackgroundSyncPlugin('Optical_Collect', {
maxRetentionTime: 12 * 60,
}),
],
})
);
&lt;/code>&lt;/pre>
&lt;h4 id="图片配置">图片配置&lt;/h4>
&lt;p>为了加速图片加载速度，并减少网络请求次数，网站对图片资源采用了 &lt;code>CacheFirst&lt;/code> 缓存策略，并设置了较长的缓存过期时间。&lt;/p>
&lt;pre>&lt;code class="language-javascript">workbox.routing.registerRoute(
new RegExp('^(https://cuterwrite-1302252842\.file\.myqcloud\.com|https://s2\.loli\.net)'),
new workbox.strategies.CacheFirst({
cacheName: 'image-cache' + cacheVersion,
plugins: [
new workbox.expiration.ExpirationPlugin({
maxEntries: maxEntries,
maxAgeSeconds: 30 * 24 * 60 * 60,
}),
new workbox.cacheableResponse.CacheableResponsePlugin({
statuses: [0, 200],
}),
],
})
);
&lt;/code>&lt;/pre>
&lt;h4 id="后缀匹配配置">后缀匹配配置&lt;/h4>
&lt;p>为了兼顾加载速度和内容更新，网站对未被域名匹配到的静态文件（例如图片、CSS 和 JavaScript 文件）采用了 &lt;code>StaleWhileRevalidate&lt;/code> 缓存策略。&lt;/p>
&lt;pre>&lt;code class="language-javascript">workbox.routing.registerRoute(
new RegExp('.*\.(?:png|jpg|jpeg|svg|gif|webp|ico)'),
new workbox.strategies.StaleWhileRevalidate()
);
workbox.routing.registerRoute(
new RegExp('.*\.(css|js)'),
new workbox.strategies.StaleWhileRevalidate()
);
&lt;/code>&lt;/pre>
&lt;h4 id="默认行为配置">默认行为配置&lt;/h4>
&lt;p>为了处理未被任何自定义路由规则匹配到的请求，网站配置了默认缓存行为，使用 &lt;code>NetworkFirst&lt;/code> 策略并设置了网络超时时间，以兼顾资源获取速度和离线可用性。&lt;/p>
&lt;pre>&lt;code class="language-javascript">workbox.routing.setDefaultHandler(
// 优先使用缓存，缓存没有则使用网络请求
new workbox.strategies.NetworkFirst({
networkTimeoutSeconds: 3,
})
);
&lt;/code>&lt;/pre>
&lt;h3 id="完整配置">完整配置&lt;/h3>
&lt;details>
&lt;summary>sw.js&lt;/summary>
&lt;pre>&lt;code class="language-javascript">importScripts('https://cdn.bootcdn.net/ajax/libs/workbox-sw/7.1.0/workbox-sw.js');
// 缓存版本号
let cacheVersion = '-240619';
// 最大条目数
const maxEntries = 100;
if (workbox) {
console.log(`Yay! Workbox is loaded 🎉`);
// 评论缓存
workbox.routing.registerRoute(
new RegExp('^https://comment\.cuterwrite\.top'),
new workbox.strategies.NetworkFirst({
plugins: [
new workbox.expiration.ExpirationPlugin({
maxEntries: maxEntries,
maxAgeSeconds: 30 * 24 * 60 * 60,
}),
new workbox.cacheableResponse.CacheableResponsePlugin({
statuses: [0, 200],
}),
],
})
);
// rss 、sitemap 不缓存
workbox.routing.registerRoute(
new RegExp('^https://cuterwrite\.top/(index|sitemap)\.xml'),
new workbox.strategies.NetworkOnly()
);
// 缓存 HTML
workbox.routing.registerRoute(
new RegExp('.*\.html'),
new workbox.strategies.StaleWhileRevalidate({
cacheName: 'html-cache' + cacheVersion,
plugins: [
new workbox.expiration.ExpirationPlugin({
maxEntries: maxEntries,
maxAgeSeconds: 30 * 24 * 60 * 60,
}),
new workbox.cacheableResponse.CacheableResponsePlugin({
statuses: [0, 200],
}),
],
})
);
// 缓存 Google Fonts
workbox.routing.registerRoute(
new RegExp('.*\.(?:woff|woff2|ttf|otf|eot)'),
new workbox.strategies.StaleWhileRevalidate({
cacheName: 'google-fonts' + cacheVersion,
plugins: [
// 使用 expiration 插件实现缓存条目数目和时间控制
new workbox.expiration.ExpirationPlugin({
// 最大缓存条目数
maxEntries: maxEntries,
// 最长缓存时间 30 天
maxAgeSeconds: 30 * 24 * 60 * 60,
}),
// 使用 cacheableResponse 插件缓存状态码为 0 的请求
new workbox.cacheableResponse.CacheableResponsePlugin({
statuses: [0, 200],
}),
],
})
);
// 缓存 bootcdn、unpkg、jsdelivr 等公共库，用正则匹配
workbox.routing.registerRoute(
new RegExp('^https://(?:cdn\.bootcdn\.net|unpkg\.com|cdn\.jsdelivr\.net)'),
new workbox.strategies.CacheFirst({
cacheName: 'cdn' + cacheVersion,
fetchOptions: {
mode: 'cors',
credentials: 'omit',
},
plugins: [
new workbox.expiration.ExpirationPlugin({
maxEntries: maxEntries,
maxAgeSeconds: 30 * 24 * 60 * 60,
}),
],
})
);
// 自建 UMA 统计脚本: https://analytics.cuterwrite.top/uma
workbox.routing.registerRoute(
new RegExp('^https://analytics\.cuterwrite\.top/uma'),
new workbox.strategies.NetworkOnly({
plugins: [
// 使用 background sync 插件实现后台同步
new workbox.backgroundSync.BackgroundSyncPlugin('Optical_Collect', {
maxRetentionTime: 12 * 60,
}),
],
})
);
// 缓存存储桶图片 https://cuterwrite-1302252842.file.myqcloud.com/
workbox.routing.registerRoute(
new RegExp('^(https://cuterwrite-1302252842\.file\.myqcloud\.com|https://s2\.loli\.net)'),
new workbox.strategies.CacheFirst({
cacheName: 'image-cache' + cacheVersion,
plugins: [
new workbox.expiration.ExpirationPlugin({
maxEntries: maxEntries,
maxAgeSeconds: 30 * 24 * 60 * 60,
}),
new workbox.cacheableResponse.CacheableResponsePlugin({
statuses: [0, 200],
}),
],
})
);
// 后缀匹配，针对其余没有被域名匹配到的静态文件
workbox.routing.registerRoute(
new RegExp('.*\.(?:png|jpg|jpeg|svg|gif|webp|ico)'),
new workbox.strategies.StaleWhileRevalidate()
);
workbox.routing.registerRoute(
new RegExp('.*\.(css|js)'),
new workbox.strategies.StaleWhileRevalidate()
);
// 默认匹配剩下的请求
workbox.routing.setDefaultHandler(
// 优先使用缓存，缓存没有则使用网络请求
new workbox.strategies.NetworkFirst({
networkTimeoutSeconds: 3,
})
);
} else {
console.log(`Boo! Workbox didn't load 😬`);
}
&lt;/code>&lt;/pre>
&lt;/details>
&lt;h3 id="manifestjson">manifest.json&lt;/h3>
&lt;ol>
&lt;li>&lt;strong>创建 manifest.json 文件&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>在你的 Hugo 博客的根目录 &lt;code>static&lt;/code> 文件夹下创建 &lt;code>manifest.json&lt;/code> 文件，该文件包含了关于你的博客的元数据，例如名称、图标和显示选项。&lt;/p>
&lt;pre>&lt;code class="language-json">{
&amp;quot;name&amp;quot;: &amp;quot;你的博客名称&amp;quot;,
&amp;quot;short_name&amp;quot;: &amp;quot;博客简称&amp;quot;,
&amp;quot;start_url&amp;quot;: &amp;quot;/&amp;quot;,
&amp;quot;display&amp;quot;: &amp;quot;standalone&amp;quot;,
&amp;quot;background_color&amp;quot;: &amp;quot;#ffffff&amp;quot;,
&amp;quot;theme_color&amp;quot;: &amp;quot;#000000&amp;quot;,
&amp;quot;icons&amp;quot;: [{
&amp;quot;src&amp;quot;: &amp;quot;/icon-192x192.png&amp;quot;,
&amp;quot;sizes&amp;quot;: &amp;quot;192x192&amp;quot;,
&amp;quot;type&amp;quot;: &amp;quot;image/png&amp;quot;
},
{
&amp;quot;src&amp;quot;: &amp;quot;/icon-512x512.png&amp;quot;,
&amp;quot;sizes&amp;quot;: &amp;quot;512x512&amp;quot;,
&amp;quot;type&amp;quot;: &amp;quot;image/png&amp;quot;
}
]
}
&lt;/code>&lt;/pre>
&lt;div class="notice notice-tip" >
&lt;div class="notice-title">&lt;svg t="1705945832245" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="19409" width="200" height="200">&lt;path d="M512 74.666667C270.933333 74.666667 74.666667 270.933333 74.666667 512S270.933333 949.333333 512 949.333333 949.333333 753.066667 949.333333 512 753.066667 74.666667 512 74.666667z m238.933333 349.866666l-2.133333 2.133334-277.333333 277.333333c-10.666667 10.666667-29.866667 12.8-42.666667 2.133333L426.666667 704l-149.333334-149.333333c-12.8-12.8-12.8-32 0-44.8 10.666667-10.666667 29.866667-12.8 42.666667-2.133334l2.133333 2.133334 125.866667 125.866666 253.866667-253.866666c10.666667-10.666667 29.866667-12.8 42.666666-2.133334l2.133334 2.133334c12.8 12.8 12.8 32 4.266666 42.666666z" fill="#ffffff" p-id="19410">&lt;/path>&lt;/svg>&lt;/div>&lt;p>注意：将 icon-192x192.png 和 icon-512x512.png 替换为你自己的图标文件名。并确保将这两个图标文件放置在 Hugo 博客的 &lt;code>static&lt;/code> 文件夹中。如果你想修改主题颜色和背景颜色，可以修改 theme_color 和 background_color 字段。&lt;/p>&lt;/div>
&lt;ol start="2">
&lt;li>&lt;strong>链接 manifest.json 文件&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>在你的 Hugo 博客的 &lt;code>layouts/partials/head/custom.html&lt;/code> 文件中添加以下代码，将 &lt;code>manifest.json&lt;/code> 文件链接到你的网站：&lt;/p>
&lt;pre>&lt;code class="language-html">&amp;lt;link rel=&amp;quot;manifest&amp;quot; href=&amp;quot;/manifest.json&amp;quot;&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>完成以上步骤后，你的 Hugo 博客就具备了 PWA 功能，用户可以像使用原生应用程序一样访问你的网站。&lt;/p>
&lt;h2 id="参考资料">参考资料&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;a class="link" href="https://web.dev/articles/offline-cookbook?hl=zh-cn" target="_blank" rel="noopener" >离线实战宝典
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a class="link" href="https://developers.google.com/web/tools/workbox" target="_blank" rel="noopener" >Workbox
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a class="link" href="https://github.com/GoogleChrome/workbox" target="_blank" rel="noopener" >Workbox Github
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Ollama：从入门到进阶</title><link>https://cuterwrite.top/p/ollama/</link><pubDate>Sat, 15 Jun 2024 23:10:00 +0000</pubDate><guid>https://cuterwrite.top/p/ollama/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-16_116903387_p0_master1200.webp" alt="Featured image of post Ollama：从入门到进阶" />&lt;p>近年来，大型语言模型（LLM）以其强大的文本生成和理解能力，成为了人工智能领域的中坚力量。商业 LLM 的价格通常高昂且代码封闭，限制了研究者和开发者的探索空间。幸运的是，开源社区提供了像 Ollama 这样优秀的替代方案，让每个人都能够轻松体验 LLM 的魅力，并能结合 HPC 和 IDE 插件，打造更强大的个人助手。&lt;/p>
&lt;h2 id="什么是-ollama">什么是 Ollama？&lt;/h2>
&lt;p>Ollama 是一个用于构建大型语言模型应用的工具，它提供了一个简洁易用的命令行界面和服务器，让你能够轻松下载、运行和管理各种开源 LLM。与需要复杂配置和强大硬件的传统 LLM 不同，Ollama 让你能够方便地像使用手机 App 一样体验 LLM 的强大功能。&lt;/p>
&lt;h2 id="ollama-的优势">Ollama 的优势&lt;/h2>
&lt;p>Ollama 拥有以下显著优势：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>开源免费&lt;/strong>： Ollama 及其支持的模型完全开源免费，任何人都可以自由使用、修改和分发。&lt;/li>
&lt;li>&lt;strong>简单易用&lt;/strong>： 无需复杂的配置和安装过程，只需几条命令即可启动和运行 Ollama。&lt;/li>
&lt;li>&lt;strong>模型丰富&lt;/strong>： Ollama 支持 Llama 3、Mistral、Qwen2 等众多热门开源 LLM，并提供一键下载和切换功能。&lt;/li>
&lt;li>&lt;strong>资源占用低&lt;/strong>： 相比于商业 LLM，Ollama 对硬件要求更低，即使在普通笔记本电脑上也能流畅运行。&lt;/li>
&lt;li>&lt;strong>社区活跃&lt;/strong>： Ollama 拥有庞大且活跃的社区，用户可以轻松获取帮助、分享经验和参与模型开发。&lt;/li>
&lt;/ul>
&lt;h2 id="如何使用-ollama">如何使用 Ollama？&lt;/h2>
&lt;p>使用 Ollama 非常简单，只需要按照以下步骤：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>安装 Ollama&lt;/strong>： 根据你的操作系统，从 &lt;a class="link" href="https://ollama.com/" target="_blank" rel="noopener" >Ollama 官网
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
下载并安装最新版本。&lt;/li>
&lt;li>&lt;strong>启动 Ollama&lt;/strong>： 打开终端或命令行，输入 &lt;code>ollama serve&lt;/code> 命令启动 Ollama 服务器。&lt;/li>
&lt;li>&lt;strong>下载模型&lt;/strong>： 在&lt;a class="link" href="https://ollama.com/library" target="_blank" rel="noopener" >模型仓库
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
找到想要的模型，然后使用 &lt;code>ollama pull&lt;/code> 命令下载，例如 &lt;code>ollama pull llama3:70b&lt;/code> 。&lt;/li>
&lt;li>&lt;strong>运行模型&lt;/strong>： 使用 &lt;code>ollama run&lt;/code> 命令启动模型，例如 &lt;code>ollama run llama3:70b&lt;/code> 。&lt;/li>
&lt;li>&lt;strong>开始聊天&lt;/strong>： 在终端中输入你的问题或指令，Ollama 会根据模型生成相应的回复。&lt;/li>
&lt;/ol>
&lt;h3 id="安装-ollama">安装 Ollama&lt;/h3>
&lt;h4 id="macos">macOS&lt;/h4>
&lt;p>&lt;a class="link" href="https://ollama.com/download/Ollama-darwin.zip" target="_blank" rel="noopener" >下载 Ollama for macOS
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/p>
&lt;h4 id="windows">Windows&lt;/h4>
&lt;p>&lt;a class="link" href="https://ollama.com/download/OllamaSetup.exe" target="_blank" rel="noopener" >下载 Ollama for Windows
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/p>
&lt;h4 id="linux">Linux&lt;/h4>
&lt;pre>&lt;code class="language-bash">curl -fsSL https://ollama.com/install.sh | sh
&lt;/code>&lt;/pre>
&lt;h4 id="docker">Docker&lt;/h4>
&lt;h5 id="cpu-版本">CPU 版本&lt;/h5>
&lt;pre>&lt;code class="language-bash">docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
&lt;/code>&lt;/pre>
&lt;h5 id="gpu-版本">GPU 版本&lt;/h5>
&lt;ol>
&lt;li>安装 &lt;a class="link" href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installation" target="_blank" rel="noopener" >Nvidia container toolkit
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/li>
&lt;li>在 Docker 容器中运行 Ollama&lt;/li>
&lt;/ol>
&lt;pre>&lt;code class="language-bash">docker run -d --gpus=all -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
&lt;/code>&lt;/pre>
&lt;h3 id="启动-ollama">启动 Ollama&lt;/h3>
&lt;pre>&lt;code class="language-bash">ollama serve
&lt;/code>&lt;/pre>
&lt;p>输出以下信息表示 Ollama 服务器已成功启动（V100 机器）：&lt;/p>
&lt;pre>&lt;code class="language-bash">$ ollama serve
### 省略的日志输出 ###
Listening on [::]:11434 (version 0.1.42)
&lt;/code>&lt;/pre>
&lt;h3 id="下载模型">下载模型&lt;/h3>
&lt;pre>&lt;code class="language-bash">ollama pull qwen2:72b
&lt;/code>&lt;/pre>
&lt;h3 id="运行模型">运行模型&lt;/h3>
&lt;pre>&lt;code class="language-bash">ollama run qwen2:72b
&lt;/code>&lt;/pre>
&lt;p>例如，运行如下命令后：&lt;/p>
&lt;pre>&lt;code class="language-bash">$ ollama run qwen2:72b
&amp;gt;&amp;gt;&amp;gt; Who are you?
I am Qwen, a pre-trained language model developed by Alibaba Cloud. My purpose is to assist users in generating various types of text, such as articles, stories, poems, and answering
questions by using the natural language processing techniques. How may I assist you today?
&amp;gt;&amp;gt;&amp;gt; Send a message(/? for help)
&lt;/code>&lt;/pre>
&lt;h4 id="docker-容器中运行模型">Docker 容器中运行模型&lt;/h4>
&lt;pre>&lt;code class="language-bash">docker exec -it ollama ollama run qwen2:72b
&lt;/code>&lt;/pre>
&lt;h3 id="配置-ollama">配置 Ollama&lt;/h3>
&lt;p>Ollama 提供了多种环境变量以供配置：&lt;/p>
&lt;ul>
&lt;li>&lt;code>OLLAMA_DEBUG&lt;/code>：是否开启调试模式，默认为 &lt;code>false&lt;/code>。&lt;/li>
&lt;li>&lt;code>OLLAMA_FLASH_ATTENTION&lt;/code>：是否闪烁注意力，默认为 &lt;code>true&lt;/code>。&lt;/li>
&lt;li>&lt;code>OLLAMA_HOST&lt;/code>：Ollama 服务器的主机地址，默认为空。&lt;/li>
&lt;li>&lt;code>OLLAMA_KEEP_ALIVE&lt;/code>：保持连接的时间，默认为 &lt;code>5m&lt;/code>。&lt;/li>
&lt;li>&lt;code>OLLAMA_LLM_LIBRARY&lt;/code>：LLM 库，默认为空。&lt;/li>
&lt;li>&lt;code>OLLAMA_MAX_LOADED_MODELS&lt;/code>：最大加载模型数，默认为 &lt;code>1&lt;/code>。&lt;/li>
&lt;li>&lt;code>OLLAMA_MAX_QUEUE&lt;/code>：最大队列数，默认为空。&lt;/li>
&lt;li>&lt;code>OLLAMA_MAX_VRAM&lt;/code>：最大虚拟内存，默认为空。&lt;/li>
&lt;li>&lt;code>OLLAMA_MODELS&lt;/code>：模型目录，默认为空。&lt;/li>
&lt;li>&lt;code>OLLAMA_NOHISTORY&lt;/code>：是否保存历史记录，默认为 &lt;code>false&lt;/code>。&lt;/li>
&lt;li>&lt;code>OLLAMA_NOPRUNE&lt;/code>：是否启用剪枝，默认为 &lt;code>false&lt;/code>。&lt;/li>
&lt;li>&lt;code>OLLAMA_NUM_PARALLEL&lt;/code>：并行数，默认为 &lt;code>1&lt;/code>。&lt;/li>
&lt;li>&lt;code>OLLAMA_ORIGINS&lt;/code>：允许的来源，默认为空。&lt;/li>
&lt;li>&lt;code>OLLAMA_RUNNERS_DIR&lt;/code>：运行器目录，默认为空。&lt;/li>
&lt;li>&lt;code>OLLAMA_SCHED_SPREAD&lt;/code>：调度分布，默认为空。&lt;/li>
&lt;li>&lt;code>OLLAMA_TMPDIR&lt;/code>：临时文件目录，默认为空。Here is the optimized list in the desired format:&lt;/li>
&lt;li>&lt;code>OLLAMA_DEBUG&lt;/code>：是否开启调试模式，默认为 &lt;code>false&lt;/code>。&lt;/li>
&lt;li>&lt;code>OLLAMA_FLASH_ATTENTION&lt;/code>：是否闪烁注意力，默认为 &lt;code>true&lt;/code>。&lt;/li>
&lt;li>&lt;code>OLLAMA_HOST&lt;/code>：Ollama 服务器的主机地址，默认为空。&lt;/li>
&lt;li>&lt;code>OLLAMA_KEEP_ALIVE&lt;/code>：保持连接的时间，默认为 &lt;code>5m&lt;/code>。&lt;/li>
&lt;li>&lt;code>OLLAMA_LLM_LIBRARY&lt;/code>：LLM 库，默认为空。&lt;/li>
&lt;li>&lt;code>OLLAMA_MAX_LOADED_MODELS&lt;/code>：最大加载模型数，默认为 &lt;code>1&lt;/code>。&lt;/li>
&lt;li>&lt;code>OLLAMA_MAX_QUEUE&lt;/code>：最大队列数，默认为空。&lt;/li>
&lt;li>&lt;code>OLLAMA_MAX_VRAM&lt;/code>：最大虚拟内存，默认为空。&lt;/li>
&lt;li>&lt;code>OLLAMA_MODELS&lt;/code>：模型目录，默认为空。&lt;/li>
&lt;li>&lt;code>OLLAMA_NOHISTORY&lt;/code>：是否保存历史记录，默认为 &lt;code>false&lt;/code>。&lt;/li>
&lt;li>&lt;code>OLLAMA_NOPRUNE&lt;/code>：是否启用剪枝，默认为 &lt;code>false&lt;/code>。&lt;/li>
&lt;li>&lt;code>OLLAMA_NUM_PARALLEL&lt;/code>：并行数，默认为 &lt;code>1&lt;/code>。&lt;/li>
&lt;li>&lt;code>OLLAMA_ORIGINS&lt;/code>：允许的来源，默认为空。&lt;/li>
&lt;li>&lt;code>OLLAMA_RUNNERS_DIR&lt;/code>：运行器目录，默认为空。&lt;/li>
&lt;li>&lt;code>OLLAMA_SCHED_SPREAD&lt;/code>：调度分布，默认为空。&lt;/li>
&lt;li>&lt;code>OLLAMA_TMPDIR&lt;/code>：临时文件目录，默认为空。&lt;/li>
&lt;/ul>
&lt;h2 id="进阶用法hpc-集群上部署-ollama">进阶用法：HPC 集群上部署 Ollama&lt;/h2>
&lt;p>对于大型模型或需要更高性能的情况，可以利用 HPC 集群的强大算力来运行 Ollama。结合 Slurm 进行任务管理，并使用端口映射将服务暴露到本地，即可方便地进行远程访问和使用：&lt;/p>
&lt;ol>
&lt;li>在登录节点配置 Ollama 环境： 安装 Ollama，并下载需要的模型。&lt;/li>
&lt;li>&lt;strong>编写 slurm 脚本&lt;/strong>： 指定资源需求（CPU、内存、GPU 等），并使用 &lt;code>ollama serve&lt;/code> 命令启动模型服务，并绑定到特定端口。&lt;/li>
&lt;/ol>
&lt;pre>&lt;code class="language-bash">#!/bin/bash
#SBATCH --job-name=ollama
#SBATCH -N 1
#SBATCH -p GPU
#SBATCH --gres=gpu:1
module load CUDA
ollama serve
&lt;/code>&lt;/pre>
&lt;ol start="3">
&lt;li>&lt;strong>提交 slurm 任务&lt;/strong>: 使用 &lt;code>sbatch&lt;/code> 命令提交脚本，Slurm 会将任务分配到计算节点运行。&lt;/li>
&lt;li>&lt;strong>本地端口映射&lt;/strong>： 使用 ssh -L 命令将计算节点的端口映射到本地，例如:&lt;/li>
&lt;/ol>
&lt;pre>&lt;code class="language-bash">ssh -t -t 用户名@登录节点 ip -L 11434:localhost:11434 -i 登录节点私钥 ssh 计算节点 IP -L 11434:127.0.0.1:11434
&lt;/code>&lt;/pre>
&lt;ol start="5">
&lt;li>&lt;strong>本地访问&lt;/strong>： 在浏览器或应用程序中访问 http://localhost:11434 即可使用 Ollama 服务。&lt;/li>
&lt;/ol>
&lt;div class="notice notice-tip" >
&lt;div class="notice-title">&lt;svg t="1705945832245" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="19409" width="200" height="200">&lt;path d="M512 74.666667C270.933333 74.666667 74.666667 270.933333 74.666667 512S270.933333 949.333333 512 949.333333 949.333333 753.066667 949.333333 512 753.066667 74.666667 512 74.666667z m238.933333 349.866666l-2.133333 2.133334-277.333333 277.333333c-10.666667 10.666667-29.866667 12.8-42.666667 2.133333L426.666667 704l-149.333334-149.333333c-12.8-12.8-12.8-32 0-44.8 10.666667-10.666667 29.866667-12.8 42.666667-2.133334l2.133333 2.133334 125.866667 125.866666 253.866667-253.866666c10.666667-10.666667 29.866667-12.8 42.666666-2.133334l2.133334 2.133334c12.8 12.8 12.8 32 4.266666 42.666666z" fill="#ffffff" p-id="19410">&lt;/path>&lt;/svg>&lt;/div>&lt;p>注意：由于计算节点不联网，需要提前在登录节点使用 &lt;code>ollama pull&lt;/code> 下载所需模型。此外，需要设置 &lt;code>OLLAMA_ORIGINS&lt;/code> 为 &lt;code>*&lt;/code>，设置 &lt;code>OLLAMA_HOST&lt;/code> 为 &lt;code>0.0.0.0&lt;/code>，以允许所有来源访问服务。&lt;/p>&lt;/div>
&lt;h2 id="进阶用法本地代码补全助手">进阶用法：本地代码补全助手&lt;/h2>
&lt;p>Ollama 不仅可以用于聊天和文本创作，还可以结合代码生成模型和 IDE 插件，打造强大的代码补全助手。例如，使用 Codeqwen 7B 模型和 VS Code 插件 &lt;a class="link" href="https://continue.dev/" target="_blank" rel="noopener" >Continue
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
，可以实现高效便捷的代码补全功能。&lt;/p>
&lt;p>首先介绍一下 Continue :
&lt;blockquote>
&lt;p>&lt;p>&lt;a class="link" href="https://continue.dev/" target="_blank" rel="noopener" >Continue
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
enables you to easily create your own coding assistant directly inside Visual Studio Code and JetBrains with open-source LLMs. All this can run entirely on your own laptop or have Ollama deployed on a server to remotely power code completion and chat experiences based on your needs.&lt;/p>
&lt;p>Continue 使您能够轻松地在 Visual Studio Code 和 JetBrains 中创建自己的代码助手，利用开源 LLM。这一切都可以完全在您的笔记本电脑上运行，或者在服务器上部署 Ollama，远程根据您的需求提供代码补全和聊天体验。&lt;/p>
&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Continue&lt;/span>&lt;cite>&lt;/cite>&lt;/span>&lt;/blockquote>&lt;/p>
&lt;p>在开始之前，你需要安装如下工具：&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="https://docs.continue.dev/quickstart" target="_blank" rel="noopener" >Continue
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
：&lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=Continue.continue" target="_blank" rel="noopener" >VS Code 版本
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
或 &lt;a class="link" href="https://plugins.jetbrains.com/plugin/22707-continue" target="_blank" rel="noopener" >JetBrains 版本
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/li>
&lt;li>&lt;a class="link" href="https://ollama.com/" target="_blank" rel="noopener" >Ollama
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/li>
&lt;/ul>
&lt;p>接下来，我们以 VS Code 为例，介绍如何使用 Ollama + Continue 实现代码补全功能：&lt;/p>
&lt;h3 id="codestral-22b-模型">Codestral 22B 模型&lt;/h3>
&lt;p>Codestral 既能完成代码自动补全，也支持聊天功能。但鉴于其拥有 220 亿参数且不具备生产许可，它对显存要求颇高，仅限于研究和测试使用，因此可能并不适合日常本地应用。&lt;/p>
&lt;h4 id="下载并运行-codestral-模型">下载并运行 Codestral 模型&lt;/h4>
&lt;pre>&lt;code class="language-bash">ollama run codestral
&lt;/code>&lt;/pre>
&lt;h4 id="配置-configjson">配置 config.json&lt;/h4>
&lt;ul>
&lt;li>在 VS Code 侧边栏点击 Continue 插件图标，然后在面板右下角点击 “齿轮” 图标，打开 &lt;code>config.json&lt;/code> 文件。然后复制以下配置到 &lt;code>config.json&lt;/code> 文件中：&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-json">{
&amp;quot;models&amp;quot;: [
{
&amp;quot;title&amp;quot;: &amp;quot;Codestral&amp;quot;,
&amp;quot;provider&amp;quot;: &amp;quot;ollama&amp;quot;,
&amp;quot;model&amp;quot;: &amp;quot;codestral&amp;quot;
}
],
&amp;quot;tabAutocompleteModel&amp;quot;: {
&amp;quot;title&amp;quot;: &amp;quot;Codestral&amp;quot;,
&amp;quot;provider&amp;quot;: &amp;quot;ollama&amp;quot;,
&amp;quot;model&amp;quot;: &amp;quot;codestral&amp;quot;
}
}
&lt;/code>&lt;/pre>
&lt;h3 id="deepseek-coder-67b-模型--llama-3-8b-模型">DeepSeek Coder 6.7B 模型 + Llama 3 8B 模型&lt;/h3>
&lt;p>根据机器的显存大小，可以利用 Ollama 同时运行多个模型并处理多个并发请求的能力，使用 &lt;code>DeepSeek Coder 6.7B&lt;/code> 进行自动补全，&lt;code>Llama 3 8B&lt;/code> 进行聊天。如果你的机器无法同时运行两者，那么可以分别尝试，决定你更偏好本地自动补全还是本地聊天体验。&lt;/p>
&lt;h4 id="下载并运行-deepseek-coder-模型">下载并运行 DeepSeek Coder 模型&lt;/h4>
&lt;pre>&lt;code class="language-bash">ollama run deepseek-coder:6.7b-base
&lt;/code>&lt;/pre>
&lt;h4 id="下载并运行-llama-3-模型">下载并运行 Llama 3 模型&lt;/h4>
&lt;pre>&lt;code class="language-bash">ollama run llama3:8b
&lt;/code>&lt;/pre>
&lt;h4 id="配置-configjson-1">配置 config.json&lt;/h4>
&lt;pre>&lt;code class="language-json">{
&amp;quot;models&amp;quot;: [
{
&amp;quot;title&amp;quot;: &amp;quot;Llama 3 8B&amp;quot;,
&amp;quot;provider&amp;quot;: &amp;quot;ollama&amp;quot;,
&amp;quot;model&amp;quot;: &amp;quot;llama3:8b&amp;quot;,
&amp;quot;apiBase&amp;quot;: &amp;quot;http://127.0.0.1:11434&amp;quot;
}
],
&amp;quot;tabAutocompleteModel&amp;quot;: {
&amp;quot;title&amp;quot;: &amp;quot;DeepSeek Coder 6.7B&amp;quot;,
&amp;quot;provider&amp;quot;: &amp;quot;ollama&amp;quot;,
&amp;quot;model&amp;quot;: &amp;quot;deepseek-coder:6.7b-base&amp;quot;,
&amp;quot;apiBase&amp;quot;: &amp;quot;http://127.0.0.1:11434&amp;quot;
}
}
&lt;/code>&lt;/pre>
&lt;h3 id="codeqwen-7b-模型--qwen2-7b-模型">Codeqwen 7B 模型 + Qwen2 7B 模型&lt;/h3>
&lt;p>Codeqwen 7B 模型是一个专门用于代码补全的模型，而 Qwen2 7B 模型则是一个通用的聊天模型。这两个模型可以很好地结合在一起，实现代码补全和聊天功能。&lt;/p>
&lt;h4 id="下载并运行-codeqwen-模型">下载并运行 Codeqwen 模型&lt;/h4>
&lt;pre>&lt;code class="language-bash">ollama run codeqwen
&lt;/code>&lt;/pre>
&lt;h4 id="下载并运行-qwen2-模型">下载并运行 Qwen2 模型&lt;/h4>
&lt;pre>&lt;code class="language-bash">ollama run qwen2:7b
&lt;/code>&lt;/pre>
&lt;h4 id="配置-configjson-2">配置 config.json&lt;/h4>
&lt;pre>&lt;code class="language-json">{
&amp;quot;models&amp;quot;: [
{
&amp;quot;title&amp;quot;: &amp;quot;Codeqwen 7B&amp;quot;,
&amp;quot;provider&amp;quot;: &amp;quot;ollama&amp;quot;,
&amp;quot;model&amp;quot;: &amp;quot;codeqwen&amp;quot;,
&amp;quot;apiBase&amp;quot;: &amp;quot;http://127.0.0.1:11434&amp;quot;
}
],
&amp;quot;tabAutocompleteModel&amp;quot;: {
&amp;quot;title&amp;quot;: &amp;quot;Qwen2 7B&amp;quot;,
&amp;quot;provider&amp;quot;: &amp;quot;ollama&amp;quot;,
&amp;quot;model&amp;quot;: &amp;quot;qwen2:7b&amp;quot;,
&amp;quot;apiBase&amp;quot;: &amp;quot;http://127.0.0.1:11434&amp;quot;
}
}
&lt;/code>&lt;/pre>
&lt;h3 id="利用-rag-向量检索优化聊天">利用 RAG 向量检索优化聊天&lt;/h3>
&lt;p>Continue 内置了 &lt;a class="link" href="https://docs.continue.dev/customization/context-providers#codebase-retrieval" target="_blank" rel="noopener" >@codebase
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
上下文提供器，能自动从代码库中检索到最相关的代码片段。假如你已经设置好了聊天模型（例如 Codestral、Llama 3），那么借助 Ollama 和 &lt;a class="link" href="https://blog.lancedb.com/lancedb-x-continue/" target="_blank" rel="noopener" >LanceDB
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
的向量化技术，可以实现更高效的代码检索和聊天体验。&lt;/p>
&lt;p>这里，我们使用 &lt;code>nomic-embed-text&lt;/code> 模型作为向量检索模型：&lt;/p>
&lt;h4 id="下载并运行-nomic-embed-text-模型">下载并运行 Nomic Embed Text 模型&lt;/h4>
&lt;pre>&lt;code class="language-bash">ollama run nomic-embed-text
&lt;/code>&lt;/pre>
&lt;h4 id="配置-configjson-3">配置 config.json&lt;/h4>
&lt;ul>
&lt;li>在文件中添加以下内容：&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-json">{
&amp;quot;embeddingsProvider&amp;quot;: {
&amp;quot;provider&amp;quot;: &amp;quot;ollama&amp;quot;,
&amp;quot;model&amp;quot;: &amp;quot;nomic-embed-text&amp;quot;,
&amp;quot;apiBase&amp;quot;: &amp;quot;http://127.0.0.1:11434&amp;quot;
}
}
&lt;/code>&lt;/pre>
&lt;h3 id="代码补全效果">代码补全效果&lt;/h3>
&lt;ul>
&lt;li>&lt;code>Ctrl + I&lt;/code>: 根据指令生成代码片段。&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/codeqwen_1-2024-06-17.png"
alt="codeqwen_1-2024-06-17" width="90%" loading="lazy">
&lt;/figure>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/codeqwen_2-2024-06-17.png"
alt="codeqwen_2-2024-06-17" width="90%" loading="lazy">
&lt;/figure>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/codeqwen_3-2024-06-17.png"
alt="codeqwen_3-2024-06-17" width="90%" loading="lazy">
&lt;/figure>
&lt;ul>
&lt;li>光标悬停自动补全代码&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/codeqwen_4-2024-06-17.png"
alt="codeqwen_4-2024-06-17" width="90%" loading="lazy">
&lt;/figure>
&lt;h3 id="与-ollama-聊天">与 Ollama 聊天&lt;/h3>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/codeqwen_5-2024-06-17.png"
alt="codeqwen_5-2024-06-17" width="90%" loading="lazy">
&lt;/figure>
&lt;h3 id="代码自动注释">代码自动注释&lt;/h3>
&lt;ul>
&lt;li>选中代码打开右键菜单&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/codeqwen_6-2024-06-17.png"
alt="codeqwen_6-2024-06-17" width="90%" loading="lazy">
&lt;/figure>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/codeqwen_7-2024-06-17.png"
alt="codeqwen_7-2024-06-17" width="90%" loading="lazy">
&lt;/figure>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>Ollama 为我们打开了通往开源 LLM 世界的大门，让每个人都能轻松体验 LLM 的强大功能，并可以根据自身需求进行定制化应用。无论是进行研究、开发，还是日常使用，Ollama 都能为你提供探索 LLM 无限可能的平台。相信随着 Ollama 的不断发展，它将为我们带来更多惊喜，推动 LLM 技术在各个领域的应用和发展。&lt;/p></description></item><item><title>RDMA 之 Address Handle</title><link>https://cuterwrite.top/p/rdma-address-handle/</link><pubDate>Sat, 15 Jun 2024 01:00:00 +0000</pubDate><guid>https://cuterwrite.top/p/rdma-address-handle/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-16_116373922_p9_master1200.webp" alt="Featured image of post RDMA 之 Address Handle" />&lt;h1 id="rdma-之-address-handle">RDMA 之 Address Handle&lt;/h1>
&lt;p>&lt;strong>本文欢迎非商业转载，转载请注明出处。&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>声明：仅用于收藏，便于阅读&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/163552044">&lt;cite>知乎专栏：8. RDMA 之 Address Handle&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>前面已经介绍过，RDMA 通信的基本单元是 QP。我们来思考一个问题，假设 A 节点的某个 QP 要跟 B 节点的某个 QP 交换信息，除了要知道 B 节点的 QP 序号——QPN 之外，还需要什么信息？要知道，QPN 是每个节点独立维护的序号，不是整个网络中唯一的。比如 A 的 QP 3 要跟 B 的 QP 5 通信，网络中可不止一个 QP5，可能有很多个节点都有自己的 QP 5。所以我们自然可以想到，还需要找到让每个节点都有一个独立的标识。&lt;/p>
&lt;p>在传统 TCP-IP 协议栈中，使用了家喻户晓的 IP 地址来标识网络层的每个节点。而 IB 协议中的这个标识被称为&lt;strong>GID（Global Identifier，全局 ID）&lt;/strong>，是一个 128 bits 的序列。关于 GID 本篇不展开讨论，将在后面介绍。&lt;/p>
&lt;h2 id="ah-是什么">AH 是什么&lt;/h2>
&lt;p>AH 全称为 Address Handle，没有想到特别合适的中文翻译，就先直译为“地址句柄”吧。这里的地址，指的是一组用于找到某个远端节点的信息的集合，在 IB 协议中，地址指的是 GID、端口号等等信息；而所谓句柄，我们可以理解为一个指向某个对象的指针。&lt;/p>
&lt;p>大家是否还记得 IB 协议中有四种基本服务类型——RC、UD、RD 和 UC，其中最常用的是 RC 和 UD。RC 的特点是两个节点的 QP 之间会建立可靠的连接，一旦建立连接关系便不容易改变，对端的信息是创建 QP 的时候储存在 QP Context 中的；&lt;/p>
&lt;p>而对于 UD 来说，QP 间没有连接关系，用户想发给谁，就在 WQE 中填好对端的地址信息就可以了。&lt;strong>用户不是直接把对端的地址信息填到 WQE 中的，而是提前准备了一个“地址薄”，每次通过一个索引来指定对端节点的地址信息，而这个索引就是 AH。&lt;/strong>&lt;/p>
&lt;p>AH 的概念大致可以用下图表示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-16_8_1.webp"
alt="2024-06-16_8_1" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Address Handle 功能示意图&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>对于每一个目的节点，本端都会创建一个对应的 AH，而同一个 AH 可以被多个 QP 共同使用。&lt;/p>
&lt;h2 id="ah-的作用">AH 的作用&lt;/h2>
&lt;p>每次进行 UD 服务类型的通信之前，用户都需要先通过 IB 框架提供的接口，来&lt;strong>为每一个可能的对端节点创建一个 AH&lt;/strong>，然后这些 AH 会被驱动放到一个“安全”的区域，并返回一个索引（指针/句柄）给用户。用户真正下发 WR（Work Request）时，就把这个索引传递进来就可以了。&lt;/p>
&lt;p>上述过程如下图所示，A 节点收到用户的这样一个任务——使用本端的 QP4 与 B 节点（通过 AH 指定）的 QP3 进行数据交换：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-16_8_2.webp"
alt="2024-06-16_8_2" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>UD 服务类型使用 AH 指定对端节点&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>IB 协议中并没有对为什么使用 AH 做出解释，我认为定义 AH 的概念的原因有以下三种：&lt;/p>
&lt;ol>
&lt;li>保证目的地址可用，提高效率&lt;/li>
&lt;/ol>
&lt;p>因为 UD 无连接的特点，用户可以在用户态直接通过 WR 来指定目的地。而如果让用户随意填写地址信息，然后硬件就根据这些信息进行组包的话，是会带来问题的。比如有这样一种场景：用户通过 WR 告诉硬件请给 GID 为 X，MAC 地址为 Y 的节点的端口 Z 发送数据。然而 X，Y，Z 可能不是一个合法的组合，或者 GID 为 X 的节点压根都不存在于网络中，而硬件是无力校验这些内容的，只能乖乖的组包、发送数据，这个目的地无效的数据包就白白发送出去了。&lt;/p>
&lt;p>而提前准备好地址信息，则可以避免上述情况。用户在创建 AH 时会陷入内核态，如果用户传递的参数有效，内核会把这些目的节点信息储存起来，生成一个指针返回给用户；如果用户传递的参数无效，AH 将创建失败。这一过程可以保证地址信息是有效的。用户通过指针就可以快速指定目的节点，加快数据交互流程。&lt;/p>
&lt;p>可能有人会问，既然内核是可信的，为什么不能在发送数据时陷入内核态去校验用户传递的地址信息呢？请别忘了 RDMA 技术的一大优势在哪里——数据流程可以直接从用户空间到硬件，完全绕过内核，这样可以避免系统调用和拷贝的开销。如果每次发送都要检验地址合法性的话，必然会降低通信速率。&lt;/p>
&lt;ol start="2">
&lt;li>向用户隐藏底层地址细节&lt;/li>
&lt;/ol>
&lt;p>用户创建 AH 时，只需要传递 gid、端口号、静态速率等信息，而其他通信所需的地址信息（主要是 MAC 地址）是内核驱动通过查询系统邻居表等方式解析到的，底层没有必要暴露这些额外的信息给用户层。&lt;/p>
&lt;ol start="3">
&lt;li>可以使用 PD 对目的地址进行管理&lt;/li>
&lt;/ol>
&lt;p>前文我们介绍保护域时曾经提过，除了 QP、MR 之外，AH 也由 PD 来进行资源划分。当定义了 AH 这个软件实体之后，我们就可以对所有的 QP 可达的目的地进行相互隔离和管理。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-16_8_3.webp"
alt="2024-06-16_8_3" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>使用 PD 隔离 AH&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>​比如上图中，AH1~3 只能被同一个 PD 下的 QP3 和 QP9 使用，而 AH4 只能被 QP5 使用。&lt;/p>
&lt;h2 id="协议相关章节">协议相关章节&lt;/h2>
&lt;p>协议中关于 AH 的篇幅并不多，甚至没有独立介绍其概念的章节：&lt;/p>
&lt;p>[1] 9.8.3 UD 服务类型中的目的地址由哪些部分组成：包括 AH、 QPN 和 Q_key&lt;/p>
&lt;p>[2] 10.2.2.2 目的地址的相关注意事项&lt;/p>
&lt;p>[3] 11.2.2.1 AH 相关的 Verbs 接口&lt;/p>
&lt;p>AH 就介绍到这里，感谢阅读。下一篇打算向大家描述更多关于 QP 的细节。&lt;/p></description></item><item><title>Docker Hub 镜像下架解决方案</title><link>https://cuterwrite.top/p/dockerhub-takedown/</link><pubDate>Wed, 12 Jun 2024 19:00:00 +0000</pubDate><guid>https://cuterwrite.top/p/dockerhub-takedown/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-05-28_crop_68935d3d33a3abc75c797b67ad25160f195413.webp" alt="Featured image of post Docker Hub 镜像下架解决方案" />&lt;h1 id="docker-hub-镜像下架解决方案">Docker Hub 镜像下架解决方案&lt;/h1>
&lt;p>Docker Hub 作为 Docker 官方的镜像仓库，拥有着丰富的镜像资源， 极大地方便了开发者获取和使用各种软件和服务。然而，从 2024 年 6 月 6 日开始，国内各大镜像站点陆续出现了 Docker Hub 镜像下架的情况，包括阿里云、科大、南大、上交等全部挂掉，导致很多开发者无法正常拉取镜像。在执行 &lt;code>docker pull&lt;/code> 命令拉取镜像 docker 镜像时无反应，会一直循环尝试。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-13_takedown-dockerhub.webp"
alt="2024-06-13_takedown-dockerhub" width="auto" loading="lazy">
&lt;/figure>
&lt;p>Docker Hub 镜像下架的可能原因主要为一些镜像包含违规内容，导致上面信息监管部门出了最新要求，要求各大镜像站点下架相关镜像。&lt;/p>
&lt;h2 id="解决方案">解决方案&lt;/h2>
&lt;p>面对 Docker Hub 镜像下架问题，目前我们可以通过以下几种方式解决：&lt;/p>
&lt;h3 id="1-使用-atomhub-镜像站点">1. 使用 AtomHub 镜像站点&lt;/h3>
&lt;p>AtomHub 是由开放原子开源基金会发起，遵循 OCI 标准，旨在为开发者提供开放中立、安全可信、高效便捷的新一代开源容器镜像中心。其具有官方背书，是当前唯一正常的 Docker Hub 镜像站点。&lt;/p>
&lt;p>不过，AtomHub 的问题是镜像数量较少，目前只有几百个镜像文件；以及，部分软件的版本较旧。&lt;/p>
&lt;h4 id="配置-atomhub-镜像站点">配置 AtomHub 镜像站点&lt;/h4>
&lt;ul>
&lt;li>修改 /etc/docker/daemon.json 文件，添加以下内容：&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-json">{
&amp;quot;registry-mirrors&amp;quot;: [&amp;quot;https://atomhub.openatom.cn&amp;quot;]
}
&lt;/code>&lt;/pre>
&lt;h4 id="重启-docker-服务">重启 Docker 服务：&lt;/h4>
&lt;pre>&lt;code class="language-bash">sudo systemctl daemon-reload
sudo systemctl restart docker
&lt;/code>&lt;/pre>
&lt;p>然后就可以正常拉取一些常用镜像了。但是，如果你需要的镜像不在 AtomHub 上，这个方法就不适用了。&lt;/p>
&lt;h3 id="2-配置-vpn-代理">2. 配置 VPN 代理&lt;/h3>
&lt;p>通过配置 VPN 代理，可以访问被屏蔽的 Docker Hub 源站点，从而拉取镜像。但是，这种方法需要自备 VPN 服务，且速度可能较慢且不稳定。&lt;/p>
&lt;h4 id="配置方法">配置方法&lt;/h4>
&lt;ul>
&lt;li>创建 &lt;code>/etc/systemd/system/docker.service.d/http-proxy.conf&lt;/code> 文件，并添加以下内容：&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-bash">[Service]
Environment=&amp;quot;HTTP_PROXY=http://your_proxy_server:port&amp;quot;
Environment=&amp;quot;HTTPS_PROXY=http://your_proxy_server:port&amp;quot;
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>重启 Docker 服务：&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-bash">sudo systemctl daemon-reload
sudo systemctl restart docker
&lt;/code>&lt;/pre>
&lt;h3 id="3-使用-skopeo-拷贝镜像到私有镜像仓库">3. 使用 Skopeo 拷贝镜像到私有镜像仓库&lt;/h3>
&lt;p>Skopeo 是一个命令行工具，可以用于在不同的镜像仓库之间复制、检查和签名镜像。该方法需要一台海外云主机，且需要没有被墙。&lt;/p>
&lt;h4 id="具体步骤">具体步骤&lt;/h4>
&lt;p>这里以阿里云私有镜像仓库为例，将 Docker Hub 上的镜像复制到阿里云私有镜像仓库。&lt;/p>
&lt;ul>
&lt;li>首先，你需要启用&lt;a class="link" href="https://cr.console.aliyun.com/" target="_blank" rel="noopener" >阿里云容器镜像服务
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
，创建一个个人实例：&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-13_aliyun-container.webp"
alt="2024-06-13_aliyun-container" width="90%" loading="lazy">
&lt;/figure>
&lt;ul>
&lt;li>进入个人实例，创建一个命名空间：&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-13_create-namespace.webp"
alt="2024-06-13_create-namespace" width="90%" loading="lazy">
&lt;/figure>
&lt;ul>
&lt;li>创建一个镜像仓库（对应你想要复制的镜像）：&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-13_create-repository.webp"
alt="2024-06-13_create-repository" width="90%" loading="lazy">
&lt;/figure>
&lt;ul>
&lt;li>设置访问凭证：&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-13_set-pass.webp"
alt="2024-06-13_set-pass" width="90%" loading="lazy">
&lt;/figure>
&lt;ul>
&lt;li>然后，登录到你的海外云主机，先安装 Skopeo：&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-bash">sudo apt-get update &amp;amp;&amp;amp; sudo apt-get install -y skopeo
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>使用 Skopeo 拷贝镜像：&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-bash">docker login --username=yourusername registry.cn-hangzhou.aliyuncs.com
skopeo copy docker://docker.io/library/image:tag docker://registry.cn-hangzhou.aliyuncs.com/yournamespace/yourimage:tag
&lt;/code>&lt;/pre>
&lt;h3 id="4-部署私有镜像仓库">4. 部署私有镜像仓库&lt;/h3>
&lt;p>除了以上方法，还可以通过最近一大佬开源的 &lt;a class="link" href="https://github.com/dqzboy/Docker-Proxy" target="_blank" rel="noopener" >Docker-Proxy
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
项目搭建自己的私有镜像仓库。&lt;/p>
&lt;a href="https://github.com/dqzboy/Docker-Proxy" target="_blank" class="card-github fetch-waiting no-styling"
repo="dqzboy/Docker-Proxy" id="repo-NzPyKIPCLsDw3fIr-card">
&lt;div class="gc-titlebar">
&lt;div class="gc-titlebar-left">
&lt;div class="gc-owner">
&lt;div id="repo-NzPyKIPCLsDw3fIr-avatar" class="gc-avatar">&lt;/div>
&lt;div class="gc-user">dqzboy&lt;/div>
&lt;/div>
&lt;div class="gc-divider">/&lt;/div>
&lt;div class="gc-repo">Docker-Proxy&lt;/div>
&lt;/div>
&lt;div class="github-logo">&lt;/div>
&lt;/div>
&lt;div id="repo-NzPyKIPCLsDw3fIr-description" class="gc-description">Waiting for api.github.com...&lt;/div>
&lt;div class="gc-infobar">
&lt;div id="repo-NzPyKIPCLsDw3fIr-stars" class="gc-stars">0&lt;/div>
&lt;div id="repo-NzPyKIPCLsDw3fIr-forks" class="gc-forks">0&lt;/div>
&lt;div id="repo-NzPyKIPCLsDw3fIr-license" class="gc-license">unkown&lt;/div>
&lt;div id="repo-NzPyKIPCLsDw3fIr-language" class="gc-language">Waiting...&lt;/div>
&lt;/div>
&lt;/a>
&lt;script id="repo-NzPyKIPCLsDw3fIr-script" type="text/javascript" defer>
fetch('https://api.cuterwrite.top/api/repos/dqzboy\/Docker-Proxy', {
referrerPolicy: "no-referrer"
})
.then(response => response.json())
.then(data => {
document.getElementById('repo-NzPyKIPCLsDw3fIr-description').innerText = data.description.replace(
/:[a-zA-Z0-9_]+:/g, '');
document.getElementById('repo-NzPyKIPCLsDw3fIr-language').innerText = data.language;
document.getElementById('repo-NzPyKIPCLsDw3fIr-forks').innerText = Intl.NumberFormat('en-us', {
notation: "compact",
maximumFractionDigits: 1
}).format(data.forks).replaceAll("\u202f", '');
document.getElementById('repo-NzPyKIPCLsDw3fIr-stars').innerText = Intl.NumberFormat('en-us', {
notation: "compact",
maximumFractionDigits: 1
}).format(data.stargazers_count).replaceAll("\u202f", '');
const avatarEl = document.getElementById('repo-NzPyKIPCLsDw3fIr-avatar');
avatarEl.style.backgroundImage = 'url(' + data.owner.avatar_url + ')';
avatarEl.style.backgroundColor = 'transparent';
if (data.license?.spdx_id) {
document.getElementById('repo-NzPyKIPCLsDw3fIr-license').innerText = data.license.spdx_id
} else {
document.getElementById('repo-NzPyKIPCLsDw3fIr-license').classList.add = "no-license"
};
document.getElementById('repo-NzPyKIPCLsDw3fIr-card').classList.remove("fetch-waiting");
console.log("[GITHUB-CARD] Loaded card for dqzboy\/Docker-Proxy.")
}).catch(err => {
const c = document.getElementById('repo-NzPyKIPCLsDw3fIr-card');
c.classList.add("fetch-error");
console.warn("[GITHUB-CARD] (Error) Loading card for dqzboy\/Docker-Proxy.")
})
&lt;/script>
&lt;p>该方法也需要一台海外云主机，且需要没有被墙；以及一个域名（不需要备案）。&lt;/p>
&lt;h4 id="部署">部署&lt;/h4>
&lt;p>目前项目提供了三种部署方式，我采用的是第一种方式，使用项目脚本一键部署。&lt;/p>
&lt;ul>
&lt;li>使用项目脚本一键部署：&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-bash"># CentOS
yum -y install wget curl
# ubuntu
apt -y install wget curl
bash -c &amp;quot;$(curl -fsSL https://raw.githubusercontent.com/dqzboy/Docker-Proxy/main/install/DockerProxy_Install.sh)&amp;quot;
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>
&lt;p>部署到 Render&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="https://github.com/dqzboy/Docker-Proxy/blob/main/Render/README.md" target="_blank" rel="noopener" >使用 Render 快速部署
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Docker Compose 部署&lt;/p>
&lt;ol>
&lt;li>下载 config 目录下对应的 yml 文件到你本地机器上&lt;/li>
&lt;li>下载 &lt;a class="link" href="https://github.com/dqzboy/Docker-Proxy/blob/main/docker-compose.yaml" target="_blank" rel="noopener" >docker-compose.yaml
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
文件到你本地机器上，并且与配置文件同级目录下&lt;/li>
&lt;li>执行 &lt;code>docker compose&lt;/code> 命令启动容器服务&lt;/li>
&lt;/ol>
&lt;pre>&lt;code class="language-bash">docker compose up -d
# 查看容器日志
docker logs -f [容器 ID 或名称]
&lt;/code>&lt;/pre>
&lt;/li>
&lt;/ul>
&lt;p>最后，需要登录域名解析方，将 &lt;code>hub&lt;/code>、&lt;code>gcr&lt;/code>、&lt;code>ghcr&lt;/code>、&lt;code>k8s-gcr&lt;/code>、&lt;code>ui&lt;/code>、&lt;code>quay&lt;/code> 等 A 记录解析到你的海外云主机 IPv4 地址，然后就可以将 &lt;code>/etc/docker/daemon.json&lt;/code> 中的 &lt;strong>registry-mirrors&lt;/strong> 设置为 &lt;code>https://hub.yourdomain&lt;/code> 进行镜像加速了。&lt;/p></description></item><item><title>RDMA 之 Protection Domain</title><link>https://cuterwrite.top/p/rdma-protection-domain/</link><pubDate>Thu, 18 Apr 2024 21:42:00 +0000</pubDate><guid>https://cuterwrite.top/p/rdma-protection-domain/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/d31a474af07682028ca085f871bc5d07195413-2024-04-19.webp" alt="Featured image of post RDMA 之 Protection Domain" />&lt;h1 id="rdma-之-protection-domain">RDMA 之 Protection Domain&lt;/h1>
&lt;p>&lt;strong>本文欢迎非商业转载，转载请注明出处。&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>声明：仅用于收藏，便于阅读&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/159493100">&lt;cite>知乎专栏：7. RDMA 之 Protection Domain&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>前文我们简单介绍了 RDMA 中最常见的一些资源，包括各种 Queue，以及 MR 的概念等等。MR 用于控制和管理 HCA 对于本端和远端内存的访问权限，确保 HCA 只有拿到正确 Key 之后才能读写用户已经注册了的内存区域。为了更好的保障安全性，IB 协议又提出了 Protection Domain（PD）的概念，用于保证 RDMA 资源间的相互隔离，本文就介绍一下 PD 的概念。&lt;/p>
&lt;h2 id="pd-是什么">PD 是什么&lt;/h2>
&lt;p>PD 全称是 Protection Domain，意为&amp;quot;保护域&amp;quot;。域的概念我们经常见到，从数学上的“实数域”、“复数域”，到地理上的“空域”、“海域”等等，表示一个空间/范围。在 RDMA 中，PD 像是一个容纳了各种资源（QP、MR 等）的“容器”，将这些资源纳入自己的保护范围内，避免他们被未经授权的访问。一个节点中可以定义多个保护域，各个 PD 所容纳的资源彼此隔离，无法一起使用。&lt;/p>
&lt;p>概念还是有些抽象，下面我们来看一下 PD 有什么作用，具体解决了什么问题。&lt;/p>
&lt;h2 id="pd-的作用">PD 的作用&lt;/h2>
&lt;p>一个用户可能创建多个 QP 和多个 MR，每个 QP 可能和不同的远端 QP 建立了连接，比如下图这样（灰色箭头表示 QP 间的连接关系）：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/7_1-2024-04-19.webp"
alt="7_1-2024-04-19" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>图 1：没有 PD 概念时的 RDMA 资源&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>由于 MR 和 QP 之间并没有绑定关系，这就意味着一旦某个远端的 QP 与本端的一个 QP 建立了连接，具备了通信的条件，那么理论上远端节点只要知道 VA 和 R_key（甚至可以靠不断的猜测直到得到一对有效的值），就可以访问本端节点某个 MR 的内容。&lt;/p>
&lt;p>其实一般情况下，MR 的虚拟地址 VA 和秘钥 R_Key 是很难猜到的，已经可以保证一定的安全性了。但是为了更好的保护内存中的数据，把各种资源的权限做进一步的隔离和划分，我们在又在每个节点中定义了 PD，如下图所示&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/7_2-2024-04-19.webp"
alt="7_2-2024-04-19" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>图 2：加入 PD 概念时的 RDMA 资源&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>图中 Node 0 上有两个 PD，将 3 个 QP 和 2 个 MR 分为了两组，此外 Node 1 和 Node 2 中各有一个 PD 包含了所有 QP 和 MR。Node 0 上的两个 PD 中的资源不可以一起使用，也就是说 QP3 和 QP9 不能访问 MR1 的数据，QP6 也不可以访问 MR0 的数据。如果我们在数据收发时，指定硬件使用 QP3 和 MR1，那么硬件校验他们不属于同一个 PD 后，会返回错误。&lt;/p>
&lt;p>对于远端节点来说，Node1 只能通过 QP8 相连的 QP3 来访问 Node0 的内存，但是因为 Node 0 的 QP3 被“圈”到了 PD0 这个保护域中，所以 Node 1 的 QP8 也只能访问 MR0 对应的内存，&lt;strong>无论如何都无法访问 MR1 中的数据&lt;/strong>，这是从两个方面限制的：&lt;/p>
&lt;ol>
&lt;li>Node 1 的 QP8 只跟 Node 0 的 QP3 有连接关系，无法通过 Node 0 的 QP6 进行内存访问。&lt;/li>
&lt;li>Node 0 的 MR1 和 QP3 属于不同的 PD，就算 Node 1 的 QP8 拿到了 MR1 的 VA 和 R_key，硬件也会因为 PD 不同而拒绝提供服务。&lt;/li>
&lt;/ol>
&lt;p>所以就如本文一开始所说的，PD 就像是一个容器，将一些 RDMA 资源保护起来，彼此隔离，以提高安全性。其实 RDMA 中不止有 QP、MR 这些资源，后文即将介绍的 Address Handle，Memory Window 等也是由 PD 进行隔离保护的。&lt;/p>
&lt;h2 id="如何使用-pd">如何使用 PD&lt;/h2>
&lt;p>还是看上面的图，我们注意到 Node 0 为了隔离资源，存在两个 PD；而 Node 1 和 Node 2 只有一个 PD 包含了所有资源。&lt;/p>
&lt;p>我之所以这样画，是为了说明一个节点上划分多少个 PD 完全是由用户决定的，&lt;strong>如果想提高安全性，那么对每个连接到远端节点的 QP 和供远端访问的 MR 都应该尽量通过划分 PD 做到隔离；如果不追求更高的安全性，那么创建一个 PD，囊括所有的资源也是可以的&lt;/strong>。&lt;/p>
&lt;p>IB 协议中规定：&lt;strong>每个节点都至少要有一个 PD，每个 QP 都必须属于一个 PD，每个 MR 也必须属于一个 PD&lt;/strong>。&lt;/p>
&lt;p>那么 PD 的包含关系在软件上是如何体现的呢？它本身是有一个软件实体的（结构体），记录了这个保护域的一些信息。用户在创建 QP 和 MR 等资源之前，必须先通过 IB 框架的接口创建一个 PD，拿到它的指针/句柄。接下来在创建 QP 和 MR 的时候，需要传入这个 PD 的指针/句柄，PD 信息就会包含在 QP 和 MR 中。硬件收发包时，会对 QP 和 MR 的 PD 进行校验。更多的软件协议栈的内容，我会在后面的文章中介绍。&lt;/p>
&lt;p>另外需要强调的是，&lt;strong>PD 是本地概念，仅存在于节点内部&lt;/strong>，对其他节点是不可见的；而 MR 是对本端和对端都可见的。&lt;/p>
&lt;p>为了方便大家查阅和学习，以后我会列出文章涉及的协议章节，前面的内容有时间的时候我也会补充一下。&lt;/p>
&lt;h2 id="pd-相关协议章节">PD 相关协议章节&lt;/h2>
&lt;ul>
&lt;li>3.5.5 PD 的基本概念和作用&lt;/li>
&lt;li>10.2.3 介绍了 PD 和其他一些 RDMA 资源的关系，以及 PD 相关的软件接口。&lt;/li>
&lt;li>10.6.3.5 再次强调 PD 和 MR 及 QP 的关系。&lt;/li>
&lt;li>11.2.1.5 详细介绍 PD 的 Verbs 接口，包括作用、入参、出参和返回值等。&lt;/li>
&lt;/ul>
&lt;p>好了，关于 PD 的介绍就到这里。下文我会介绍用于 UD 服务类型的 Address Handle 的概念。&lt;/p></description></item><item><title>RDMA 之 Memory Region</title><link>https://cuterwrite.top/p/rdma-mr/</link><pubDate>Wed, 03 Apr 2024 16:17:00 +0000</pubDate><guid>https://cuterwrite.top/p/rdma-mr/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/8fa232626b76940fddc8cc52a49c49e9195413-2024-04-04.webp" alt="Featured image of post RDMA 之 Memory Region" />&lt;h1 id="rdma-之-memory-region">RDMA 之 Memory Region&lt;/h1>
&lt;p>&lt;strong>本文欢迎非商业转载，转载请注明出处。&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>声明：仅用于收藏，便于阅读&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/156975042">&lt;cite>知乎专栏：6. RDMA 之 Memory Region&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>我们假设一种场景，同时也顺便温习一下 RDMA WRITE 操作的流程：&lt;/p>
&lt;p>如下图所示，A 节点想要通过 IB 协议向 B 节点的内存中写入一段数据，上层应用给本节点的 RDMA 网卡下发了一个 WQE，WQE 中包含了源内存地址、目的内存地址、数据长度和秘钥等信息，然后硬件会从内存中取出数据，组包发送到对端网卡。B 节点的网卡收到数据后，解析到其中的目的内存地址，把数据写入到本节点的内存中。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/6_1-2024-04-04.webp"
alt="6_1-2024-04-04" width="auto" loading="lazy">
&lt;/figure>
&lt;p>那么问题来了，APP 提供的地址都是虚拟地址（Virtual Address，下文称 VA），经过 MMU 的转换才能得到真实的物理地址（Physical Address，下文称 PA），我们的&lt;strong>RDMA 网卡是如何得到 PA 从而去内存中拿到数据的呢&lt;/strong>？就算网卡知道上哪去取数据，&lt;strong>如果用户恶意指定了一个非法的 VA，那网卡岂不是有可能被“指使”去读写关键内存&lt;/strong>？&lt;/p>
&lt;p>为了解决上面的问题，IB 协议提出了 MR 的概念。&lt;/p>
&lt;h2 id="mr-是什么">MR 是什么&lt;/h2>
&lt;p>MR 全称为 Memory Region，指的是由 RDMA 软件层在内存中规划出的一片区域，用于存放收发的数据。IB 协议中，用户在申请完用于存放数据的内存区域之后，都需要通过调用 IB 框架提供的 API 注册 MR，才能让 RDMA 网卡访问这片内存区域。由下图可以看到，MR 就是一片特殊的内存而已：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/6_2-2024-04-04.webp"
alt="6_2-2024-04-04" width="auto" loading="lazy">
&lt;/figure>
&lt;p>在对 IB 协议进行相关描述时，我们通常称 RDMA 硬件为&lt;strong>HCA（Host Channel Adapter， 宿主通道适配器）&lt;/strong>，IB 协议中对其的定义是“处理器和 I/O 单元中能够产生和消耗数据包的 IB 设备”，为了与协议保持一致，我们在包括本文及之后的文章中都称硬件部分为 HCA。&lt;/p>
&lt;h2 id="为什么要注册-mr">为什么要注册 MR&lt;/h2>
&lt;p>下面我们来看一下 MR 是如何解决本文开篇提出的两个问题的：&lt;/p>
&lt;h3 id="1-注册-mr-以实现虚拟地址与物理地址转换">1. 注册 MR 以实现虚拟地址与物理地址转换&lt;/h3>
&lt;p>我们都知道 APP 只能看到虚拟地址，而且会在 WQE 中直接把 VA 传递给 HCA（既包括本端的源 VA，也包括对端的目的 VA）。现在的 CPU 都有 MMU 和页表这一“利器”来进行 VA 和 PA 之间的转换，而 HCA 要么直接连接到总线上，要么通过 IOMMU/SMMU 做地址转换后连接到总线上，它是“看不懂”APP 提供的 VA 所对应的真实物理内存地址的。&lt;/p>
&lt;p>所以注册 MR 的过程中，硬件会在内存中创建并填写一个 VA to PA 的映射表，这样需要的时候就能通过查表把 VA 转换成 PA 了。我们还是提供一个具体的例子来讲一下这个过程：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/6_3-2024-04-04.webp"
alt="6_3-2024-04-04" width="auto" loading="lazy">
&lt;/figure>
&lt;p>现在假设左边的节点向右边的节点发起了 RDMA WRITE 操作，即直接向右节点的内存区域中写入数据。假设图中两端都已经完成了注册 MR 的动作，MR 即对应图中的“数据 Buffer”，同时也创建好了 VA-&amp;gt;PA 的映射表。&lt;/p>
&lt;ul>
&lt;li>首先本端 APP 会下发一个 WQE 给 HCA，告知 HCA，用于存放待发送数据的本地 Buffer 的虚拟地址，以及即将写入的对端数据 Buffer 的虚拟地址。&lt;/li>
&lt;li>本端 HCA 查询 VA-&amp;gt;PA 映射表，得知待发数据的物理地址，然后从内存中拿到数据，组装数据包并发送出去。&lt;/li>
&lt;li>对端 HCA 收到了数据包，从中解析出了目的 VA。&lt;/li>
&lt;li>对端 HCA 通过存储在本地内存中的 VA-&amp;gt;PA 映射表，查到真实的物理地址，核对权限无误后，将数据存放到内存中。&lt;/li>
&lt;/ul>
&lt;p>再次强调一下，对于右侧节点来说，&lt;strong>无论是地址转换还是写入内存，完全不用其 CPU 的参与&lt;/strong>。&lt;/p>
&lt;h3 id="2-mr-可以控制-hca-访问内存的权限">2. MR 可以控制 HCA 访问内存的权限&lt;/h3>
&lt;p>因为 HCA 访问的内存地址来自于用户，如果用户传入了一个非法的地址（比如系统内存或者其他进程使用的内存），HCA 对其进行读写可能造成信息泄露或者内存覆盖。所以我们需要一种机制来确保 HCA 只能访问已被授权的、安全的内存地址。IB 协议中，APP 在为数据交互做准备的阶段，需要执行注册 MR 的动作。&lt;/p>
&lt;p>而用户注册 MR 的动作会产生两把钥匙——L_KEY（Local Key）和 R_KEY（Remote Key），说是钥匙，它们的实体其实就是一串序列而已。它们将分别用于保障对于本端和远端内存区域的访问权限。下面两张图分别是描述 L_Key 和 R_Key 的作用的示意图：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/6_4-2024-04-04.webp"
alt="6_4-2024-04-04" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>L_Key&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/6_5-2024-04-04.webp"
alt="6_5-2024-04-04" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>R_Key&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>这里大家可能会有疑问，本端是如何知道对端节点的可用 VA 和对应的 R_Key 的？其实两端的节点在真正的 RDMA 通信之前，都会通过某些方式先建立一条链路（可能是 Socket 连接，也可能是 CM 连接）并通过这条链路交换一些 RDMA 通信所必须的信息（VA，Key，QPN 等），我们称这一过程叫做“建链”和“握手”。我将在后面的文章中详细介绍。&lt;/p>
&lt;p>除了上面两个点之外，注册 MR 还有个重要的作用：&lt;/p>
&lt;h3 id="3-mr-可以避免换页">3. MR 可以避免换页&lt;/h3>
&lt;p>因为物理内存是有限的，所以操作系统通过换页机制来暂时把某个进程不用的内存内容保存到硬盘中。当该进程需要使用时，再通过缺页中断把硬盘中的内容搬移回内存，这一过程几乎必然导致 VA-PA 的映射关系发生改变。&lt;/p>
&lt;p>由于 HCA 经常会绕过 CPU 对用户提供的 VA 所指向的物理内存区域进行读写，如果前后的 VA-PA 映射关系发生改变，那么我们在前文提到的 VA-&amp;gt;PA 映射表将失去意义，HCA 将无法找到正确的物理地址。&lt;/p>
&lt;p>为了防止换页所导致的 VA-PA 映射关系发生改变，注册 MR 时会 &amp;ldquo;Pin&amp;rdquo; 住这块内存（亦称“锁页”），即锁定 VA-PA 的映射关系。也就是说，MR 这块内存区域会长期存在于物理内存中不被换页，直到完成通信之后，用户主动注销这片 MR。&lt;/p>
&lt;p>好了，至此我们介绍完了 MR 的概念和作用，下一篇文章我将给大家介绍一下 PD（Protection Domain，保护域）的概念。&lt;/p>
&lt;h2 id="代码示例">代码示例&lt;/h2>
&lt;p>下面是一个简单的 RDMA 程序，展示了如何注册 MR：&lt;/p>
&lt;pre>&lt;code class="language-c">#include &amp;lt;infiniband/verbs.h&amp;gt;
int main() {
// 省略初始化过程...
struct ibv_mr *mr;
mr = ibv_reg_mr(pd, buf, 1024, IBV_ACCESS_LOCAL_WRITE |
IBV_ACCESS_REMOTE_WRITE);
// 获取 L_Key 和 R_Key
uint32_t lkey = mr-&amp;gt;lkey;
uint32_t rkey = mr-&amp;gt;rkey;
// 省略其它代码...
}
&lt;/code>&lt;/pre></description></item><item><title>记录：安装 Intel® OneAPI-2024.0</title><link>https://cuterwrite.top/p/intel-oneapi/</link><pubDate>Fri, 08 Mar 2024 14:39:00 +0000</pubDate><guid>https://cuterwrite.top/p/intel-oneapi/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/crop_62cf8bae89f60c3522eb45af53a53f4b195413-2024-03-09.webp" alt="Featured image of post 记录：安装 Intel® OneAPI-2024.0" />&lt;h1 id="记录安装-intel-oneapi-20240">记录：安装 Intel® OneAPI-2024.0&lt;/h1>
&lt;p>Intel one API 由两个部分组成，前者为基础 Base Toolkit ，后者必须依赖前者，Intel one API HPC Toolkit，也就是要前后依次安装。&lt;/p>
&lt;h2 id="base-toolkit">Base Toolkit&lt;/h2>
&lt;p>Base Toolkit 是 Intel 的一个 API 基础工具包包括以下库和其他库&lt;/p>
&lt;pre>&lt;code class="language-text">Intel® oneAPI DPC++/C++ Compiler
Intel® DPC++ Compatibility Tool
Intel® oneAPI DPC++ Library
Intel® oneAPI Math Kernel Library
Intel® oneAPI Threading Building Blocks
Intel® oneAPI Collective Communications Library
Intel® oneAPI Data Analytics Library
Intel® oneAPI Deep Neural Networks Library
Intel® Integrated Performance Primitives
Intel® VTune™ Profiler
Intel® Advisor
Intel® Distribution for GDB*
Intel® Distribution for Python* (separate download required)
Intel® FPGA Add-on for oneAPI Base Toolkit (separate download required)
&lt;/code>&lt;/pre>
&lt;h3 id="base-toolkit-安装">Base Toolkit 安装&lt;/h3>
&lt;ol>
&lt;li>下载安装包&lt;/li>
&lt;/ol>
&lt;pre>&lt;code class="language-bash">$ wget https://registrationcenter-download.intel.com/akdlm/IRC_NAS/163da6e4-56eb-4948-aba3-debcec61c064/l_BaseKit_p_2024.0.1.46_offline.sh
&lt;/code>&lt;/pre>
&lt;ol start="2">
&lt;li>安装&lt;/li>
&lt;/ol>
&lt;pre>&lt;code class="language-bash">$ chmod +x l_BaseKit_p_2024.0.1.46_offline.sh
$ sudo ./l_BaseKit_p_2024.0.1.46_offline.sh
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>如果自定义安装在用户目录，就不需要 root 权限&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>./l_BaseKit_p_2024.0.1.46_offline.sh
&lt;/code>&lt;/pre>
&lt;p>然后将启动一个图形安装界面，继续操作：&lt;/p>
&lt;p>&lt;strong>（1）选择 Accept &amp;amp; customize&lt;/strong>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/OneAPI-Accepet-2024-03-09.png"
alt="OneAPI-Accepet-2024-03-09" width="auto" loading="lazy">
&lt;/figure>
&lt;/p>
&lt;p>&lt;strong>（2）选择安装的组件&lt;/strong>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/OneAPI-Select-2-2024-03-09.png"
alt="OneAPI-Select-2-2024-03-09" width="auto" loading="lazy">
&lt;/figure>
&lt;/p>
&lt;p>&lt;strong>（3）选择安装的路径&lt;/strong>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/OneAPI-Select-3-2024-03-09.png"
alt="OneAPI-Select-3-2024-03-09" width="auto" loading="lazy">
&lt;/figure>
&lt;/p>
&lt;p>&lt;strong>（4）选择 Next&lt;/strong>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/OneAPI-Select-4-2024-03-09.png"
alt="OneAPI-Select-4-2024-03-09" width="auto" loading="lazy">
&lt;/figure>
&lt;/p>
&lt;p>&lt;strong>（5）选择 2 然后开始安装&lt;/strong>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/OneAPI-Select-5-2024-03-09.png"
alt="OneAPI-Select-5-2024-03-09" width="auto" loading="lazy">
&lt;/figure>
&lt;/p>
&lt;p>接下来等待安装完成即可。&lt;/p>
&lt;h2 id="hpc-toolkit">HPC Toolkit&lt;/h2>
&lt;p>运行基于 Base Toolkit ，这个必须作为后者安装&lt;/p>
&lt;pre>&lt;code class="language-text">Intel® Fortran Compiler
Intel® Fortran Compiler Classic
Intel® Inspector
Intel® MPI Library
Intel® Trace Analyzer and Collector
&lt;/code>&lt;/pre>
&lt;h3 id="hpc-toolkit-安装">HPC Toolkit 安装&lt;/h3>
&lt;ol>
&lt;li>下载安装包&lt;/li>
&lt;/ol>
&lt;pre>&lt;code class="language-bash">$ wget https://registrationcenter-download.intel.com/akdlm/IRC_NAS/67c08c98-f311-4068-8b85-15d79c4f277a/l_HPCKit_p_2024.0.1.38_offline.sh
&lt;/code>&lt;/pre>
&lt;ol start="2">
&lt;li>安装&lt;/li>
&lt;/ol>
&lt;pre>&lt;code class="language-bash">$ chmod +x l_HPCKit_p_2024.0.1.38_offline.sh
$ sudo ./l_HPCKit_p_2024.0.1.38_offline.sh
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>如果自定义安装在用户目录，就不需要 root 权限&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>./l_HPCKit_p_2024.0.1.38_offline.sh
&lt;/code>&lt;/pre>
&lt;p>必须安装的库文件： Intel® MPI Library Intel® Fortran Compiler (Beta) &amp;amp; Intel® Fortran Compiler Classic Intel® oneAPI DPC++/C++ Compiler &amp;amp; Intel® C++ Compiler Classic&lt;/p>
&lt;p>安装过程与 Base Toolkit 类似，不再赘述。&lt;/p>
&lt;h2 id="环境配置">环境配置&lt;/h2>
&lt;p>安装完成后，需要配置环境变量，以便在终端中使用 Intel® oneAPI 工具。&lt;/p>
&lt;p>在 HPC 环境中，使用 &lt;code>modulefile&lt;/code> 来管理环境变量，可以使用 &lt;code>module&lt;/code> 命令来加载环境变量。&lt;/p>
&lt;p>以下是参考的 &lt;code>modulefile&lt;/code> 文件，可以根据自己的安装路径进行修改。&lt;/p>
&lt;pre>&lt;code class="language-modulefile">#%Module1.0#####################################################################
##
## modules modulefile
##
proc ModulesHelp { } {
global version prefix
puts stderr &amp;quot;\tmodules - loads the modules software &amp;amp; application environment&amp;quot;
puts stderr &amp;quot;\n\tThis adds $prefix/* to several of the&amp;quot;
puts stderr &amp;quot;\tenvironment variables.&amp;quot;
puts stderr &amp;quot;\n\tVersion $version\n&amp;quot;
}
module-whatis &amp;quot;loads intel/oneapi2024.0&amp;quot;
# for Tcl script use only
set version oneapi2024.0
set prefix /opt/software/intel/oneapi2024.0
conflict intel
prepend-path TBBROOT ${prefix}/tbb/2021.11/env/..
prepend-path DAALROOT ${prefix}/cdal/2024.0
prepend-path DPCT_BUNDLE_ROOT ${prefix}/dpcpp-ct/2024.0
prepend-path INSPECTOR_2023_DIR ${prefix}/inspector/2024.0
prepend-path ONEAPI_ROOT ${prefix}
prepend-path PKG_CONFIG_PATH ${prefix}/vtune/2024.0/include/pkgconfig/lib64:${prefix}/tbb/2021.11/env/../lib/pkgconfig:${prefix}/mpi/2021.11/lib/pkgconfig:${prefix}/mkl/2024.0/lib/pkgconfig:${prefix}/ippcp/2021.9/lib/pkgconfig:${prefix}/inspector/2024.0/include/pkgconfig/lib64:${prefix}/dpl/2022.3/lib/pkgconfig:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/../lib/pkgconfig:${prefix}/cdal/2024.0/lib/pkgconfig:${prefix}/compiler/2024.0/lib/pkgconfig:${prefix}/ccl/2021.11/lib/pkgconfig:${prefix}/advisor/2024.0/include/pkgconfig/lib64:
#prepend-path PKG_CONFIG_PATH ${prefix}/vtune/2024.0/include/pkgconfig/lib64:${prefix}/tbb/2021.11/env/../lib/pkgconfig:${prefix}/mkl/2024.0/lib/pkgconfig:${prefix}/ippcp/2021.9/lib/pkgconfig:${prefix}/inspector/2024.0/include/pkgconfig/lib64:${prefix}/dpl/2022.3/lib/pkgconfig:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/../lib/pkgconfig:${prefix}/cdal/2024.0/lib/pkgconfig:${prefix}/compiler/2024.0/lib/pkgconfig:${prefix}/ccl/2021.11/lib/pkgconfig:${prefix}/advisor/2024.0/include/pkgconfig/lib64:
prepend-path VT_MPI impi4
prepend-path ACL_BOARD_VENDOR_PATH /opt/Intel/OpenCLFPGA/oneAPI/Boards
prepend-path FPGA_VARS_DIR ${prefix}/compiler/2024.0/lib/oclfpga
prepend-path CCL_ROOT ${prefix}/ccl/2021.11
prepend-path VT_ADD_LIBS &amp;quot;-ldwarf -lelf -lvtunwind -lm -lpthread&amp;quot;
prepend-path I_MPI_ROOT ${prefix}/mpi/2021.11
prepend-path FI_PROVIDER_PATH ${prefix}/mpi/2021.11//libfabric/lib/prov:/usr/lib/x86_64-linux-gnu/libfabric
prepend-path DNNLROOT ${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp
prepend-path DIAGUTIL_PATH ${prefix}/vtune/2024.0/sys_check/vtune_sys_check.py:${prefix}/dpcpp-ct/2024.0/sys_check/sys_check.sh:${prefix}/debugger/2024.0/sys_check/debugger_sys_check.py:${prefix}/compiler/2024.0/sys_check/sys_check.sh:${prefix}/advisor/2024.0/sys_check/advisor_sys_check.py:
prepend-path CCL_CONFIGURATION cpu_gpu_dpcpp
prepend-path DPL_ROOT ${prefix}/dpl/2022.3
prepend-path MANPATH ${prefix}/mpi/2021.11/man:${prefix}/itac/2022.0/man:${prefix}/debugger/2024.0/documentation/man:${prefix}/compiler/2024.0/documentation/en/man/common:::
#prepend-path MANPATH ${prefix}/itac/2022.0/man:${prefix}/debugger/2024.0/documentation/man:${prefix}/compiler/2024.0/documentation/en/man/common:::
prepend-path GDB_INFO ${prefix}/debugger/2024.0/documentation/info/
prepend-path SETVARS_COMPLETED 1
prepend-path APM ${prefix}/advisor/2024.0/perfmodels
prepend-path CMAKE_PREFIX_PATH ${prefix}/tbb/2021.11/env/..:${prefix}/ipp/2021.10/lib/cmake/ipp:${prefix}/ipp/2021.10/lib/cmake/ipp:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/../lib/cmake:${prefix}/cdal/2024.0:${prefix}/compiler/2024.0/IntelDPCPP:${prefix}/ccl/2021.11/lib/cmake/oneCCL
prepend-path VTUNE_PROFILER_2023_DIR ${prefix}/vtune/2024.0
prepend-path CMPLR_ROOT ${prefix}/compiler/2024.0
prepend-path ADVISOR_2023_DIR ${prefix}/advisor/2024.0
prepend-path FPGA_VARS_ARGS &amp;quot;&amp;quot;
prepend-path INFOPATH ${prefix}/debugger/2024.0/gdb/intel64/lib
prepend-path IPPROOT ${prefix}/ipp/2021.10
prepend-path IPP_TARGET_ARCH intel64
prepend-path PYTHONPATH ${prefix}/advisor/2024.0/pythonapi
prepend-path VT_ROOT ${prefix}/itac/2022.0
prepend-path DALROOT ${prefix}/cdal/2024.0
prepend-path LIBRARY_PATH ${prefix}/tbb/2021.11/env/../lib/intel64/gcc4.8:${prefix}/mpi/2021.11//libfabric/lib:${prefix}/mpi/2021.11//lib/release:${prefix}/mpi/2021.11//lib:${prefix}/mkl/2024.0/lib/intel64:${prefix}/ipp/2021.10/lib/intel64:${prefix}/ippcp/2021.9/lib/intel64:${prefix}/ipp/2021.10/lib/intel64:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/lib:${prefix}/cdal/2024.0/lib/intel64:${prefix}/compiler/2024.0/compiler/lib/intel64_lin:${prefix}/compiler/2024.0/lib:${prefix}/ccl/2021.11/lib/cpu_gpu_dpcpp
#prepend-path LIBRARY_PATH ${prefix}/tbb/2021.11/env/../lib/intel64/gcc4.8:${prefix}/mkl/2024.0/lib/intel64:${prefix}/ipp/2021.10/lib/intel64:${prefix}/ippcp/2021.9/lib/intel64:${prefix}/ipp/2021.10/lib/intel64:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/lib:${prefix}/cdal/2024.0/lib/intel64:${prefix}/compiler/2024.0/compiler/lib/intel64_lin:${prefix}/compiler/2024.0/lib:${prefix}/ccl/2021.11/lib/cpu_gpu_dpcpp
prepend-path DAL_MAJOR_BINARY 1
prepend-path IPPCRYPTOROOT ${prefix}/ippcp/2021.9
prepend-path IPPCP_TARGET_ARCH intel64
prepend-path OCL_ICD_FILENAMES libintelocl_emu.so:libalteracl.so:${prefix}/compiler/2024.0/lib/x64/libintelocl.so
prepend-path CLASSPATH ${prefix}/mpi/2021.11//lib/mpi.jar:${prefix}/cdal/2024.0/lib/onedal.jar
#prepend-path CLASSPATH ${prefix}/cdal/2024.0/lib/onedal.jar
prepend-path INTELFPGAOCLSDKROOT ${prefix}/compiler/2024.0/lib/oclfpga
prepend-path LD_LIBRARY_PATH ${prefix}/tbb/2021.11/env/../lib/intel64/gcc4.8:${prefix}/mpi/2021.11//libfabric/lib:${prefix}/mpi/2021.11//lib/release:${prefix}/mpi/2021.11//lib:${prefix}/mkl/2024.0/lib/intel64:${prefix}/itac/2022.0/slib:${prefix}/ipp/2021.10/lib/intel64:${prefix}/ippcp/2021.9/lib/intel64:${prefix}/ipp/2021.10/lib/intel64:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/lib:${prefix}/debugger/2024.0/gdb/intel64/lib:${prefix}/debugger/2024.0/libipt/intel64/lib:${prefix}/debugger/2024.0/dep/lib:${prefix}/cdal/2024.0/lib/intel64:${prefix}/compiler/2024.0/lib:${prefix}/compiler/2024.0/lib/x64:${prefix}/compiler/2024.0/lib/oclfpga/host/linux64/lib:${prefix}/compiler/2024.0/compiler/lib/intel64_lin:${prefix}/ccl/2021.11/lib/cpu_gpu_dpcpp:${prefix}/compiler/2024.0/compiler/lib/intel64_lin:${prefix}/ccl/2021.11/lib/cpu_gpu_dpcpp
#prepend-path LD_LIBRARY_PATH ${prefix}/tbb/2021.11/env/../lib/intel64/gcc4.8:${prefix}/mkl/2024.0/lib/intel64:${prefix}/itac/2022.0/slib:${prefix}/ipp/2021.10/lib/intel64:${prefix}/ippcp/2021.9/lib/intel64:${prefix}/ipp/2021.10/lib/intel64:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/lib:${prefix}/debugger/2024.0/gdb/intel64/lib:${prefix}/debugger/2024.0/libipt/intel64/lib:${prefix}/debugger/2024.0/dep/lib:${prefix}/cdal/2024.0/lib/intel64:${prefix}/compiler/2024.0/lib:${prefix}/compiler/2024.0/lib/x64:${prefix}/compiler/2024.0/lib/oclfpga/host/linux64/lib:${prefix}/compiler/2024.0/compiler/lib/intel64_lin:${prefix}/ccl/2021.11/lib/cpu_gpu_dpcpp:${prefix}/compiler/2024.0/compiler/lib/intel64_lin:${prefix}/ccl/2021.11/lib/cpu_gpu_dpcpp
prepend-path VT_LIB_DIR ${prefix}/itac/2022.0/lib
prepend-path VTUNE_PROFILER_DIR ${prefix}/vtune/2024.0
prepend-path VT_SLIB_DIR ${prefix}/itac/2022.0/slib
prepend-path MKLROOT ${prefix}/mkl/2024.0
prepend-path DAL_MINOR_BINARY 1
prepend-path NLSPATH ${prefix}/mkl/2024.0/lib/intel64/locale/%l_%t/%N:${prefix}/compiler/2024.0/compiler/lib/intel64_lin/locale/%l_%t/%N
prepend-path PATH ${prefix}/vtune/2024.0/bin64:${prefix}/mpi/2021.11//libfabric/bin:${prefix}/mpi/2021.11//bin:${prefix}/mkl/2024.0/bin/intel64:${prefix}/itac/2022.0/bin:${prefix}/inspector/2024.0/bin64:${prefix}/dpcpp-ct/2024.0/bin:${prefix}/dev-utilities/2024.0/bin:${prefix}/debugger/2024.0/gdb/intel64/bin:${prefix}/compiler/2024.0/lib/oclfpga/bin:${prefix}/compiler/2024.0/bin/intel64:${prefix}/compiler/2024.0/bin:${prefix}/advisor/2024.0/bin64
#prepend-path PATH ${prefix}/vtune/2024.0/bin64:${prefix}/mkl/2024.0/bin/intel64:${prefix}/itac/2022.0/bin:${prefix}/inspector/2024.0/bin64:${prefix}/dpcpp-ct/2024.0/bin:${prefix}/dev-utilities/2024.0/bin:${prefix}/debugger/2024.0/gdb/intel64/bin:${prefix}/compiler/2024.0/lib/oclfpga/bin:${prefix}/compiler/2024.0/bin/intel64:${prefix}/compiler/2024.0/bin:${prefix}/advisor/2024.0/bin64
prepend-path INTEL_PYTHONHOME ${prefix}/debugger/2024.0/dep
prepend-path INTEL_LICENSE_FILE /opt/intel/licenses:/root/intel/licenses
prepend-path CPATH ${prefix}/tbb/2021.11/env/../include:${prefix}/mpi/2021.11//include:${prefix}/mkl/2024.0/include:${prefix}/ipp/2021.10/include:${prefix}/ippcp/2021.9/include:${prefix}/ipp/2021.10/include:${prefix}/dpl/2022.3/linux/include:${prefix}/dpcpp-ct/2024.0/include:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/include:${prefix}/dev-utilities/2024.0/include:${prefix}/cdal/2024.0/include:${prefix}/compiler/2024.0/lib/oclfpga/include:${prefix}/ccl/2021.11/include/cpu_gpu_dpcpp
#prepend-path CPATH ${prefix}/tbb/2021.11/env/../include:${prefix}/mkl/2024.0/include:${prefix}/ipp/2021.10/include:${prefix}/ippcp/2021.9/include:${prefix}/ipp/2021.10/include:${prefix}/dpl/2022.3/linux/include:${prefix}/dpcpp-ct/2024.0/include:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/include:${prefix}/dev-utilities/2024.0/include:${prefix}/cdal/2024.0/include:${prefix}/compiler/2024.0/lib/oclfpga/include:${prefix}/ccl/2021.11/include/cpu_gpu_dpcpp
&lt;/code>&lt;/pre>
&lt;h2 id="运行测试">运行测试&lt;/h2>
&lt;p>通过 &lt;code>module load&lt;/code> 命令加载环境变量&lt;/p>
&lt;pre>&lt;code class="language-bash">$ module load intel/oneapi2024.0
&lt;/code>&lt;/pre>
&lt;p>测试是否安装成功&lt;/p>
&lt;pre>&lt;code class="language-bash">$ icx -v
&lt;/code>&lt;/pre>
&lt;p>如果输出版本信息，则安装成功。&lt;/p>
&lt;pre>&lt;code class="language-bash">Intel(R) oneAPI DPC++/C++ Compiler 2024.0.2 (2024.0.2.20231213)
Target: x86_64-unknown-linux-gnu
Thread model: posix
InstalledDir: /opt/software/intel/oneapi2024.0/compiler/2024.0/bin/compiler
Configuration file: /opt/software/intel/oneapi2024.0/compiler/2024.0/bin/compiler/../icx.cfg
Found candidate GCC installation: /opt/rh/devtoolset-11/root/usr/lib/gcc/x86_64-redhat-linux/11
Selected GCC installation: /opt/rh/devtoolset-11/root/usr/lib/gcc/x86_64-redhat-linux/11
Candidate multilib: .;@m64
Candidate multilib: 32;@m32
Selected multilib: .;@m64
&lt;/code>&lt;/pre>
&lt;p>继续测试 MPI&lt;/p>
&lt;pre>&lt;code class="language-bash">$ mpirun --version
&lt;/code>&lt;/pre>
&lt;p>如果输出版本信息，则安装成功。&lt;/p>
&lt;pre>&lt;code class="language-bash">Intel(R) MPI Library for Linux* OS, Version 2021.11 Build 20231005 (id: 74c4a23)
Copyright 2003-2023, Intel Corporation.
&lt;/code>&lt;/pre>
&lt;h2 id="icx-说明">icx 说明&lt;/h2>
&lt;blockquote>
&lt;p>&lt;strong>Intel® oneAPI DPC++/C++ Compiler (icx)&lt;/strong> is Intel nextgen compiler based on Clang /LLVM technology plus Intel proprietary optimizations and code generation.&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Intel®, &lt;/span>&lt;a href="https://www.intel.cn/content/www/cn/zh/developer/articles/technical/adoption-of-llvm-complete-icx.html">&lt;cite>Intel® C/C&amp;#43;&amp;#43; Compilers Complete Adoption of LLVM&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>icx 是基于 Clang /LLVM 技术的 Intel 下一代编译器，加上 Intel 专有的优化和代码生成。&lt;/p>
&lt;p>LLVM 帮助实现了为英特尔架构提供更加优秀的 C/C++编译器这一目标。最新的英特尔 C/C++编译器使用 LLVM 架构，可提供更快的编译时间、更好的优化、增强的标准支持以及对 GPU 和 FPGA 负载转移（offloading）的支持。&lt;/p>
&lt;h3 id="采用-llvm-的好处">采用 LLVM 的好处&lt;/h3>
&lt;p>LLVM 开源项目是模块化和可重用的编译器和一系列工具链技术的集合，整个项目支持多种处理器架构和编程语言。Clang 开源项目提供了一个 C/C++前端，为 LLVM 项目支持了最新的语言标准。包括 Clang 在内，LLVM 是由一个庞大且非常活跃的开发社区维护的。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/v2-7ac93f64b283ba0b5c5371b7cd524210_1440w-2024-03-09.webp"
alt="v2-7ac93f64b283ba0b5c5371b7cd524210_1440w-2024-03-09" width="auto" loading="lazy">
&lt;/figure>
&lt;p>采用 LLVM 的好处有很多，第一条要说的是更快的构建时间。众所周知，Clang 是很快的！我们使用英特尔 oneAPI 2021.3 工具包中的英特尔 C/C++编译器时，测得构建时间减少了 14％。除了减少构建时间外，采用 Clang 使我们可以从社区支持最新 C++语言标准的一系列成果中受益，并贡献成果来反哺社区。&lt;/p>
&lt;p>英特尔为开源项目提供贡献和支持的历史颇为悠久，其中向 LLVM 做出贡献就有十年时间了。我们今天的主动合作行为包括了优化报告补充、扩大的浮点模型支持，以及向量增强。英特尔直接对 LLVM 项目做出贡献，也有一个临时区域（英特尔 LLVM 技术项目），针对 SYCL 支持。&lt;/p>
&lt;p>在英特尔架构上，英特尔 C/C++编译器预期能提供比基础 Clang+LLVM 编译器更高的性能。接下来英特尔 C/C++编译器都会是采用了 LLVM 开源基础架构的版本（icx）。我们会继续之前的长期努力，持续为 Clang 和 LLVM 项目做出贡献，包括为它们提供优化。并非所有的优化技术都会被上游采纳，有时是因为它们太新了，有时因为它们过于针对英特尔架构。这是可以预料的，并且与其他已经采用 LLVM 的编译器是同样的情况。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/v2-1a1672571e4a8a60c335e5abe38ee86b_1440w-2024-03-09.webp"
alt="v2-1a1672571e4a8a60c335e5abe38ee86b_1440w-2024-03-09" width="auto" loading="lazy">
&lt;/figure>
&lt;p>英特尔 C/C++编译器一直都在提供最优秀的性能。经典版本的英特尔 C/C++编译器取得了对 GCC 18％的优势，而基于 LLVM 的英特尔 C/C++编译器取得了 41％的优势。&lt;/p></description></item><item><title>笔记：Pure - 改进消息传递以更好地利用节点内的共享内存</title><link>https://cuterwrite.top/p/pure/</link><pubDate>Sun, 03 Mar 2024 01:16:00 +0000</pubDate><guid>https://cuterwrite.top/p/pure/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/crop_e9af4c445d695be5002248c7c814c67d195413-2024-03-04.webp" alt="Featured image of post 笔记：Pure - 改进消息传递以更好地利用节点内的共享内存" />&lt;h1 id="笔记pure-改进消息传递以更好地利用节点内的共享内存">笔记：Pure: 改进消息传递以更好地利用节点内的共享内存&lt;/h1>
&lt;h2 id="引用出处">引用出处&lt;/h2>
&lt;p>James Psota and Armando Solar-Lezama. 2024. Pure: Evolving Message Passing To Better Leverage Shared Memory Within Nodes. In Proceedings of the 29th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming (&lt;strong>PPoPP &amp;lsquo;24&lt;/strong>). Association for Computing Machinery, New York, NY, USA, 133–146. &lt;a class="link" href="https://doi.org/10.1145/3627535.3638503" target="_blank" rel="noopener" >https://doi.org/10.1145/3627535.3638503
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/p>
&lt;h2 id="关键词">关键词&lt;/h2>
&lt;ul>
&lt;li>并行编程模型&lt;/li>
&lt;li>分布式运行时系统&lt;/li>
&lt;li>基于任务的并行模型&lt;/li>
&lt;li>并发数据结构&lt;/li>
&lt;li>无锁数据结构&lt;/li>
&lt;/ul>
&lt;h2 id="摘要">摘要&lt;/h2>
&lt;p>Pure 是一种新的编程模型和运行时系统，旨在在基于消息传递接口（增强使用任务利用空闲核心能力）的环境中充分利用节点内部的共享内存。Pure 通过两种方式利用共享内存：(1) 允许 rank 在等待消息到达时从彼此那里窃取工作；(2) 利用高效无锁的数据结构实现节点内各进程间高性能的消息传递和集合操作。研究者通过 micro benchmark 测试评估了 Pure 的关键消息传递和集合特性，并展示了在 CoMD 分子动力学和 miniAMR 自适应网格细化应用中，当扩展到 4096 个 rank 时，Pure 可实现高达 &lt;strong>2.1x&lt;/strong> 的应用加速。&lt;/p>
&lt;h2 id="1-引言">1. 引言&lt;/h2>
&lt;p>在过去的几十年里，高性能计算领域经历了从大型向量计算机到由单处理器构成的集群的转变，这些集群通过网络互连。MPI 成为了分布式内存系统上并行编程的事实标准。随着硬件的进步，多核集群的出现使得节点内的核心能够共享内存并通过网络进行通信，这促使社区不断寻求新的范式，以更有效地利用现代集群资源。目前主要的策略有两种：一种是维持统一的 MPI 编程方法，通过改进 MPI 运行时系统来更好地利用共享内存；另一种是采用 MPI+X 等混合编程模式，在节点内部采用共享内存并行性，而在节点之间继续使用 MPI。&lt;strong>然而，这些方法要么可能受到 MPI 标准对接口行为规定的限制，无法最大化性能；要么给程序员带来了管理两种编程模型的挑战&lt;/strong>。&lt;/p>
&lt;p>社区已经尝试了许多其他方法，其中包括 &lt;strong>PGAS&lt;/strong> 模型，它提供了一种集群范围内的共享内存抽象，以及 &lt;strong>Legion 、Chapel&lt;/strong> 和 &lt;strong>X10&lt;/strong> 等隐式并行编程语言，这些语言提供了高级抽象，并尝试自动高效地协调应用程序。尽管取得了一定的进展，许多现代 HPC 应用仍然依赖于 MPI。&lt;strong>MPC&lt;/strong> 和 &lt;strong>AMPI&lt;/strong> 也尝试通过将线程作为 MPI Rank 来利用内部的共享内存，以提高性能。&lt;/p>
&lt;p>然而，仅使用 MPI 的方法往往比混合编程方法表现更佳。这可能是因为接口的局限性和无法充分利用节点内的共享内存，导致 MPI 未能充分发挥其潜在性能。因此，本文提出的 Pure 系统基于 MPI-everywhere 方法构建，打破了一些 MPI 的传统假设，更有效地利用了共享内存，同时避免了对现有程序进行重大重构的需求。Pure 采用了与 MPI 类似的编程模型，从而能够利用 HPC 社区现有的 MPI 知识和应用程序基础。&lt;/p>
&lt;p>Pure 的设计灵感源自 MPI，其核心编程模型是基于消息传递的，并可选择性地整合任务并行性。与 MPI 不同，Pure 摒弃了使用进程级别的 rank 和对旧版语言的支持限制，转而采用线程作为 rank 的实现，而非传统的进程。这种转变使得 Pure 能够高效地采用轻量级的无锁同步机制，实现同一节点内各线程间的协调。利用这种线程化的 rank 架构，Pure 构建了高效的节点内集体操作功能，并通过无锁算法来优化这些操作的性能。此外，Pure 支持将应用程序中的一部分并行代码块以标准的 C++ lambda 表达式的形式运行，这些表达式能够被当前拥有 rank 的线程以及其他空闲的 rank 自动且并发地执行，而这一切的操作都由 Pure Runtime 运行时系统自动进行调度。&lt;/p>
&lt;p>论文提出的优化策略涵盖了以下几点：&lt;/p>
&lt;ul>
&lt;li>一种无锁消息传递方法，适用于小消息和大数据消息的传输。&lt;/li>
&lt;li>无锁数据结构，用于高效实现集合通信算法。&lt;/li>
&lt;li>一个无锁任务调度器，允许空闲线程高效地从其他线程中“窃取”工作负载。&lt;/li>
&lt;/ul>
&lt;p>作者采用了标准的 C++ 库来确保 Pure 的广泛兼容性，并证明了 Pure 相较于经过高度优化的 MPI 基准测试，在性能上有显著提升。此外，作者还展示了 Pure 编程模型在语义上与 MPI 非常相似，这意味着从现有应用程序迁移到 Pure 是直接且简便的，这一点通过源码到源码的转换工具 mpi2pure 得到了进一步的证明。总体而言，论文的主要贡献可以总结为以下几点：&lt;/p>
&lt;ol>
&lt;li>提出了一种新的编程模型和运行时系统，该系统有效地结合了消息传递和任务并行性，并且利用了标准 C++ 的特性来实现。&lt;/li>
&lt;li>展示了现代 C++ 如何支持更加灵活的并行运行时系统接口。&lt;/li>
&lt;li>描述了一个设计精良的无锁、多线程和分布式运行时系统，该系统在节点内部相比 MPI 显示出了显著的速度提升。&lt;/li>
&lt;li>证明了通过仅对现有的 MPI 应用程序进行最小的源代码修改，就能在 micro benchmark 测试和三个实际应用中实现与最先进的 MPI 实现相比的显著性能提升。&lt;/li>
&lt;/ol>
&lt;h2 id="2-pure-使用示例">2. Pure 使用示例&lt;/h2>
&lt;p>本节通过一个简单的 1-D Stencil 算法示例来阐释 Pure 的使用方法。该示例虽然简单，但能够清晰展示 Pure 的核心概念及其与 MPI 的相似之处，为开发者编写更复杂的应用程序奠定了基础。&lt;/p>
&lt;p>在 MPI 版本的实现代码 &lt;code>rand_stencil_mpi&lt;/code> 中，计算工作主要集中在函数 &lt;code>random_work&lt;/code> 中执行。简单来说，&lt;code>rand_stencil_mpi&lt;/code> 函数首先会进入一个循环，迭代次数为 &lt;code>iters&lt;/code> ，在数组 &lt;code>a&lt;/code> 的每个元素上计算 &lt;code>random_work&lt;/code> 。值得注意的是，&lt;code>random_work&lt;/code> 执行的时间长度是可变且未知的，因此会引入负载不平衡。此外，&lt;code>random_work&lt;/code> 不会修改数组 &lt;code>a&lt;/code> 的内容，而是接着通过对相邻元素求平均值更新数组 &lt;code>a&lt;/code> 。最后，程序利用 &lt;code>MPI_Send&lt;/code> 和 &lt;code>MPI_Recv&lt;/code> 交换 &lt;code>temp&lt;/code> 数组的首尾元素，以便计算数组 &lt;code>a&lt;/code> 的首尾元素。由于 &lt;code>random_work&lt;/code> 所需时间长短不一，某些处理单元会提前完成任务，有时会在等待发送方较慢的 &lt;code>MPI_Recv&lt;/code> 调用时陷入阻塞状态。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/1D_stencil-2024-03-14.webp"
alt="1D_stencil-2024-03-14" width="auto" loading="lazy">
&lt;/figure>
&lt;div class="notice notice-info" >
&lt;div class="notice-title">&lt;svg t="1705940100069" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6252" width="200" height="200">&lt;path d="M512 64C264.6 64 64 264.6 64 512s200.6 448 448 448 448-200.6 448-448S759.4 64 512 64z m32 664c0 4.4-3.6 8-8 8h-48c-4.4 0-8-3.6-8-8V456c0-4.4 3.6-8 8-8h48c4.4 0 8 3.6 8 8v272z m-32-344c-26.5 0-48-21.5-48-48s21.5-48 48-48 48 21.5 48 48-21.5 48-48 48z" p-id="6253" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>示例 1：1-D Stencil with Random Work, MPI Version&lt;/p>&lt;/div>
&lt;pre>&lt;code class="language-cpp">void rand_stencil_mpi(double* const a, size_t arr_sz, size_t iters, int my_rank,
int n_ranks) {
double temp[arr_sz];
for (auto it = 0; it &amp;lt; iters; ++it) {
for (auto i = 0; i &amp;lt; arr_sz; ++i) {
temp[i] = random_work(a[i]);
}
for (auto i = 1; i &amp;lt; arr_sz - 1; ++i) {
a[i] = (temp[i - 1] + temp[i] + temp[i + 1]) / 3.0;
}
if (my_rank &amp;gt; 0) {
MPI_Send(&amp;amp;temp[0], 1, MPI_DOUBLE, my_rank - 1, 0, MPI_COMM_WORLD);
double neighbor_hi_val;
MPI_Recv(&amp;amp;neighbor_hi_val, 1, MPI_DOUBLE, my_rank - 1, 0, MPI_COMM_WORLD,
MPI_STATUS_IGNORE);
a[0] = (neighbor_hi_val + temp[0] + temp[1]) / 3.0;
} // ends if not first rank
if (my_rank &amp;lt; n_ranks - 1) {
MPI_Send(&amp;amp;temp[arr_sz - 1], 1, MPI_DOUBLE, my_rank + 1, 0,
MPI_COMM_WORLD);
double neighbor_lo_val;
MPI_Recv(&amp;amp;neighbor_lo_val, 1, MPI_DOUBLE, my_rank + 1, 0, MPI_COMM_WORLD,
MPI_STATUS_IGNORE);
a[arr_sz - 1] =
(temp[arr_sz - 2] + temp[arr_sz - 1] + neighbor_lo_val) / 3.0;
} // ends if not last rank
} // ends for all iterations
}
&lt;/code>&lt;/pre>
&lt;p>示例 2 则展示了实现同样功能的 Pure 版本。其中存在一些关键差异。首先，消息调用函数接口不同，使用的是相应的 Pure 消息传递函数 &lt;code>pure_send_msg&lt;/code> 和 &lt;code>pure_recv_msg&lt;/code> ，而非 MPI 调用，但参数实质上与 MPI 对应函数基本相同。Pure 的消息传递语义类似于 MPI：发送端缓冲区被复制到接收端缓冲区。实现区别主要在于：Pure 在&lt;strong>节点内部采用了轻量级的消息传递方法&lt;/strong>，从而在节点内的消息传递比 MPI 的延迟更低。&lt;/p>
&lt;div class="notice notice-info" >
&lt;div class="notice-title">&lt;svg t="1705940100069" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6252" width="200" height="200">&lt;path d="M512 64C264.6 64 64 264.6 64 512s200.6 448 448 448 448-200.6 448-448S759.4 64 512 64z m32 664c0 4.4-3.6 8-8 8h-48c-4.4 0-8-3.6-8-8V456c0-4.4 3.6-8 8-8h48c4.4 0 8 3.6 8 8v272z m-32-344c-26.5 0-48-21.5-48-48s21.5-48 48-48 48 21.5 48 48-21.5 48-48 48z" p-id="6253" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>示例 2：Pure 版本&lt;/p>&lt;/div>
&lt;pre>&lt;code class="language-cpp">void rand_stencil_pure(double* a, const int arr_sz, const int n_iter,
const int my_rank, const int n_ranks) {
double temp[arr_sz];
PureTask rand_work_task = [a, temp, arr_sz, my_rank](
chunk_id_t start_chunk, chunk_id_t end_chunk,
std::optinal&amp;lt;void&amp;gt; cont_params) {
auto [min_idx, max_idx] =
pure_aligned_idx_range&amp;lt;double&amp;gt;(arr_sz, start_chunk, end_chunk);
for (auto i = min_idx; i &amp;lt; max_idx; i++) {
temp[i] = random_work(a[i]);
}
}; // ends definding the Pure Task for rand_work_task
for (auto it = 0; it &amp;lt; n_iter; it++) {
rand_work_task.execute(); // execute all chunks of rank_work_task
for (auto i = 1; i &amp;lt; arr_sz - 1; ++i) {
a[i] = (temp[i - 1] + temp[i] + temp[i + 1]) / 3.0;
}
if (my_rank &amp;gt; 0) {
pure_send_msg(&amp;amp;temp[0], 1, MPI_DOUBLE, my_rank - 1, 0, PURE_COMM_WORLD);
double neighbor_hi_val;
pure_recv_msg(&amp;amp;neighbor_hi_val, 1, MPI_DOUBLE, my_rank - 1, 0,
PURE_COMM_WORLD);
a[0] = (neighbor_hi_val + temp[0] + temp[1]) / 3.0;
} // ends if not first rank
if (my_rank &amp;lt; n_ranks - 1) {
pure_send_msg(&amp;amp;temp[arr_sz - 1], 1, MPI_DOUBLE, my_rank + 1, 0,
PURE_COMM_WORLD);
double neighbor_lo_val;
pure_recv_msg(&amp;amp;neighbor_lo_val, 1, MPI_DOUBLE, my_rank + 1, 0,
PURE_COMM_WORLD);
a[arr_sz - 1] =
(temp[arr_sz - 2] + temp[arr_sz - 1] + neighbor_lo_val) / 3.0;
} // ends if not last rank
} // ends definding the Pure Task for rand_work_task
}
&lt;/code>&lt;/pre>
&lt;p>更重要的差异在于 Pure 中增加的 &lt;strong>Pure Task&lt;/strong> ，用带有一组特定参数定义的 lambda 表达式，其利用 lambda 的捕获参数特性，允许外部于 lambda 体内的变量以值或引用形式被捕获并在 lambda 执行时使用。Pure Task 可以被视为由 Pure Runtime 运行时系统负责执行应用程序代码片段，可以通过多线程并发执行。因此，Pure 任务应结构化为类似数据并行的形式。此外，Pure Task 需要由程序员保证线程安全。&lt;/p>
&lt;p>在以上 Pure 实现中，程序员可以利用 chunk ranges 来描述并发性。这些子范围或 chunk 是通过 &lt;code>start_chunk&lt;/code> 和 &lt;code>end_chunk&lt;/code> 参数传递给 Pure Task 的，而它们是由 Pure Runtime 运行时系统提供。Pure Runtime 运行时系统负责确保所有工作顺利完成。由于可能涉及到不同的多个线程，Pure Runtime 运行时系统会通过追踪哪些 chunk 已分配和完成来实现这一点。&lt;/p>
&lt;p>其次，程序员需要将 Pure Runtime 运行时系统提供的 &lt;code>start_chunk&lt;/code> 和 &lt;code>end_chunk&lt;/code> 参数映射到与应用计算相关的具体内容上。在这里，代码使用了 &lt;code>pure_aligned_idx_range&lt;/code> 辅助函数将其转化为循环索引子范围。这个辅助函数考虑到了缓存行，所以有利于避免伪共享问题。&lt;/p>
&lt;p>由于 random_work 可能导致负载分布不均，某些 rank 可能会在等待消息时处于空闲状态。Pure 的任务调度器会自动利用这些空闲的 rank，以执行同一节点内其他待处理的 Pure 任务块。以下图中在同一节点内的三个 rank 为例：&lt;strong>rank 0&lt;/strong> 正在执行一个被划分为 6 个 chunks 的 Pure Task，而 &lt;strong>rank 1&lt;/strong> 和 &lt;strong>rank 2&lt;/strong> 因为接收消息而阻塞。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/timeline-2024-03-14.png"
alt="timeline-2024-03-14" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>示例 Pure 代码的时间线示意图&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>从图中可以清晰地看到以下执行流程：&lt;/p>
&lt;ul>
&lt;li>rank 0 开始处理第一个 chunk（chunk 0） 。&lt;/li>
&lt;li>同时，rank 1 窃取并行执行第二个 chunk（chunk 1）。&lt;/li>
&lt;li>任务调度器随后为 rank 0 分配第三个 chunk（chunk 2），为 rank 1 分配第四个 chunk（chunk 3）。&lt;/li>
&lt;li>rank 2 尝试窃取一个任务，并成功执行第五个 chunk（chunk 4）。由于 &lt;code>random_work&lt;/code> 的执行随机性，chunk 2 和 chunk 4 可能是耗时较长的任务。&lt;/li>
&lt;li>rank 0 完成 chunk 5 的处理，这是一个较小的任务块，它在 rank 2 完成 chunk 4 之前就已经结束了。&lt;/li>
&lt;li>任务调度器确保在所有 chunks 完成之前，rank 0 不会结束执行。实际上，rank 0 要等到 chunk 4 完成后才能继续。&lt;/li>
&lt;li>在 rank 1 和 rank 2 等待消息的过程中，它们会尝试从其他任何可用的 rank 中窃取更多的 chunks。&lt;/li>
&lt;li>得益于 lambda 表达式的变量捕获功能，不同 rank 之间可以高效地共享上下文信息。&lt;/li>
&lt;/ul>
&lt;p>实验结果显示，在单节点上配置 32 个 rank 的 Pure 版本因为更快的消息传递和 Pure Task 的并行执行，相比于 MPI 版本，Pure 版本实现了 10% 的性能提升。在负载分布不均的情境下，Pure 的加速比甚至超过了 200%。这些性能提升的程度虽然受到负载不平衡的影响，但在实际应用场景中，Pure 仍展现出了显著的性能改进。这归功于 Pure Runtime 运行时系统的能力，它能够自动检测并高效利用未被充分利用的计算资源。&lt;/p>
&lt;h2 id="3-编程模型">3. 编程模型&lt;/h2>
&lt;p>Pure 的编程模型核心是“消息传递结合可选的任务并行性”。在语义上，Pure 的消息传递和集合通信操作与 MPI 等同，差异主要体现在语法上的一些细节。&lt;/p>
&lt;p>尽管 Pure 在节点内部采用线程，但其 rank 命名空间在整个集群中保持非层级结构。在 Pure 程序的执行周期内，rank 的数量保持不变。&lt;/p>
&lt;p>Pure 应用程序采用 C++ 编写，并通过 SPMD（单程序多数据）模式运行，实现了内部的多线程化。在同一个节点上，所有的 rank 都是通过内核线程实现的。&lt;/p>
&lt;p>&lt;strong>需要注意的是，Pure 应用程序并不支持全局变量&lt;/strong>。因此，开发者应当移除全局变量或者使用 &lt;code>thread_local&lt;/code> 关键字来限制变量的作用域，确保线程之间的安全性。&lt;/p>
&lt;p>对于存在负载不均衡问题的应用程序，开发者可以在满足以下特定条件的程序部分使用 Pure Task：&lt;/p>
&lt;ol>
&lt;li>计算密集型的热点区域。&lt;/li>
&lt;li>可以并发执行的任务。&lt;/li>
&lt;/ol>
&lt;h3 id="消息传递和集合通信操作">消息传递和集合通信操作&lt;/h3>
&lt;p>在 Pure 中，&lt;code>pure_send_msg&lt;/code> 和 &lt;code>pure_recv_msg&lt;/code> 函数在功能上与 MPI 的 &lt;code>MPI_Send&lt;/code> 和 &lt;code>MPI_Recv&lt;/code> 相对应，同时 Pure 也提供了相应的非阻塞版本。&lt;/p>
&lt;p>Pure Runtime 运行时系统确保所有消息都会被送达，并且按照发送的顺序进行交付。Pure 还实现了一系列的集合通信操作，包括：&lt;/p>
&lt;ul>
&lt;li>Reduce&lt;/li>
&lt;li>All-Reduce&lt;/li>
&lt;li>Barrier&lt;/li>
&lt;li>Broadcast&lt;/li>
&lt;/ul>
&lt;p>此外，Pure 引入了通信子（communication subgroup）的概念，允许开发者通过 &lt;code>pure_comm_split&lt;/code> 函数将一个通信子集进一步细分为更小的子集。&lt;/p>
&lt;p>为了使用 Pure，应用程序需要采用现代 C++ 标准进行编写，推荐使用 &lt;code>std=c++11&lt;/code> 或更高版本进行编译。Pure 提供了一个基于 Make 的构建系统，它会自动配置合适的编译器选项，并链接到 Pure Runtime 运行时系统（libpure），同时定义了一系列用于调试和性能分析的 target。&lt;/p>
&lt;h3 id="pure-task">Pure Task&lt;/h3>
&lt;p>Pure Task 允许开发者定义应用程序中的计算部分，并将其分解为可并行执行的 chunks。这些 chunks 可以由 Pure Runtime 运行时系统自动并发执行。&lt;/p>
&lt;p>然而，Pure Task 不是必需的，只有在任务可以划分为多个小块，并且这样做有助于缓解负载不均衡问题时，才推荐使用 Pure Task。&lt;/p>
&lt;p>Pure Task 通过 C++ Lambda 表达式实现，并在拥有该任务的 rank 调用 &lt;code>execute&lt;/code> 方法时同步执行。每个 rank 同一时间只能执行一个 Pure Task。Lambda 表达式的变量捕获功能使得不同 rank 在执行不同 chunks 时能够高效共享上下文信息。通常，一个 Pure Task 在应用程序的运行过程中会被定义一次，然后在每个时间步或其他迭代中多次执行。&lt;/p>
&lt;p>定义 Pure Task 时，需要指定 chunk 的数量和额外的应用程序参数。任务之间应避免相互依赖，不过因为它们会在 &lt;code>execute&lt;/code> 调用期间完全执行，所以它们不会与任务外部的代码发生冲突。&lt;/p>
&lt;p>Pure Task 包含一个 &lt;code>execute&lt;/code> 方法，该方法接受一个 &lt;code>optional&amp;lt;void*&amp;gt;&lt;/code> 类型的参数 &lt;code>per_exe_args&lt;/code> ，用于每次执行任务时传递额外的参数。这在任务主体的输入值在连续执行中发生变化时非常有用。例如，开发者可以将指向局部结构体的指针传递给 &lt;code>execute&lt;/code> 方法。&lt;/p>
&lt;p>Pure Task 的前两个参数 &lt;code>start_chunk&lt;/code> 和 &lt;code>end_chunk&lt;/code> 是无符号整数，用于指定要执行的 chunk 范围。这些 chunk 由 Pure Runtime 运行时系统分配，确保每个 chunk 只被执行一次，即使它们可能并发执行。&lt;/p>
&lt;p>Pure Task 使用 chunk 范围为调度器提供了灵活性，允许一次性分配多个 chunks。chunks 的数量由 Pure 任务调度器决定，但不会超过在 Makefile 文件中预定义的 &lt;code>PURE_MAX_TASK_CHUNKS&lt;/code> 。&lt;/p>
&lt;p>目前，Pure Task 的接口需要手动将 chunk 编号映射到数组索引，这在处理多维数组时可能比较繁琐。因此，未来的工作目标是扩展接口，提供类似于 TBB 的 &lt;code>parallel_for&lt;/code> 那样更简洁、更高级的接口。&lt;/p>
&lt;p>最后，开发者需要确保 Pure Task 内部的实现是线程安全的，以避免同一任务的多个并发执行的 chunks 之间的相互竞争。例如，在 CoMD 分子动力学 Benchmark 中，需要处理多个线程同时写入同一内存位置的问题，这时可以使用 &lt;code>std::atomic&lt;/code> 数组来替代普通 &lt;code>int&lt;/code> 数组。&lt;/p>
&lt;h2 id="4-运行时系统">4. 运行时系统&lt;/h2>
&lt;p>Pure 运行时系统是一个多线程和分布式运行时的动态库，用于支持 Pure 应用程序的开发。开发者在使用时需要包含 &lt;code>pure.h&lt;/code> 头文件，并使用 C++17 标准进行编译，同时链接到 &lt;code>libpure&lt;/code> 库。Pure 运行时系统能够自动地在计算和通信操作之间寻找并利用重叠执行的机会，尤其是在通信延迟较高的情况下。&lt;/p>
&lt;p>Pure 运行时系统的主要职能包括：&lt;/p>
&lt;ul>
&lt;li>初始化并配置必要的进程和线程，启动应用程序。&lt;/li>
&lt;li>管理节点内部的 rank 间通信和集合操作。&lt;/li>
&lt;li>管理内部的内存缓冲区和数据结构。&lt;/li>
&lt;li>如果应用程序中定义了 Pure Task，运行时系统还需负责这些任务的调度和执行。&lt;/li>
&lt;/ul>
&lt;h3 id="rank-初始化与映射">Rank 初始化与映射&lt;/h3>
&lt;p>Pure 中的 rank 实现为 MPI 进程的内核线程。在多节点应用中，Pure 运行 MPI 来处理跨节点通信，而在单节点应用中则不使用 MPI，尽管如此，Pure 应用程序并不直接调用 MPI 函数。通过 Makefile 配置，Pure 程序可以在一个节点或 NUMA 节点上启动一个 MPI 进程，并根据每个节点或 NUMA 节点的核心数来创建相应数量的线程。对于应用程序开发者而言，他们只需了解非层次化的 rank 命名空间，而节点、线程、MPI 进程和通信延迟等底层概念都被抽象化，对开发者透明。&lt;/p>
&lt;p>Pure 支持灵活的 rank 到节点的映射策略，并且默认采用 SMP 风格的分配策略。同时，Pure 也支持自定义的 rank 映射，包括使用 CrayPAT 的 rank 重排文件。虽然这些硬件相关的细节对开发者来说是不可见的，但 Pure 内部会利用这些信息来优化关键功能。&lt;/p>
&lt;p>在 Pure 应用程序启动时，不会直接执行应用程序的原始 &lt;code>main&lt;/code> 函数。相反，底层的 MPI 程序会调用 Pure 运行时系统中定义的 &lt;code>main&lt;/code> 函数，该函数负责初始化 Pure 的核心数据结构，然后创建并绑定线程，每个线程执行一个 &lt;code>original_main&lt;/code> 函数，这是从应用程序代码中的原始 &lt;code>main&lt;/code> 函数重命名而来的版本。应用程序执行完毕后，&lt;code>original_main&lt;/code> 函数返回到 Pure 运行时系统，后者负责完成 MPI 的清理和终止过程。&lt;/p>
&lt;h3 id="spin-steal-waiting-loop-ssw-loop">Spin-Steal Waiting Loop (SSW-Loop)&lt;/h3>
&lt;p>当 Pure 的 rank 遇到阻塞事件，如等待消息到达，它将执行一个称为 &lt;strong>自旋、窃取等待循环（SSW-Loop）&lt;/strong> 的机制，而不是简单地进入空闲状态。在此循环中，rank 会检查是否满足阻塞条件，例如是否有消息到达，如果没有，它会尝试从其他 rank 窃取任务。如果一个阻塞的 rank 能够协助其进程中正在并发执行的其他线程完成任务，它就会参与这种协助工作。&lt;/p>
&lt;p>由于线程是绑定到特定的 CPU 的，并且每个 rank 只运行一个应用程序，Pure 选择让 rank 主动自旋等待，而不是放弃 CPU。SSW-Loop 让计算中的 rank 具有“多态性”：它既可以作为主程序的计算节点，也可以协助其他 rank 执行窃取到的任务块，然后再返回检查自身的阻塞事件。&lt;/p>
&lt;p>Pure 遵循优先处理当前 rank 拥有的窃取任务负载的策略，坚持任务负载优先的调度原则。&lt;/p>
&lt;p>与那些使用辅助线程来实现工作负载窃取或通信的系统不同，Pure 的特点是允许应用级别的计算节点直接进行任务窃取操作。&lt;/p>
&lt;h3 id="实现说明">实现说明&lt;/h3>
&lt;p>Pure 是使用 C++17 标准库编写的。Pure 运行时系统由大约 21,000 行源代码构成，而 Pure 工具则包含了约 14,000 行源代码。Pure 已在多种环境下进行测试，包括笔记本电脑和集群，其运行仅需要一个支持 C++17 的编译器、类 Unix 操作系统以及 MPI 环境。Pure 的源代码可以在 GitHub 上公开获取，链接为： &lt;a class="link" href="https://github.com/psota/pure" target="_blank" rel="noopener" >https://github.com/psota/pure
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
。&lt;/p>
&lt;h3 id="点对点通信">点对点通信&lt;/h3>
&lt;p>Pure 提供了阻塞和非阻塞的点对点消息传递功能，其语义与 MPI 的消息传递相一致。&lt;/p>
&lt;p>Pure 内部采用三种不同的策略来进行消息传递，选择哪种策略取决于消息的大小以及发送方和接收方是否位于同一节点。&lt;/p>
&lt;p>Pure 在整个程序的生命周期中分配并复用一个持久的 Channel 对象，该对象存储于运行时系统中。内部的 Channel Manager 负责将消息参数映射到合适的数据结构，并根据需要创建这些结构。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/strategy-2024-03-15.webp"
alt="strategy-2024-03-15" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Pure 消息传递策略&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;ul>
&lt;li>&lt;strong>短消息（小于 8KB）&lt;/strong>：
&lt;ul>
&lt;li>采用无锁循环队列（PureBufferQueue，PBQ），具有 acquire-release 内存语义。发送线程在有可用空间时将消息复制到 PBQ，接收线程则在消息准备好时将其取出。
&lt;ul>
&lt;li>在短消息传递中，拷贝的开销相对较小，这样可以让发送方调用返回后立即执行执行其它有用的工作。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>发送和接收线程都使用 SSW-Loop 进行等待，以尽可能地实现计算与通信的重叠执行。&lt;/li>
&lt;li>所有消息的 slot 存储在一个连续的缓冲区中，通过指针算术确保每个 slot 与缓存行边界对齐，避免发送和接收线程之间的伪共享。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>大消息（大于等于 8KB）&lt;/strong>：
&lt;ul>
&lt;li>类似于 PBQ 的策略，但使用直接从发送方到接收方的单次内存拷贝，灵感来自 MPI 的 rendezvous 模式。&lt;/li>
&lt;li>使用无锁的固定大小循环缓冲区来存储接收方的接收调用参数。&lt;/li>
&lt;li>发送方通过 SSW-Loop 等待元数据队列项，然后将消息内容直接复制到接收方的缓冲区。发送方通过在无锁队列中插入传输的字节数来通知接收方传输已完成。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>跨节点消息&lt;/strong>
&lt;ul>
&lt;li>透明地使用 MPI 接口进行消息传递。&lt;/li>
&lt;li>在 Pure 初始化期间，使用分布式一致性算法创建 &lt;code>thread-rank-process-node&lt;/code> 映射数据结构，将 Pure rank 映射到 MPI rank。&lt;/li>
&lt;li>为了确保在接收节点上正确的接收线程能够接收到消息，在 &lt;code>MPI_TAG&lt;/code> 中编码发送和接收线程的 ID，解决多线程路由问题。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="集合通信">集合通信&lt;/h3>
&lt;p>Pure 的集体通信操作在语义上与 MPI 相同，但在节点内部通过自下而上构建的数据结构来实现，这在单节点和多节点基准测试中都显示出了显著的性能提升，即使在跨节点通信时仍然依赖于 MPI 的集合操作。&lt;/p>
&lt;p>Pure 采用一个领导者线程来协调集体通信过程，其他线程则协助进行计算并按需调用 MPI 集合函数。&lt;/p>
&lt;ul>
&lt;li>Pure 使用静态领导者选举方法，这比基于比较和交换的“首先进入”方法更为高效。&lt;/li>
&lt;/ul>
&lt;p>以下仅以 All-Reduce 为例子，其它集合通信操作思想类似。&lt;/p>
&lt;p>对于小数据的 All-Reduce 操作，Pure 设计了名为 Sequenced Per-Thread Dropbox (SPTD) 的并发数据结构，提供了一种高效的无锁机制，用于在领导线程和其他非领导线程之间对偶同步和可选共享数据。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/SPTD-2024-03-15.webp"
alt="SPTD-2024-03-15" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Sequenced Per-Thread Dropbox (SPTD)&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>该方法借鉴了 flat-combinding 技术，将通信器中的线程 0 作为领导者线程。&lt;/p>
&lt;ul>
&lt;li>对于大小不超过 2KB 的小数组：
&lt;ul>
&lt;li>非领导者线程首先将数据复制到 SPTD，然后与领导者线程同步，表明输入数据已就绪（使用原子序列号而非共享原子计数器）。&lt;/li>
&lt;li>领导者线程执行所有输入数组的逐元素 Reduce 操作。&lt;/li>
&lt;li>每个节点的领导者线程使用 &lt;code>MPI_Allreduce&lt;/code> 对局部 Reduce 结果进行全局 Reduce。&lt;/li>
&lt;li>领导者线程同步，非领导者线程将最终的 Reduce 结果复制到私有缓冲区。&lt;/li>
&lt;li>所有线程在等待时执行 SSW-Loop。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>对于超过 2KB 的大数组，Reduce 计算可能成为性能瓶颈，因此需要所有线程并发执行 Reduce 计算，并通过共享内存直接从每个线程的缓冲区中读取或写入数据。
&lt;ul>
&lt;li>Reduce 工作被划分为大小相等的块，避免伪共享并实现向量化计算。&lt;/li>
&lt;li>线程使用 SPTD 报告准备状态，并通过原子序列号标记计算完成。&lt;/li>
&lt;li>领导者线程调用 &lt;code>MPI_Allreduce&lt;/code> 执行跨节点的 All-Reduce 操作，并通过另一个原子序列号传播最终结果。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="任务调度器">任务调度器&lt;/h3>
&lt;p>Pure 运行时系统精心设计了一个任务调度器，它在共享内存中维护了一个名为 &lt;code>active_tasks&lt;/code> 的数组。这个数组存储了一系列原子指针，每个指针对应于一个正在执行的任务，并且为系统中的每个节点和每个 rank 分配了一个条目。这些条目最初被设置为 &lt;code>nullptr&lt;/code>，表示任务尚未分配。&lt;/p>
&lt;p>当一个任务被创建并准备执行时，系统会为其初始化状态，并通过原子操作更新 &lt;code>active_tasks&lt;/code> 数组中相应的条目，以反映该任务已被分配。这个更新过程确保了任务的执行状态对系统中的所有线程都是可见的，从而使得任务可以被其他线程“窃取”。&lt;/p>
&lt;p>在任务的执行过程中，拥有任务的 rank 会开始执行一系列的 chunk，这些是任务的细分工作单元。同时，其他线程会在它们的 SSL-Loop 期间不断检查 &lt;code>active_tasks&lt;/code> 数组，通过原子加载操作来寻找可执行的非空任务。&lt;/p>
&lt;p>任务的执行是由两个原子整数 &lt;code>curr_chunk&lt;/code> 和 &lt;code>chunks_done&lt;/code> 来协调的。拥有任务的 rank（owner rank）和可能的窃取者 rank（thief ranks）都会运行相同的并发执行函数。窃取者线程会执行一个 chunk 后返回，而拥有者线程则持续执行直到所有 chunk 完成。通过使用 &lt;code>fetch_add&lt;/code> 操作，线程可以确定自己应该执行哪个 chunk，如果 &lt;code>curr_chunk&lt;/code> 的值已经超过了总的 chunk 数量，线程则会停止执行。&lt;/p>
&lt;p>每当一个 chunk 被成功完成后，线程会原子性地增加 &lt;code>chunks_done&lt;/code> 的值。拥有者线程会更新其本地存储，以避免缓存未命中。最终，拥有者 rank 会等待，直到所有的 chunk 都执行完毕，确保任务的完整执行。&lt;/p>
&lt;p>值得注意的是，任务的 chunk 与应用程序的 rank 是在同一硬件线程上执行的。在 Pure 应用中，每个硬件线程都被分配给一个特定的 rank。尽管目前 Pure 还没有利用硬件加速器（如 GPU）来加速任务执行，但设计者相信 Pure 的架构完全有能力支持这种加速。&lt;/p>
&lt;p>Pure 的任务调度器提供了多种执行模式和窃取算法，以适应不同的执行需求。例如，作者实现了单 chunk 执行模式和一种引导式自调度模式，后者是一种工作划分算法，它优先分配较大的工作块，然后是较小的工作块。此外，调度器还包括 NUMA 感知窃取模式，它优先从同一 NUMA 节点上的线程窃取任务，以及一种“黏性”窃取模式，允许窃取者线程返回它们最近窃取且仍在活跃状态的任务。这些特性共同确保了任务调度的高效性和灵活性。&lt;/p>
&lt;h2 id="评估">评估&lt;/h2>
&lt;p>在伯克利 NERSC 的 Cori HPC 集群上进行了 Pure 的性能评估。该集群包含 2388 个节点，每个节点配置有 2 个插槽、16 个核心和 128GB 内存，通过 Cray Aires 进行节点间互联。实验配置启用了超线程，并采用 256 位向量宽度。每个节点上运行 2 个进程，共 32 个线程。评估使用 Intel 编译器，并将 Cray MPICH 作为性能基线。&lt;/p>
&lt;h3 id="nas-dt-基准测试结果">NAS DT 基准测试结果&lt;/h3>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/nasdt-2024-03-15.webp"
alt="nasdt-2024-03-15" width="auto" loading="lazy">
&lt;/figure>
&lt;ul>
&lt;li>仅通过优化消息传递机制，Pure 取得了 11% 至 25% 的性能加速。&lt;/li>
&lt;li>引入 Pure Tasks 后，性能加速比提升至 1.7 倍至 2.6 倍。&lt;/li>
&lt;li>辅助线程能小幅提高性能，不过仅限于剩余未使用的 CPU 核心才能使用。在这里，除了 80 个 rank 的情况下空闲了 24 个核心，其它情况下都充分利用了 CPU 核心。&lt;/li>
&lt;/ul>
&lt;h3 id="comd-和-miniamr-基准测试">CoMD 和 miniAMR 基准测试&lt;/h3>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/benchmark-pure-2024-03-15.webp"
alt="benchmark-pure-2024-03-15" width="auto" loading="lazy">
&lt;/figure>
&lt;p>-在 CoMD 分子动力学应用中，Pure 在所有 rank 数下的性能均优于仅使用 MPI 及 MPI+OpenMP 的性能，分别实现了 7% 至 25% 以及 35% 至 50% 的加速比，即使在没有负载不均衡的情况下。&lt;/p>
&lt;ul>
&lt;li>在 miniAMR 自适应网格细化应用中，Pure 至少实现了 20%，最多 50% 的性能加速。&lt;/li>
&lt;/ul>
&lt;h3 id="集合通信性能">集合通信性能&lt;/h3>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/benchmark-pure-msg-2024-03-15.webp"
alt="benchmark-pure-msg-2024-03-15" width="auto" loading="lazy">
&lt;/figure>
&lt;ul>
&lt;li>Pure 在集合通信操作中的性能表现突出，这些操作的内部优化机制和数据结构设计使得 Pure 在处理大规模并行计算任务时展现出显著的效率和优势。&lt;/li>
&lt;/ul>
&lt;h2 id="相关工作">相关工作&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">类别&lt;/th>
&lt;th style="text-align:left">相关工作&lt;/th>
&lt;th style="text-align:left">Pure 的优势&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">MPI&lt;/td>
&lt;td style="text-align:left">1. 利用多核节点内的共享内存提升性能；2. XPMEM 显著增强节点内通信效率；3. ch4 网络库优化了 MPI 的共享内存通信；4. 改进了 MPI 的集合通信算法；5. DMAPP 库针对特定集合通信进行了优化，但限制较多；6. 解决了大规模全对全集合通信的挑战；7. 单边消息 API 实现了解耦；8. 优化了数据移动与进程同步&lt;/td>
&lt;td style="text-align:left">1. Pure 在所有集合通信和负载大小上均展现出卓越的性能；2. 提供了高级的通信计算重叠机制，超越了传统的单边消息 API&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">MPI 多线程&lt;/td>
&lt;td style="text-align:left">1. 支持 MPI_THREAD_MULTIPLE 模式下的 rank 内多线程； 2. 多数 MPI 实现通过全局锁实现线程安全，导致性能瓶颈；3. MPI 4.0 引入 MPI+X 方法增强多线程支持；4. 引入了 MPI Fine-points 和 Endpoints 概念以支持线程&lt;/td>
&lt;td style="text-align:left">1. Pure 重视多线程代码中的 MPI 调用，强调其重要性；2. 提供了一种统一的编程模型，简化了并行任务的引入&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">AMPI&lt;/td>
&lt;td style="text-align:left">1. 基于 Charm++ 的 MPI 兼容库；2. 提供高级并行编程抽象；3. 通过最小化代码更改实现性能提升&lt;/td>
&lt;td style="text-align:left">1. Pure 在实际测试中表现优于 AMIP，得益于其优化的消息传递和集合通信，以及更精细和低开销的负载均衡策略；2. 相较于 AMIP SMP 基于线程的模型，Pure 提供了更高效的并行处理&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">PGAS 语言和并行框架&lt;/td>
&lt;td style="text-align:left">1. PGAS 语言提供了全局内存地址空间的抽象；2. Chapel 和 X10 扩展了 PGAS 方法，支持本地和远程异步任务；3. HPX 为现代 C++标准增加了分布式操作支持；4. Legion 作为数据中心并行编程系统；5. Kokkos, STAPL, BCL 等框架提供了应用程序与硬件间的抽象层&lt;/td>
&lt;td style="text-align:left">1. 类似于 Pure，PGAS 模型采用 SPMD 风格，通过局部性引用提高性能；2. 这些框架虽然利用了现代 C++特性，但通常需要对现有应用程序进行大量重写，而 Pure 则提供了更为直接的优化路径&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>数十年来，由于其相对的简单性和性能优势，消息传递一直被视为并行编程的标准模型。然而，本文表明，消息传递与共享内存并非不可兼容。实际上，通过设计合适的库，可以在不牺牲大多数消息传递优点的前提下充分利用共享内存。&lt;/p></description></item></channel></rss>