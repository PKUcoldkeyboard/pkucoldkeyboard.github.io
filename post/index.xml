<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on cuterwrite</title>
        <link>https://cuterwrite.top/post/</link>
        <description>Recent content in Posts on cuterwrite</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>cuterwrite</copyright>
        <lastBuildDate>Thu, 02 Nov 2023 00:55:55 +0000</lastBuildDate><atom:link href="https://cuterwrite.top/post/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>离子通道与 Hudgkin-Huxley 模型</title>
        <link>https://cuterwrite.top/p/ion-channels-and-hudgkin-huxley/</link>
        <pubDate>Thu, 02 Nov 2023 00:55:55 +0000</pubDate>
        
        <guid>https://cuterwrite.top/p/ion-channels-and-hudgkin-huxley/</guid>
        <description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/20231102162211-2023-11-02.png" alt="Featured image of post 离子通道与 Hudgkin-Huxley 模型" /&gt;&lt;h1 id=&#34;离子通道与-hudgkin-huxley-模型&#34;&gt;离子通道与 Hudgkin-Huxley 模型&lt;/h1&gt;
&lt;p&gt;从生物物理学的角度来看，动作电位是通过细胞膜中离子通道的电流的结果。在对乌贼的巨型轴突进行的一系列广泛实验中，霍奇金和胡克斯利成功地测量了这些电流，并以微分方程的方式描述了它们的动力学。在转向 Hudgkin-Huxley 方程之前，我们需要补充一些关于离子通道平衡电位的额外知识。&lt;/p&gt;
&lt;h2 id=&#34;一平衡电位equilibrium-potential&#34;&gt;一、平衡电位（Equilibrium Potential）&lt;/h2&gt;
&lt;p&gt;神经元和其他细胞一样，被一个膜所包围，该膜将细胞的内部与细胞外空间分开。细胞内的离子浓度与周围液体中的离子浓度不同。浓度的差异产生了一个电位，在神经元动力学中起着重要作用。该小节将对平衡电位给出一个直观的解释。&lt;/p&gt;
&lt;h3 id=&#34;1-nernst-电位nernst-potential&#34;&gt;1. Nernst 电位（Nernst Potential）&lt;/h3&gt;
&lt;p&gt;根据热力学理论，分子处于能量状态的概率与 Boltzmann 因子成正比，即 $p \propto \exp \left( -E/kT \right )$，其中 $E$ 是分子的能量，$k$ 是 Boltzmann 常数，$T$ 是温度。现在考虑带有电荷 $q$ 的正离子在静电场中。它们在位置 $x$ 的能量为 $E=q u(x)$，其中 $u(x)$ 是 $x$ 处的电势。因此，正离子在位置 $x$ 附近的概率为 $p(x) \propto \exp \left[ -q u(x)/kT \right ] $。对于带有正电荷 $q&amp;gt;0$ 的离子，离子密度在电位低的区域更高。我们用 $n(x)$ 表示点 $x$ 处的离子密度。则点 $x_1$ 处和点 $x_2$ 处的密度之间的关系为：&lt;/p&gt;
&lt;p&gt;$$
\frac{n(x_1)}{n(x_2)} = \exp \left [ -\frac{qu(x_1)-qu(x_2)}{kT} \right ] \tag{1.1}
$$&lt;/p&gt;
&lt;p&gt;因此，电位差 $\Delta u = u(x_1) − u(x_2)$ 引起了离子密度的差异。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20231102170347-2023-11-02.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20231102170347-2023-11-02&#34;
	
	
&gt;&lt;/p&gt;



&lt;div class=&#34;notice notice-note&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M504 256a248 248 0 11-496 0 248 248 0 01496 0zm-248 50a46 46 0 100 92 46 46 0 000-92zm-44-165l8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;图1.1： (a)在热平衡状态下，电场中的正离子分布为：高能态的离子较少，低能态的离子较多。因此，电压差会产生浓度梯度。(b) 类似地，离子浓度的差异会产生电势差。神经元内部的浓度与周围的浓度不同。由此产生的电位称为 &lt;strong&gt;Nernst 电位&lt;/strong&gt; 。实线表示细胞膜。离子可以通过间隙传递。&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;由于这是关于平衡状态的陈述，反过来也是成立的。离子密度的差异会产生电势差 $\Delta u$ 。我们考虑两个离子浓度分别为 $n_1$ 和 $n_2$ 的区域；参见图1.1(b)。通过求解公式 (1.1) 得到 $\Delta u$，我们发现，在平衡状态下，浓度差异会产生一个电压。&lt;/p&gt;
&lt;p&gt;$$
\Delta u = \frac{kT}{q} \ln \frac{n_1}{n_2} \tag{1.2}
$$&lt;/p&gt;
&lt;p&gt;该电压又被称为 Nernst 电位（Hille, 2001）。&lt;/p&gt;
&lt;h3 id=&#34;2-反转电位reversal-potential&#34;&gt;2. 反转电位（Reversal Potential）&lt;/h3&gt;
&lt;p&gt;细胞膜由一层薄的脂质双层组成，几乎是一个完美的电绝缘体。然而，在细胞膜中嵌入了特定的蛋白质，它们作为离子门控通道。第一种类型的门控通道是离子泵，第二种是离子通道。离子泵能够主动地将离子从一侧运输到另一侧。因此，细胞内液体中的离子浓度与周围环境不同。例如，哺乳动物神经元内的钠浓度（约为 $10 mM$ ）低于细胞外液体中的钠浓度（约为 $145 mM$ ）。另一方面，细胞内的钾浓度（约为 $140 mM$ ）高于周围环境中的钾浓度（约为 $5 mM$ ）。对于霍奇金和哈克斯利研究的鱿鱼巨大轴突，这些数字略有不同，但基本思想是相同的：细胞外的钠离子比细胞内多，而钾离子则相反。&lt;/p&gt;
&lt;p&gt;让我们暂时专注于钠离子。在平衡状态下，浓度差引起了约为 $+67 mV$ 的 Nernst 电位 $E_{Na}$ 。也就是说，在平衡状态下，细胞内部相对于周围环境具有正电势。细胞内部和周围液体通过离子通道相互联系，钠离子可以从膜的一侧通过到另一侧。如果电压差 $\Delta u$ 小于 Nernst电势 $E_{Na^{+}}$ 的值，更多的 $Na^+$ 离子会流入细胞，以减小浓度差异。如果电压大于 Nernst 电势，离子会从细胞流出。因此，当电压 $\Delta u$ 通过 $E_{Na}$ 时，电流的方向会反转。因此，$E_{Na}$ 被称为反转电位。&lt;/p&gt;
&lt;p&gt;继续看钾离子，正如上面提到的，钾离子在细胞内的浓度（约为 $140 mM$ ）比细胞外液体（约为 $5 mM$ ）高。钾离子具有单个正电荷 $q = 1.6 × 10^{-19} C$ 。应用 Nernst 公式（1.2），其中玻尔兹曼常数 $k = 1.4 × 10^{-23} J/K$ ，在室温下得到 $E_K ≈ -83 mV$ 。因此，钾离子 $K^{+} 的反转电势是负的。&lt;/p&gt;
&lt;p&gt;到目前为止，我们考虑了钠或钾的存在。在真实的细胞中，这些和其他离子类型同时存在，并对跨膜电压做出贡献。实验发现，细胞膜的静息电位约为 $u_{rest} ≈ 65 mV$ 。由于 $E_K &amp;lt; u_{rest} &amp;lt; E_{Na}$ ，钾离子在静息电位下从细胞流出，而钠离子则流入细胞。在稳态下，主动离子泵平衡这种流动，并通过通道运输与通过通道的离子数量相同的离子返回。$u_{rest}$ 的值由通道中离子流动（膜的渗透性）和主动离子转运（维持浓度差的离子泵的效率）之间的动态平衡决定。&lt;/p&gt;
&lt;h2 id=&#34;二hudgkin-huxley-模型&#34;&gt;二、Hudgkin-Huxley 模型&lt;/h2&gt;
&lt;p&gt;霍奇金和哈克斯利（1952）对乌贼的巨型轴突进行了实验，发现了三种不同类型的离子电流，即钠、钾和主要由氯离子组成的泄漏电流。特定的电压依赖性离子通道，一个用于钠，另一个用于钾，控制这些离子通过细胞膜的流动。泄漏电流负责其他未明确描述的通道类型。&lt;/p&gt;
&lt;h3 id=&#34;1-模型定义model-definition&#34;&gt;1. 模型定义（Model Definition）&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20231102175050-2023-11-02.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20231102175050-2023-11-02&#34;
	
	
&gt;&lt;/p&gt;



&lt;div class=&#34;notice notice-note&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M504 256a248 248 0 11-496 0 248 248 0 01496 0zm-248 50a46 46 0 100 92 46 46 0 000-92zm-44-165l8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;图2.1： Hodgkin-Huxley模型示意图。&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;Hodgkin-Huxley模型可以通过图 2.1 来理解。半透膜细胞膜将细胞内部与细胞外液体隔开，并起到电容器的作用。如果将输入电流 $I(t)$ 注入细胞，它可能会在电容器上增加进一步的电荷，或者通过细胞膜中的通道泄漏。&lt;/p&gt;
&lt;p&gt;图 2.1 中的每种通道类型都由一个电阻器表示。非特异通道具有泄漏电阻 $R$ ，钠通道具有电阻 $R_{Na}$ ，钾通道具有电阻 $R_K$ 。电阻器图中的对角箭头表示电阻值不固定，而是根据离子通道是否打开或关闭而变化。&lt;/p&gt;
&lt;p&gt;由于通过细胞膜的主动离子转运，细胞内的离子浓度与细胞外液体不同。由离子浓度差产生的 Nernst 电位在图 2.1 中由电池表示。由于每种离子类型的 Nernst 电位不同，分别为钠、钾和非特异第三通道设置了单独的电池，其电池电压分别为 $E_{Na}$ 、$E_K$ 和 $E_L$ 。&lt;/p&gt;
&lt;p&gt;现在让我们将上述电路图转化为数学方程。膜上电荷的守恒意味着施加的电流 $I(t)$ 可以分为充电电流 $I_C$ ，用于充电电容器 $C$ ，以及通过离子通道的其他电流 $I_k$ 。因此，可以写成以下方程：&lt;/p&gt;
&lt;p&gt;$$
I(t) = I_C(t) + \sum_{k} I_k(t) \tag{2.1}
$$&lt;/p&gt;
&lt;p&gt;在标准的 Hodgkin-Huxley 模型中，只有三种类型的通道：一个带有 $Na$ 索引的钠通道，一个带有 $K$ 索引的钾通道，以及一个具有电阻 $R$ 的非特异泄漏通道。根据电容的定义 $C = q / u$ ，可以得到充电电流 $I_C = C\frac{du}{dt}$ 。因此，方程 (2.1) 可以写成：&lt;/p&gt;
&lt;p&gt;$$
C \frac{du}{dt} = I(t) - \sum_{k} I_k(t) \tag{2.2}
$$&lt;/p&gt;
&lt;p&gt;在生物学术语中，$u$ 是膜上的电压，$\sum_{k} I_k(t)$ 是通过细胞膜的离子电流之和。&lt;/p&gt;
&lt;p&gt;如上所述，Hodgkin-Huxley 模型描述了三种类型的通道。所有通道可以通过它们的电阻或等效地通过它们的电导来表征。泄漏通道由电压无关的电导 $g_L=1/R$ 来描述。由于 $u$ 是细胞膜上的总电压，$E_L$ 是电池的电压，在图 2.1 中泄漏电阻器的电压为 $u - E_L$ 。根据欧姆定律，我们得到泄漏电流 $I_L = g_L (u - E_L)$ 。&lt;/p&gt;
&lt;p&gt;其他离子通道的数学模型类似，只是它们的电导是电压和时间依赖的。如果所有通道都打开，它们分别以最大电导率 $g_{Na}$ 或 $g_K$ 发射电流。然而，通常情况下，一些通道被阻断。霍奇金和哈克斯利的突破是，他们成功地测量了通道的有效电阻如何随着时间和电压的变化而变化。此外，他们还提出了对其观察结果的数学描述。具体来说，他们引入了额外的门控变量 $m$ , $n$ 和 $h$ 来模拟模拟通道在给定时间点开放的概率。例如，钠通道的有效电导被建模为 $1 / R_{Na} = g_{Na} \cdot m^3 h$ ，其中 $m$ 描述通道的激活（开放），$h$ 描述通道的失活（阻塞）。钾的电导率为 $1 / R_K = g_K \cdot n^4$ ，其中 $n$ 描述通道的激活。&lt;/p&gt;
&lt;p&gt;总的来说，霍奇金和哈克斯利将公式 (2.2) 右边的三个离子电流写成：&lt;/p&gt;
&lt;p&gt;$$
\sum_{k} I_k(t) = g_{Na} \cdot m^3 h \cdot (u - E_{Na}) + g_K \cdot n^4 \cdot (u - E_K) + g_L \cdot (u - E_L) \tag{2.3}
$$&lt;/p&gt;
&lt;p&gt;其中参数 $E_{Na}$ , $E_K$ , 和 $E_L$ 是反转电位。&lt;/p&gt;
&lt;p&gt;三个门控变量 $m$ , $n$ 和 $h$ 根据以下形式的微分方程变化：&lt;/p&gt;
&lt;p&gt;$$
\dot{x}=-\frac{1}{\tau_x (u)}\left [ x-x_0(u)\right ] \tag{2.4}
$$&lt;/p&gt;
&lt;p&gt;其中，$\dot{x} = \frac{dx}{dt}$ ，其中 $x$ 表示 $m$, $n$ 或者 $h$ 。公式 （2.4） 的解释很简单：对于一个固定的电压 $u$ ，变量 $x$ 以时间常数 $\tau_x(u)$ 逼近目标值 $x_0(u)$ 。目标值 $x_0(u)$ 和时间常数 $\tau_x(u)$ 对电压的依赖关系分别如图 2.2 (a), (b) 所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20231102185532-2023-11-02.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20231102185532-2023-11-02&#34;
	
	
&gt;&lt;/p&gt;



&lt;div class=&#34;notice notice-note&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M504 256a248 248 0 11-496 0 248 248 0 01496 0zm-248 50a46 46 0 100 92 46 46 0 000-92zm-44-165l8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;图 2.2 ： Hodgkin-Huxley 模型。(a) 门控变量 $m$, $n$, $h$ 的平衡函数。(b)与电压有关的时间常数，静息电位为 $u=-65mV$ （箭头），参数由表 2.1 给出。&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20231102185758-2023-11-02.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20231102185758-2023-11-02&#34;
	
	
&gt;&lt;/p&gt;



&lt;div class=&#34;notice notice-note&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M504 256a248 248 0 11-496 0 248 248 0 01496 0zm-248 50a46 46 0 100 92 46 46 0 000-92zm-44-165l8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;表 2.1 ：在大脑皮层上的锥体神经元上拟合的 Hodgkin-Huxley 方程的参数。$n$ 和 $m$ 的参数由Zach Mainen（Mainen et al., 1995）根据Huguenard等人（1988）报告的实验进行拟合，$h$ 的参数由 Richard Naud 根据 Hamill 等人（1991）报告的实验进行拟合。电压以 $mV$ 为单位，膜电容为 $C = 1 \mu F/ cm^2$ 。&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;图 2.2 中绘制的函数形式，以及公式（2.3）中的最大电导和反转电位，是霍奇金和哈克斯利根据经验推导出来的。&lt;/p&gt;
&lt;p&gt;实验者通过向细胞注入适当的电流来保持细胞膜上的电压在所需的值上。在实验中，假设实验者在 $t&amp;lt;t_0$ 时将细胞保持在静息电位 $u_0 =-65mV$ ，并且在 $t=t_0$ 时将电压切换到一个新值 $u_1$ 。对于 $t &amp;gt; t _$ ，通过对微分方程（2.4）进行积分，可以得到以下动力学方程：&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
&amp;amp; m(t)=m_0(u_1) + [m_0(u_0)-m_0(u_1)] \exp \left[ -\frac{t-t_0}{\tau_m(u_1)} \right ] ,\\
&amp;amp; h(t)=h_0(u_1) + [h_0(u_0)-h_0(u_1)] \exp \left[ -\frac{t-t_0}{\tau_h(u_1)} \right ] ,
\end{aligned}
\tag{2.5}
$$&lt;/p&gt;
&lt;p&gt;其中 $m(t)$ 和 $h(t)$ 分别表示钠通道和钾通道的激活和失活状态。基于给定的函数 $m_0(u)$ 、$h_0(u)$ 、$\tau_m(u)$ 和 $\tau_h(u)$ 的模型，可以预测在 $t &amp;gt; t_0$ 时电压变化引起的钠电流 $I_{Na}(t)=g_{Na} [m(t)^3] h(t)  (u_1 - E_{Na})$ 和钾电流 $I_K(t)=g_K [n(t)^4] (u_1 - E_K)$ 。&lt;/p&gt;
&lt;p&gt;而 $n(t)$ 的表达式为：&lt;/p&gt;
&lt;p&gt;$$
n(t)=n_0(u_1) + [n_0(u_0)-n_0(u_1)] \exp \left[ -\frac{t-t_0}{\tau_n(u_1)} \right ] \tag{2.6}
$$&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20231102222844-2023-11-02.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20231102222844-2023-11-02&#34;
	
	
&gt;&lt;/p&gt;



&lt;div class=&#34;notice notice-note&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M504 256a248 248 0 11-496 0 248 248 0 01496 0zm-248 50a46 46 0 100 92 46 46 0 000-92zm-44-165l8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;图 2.3 ：Hodgkin 和 Huxley 绘制的钾离子电导率变化原始测量曲线和公式拟合曲线。施加 $25 mV$ 的电压切换后，回到静息电位后，钾的电导率（圆圈）的测量时间过程。拟合实线是基于公式（2.6）的。&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;霍奇金和哈克斯利使用方程（2.4）和（2.5）反过来进行研究。他们在使用适当的药物阻断钠通道后，施加电压变化并测量钾电流的时间变化。将记录的电流除以驱动电位 $(u_1 - E_K)$ 可以得到时间相关的电导率 $g_K [ n(t)^4]$ (图 2.3 ）。使用方程（2.6），霍奇金和哈克斯利推导出了钾通道的 $n_0(u_1)$ 和 $τ_n(u_1)$ 的值，以及 $n^4(t)$ 中的指数 4。通过对不同的 $u_1$ 值重复实验，可以得到 $n_0(u)$ 和 $τ_n(u)$ 的实验曲线。&lt;/p&gt;
&lt;p&gt;变量 $m$ 被称为激活变量。为了理解这个术语，我们注意到从图 2.2 可以看出，在神经元的静息电位 $u = -65 mV$ 时，$m_0(u)$ 的值接近于零。因此，在静息状态下，通过通道的钠电流 $I_{Na} = g_{Na} m^3 h(u - E_{Na})$ 为零。换句话说，钠通道是关闭的。&lt;/p&gt;
&lt;p&gt;当膜电位显著增加超过静息电位时，门控变量 $m$ 增加到其新值 $m_0(u)$ 。只要 $h$ 不变，钠电流就会增加，门打开。因此，变量 $m$ “激活”了通道。如果在电压恢复到静息状态后，$m$ 衰减回零，就被称为“去激活”。类似地，关于失活变量 $h$ 的术语也是类似的。在静息状态下，$h$ 有一个较大的正值。如果电压增加到超过 $-40 mV$ 的值，$h$ 接近一个接近静息状态的新值 $h_0(u)$ 。因此，通道通过一个由 $\tau_h(u)$ 给出的时间常数“失活”（阻塞）。如果电压返回到零，$h$ 增加，使得通道经历“去失活”。这听起来像是一种棘手的词汇，但事实证明，将一个去激活的通道（$m$ 接近零，$h$ 接近1）与一个失活的通道（$h$ 接近零）区分开来是有用的。&lt;/p&gt;
&lt;h3 id=&#34;2-随机通道的打开stochastic-channel-opening&#34;&gt;2. 随机通道的打开（Stochastic Channel Opening）&lt;/h3&gt;
&lt;p&gt;首先，离子通道的数量在一个细胞膜上是有限的，而且每个离子通道的开启和关闭是随机的。因此，当实验者记录通过细胞膜的电流时，他不会发现测量变量随时间平滑可靠地演变，而是会发现电流高度波动，每次重复实验时看起来都不同。这就是离子通道的随机性（如图 2.4 所示）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20231102224048-2023-11-02.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20231102224048-2023-11-02&#34;
	
	
&gt;&lt;/p&gt;



&lt;div class=&#34;notice notice-note&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M504 256a248 248 0 11-496 0 248 248 0 01496 0zm-248 50a46 46 0 100 92 46 46 0 000-92zm-44-165l8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;图 2.4 ： 随机通道激活现象。在实验中，当施加一个电压阶跃到细胞膜上时，通过细胞膜的电流会呈现阶梯状变化，并且在每次试验中都有所不同（如顶部的连续轨迹所示）。对多次试验进行平均后，得到的结果是底部的轨迹。&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;然而，Hodgkin-Huxley 模型是用确定性方程描述离子通道的开启和关闭的。这些方程涉及的变量包括 $m$ ，$h$ 和 $n$ ，它们对应的是通过一个假设的、包含无限数量离子通道的极大细胞膜的电流密度，或者说是通过一小片细胞膜的电流，但是这个电流是在多次重复同一实验后得到的平均值。这就是 $Hodgkin-Huxley$ 模型的局限性，因为它忽略了离子通道的随机性。不过可以通过向模型中添加适当的噪声来包含随机性。这种噪声可以模拟离子通道开启和关闭的随机性，从而使模型更准确地描述神经元的动力学行为。&lt;/p&gt;
&lt;p&gt;使用以电压为自变量的转换速率 $\alpha$ 和 $\beta$ 来描述每种通道类型的激活和失活动力学，公式如下：&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
\dot{m}= &amp;amp;\alpha_m (u) (1-m) - \beta_m (u) m ,\\
\dot{n}= &amp;amp;\alpha_n (u) (1-n) - \beta_n (u) n ,\\
\dot{h}= &amp;amp;\alpha_h (u) (1-h) - \beta_h (u) h , \\
\end{aligned}
\tag{2.7}
$$&lt;/p&gt;
&lt;p&gt;公式 （2.4）和 （2.7）是等价的。逼近值 $x_0(u)$ 和时间常数 $\tau_x(u)$ 由变换 $x_0(u)=\alpha_x(u)/[\alpha_x(u)+\beta_x(u)]$ 和 $\tau_x(u)=1/[\alpha_x(u)+\beta_x(u)]$ 给出。表 2.1 中的第二个表格给出了各种以 $u$ 为自变量的经验拟合函数 $\alpha$ 和 $\beta$ ，用于生成图 2.2 中的曲线。&lt;/p&gt;
&lt;p&gt;方程（2.7）是化学中常用的方程，用于描述具有速率常数 $α$ 和 $β$ 的激活过程的随机动力学。我们可以将这个过程解释为具有电压依赖的转换速率的两个状态之间的分子开关。例如，激活变量 $n$ 可以解释为找到一个开放的钾通道的概率。因此，在一个具有 $K$ 个离子通道的细胞膜中，预计有 $k \approx (1 - n)K$ 个通道是关闭的。我们可以将 $\alpha_n(u) \Delta t$ 解释为在短时间区间 $\Delta t$ 内，暂时关闭的通道中有一个切换到开放状态的概率。&lt;/p&gt;
&lt;h3 id=&#34;3-hudgkin-huxley-模型的动力学dynamics-of-hudgkin-huxley-model&#34;&gt;3. Hudgkin-Huxley 模型的动力学（Dynamics of Hudgkin-Huxley Model）&lt;/h3&gt;
&lt;p&gt;不同类型的输入被依次考虑，包括脉冲输入、恒定输入、阶跃电流输入和时间依赖输入。选择这些输入场景是为了直观理解 Hodgkin-Huxley 模型的动力学特性。Hodgkin-Huxley 模型最重要的特性是能够产生动作电位。在图 2.5(a) 中，一个持续 $1ms$ 的短脉冲电流在 $t=1ms$ 时施加，引发了一个动作电位。这个脉冲的幅度接近 $100mV$ ，半峰宽约为 $2.5ms$ 。在动作电位之后，膜电位下降到静息电位以下，再慢慢回到静息电位值 $-65mV$ 。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20231102225930-2023-11-02.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20231102225930-2023-11-02&#34;
	
	
&gt;



&lt;div class=&#34;notice notice-note&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M504 256a248 248 0 11-496 0 248 248 0 01496 0zm-248 50a46 46 0 100 92 46 46 0 000-92zm-44-165l8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;图 2.5 ： (a)动作电位。Hodgkin-Huxley 模型受到 $t=1ms$ 和 $t=2ms$ 之间的短而强的电流脉冲的刺激。对于 $t&amp;gt;2ms$ 的膜电位 $u(t)$ 的时间变化显示了动作电位（正峰值），随后是相对不应期，此时电位低于静息电位 $u_rest$（虚线）。右侧面板显示了 $t=2ms$ 和 $t=5ms$ 之间动作电位的放大视图。（b）门控变量 $m，h，n$ 的变化揭示了动作电位是如何通过钠通道和钾通道介导的。（c）钠电流 $I_{Na}$ 取决于变量 $m$ 和 $h$ ，在动作电位的上升阶段有一个脉冲。钾电流 $I_K$ 受变量 $n$ 控制，并与 $I_{Na}$ 相比有一定的延迟开始。&lt;/p&gt;&lt;/div&gt;
&lt;/p&gt;
&lt;h4 id=&#34;31-脉冲产生过程中离子通道的动力学ion-channel-dynamics-during-spike-generation&#34;&gt;3.1 脉冲产生过程中离子通道的动力学（Ion channel dynamics during spike generation）&lt;/h4&gt;
&lt;p&gt;为了理解动作电位生成的生物物理学基础，我们回到图 2.2(a) 。我们发现 $m_0$ 和 $n_0$ 随着 $u$ 的增加而增加，而 $h_0$ 则减少。因此，如果某些外部输入导致膜电压上升，由于 $m$ 的增加，钠通道的电导增加。结果，正钠离子流入细胞，进一步提高膜电位。如果这种正反馈足够大，就会引发动作电位。当膜电位接近钠电流的反转电位 $E_{Na}$ 时，这种爆发性增加自然停止。&lt;/p&gt;
&lt;p&gt;在高 $u$ 值下，由于因子 $h$ 的作用，钠电导缓慢关闭。如图 2.2(b) 所示，时间常数 $\tau_h$ 始终大于 $\tau_m$ 。因此，使通道失活的变量 $h$ 对电压增加的反应比激活通道的变量 $m$ 慢。在类似的较慢时间尺度上，钾电流在图 2.5(c) 中开始。由于它是向外的电流，它降低了电位。钠和钾电流的整体效应是一个短暂的动作电位，随后是负超调；(负超调，又被称为超极化脉冲后电位，是由于 $h$ 变量引起的钠通道的缓慢去失活过程所导致）。&lt;/p&gt;
&lt;h4 id=&#34;32-平均发射率与增益函数mean-firing-rate-and-gain-function&#34;&gt;3.2 平均发射率与增益函数（Mean Firing Rate and Gain Function）&lt;/h4&gt;
&lt;h4 id=&#34;33-时间依赖的输入刺激-stimulations-by-time-dependent-input&#34;&gt;3.3 时间依赖的输入刺激 （Stimulations by Time-Dependent Input）&lt;/h4&gt;
&lt;h4 id=&#34;34-发射阈值firing-threshold&#34;&gt;3.4 发射阈值（Firing Threshold）&lt;/h4&gt;
&lt;h4 id=&#34;35-不应性refractoriness&#34;&gt;3.5 不应性（Refractoriness）&lt;/h4&gt;
&lt;h4 id=&#34;36-阻尼振荡与瞬时脉冲damped-oscillations-and-transient-spiking&#34;&gt;3.6 阻尼振荡与瞬时脉冲（Damped Oscillations and transient spiking）&lt;/h4&gt;
&lt;h2 id=&#34;三多种多样的离子通道zoo-of-ion-channels&#34;&gt;三、多种多样的离子通道（Zoo of Ion Channels）&lt;/h2&gt;
</description>
        </item>
        <item>
        <title>脉冲神经网络入门：神经元与数学</title>
        <link>https://cuterwrite.top/p/introduction-neuron-math/</link>
        <pubDate>Wed, 01 Nov 2023 00:55:55 +0000</pubDate>
        
        <guid>https://cuterwrite.top/p/introduction-neuron-math/</guid>
        <description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2bb88c98-90f9-4308-abcf-493b7e507baa-2023-09-12.jpg" alt="Featured image of post 脉冲神经网络入门：神经元与数学" /&gt;&lt;h1 id=&#34;脉冲神经网络入门神经元与数学&#34;&gt;脉冲神经网络入门：神经元与数学&lt;/h1&gt;
&lt;h2 id=&#34;一神经元系统的结构&#34;&gt;一、神经元系统的结构&lt;/h2&gt;
&lt;p&gt;生物神经元是一种高度特化的细胞，其结构和功能包含很多因素，其中神经元的几何形态特征和电学物理特性是两个重要方面。几何形态特征主要指神经元的空间结构，而电学物理特性包含神经元不同的动作点位发放模式。生物神经系统内有两类细胞：神经元细胞和神经胶质细胞，前者担负着信息处理的主要任务，而后者对前者起支持作用。神经元细胞的几何形态结构和电学物理特性是生物神经系统进行信息处理的基础。所谓的神经胶质细胞，它们是脑组织能量供应和结构稳定所需要的。由于胶质细胞不直接参与信息处理，本文将不再进一步讨论它们。本文还将忽略一些罕见的神经元亚型，如哺乳动物视网膜上的非脉冲神经元。本文只专注于脉冲神经元。&lt;/p&gt;
&lt;h3 id=&#34;1-理想的脉冲神经元-ideal-spike-neuron&#34;&gt;1. 理想的脉冲神经元 (ideal spike neuron)&lt;/h3&gt;
&lt;p&gt;一个典型的神经元可以分为三个功能不同的部分，称为树突（dendrite）、细胞体（soma）和轴突（axon）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230912222755-2023-09-12.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230912222755-2023-09-12&#34;
	
	
&gt;&lt;/p&gt;



&lt;div class=&#34;notice notice-note&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M504 256a248 248 0 11-496 0 248 248 0 01496 0zm-248 50a46 46 0 100 92 46 46 0 000-92zm-44-165l8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;图 1.1：(a) Ramón y Cajal 于 1899 年绘制的神经元示意图。树突、体细胞和轴突可以被清楚地区分出来。图片显示了一个神经元动作电位的例子。动作电位是一个持续时间为 $1ms$ 的短电压脉冲，振幅约为 $100mv$ 。(b) 从突触前神经元 $j$ 到突触后神经元 $i$ 的信号传输。突触由虚线圈标记。右下端的轴突通向其它神经元。&lt;/p&gt;&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;树突：指从神经元细胞体内向外伸出的许多较短的分支，它们充当着神经元的&lt;strong&gt;输入端&lt;/strong&gt;，接收来自其它神经元的神经冲动并传递给细胞体；&lt;/li&gt;
&lt;li&gt;细胞体：神经元的核心，由细胞核、细胞质和细胞膜等组成，&lt;strong&gt;负责处理接收到的信号&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;轴突：指由神经元细胞体向外伸出的一条最长的分支，它是管状纤维组织，充当神经元的&lt;strong&gt;输出端&lt;/strong&gt;，再轴突末端有很多神经末梢，它们向外发出神经冲动。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;神经元的轴突末梢经过多次分支，最后每一个小支的末端膨大呈杯状或球状，称为突触小体。这些突触小体可以与多个神经元的细胞体或树突相接触，形成神经元之间连接的突触（synapse）。通常把发送神经元成为突触前神经元（presynaptic neuron），把接收神经元称为突触后神经元（postsynaptic neuron）。&lt;/p&gt;
&lt;h3 id=&#34;2-脉冲序列-spike-train&#34;&gt;2. 脉冲序列 (spike train)&lt;/h3&gt;
&lt;p&gt;生物神经系统在内外刺激作用下，使得神经元按照一定的时间间隔产生一系列的活动电位，称为脉冲序列 (spike train)。神经元信号由短的电脉冲组成，可以通过在神经元的体部或靠近体部或轴突的位置放置一个精细的电极来观察，如下图所示，脉冲（或活动电位），其振幅为 100 毫伏，通常持续时间为 1~2 ms。脉冲的形式不会因为活动电位沿轴突传播而改变。神经元发送的单个活动电位或脉冲是信号传递的基本单元，因为所有脉冲的波形都是相似的，所以活动电位的形状不会携带任何信息，而传递有用神经信息的是&lt;strong&gt;脉冲的发放时间和频率&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230912224451-2023-09-12.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230912224451-2023-09-12&#34;
	
	
&gt;&lt;/p&gt;



&lt;div class=&#34;notice notice-note&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M504 256a248 248 0 11-496 0 248 248 0 01496 0zm-248 50a46 46 0 100 92 46 46 0 000-92zm-44-165l8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;图 1.2：动作电位是刻板事件。在最大电压时间内排列的膜电位记录显示动作电位形状的变化很小。&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;脉冲序列中的活动电位通常是很好地分开的。即使有非常强的输入，也不可能在第一次脉冲期间紧接着激发第二次脉冲。两个脉冲之间的最小距离定义了神经元的绝对不应期（absolute refractory period）—— 大致在活动电位的复极化阶段（repolarization phase），无论用任何强的刺激都不能再引起活动电位。&lt;/p&gt;
&lt;h3 id=&#34;3-突触-synapse&#34;&gt;3. 突触 (synapse)&lt;/h3&gt;
&lt;p&gt;突触前神经元的轴突与突触后细胞的树突（或体细胞）接触的部位是突触。脊椎动物大脑中最常见的突触类型是化学突触。在化学突触处，轴突终端非常接近突触后神经元，在突触前和突触后细胞膜之间只留下一个微小的间隙。这就是所谓的突触间隙（synaptic cleft）。当一个活动电位到达突触时，它触发了一个复杂的生化处理步骤链，导致神经递质从突触前末端释放到突触间隙中。一旦递质分子到达突触后一侧，它们将被突触后细胞膜上的专门受体检测到，并导致（直接或通过生化信号链）打开特定通道，导致细胞外液体中的离子流入细胞。离子的涌入反过来又改变了突触后部位的膜电位，因此，最后，化学信号被转化为电反应。从突触前神经元传入的脉冲信号引起突触后神经元膜电位发生的变化称为突触后电位（postsynaptic potential）。&lt;/p&gt;
&lt;p&gt;除了化学突触之外，神经元还可以通过电突触连接，称为间隙连接（gap junctions）。特化膜蛋白在两个神经元之间形成直接的电连接。关于间隙连接的功能方面当前所知不多，但它们被认为参与了神经元的同步。&lt;/p&gt;
&lt;h2 id=&#34;二神经动力学的要素&#34;&gt;二、神经动力学的要素&lt;/h2&gt;
&lt;p&gt;脉冲对突触后神经元的影响可以用细胞内电极来记录，该电极测量细胞内部和其周围环境之间的电位差 $u(t)$ 。这个电位差被称为膜电位。在没有任何输入的情况下，神经元处于静息状态，对应一个恒定的膜电位 $u_{rest}$，称为静息电位（resting potential），一般在 $-80\sim -40mV$ （当以细胞外的电位为 0 ）。当神经元受到外界刺激，突触后电位的总和超过某一阈值时，神经元产生一个不衰减的沿神经纤维传递的神经冲动，即活动电位或脉冲。活动电位的动态变化过程包含一个迅速的去极化正向电位变化和缓慢的复极化负向电位变化。活动电位的另一特征是电位的极性在峰电位顶端倒转，细胞内由静息时的负电位变为正电位，这一过程称为超射。神经元活动电位的产生会导致局部的兴奋性发生一系列的变化。大致在活动电位的复极化阶段（repolarization phase），无论用任何强的刺激都不能再引起活动电位，这个阶段称为绝对不应期（absolute refractory period）；在随后的短时间内，活动电位进入超极化阶段（hyperpolarization phase），用比原来强的刺激方能引起活动电位，而且反应幅度还会小一些，这个阶段称为相对不应期（relative refractory period）。神经元对信号的传递方式在很大程度上与神经元的电学特性有关。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230913004838-2023-09-13.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230913004838-2023-09-13&#34;
	
	
&gt;&lt;/p&gt;



&lt;div class=&#34;notice notice-note&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M504 256a248 248 0 11-496 0 248 248 0 01496 0zm-248 50a46 46 0 100 92 46 46 0 000-92zm-44-165l8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;图 2.1：膜电位在绝对不应期和相对不应期的变化。在绝对不应期，神经元不能再次激发。在相对不应期，神经元可以激发，但需要更强的刺激。&lt;/p&gt;&lt;/div&gt;

&lt;h3 id=&#34;1-突触后电位postsynaptic-potential&#34;&gt;1. 突触后电位（postsynaptic potential）&lt;/h3&gt;
&lt;p&gt;从突触前神经元传入的脉冲信号引起突触后神经元膜电位发生的变化称为突触后电位（postsynaptic potential），具有局部电位的性质。一个神经元通常有许多突触，其中有些是兴奋性的，有些是抑制性的。对于从突触前神经元传来的多个脉冲，由于突触类型的不同，突触后电位可分为兴奋性和抑制性两类。兴奋性突触使突触后神经元的膜去极化，产生正的突触后电位，称为兴奋性突触后电位（excitatory postsynaptic potential，EPSP）。EPSP 在传入脉冲到达突触后神经元 $0.3\sim 0.5ms$ 之后产生，它有一个较快的上升过程和缓慢的指数衰减过程，电位总共持续  $10\sim 20ms$ 。抑制性突触使突触后神经元的膜超极化，产生负的突触后电位，称为抑制性突触后电位（inhibitory postsynapticpotential，IPSP），IPSP 到达峰值时间和 EPSP 相似。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230913005342-2023-09-13.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230913005342-2023-09-13&#34;
	
	
&gt;&lt;/p&gt;



&lt;div class=&#34;notice notice-note&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M504 256a248 248 0 11-496 0 248 248 0 01496 0zm-248 50a46 46 0 100 92 46 46 0 000-92zm-44-165l8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;图 2.2：(a)兴奋性突触后电位（EPSP）; (b)抑制性突触后电位（IPSP）。&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;用数学术语规范化，那么研究神经元 $i$ 的膜电位随时间变化的函数 $u_i(t)$ 。在输入脉冲到达之前，有 $u_i(t)=u_{rest}\ (t=0)$ 。对于 $t&amp;gt;0$ ，在电极上看到神经元 $i$ 的反应如下：&lt;/p&gt;
&lt;p&gt;$$
u_i(t)-u_{rest}=: \varepsilon_{ij}(t) \tag{2.1}
$$&lt;/p&gt;
&lt;h3 id=&#34;2-发射阈值与活动电位firing-threshold-and-action-potential&#34;&gt;2. 发射阈值与活动电位（firing threshold and action potential）&lt;/h3&gt;
&lt;p&gt;考虑两个突触前神经元 $j=1,2$ ，它们都向突触后神经元 $i$ 发送脉冲。神经元 $j=1$ 在时刻 $t_1^{(1)}, t_2^{(2)}, \cdots$ 发送脉冲，神经元 $j=2$ 也在时刻 $t_1^{(1)}, t_2^{(2)}, \cdots$ 发送脉冲。每个脉冲分别引起一个突触后电位 $\varepsilon_{i1}$ 或 $\varepsilon_{i2}$ 。只要只有少数的输入脉冲，电位的总变化大小约是各个 PSP 的总和：&lt;/p&gt;
&lt;p&gt;$$
u_i(t)=\sum_{j}\sum_{f} \varepsilon_{ij}(t-t_j^{f}) + u_{rest} \tag{2.2}
$$&lt;/p&gt;
&lt;p&gt;即，膜电位对输入脉冲的反应是线性的。&lt;/p&gt;
&lt;p&gt;另一方面，如果在很短的时间间隔内有太多的输入脉冲到达，线性就会被打破。一旦膜电位达到一个临界值 $\vartheta$ ，它的曲线就会显示出与 PSP 的简单求和完全不同的行为：膜电位表现出类似脉冲的偏移，振幅约为 $100 mV$ 。这个短电压脉冲将沿着神经元轴突与其他神经元的突触传播。在脉冲之后，膜电位并不直接回到静止电位，而是在许多神经元类型中通过低于静止值的超极化阶段。&lt;/p&gt;
&lt;p&gt;单个 EPSP 的振幅在 $1 mV$ 的范围内。脉冲初始临界值比静息电位高约 $20$ 至 $30 mV$ 。因此在大多数神经元中，如下图所示的四个脉冲是不足以触发一个活动电位的。相反地，需要大约 $20\sim 50$ 个突触前脉冲在很短的时间窗口内到达才能触发一个突触后活动电位。这个时间窗口称为发射阈值（firing threshold），它是神经元的一个重要参数。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230913012304-2023-09-13.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230913012304-2023-09-13&#34;
	
	
&gt;&lt;/p&gt;



&lt;div class=&#34;notice notice-note&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M504 256a248 248 0 11-496 0 248 248 0 01496 0zm-248 50a46 46 0 100 92 46 46 0 000-92zm-44-165l8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;图 2.3：来自第二个突触前神经元 $j=2$ 的输入脉冲在来自神经元 $j=1$ 的尖峰后不久到达，导致第二个突触后电位增加到了第一个上。&lt;/p&gt;&lt;/div&gt;

&lt;h2 id=&#34;三integrade-and-fire-模型&#34;&gt;三、Integrade-and-fire 模型&lt;/h2&gt;
&lt;p&gt;神经元动力学可以被视为一个整合的过程，与出发活动电位超过某个临界电压的机制相结合。事实上，在实验中，发射时间通常被定义为膜电位从下往上达到某个阈值的时刻。为了建立一个神经元动力学的现实模型，我们通过阈值 $\vartheta$ 来描述神经元的发射阈值。如果电压 $u_i(t)$ （包含所有输入的总效应）从下往上到达 $\vartheta$ ，我们就说神经元会发射一个脉冲。跨越阈值的时刻定义了发射时间 $t_i^f$ 。&lt;/p&gt;
&lt;p&gt;该模型利用了一个事实，即一个而给定的神经元的活动电位总是具有大致相同的形式。如果一个活动电位的形状总是相同的，那么这个形状就不能用来传递信息；相反，信息包含在脉冲的存在或不存在中。因此活动电位被简化为“发生在一个精确的时刻的事件”。&lt;/p&gt;
&lt;p&gt;将活动电位描述为事件的神经元模型被称为 Intergrate-and-fire 模型。该模型没有尝试描述活动电位的形状。Integrade-and-fire 模型有两个独立的组成部分，都是定义其动力学所必须的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;描述膜电位 $u_i(t)$ 变化的方程；&lt;/li&gt;
&lt;li&gt;产生脉冲的机制。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在下文中将介绍最简单的 Intergrade-and-fire 类模型：Leaky Integrade-and-fire 模型，该模型有两个独立的组成部分：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;描述膜电位变化的线性微分方程；&lt;/li&gt;
&lt;li&gt;脉冲发射的阈值。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;1-输入的整合input-integration&#34;&gt;1. 输入的整合（input integration）&lt;/h3&gt;
&lt;p&gt;变量 $u_i$ 描述了神经元 $i$ 的膜电位的瞬时值。在没有任何输入的情况下，电位处于静息值 $u_{rest}$ 。如果实验者向神经元 $i$ 注入电流 $I(t)$ ，或神经元 $i$ 接收其它神经元的突触输入，电位 $u_i$ 将被偏离其静止值。&lt;/p&gt;
&lt;p&gt;为了得到一个将瞬时电压 $u_i(t) - u_{rest}$ 与输入电流 $I(t)$ 联系起来的方程，我们使用电学理论中的基本定律。一个神经元被细胞膜所包围，这是一个相当好的绝缘体。如果一个短的电流脉冲 $I(t)$ 被注入到神经元中，额外的电荷 $q=\int I(t&amp;rsquo;)\ dt&amp;rsquo;$ 必须去到某个地方：给细胞膜充电（如下图所示）。因此，细胞膜的作用就相当于一个容量为 $C$ 的电容器。因为绝缘体并不完美，电荷会随着时间的推移慢慢通过细胞膜泄露。因此，细胞膜可以用一个有限的泄露电阻 $R$ 表示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230914213909-2023-09-14.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230914213909-2023-09-14&#34;
	
	
&gt;&lt;/p&gt;



&lt;div class=&#34;notice notice-note&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M504 256a248 248 0 11-496 0 248 248 0 01496 0zm-248 50a46 46 0 100 92 46 46 0 000-92zm-44-165l8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;图 3.1：神经元的电学特性：被动膜。(a)由细胞膜（大圈）包围的神经元接收一个（正）输入电流 $I(t)$ ，增加细胞内的电荷。细胞膜的作用就像一个与电阻并联的电容器，与电位为 $u_{rest}$ 的电池并联。(b)细胞膜对具有平滑电压轨迹的阶梯电流的反应。&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;代表 Leaky Integrate-and-fire 模型的基本电路由一个电容 $C$ 和一个由电流 $I(t)$ 驱动的电阻 $R$ 并联组成。如果驱动电流 $I(t)$ 为零，则电容器两端的电压由电池电压 $u_{rest}$ 给出。&lt;/p&gt;
&lt;p&gt;为了分析电路，我们使用电流守恒定律，将驱动电流分成两部分。&lt;/p&gt;
&lt;p&gt;$$
I(t) = I_{R} + I_{C}. \tag{3.1}
$$&lt;/p&gt;
&lt;p&gt;第一个是通过线性电阻 $R$ 的阻性电流 $I_R$ ，根据欧姆定律可以计算出 $I_R=\frac{u_R}{R}$，其中 $u_R=u-u_{rest}$ 是电阻两端的电压。第二个分量 $I_C$ 给电容器 $C$ 充电。根据电容的定义 $C=\frac{q}{u}$ ，其中 $q$ 为电荷，$u$ 为电压，我们可以得出电容电流 $I_C=\frac{dq}{dt}=C \frac{du}{dt}$ ，即：&lt;/p&gt;
&lt;p&gt;$$
I(t)=\frac{u(t)-u_{rest}}{R}+C \frac{du}{dt}. \tag{3.2}
$$&lt;/p&gt;
&lt;p&gt;等式两边乘以 $R$ ，并引入时间常数 $\tau_{m}=RC$ ， 则标准形式为：&lt;/p&gt;
&lt;p&gt;$$
\tau_m \frac{du}{dt} = -[u(t)-u_{rest}]+RI(t). \tag{3.3}
$$&lt;/p&gt;
&lt;p&gt;其中，$u$ 是膜电位，$\tau_m$ 是神经元的膜时间常数。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20231031161758-2023-10-31.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20231031161758-2023-10-31&#34;
	
	
&gt;&lt;/p&gt;



&lt;div class=&#34;notice notice-note&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M504 256a248 248 0 11-496 0 248 248 0 01496 0zm-248 50a46 46 0 100 92 46 46 0 000-92zm-44-165l8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;图3.2：被动膜上的短脉冲和总充电量。由短电流脉冲 $I(t)$ 驱动的漏电整合器的电压响应振幅（底部）（顶部）只取决于总电荷 $q = \int I(t) \ dt$ ，而不取决于电流脉冲的高度。&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;从数学的角度来看，公式 (3.3) 是一个线性微分方程。从电气工程师的角度来看，它是一个漏电整合器或 $RC$ 电路的方程，其中电阻 $R$ 和电容 $C$ 是平行排列的。从神经科学家的角度来看，它被称为被动膜的方程。&lt;/p&gt;
&lt;p&gt;方程 (3.3) 的解是什么？我们假设，无论出于什么原因，在时刻 $t=0$ 时，膜电位的值为 $u_{rest} + \Delta u$ 。在 $t&amp;gt;0$ 时，输入电流 $I(t)$ 将消失变为零。直观地讲，我们期望，如果我们等待足够长的时间，膜电位会放松到静息电位 $u_{rest}$ 。事实上，具有初始条件 $u(t_0)=u_{rest} + \Delta u$ 的方程 (3.3) 的解是：&lt;/p&gt;
&lt;p&gt;$$
u(t)-u_{rest}=\Delta u \exp \left ( -\frac{t-t_0}{\tau_m} \right)\ \mathrm{for}\ t&amp;gt;0. \tag{3.4}
$$&lt;/p&gt;
&lt;p&gt;因此，在没有输入的情况下，膜电位以指数形式衰减静息电位。膜时间常数 $\tau_m=RC$ 是衰减的特征时间。对于一个典型的神经元来说，它在 $10ms$ 的范围内，因此与 $1ms$ 数量级的脉冲持续时间相比相当长。解 (3.4) 的有效性可以通过在方程两边取导数来检查。由于它是没有输入时的解，它又被称为自由解（free solution）。&lt;/p&gt;
&lt;h3 id=&#34;2-脉冲输入pulse-input&#34;&gt;2. 脉冲输入（pulse input）&lt;/h3&gt;
&lt;p&gt;在我们继续定义 Intergrate-and-Fire 模型及其变体之前，让我们研究一下由公式 (3.3) 定义的被动膜的动力学。假设被动膜受到恒定输入电流 $I(t)=I_0$ 的刺激。该电流从 $t=0$ 开始，持续到 $t=Delta$ 。为了简单起见，我们假设 $t=0$ 时，膜电位为 $u_{rest}$ 。&lt;/p&gt;
&lt;p&gt;第一步，我们计算一下膜电位的时间过程。膜电位的轨迹可以通过整合方程 (3.3) 和初始条件 $u(t_0)=u_{rest}$ 得到，即 $0 &amp;lt; t &amp;lt; \Delta$ 时的解为：&lt;/p&gt;
&lt;p&gt;$$
u(t) = u_{rest} + RI_0 \left [ 1 - \exp \left ( -\frac{t}{\tau_m} \right ) \right ]. \tag{3.5}
$$&lt;/p&gt;
&lt;p&gt;如果输入电流从未停止，膜电位 (3.5) 将在 $t\rightarrow \infty$ 时接近渐进值 $u(\infty)=u_{rest}+RI_0$ 。一旦达到稳定状态，电容器上的电荷就不再变化。然后，所有的输入电流必须流经电阻。因此，电阻处的稳态电压是 $RI_0$ ，所哟膜的总电压是 $u_{rest}+RI_0$ 。&lt;/p&gt;
&lt;h3 id=&#34;3-脉冲发射阈值spike-firing-threshold&#34;&gt;3. 脉冲发射阈值（spike firing threshold）&lt;/h3&gt;
&lt;p&gt;发射时间指的是一个给定的神经元发射动作电位 $t^f$ 的时刻。Leaky Integrate-and-Fire(LIF) 模型中的发射时间 $t^f$ 是由一个阈值标准定义的：&lt;/p&gt;
&lt;p&gt;$$
t^f\ : \quad u(t^f) = \vartheta. \tag{3.6}
$$&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20231031165128-2023-10-31.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20231031165128-2023-10-31&#34;
	
	
&gt;&lt;/p&gt;



&lt;div class=&#34;notice notice-note&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M504 256a248 248 0 11-496 0 248 248 0 01496 0zm-248 50a46 46 0 100 92 46 46 0 000-92zm-44-165l8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;图3.3：Integrate-and-Fire 模型。(a)由恒定输入电流 $I_0=1.5$ 驱动的 Integrate-and-fire 神经元的膜电位的事件过程。电压 $\Delta u(t)=u-u_{rest}$ 被阈值 $\vartheta$ 归一化。输入电流的单位将被选择，以便 $I_0=1$ 能对应达到 $t\rightarrow \infty$ 的阈值曲线。在一个脉冲过后，电位被重置为 $u_{\tau} = u_{rest}$ 。(b)对随时间变化的输入电流的电压反应。&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;虽然脉冲的形式没有被明确描述。然而注意到，在发射时间 $t^f$ 之后，电位立即被重置为一个新的值 $u_r &amp;lt; \vartheta$。&lt;/p&gt;
&lt;p&gt;$$
\lim_{\delta \rightarrow 0; \delta &amp;gt; 0} u(t^f + \delta) = u_r. \tag{3.7}
$$&lt;/p&gt;
&lt;p&gt;对于 $t&amp;gt;t^f$，动力学再次由 (3.3) 给出，直到发生下一个阈值跨越。联立 (3.3) 和 (3.7)，我们可以定义 Leak Integrate-and-Fire(LIF) 模型（Stein, 1967）。图 3.3 显示了由恒定电流 $I_0$ 驱动的 LIF 模型的电压曲线。&lt;/p&gt;
&lt;p&gt;对于神经元 $i$ 的发射时间，我们定义 $t_i^f$ ，其中 $f=1,2,\cdots $ 是脉冲的标签。从形式上看，我们可以将神经元的脉冲序列表示为发射时间的序列：&lt;/p&gt;
&lt;p&gt;$$
S_i(t) = \sum_{f} \delta (t-t_i^f). \tag{3.8}
$$&lt;/p&gt;
&lt;p&gt;其中，$\delta(x)$ 是 Dirac $\delta$ 函数：&lt;/p&gt;
&lt;p&gt;$$
\delta(x)=\begin{cases}
0,&amp;amp;x = 0 \\
\int_{-\infty}^{\infty} \delta(x) dx = 1,&amp;amp; x \neq 0
\end{cases} \tag{3.9}
$$&lt;/p&gt;
&lt;h2 id=&#34;四lif-模型的局限性&#34;&gt;四、LIF 模型的局限性&lt;/h2&gt;
&lt;p&gt;LIF 模型是高度简化的，忽略了神经元动力学的许多细节。尤其是，可能来自突触前神经元或者电流注入的输入被线性整合，与突触后神经元的状态无关：&lt;/p&gt;
&lt;p&gt;$$
\tau_m \frac{du}{dt} = -[u(t)-u_{rest}]+RI(t). \tag{4.1}
$$&lt;/p&gt;
&lt;p&gt;其中，$I(t)$ 是输入电流。此外，在每个输出脉冲之后，膜电位被重置。&lt;/p&gt;
&lt;p&gt;$$
\mathrm{if}\ u(t)=\vartheta \quad\mathrm{then} \ \lim_{\delta \rightarrow 0; \delta &amp;gt; 0} u(t+\delta) = u_r. \tag{4.2}
$$&lt;/p&gt;
&lt;p&gt;这样就不会保留对以前脉冲的记忆。现在，让我们列出到目前位置讨论的简化模型的主要局限性。&lt;/p&gt;
&lt;h3 id=&#34;1-适应爆发和抑制性反弹adaptation-bursting-and-inhibitory-rebound&#34;&gt;1. 适应、爆发和抑制性反弹（adaptation, bursting and inhibitory rebound）&lt;/h3&gt;
&lt;p&gt;通过细胞内电极注入电流。在一个标准的实验方案中，我们可以施加一个刺激电流，在时间 $t_0$ 从一个电流值 $I_1$ 切换到一个新的电流值 $I_2$ 。假设 $I_1=0$ ，这样神经元在 $t&amp;lt;t_0$ 时是静息状态的。如果电流 $I_2$ 足够大，它将引起 $t&amp;gt;t_0$ 的脉冲。大多数神经元会对当前阶跃做出反应，产生一列脉冲，脉冲之间的间隔会连续增加，直到达到周期性发射的稳定状态。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20231031210458-2023-10-31.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20231031210458-2023-10-31&#34;
	
	
&gt;&lt;/p&gt;



&lt;div class=&#34;notice notice-note&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M504 256a248 248 0 11-496 0 248 248 0 01496 0zm-248 50a46 46 0 100 92 46 46 0 000-92zm-44-165l8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;图4.1：对当前阶跃的反应。在(a)(c)中，电流在 $t=t_0$ 时从 $I_1=0$ 切换到 $I_2&amp;gt;0$ 。fast-spiking neuron(a)在没有适应的情况下具有较短的脉冲间隔，而 regularly firing neuron(c)表现出适应性，可以看到脉冲间隔时间的增加。(b)中显示了一个 stuttering neuron(指发生语言或运动障碍的神经元，这种神经元在传递信号时可能会出现中断、重复或不协调的行为，导致口吃或肌肉抽动等症状)的例子。许多神经元在抑制性电流 $I_1 &amp;lt;0$ 被关闭后发出一个抑制性反弹脉冲(d)。&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;图4.1(c)中这种具有适应性的神经元被称为 regularly firing neuron。适应是一个缓慢的过程，在几个脉冲上积累起来。由于标准的 LIF 模型在每次脉冲后将电位重置位相同的值并重新启动整合过程，因此在最近的脉冲之后不会保留任何记忆。因此，LIF 神经元不具有适应性。&lt;/p&gt;
&lt;p&gt;第二类神经元为 fast-spiking neuron。这些神经元不显示适应性，因此可以用 LIF 模型来近似。许多抑制性神经元是 fast-spiking neuron。&lt;/p&gt;
&lt;p&gt;除了 regularly firing neuron 和 fast-spiking neuron 外，还有 bursting neuron 和 stuttering neuron。这些神经元对恒定刺激的反应是一连串的脉冲，这些脉冲周期性地爆发或非周期性地被相当长的间隔打断。&lt;/p&gt;
&lt;p&gt;另一个经常观察到的行为是抑制后的反弹。考虑到一个 $I_1&amp;lt;0$ 和 $I_2=0$ 的阶梯电流，即：在一个时间 $t_0$ 从一个抑制性电流 $I_1$ 切换到零电流。在这种情况下，许多神经元会在 $t&amp;gt;t_0$ 时发出一个或多个抑制性反弹脉冲，甚至抑制的释放也能出发动作电位。这种行为在图 4.1(d) 中显示。&lt;/p&gt;
&lt;h3 id=&#34;2-分流抑制和反转电位shunting-inhibition-and-reversal-potential&#34;&gt;2. 分流抑制和反转电位（shunting inhibition and reversal potential）&lt;/h3&gt;
&lt;p&gt;在显示中，神经元被嵌入在一个大型网络中，并接受来自许多其它神经元的输入。假设一个来自突触前神经元 $j$ 的脉冲在时间 $t_j^f$ 被发送到突触后神经元 $i$ 的突触。突触后电位是脉冲到达突触后产生的，其形状和振幅不取决于突触后神经元 $i$ 的状态。这当然是一种简化，现实中的情况要复杂一些。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20231031231444-2023-10-31.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20231031231444-2023-10-31&#34;
	
	
&gt;&lt;/p&gt;



&lt;div class=&#34;notice notice-note&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M504 256a248 248 0 11-496 0 248 248 0 01496 0zm-248 50a46 46 0 100 92 46 46 0 000-92zm-44-165l8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;图4.2：突触后电位的形状取决于去极化的瞬间水平。(a)当神经元处于静息状态时，在时间 $t^f$ 到达的抑制性突触的突触前脉冲对膜电位几乎没有影响，但如果膜电位 $u$ 高于静息电位，则影响很大。如果膜在抑制性突触的反转电位以下超极化，对突触前输入的反应就会改变符号。(b)兴奋性突触的脉冲引起突触后电位，其振幅仅略微取决于瞬间电压 $u$ 。对于大的去极化，振幅会饱和并且变小。&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;在图 4.2 中示意性地勾勒了一个实验，其中神经元由恒定电流 $I_0$ 驱动。假设 $I_0$ 太弱，无法引起发射，因此，在一定的静息时间后，膜电位会稳定在一个恒定值 $u_0$ 。在 $t=t^f$ 时，其中一个突触前神经元发出一个脉冲，这样，不久之后动作电位就会到达突触，并且提供突触后神经元的额外刺激。更精确的说，脉冲在突触后神经元产生一个电流脉冲（突触后电流，PSC），其振幅为：&lt;/p&gt;
&lt;p&gt;$$
PSC \propto [u_0-E_{syn}] \tag{4.3}
$$&lt;/p&gt;
&lt;p&gt;其中，$u_0$ 是膜电位，$E_{syn}$ 是突触的反转电位。由于电流输入的振幅取决于 $u_0$ ，突触后电位的反应也是如此。&lt;/p&gt;
&lt;p&gt;突触后反应对神经元瞬间状态的依赖性在抑制性突触中最为明显。抑制性突触 $E_{syn}$ 的反转电位更低，但通常接近静息电位。因此，如果神经元处于精细状态，输入脉冲对膜电位几乎没有任何影响。然而，如果膜是去极化的，同样的输入脉冲会引起更大的抑制性突触后电位；如果膜已经超极化，输入脉冲甚至可以产生去极化的效果。&lt;/p&gt;
&lt;p&gt;虽然抑制性输入通常对膜电位只有很小的影响，但细胞膜的局部电导率可以大大增加。突触通常位于树突树的体部或轴上。由于它们的策略位置，少数抑制性输入脉冲可以“冲刷”树突树从从数百个兴奋性突触收集的整合输入。这种现象被称为分流抑制（shunting inhibition）。&lt;/p&gt;
&lt;p&gt;兴奋性突触的反转电位通常明显高于静息电位。如果膜去极化， $u_0 \gg u_rest$ ，兴奋性突触后电位的振幅就会降低，但其效果并不像抑制那样明显。对于非常高的去极化水平，可以观察到 EPSPs 的饱和。&lt;/p&gt;
&lt;h3 id=&#34;3-脉冲后的电导率变化conductance-changes-after-spikes&#34;&gt;3. 脉冲后的电导率变化（conductance changes after spikes）&lt;/h3&gt;
&lt;p&gt;突触后电位的形状不仅取决于去极化的程度，而且更广泛地取决于神经元的内部状态，例如，相对于以前动作电位的时间。假设在时间 $t^f_i$ 产生了动作电位，突触前的脉冲在突触 $j$ 的时间 $t^f_j &amp;gt; t^f_i$ 到达。如果突触前脉冲在突触后动作电位期间或之后不久到达，它的影响不大，因为参与发射动作电位的一些离子通道依然是开放的。如果输入脉冲到达地更晚，它就会产生一个通常大小的突触后电位。&lt;/p&gt;
&lt;h3 id=&#34;4-空间结构spatial-structure&#34;&gt;4. 空间结构（spatial structure）&lt;/h3&gt;
&lt;p&gt;突触后电位的形式也取决于突触在树突树上的位置。位于远离体细胞的突触引起的突触后电位通常比位于体细胞附近的突触引起的突触后电位小。如果几个输入在几毫秒内出现在同一个树突分支上，第一个输入将引起膜电位的局部变化，影响对稍晚到达的输入脉冲的反应幅度。这可能会导致饱和，或者在所谓的“活性”电流的情况下，导致反应的增强。而在 LIF 模型中，不同突触前脉冲之间这种非线性相互作用被忽略了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20231101212827-2023-11-01.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20231101212827-2023-11-01&#34;
	
	
&gt;&lt;/p&gt;



&lt;div class=&#34;notice notice-note&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M504 256a248 248 0 11-496 0 248 248 0 01496 0zm-248 50a46 46 0 100 92 46 46 0 000-92zm-44-165l8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;图4.3：突触后电位的形状（虚线）取决于自神经元 $i$ 的最后一次输出脉冲以来所经过的时间 $t-t^f_i$。 突触后的尖峰在时间 $t^f_i$ 被触发。突触前的脉冲在突触后神经元的尖峰后不久到达 $t^f_j$ ，其振幅比后来到达的脉冲小得多。&lt;/p&gt;&lt;/div&gt;

&lt;h2 id=&#34;五lif-模型的启示&#34;&gt;五、LIF 模型的启示&lt;/h2&gt;
&lt;p&gt;LIF 模型是一个极其简化的神经元模型。它忽略了神经科学家在研究活脑或脑组织切片中的神经元时观察到的许多特征。因此，问题出现了：我们应该从这样一个模型中期待什么？显然，我们不能指望它能解释神经元的完整生物化学和生物物理学。我们也不期望它能解释由树突树上某些 &amp;ldquo;热点 &amp;ldquo;的活性电流引起的高度非线性的相互作用。然而，当涉及到产生脉冲时，即在时间上精确计时的事件时，LIF 模型是十分精确的。因此，它有可能成为神经元中脉冲产生的有效模型，或者更准确地说，能成为细胞体中脉冲产生的有效模型。&lt;/p&gt;
&lt;p&gt;从脉冲生成模型中预测真实神经元脉冲的时间趋势是合理的。实验者使用第一个电极将随时间变化的输入电流 $I(t)$ 注入皮质神经元的细胞体中。通过一个独立的第二电极，实验者测量神经元体部的电压。毫不奇怪，电压轨迹不时地包含尖锐的电脉冲。这些是动作电位或脉冲。&lt;/p&gt;
&lt;p&gt;数学神经科学家现在把实验者使用的输入电流的时间过程 $I(t)$ 与神经元膜电位的时间过程一起，调整一个 LIF 模型的参数，使该模型在输入电流相同的情况下，在时间上产生与真实神经元大致相同的脉冲。这需要一些参数调整，但似乎是可行的。然而，更难解决的相关问题是，神经元模型现在是否可以用来预测真实神经元在新的随时间变化的输入电流下的发射时间，而这种新的输入电流在参数优化过程中并未使用。&lt;/p&gt;
&lt;p&gt;如上所述，神经元不仅在每次放电后表现出不稳定，而且还表现出在数百毫秒内积累起来的适应能力。简单的 LIF 模型并不能很好地预测真实神经元的脉冲时间。然而，如果在神经元模型中加入适应性(和不稳定因素)，预测结果就会出奇地好。增加适应性的一种直接方法是使神经元模型的放电阈值动态：在每个脉冲之后，将阈值 $\vartheta$ 增加一个增量 $\theta$ ，使得静息期间，阈值接近其固定值 $θ_0$ 。我们可以使用 Dirac $\delta$ 函数来表示这种动态阈值：&lt;/p&gt;
&lt;p&gt;$$
\tau_{adapt} \frac{d\vartheta}{dt} = -[\vartheta(t)-\vartheta_0] + \theta \sum_{f} \delta(t-t_i^f). \tag{5.1}
$$&lt;/p&gt;
&lt;p&gt;其中，$\tau_{adapt}$ 为适应时间常数（~几百毫秒），$t^f=t^{(1)}, t^{(2)}, t^{(3)}, \cdots$ 是神经元的发射时间。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20231101214530-2023-11-01.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20231101214530-2023-11-01&#34;
	
	
&gt;&lt;/p&gt;



&lt;div class=&#34;notice notice-note&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M504 256a248 248 0 11-496 0 248 248 0 01496 0zm-248 50a46 46 0 100 92 46 46 0 000-92zm-44-165l8 136c0 6 5 11 12 11h48c7 0 12-5 12-11l8-136c0-7-5-13-12-13h-64c-7 0-12 6-12 13z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;图5.1： 广义 LIF 模型与真实实验测量的对比。由波动电流驱动的真实神经元中记录的电压曲线（粗黑线）被叠加在由相同电流驱动的广义 LIF 模型（细线）上。除了少数额外或遗漏的脉冲（箭头），平均脉冲时间也得到了很好的预测。&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;从图 5.1 中可以看出，具有动态阈值的 LIF 模型的预测结果与真实神经元的电压曲线非常吻合。&lt;/p&gt;
&lt;p&gt;一旦我们确定了好的候选神经元模型，我们将可以尝试用这些模型构建大的神经元网络，并进一步尝试理解神经元网络所使用的动态和计算原理以及潜在的神经编码。虽然这并不意味着理解了整个大脑，但经过良好测试的简化神经元模型中理解大量神经元群体的原理是朝着这个方向迈出的第一步，也是重要的一步。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;神经元信号由短电压脉冲组成，称为动作电位或者脉冲。这些脉冲沿着轴突行进，并被分配到几个突触后神经元，在那里它们又引起突触后电位。如果一个突触后神经元在一个短时间窗口内从多个突触前神经元那收集到足够多的脉冲，它的膜电位可能会达到一个临界值，然后发射出一个脉冲。我们说，神经元已经“发射”了一个脉冲。这个脉冲是神经元的输出信号，反过来又被传输到其它神经元。&lt;/p&gt;
&lt;p&gt;一个比较简单的脉冲神经元模型是 LIF 模型。该模型用一个线性微分方程描述了输入电流如何被整合并转化为膜电位 $u(t)$ 。这里的输入可以是实验者注入孤立神经元的输入电流，也可以是由大型高度连接网络中其它神经元到达的脉冲引起的突触输入电流。其次，如果膜电位到达阈值 $\vartheta$ ，LIF 神经元会产生一个输出脉冲。最后，在脉冲发射后，线性整合过程被重置，膜电位被重置为一个新的值 $u_r$ 。这个过程被称为膜电位的重置。&lt;/p&gt;
&lt;p&gt;LIF 模型并没有考虑持久的适应性，然而，如果 LIF 模型的电压动态地通过适应机制得到增强，那么它可以成为准确预测皮层神经元脉冲时间的有力工具。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>NEST on HPC 安装教程</title>
        <link>https://cuterwrite.top/p/nest-on-hpe-install/</link>
        <pubDate>Mon, 30 Oct 2023 00:00:00 +0000</pubDate>
        
        <guid>https://cuterwrite.top/p/nest-on-hpe-install/</guid>
        <description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/20231031002508-2023-10-31.png" alt="Featured image of post NEST on HPC 安装教程" /&gt;&lt;h1 id=&#34;nest-on-hpc-安装教程&#34;&gt;NEST on HPC 安装教程&lt;/h1&gt;
&lt;h2 id=&#34;1-安装-miniconda3&#34;&gt;1. 安装 MiniConda3&lt;/h2&gt;
&lt;p&gt;从 &lt;a class=&#34;link&#34; href=&#34;https://repo.anaconda.com/miniconda/Miniconda3-py39_23.5.2-0-Linux-x86_64.sh&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Miniconda3 官方网站&lt;/a&gt; 下载 Miniconda3_py39_23.5.2 。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wget https://repo.anaconda.com/miniconda/Miniconda3-py39_23.5.2-0-Linux-x86_64.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;执行 Miniconda3-py39_23.5.2-0-Linux-x86_64.sh ，按照提示安装 Miniconda3。（安装在 &lt;code&gt;$HOME/software/miniconda3/23.5.2&lt;/code&gt; 目录下）&lt;/p&gt;
&lt;p&gt;然后，设置 Miniconda3 环境变量。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt;/software/miniconda3/23.5.2/bin:&lt;span class=&#34;nv&#34;&gt;$PATH&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;2-安装-boost&#34;&gt;2. 安装 Boost&lt;/h2&gt;
&lt;p&gt;从 &lt;a class=&#34;link&#34; href=&#34;https://boostorg.jfrog.io/artifactory/main/release/1.77.0/source/boost_1_77_0.tar.gz&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Boost 官方网站&lt;/a&gt; 下载 Boost。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wget https://boostorg.jfrog.io/artifactory/main/release/1.77.0/source/boost_1_77_0.tar.gz
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;tar -zxvf boost_1_77_0.tar.gz
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; boost_1_77_0
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;在 Boost 根目录下执行以下命令安装 Boost：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;module load gcc/8.4.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;./bootstrap.sh --prefix&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt;/software/boost/1.77.0-gcc-8.4.0 &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;CC&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;gcc &lt;span class=&#34;nv&#34;&gt;CXX&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;g++ &lt;span class=&#34;nv&#34;&gt;FC&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;gfortran &lt;span class=&#34;nv&#34;&gt;CFLAGS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;-O3&amp;#39;&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;CXXFLAGS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;-O3&amp;#39;&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;FCFLAGS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;-O3&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;配置环境变量：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;BOOST_ROOT&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt;/software/boost/1.77.0-gcc-8.4.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;LD_LIBRARY_PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$BOOST_ROOT&lt;/span&gt;/lib:&lt;span class=&#34;nv&#34;&gt;$LD_LIBRARY_PATH&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;LIBRARY_PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$BOOST_ROOT&lt;/span&gt;/lib:&lt;span class=&#34;nv&#34;&gt;$LIBRARY_PATH&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;CMAKE_PREFIX_PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$BOOST_ROOT&lt;/span&gt;/lib/cmake:&lt;span class=&#34;nv&#34;&gt;$CMAKE_PREFIX_PATH&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;CPATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$BOOST_ROOT&lt;/span&gt;/include:&lt;span class=&#34;nv&#34;&gt;$CPATH&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;LD_RUN_PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$BOOST_ROOT&lt;/span&gt;/lib:&lt;span class=&#34;nv&#34;&gt;$LD_RUN_PATH&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;3-安装-gnu-scientific-library&#34;&gt;3. 安装 GNU Scientific Library&lt;/h2&gt;
&lt;p&gt;从 &lt;a class=&#34;link&#34; href=&#34;https://mirror.ibcp.fr/pub/gnu/gsl/gsl-latest.tar.gzz&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GNU Scientific Library 镜像站&lt;/a&gt; 下载 GSL。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wget https://mirror.ibcp.fr/pub/gnu/gsl/gsl-latest.tar.gz
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;tar -zxvf gsl-latest.tar.gz
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;在 GSL 根目录执行以下命令安装 GSL：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;module load gcc/8.4.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;./configure --prefix&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt;/software/gsl/2.7.1-gcc-8.4.0 &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;CC&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;gcc &lt;span class=&#34;nv&#34;&gt;CXX&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;g++ &lt;span class=&#34;nv&#34;&gt;FC&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;gfortran &lt;span class=&#34;nv&#34;&gt;CFLAGS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;-O3&amp;#39;&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;CXXFLAGS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;-O3&amp;#39;&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;FCFLAGS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;-O3&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;make install
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;配置环境变量：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;GSL_ROOT&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt;/software/gsl/2.7.1-gcc-8.4.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;LD_LIBRARY_PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$GSL_ROOT&lt;/span&gt;/lib:&lt;span class=&#34;nv&#34;&gt;$LD_LIBRARY_PATH&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$GSL_ROOT&lt;/span&gt;/bin:&lt;span class=&#34;nv&#34;&gt;$PATH&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;CPATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$GSL_ROOT&lt;/span&gt;/include:&lt;span class=&#34;nv&#34;&gt;$CPATH&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;LIBRARY_PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$GSL_ROOT&lt;/span&gt;/lib:&lt;span class=&#34;nv&#34;&gt;$LIBRARY_PATH&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;LD_RUN_PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$GSL_ROOT&lt;/span&gt;/lib:&lt;span class=&#34;nv&#34;&gt;$LD_RUN_PATH&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;4-安装-nest&#34;&gt;4. 安装 NEST&lt;/h2&gt;
&lt;p&gt;使用 Miniconda3 创建一个虚拟环境。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt; activate
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda create -n nest &lt;span class=&#34;nv&#34;&gt;python&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;3.9
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;conda activate nest
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;使用 pip 安装 numpy, scipy, cython==0.29.36&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install numpy scipy &lt;span class=&#34;nv&#34;&gt;cython&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;0.29.36
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;从 &lt;a class=&#34;link&#34; href=&#34;https://github.com/nest/nest-simulator/archive/refs/tags/v3.4.tar.gz&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;NEST github仓库&lt;/a&gt; 下载 NEST 3.4。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wget https://github.com/nest/nest-simulator/archive/refs/tags/v3.4.tar.gz
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;tar -zxvf v3.4.tar.gz
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;在 nest-simulator-3.4 目录下执行:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;module load gcc/8.4.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;module load mvaapich2/2.3.7-gcc-8.4.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cmake -DCMAKE_C_COMPILER&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;mpicc &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      -DCMAKE_CXX_COMPILER&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;mpicxx &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      -Dwith-mpi&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;which mpiexec&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      -DCMAKE_C_FLAGS&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;-O3 -fPIC&amp;#39;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      -DCMAKE_CXX_FLAGS&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;-O3&amp;#39;&lt;/span&gt; &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      -Dwith-boost&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt;/software/boost/1.77.0-gcc-8.4.0 &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      -DGSL_INCLUDE_DIR&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt;/software/gsl/2.7.1-gcc-8.4.0/include &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      -DGSL_LIBRARY&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt;/software/gsl/2.7.1-gcc-8.4.0/lib/libgsl.a &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      -DGSL_CBLAS_LIBRARY&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt;/software/gsl/2.7.1-gcc-8.4.0/lib/libgslcblas.a &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;      -DCMAKE_INSTALL_PREFIX:PATH&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt;/software/nest-simulator/3.4-gcc-8.4.0 .
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;配置环境变量：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;NEST_ROOT&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt;/software/nest-simulator/3.4-gcc-8.4.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;LIBRARY_PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$NEST_ROOT&lt;/span&gt;/lib:&lt;span class=&#34;nv&#34;&gt;$LIBRARY_PATH&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;LD_LIBRARY_PATH&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$NEST_ROOT&lt;/span&gt;/lib:&lt;span class=&#34;nv&#34;&gt;$LD_LIBRARY_PATH&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;5-运行-hpc_benchmark-测试&#34;&gt;5. 运行 hpc_benchmark 测试&lt;/h2&gt;
&lt;p&gt;运行 NEST 前需要配置nest环境：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;$HOME&lt;/span&gt;/software/nest-simulator/3.4-gcc-8.4.0/bin/nest_vars.sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;接着找到 &lt;code&gt;hpc_benchmark.py&lt;/code&gt; 目录，该文件位于 &lt;code&gt;$HOME/software/nest-simulator/3.4-gcc-8.4.0/share/doc/nest/examples/hpc_benchmark.py&lt;/code&gt;。修改其中的 params 以并行运行更大的模型。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;修改 nvp 为所需 MPI 进程数 × 每进程线程数，如 2 MPI进程 × 14 线程 = 28&lt;/li&gt;
&lt;li&gt;设置合适的 scale ，如 10 。更大的需要更多 nvp 。&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;params&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s1&#34;&gt;&amp;#39;nvp&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;28&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;               &lt;span class=&#34;c1&#34;&gt;# total number of virtual processes&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s1&#34;&gt;&amp;#39;scale&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;10.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;            &lt;span class=&#34;c1&#34;&gt;# scaling factor of the network size&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# others...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;在 &lt;code&gt;hpc_benchmark.py&lt;/code&gt; 目录下执行：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;OMP_NUM_THREADS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;14&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;mpiexec -N &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; -n &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; -p &amp;lt;partition_name&amp;gt; --export&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;all python3 hpc_benchmark.py
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;其中 -N 指定节点数，-n 指定 MPI 进程数，-p 指定分区名，如 &lt;code&gt;compute&lt;/code&gt;，&amp;ndash;export=all 用于将环境变量导出到 MPI 进程中。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;本文介绍了在高性能计算机上安装 NEST-3.4 的方法。&lt;/p&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://nest-simulator.readthedocs.io/en/latest/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;NEST 官方文档&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>CUDA基础：内存访问模式</title>
        <link>https://cuterwrite.top/p/cuda-base-memory-access-mode/</link>
        <pubDate>Mon, 04 Sep 2023 00:55:55 +0000</pubDate>
        
        <guid>https://cuterwrite.top/p/cuda-base-memory-access-mode/</guid>
        <description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/14ce26d6f495200cea2cfa76fefadf88eaab94e5.jpg@1256w_754h_!web-article-pic-2023-09-04.webp" alt="Featured image of post CUDA基础：内存访问模式" /&gt;&lt;h1 id=&#34;cuda基础内存访问模式&#34;&gt;CUDA基础：内存访问模式&lt;/h1&gt;
&lt;p&gt;大多数设备端数据访问都是从全局内存开始的，并且多数 GPU 应用程序容易受内存带宽的限制。因此，最大限度地利用全局内存带宽是调控核函数性能的基本。如果不能正确地调控全局内存的使用，其他优化方案很可能也收效甚微。&lt;/p&gt;
&lt;p&gt;为了在读写数据时达到最佳的性能，内存访问操作必须满足一定的条件。CUDA 执行模型的显著特征之一就是指令必须以线程束为单位进行发布和执行。存储操作也是同样。在执行内存指令时，线程束中的每个线程都提供了一个正在加载或存储的内存地址。在线程束的 32 个线程中，每个线程都提出了一个包含请求地址的单一内存访问请求，它并由一个或多个设备内存传输提供服务。根据线程束中内存地址的分布，内存访问可以被分成不同的模式。&lt;/p&gt;
&lt;h2 id=&#34;一对齐与合并访问&#34;&gt;一、对齐与合并访问&lt;/h2&gt;
&lt;p&gt;全局内存通过缓存实现加载和存储的过程如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230904151729-2023-09-04.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230904151729-2023-09-04&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;全局内存是一个逻辑内存空间，用户可以通过核函数访问它。所有应用程序数据最初存在于 DRAM 上，即物理设备内存中。核函数的内存请求通常是在 DRAM 设备和片上内存间以 128 字节或 32 字节内存事务来实现。&lt;/p&gt;
&lt;p&gt;所有对全局内存的访问都会通过二级缓存，也有许多访问会通过一级缓存，这取决于访问类型和 GPU 架构。如果这两级缓存都被用到，那么内存访问是由一个 128 字节的内存事务实现的。如果只使用二级缓存，那么这个内存访问是由一个 32 字节的内存事务来实现的。对全局内存缓存其架构，如果允许使用一级缓存，那么可以在编译时选择启用或禁用一级缓存。&lt;/p&gt;
&lt;p&gt;一行一级缓存是 128 字节，它映射到设备内存中一个 128 字节 的对齐段。如果线程束中的每个线程请求一个 4 字节的值，那么每次请求就会获取 128 字节的数据，这恰好与缓存行和设备内存段的大小相契合。&lt;/p&gt;
&lt;p&gt;因此在优化应用程序时，需要注意设备内存访问的两个特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对齐内存访问&lt;/li&gt;
&lt;li&gt;合并内存访问&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们把一次内存请求：也就是从核函数发起请求，到硬件响应返回数据这个过程称为一个内存事务（加载和存储都行）。&lt;/p&gt;
&lt;p&gt;当一个内存事务的首个访问地址是缓存粒度（32或128字节）的偶数倍的时候：比如二级缓存32字节的偶数倍 64，128 字节的偶数倍 256 的时候，这个时候被称为对齐内存访问，非对齐访问就是除上述的其他情况，&lt;strong&gt;非对齐的内存访问会造成带宽浪费&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;当一个线程束内的线程访问的内存都在一个内存块里的时候，就会出现合并访问。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;对齐合并访问的状态是理想化的，也是最高速的访问方式&lt;/strong&gt;，当线程束内的所有线程访问的数据在一个内存块，并且数据是从内存块的首地址开始被需要的，那么对齐合并访问出现了。为了最大化全局内存访问的理想状态，尽量将线程束访问内存组织成对齐合并的方式，这样的效率是最高的。下面看一个例子。&lt;/p&gt;
&lt;p&gt;一个线程束加载数据，使用一级缓存，并且这个事务所请求的所有数据在一个 128 字节的对齐的地址段上，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230904152703-2023-09-04.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230904152703-2023-09-04&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;上面蓝色表示全局内存，下面橙色是线程束要的数据，绿色就是对齐的地址段。&lt;/p&gt;
&lt;p&gt;而如果一个事务加载的数据分布在不一个对齐的地址段上，就会有以下两种情况：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;连续的，但是不在一个对齐的段上，比如，请求访问的数据分布在内存地址 1~128 ，那么 0~127 和 128~255 这两段数据要传递两次到 SM 。&lt;/li&gt;
&lt;li&gt;不连续的，也不在一个对齐的段上，比如，请求访问的数据分布在内存地址 0~63 和 128~191 上，明显这也需要两次加载。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230904152901-2023-09-04.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230904152901-2023-09-04&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;上图就是典型的一个线程束，数据分散开了，thread 0 的请求在 128 之前，后面还有请求在 256 之后，所以需要三个内存事务，而利用率，也就是从主存取回来的数据被使用到的比例，只有 $\frac{128}{128 \times 3}$ 的比例。这个比例低会造成带宽的浪费，最极端的表现，就是如果每个线程的请求都在不同的段，也就是一个 128 字节的事务只有 1 个字节是有用的，那么利用率只有 $\frac{1}{128}$ 。&lt;/p&gt;
&lt;p&gt;这里总结一下内存事务的优化关键：&lt;strong&gt;用最少的事务次数满足最多的内存请求&lt;/strong&gt;。事务数量和吞吐量的需求随设备的计算能力变化。&lt;/p&gt;
&lt;h2 id=&#34;二全局内存读取&#34;&gt;二、全局内存读取&lt;/h2&gt;
&lt;p&gt;在 SM 中，数据通过以下 3 种缓存 / 缓冲路径进行传输，具体使用何种方式取决于引用了哪种类型的设备内存：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一级和二级缓存&lt;/li&gt;
&lt;li&gt;常量缓存&lt;/li&gt;
&lt;li&gt;只读缓存&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一 / 二级缓存是默认路径。想要通过其它两种路径传输数据需要&lt;strong&gt;应用程序显式说明&lt;/strong&gt;，但想要提升性能还要取决于使用地访问模式。全局内存加载操作是否会通过一级缓存取决于两个因素：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;设备的计算能力：比较老的设备可能没有一级缓存&lt;/li&gt;
&lt;li&gt;编译器选项&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在 Fermi GPU 和 Kepler K40 及以后的 GPU （计算能力为 3.5 及以上）中，可以通过编译器标志启用或禁用全局内存负载的一级缓存。默认情况下，在 Fermi 设备上对于全局内存加载可以使用一级缓存，在 K40 及以上 GPU 中禁用。以下标志通知编译器禁用一级缓存：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;-Xptxas -dlcm=cg
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;如果一级缓存被禁用，所有对全局内存的加载请求将直接进入到二级缓存；如果二级缓存缺失，则由 DRAM 完成请求。每一次内存事务可由一个、两个或四个部分执行，每个部分有 32 个字节。一级缓存也可以使用下列标识符直接启用:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;-Xptxas -dlcm=ca
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;设置这个标志后，全局内存加载请求首先尝试通过一级缓存。如果一级缓存缺失，该请求转向二级缓存。如果二级缓存缺失，则请求由 DRAM 完成。在这种模式下，一个内存加载请求由一个 128 字节的设备内存事务实现。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230904164822-2023-09-04.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230904164822-2023-09-04&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;在 Kepler K10、K20 和 K20X GPU 中一级缓存不用来缓存全局内存加载。一级缓存专门用于&lt;strong&gt;缓存寄存器溢出到本地内存中的数据&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;内存加载可以分为两类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;缓存加载&lt;/li&gt;
&lt;li&gt;没有缓存的加载&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;内存访问有以下特点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;是否使用缓存：一级缓存是否介入加载过程&lt;/li&gt;
&lt;li&gt;对齐与非对齐的：如果访问的第一个地址是 32 的倍数&lt;/li&gt;
&lt;li&gt;合并与非合并，访问连续数据块则是合并的&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;1-缓存加载&#34;&gt;1. 缓存加载&lt;/h3&gt;
&lt;p&gt;下面是使用一级缓存的加载过程&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对齐合并的访问，总线利用率 $100\%$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230904165226-2023-09-04.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230904165226-2023-09-04&#34;
	
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;对齐的，但是不是连续的，每个线程访问的数据都在一个块内，但是位置是交叉的，总线利用率 $100\%$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230904165245-2023-09-04.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230904165245-2023-09-04&#34;
	
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;连续非对齐的，线程束请求一个连续的非对齐的，32 个 4 字节数据，那么会出现，数据横跨两个块，但是没有对齐，当启用一级缓存的时候，就要两个 128 字节的事务来完成，总线利用率为 $50\%$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230904165306-2023-09-04.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230904165306-2023-09-04&#34;
	
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;线程束所有线程请求同一个地址，那么肯定落在一个缓存行范围内，那么如果按照请求的是 4 字节数据来说，总线利用率是 $\frac{4}{128}=3.125\% $&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230904165516-2023-09-04.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230904165516-2023-09-04&#34;
	
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;比较坏的情况，前面提到过最坏的，就是每个线程束内的线程请求的都是不同的缓存行内，这里比较坏的情况就是，所有数据分布在 $N$ 个缓存行，其中 $1\leq N \leq 32$ ，那么请求 32 个 4 字节的数据，就需要 $N$ 个事务来完成，总线利用率也是 $\frac{1}{N}$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230904165524-2023-09-04.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230904165524-2023-09-04&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;CPU 和 GPU 的一级缓存有显著的差异， GPU 的一级缓存可以通过编译选项等控制，CPU 不可以，而且 CPU 的一级缓存是的替换算法是有使用频率和时间局部性的， GPU 则没有。&lt;/p&gt;
&lt;h3 id=&#34;2-没有缓存的加载&#34;&gt;2. 没有缓存的加载&lt;/h3&gt;
&lt;p&gt;没有缓存的加载是指的没有通过一级缓存，二级缓存则是不得不经过的。&lt;/p&gt;
&lt;p&gt;当不使用一级缓存的时候，&lt;strong&gt;内存事务的粒度变为 32 字节&lt;/strong&gt;，更细粒度的加载可以为非对齐或非合并的内存访问带来更好的总线利用率。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对齐合并访问 128 字节，不用说，还是最理想的情况，使用 4 个段，总线利用率 $100\%$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230904170430-2023-09-04.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230904170430-2023-09-04&#34;
	
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;对齐不连续访问 128 字节，都在四个段内，且互不相同，这样的总线利用率也是 $100\%$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230904170454-2023-09-04.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230904170454-2023-09-04&#34;
	
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;连续不对齐，一个段 32 字节，所以，一个连续的 128 字节的请求，即使不对齐，最多也不会超过五个段，总线利用率至少为 $\frac{4}{5}=80\%$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230904170542-2023-09-04.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230904170542-2023-09-04&#34;
	
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;所有线程访问一个 4 字节的数据，那么此时的总线利用率是 $\frac{4}{32} = 12.5\%$ ，在这种情况下，非缓存加载性能也是优于缓存加载的性能。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230904170609-2023-09-04.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230904170609-2023-09-04&#34;
	
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;最坏的情况：所有目标数据分散在内存的各个角落，那么需要 $N$ 个内存段，由于请求的 128 个字节最多落在 $N$ 个 32 字节的内存分段内而不是 $N$ 个 128 字节的缓存行内，所以相比于缓存加载，即便是最坏的情况也有所改善。需要注意这里比较的前提是$N$ 不变，然而在实际情况下，当使用大粒度的缓存行时，$N$ 有可能会减少。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230904170847-2023-09-04.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230904170847-2023-09-04&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;3-只读缓存&#34;&gt;3. 只读缓存&lt;/h3&gt;
&lt;p&gt;只读缓存最初是预留给纹理内存加载用的。对计算能力为 3.5 及以上的 GPU 来说，只读缓存也支持使用全局内存加载代替一级缓存。&lt;/p&gt;
&lt;p&gt;只读缓存的加载粒度是 32 个字节。通常，对分散读取来说，这些更细粒度的加载要优于一级缓存。&lt;/p&gt;
&lt;p&gt;有两种方式可以指导内存通过只读缓存进行读取:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用函数 __ldg&lt;/li&gt;
&lt;li&gt;在间接引用的指针上使用修饰符&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;__global__&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;copyKernel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockDim&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;threadIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;__ldg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;然后就能强制使用只读缓存了。&lt;/p&gt;
&lt;p&gt;也可以将常量 restrict 修饰符应用到指针上。这些修饰符帮助 nvcc 编译器识别无别名指针(即专门用来访问特定数组的指针)。nvcc将自动通过只读缓存指导无别名指针的加载。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;__global__&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;copyKernel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;__restrict__&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;__restrict__&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockDim&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;threadIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;out&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;三全局内存写入&#34;&gt;三、全局内存写入&lt;/h2&gt;
&lt;p&gt;内存的存储操作相对简单。一级缓存不能用在 Fermi 或 Kepler GPU 上进行存储操作，在发送到设备内存之间存储操作&lt;strong&gt;只通过二级缓存&lt;/strong&gt;。存储操作在 &lt;strong&gt;32 个字节段&lt;/strong&gt;的粒度上被执行。内存事务可以同时被分为一段、两段或四段。例如，如果两个地址同属于一个 128 字节区域，但是不属于一个对齐的 64 字节区域，则会执行一个四段事务（也就是说，执行一个四段事务比执行两个一段事务效果更好）。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对齐的，访问一个连续的 128 字节范围。存储操作使用一个四段事务完成：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230904172018-2023-09-04.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230904172018-2023-09-04&#34;
	
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;分散在一个 192 字节的范围内，不连续，使用 3 个一段事务完成：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230904172036-2023-09-04.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230904172036-2023-09-04&#34;
	
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;对齐的，在一个 64 字节的范围内，使用一个两段事务完成：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230904172052-2023-09-04.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230904172052-2023-09-04&#34;
	
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;非对齐写入示例与读取情况类似，且更简单，因为始终不经过一级缓存，这里就略过了。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;四结构体数组与数组结构体&#34;&gt;四、结构体数组与数组结构体&lt;/h2&gt;
&lt;p&gt;数组结构体（AoS）和结构体数组（SoA）是C语言中常见的两种数组组织方式。当存储结构化数据集时，它们代表了可以采用的两种强大的数据组织方式（结构体和数组）。&lt;/p&gt;
&lt;p&gt;下面是存储成对的浮点数据数据集的例子。首先，考虑这些成对数据元素集如何使用 AoS 方法进行存储。如下定义一个结构体，命名为 innerStruct ：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;innerStruct&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;};&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;然后，按照下面的方法定义这些结构体数组。这是利用 AoS 方式来组织数据的。它存储的是空间上相邻的数据，这在 CPU 上会有良好的缓存局部性。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;innerStruct&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;myAoS&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;接下来，考虑使用 SoA 方法来存储数据：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;innerArray&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;};&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这里，在原结构体中每个字段的所有值都被分到各自的数组中。这不仅能将相邻数据点紧密存储起来，也能将跨数组的独立数据点存储起来。可以使用如下结构体定义一个变量：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;innerArray&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mySoA&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;下图说明了 AoS 和 SoA 方法的内存布局。用 AoS 模式在 GPU 上存储示例数据并执行一个只有 $x$ 字段的应用程序，将导致 $50\%$ 的带宽损失，因为 $y$ 值在每 32 个字节段或 128 个字节缓存行上隐式地被加载。 AoS格式也在不需要的 $y$ 值上浪费了二级缓存空间。&lt;/p&gt;
&lt;p&gt;用 SoA 模式存储数据充分利用了 GPU 的内存带宽。由于没有相同字段元素的交叉存取， GPU 上的 SoA 布局提供了合并内存访问，并且可以对全局内存实现更高效的利用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230904173436-2023-09-04.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230904173436-2023-09-04&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;当 32 个线程同时访问的时候， SoA 的访问就是连续的，而 AoS 则是不连续的。&lt;/p&gt;
&lt;p&gt;对比 AoS 和 SoA 的内存布局，我们能得到下面结论：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;并行编程范式，尤其是 SIMD（单指令多数据）对 SoA 更友好。 CUDA 中普遍倾向于 SoA 因为这种内存访问可以有效地合并。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;五性能调整&#34;&gt;五、性能调整&lt;/h2&gt;
&lt;p&gt;优化设备内存带宽利用率有两个目标：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对齐及合并内存访问，以减少带宽的浪费&lt;/li&gt;
&lt;li&gt;足够的并发内存操作，以隐藏内存延迟&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;实现并发内存访问量最大化是通过以下方式得到的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;增加每个线程中执行独立内存操作的数量&lt;/li&gt;
&lt;li&gt;对核函数启动的执行配置进行试验，已充分体现每个 SM 的并行性&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;按照这个思路对程序进行优化，则有两种方法：展开技术和增大并行性。&lt;/p&gt;
&lt;h3 id=&#34;1-展开技术&#34;&gt;1. 展开技术&lt;/h3&gt;
&lt;p&gt;包含了内存操作的展开循环增加了更独立的内存操作。考虑如下 readOffsetUnroll4 核函数，每个线程都执行 4 个独立的内存操作。因为每个加载过程都是独立的，所以可以调用更多的并发内存访问：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;__global__&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;readOffsetUnroll4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;offset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;unsigned&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockDim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;threadIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;unsigned&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;offset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockDim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockDim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockDim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockDim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockDim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockDim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockDim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;      &lt;span class=&#34;n&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockDim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;A&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockDim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockDim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;启用一级缓存编译选项：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;nvcc -O3 readSegmentUnroll.cu -o readSegmentUnroll -Xptxas -dlcm&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;ca
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;结果表明，展开技术对性能有非常好的影响，甚至比地址对齐还要好。对于 I/O 密集型的核函数，充分说明内存访问并行有很高的优先级。&lt;/p&gt;
&lt;h3 id=&#34;2-增大并行性&#34;&gt;2. 增大并行性&lt;/h3&gt;
&lt;p&gt;可以通过调整块的大小来实现并行性调整：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;线程块最内层维度的大小对性能起着关键的作用&lt;/li&gt;
&lt;li&gt;在所有其它情况下，线程块的数量越多，一般性能越高。因此，增大并行性仍然是性能优化的一个重要因素。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;p&gt;[1] CUDA C编程权威指南，机械工业出版社，（美）程润伟（John Cheng） 等著&lt;/p&gt;
</description>
        </item>
        <item>
        <title>CUDA基础：内存管理</title>
        <link>https://cuterwrite.top/p/cuda-base-memory-manage/</link>
        <pubDate>Sat, 02 Sep 2023 05:55:55 +0000</pubDate>
        
        <guid>https://cuterwrite.top/p/cuda-base-memory-manage/</guid>
        <description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/fb80f7f3a9a0e016420a324823ef950b9847fb8d.jpg@1256w_2128h_!web-article-pic-2023-09-02.jpg" alt="Featured image of post CUDA基础：内存管理" /&gt;&lt;h1 id=&#34;cuda基础内存管理&#34;&gt;CUDA基础：内存管理&lt;/h1&gt;
&lt;p&gt;CUDA 编程的内存管理与C语言的类似，需要程序员显式地管理主机和设备之间的数据移动。随着CUDA版本的升级，NVIDIA正系统地实现主机和设备内存空间的统一，但对于大多数应用程序来说，仍需要手动移动数据。本文重点在于如何使用CUDA函数来显式地管理内存和数据移动。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分配和释放设备内存&lt;/li&gt;
&lt;li&gt;在主机和设备之间传输数据&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了达到最优性能，CUDA提供了在主机端准备设备内存的函备内存的函数，并且显式地向设备传输数据和从设备中获取数据。&lt;/p&gt;
&lt;h2 id=&#34;一内存分配和释放&#34;&gt;一、内存分配和释放&lt;/h2&gt;
&lt;p&gt;CUDA编程模型假设了一个包含一个主机和一个设备的异构系统，每一个异构系统都有自己独立的内存空间。核函数在设备内存空间中运行，CUDA运行时提供函数以分配和释放设备内存。用户可以在主机上使下列函数分配全局内存：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;cudaError_t&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;cudaMalloc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;devPtr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;size_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这个函数在设备上分配了 count 字节的全局内存，并用 devptr 指针返回该内存的地址。所分配的内存支持任何变量类型，包括整型、浮点类型变量、布尔类型等。如果 cudaMalloc 函数执行失败则返回 cudaErrorMemoryAllocation 。在已分配的全局内存中的值不会被清除。用户需要用从主机上传输的数据来填充所分配的全局内存，或用下列函数将其初始化：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;cudaError_t&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;cudaMemset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;devPtr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;size_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这个函数用存储在变量value中的值来填充从设备内存地址 devPtr 处开始的count字节。&lt;/p&gt;
&lt;p&gt;一旦一个应用程序不再使用已分配的全局内存，那么可以以下代码释放该内存空间：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;cudaError_t&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;cudaFree&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;devPtr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这个函数释放了 devPtr 指向的全局内存，该内存必须在此前使用了一个设备分配函数（如cudaMalloc）来进行分配。否则，它将返回一个错误 cudaErrorInvalidDevicePointer 。如果地址空间已经被释放，那么 cudaFree 也返回一个错误。&lt;/p&gt;
&lt;p&gt;设备内存的分配和释放操作成本较高，所以应用程序应&lt;strong&gt;重利用设备内存&lt;/strong&gt;，以减少对整体性能的影响。&lt;/p&gt;
&lt;h2 id=&#34;二内存传输&#34;&gt;二、内存传输&lt;/h2&gt;
&lt;p&gt;一旦分配好了全局内存，就可以使用下列函数从主机向设备传输数据：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;cudaError_t&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;cudaMemcpy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dst&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;src&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;size_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cudaMemcpyKind&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这个函数从内存位置 src 复制了 count 字节到内存位置 dst 。变量 kind 指定了复制的方向，可以有下列取值：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;cudaMemcpyHostToHost：从主机内存复制到主机内存&lt;/li&gt;
&lt;li&gt;cudaMemcpyHostToDevice：从主机内存复制到设备内存&lt;/li&gt;
&lt;li&gt;cudaMemcpyDeviceToHost：从设备内存复制到主机内存&lt;/li&gt;
&lt;li&gt;cudaMemcpyDeviceToDevice：从设备内存复制到设备内存&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果指针 dst 和 src 与 kind 指定的复制方向不一致，那么 cudaMemcpy 的行为就是未定义行为。这个函数在大多数情况下都是同步的。&lt;/p&gt;
&lt;p&gt;下图为 CPU 内存和 GPU 内存间的连接性能。从图中可以看到 GPU 芯片和板载 GDDR5 GPU 内存之间的理论峰值带宽非常高，对于 Fermi C2050 GPU 来说为 144GB/s 。CPU 和 GPU 之间通过 PCIe Gen2 总线相连，这种连接的理论带宽要低得多，为 8GB/s（ PCIe Gen3 总线最大理论限制值是16GB/s）。这种差距意味着如果管理不当的话，主机和设备间的数据传输会降低应用程序的整体性能。因此，CUDA编程的一个基本原则应是尽可能地减少主机与设备之间的传输。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230902212815-2023-09-02.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230902212815-2023-09-02&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;三固定内存&#34;&gt;三、固定内存&lt;/h2&gt;
&lt;p&gt;分配的主机内存默认是pageable（可分页），它的意思也就是因页面错误导致的操作，该操作按照操作系统的要求将主机虚拟内存上的数据移动到不同的物理位置。虚拟内存给人一种比实际可用内存大得多的假象，就如同一级缓存好像比实际可用的片上内存大得多一样。&lt;/p&gt;
&lt;p&gt;GPU &lt;strong&gt;不能在可分页主机内存上安全地访问数据&lt;/strong&gt;，因为当主机操作系统在物理位置上移动该数据时，它无法控制。当从可分页主机内存传输数据到设备内存时，CUDA驱动程序首先分配&lt;strong&gt;临时页面锁定的或固定的&lt;/strong&gt;主机内存，将主机源数据复制到固定内存中，然后从固定内存传输数据给设备内存，如下图左边部分所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230903003123-2023-09-03.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230903003123-2023-09-03&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;左边是正常分配内存，传输过程是：锁页-复制到固定内存-复制到设备&lt;/p&gt;
&lt;p&gt;右边是分配时就是固定内存，直接传输到设备上。&lt;/p&gt;
&lt;p&gt;下面函数用来分配固定内存：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;cudaError_t&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;cudaMallocHost&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;devPtr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;size_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这个函数分配了 count 字节的主机内存，这些内存是页面锁定的并且对设备来说是可访问的。由于固定内存能被设备直接访问，所以它能用比可分页内存高得多的带宽进行读写。然而，分配过多的固定内存可能会降低主机系统的性能，因为它减少了用于存储虚拟内存数据的可分页内存的数量，其中分页内存对主机系统是可用的。&lt;/p&gt;
&lt;p&gt;固定的主机内存释放使用：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;cudaError_t&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;cudaFreeHost&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;devPtr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;总的来说，固定内存的释放和分配成本比可分页内存要高很多，但是传输速度更快，所以对于大规模数据，固定内存效率更高。应该尽量使用流来使内存传输和计算之间同时进行。&lt;/p&gt;
&lt;h2 id=&#34;四零拷贝内存&#34;&gt;四、零拷贝内存&lt;/h2&gt;
&lt;p&gt;通常来说，主机不能直接访问设备变量，同时设备也不能直接访问主机变量。但有一个例外：零拷贝内存。&lt;strong&gt;主机和设备都可以访问零拷贝内存&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;GPU 线程可以直接访问零拷贝内存。在CUDA核函数中使用零拷贝内存有以下几个优势。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当设备内存不足时可利用主机内存&lt;/li&gt;
&lt;li&gt;避免主机和设备间的显式数据传输&lt;/li&gt;
&lt;li&gt;提高PCIe传输率&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当使用零拷贝内存来共享主机和设备间的数据时，用户必须同步主机和设备间的内存访问，同时更改主机和设备的零拷贝内存中的数据将导致不可预知的后果。&lt;/p&gt;
&lt;p&gt;零拷贝内存是固定内存，不可分页，该内存映射到设备地址空间中。用户可以通过下列函数创建零拷贝内存：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;cudaError_t&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;cudaHostAlloc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pHost&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;size_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;unsigned&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;flags&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;最后一个标志参数，可以选择以下值：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;cudaHostAllocDefalt：和cudaMallocHost函数一致&lt;/li&gt;
&lt;li&gt;cudaHostAllocPortable：返回能被所有CUDA上下文使用的固定内存&lt;/li&gt;
&lt;li&gt;cudaHostAllocMapped：产生零拷贝内存，可以实现主机写入和设备读取被映射到设备地址空间中的主机内存&lt;/li&gt;
&lt;li&gt;cudaHostAllocWriteCombined：返回写结合内存，在某些设备上这种内存传输效率更高&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注意，零拷贝内存虽然不需要显式的传递到设备上，但是设备还不能通过 pHost 直接访问对应的内存地址，设备需要访问主机上的零拷贝内存，需要先获得另一个地址，这个地址帮助设备访问到主机对应的内存，方法是：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;cudaError_t&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;cudaHostGetDevicePointer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pDevice&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pHost&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;unsigned&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;flags&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;pDevice 就是设备上访问主机零拷贝内存的指针了，此处 flags 必须设置为 0 。&lt;/p&gt;
&lt;p&gt;在进行频繁的读写操作时，使用零拷贝内存作为设备内存的补充将显著降低性能。因为每一次映射到内存的传输必须经过 PCIe 总线。与全局内存相比，延迟也显著增加。&lt;/p&gt;
&lt;p&gt;注意不要过度使用零拷贝内存。由于其延迟较高，从零拷贝内存中读取设备核函数可能很慢。&lt;/p&gt;
&lt;h2 id=&#34;五统一虚拟寻址&#34;&gt;五、统一虚拟寻址&lt;/h2&gt;
&lt;p&gt;计算能力为 2.0 及以上版本的设备支持一种特殊的寻址方式，称为&lt;strong&gt;统一虚拟寻址（UVA）&lt;/strong&gt;。UVA，在CUDA 4.0中被引入，支持64位Linux系统。有了UVA，主机内存和设备内存可以共享同一个虚拟地址空间，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230903004449-2023-09-03.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230903004449-2023-09-03&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;UVA之前，我们要管理所有的设备和主机内存，尤其是它们的指针，零拷贝内存尤其麻烦。有了UVA，由指针指向的内存空间对应用程序代码来说是透明的。&lt;/p&gt;
&lt;p&gt;通过UVA，由 cudaHostAlloc 分配的固定主机内存具有相同的主机和设备指针。因此，可以将返回的指针直接传递给核函数。&lt;/p&gt;
&lt;p&gt;前面的零拷贝内存，可以知道以下几个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分配映射的固定主机内存&lt;/li&gt;
&lt;li&gt;使用CUDA运行时函数获取映射到固定内存的设备指针&lt;/li&gt;
&lt;li&gt;将设备指针传递给核函数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;有了 UVA ，可以不用上面的那个获得设备上访问零拷贝内存的函数了：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;cudaError_t&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;cudaHostGetDevicePointer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pDevice&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pHost&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;unsigned&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;flags&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;因为 UVA 之后，主机和设备的指针都是一样的，所以可以直接传递给核函数了。&lt;/p&gt;
&lt;h2 id=&#34;六统一内存寻址&#34;&gt;六、统一内存寻址&lt;/h2&gt;
&lt;p&gt;在CUDA 6.0中，引入了&lt;strong&gt;统一内存寻址&lt;/strong&gt;这一新特性，它用于简化 CUDA 编程模型中的内存管理。统一内存中创建了一个托管内存池，内存池中已分配的空间可以用相同的内存地址（即指针）在 CPU 和 GPU 上进行访问。底层系统在统一内存空间中自动在主机和设备之间进行数据传输。这种数据传输对应用程序是透明的，这大大简化了程序代码。&lt;/p&gt;
&lt;p&gt;统一内存寻址依赖于 UVA 的支持，但它们是完全不同的技术。 UVA 为系统中的所有处理器提供了一个单一的虚拟内存地址空间。但是， UVA 不会自动将数据从一个物理位置转移到另一个位置，这是统一内存寻址的一个特有功能。&lt;/p&gt;
&lt;p&gt;统一内存寻址提供了一个&lt;strong&gt;单指针到数据&lt;/strong&gt;模型，在概念上它类似于零拷贝内存。但是零拷贝内存在主机内存中进行分配，因此，由于受到在 PCIe 总线上访问零拷贝内存的影响，核函数的性能将具有较高的延迟。另一方面，统一内存寻址将内存和执行空间分离，因此可以根据需要将数据透明地传输到主机或设备上，以提升局部性和性能。&lt;/p&gt;
&lt;p&gt;托管内存指的是由底层系统自动分配的统一内存，未托管内存就是用户自己分配的内存，这时候对于核函数，可以传递给它两种类型的内存，已托管和未托管内存，可以同时传递。&lt;/p&gt;
&lt;p&gt;托管内存可以是静态的，也可以是动态的，添加 managed 关键字修饰托管内存变量。静态声明的托管内存作用域是文件，这一点可以注意一下。&lt;/p&gt;
&lt;p&gt;托管内存分配方式：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;cudaError_t&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;cudaMallocManaged&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;devPtr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;size_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;unsigned&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;flags&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这个函数分配 size 字节的托管内存，并用 devPtr 返回一个指针。该指针在所有设备和主机上都是有效的。使用托管内存的程序行为与使用未托管内存的程序副本行为在功能上是一致的。但是，使用托管内存的程序可以利用自动数据传输和重复指针消除功能。&lt;/p&gt;
&lt;p&gt;在CUDA 6.0中，设备代码不能调用 cudaMallocManaged 函数。所有的托管内存必须在主机端动态声明或者在全局范围内静态声明。&lt;/p&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;p&gt;[1] CUDA C编程权威指南，机械工业出版社，（美）程润伟（John Cheng） 等著&lt;/p&gt;
</description>
        </item>
        <item>
        <title>CUDA基础：内存模型概述</title>
        <link>https://cuterwrite.top/p/cuda-base-memory-model/</link>
        <pubDate>Fri, 01 Sep 2023 04:00:00 +0000</pubDate>
        
        <guid>https://cuterwrite.top/p/cuda-base-memory-model/</guid>
        <description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/47a9b8a012cf3a3f552c9aba3aeaa93fe669cf70.jpg@1256w_970h_!web-article-pic-2023-09-01.jpg" alt="Featured image of post CUDA基础：内存模型概述" /&gt;&lt;h1 id=&#34;cuda基础内存模型概述&#34;&gt;CUDA基础：内存模型概述&lt;/h1&gt;
&lt;p&gt;内存的访问和管理是所有编程语言的重要部分。在现代加速器中，内存管理对高性能计算有着很大的影响。&lt;/p&gt;
&lt;p&gt;因为多数工作负载被加载和存储数据的速度所限制，所以有大量低延迟、高带宽的内存对性能是十分有利的。然而，大容量、高性能的内存造价高且不容易生产。因此，在现有的硬件存储子系统下，必须依靠&lt;strong&gt;内存模型&lt;/strong&gt;获得最佳的延迟和带宽。CUDA内存模型结合了主机和设备的内存系统，展现了完整的内存层次结构，能显式地控制数据布局以优化性能。&lt;/p&gt;
&lt;h2 id=&#34;一内存层次结构的优点&#34;&gt;一、内存层次结构的优点&lt;/h2&gt;
&lt;p&gt;程序具有局部性特点，包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;时间局部性：如果一个数据被访问，那么它在不久的将来也会被访问。&lt;/li&gt;
&lt;li&gt;空间局部性：如果一个数据被访问，那么它附近的数据也会被访问。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;现代计算机的内存结构主要如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230901232704-2023-09-01.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230901232704-2023-09-01&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;一个内存层次结构由具有不同延迟、带宽和容量的多级内存组成。通常，随着从处理器到内存延迟的增加，内存的容量也在增加。&lt;/p&gt;
&lt;p&gt;CPU 和 GPU 的主存都采用的是 DRAM（动态随机存取存储器），而低延迟内存（如CPU一级缓存）使用的则是SRAM（静态随机存取存储器）。内存层次结构中最大且最慢的级别通常使用磁盘或闪存驱动来实现。在这种内存层次结构中，当数据被处理器频繁使用时，该数据保存在低延迟、低容量的存储器中；而当该数据被存储起来以备后用时，数据就存储在高延迟、大容量的存储器中。这种内存层次结构符合大内存低延迟的设想。&lt;/p&gt;
&lt;p&gt;GPU 和 CPU 的内存设计有相似的准则和模型。但它们的主要区别是，CUDA 编程模型能将内存层次结构更好地呈现给用户，能让我们显式地控制它的行为。&lt;/p&gt;
&lt;h2 id=&#34;二cuda内存模型&#34;&gt;二、CUDA内存模型&lt;/h2&gt;
&lt;p&gt;对于程序员来说，一般有两种类型的存储器：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;可编程的：你需要显式地控制哪些数据存放在可编程内存中&lt;/li&gt;
&lt;li&gt;不可编程的：你不能决定数据的存放位置，程序将自动生成存放位置以获得良好的性能&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;CPU 内存结构中，一级二级缓存都是不可编程（完全不可控制）的存储设备。另一方面，CUDA 内存模型相对于 CPU 来说更为丰富，提出了多种可编程内存的类型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;寄存器&lt;/li&gt;
&lt;li&gt;共享内存&lt;/li&gt;
&lt;li&gt;本地内存&lt;/li&gt;
&lt;li&gt;常量内存&lt;/li&gt;
&lt;li&gt;纹理内存&lt;/li&gt;
&lt;li&gt;全局内存&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下图所示为这些内存空间的层次结构，每种都有不同的作用域、生命周期和缓存行为。一个核函数中的线程都有自己私有的&lt;strong&gt;本地内存&lt;/strong&gt;。一个线程块有自己的&lt;strong&gt;共享内存&lt;/strong&gt;，对同一线程块中所有线程都可见，其内容持续线程块的整个生命周期。所有线程都可以访问&lt;strong&gt;全局内存&lt;/strong&gt;。所有线程都能访问的只读内存空间有：&lt;strong&gt;常量内存空间和纹理内存空间&lt;/strong&gt;。全局内存、常量内存和纹理内存空间有不同的用途。&lt;strong&gt;纹理内存&lt;/strong&gt;为各种数据布局提供了不同的寻址模式和滤波模式。对于一个应用程序来说， &lt;strong&gt;全局内存、常量内存和纹理内存&lt;/strong&gt;中的内容具有相同的生命周期。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230901233955-2023-09-01.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230901233955-2023-09-01&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;1-寄存器&#34;&gt;1. 寄存器&lt;/h3&gt;
&lt;p&gt;寄存器无论是在 CPU 还是在 GPU 都是速度最快的内存空间，但是和 CPU 不同的是 GPU 的寄存器储量要多一些，而且当我们在核函数内不加修饰的声明一个变量，此变量就存储在寄存器中，但是 CPU 运行的程序有些不同，只有当前在计算的变量存储在寄存器中，其余在主存中，使用时传输至寄存器。在核函数声明的数组中，&lt;strong&gt;如果用于引用该数组的索引是常量且能在编译时确定&lt;/strong&gt;，那么该数组也存储在寄存器中。&lt;/p&gt;
&lt;p&gt;寄存器变量对于每个线程来说都是私有的，一个核函数通常使用寄存器来保存需要频繁访问的线程私有变量。寄存器变量与核函数的生命周期相同。一旦核函数执行完毕，就不能对寄存器变量进行访问了。&lt;/p&gt;
&lt;p&gt;寄存器是SM中的稀缺资源，Fermi 架构中每个线程最多 63 个寄存器。Kepler 结构扩展到 255个 寄存器，一个线程如果使用更少的寄存器，那么就会有更多的常驻线程块，SM上并发的线程块越多，效率越高，性能和使用率也就越高。&lt;/p&gt;
&lt;p&gt;那么问题就来了，如果一个线程里面的变量太多，以至于寄存器完全不够呢？这时候寄存器发生溢出，本地内存就会过来帮忙存储多出来的变量，这种情况会对效率产生非常负面的影响，所以，不到万不得已，一定要避免此种情况发生。&lt;/p&gt;
&lt;p&gt;为了避免寄存器溢出，可以在核函数的代码中配置额外的信息来辅助编译器优化，比如：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;__global__&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;__lauch_bounds__&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;maxThreadaPerBlock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;minBlocksPerMultiprocessor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;kernel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(...)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;cm&#34;&gt;/* kernel code */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这里面在核函数定义前加了一个 关键字 &lt;strong&gt;lauch_bounds&lt;/strong&gt; ，然后它后面对应了两个变量：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;maxThreadaPerBlock：线程块内包含的最大线程数，线程块由核函数来启动&lt;/li&gt;
&lt;li&gt;minBlocksPerMultiprocessor：可选参数，每个SM中预期的最小的常驻内存块参数。注意，对于一定的核函数，优化的启动边界会因为不同的结构而不同
也可以在编译选项中加入 &lt;strong&gt;-maxrregcount=32&lt;/strong&gt; 来指定每个线程使用的最大寄存器数。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;2-本地内存&#34;&gt;2. 本地内存&lt;/h3&gt;
&lt;p&gt;核函数中符合存储在寄存器中但不能进入被该核函数分配的寄存器空间中的变量将溢出到本地内存中。编译器可能存放到本地内存中的变量有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在编译时使用未知索引引用的本地数组&lt;/li&gt;
&lt;li&gt;可能会占用大量寄存器空间的较大本地结构体或数组&lt;/li&gt;
&lt;li&gt;任何不满足核函数寄存器限定条件的变量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本地内存实质上是和全局内存一样在同一块存储区域当中的，其访问特点——高延迟，低带宽。对于计算能力 2.0 以上的设备，本地内存存储在每个 SM 的一级缓存，或者设备的二级缓存上。&lt;/p&gt;
&lt;h3 id=&#34;3-共享内存&#34;&gt;3. 共享内存&lt;/h3&gt;
&lt;p&gt;在核函数中使用 &lt;strong&gt;__shared__&lt;/strong&gt; 修饰符修饰的变量存放在共享内存中。&lt;/p&gt;
&lt;p&gt;因为共享内存是片上内存，所以与本地内存或全局内存相比，它具有更高的带宽和更低的延迟。它的使用类似于 CPU 一级缓存，但它是可编程的。&lt;/p&gt;
&lt;p&gt;每一个 SM 都有一定数量的由线程块分配的共享内存。因此，必须非常小心不要过度使用共享内存，否则将在不经意间限制活跃线程束的数量。&lt;/p&gt;
&lt;p&gt;共享内存在核函数的范围内声明，其生命周期伴随着整个线程块。当一个线程块执行结束后，其分配的共享内存将被释放并重新分配给其他线程块。&lt;/p&gt;
&lt;p&gt;共享内存是线程之间相互通信的基本方式。因为共享内存是块内线程可见的，所以就有竞争问题的存在，也可以通过共享内存进行通信，当然，为了避免内存竞争，可以使用同步语句：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;__syncthreads&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;此语句相当于在线程块执行时各个线程的一个障碍点，当块内所有线程都执行到本障碍点的时候才能进行下一步的计算，这样可以设计出避免内存竞争的共享内存使用程序。但是，该语句频繁使用会影响内核执行效率。SM 中的一级缓存和共享内存都使用 64KB 的片上内存，它通过静态划分，但在运行时可以通过如下指令进行动态配置：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;cudaError_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cudaFuncSetCacheConfig&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cudaFuncCache&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cacheConfig&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这个函数在每个核函数的基础上配置了片上内存划分，为 func 指定的核函数设置了配置。支持的缓存配置如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cudaFuncCachePreferNone    // 无参考值，默认设置
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cudaFuncCachePreferShared  // 48k共享内存，16k一级缓存
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cudaFuncCachePreferL1      // 48k一级缓存，16k共享内存
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cudaFuncCachePreferEqual   // 32k一级缓存，32k共享内存
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Fermi 架构支持前三种，后面的设备都支持。&lt;/p&gt;
&lt;h3 id=&#34;4-常量内存&#34;&gt;4. 常量内存&lt;/h3&gt;
&lt;p&gt;常量内存驻留在设备内存中，每个 SM 都有专用的常量内存缓存，常量内存使用 &lt;strong&gt;__constant__&lt;/strong&gt; 修饰符修饰。&lt;/p&gt;
&lt;p&gt;常量变量必须在全局空间内和所有核函数之外进行声明。对于所有计算能力的设备，都只可以声明 64kB 的常量内存，常量内存是静态声明的，并对同一编译单元中的所有核函数可见。&lt;/p&gt;
&lt;p&gt;核函数只能从常量内存中读取数据（只读）。因此，常量内存必须在主机端使用下面的函数来初始化：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;cudaError_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cudaMemcpyToSymbol&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;symbol&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;const&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;src&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;offset&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cudaMemcpyKind&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;kind&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cudaMemcpyHostToDevice&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这个函数将 count 个字节从 src 指向的内存复制到 symbol 指向的内存中，这个变量存放在设备的全局内存或常量内存中。在大多数情况下这个函数是同步的。&lt;/p&gt;
&lt;p&gt;线程束中的所有线程从相同的内存地址中读取数据时，常量内存表现最好。举个例子，数学公式中的系数就是一个很好的使用常量内存的例子，因为一个线程束中所有的线程使用相同的系数来对不同数据进行相同的计算。如果线程束里每个线程都从不同的地址空间读取数据，并且只读一次，那么常量内存中就不是最佳选择，因为每从一个常量内存中读取一次数据，都会广播给线程束里的所有线程。&lt;/p&gt;
&lt;h3 id=&#34;5-纹理内存&#34;&gt;5. 纹理内存&lt;/h3&gt;
&lt;p&gt;纹理内存驻留在设备内存中，并在每个 SM 的只读缓存中缓存。&lt;strong&gt;纹理内存&lt;/strong&gt;是一种通过指定的只读缓存访问的全局内存。只读缓存包括硬件滤波的支持，它可以将浮点插入作为读过程的一部分来执行。纹理内存是对&lt;strong&gt;二维空间局部性&lt;/strong&gt;的优化所以线程束里使用纹理内存访问二维数据的线程可以达到最优性能。对于一些应用程序来说，这是理想的内存，并由于缓存和滤波硬件的支持所以有较好的性能优势。然而对于另一些应用程序来说，与全局内存相比，使用纹理内存更慢。&lt;/p&gt;
&lt;p&gt;总的来说纹理内存设计目的应该是为了 GPU 本职工作显示设计的，但是对于某些特定的程序可能效果更好，比如需要滤波的程序，可以直接通过硬件完成。&lt;/p&gt;
&lt;h3 id=&#34;6-全局内存&#34;&gt;6. 全局内存&lt;/h3&gt;
&lt;p&gt;全局内存是 GPU 中最大、&lt;strong&gt;延迟最高&lt;/strong&gt;并且最常使用的内存。 global 指的是其作用域和生命周期。它的声明可以在任何 SM 设备上被访问到，并且贯穿应用程序的整个生命周期。一个全局内存变量可以被静态声明或动态声明。可以使用 &lt;strong&gt;__device__&lt;/strong&gt; 修饰符在设备代码中静态地声明一个变量。&lt;/p&gt;
&lt;p&gt;默认通过 cudaMalloc 声明的所有在 GPU 上访问的内存都是全局内存，也就是没有对内存进行任何优化。因为全局内存的性质，当有多个核函数同时执行的时候，如果使用到了同一全局变量，应注意内存竞争。&lt;/p&gt;
&lt;p&gt;全局内存访问是对齐，也就是一次要读取指定大小 $(32，64，128)$ 整数倍字节的内存，所以当线程束执行内存加载/存储时，需要满足的传输数量通常取决与以下两个因素：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;跨线程的内存地址分布&lt;/li&gt;
&lt;li&gt;内存事务的对齐方式&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在一般情况下，用来满足内存请求的事务越多，未使用的字节被传输回的可能性就越高，这就造成了数据吞吐率的降低。&lt;/p&gt;
&lt;p&gt;对于一个给定的线程束内存请求，事务数量和数据吞吐率是由设备的计算能力来确定的。对于计算能力为1.0和1.1的设备，全局内存访问的要求是非常严格的。对于计算能力高于 1.1 的设备，由于内存事务被缓存，所以要求较为宽松。缓存的内存事务利用数据局部性来提高数据吞吐率。&lt;/p&gt;
&lt;h3 id=&#34;7-gpu缓存&#34;&gt;7. GPU缓存&lt;/h3&gt;
&lt;p&gt;与 CPU 缓存类似， GPU 缓存是不可编程的内存。在GPU上有 4 种缓存：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一级缓存&lt;/li&gt;
&lt;li&gt;二级缓存&lt;/li&gt;
&lt;li&gt;只读常量缓存&lt;/li&gt;
&lt;li&gt;只读纹理缓存&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;每个 SM 都有一个一级缓存，所有的 SM 共享一个二级缓存。一级和二级缓存都被用来在存储本地内存和全局内存中的数据，也包括寄存器溢出的部分。对 Fermi GPU 和 Kepler K40 或其后发布的 GPU 来说，CUDA 允许我们配置读操作的数据是使用一级和二级缓存，还是只使用二级缓存。&lt;/p&gt;
&lt;p&gt;在 CPU 上，内存的加载和存储都可以被缓存。但是，在 GPU 上只有内存加载操作可以被缓存，内存存储操作不能被缓存。&lt;/p&gt;
&lt;p&gt;每个 SM 也有一个只读常量缓存和只读纹理缓存，它们用于在设备内存中提高来自于各自内存空间内的读取性能。&lt;/p&gt;
&lt;h3 id=&#34;8-cuda变量声明总结&#34;&gt;8. CUDA变量声明总结&lt;/h3&gt;
&lt;p&gt;用表格进行总结：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;修饰符&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;变量名&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;存储器&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;作用域&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;生命周期&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;无&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;float var&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;寄存器&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;线程&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;线程&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;无&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;float var[100]&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;本地&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;线程&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;线程&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;__shared__&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;float var*&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;共享内存&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;块&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;块&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;__device__&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;float var*&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;全局内存&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;全局&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;应用程序&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;__constant__&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;float var*&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;常量内存&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;全局&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;应用程序&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;设备存储器的重要特征：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;存储器&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;片上/片外&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;缓存&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;存取&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;范围&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;生命周期&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;寄存器&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;片上&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;n/a&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;R/W&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;一个线程&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;线程&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;本地&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;片外&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.0以上有&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;R/W&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;一个线程&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;线程&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;共享&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;片上&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;n/a&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;R/W&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;块内所有线程&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;块&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;全局&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;片外&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.0以上有&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;R/W&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;所有线程+主机&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;主机配置&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;常量&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;片外&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;有&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;R&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;所有线程+主机&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;主机配置&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;纹理&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;片外&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;有&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;R&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;所有线程+主机&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;主机配置&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;9-静态全局内存&#34;&gt;9. 静态全局内存&lt;/h3&gt;
&lt;p&gt;CPU 内存有动态分配和静态分配两种类型，从内存位置来说，动态分配在堆上进行，静态分配在站上进行，在代码上的表现是一个需要 new，malloc 等类似的函数动态分配空间，并用 delete 和 free 来释放。在CUDA中也有类似的动态静态之分，需要 cudaMalloc 的就是动态分配，静态分配与动态分配相同是，也需要显式的将内存copy到设备端。下面代码是一个静态分配的例子：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;lt;cuda_runtime.h&amp;gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;#34;dbg.h&amp;#34;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;__device__&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;devData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;__global__&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;checkGlobalVariable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Device: the value of devData is %f&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;devData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;devData&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;2.0f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;argc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;char&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;argv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;3.14f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;CHECK&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cudaMemcpyToSymbol&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;devData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;sizeof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Host: copied %f to the global variable&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;checkGlobalVariable&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;CHECK&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cudaMemcpyFromSymbol&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;devData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;sizeof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Host: the value changed by the kernel to %f&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;CHECK&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cudaDeviceReset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;());&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;EXIT_SUCCESS&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;运行结果为：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Host: copied 3.140000 to the global variable
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Device: the value of devData is 3.140000
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Host: the value changed by the kernel to 5.140000
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;唯一要注意的就是这一句：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;cudaMemcpyToSymbol&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;devData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;sizeof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;设备上的变量定义和主机变量定义的不同，设备变量在代码中定义的时候其实就是一个指针，这个指针指向何处，主机端是不知道的，指向的内容也不知道，想知道指向的内容，唯一的办法还是通过显式的办法即 cudaMemcpyToSymbol 传输过来。&lt;/p&gt;
&lt;p&gt;此外还需要注意的是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在主机端，devData 只是一个标识符，不是设备全局内存的变量地址&lt;/li&gt;
&lt;li&gt;在核函数中，devData 就是一个全局内存中的变量。主机代码不能直接访问设备变量，设备也不能访问主机变量，这就是 CUDA 编程与 CPU 多核最大的不同之处&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;一方面，是无法使用 cudaMemcpy 来给静态变量赋值的，除非：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dptr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;cudaGetSymbolAddress&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dptr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;devData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;cudaMemcpy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dptr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;sizeof&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cudaMemcpyHostToDevice&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;另一方面，主机端不可以对设备变量进行取地址操作，该操作是非法的。想要得到 devData 的地址可以用下面方法：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dptr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;NULL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;cudaGetSymbolAddress&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dptr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;devData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;当然也有一个例外，可以直接从主机引用GPU内存——CUDA固定内存。&lt;/p&gt;
&lt;p&gt;CUDA 运行时 API 能访问主机和设备变量，但这取决于你给正确的函数是否提供了正确的参数，使用运行时 API ，如果参数填错，尤其是主机和设备上的指针，结果是无法预测的。&lt;/p&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;p&gt;[1] CUDA C编程权威指南，机械工业出版社，（美）程润伟（John Cheng） 等著&lt;/p&gt;
</description>
        </item>
        <item>
        <title>CUDA基础：线程束执行的本质</title>
        <link>https://cuterwrite.top/p/cuda-base-warp/</link>
        <pubDate>Thu, 31 Aug 2023 00:00:00 +0000</pubDate>
        
        <guid>https://cuterwrite.top/p/cuda-base-warp/</guid>
        <description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/20230831184001-2023-08-31.png" alt="Featured image of post CUDA基础：线程束执行的本质" /&gt;&lt;h1 id=&#34;cuda基础线程束执行的本质&#34;&gt;CUDA基础：线程束执行的本质&lt;/h1&gt;
&lt;h2 id=&#34;1-线程束和线程块&#34;&gt;1. 线程束和线程块&lt;/h2&gt;
&lt;p&gt;线程束是 SM 中基本的执行单元，当一个线程块的网格被启动后，网格中的线程块分布在 SM 中。一旦线程块被调度在一个 SM 上，线程块中的线程会被进一步划分为线程束。一个线程束由 32 个连续的线程组成（目前的 GPU 都是 32 个线程，但不保证未来是 32 个），在一个线程束中，所有的线程按照单指令多线程（SIMT）方式执行；也就是说，所有线程都执行相同的指令，每个线程在私有数据上进行操作。下图展示了线程块的逻辑视图和硬件视图之间的关系：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230831184443-2023-08-31.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230831184443-2023-08-31&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;然而，从硬件的角度来看，所有的线程都被组织成了一维的，线程块可以被配置为一维、二维、三维的。在一个块中，每个线程都有唯一的 ID 。对于一维的线程块，唯一的线程 ID 被存储在 CUDA 的内置变量 threadIdx.x 中，并且，threadIdx.x 中拥有连续值得线程被分组到线程束中。例如，一个有 128 个线程的一维线程块被组织到 4 个线程束里，如下所示：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;warp0: thread 0, .........., thread 31
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;warp1: thread 32, ........., thread 63
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;warp2: thread 64, ........., thread 95
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;warp3: thread 96, ........., thread 127
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;线程块是一个逻辑产物，因为在计算机里，内存总是一维线性存在的，所以执行起来也是一维的访问线程块中的线程，但是我们在写程序的时候却可以以二维三维的方式进行，原因是方便我们写程序，比如处理图像或者三维的数据，三维块就会变得很直接，很方便。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在块中，每个线程有唯一的编号（可能是个三维的编号），threadIdx&lt;/li&gt;
&lt;li&gt;网格中，每个线程块也有唯一的编号(可能是个三维的编号)，blockIdx&lt;/li&gt;
&lt;li&gt;那么每个线程就有在网格中的唯一编号。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用 $x$ 维度作为最内层的维度， $y$ 维度作为第二个维度， $z$ 维度作为最外层的维度，则二维或三维线程块的逻辑布局可以转化为一维物理布局。例如，对于一个给定的二维线程块，在一个块中每个线程的独特标识符都可以用内置变量 threadIdx 和 blockDim 来计算：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;tid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;threadIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;threadIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockDim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;对于一个三维线程块，可以用下面的方式计算：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;tid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;threadIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;threadIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockDim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;threadIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;z&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockDim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockDim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;在C语言中，假设三维数组 t 保存了所有的线程，那么 (threadIdx.x, threadIdx.y, threadIdx.z) 就相当于：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;z&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;一个线程块的线程束的数量可以根据下式确定：&lt;/p&gt;
&lt;p&gt;$$
\mathrm{WarpsPerBlock} = \left \lceil \frac{\mathrm{threadsPerBlock}}{\mathrm{warpSize}} \right \rceil
$$&lt;/p&gt;
&lt;p&gt;因此，硬件总是给一个线程块分配一定数量的线程束。线程束不会在不同的线程块之间分离。如果线程块的大小不是线程束大小的偶数倍，那么在最后的线程束里有些线程就不会活跃。比如说一个在 $x$ 轴中有 40 个线程、在 $y$ 轴中有 2 个线程的二维线程块。从应用程序的角度来看，在一个二维网格中共有 80 个线程。&lt;/p&gt;
&lt;p&gt;硬件为这个线程块配置了 3 个线程束，使总共 96 个硬件线程去支持 80 个软件线程。注意，最后半个线程束是不活跃的。即使这些线程未被使用，它们仍然消耗 SM 的资源，如寄存器。&lt;/p&gt;



&lt;div class=&#34;notice notice-info&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M256 8a248 248 0 100 496 248 248 0 000-496zm0 110a42 42 0 110 84 42 42 0 010-84zm56 254c0 7-5 12-12 12h-88c-7 0-12-5-12-12v-24c0-7 5-12 12-12h12v-64h-12c-7 0-12-5-12-12v-24c0-7 5-12 12-12h64c7 0 12 5 12 12v100h12c7 0 12 5 12 12v24z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;从逻辑角度来看：&lt;/strong&gt; 线程块是线程的集合，它们可以组织为一维、二维或三维布局。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;从硬件角度来看：&lt;/strong&gt; 线程块是一维线程束的集合。在线程块中线程被组织成一维布局，每 32 个连续线程组成一个线程束。&lt;/p&gt;&lt;/div&gt;

&lt;h2 id=&#34;2-线程束分化&#34;&gt;2. 线程束分化&lt;/h2&gt;
&lt;p&gt;控制流是高级编程语言的基本构造中的一种。GPU支持传统的、C风格的、显式的控制流结构，例如，if···then···else、for和while。&lt;/p&gt;
&lt;p&gt;CPU 拥有复杂的硬件以执行分支预测，也就是在每个条件检查中预测应用程序的控制流会使用哪个分支。如果预测正确，CPU 中的分支只需付出很小的性能代价。如果预测不正确，CPU可能会停止运行很多个周期，因为指令流水线被清空了。我们不必完全理解为什么 CPU 擅长处理复杂的控制流。这个解释只是作为对比的背景。当我们的程序包含大量的分支判断时，从程序角度来说，程序的逻辑是很复杂的，因为一个分支就会有两条路可以走，如果有 10 个分支，那么一共有 1024 条路走，CPU 采用流水线话作业，如果每次等到分支执行完再执行下面的指令会造成很大的延迟，所以现在处理器都采用分支预测技术，而CPU的这项技术相对于 GPU 来说高级了不止一点点，而这也是GPU与CPU的不同，设计初衷就是为了解决不同的问题。CPU适合逻辑复杂计算量不大的程序，比如操作系统，控制系统，GPU适合大量计算简单逻辑的任务，所以被用来算数。&lt;/p&gt;
&lt;p&gt;GPU 是相对简单的设备，它没有复杂的分支预测机制。一个线程束中的所有线程在同周期中必须执行相同的指令，如果一个线程执行一条指令，那么线程束中的所有线程都必须执行该指令。如果在同一线程束中的线程使用不同的路径通过同一个应用程序，这可能会产生问题。例如，思考下面的语句:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cond&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;假设在一个线程束中有 16 个线程执行这段代码，cond 为 true，但对于其他 16 个来说 cond 为 false 。一半的线程束需要执行 if 语句块中的指令，而另一半需要执行 else 语句块中的指令。在同一线程束中的线程执行不同的指令，被称为&lt;strong&gt;线程束分化&lt;/strong&gt;。我们已经知道，在一个线程束中所有线程在每个周期中必须执行相同的指令，所以线程束分化似乎会产生一
个悖论。&lt;/p&gt;
&lt;p&gt;如果一个线程束中的线程产生分化，线程束将连续执行每一个分支路径，而禁用不执行这一路径的线程。线程束分化会导致性能明显地下降。在前面的例子中可以看到，线程中并行线程的数量减少了一半: 只有 16 个线程同时活跃地执行，而其他 16 个被禁用了。条件分支越多，并行性削弱越严重。此外，线程束分化只发生在同一个线程束中。在不同的线程束中，不同的条件值不会引起线程束分化。&lt;/p&gt;
&lt;p&gt;执行过程如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230831205444-2023-08-31.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230831205444-2023-08-31&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;因为线程束分化导致的性能下降就应该用线程束的方法解决，根本思路是&lt;strong&gt;避免同一个线程束内的线程分化&lt;/strong&gt;，而让我们能控制线程束内线程行为的原因是线程块中线程分配到线程束是有规律的而不是随机的。这就使得我们根据线程编号来设计分支是可以的，补充说明下，当一个线程束中所有的线程都执行 if 或者，都执行 else 时，不存在性能下降；只有当线程束内有分歧产生分支的时候，性能才会急剧下降。&lt;/p&gt;
&lt;p&gt;线程束内的线程是可以被我们控制的，那么我们就把都执行 if 的线程塞到一个线程束中，或者让一个线程束中的线程都执行 if ，另外线程都执行 else 的这种方式可以将效率提高很多。&lt;/p&gt;
&lt;p&gt;举以下一个低效的核函数为例：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;__global__&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;mathKernel1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockDim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;threadIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.0f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;100.0f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;200.0f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这种情况下，线程束内的线程会产生分化，因为线程束内的线程会有一半执行 if ，另一半执行 else ，这样就会导致性能下降。我们可以通过下面的方式来优化：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;__global__&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;mathKernel2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;blockDim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;threadIdx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;float&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.0f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;warpSize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;100.0f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;200.0f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;假设只配置一个大小为 64 的一维线程块，那么只有 2 个线程束，第一个线程束内的线程编号 tid 从 0 到 31， tid / warpSize 都等于 0，那么都执行 if 语句；第二个线程束内的线程编号 tid 从 32 到 63， tid / warpSize 都等于 1，那么都执行 else 语句。这样就避免了线程束内的线程分化，效率较高。&lt;/p&gt;
&lt;p&gt;在 CUDA 中，对线程束分化的评价指标为&lt;strong&gt;分支效率 (branch efficiency)&lt;/strong&gt;，它是一个 0 到 100 之间的百分比，表示线程束中的线程在同一周期中执行的分支指令的百分比。分支效率越高，性能越好。分支效率的计算公式如下：&lt;/p&gt;
&lt;p&gt;$$
\mathrm{branch\ efficiency} = \frac{\mathrm{branches - divergent\ branches}}{\mathrm{branches}}
$$&lt;/p&gt;
&lt;p&gt;以上线程束分化例子的完整代码如下：&lt;/p&gt;
&lt;div class=&#34;github&#34;&gt;
    &lt;div class=&#34;logo&#34;&gt;
        &lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon github-icon&#34; viewBox=&#34;0 0 16 16&#34;&gt;&lt;path fill-rule=&#34;evenodd&#34; clip-rule=&#34;evenodd&#34; d=&#34;M2 2.5C2 1.83696 2.26339 1.20107 2.73223 0.732233C3.20108 0.263392 3.83696 0 4.5 0L13.25 0C13.4489 0 13.6397 0.0790176 13.7803 0.21967C13.921 0.360322 14 0.551088 14 0.75V13.25C14 13.4489 13.921 13.6397 13.7803 13.7803C13.6397 13.921 13.4489 14 13.25 14H10.75C10.5511 14 10.3603 13.921 10.2197 13.7803C10.079 13.6397 10 13.4489 10 13.25C10 13.0511 10.079 12.8603 10.2197 12.7197C10.3603 12.579 10.5511 12.5 10.75 12.5H12.5V10.5H4.5C4.30308 10.5 4.11056 10.5582 3.94657 10.6672C3.78257 10.7762 3.65442 10.9312 3.57816 11.1128C3.50191 11.2943 3.48096 11.4943 3.51793 11.6878C3.5549 11.8812 3.64816 12.0594 3.786 12.2C3.92524 12.3422 4.0023 12.5338 4.00024 12.7328C3.99818 12.9318 3.91716 13.1218 3.775 13.261C3.63285 13.4002 3.4412 13.4773 3.24222 13.4752C3.04325 13.4732 2.85324 13.3922 2.714 13.25C2.25571 12.7829 1.99929 12.1544 2 11.5V2.5ZM12.5 1.5V9H4.5C4.144 9 3.806 9.074 3.5 9.208V2.5C3.5 2.23478 3.60536 1.98043 3.79289 1.79289C3.98043 1.60536 4.23478 1.5 4.5 1.5H12.5ZM5 12.25V15.5C5 15.5464 5.01293 15.5919 5.03734 15.6314C5.06175 15.6709 5.09667 15.7028 5.1382 15.7236C5.17972 15.7444 5.22621 15.7532 5.27245 15.749C5.31869 15.7448 5.36286 15.7279 5.4 15.7L6.85 14.613C6.89328 14.5805 6.94591 14.563 7 14.563C7.05409 14.563 7.10673 14.5805 7.15 14.613L8.6 15.7C8.63714 15.7279 8.68131 15.7448 8.72755 15.749C8.77379 15.7532 8.82028 15.7444 8.8618 15.7236C8.90333 15.7028 8.93826 15.6709 8.96266 15.6314C8.98707 15.5919 9 15.5464 9 15.5V12.25C9 12.1837 8.97366 12.1201 8.92678 12.0732C8.87989 12.0263 8.81631 12 8.75 12H5.25C5.1837 12 5.12011 12.0263 5.07322 12.0732C5.02634 12.1201 5 12.1837 5 12.25Z&#34;/&gt;&lt;/svg&gt;
        &lt;a class=&#34;name&#34; href=https://github.com/PKUcoldkeyboard/cuda-demo/blob/main/Chap3/simpleDivergence.cu target=&#34;_blank&#34;&gt;线程束分化示例&lt;/a&gt;
    &lt;/div&gt;
    &lt;div class=&#34;description&#34;&gt;CUDA编程DEMO：线程束分化&lt;/div&gt; 
    &lt;div class=&#34;language&#34;&gt;
        &lt;span class=&#34;language-color&#34; style=&#34;background-color: #3A4E3A&#34;&gt;&lt;/span&gt;
        &lt;span class=&#34;language-name&#34;&gt;Cuda&lt;/span&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;编译命令为：（强制 CUDA 编译器不利用分支预测去优化内核，使用 Tesla T4 GPU）&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;nvcc -g -G -arch&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;sm_75 -o simpleDivergence simpleDivergence.cu
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;运行结果为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230831223456-2023-08-31.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230831223456-2023-08-31&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;代码中的 Warmup 部分是提前启动一次GPU，因为第一次启动GPU时会比第二次速度慢一些，具体原因未知，可以去查一下CUDA的相关技术文档了解内容。我们可以通过 Nvidia Nsight Compute 来查看分支效率（&lt;strong&gt;旧版的 nvprof 被弃用了&lt;/strong&gt;，metrics 参数对应的修改可以参考 &lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/weixin_44334901/article/details/128596081&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CUDA编程性能分析工具 nvprof/ncu &amp;ndash;metrics参数含义&lt;/a&gt; ，而且运行 ncu 时候必须使用 root 权限），结果如下所示：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;[58735] simpleDivergence@127.0.0.1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  warmingup(float *) (1, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Section: Command line profiler metrics
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ---------------------------------------------------- ----------- ------------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Metric Name                                          Metric Unit Metric Value
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ---------------------------------------------------- ----------- ------------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    smsp_sass_average_branch_targets_threads_uniform.pct                  100.00%
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ---------------------------------------------------- ----------- ------------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  mathKernel1(float *) (1, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Section: Command line profiler metrics
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ---------------------------------------------------- ----------- ------------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Metric Name                                          Metric Unit Metric Value
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ---------------------------------------------------- ----------- ------------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    smsp_sass_average_branch_targets_threads_uniform.pct                   83.33%
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ---------------------------------------------------- ----------- ------------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  mathKernel2(float *) (1, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Section: Command line profiler metrics
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ---------------------------------------------------- ----------- ------------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Metric Name                                          Metric Unit Metric Value
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ---------------------------------------------------- ----------- ------------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    smsp_sass_average_branch_targets_threads_uniform.pct                  100.00%
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ---------------------------------------------------- ----------- ------------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  mathKernel3(float *) (1, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Section: Command line profiler metrics
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ---------------------------------------------------- ----------- ------------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Metric Name                                          Metric Unit Metric Value
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ---------------------------------------------------- ----------- ------------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    smsp_sass_average_branch_targets_threads_uniform.pct                   71.43%
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ---------------------------------------------------- ----------- ------------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  mathKernel4(float *) (1, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 7.5
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Section: Command line profiler metrics
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ---------------------------------------------------- ----------- ------------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    Metric Name                                          Metric Unit Metric Value
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ---------------------------------------------------- ----------- ------------
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    smsp_sass_average_branch_targets_threads_uniform.pct                  100.00%
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ---------------------------------------------------- ----------- ------------
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;CUDA 的 nvcc 编译器仍然是在 mathKernel1 和 mathKernel3 上执行有限的优化，以保证分支效率在 50% 以上。注意，mathKernel2 不报告分支分化的唯一原因是它的分支粒度是线程束大小的倍数。此外，把 mathKernel1 中的 if&amp;hellip;else 语句分离为 mathKernel3 的多个 if 语句，可以使分支分化的数量翻倍。&lt;/p&gt;
&lt;h2 id=&#34;3-资源分配&#34;&gt;3. 资源分配&lt;/h2&gt;
&lt;p&gt;前面提到，每个 SM 上执行的基本单位是线程束，也就是说，单指令通过指令调度器广播给某线程束的全部线程，这些线程同一时刻执行同一命令，当然也有分支情况，也有很多线程束没执行，那么这些没执行的线程束情况又如何呢？可以将这些没执行的线程束分为两类：一类是已经激活的，也就是说这类线程束其实已经在 SM 上准备就绪了，只是没轮到它执行，这时候它的状态为阻塞，另一类是可能分配到 SM 了，但是还没上片，这类就称之为未激活线程束。而每个 SM 上有多少个线程束处于激活状态，取决于以下资源：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;程序计数器&lt;/li&gt;
&lt;li&gt;寄存器&lt;/li&gt;
&lt;li&gt;共享内存&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;线程束一旦被激活来到片上，那么它就不会再离开 SM 直到执行结束。&lt;/p&gt;
&lt;p&gt;每个 SM 都有 32 位的寄存器组，每个架构寄存器的数量不一样，其存储于寄存器文件中，为每个线程进行分配，同时，固定数量的共享内存，在线程块之间分配。&lt;/p&gt;
&lt;p&gt;一个 SM 上被分配多少个线程块和线程束取决于SM中可用的寄存器和共享内存，以及内核需要的寄存器和共享内存大小。 当 kernel 占用的资源较少，那么更多的线程处于活跃状态，相反则线程越少。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;寄存器资源的分配&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230901150726-2023-09-01.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230901150726-2023-09-01&#34;
	
	
&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;共享内存的分配&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230901150743-2023-09-01.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230901150743-2023-09-01&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;上面讲的主要是线程束，如果从逻辑上来看线程块的话，可用资源的分配也会影响常驻线程块的数量。特别是当 SM 内的资源没办法处理一个完整块，那么程序将无法启动。&lt;/p&gt;
&lt;p&gt;以下是资源列表：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230901150843-2023-09-01.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230901150843-2023-09-01&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;当寄存器和共享内存分配给了线程块，这个线程块处于活跃状态，所包含的线程束称为活跃线程束。活跃的线程束又分为三类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;选定的线程束&lt;/li&gt;
&lt;li&gt;阻塞的线程束&lt;/li&gt;
&lt;li&gt;符合条件的线程束&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当 SM 要执行某个线程束的时候，执行的这个线程束叫做选定的线程束，准备要执行的叫符合条件的线程束，如果线程束不符合条件还没准备好就是阻塞的线程束。
满足下面的要求，线程束才算是符合条件的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;32 个 CUDA 核心可以用于执行&lt;/li&gt;
&lt;li&gt;执行所需要的资源全部就位&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kepler活跃的线程束数量从开始到结束不得大于 64，可以等于。任何周期选定的线程束小于等于 4 。由于计算资源是在线程束之间分配的，且线程束的整个生命周期都在片上，所以线程束的上下文切换是非常快速的。下一节将说明如何通过大量的活跃的线程束切换来隐藏延迟。&lt;/p&gt;
&lt;h2 id=&#34;4-延迟隐藏&#34;&gt;4. 延迟隐藏&lt;/h2&gt;
&lt;p&gt;SM 依赖线程级并行，以最大化功能单元的利用率，因此，利用率与常驻线程束的数量直接相关。在指令发出和完成之间的时钟周期被定义为&lt;strong&gt;指令延迟&lt;/strong&gt;。当每个时钟周期中所有的线程调度器都有一个符合条件的线程束时，可以达到计算资源的完全利用。这就可以保证，通过在其他常驻线程束中发布其他指令，可以&lt;strong&gt;隐藏每个指令的延迟&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;与在 CPU 上用C语言编程相比，&lt;strong&gt;延迟隐藏&lt;/strong&gt;在 CUDA 编程中尤为重要。CPU 核心是为同时最小化延迟一个或两个线程而设计的，而 GPU 则是为处理大量并发和轻量级线程以最大化吞吐量而设计的。GPU 的指令延迟被其他线程束的计算隐藏。&lt;/p&gt;
&lt;p&gt;考虑到指令延迟，指令可以被分为两种基本类型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;算术指令&lt;/li&gt;
&lt;li&gt;内存指令&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;算术指令延迟&lt;/strong&gt;是一个算术操作从开始到它产生输出之间的时间。&lt;strong&gt;内存指令延迟&lt;/strong&gt;是指发送出的加载或存储操作和数据到达目的地之间的时间。对于每种情况，相应的延迟大约为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;算术操作为 10～20 个周期&lt;/li&gt;
&lt;li&gt;全局内存访问为 400～800 个周期&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下图是阻塞线程束到可选线程束的过程逻辑图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230901151502-2023-09-01.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230901151502-2023-09-01&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;其中线程束 0 （Warp 0） 阻塞两段时间后恢复可选模式，但是在这段等待时间中，SM 没有闲置。那么至少需要多少线程，线程束来保证最小化延迟呢？可以根据利特尔法则（Little&amp;rsquo;s Law）提供一个合理的近似值。它起源于队列理论中的一个定理，也可以用于 GPU 中：&lt;/p&gt;
&lt;p&gt;$$
\mathrm{所需线程束}=\mathrm{延迟}\times \mathrm{吞吐量}
$$&lt;/p&gt;



&lt;div class=&#34;notice notice-info&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34;&gt;&lt;path d=&#34;M256 8a248 248 0 100 496 248 248 0 000-496zm0 110a42 42 0 110 84 42 42 0 010-84zm56 254c0 7-5 12-12 12h-88c-7 0-12-5-12-12v-24c0-7 5-12 12-12h12v-64h-12c-7 0-12-5-12-12v-24c0-7 5-12 12-12h64c7 0 12 5 12 12v100h12c7 0 12 5 12 12v24z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;注意带宽和吞吐量的区别，带宽一般指的是理论峰值，最大每个时钟周期能执行多少个指令，吞吐量是指实际操作过程中每分钟处理多少个指令。简单来说，带宽通常是指理论峰值，而吞吐量是指已达到的值。&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;这个可以想象成一个瀑布，像这样，绿箭头是线程束，只要线程束足够多，吞吐量是不会降低的：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230901151942-2023-09-01.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230901151942-2023-09-01&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;假设在 kernel 里一条指令的平均延迟是5个周期。为了保持在每个周期内执行 6 个线程束的吞吐量，则至少需要 30 个未完成的线程束。&lt;/p&gt;
&lt;p&gt;对于算术运算来说，其所需的并行可以表示成隐藏算术延迟所需要的操作数量。下面的表格出了 Fermi 和 Kepler 设备所需的操作数量。示例中的算术运算是一个 32 位的浮点数乘加运算 (a + b $\times$ c)，表示在每个 SM 中每个时钟周期内的操作数量。吞吐量因不同的算术指令而不同。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230901152413-2023-09-01.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230901152413-2023-09-01&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;吞吐量由 SM 中每个周期内的操作数量确定，而执行一条指令的一个线程束对应 32 个操作。因此，为保持计算资源的充分利用，对于 Fermi GPU 而言，每个 SM 中所需的线程束数量通过计算为 $640 \div 32 = 20 $ 个线程束。因此，算术运算所需的并行可以用操作的数量或线程束的数量来表示。这个简单的单位转换表明，有两种方法可以提高并行：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;指令级并行（ILP）：一个线程中有很多独立的指令&lt;/li&gt;
&lt;li&gt;线程级并行（TLP）：很多并发地符合条件的线程&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;同样，与指令周期隐藏延迟类似，&lt;strong&gt;内存隐藏延迟&lt;/strong&gt;是靠内存读取的并发操作来完成的，需要注意的是，指令隐藏的关键目的是使用全部的计算资源，而内存读取的延迟隐藏是为了使用全部的内存带宽，内存延迟的时候，计算资源正在被别的线程束使用，所以我们不考虑内存读取延迟的时候计算资源在做了什么，我们的根本目的是把计算资源，内存读取的带宽资源全部使用满，这样就能达到理论的最大效率。同样下表根据利特尔法则给出了需要多少线程束来最小化内存读取延迟，不过这里有个单位换算过程，机器的性能指标内存读取速度给出的是 GB/s 的单位，而我们需要的是每个时钟周期读取字节数，所以要用这个速度除以频率，例如 Tesla C2070 的内存带宽是 144 GB/s，转化成时钟周期： $\frac{144\mathrm{GB/s}}{1.566 \mathrm{GHz}}=92\mathrm{B/t}$，这样就能得到单位时间周期的内存带宽了。即下表的数据：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230901152915-2023-09-01.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230901152915-2023-09-01&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;需要说明的是这个速度不是单个 SM 的而是整个GPU设备的。Fermi 需要并行的读取 74KB 的数据才能让GPU带宽满载，如果每个线程读取4个字节，我们大约需要18500个线程，大约579个线程束才能达到这个峰值。&lt;/p&gt;
&lt;p&gt;所以，延迟的隐藏取决于活动的线程束的数量，数量越多，隐藏的越好，但是线程束的数量又受到上面的说的资源影响。所以这里就需要寻找最优的执行配置来达到最优的延迟隐藏。&lt;/p&gt;
&lt;p&gt;那么我们怎么样确定一个线程束的下界呢，使得当高于这个数字时SM的延迟能充分的隐藏，其实这个公式很简单，也很好理解，就是SM的计算核心数乘以单条指令的延迟，比如 32 个单精度浮点计算器，每次计算延迟 20 个时钟周期，那么我需要最少 $32 \times 20 =640$ 个线程使设备处于忙碌状态。然而，这只是一个下边界。&lt;/p&gt;
&lt;h2 id=&#34;5-占用率&#34;&gt;5. 占用率&lt;/h2&gt;
&lt;p&gt;在每个CUDA核心里指令是顺序执行的。当一个线程束阻塞时，SM 切换执行其他符合条件的线程束。理想情况下，我们想要有足够的线程束占用设备的核心。占用率是每个 SM 中活跃的线程束占最大线程束数量的比值。即：&lt;/p&gt;
&lt;p&gt;$$
\mathrm{Occupancy} = \frac{\mathrm{Active\ Warps}}{\mathrm{Max\ Warps}}
$$&lt;/p&gt;
&lt;p&gt;通过以下代码可以查询设备的最大线程束数量：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dev&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;cudaDeviceProp&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;deviceProp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;CHECK&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;cudaGetDeviceProperties&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;deviceProp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dev&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;log_info&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Device %d: %s&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dev&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;deviceProp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;log_info&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Number of SMs: %d&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;deviceProp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;multiProcessorCount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;log_info&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Total amount of constant memory: %4.2f KB&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;deviceProp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;totalConstMem&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1024.0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;log_info&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Total amount of shared memory per block: %4.2f KB&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;n&#34;&gt;deviceProp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sharedMemPerBlock&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1024.0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;log_info&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Total number of registers available per block: %d&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;deviceProp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;regsPerBlock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;log_info&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Warp size: %d&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;deviceProp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;warpSize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;log_info&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Maximum number of threads per block: %d&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;deviceProp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;maxThreadsPerBlock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;log_info&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Maximum number of threads per multiprocessor: %d&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;n&#34;&gt;deviceProp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;maxThreadsPerMultiProcessor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;log_info&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Maximum number of warps per multiprocessor: %d&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;          &lt;span class=&#34;n&#34;&gt;deviceProp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;maxThreadsPerMultiProcessor&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;输出结果为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230901155126-2023-09-01.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230901155126-2023-09-01&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;可以看到 RTX4090 最大 64 个线程束每个 SM。&lt;/p&gt;
&lt;p&gt;内核使用寄存器的数量会影响 SM 内线程束的数量，nvcc 的编译选项也有手动控制寄存器的使用。也可以通过调整线程块内线程的多少来提高占用率，当然要合理不能太极端：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;小的线程块：每个线程块中线程太少，会在所有资源没用完就达到了线程束的最大要求&lt;/li&gt;
&lt;li&gt;大的线程块：每个线程块中太多线程，会导致每个 SM 中每个线程可用的硬件资源较少。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一个确定网格和线程块大小的基本准则如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;保持每个块中线程数量是线程束大小（32）的倍数&lt;/li&gt;
&lt;li&gt;避免块太小：每个块至少要有 128 或 256 个线程&lt;/li&gt;
&lt;li&gt;根据内核资源的需求调整块大小&lt;/li&gt;
&lt;li&gt;块的数量要远远多于 SM 的数量，从而在设备中可以显示有足够的并行&lt;/li&gt;
&lt;li&gt;通过实验得到最佳执行配置和资源使用情况&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;尽管在每种情况下会遇到不同的硬件限制，但它们都会导致计算资源未被充分利用，阻碍隐藏指令和内存延迟的并行的建立。占用率唯一注重的是在每个 SM 中并发线程或线程束的数量。然而，充分的占用率不是性能优化的唯一目标。内核一旦达到一定级别的占用率，进一步增加占用率可能不会改进性能。为了提高性能，可以调整很多其他因素。&lt;/p&gt;
&lt;h2 id=&#34;6-同步&#34;&gt;6. 同步&lt;/h2&gt;
&lt;p&gt;栅栏同步是一个原语，它在许多并行编程语言中都很常见。在 CUDA 中，同步可以在两个级别执行：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;线程块内同步&lt;/li&gt;
&lt;li&gt;系统级别&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;块级别的就是同一个块内的线程会同时停止在某个设定的位置，用&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;__syncthreads&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这个函数完成，这个函数只能同步同一个块内的线程，不能同步不同块内的线程，想要同步不同块内的线程，就只能让核函数执行完成，控制程序交换主机，这种方式来同步所有线程。当__syncthreads被调用时，在同一个线程块中每个线程都必须等待直至该线程块中所有其他线程都已经达到这个同步点。线程产生的所有全局内存和共享内存访问，将会在栅栏后对线程块中所有其他的线程可见。该函数可以协调同一个块中线程之间的通信，但它强制线程束空闲，从而可能对性能产生负面影响。&lt;/p&gt;
&lt;p&gt;在不同的块之间没有线程同步。块间同步，唯一安全的方法是在每个内核执行结束端使用全局同步点；也就是说，在全局同步之后，终止当前的核函数，开始执行新的核函数。&lt;/p&gt;
&lt;p&gt;不同块中的线程不允许相互同步，因此GPU可以以任意顺序执行块。这使得CUDA程序在大规模并行GPU上是可扩展的。&lt;/p&gt;
&lt;h2 id=&#34;7-可扩展性&#34;&gt;7. 可扩展性&lt;/h2&gt;
&lt;p&gt;对于任何并行应用程序而言，可扩展性是一个理想的特性。可扩展性意味着为并行应用程序提供了额外的硬件资源，相对于增加的资源，并行应用程序会产生加速。例如，若一个CUDA程序在两个 SM 中是可扩展的，则与在一个 SM 中运行相比，在两个 SM 中运行会使运行时间减半。一个可扩展的并行程序可以高效地使用所有的计算资源以提高性能。可扩展性意味着增加的计算核心可以提高性能。串行代码本身是不可扩展的，因为在成千上万的内核上运行一个串行单线程应用程序，对性能是没有影响的。并行代码有可扩展的潜能，但真正的可扩展性取决于算法设计和硬件特性。&lt;/p&gt;
&lt;p&gt;能够在可变数量的计算核心上执行相同的应用程序代码的能力被称为&lt;strong&gt;透明可扩展性&lt;/strong&gt;。一个透明的可扩展平台拓宽了现有应用程序的应用范围，并减少了开发人员的负担，因为它们可以避免新的或不同的硬件产生的变化。可扩展性比效率更重要。一个可扩展但效率很低的系统可以通过简单添加硬件核心来处理更大的工作负载。一个效率很高但不可扩展的系统可能很快会达到可实现性能的上限。&lt;/p&gt;
&lt;p&gt;CUDA内核启动时，线程块分布在多个 SM 中。网格中的线程块以并行或连续或任意的顺序被执行。这种独立性使得CUDA程序在任意数量的计算核心间可以扩展。&lt;/p&gt;
&lt;p&gt;下图展示了 CUDA 架构可扩展性的一个例子。左侧的 GPU 有两个 SM，  可以同时执行两个块；右侧的 GPU 有 4 个 SM ，可以同时执行 4 个块。不修改任何代码，一个应用程序可以在不同的GPU配置上运行，并且所需的执行时间根据可用的资源而改变。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cuterwrite-1302252842.file.myqcloud.com/img/20230901163747-2023-09-01.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;20230901163747-2023-09-01&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;p&gt;[1] CUDA C编程权威指南，机械工业出版社，（美）程润伟（John Cheng） 等著&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
