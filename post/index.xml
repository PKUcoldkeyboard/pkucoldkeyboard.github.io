<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Cuterwrite's Blog</title><link>https://cuterwrite.top/post/</link><description>Recent content in Posts on Cuterwrite's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>cuterwrite</copyright><lastBuildDate>Fri, 08 Mar 2024 14:39:00 +0000</lastBuildDate><atom:link href="https://cuterwrite.top/post/index.xml" rel="self" type="application/rss+xml"/><item><title>记录：安装 Intel® OneAPI-2024.0</title><link>https://cuterwrite.top/p/intel-oneapi/</link><pubDate>Fri, 08 Mar 2024 14:39:00 +0000</pubDate><guid>https://cuterwrite.top/p/intel-oneapi/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/crop_62cf8bae89f60c3522eb45af53a53f4b195413-2024-03-09.webp" alt="Featured image of post 记录：安装 Intel® OneAPI-2024.0" />&lt;h1 id="记录安装-intel-oneapi-20240">记录：安装 Intel® OneAPI-2024.0&lt;/h1>
&lt;p>Intel one API 由两个部分组成，前者为基础 Base Toolkit ，后者必须依赖前者，Intel one API HPC Toolkit，也就是要前后依次安装。&lt;/p>
&lt;h2 id="base-toolkit">Base Toolkit&lt;/h2>
&lt;p>Base Toolkit 是 Intel 的一个 API 基础工具包包括以下库和其他库&lt;/p>
&lt;pre>&lt;code class="language-text">Intel® oneAPI DPC++/C++ Compiler
Intel® DPC++ Compatibility Tool
Intel® oneAPI DPC++ Library
Intel® oneAPI Math Kernel Library
Intel® oneAPI Threading Building Blocks
Intel® oneAPI Collective Communications Library
Intel® oneAPI Data Analytics Library
Intel® oneAPI Deep Neural Networks Library
Intel® Integrated Performance Primitives
Intel® VTune™ Profiler
Intel® Advisor
Intel® Distribution for GDB*
Intel® Distribution for Python* (separate download required)
Intel® FPGA Add-on for oneAPI Base Toolkit (separate download required)
&lt;/code>&lt;/pre>
&lt;h3 id="base-toolkit-安装">Base Toolkit 安装&lt;/h3>
&lt;ol>
&lt;li>下载安装包&lt;/li>
&lt;/ol>
&lt;pre>&lt;code class="language-bash">$ wget https://registrationcenter-download.intel.com/akdlm/IRC_NAS/163da6e4-56eb-4948-aba3-debcec61c064/l_BaseKit_p_2024.0.1.46_offline.sh
&lt;/code>&lt;/pre>
&lt;ol start="2">
&lt;li>安装&lt;/li>
&lt;/ol>
&lt;pre>&lt;code class="language-bash">$ chmod +x l_BaseKit_p_2024.0.1.46_offline.sh
$ sudo ./l_BaseKit_p_2024.0.1.46_offline.sh
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>如果自定义安装在用户目录，就不需要 root 权限&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>./l_BaseKit_p_2024.0.1.46_offline.sh
&lt;/code>&lt;/pre>
&lt;p>然后将启动一个图形安装界面，继续操作：&lt;/p>
&lt;p>&lt;strong>（1）选择 Accept &amp;amp; customize&lt;/strong>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/OneAPI-Accepet-2024-03-09.png"
alt="OneAPI-Accepet-2024-03-09" width="auto" loading="lazy"/>
&lt;/figure>
&lt;/p>
&lt;p>&lt;strong>（2）选择安装的组件&lt;/strong>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/OneAPI-Select-2-2024-03-09.png"
alt="OneAPI-Select-2-2024-03-09" width="auto" loading="lazy"/>
&lt;/figure>
&lt;/p>
&lt;p>&lt;strong>（3）选择安装的路径&lt;/strong>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/OneAPI-Select-3-2024-03-09.png"
alt="OneAPI-Select-3-2024-03-09" width="auto" loading="lazy"/>
&lt;/figure>
&lt;/p>
&lt;p>&lt;strong>（4）选择 Next&lt;/strong>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/OneAPI-Select-4-2024-03-09.png"
alt="OneAPI-Select-4-2024-03-09" width="auto" loading="lazy"/>
&lt;/figure>
&lt;/p>
&lt;p>&lt;strong>（5）选择 2 然后开始安装&lt;/strong>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/OneAPI-Select-5-2024-03-09.png"
alt="OneAPI-Select-5-2024-03-09" width="auto" loading="lazy"/>
&lt;/figure>
&lt;/p>
&lt;p>接下来等待安装完成即可。&lt;/p>
&lt;h2 id="hpc-toolkit">HPC Toolkit&lt;/h2>
&lt;p>运行基于 Base Toolkit ，这个必须作为后者安装&lt;/p>
&lt;pre>&lt;code class="language-text">Intel® Fortran Compiler
Intel® Fortran Compiler Classic
Intel® Inspector
Intel® MPI Library
Intel® Trace Analyzer and Collector
&lt;/code>&lt;/pre>
&lt;h3 id="hpc-toolkit-安装">HPC Toolkit 安装&lt;/h3>
&lt;ol>
&lt;li>下载安装包&lt;/li>
&lt;/ol>
&lt;pre>&lt;code class="language-bash">$ wget https://registrationcenter-download.intel.com/akdlm/IRC_NAS/67c08c98-f311-4068-8b85-15d79c4f277a/l_HPCKit_p_2024.0.1.38_offline.sh
&lt;/code>&lt;/pre>
&lt;ol start="2">
&lt;li>安装&lt;/li>
&lt;/ol>
&lt;pre>&lt;code class="language-bash">$ chmod +x l_HPCKit_p_2024.0.1.38_offline.sh
$ sudo ./l_HPCKit_p_2024.0.1.38_offline.sh
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>如果自定义安装在用户目录，就不需要 root 权限&lt;/li>
&lt;/ul>
&lt;pre>&lt;code>./l_HPCKit_p_2024.0.1.38_offline.sh
&lt;/code>&lt;/pre>
&lt;p>必须安装的库文件： Intel® MPI Library Intel® Fortran Compiler (Beta) &amp;amp; Intel® Fortran Compiler Classic Intel® oneAPI DPC++/C++ Compiler &amp;amp; Intel® C++ Compiler Classic&lt;/p>
&lt;p>安装过程与 Base Toolkit 类似，不再赘述。&lt;/p>
&lt;h2 id="环境配置">环境配置&lt;/h2>
&lt;p>安装完成后，需要配置环境变量，以便在终端中使用 Intel® oneAPI 工具。&lt;/p>
&lt;p>在 HPC 环境中，使用 &lt;code>modulefile&lt;/code> 来管理环境变量，可以使用 &lt;code>module&lt;/code> 命令来加载环境变量。&lt;/p>
&lt;p>以下是参考的 &lt;code>modulefile&lt;/code> 文件，可以根据自己的安装路径进行修改。&lt;/p>
&lt;pre>&lt;code class="language-modulefile">#%Module1.0#####################################################################
##
## modules modulefile
##
proc ModulesHelp { } {
global version prefix
puts stderr &amp;quot;\tmodules - loads the modules software &amp;amp; application environment&amp;quot;
puts stderr &amp;quot;\n\tThis adds $prefix/* to several of the&amp;quot;
puts stderr &amp;quot;\tenvironment variables.&amp;quot;
puts stderr &amp;quot;\n\tVersion $version\n&amp;quot;
}
module-whatis &amp;quot;loads intel/oneapi2024.0&amp;quot;
# for Tcl script use only
set version oneapi2024.0
set prefix /opt/software/intel/oneapi2024.0
conflict intel
prepend-path TBBROOT ${prefix}/tbb/2021.11/env/..
prepend-path DAALROOT ${prefix}/cdal/2024.0
prepend-path DPCT_BUNDLE_ROOT ${prefix}/dpcpp-ct/2024.0
prepend-path INSPECTOR_2023_DIR ${prefix}/inspector/2024.0
prepend-path ONEAPI_ROOT ${prefix}
prepend-path PKG_CONFIG_PATH ${prefix}/vtune/2024.0/include/pkgconfig/lib64:${prefix}/tbb/2021.11/env/../lib/pkgconfig:${prefix}/mpi/2021.11/lib/pkgconfig:${prefix}/mkl/2024.0/lib/pkgconfig:${prefix}/ippcp/2021.9/lib/pkgconfig:${prefix}/inspector/2024.0/include/pkgconfig/lib64:${prefix}/dpl/2022.3/lib/pkgconfig:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/../lib/pkgconfig:${prefix}/cdal/2024.0/lib/pkgconfig:${prefix}/compiler/2024.0/lib/pkgconfig:${prefix}/ccl/2021.11/lib/pkgconfig:${prefix}/advisor/2024.0/include/pkgconfig/lib64:
#prepend-path PKG_CONFIG_PATH ${prefix}/vtune/2024.0/include/pkgconfig/lib64:${prefix}/tbb/2021.11/env/../lib/pkgconfig:${prefix}/mkl/2024.0/lib/pkgconfig:${prefix}/ippcp/2021.9/lib/pkgconfig:${prefix}/inspector/2024.0/include/pkgconfig/lib64:${prefix}/dpl/2022.3/lib/pkgconfig:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/../lib/pkgconfig:${prefix}/cdal/2024.0/lib/pkgconfig:${prefix}/compiler/2024.0/lib/pkgconfig:${prefix}/ccl/2021.11/lib/pkgconfig:${prefix}/advisor/2024.0/include/pkgconfig/lib64:
prepend-path VT_MPI impi4
prepend-path ACL_BOARD_VENDOR_PATH /opt/Intel/OpenCLFPGA/oneAPI/Boards
prepend-path FPGA_VARS_DIR ${prefix}/compiler/2024.0/lib/oclfpga
prepend-path CCL_ROOT ${prefix}/ccl/2021.11
prepend-path VT_ADD_LIBS &amp;quot;-ldwarf -lelf -lvtunwind -lm -lpthread&amp;quot;
prepend-path I_MPI_ROOT ${prefix}/mpi/2021.11
prepend-path FI_PROVIDER_PATH ${prefix}/mpi/2021.11//libfabric/lib/prov:/usr/lib/x86_64-linux-gnu/libfabric
prepend-path DNNLROOT ${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp
prepend-path DIAGUTIL_PATH ${prefix}/vtune/2024.0/sys_check/vtune_sys_check.py:${prefix}/dpcpp-ct/2024.0/sys_check/sys_check.sh:${prefix}/debugger/2024.0/sys_check/debugger_sys_check.py:${prefix}/compiler/2024.0/sys_check/sys_check.sh:${prefix}/advisor/2024.0/sys_check/advisor_sys_check.py:
prepend-path CCL_CONFIGURATION cpu_gpu_dpcpp
prepend-path DPL_ROOT ${prefix}/dpl/2022.3
prepend-path MANPATH ${prefix}/mpi/2021.11/man:${prefix}/itac/2022.0/man:${prefix}/debugger/2024.0/documentation/man:${prefix}/compiler/2024.0/documentation/en/man/common:::
#prepend-path MANPATH ${prefix}/itac/2022.0/man:${prefix}/debugger/2024.0/documentation/man:${prefix}/compiler/2024.0/documentation/en/man/common:::
prepend-path GDB_INFO ${prefix}/debugger/2024.0/documentation/info/
prepend-path SETVARS_COMPLETED 1
prepend-path APM ${prefix}/advisor/2024.0/perfmodels
prepend-path CMAKE_PREFIX_PATH ${prefix}/tbb/2021.11/env/..:${prefix}/ipp/2021.10/lib/cmake/ipp:${prefix}/ipp/2021.10/lib/cmake/ipp:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/../lib/cmake:${prefix}/cdal/2024.0:${prefix}/compiler/2024.0/IntelDPCPP:${prefix}/ccl/2021.11/lib/cmake/oneCCL
prepend-path VTUNE_PROFILER_2023_DIR ${prefix}/vtune/2024.0
prepend-path CMPLR_ROOT ${prefix}/compiler/2024.0
prepend-path ADVISOR_2023_DIR ${prefix}/advisor/2024.0
prepend-path FPGA_VARS_ARGS &amp;quot;&amp;quot;
prepend-path INFOPATH ${prefix}/debugger/2024.0/gdb/intel64/lib
prepend-path IPPROOT ${prefix}/ipp/2021.10
prepend-path IPP_TARGET_ARCH intel64
prepend-path PYTHONPATH ${prefix}/advisor/2024.0/pythonapi
prepend-path VT_ROOT ${prefix}/itac/2022.0
prepend-path DALROOT ${prefix}/cdal/2024.0
prepend-path LIBRARY_PATH ${prefix}/tbb/2021.11/env/../lib/intel64/gcc4.8:${prefix}/mpi/2021.11//libfabric/lib:${prefix}/mpi/2021.11//lib/release:${prefix}/mpi/2021.11//lib:${prefix}/mkl/2024.0/lib/intel64:${prefix}/ipp/2021.10/lib/intel64:${prefix}/ippcp/2021.9/lib/intel64:${prefix}/ipp/2021.10/lib/intel64:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/lib:${prefix}/cdal/2024.0/lib/intel64:${prefix}/compiler/2024.0/compiler/lib/intel64_lin:${prefix}/compiler/2024.0/lib:${prefix}/ccl/2021.11/lib/cpu_gpu_dpcpp
#prepend-path LIBRARY_PATH ${prefix}/tbb/2021.11/env/../lib/intel64/gcc4.8:${prefix}/mkl/2024.0/lib/intel64:${prefix}/ipp/2021.10/lib/intel64:${prefix}/ippcp/2021.9/lib/intel64:${prefix}/ipp/2021.10/lib/intel64:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/lib:${prefix}/cdal/2024.0/lib/intel64:${prefix}/compiler/2024.0/compiler/lib/intel64_lin:${prefix}/compiler/2024.0/lib:${prefix}/ccl/2021.11/lib/cpu_gpu_dpcpp
prepend-path DAL_MAJOR_BINARY 1
prepend-path IPPCRYPTOROOT ${prefix}/ippcp/2021.9
prepend-path IPPCP_TARGET_ARCH intel64
prepend-path OCL_ICD_FILENAMES libintelocl_emu.so:libalteracl.so:${prefix}/compiler/2024.0/lib/x64/libintelocl.so
prepend-path CLASSPATH ${prefix}/mpi/2021.11//lib/mpi.jar:${prefix}/cdal/2024.0/lib/onedal.jar
#prepend-path CLASSPATH ${prefix}/cdal/2024.0/lib/onedal.jar
prepend-path INTELFPGAOCLSDKROOT ${prefix}/compiler/2024.0/lib/oclfpga
prepend-path LD_LIBRARY_PATH ${prefix}/tbb/2021.11/env/../lib/intel64/gcc4.8:${prefix}/mpi/2021.11//libfabric/lib:${prefix}/mpi/2021.11//lib/release:${prefix}/mpi/2021.11//lib:${prefix}/mkl/2024.0/lib/intel64:${prefix}/itac/2022.0/slib:${prefix}/ipp/2021.10/lib/intel64:${prefix}/ippcp/2021.9/lib/intel64:${prefix}/ipp/2021.10/lib/intel64:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/lib:${prefix}/debugger/2024.0/gdb/intel64/lib:${prefix}/debugger/2024.0/libipt/intel64/lib:${prefix}/debugger/2024.0/dep/lib:${prefix}/cdal/2024.0/lib/intel64:${prefix}/compiler/2024.0/lib:${prefix}/compiler/2024.0/lib/x64:${prefix}/compiler/2024.0/lib/oclfpga/host/linux64/lib:${prefix}/compiler/2024.0/compiler/lib/intel64_lin:${prefix}/ccl/2021.11/lib/cpu_gpu_dpcpp:${prefix}/compiler/2024.0/compiler/lib/intel64_lin:${prefix}/ccl/2021.11/lib/cpu_gpu_dpcpp
#prepend-path LD_LIBRARY_PATH ${prefix}/tbb/2021.11/env/../lib/intel64/gcc4.8:${prefix}/mkl/2024.0/lib/intel64:${prefix}/itac/2022.0/slib:${prefix}/ipp/2021.10/lib/intel64:${prefix}/ippcp/2021.9/lib/intel64:${prefix}/ipp/2021.10/lib/intel64:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/lib:${prefix}/debugger/2024.0/gdb/intel64/lib:${prefix}/debugger/2024.0/libipt/intel64/lib:${prefix}/debugger/2024.0/dep/lib:${prefix}/cdal/2024.0/lib/intel64:${prefix}/compiler/2024.0/lib:${prefix}/compiler/2024.0/lib/x64:${prefix}/compiler/2024.0/lib/oclfpga/host/linux64/lib:${prefix}/compiler/2024.0/compiler/lib/intel64_lin:${prefix}/ccl/2021.11/lib/cpu_gpu_dpcpp:${prefix}/compiler/2024.0/compiler/lib/intel64_lin:${prefix}/ccl/2021.11/lib/cpu_gpu_dpcpp
prepend-path VT_LIB_DIR ${prefix}/itac/2022.0/lib
prepend-path VTUNE_PROFILER_DIR ${prefix}/vtune/2024.0
prepend-path VT_SLIB_DIR ${prefix}/itac/2022.0/slib
prepend-path MKLROOT ${prefix}/mkl/2024.0
prepend-path DAL_MINOR_BINARY 1
prepend-path NLSPATH ${prefix}/mkl/2024.0/lib/intel64/locale/%l_%t/%N:${prefix}/compiler/2024.0/compiler/lib/intel64_lin/locale/%l_%t/%N
prepend-path PATH ${prefix}/vtune/2024.0/bin64:${prefix}/mpi/2021.11//libfabric/bin:${prefix}/mpi/2021.11//bin:${prefix}/mkl/2024.0/bin/intel64:${prefix}/itac/2022.0/bin:${prefix}/inspector/2024.0/bin64:${prefix}/dpcpp-ct/2024.0/bin:${prefix}/dev-utilities/2024.0/bin:${prefix}/debugger/2024.0/gdb/intel64/bin:${prefix}/compiler/2024.0/lib/oclfpga/bin:${prefix}/compiler/2024.0/bin/intel64:${prefix}/compiler/2024.0/bin:${prefix}/advisor/2024.0/bin64
#prepend-path PATH ${prefix}/vtune/2024.0/bin64:${prefix}/mkl/2024.0/bin/intel64:${prefix}/itac/2022.0/bin:${prefix}/inspector/2024.0/bin64:${prefix}/dpcpp-ct/2024.0/bin:${prefix}/dev-utilities/2024.0/bin:${prefix}/debugger/2024.0/gdb/intel64/bin:${prefix}/compiler/2024.0/lib/oclfpga/bin:${prefix}/compiler/2024.0/bin/intel64:${prefix}/compiler/2024.0/bin:${prefix}/advisor/2024.0/bin64
prepend-path INTEL_PYTHONHOME ${prefix}/debugger/2024.0/dep
prepend-path INTEL_LICENSE_FILE /opt/intel/licenses:/root/intel/licenses
prepend-path CPATH ${prefix}/tbb/2021.11/env/../include:${prefix}/mpi/2021.11//include:${prefix}/mkl/2024.0/include:${prefix}/ipp/2021.10/include:${prefix}/ippcp/2021.9/include:${prefix}/ipp/2021.10/include:${prefix}/dpl/2022.3/linux/include:${prefix}/dpcpp-ct/2024.0/include:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/include:${prefix}/dev-utilities/2024.0/include:${prefix}/cdal/2024.0/include:${prefix}/compiler/2024.0/lib/oclfpga/include:${prefix}/ccl/2021.11/include/cpu_gpu_dpcpp
#prepend-path CPATH ${prefix}/tbb/2021.11/env/../include:${prefix}/mkl/2024.0/include:${prefix}/ipp/2021.10/include:${prefix}/ippcp/2021.9/include:${prefix}/ipp/2021.10/include:${prefix}/dpl/2022.3/linux/include:${prefix}/dpcpp-ct/2024.0/include:${prefix}/dnnl/2024.0/cpu_dpcpp_gpu_dpcpp/include:${prefix}/dev-utilities/2024.0/include:${prefix}/cdal/2024.0/include:${prefix}/compiler/2024.0/lib/oclfpga/include:${prefix}/ccl/2021.11/include/cpu_gpu_dpcpp
&lt;/code>&lt;/pre>
&lt;h2 id="运行测试">运行测试&lt;/h2>
&lt;p>通过 &lt;code>module load&lt;/code> 命令加载环境变量&lt;/p>
&lt;pre>&lt;code class="language-bash">$ module load intel/oneapi2024.0
&lt;/code>&lt;/pre>
&lt;p>测试是否安装成功&lt;/p>
&lt;pre>&lt;code class="language-bash">$ icx -v
&lt;/code>&lt;/pre>
&lt;p>如果输出版本信息，则安装成功。&lt;/p>
&lt;pre>&lt;code class="language-bash">Intel(R) oneAPI DPC++/C++ Compiler 2024.0.2 (2024.0.2.20231213)
Target: x86_64-unknown-linux-gnu
Thread model: posix
InstalledDir: /opt/software/intel/oneapi2024.0/compiler/2024.0/bin/compiler
Configuration file: /opt/software/intel/oneapi2024.0/compiler/2024.0/bin/compiler/../icx.cfg
Found candidate GCC installation: /opt/rh/devtoolset-11/root/usr/lib/gcc/x86_64-redhat-linux/11
Selected GCC installation: /opt/rh/devtoolset-11/root/usr/lib/gcc/x86_64-redhat-linux/11
Candidate multilib: .;@m64
Candidate multilib: 32;@m32
Selected multilib: .;@m64
&lt;/code>&lt;/pre>
&lt;p>继续测试 MPI&lt;/p>
&lt;pre>&lt;code class="language-bash">$ mpirun --version
&lt;/code>&lt;/pre>
&lt;p>如果输出版本信息，则安装成功。&lt;/p>
&lt;pre>&lt;code class="language-bash">Intel(R) MPI Library for Linux* OS, Version 2021.11 Build 20231005 (id: 74c4a23)
Copyright 2003-2023, Intel Corporation.
&lt;/code>&lt;/pre>
&lt;h2 id="icx-说明">icx 说明&lt;/h2>
&lt;blockquote>
&lt;p>&lt;strong>Intel® oneAPI DPC++/C++ Compiler (icx)&lt;/strong> is Intel nextgen compiler based on Clang /LLVM technology plus Intel proprietary optimizations and code generation.&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Intel®, &lt;/span>&lt;a href="https://www.intel.cn/content/www/cn/zh/developer/articles/technical/adoption-of-llvm-complete-icx.html">&lt;cite>Intel® C/C&amp;#43;&amp;#43; Compilers Complete Adoption of LLVM&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>icx 是基于 Clang /LLVM 技术的 Intel 下一代编译器，加上 Intel 专有的优化和代码生成。&lt;/p>
&lt;p>LLVM 帮助实现了为英特尔架构提供更加优秀的 C/C++编译器这一目标。最新的英特尔 C/C++编译器使用 LLVM 架构，可提供更快的编译时间、更好的优化、增强的标准支持以及对 GPU 和 FPGA 负载转移（offloading）的支持。&lt;/p>
&lt;h3 id="采用-llvm-的好处">采用 LLVM 的好处&lt;/h3>
&lt;p>LLVM 开源项目是模块化和可重用的编译器和一系列工具链技术的集合，整个项目支持多种处理器架构和编程语言。Clang 开源项目提供了一个 C/C++前端，为 LLVM 项目支持了最新的语言标准。包括 Clang 在内，LLVM 是由一个庞大且非常活跃的开发社区维护的。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/v2-7ac93f64b283ba0b5c5371b7cd524210_1440w-2024-03-09.webp"
alt="v2-7ac93f64b283ba0b5c5371b7cd524210_1440w-2024-03-09" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>采用 LLVM 的好处有很多，第一条要说的是更快的构建时间。众所周知，Clang 是很快的！我们使用英特尔 oneAPI 2021.3 工具包中的英特尔 C/C++编译器时，测得构建时间减少了 14％。除了减少构建时间外，采用 Clang 使我们可以从社区支持最新 C++语言标准的一系列成果中受益，并贡献成果来反哺社区。&lt;/p>
&lt;p>英特尔为开源项目提供贡献和支持的历史颇为悠久，其中向 LLVM 做出贡献就有十年时间了。我们今天的主动合作行为包括了优化报告补充、扩大的浮点模型支持，以及向量增强。英特尔直接对 LLVM 项目做出贡献，也有一个临时区域（英特尔 LLVM 技术项目），针对 SYCL 支持。&lt;/p>
&lt;p>在英特尔架构上，英特尔 C/C++编译器预期能提供比基础 Clang+LLVM 编译器更高的性能。接下来英特尔 C/C++编译器都会是采用了 LLVM 开源基础架构的版本（icx）。我们会继续之前的长期努力，持续为 Clang 和 LLVM 项目做出贡献，包括为它们提供优化。并非所有的优化技术都会被上游采纳，有时是因为它们太新了，有时因为它们过于针对英特尔架构。这是可以预料的，并且与其他已经采用 LLVM 的编译器是同样的情况。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/v2-1a1672571e4a8a60c335e5abe38ee86b_1440w-2024-03-09.webp"
alt="v2-1a1672571e4a8a60c335e5abe38ee86b_1440w-2024-03-09" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>英特尔 C/C++编译器一直都在提供最优秀的性能。经典版本的英特尔 C/C++编译器取得了对 GCC 18％的优势，而基于 LLVM 的英特尔 C/C++编译器取得了 41％的优势。&lt;/p></description></item><item><title>笔记：Pure - 改进消息传递以更好地利用节点内的共享内存</title><link>https://cuterwrite.top/p/pure/</link><pubDate>Sun, 03 Mar 2024 01:16:00 +0000</pubDate><guid>https://cuterwrite.top/p/pure/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/crop_e9af4c445d695be5002248c7c814c67d195413-2024-03-04.webp" alt="Featured image of post 笔记：Pure - 改进消息传递以更好地利用节点内的共享内存" />&lt;h1 id="笔记pure-改进消息传递以更好地利用节点内的共享内存">笔记：Pure: 改进消息传递以更好地利用节点内的共享内存&lt;/h1>
&lt;h2 id="citation">Citation&lt;/h2>
&lt;p>James Psota and Armando Solar-Lezama. 2024. Pure: Evolving Message Passing To Better Leverage Shared Memory Within Nodes. In Proceedings of the 29th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming (&lt;strong>PPoPP &amp;lsquo;24&lt;/strong>). Association for Computing Machinery, New York, NY, USA, 133–146. &lt;a class="link" href="https://doi.org/10.1145/3627535.3638503" target="_blank" rel="noopener" >https://doi.org/10.1145/3627535.3638503
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/p>
&lt;h2 id="关键词">关键词&lt;/h2>
&lt;p>parallel programming models; distributed runtime systems; task-based parallelism; concurrent data structures; lock-free data structures&lt;/p>
&lt;h2 id="摘要">摘要&lt;/h2>
&lt;p>Pure 是一种新的编程模型和运行时系统，旨在在基于消息传递接口（增强使用任务利用空闲核心能力）的环境中充分利用节点内部的共享内存。Pure 通过两种方式利用共享内存：(1) 允许 rank 在等待消息到达时从彼此那里窃取工作；(2) 利用高效无锁的数据结构实现节点内各进程间高性能的消息传递和集合操作。研究者通过 micro benchmark 测试评估了 Pure 的关键消息传递和集合特性，并展示了在 CoMD 分子动力学和 miniAMR 自适应网格细化应用中，当扩展到 4096 个 rank 时，Pure 可实现高达 &lt;strong>2.1x&lt;/strong> 的应用加速。&lt;/p>
&lt;h2 id="1-引言">1. 引言&lt;/h2>
&lt;p>在过去的几十年里，高性能计算从大型向量机转向由单处理器机器组成的集群并通过网络连接。MPI 成为分布式内存机器上并行编程的标准方法。随着硬件发展为多核集群，节点内的核心共享内存并通过网络通信，社区一直在寻找新范式以更充分地利用现代集群。目前主要有两种方法：一是保持统一的 MPI 编程方法，改进 MPI 运行时系统以更好地利用共享内存；二是采用 MPI+X 等混合编程方法，在节点内部使用共享内存并行性，而在节点之间仍使用 MPI。&lt;strong>然而，这些方法要么可能受限于 MPI 标准对接口行为的规定而无法充分发挥性能，要么给程序员带来管理优化两个编程模型的挑战&lt;/strong>。&lt;/p>
&lt;p>社区已经尝试了许多其他方法，其中包括&lt;strong>PGAS&lt;/strong>模型，它提供了一种集群范围内的共享内存假象，以及诸如&lt;strong>Legion、Chapel&lt;/strong>和&lt;strong>X10&lt;/strong>等隐式并行编程语言，这些语言为程序员提供了更高级别的抽象，并试图自动有效地协调应用程序。尽管取得了进展且新方法不断涌现，但现代 HPC 应用中仍有相当一部分仍在使用 MPI。&lt;strong>MPC&lt;/strong>和&lt;strong>AMPI&lt;/strong>也同样将线程作为 MPI Rank，并努力利用内部的共享内存来提高性能。&lt;/p>
&lt;p>然而，仅使用 MPI 的方法往往胜过混合编程方法。这很大程度上可能由于接口的局限性以及无法充分利用节点内的共享内存，导致 MPI 未能发挥出很多潜在性能。因此，论文提出的 Pure 系统建立在 MPI-everywhere 方法之上，打破了一些 MPI 的假设，更有效地利用共享内存，同时不需要对程序进行重大重写。它是一个与 MPI 相似的编程模型，从而能够利用上 HPC 社区现有的 MPI 知识和现有应用程序基础。&lt;/p>
&lt;p>Pure 设计灵感来源于 MPI，其编程模型本质上是消息传递，并可选择性地利用任务。不过，Pure 打破了对使用进程级别 rank 以及支持旧版语言的限制，使用线程作为 rank 而不是进程，如此一来能够高效地运用轻量级、无锁同步机制，在同一节点内各线程间进行协调。基于线程化的 rank，Pure 构建了高效的节点内部集体操作功能，利用高效的无锁算法实现这一目标。此外，Pure 允许应用程序的部分并行代码块以标准 C++ lambda 表达式形式运行，这些表达式可以被拥有 rank 和其他空闲 rank 自动且并发地执行，所有这一切均由 Pure Runtime 运行时系统自动调度。将 Pure Runtime 运行时系统的职责扩展至包括可选的并发任务执行具有重要价值，因为它使得 Pure Runtime 运行时系统能够在无需程序员编排的情况下，高效地自动化重叠通信与计算过程。&lt;/p>
&lt;p>论文提出的优化策略包括：&lt;/p>
&lt;ul>
&lt;li>小消息和大数据消息都适用的无锁消息传递方法。&lt;/li>
&lt;li>用于实现集合通信算法的无锁数据结构。&lt;/li>
&lt;li>允许空闲线程从其他线程高效窃取工作的无锁任务调度器。&lt;/li>
&lt;/ul>
&lt;p>作者采用标准 C++库以确保广泛兼容性，并展示出相较于高度优化的 MPI 基准有显著的性能提升。同时，作者也证明了 Pure 编程模型在语义上与 MPI 相似，这意味着学习并从现有应用程序迁移至 Pure 十分直接简便，并且展示了源码到源码的转换工具 mpi2pure 。总的来说，论文的主要贡献如下：&lt;/p>
&lt;ol>
&lt;li>引入一种编程模型及运行时系统，它有效地整合了消息传递与任务并行性，利用标准 C++特性实现。&lt;/li>
&lt;li>展示了现代 C++如何帮助支持更灵活的并行运行时系统应用接口。&lt;/li>
&lt;li>描述了一种设计良好的无锁、多线程和分布式运行时系统，相比 MPI，在节点内部获得了显著的速度提升。&lt;/li>
&lt;li>证明仅需要对现有 MPI 应用程序进行最小程度的源代码修改，就能在 micro benchmark 测试和三个实际应用中获得相较于最先进的 MPI 实现的显著性能提升。&lt;/li>
&lt;/ol>
&lt;h2 id="2-pure-使用示例">2. Pure 使用示例&lt;/h2>
&lt;p>首先通过一个简单的示例程序来说明如何使用 Pure。尽管该应用程序是一个简单的 1-D stencil 算法，但通过这个例子可以展示出 Pure 的基本原理及其与 MPI 的共同之处，从而帮助开发者编写更复杂的应用程序。&lt;/p>
&lt;p>在 MPI 版本的实现代码 &lt;code>rand_stencil_mpi&lt;/code> 中，大部分计算工作集中在函数 &lt;code>random_work&lt;/code> 中执行。简单来说，&lt;code>rand_stencil_mpi&lt;/code> 函数首先会进入一个循环，迭代次数为 &lt;code>iters&lt;/code> ，在数组 &lt;code>a&lt;/code> 的每个元素上计算 &lt;code>random_work&lt;/code> 。值得注意的是，&lt;code>random_work&lt;/code> 执行的时间长度是可变且未知的，因此会引入负载不平衡。此外，&lt;code>random_work&lt;/code> 不会修改数组 &lt;code>a&lt;/code> 的内容，而是接着通过对相邻元素求平均值更新数组 &lt;code>a&lt;/code> 。最后，程序利用 &lt;code>MPI_Send&lt;/code> 和 &lt;code>MPI_Recv&lt;/code> 交换 &lt;code>temp&lt;/code> 数组的首尾元素，以便计算数组 &lt;code>a&lt;/code> 的首尾元素。由于 &lt;code>random_work&lt;/code> 所需时间长短不一，某些处理单元会提前完成任务，有时会在等待发送方较慢的 &lt;code>MPI_Recv&lt;/code> 调用时陷入阻塞状态。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/1D_stencil-2024-03-14.webp"
alt="1D_stencil-2024-03-14" width="auto" loading="lazy"/>
&lt;/figure>
&lt;div class="notice notice-info" >
&lt;div class="notice-title">&lt;svg t="1705940100069" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6252" width="200" height="200">&lt;path d="M512 64C264.6 64 64 264.6 64 512s200.6 448 448 448 448-200.6 448-448S759.4 64 512 64z m32 664c0 4.4-3.6 8-8 8h-48c-4.4 0-8-3.6-8-8V456c0-4.4 3.6-8 8-8h48c4.4 0 8 3.6 8 8v272z m-32-344c-26.5 0-48-21.5-48-48s21.5-48 48-48 48 21.5 48 48-21.5 48-48 48z" p-id="6253" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>示例 1：1-D Stencil with Random Work, MPI Version&lt;/p>&lt;/div>
&lt;pre>&lt;code class="language-cpp">void rand_stencil_mpi(double* const a, size_t arr_sz, size_t iters, int my_rank,
int n_ranks) {
double temp[arr_sz];
for (auto it = 0; it &amp;lt; iters; ++it) {
for (auto i = 0; i &amp;lt; arr_sz; ++i) {
temp[i] = random_work(a[i]);
}
for (auto i = 1; i &amp;lt; arr_sz - 1; ++i) {
a[i] = (temp[i - 1] + temp[i] + temp[i + 1]) / 3.0;
}
if (my_rank &amp;gt; 0) {
MPI_Send(&amp;amp;temp[0], 1, MPI_DOUBLE, my_rank - 1, 0, MPI_COMM_WORLD);
double neighbor_hi_val;
MPI_Recv(&amp;amp;neighbor_hi_val, 1, MPI_DOUBLE, my_rank - 1, 0, MPI_COMM_WORLD,
MPI_STATUS_IGNORE);
a[0] = (neighbor_hi_val + temp[0] + temp[1]) / 3.0;
} // ends if not first rank
if (my_rank &amp;lt; n_ranks - 1) {
MPI_Send(&amp;amp;temp[arr_sz - 1], 1, MPI_DOUBLE, my_rank + 1, 0,
MPI_COMM_WORLD);
double neighbor_lo_val;
MPI_Recv(&amp;amp;neighbor_lo_val, 1, MPI_DOUBLE, my_rank + 1, 0, MPI_COMM_WORLD,
MPI_STATUS_IGNORE);
a[arr_sz - 1] =
(temp[arr_sz - 2] + temp[arr_sz - 1] + neighbor_lo_val) / 3.0;
} // ends if not last rank
} // ends for all iterations
}
&lt;/code>&lt;/pre>
&lt;p>示例 2 则展示了实现同样功能的 Pure 版本。其中存在一些关键差异。首先，消息调用函数接口不同，使用的是相应的 Pure 消息传递函数 &lt;code>pure_send_msg&lt;/code> 和 &lt;code>pure_recv_msg&lt;/code> ，而非 MPI 调用，但参数实质上与 MPI 对应函数基本相同。Pure 的消息传递语义类似于 MPI：发送端缓冲区被复制到接收端缓冲区。实现区别主要在于：Pure 在&lt;strong>节点内部采用了轻量级的消息传递方法&lt;/strong>，从而在节点内的消息传递比 MPI 的延迟更低。&lt;/p>
&lt;div class="notice notice-info" >
&lt;div class="notice-title">&lt;svg t="1705940100069" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6252" width="200" height="200">&lt;path d="M512 64C264.6 64 64 264.6 64 512s200.6 448 448 448 448-200.6 448-448S759.4 64 512 64z m32 664c0 4.4-3.6 8-8 8h-48c-4.4 0-8-3.6-8-8V456c0-4.4 3.6-8 8-8h48c4.4 0 8 3.6 8 8v272z m-32-344c-26.5 0-48-21.5-48-48s21.5-48 48-48 48 21.5 48 48-21.5 48-48 48z" p-id="6253" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>示例 2：Pure 版本&lt;/p>&lt;/div>
&lt;pre>&lt;code class="language-cpp">void rand_stencil_pure(double* a, const int arr_sz, const int n_iter,
const int my_rank, const int n_ranks) {
double temp[arr_sz];
PureTask rand_work_task = [a, temp, arr_sz, my_rank](
chunk_id_t start_chunk, chunk_id_t end_chunk,
std::optinal&amp;lt;void&amp;gt; cont_params) {
auto [min_idx, max_idx] =
pure_aligned_idx_range&amp;lt;double&amp;gt;(arr_sz, start_chunk, end_chunk);
for (auto i = min_idx; i &amp;lt; max_idx; i++) {
temp[i] = random_work(a[i]);
}
}; // ends definding the Pure Task for rand_work_task
for (auto it = 0; it &amp;lt; n_iter; it++) {
rand_work_task.execute(); // execute all chunks of rank_work_task
for (auto i = 1; i &amp;lt; arr_sz - 1; ++i) {
a[i] = (temp[i - 1] + temp[i] + temp[i + 1]) / 3.0;
}
if (my_rank &amp;gt; 0) {
pure_send_msg(&amp;amp;temp[0], 1, MPI_DOUBLE, my_rank - 1, 0, PURE_COMM_WORLD);
double neighbor_hi_val;
pure_recv_msg(&amp;amp;neighbor_hi_val, 1, MPI_DOUBLE, my_rank - 1, 0,
PURE_COMM_WORLD);
a[0] = (neighbor_hi_val + temp[0] + temp[1]) / 3.0;
} // ends if not first rank
if (my_rank &amp;lt; n_ranks - 1) {
pure_send_msg(&amp;amp;temp[arr_sz - 1], 1, MPI_DOUBLE, my_rank + 1, 0,
PURE_COMM_WORLD);
double neighbor_lo_val;
pure_recv_msg(&amp;amp;neighbor_lo_val, 1, MPI_DOUBLE, my_rank + 1, 0,
PURE_COMM_WORLD);
a[arr_sz - 1] =
(temp[arr_sz - 2] + temp[arr_sz - 1] + neighbor_lo_val) / 3.0;
} // ends if not last rank
} // ends definding the Pure Task for rand_work_task
}
&lt;/code>&lt;/pre>
&lt;p>更重要的差异在于 Pure 中增加的 &lt;strong>Pure Task&lt;/strong> ，用带有一组特定参数定义的 lambda 表达式，其利用 lambda 的捕获参数特性，允许外部于 lambda 体内的变量以值或引用形式被捕获并在 lambda 执行时使用。Pure Task 可以被视为由 Pure Runtime 运行时系统负责执行应用程序代码片段，可以通过多线程并发执行。因此，Pure 任务应结构化为类似数据并行的形式。此外，PureTask 需要由程序员保证线程安全。&lt;/p>
&lt;p>在以上 Pure 实现中，程序员可以利用 chunk ranges 来描述并发性。这些子范围或 chunk 是通过 &lt;code>start_chunk&lt;/code> 和 &lt;code>end_chunk&lt;/code> 参数传递给 Pure Task 的，而它们是由 Pure Runtime 运行时系统提供。Pure Runtime 运行时系统负责确保所有工作顺利完成。由于可能涉及到不同的多个线程，Pure Runtime 运行时系统会通过追踪哪些 chunk 已分配和完成来实现这一点。&lt;/p>
&lt;p>其次，程序员需要将 Pure Runtime 运行时系统提供的 &lt;code>start_chunk&lt;/code> 和 &lt;code>end_chunk&lt;/code> 参数映射到与应用计算相关的具体内容上。在这里，代码使用了 &lt;code>pure_aligned_idx_range&lt;/code> 辅助函数将其转化为循环索引子范围。这个辅助函数考虑到了缓存行，所以有利于避免伪共享问题。&lt;/p>
&lt;p>由于 &lt;code>random_work&lt;/code> 引入了负载不平衡，因此某些 rank 不可避免地会等待其他 rank 发送消息。Pure 任务调度器自动利用这些空闲 rank ，在同一节点内执行待执行的 Pure 任务块。以下图中在同一节点内的三个 rank 为例：&lt;strong>rank 0&lt;/strong> 正在执行一个被划分为 6 个 chunks 的 Pure Task，而 &lt;strong>rank 1&lt;/strong> 和 &lt;strong>rank 2&lt;/strong> 因为接收消息而阻塞。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/timeline-2024-03-14.png"
alt="timeline-2024-03-14" width="auto" loading="lazy"/>&lt;figcaption>
&lt;h4>示例 Pure 代码的时间线示意图&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>可以观察到：&lt;/p>
&lt;ul>
&lt;li>rank 0 首先处理 chunk 0 。&lt;/li>
&lt;li>rank 1 窃取且并行执行 chunk 1 。&lt;/li>
&lt;li>Pure 任务调度器接着将 chunk 2 分配给 rank 0，把 chunk 3 分配给 rank 1 。&lt;/li>
&lt;li>rank 2 尝试窃取 task 并得到 chunk 4 。由于 &lt;code>random_work&lt;/code> 的随机特性，chunk 2 和 chunk 4 事实上是耗时较长的任务量。&lt;/li>
&lt;li>chunk 5 被分配给 rank 0，这部分任务量较小，以至于 rank 2 完成 chunk 4 之前就已经结束。&lt;/li>
&lt;li>调度器确保所有 chunks 都完成之前，rank 0 不会返回。这里直到 chunk 4 完成之后 rank 0 才会返回。&lt;/li>
&lt;li>当 rank 1 和 rank 2 还处于阻塞状态时，它们会继续尝试从任何其它 rank 中窃取更多的 chunks。&lt;/li>
&lt;li>由于 lambda 支持变量捕获，因此可以在不同 rank 之间高效共享上下文信息。&lt;/li>
&lt;/ul>
&lt;p>实验结果表明，在单节点上使用 32 个 rank 运行的 Pure 版本时，由于更快的消息传递速度和 Pure Task 的使用，Pure 版本相比 MPI 版本获得了 10% 的速度提升，并且在存在负载不均衡的情况下实现了超过 200% 的加速。尽管这些提升取决于负载不均衡的程度，但在实际应用中，Pure 也能取得类似的性能提升。这是因为 Pure Runtime 运行时系统能够自动识别并有效利用闲置计算资源。&lt;/p>
&lt;h2 id="3-编程模型">3. 编程模型&lt;/h2>
&lt;p>Pure 的编程模型可以概述为”带有可选任务的消息传递“。Pure 的消息传递和集合通信操作在语义上与 MPI 等效，只是存在一些语法上的细微差异。&lt;/p>
&lt;p>尽管在节点内使用了线程，Pure 的 rank 命名空间在整个节点间仍是非层级结构的。此外，在 Pure 程序的生命周期内，rank 的数量不会发生改变。&lt;/p>
&lt;p>Pure 采用 C++ 编写，并通过 SPMD 方式运行，其内部实现了多线程化。同一节点内的所有 rank 都是通过内核线程来实现。&lt;/p>
&lt;p>&lt;strong>Pure 应用程序并不支持全局变量&lt;/strong>，所以应当移除或者使用 thread_local 关键字来限制变量的作用域，从而保证线程安全。&lt;/p>
&lt;p>针对包含负载不均衡问题的应用程序，程序员可在满足以下条件的部分应用中使用 Pure Task：&lt;/p>
&lt;ol>
&lt;li>计算密集型热点区域&lt;/li>
&lt;li>可以被构造为并发执行&lt;/li>
&lt;/ol>
&lt;h3 id="消息传递和集合通信操作">消息传递和集合通信操作&lt;/h3>
&lt;p>Pure 消息传递中的 &lt;code>pure_send_msg&lt;/code> 和 &lt;code>pure_recv_msg&lt;/code> 函数与 MPI 中的 &lt;code>MPI_Send&lt;/code> 和 &lt;code>MPI_Recv&lt;/code> 函数类似。同时，Pure 也提供了非阻塞版本。&lt;/p>
&lt;p>Pure Runtime 运行时系统会保证消息最终会送达且按发送顺序交付。而且，Pure 还实现以下集合通信操作：&lt;/p>
&lt;ul>
&lt;li>Reduce&lt;/li>
&lt;li>All-Reduce&lt;/li>
&lt;li>Barrier&lt;/li>
&lt;li>Broadcast&lt;/li>
&lt;/ul>
&lt;p>除此之外，Pure 还设计了通信子的概念，可以通过 &lt;code>pure_comm_split&lt;/code> 函数将通信子分割为更小的子集。&lt;/p>
&lt;p>Pure 应用程序应当使用现代 C++ 编写，必须指定 &lt;code>std=c++11&lt;/code> 或更高版本来对其进行编译。Pure 的分发包中包含了一个基于 Make 的构建系统，其自动设置了恰当的编译器选项，并且链接好了 Pure Runtime 运行时系统，即 &lt;code>libpure&lt;/code> ，定义了一系列用于调试和性能分析的 Target。&lt;/p>
&lt;h3 id="pure-task">Pure Task&lt;/h3>
&lt;p>首先，Pure Task 允许程序员描述应用程序中的计算部分如何能够被分解为 chunks ，这些 chunks 可以由 Pure Runtime 运行时系统自动地并发执行。&lt;/p>
&lt;p>需要注意的是，Pure Task 并不是一个必须选项，只有当任务能被划分为多个小块且有助于解决负载不均衡问题时，才应该使用 Pure Task。&lt;/p>
&lt;p>其次，Pure Task 使用 C++ Lambda 表达式实现，并且拥有该任务的 rank 调用 &lt;code>execute&lt;/code> 方法时同步执行。任何给定的 rank 在同一时间内至多只能执行一个任务。由于 C++ Lambda 表达式支持变量捕获，因此可以高效地在执行任务不同 chunks 的不同 rank 之间共享上下文信息。通常情况下，同一个任务在应用程序运行过程中定义一次并多次执行，如科学应用中每一个时间步的迭代。&lt;/p>
&lt;p>再次，Pure Task 在定义时需要指定 chunk 的数量，以及来自应用程序的额外参数。任务间还必须避免依赖关系，但由于它们会在 &lt;code>execute&lt;/code> 调用期间完全执行，因此它们的执行不会与任务外部的代码发生竞争。&lt;/p>
&lt;p>此外，Pure Task 具有一个名为 &lt;code>execute&lt;/code> 的方法，该方法由应用程序代码调用，并接受一个 &lt;code>optional&amp;lt;void*&amp;gt; per_exe_args&lt;/code> 参数，运行时将其传递给任务进行每一次的调用。当任务主体的输入值在连续执行任务时发生变化时，这个功能会非常有用。例如，程序员可以在堆栈上定义一个局部结构体，并将指向它的指针传递给 &lt;code>execute&lt;/code> 方法。&lt;/p>
&lt;p>另外，Pure Task 的前两个参数是无符号整数 &lt;code>start_chunk&lt;/code> 和 &lt;code>end_chunk&lt;/code> ，用于指定要执行的 chunk 的范围。chunk 参数则由 Pure Runtime 运行时系统分配以确保所有 chunks 仅被精确地执行一次，即使这些 chunks 可能同时并发执行且乱序。&lt;/p>
&lt;p>值得一提的是，Pure Task 使用 chunk 范围赋予调度程序灵活性，以便一次性分配多个 chunk。chunks 数量由 Pure 任务调度器决定，但是不会超过 Makefile 文件中定义的 &lt;code>PURE_MAX_TASK_CHUNKS&lt;/code> 。&lt;/p>
&lt;p>除此之外，当前实现的接口需要手动将 chunk 编号转换为数组索引，这对于多维数组来说这项工作尤为繁琐。因此作者的目标是扩展当前接口，提供更简洁、更高级的接口，类似于 TBB 的 &lt;code>parallel_for&lt;/code> 。&lt;/p>
&lt;p>最后，程序员需要确保在 Pure Task 定义内部的实现线程安全，以防止同一任务的多个并发执行的 chunk 相互竞争。在后续的 CoMD 分子动力学 Benchmark 中，就不得不处理多个线程同时写入同一内存位置的问题，因此需要使用 &lt;code>std::atomic&lt;/code> 数组代替 &lt;code>int&lt;/code> 数组。&lt;/p>
&lt;h2 id="4-运行时系统">4. 运行时系统&lt;/h2>
&lt;p>Pure 的运行时系统实现为一个多线程和分布式运行时的动态库。Pure 应用程序开发时需要引入 &lt;code>pure.h&lt;/code> 头文件，并使用 C++17 编译选项构建，然后链接 &lt;code>libpure&lt;/code> 库。Pure 运行时系统会自动寻找并透明地利用计算与通信的重叠机会，这通常发生在高延迟通信事件期间。&lt;/p>
&lt;p>总的来说，Pure 运行时系统的职责为：&lt;/p>
&lt;ul>
&lt;li>创建并绑定必要的进程以及线程，启动应用程序。&lt;/li>
&lt;li>管理节点内各个 rank 之间的通信和集合操作。&lt;/li>
&lt;li>管理内部的内存缓冲区和数据结构。&lt;/li>
&lt;li>如果定义了 Pure Task，则需要负责调度和执行这些任务。&lt;/li>
&lt;/ul>
&lt;h3 id="rank-初始化与映射">Rank 初始化与映射&lt;/h3>
&lt;p>Pure rank 作为 MPI 进程的内核线程实现。在内部机制上，Pure 在多节点应用中运行 MPI 以支持跨节点通信，而在单节点运行时则完全不使用 MPI ，但 Pure 应用程序不能直接调用 MPI 函数。Pure 程序可通过 Makefile 配置，使其在一个节点或 NUMA 节点上运行一个 MPI 进程，并按每个节点或 NUMA 节点的核心数来运行相同数量的线程。应用程序程序员只知道非层次结构的 rank 命名空间，而节点、线程、MPI 进程、可变延迟等概念均被抽象化，对程序员不可见。&lt;/p>
&lt;p>类似于 MPI ，Pure 支持任意方式将 rank 映射到节点上。默认情况下，Pure 采用 SMP 风格的分配策略放置 rank ，但同时支持任意 rank 到节点再到核心的映射。Pure 还支持 CrayPAT 的 rank 重排文件。虽然这些层次化的硬件细节从程序员角度看已被抽象，但 Pure 在内部会利用这些信息优化关键功能。&lt;/p>
&lt;p>当 Pure 应用程序启动时，并不会直接调用应用程序原始的 &lt;code>main&lt;/code> 函数。底层的 MPI 程序包含了定义在 Pure 运行时系统中的 &lt;code>main&lt;/code> 函数。这个函数首先初始化 Pure 核心的数据结构，然后 fork 并绑定线程，这些线程各自运行一个 &lt;code>original_main&lt;/code> 函数，这是从应用程序代码中原始 &lt;code>main&lt;/code> 函数的改名版本。当应用程序完成执行后，该应用程序的 &lt;code>__original_main&lt;/code> 函数返回至 Pure 运行时系统，后者接着完成 MPI 的终止过程，清理资源。&lt;/p>
&lt;h3 id="spin-steal-waiting-loop-ssw-loop">Spin-Steal Waiting Loop (SSW-Loop)&lt;/h3>
&lt;p>当 Pure rank 遇到阻塞事件，例如等待消息到达时，它必须进行等待。然而，在 Pure 中，它会执行&lt;strong>自旋、窃取等待循环（SSW-Loop）&lt;/strong>，而非简单地放弃或空闲等待。这个循环会检查阻塞条件，例如消息是否已到达，如若未到达，则尝试窃取其它 rank 的任务。若该被阻塞的 rank 能够帮助其进程中恰好处于并发执行状态的其它线程完成任务，那么就会进行协助。&lt;/p>
&lt;p>鉴于线程固定在 CPU ，并且每个 rank 仅运行一个应用程序，我们选择主动进行自旋等待而非让出 CPU 。SSW-Loop 使得计算中的 rank 具备“多态性”，一方面既要作为主程序的计算节点，另一方面也要协助其它 rank 执行窃取到的任务 chunk ，然后再检查其自身所关注的阻塞事件。&lt;/p>
&lt;p>Pure 采取优先处理 rank 拥有的窃取到的任务负载的策略，遵循以任务负载优先的调度策略。&lt;/p>
&lt;p>相对于利用辅助线程来实现工作负载窃取或通信的系统，Pure 的独特之处在于由应用级别的计算节点直接执行窃取操作。&lt;/p>
&lt;h3 id="实现复杂度">实现复杂度&lt;/h3>
&lt;p>Pure 使用 C++17 标准库进行编写。Pure 运行时系统包含 21,000 行源代码，而 Pure 工具则另外包含大约 14,000 行源代码。Pure 已经在笔记本电脑和集群上进行了测试，所需环境仅为支持 C++17 的编译器、类 Unix 操作系统以及 MPI 。Pure 的源代码可从 &lt;a class="link" href="https://github.com/psota/pure" target="_blank" rel="noopener" >https://github.com/psota/pure
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
获取。&lt;/p>
&lt;h3 id="点对点通信">点对点通信&lt;/h3>
&lt;p>Pure 实现了阻塞和非阻塞的点对点消息传递，语义上等同于 MPI 的消息传递。&lt;/p>
&lt;p>在 Pure 内部，消息传递有三种不同的策略，具体采用哪种方法取决于消息的大小以及发送方和接收方是否位于同一节点内。&lt;/p>
&lt;p>对于整个生命周期，Pure 会分配一个持久存在的 Channel 对象，该对象存储在运行时系统中并会在整个程序中复用。内部 Channel Manager 会将消息参数映射到合适的数据结构，按需创建。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/strategy-2024-03-15.webp"
alt="strategy-2024-03-15" width="auto" loading="lazy"/>&lt;figcaption>
&lt;h4>Pure 消息传递策略&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;ul>
&lt;li>对于同一节点内的短消息（&amp;lt;8KB）
&lt;ul>
&lt;li>实现了一种带有 acquire-release 内存语义的无锁循环队列。发送线程在空间可用时将消息复制到 PureBufferQueue（PBQ）中，接收线程在消息可用时将其拷贝出来。
&lt;ul>
&lt;li>在短消息传递中，拷贝的开销相对较小，这样可以让发送方调用返回后立即执行执行其它有用的工作。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>两个线程均采用 SSW-Loop 进行等待，尽可能地实现计算与通信的自动重叠。&lt;/li>
&lt;li>使用一个连续的缓冲区来存储所有消息的 slot ，并通过简单指针算术使其每个 slot 对齐缓存行边界，以避免写入的发送线程与读取的接收线程之间产生伪共享。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>对于同一节点内的大消息（&amp;gt;=8KB）
&lt;ul>
&lt;li>采取类似于 PBQ 的策略，但采用从发送方直接到接收方的单次内存拷贝，灵感来源于 MPI 的 rendezvous 模式。&lt;/li>
&lt;li>无锁的固定大小循环缓冲区来存储接收方的接收调用参数，&lt;/li>
&lt;li>发送方通过 SSW-Loop 等待元数据队列项，然后直接将消息有效负载复制到接收方期望的缓冲区中。发送方通过插入传输的字节数量到不同的无锁队列中，以此通知接收方完成传输。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>不同节点间的消息
&lt;ul>
&lt;li>透明地调用 MPI 接口&lt;/li>
&lt;li>在 Pure 初始化期间使用分布式一致性算法创建一个 &lt;code>thread-rank-process-node&lt;/code> 映射数据结构，用于将 Pure rank 转换为给定通信器内的 MPI rank。&lt;/li>
&lt;li>为了确保接收节点上的正确接收线程接收到对应消息，需要在 &lt;code>MPI_TAG&lt;/code> 中编码发送线程号和接收线程号以解决多线程路由问题。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="集合通信">集合通信&lt;/h3>
&lt;p>Pure 中的集体通信操作语义与 MPI 等效，且在节点内采用自下而上构建的数据结构实现。尽管跨节点使用 MPI 集合操作，但在单节点和多节点基准测试中仍实现了显著的速度提升。&lt;/p>
&lt;p>Pure 的方案是有一个领导者线程（leader）协调集体过程，利用其它线程协助计算并按需调用 MPI 集合函数。&lt;/p>
&lt;ul>
&lt;li>Pure 采用静态领导者选举方法，优于基于比较和交换的“首先进入”方法。&lt;/li>
&lt;/ul>
&lt;p>以下仅以 All-Reduce 为例子，其它集合通信操作思想类似。&lt;/p>
&lt;p>对于小数据的 All-Reduce 操作，Pure 设计了名为 Sequenced Per-Thread Dropbox (SPTD) 的并发数据结构，提供了一种高效的无锁机制，用于在领导线程和其他非领导线程之间对偶同步和可选共享数据。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/SPTD-2024-03-15.webp"
alt="SPTD-2024-03-15" width="auto" loading="lazy"/>&lt;figcaption>
&lt;h4>Sequenced Per-Thread Dropbox (SPTD)&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>该方法借鉴了 flat-combinding 技术，将通信器中的线程 0 作为领导者线程。&lt;/p>
&lt;ul>
&lt;li>对于大小不超过 2KB 的数组
&lt;ul>
&lt;li>首先每个非领导者线程将其数据复制到 SPTD 中，然后与领导者线程一对一同步以表明其输入值已准备就绪（使用原子序列号，而不是共享原子计数器）。&lt;/li>
&lt;li>领导者线程执行针对所有输入数组的逐元素 Reduce 计算。&lt;/li>
&lt;li>每个节点上的领导者线程利用 &lt;code>MPI_Allreduce&lt;/code> 函数对该节点内的 Reduce 结果进一步进行全局 Reduce 。&lt;/li>
&lt;li>领导者线程进行同步，各个非领导者线程将最终 Reduce 值分别拷贝到各自的私有结果缓冲区。&lt;/li>
&lt;li>所有线程在等待时会进行 SSW-Loop 操作。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>对于大小超过 2KB 的数组，实际的 Reduce 计算开始成为性能瓶颈，因而需要尽可能利用所有线程并发执行 Reduce 计算，并通过共享内存直接从每个线程的输入输出缓冲区拉取数据或将 Reduce 结果写入缓冲区。
&lt;ul>
&lt;li>Reduce 工作被划分为大致相等的块，避免伪共享并实现向量化计算。&lt;/li>
&lt;li>线程使用 SPTD 报告消息已准备就绪，并通过原子序列号指示计算完成。&lt;/li>
&lt;li>领导者线程使用 &lt;code>MPI_Allreduce&lt;/code> 执行跨节点 All-Reduce 操作，并通过另一个原子序列号传播最终 Reduce 后的值。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="任务调度器">任务调度器&lt;/h3>
&lt;p>Pure 运行时系统会在共享内存中维护一个名为 &lt;code>active_tasks&lt;/code> 的数组，其中包含指向正在执行任务的原子指针，每节点每个 rank 有一个条目，并初始化为 &lt;code>nullptr&lt;/code> 。当一个任务被执行时，运行时会初始化相应的状态并以原子方式更新拥有该任务的 rank 在 &lt;code>active_tasks&lt;/code> 中的条目。当 &lt;code>active_tasks&lt;/code> 包含非空指针时，它向其他线程表明这个任务是“可供窃取的”。&lt;/p>
&lt;p>当任务被初始化后，拥有该任务的 rank 开始执行多个 chunk ，其他线程在其 SSL-Loop 期间探测 &lt;code>active_tasks&lt;/code> ，通过原子加载操作寻找非空条目。&lt;/p>
&lt;p>任务的 chunk 始终由拥有者 rank 及其可能的窃取者 rank 执行。两个原子整数值 &lt;code>curr_chunk&lt;/code> 和 &lt;code>chunks_done&lt;/code> 驱动着整个并发执行过程。owner rank 和 thief ranks 运行相同的并发执行函数，尽管窃取者线程只执行一个 chunk 然后返回，而拥有者线程会一直执行直到所有 chunk 完成。线程使用 &lt;code>fetch_add&lt;/code> 确定要执行哪个 chunk ，但如果其值已大于总 chunk 数量，则它们会返回。&lt;/p>
&lt;p>线程还会在成功完成任何 chunk 时原子性地增加 &lt;code>chunks_done&lt;/code> 的值；拥有者线程仅将其本地存储以避免缓存未命中。最后，拥有者 rank 等待直至所有 chunk 都执行完毕。&lt;/p>
&lt;p>值得注意的是，任务的 chunk 与应用程序 rank 在同一硬件线程上执行；每一个硬件线程都分配给 Pure 应用的 rank 。目前 Pure 尚不利用硬件加速器硬件（例如 GPU）来加速任务执行，但作者相信 Pure 架构能够支持这一点。&lt;/p>
&lt;p>Pure 任务调度器具有不同的 chunk 执行模式和窃取算法。例如，作者实现了单 chunk 模式和一种引导式自调度模式，这是一种工作划分算法，按照先分配（窃取）较大的工作块，随后分配（窃取）较小的工作块的方式进行。&lt;/p>
&lt;p>任务调度器还具有 NUMA 感知窃取模式（优先从同一 NUMA 节点上的受害者线程窃取任务）以及一种“黏性”窃取模式，窃取者线程会返回它们最近窃取且仍处于活跃状态的任务。&lt;/p>
&lt;h2 id="评估">评估&lt;/h2>
&lt;p>评估实验采用的 HPC 集群是伯克利的 NERSC Cori，一共 2388 个节点，每个节点有 2 个插槽，16 核心 128GB 内存，节点互联使用了 Cray Aires。然后开启了超线程，采用了 256 位的向量宽度，实验在每个节点运行 2 个进程，32 个线程。工具链则使用的是 Intel 编译器，以及高度优化的 Cray MPICH 作为 baseline。&lt;/p>
&lt;h3 id="nas-dt-基准测试">NAS DT 基准测试&lt;/h3>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/nasdt-2024-03-15.webp"
alt="nasdt-2024-03-15" width="auto" loading="lazy"/>
&lt;/figure>
&lt;ul>
&lt;li>只采用更快的消息传递，则有 11%至 25%的加速比&lt;/li>
&lt;li>引入 PureTasks，则能达到 1.7 倍到 2.6 倍的加速比。&lt;/li>
&lt;li>辅助线程能小幅提高性能，不过仅限于剩余未使用的 CPU 核心才能使用。在这里，除了 80 个 rank 的情况下空闲了 24 个核心，其它情况下都充分利用了 CPU 核心。&lt;/li>
&lt;/ul>
&lt;h3 id="comd-和-miniamr-基准测试">CoMD 和 miniAMR 基准测试&lt;/h3>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/benchmark-pure-2024-03-15.webp"
alt="benchmark-pure-2024-03-15" width="auto" loading="lazy"/>
&lt;/figure>
&lt;ul>
&lt;li>在 CoMD 分子动力学应用上，如果没有负载不均衡的情况，可以看到 Pure 的性能在各个 rank 数下都优于 MPI 以及 MPI+OpenMP 的性能，分别达到 7%至 25%，以及 35%至 50%的加速比&lt;/li>
&lt;li>在 miniAMR 自适应网格细化应用中，则实现了最少 20%，最多 50%的加速比。&lt;/li>
&lt;/ul>
&lt;h3 id="集合通信性能">集合通信性能&lt;/h3>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/benchmark-pure-msg-2024-03-15.webp"
alt="benchmark-pure-msg-2024-03-15" width="auto" loading="lazy"/>
&lt;/figure>
&lt;h2 id="相关工作">相关工作&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">类别&lt;/th>
&lt;th style="text-align:left">相关工作&lt;/th>
&lt;th style="text-align:left">Pure 的优势&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">MPI&lt;/td>
&lt;td style="text-align:left">1. 利用多核节点内的共享内存提高性能；2. XPMEM 显著提升节点内性能； 3. ch4 网络库改进了 MPI 的共享内存性能；4. 优化 MPI 集合通信；5. MPI DMAPP 库优化集合通信，但仅支持部分集合和 8B 负载；6. 优化大规模全对全集合通信；7. MPI 单边消息 API 解耦；8. 数据移动和进程同步&lt;/td>
&lt;td style="text-align:left">1. 为利用共享内存做了大量工作，但 Pure 在所有集合和负载大小上都很快；2. 单边消息 API 提供了通信计算重叠的机制，但 Pure 提供了更高层的机制&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">MPI 多线程&lt;/td>
&lt;td style="text-align:left">1. 通过 MPI_THREAD_MULTIPLE 模式支持 rank 内多线程； 2. 大多数 MPI 实现使用全局锁来支持线程安全，导致线程序列化；3. MPI 4.0 标准通过 MPI+X 方法加强了对多线程的支持；4. MPI Fine-points 和 MPI Endpoints 引入了线程和 MPI+X 的概念&lt;/td>
&lt;td style="text-align:left">1. 程序员认为在多线程代码中进行 MPI 调用很重要；2. MPI+X 方法的性能和可编程性尚不清楚；3. 与 MPI+OpenMP 相比，Pure 允许程序员使用统一的编程模型，在需要的地方引入任务&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">AMPI&lt;/td>
&lt;td style="text-align:left">1. 基于 Charm++构建的 MPI 兼容库；2. 提供了更高层次的并行编程抽象；3. 通过最小的源代码更改提供性能提升&lt;/td>
&lt;td style="text-align:left">1. Pure 在实验中优于 AMPI，可能是由于优化的消息传递和集合，以及更细粒度和低开销的负载均衡；2. AMPI SMP 也是基于线程的，但需要每个节点至少一个工作线程&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">PGAS 语言和并行框架&lt;/td>
&lt;td style="text-align:left">1. PGAS 语言提供全局内存地址空间的抽象；2. Chapel 和 X10 扩展了 PGAS 方法，支持本地和远程异步任务创建；3. HPX 扩展了现代 C++标准以支持分布式操作；4. Legion 是一种数据中心并行编程系统；5. Kokkos, STAPL, BCL 等框架在应用程序和机器之间提供抽象层&lt;/td>
&lt;td style="text-align:left">1. 与 Pure 类似，PGAS 模型采用 SPMD 编程风格，提供统一的编程模型，并通过引用局部性提高性能；2. 这些框架 通常利用现代 C++特性，但使用它们通常需要对现有应用程序进行重大重写&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>数十年来，由于其相对的简单性和性能优势，消息传递一直被视为并行编程的标准模型。然而，本文表明，消息传递与共享内存并非不可兼容。实际上，通过设计合适的库，可以在不牺牲大多数消息传递优点的前提下充分利用共享内存。&lt;/p></description></item><item><title>科研图表绘制</title><link>https://cuterwrite.top/p/science-plot/</link><pubDate>Tue, 27 Feb 2024 00:14:00 +0000</pubDate><guid>https://cuterwrite.top/p/science-plot/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/crop_ee40c9cb9e33ffe888365e66e0a104dc195413-2024-02-28.webp" alt="Featured image of post 科研图表绘制" />&lt;h1 id="科研图表绘制">科研图表绘制&lt;/h1>
&lt;h2 id="前置知识">前置知识&lt;/h2>
&lt;h3 id="位图">位图&lt;/h3>
&lt;p>又称为点阵图像、像素图或栅格图像，由像素点组成。这些点可以进行不同的排列和染色以构成图像。&lt;/p>
&lt;p>&lt;strong>位图特点&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>位图图像善于重现颜色的细微层次，能够制作出色彩和亮度变化丰富的图像，颜色逼真，文件庞大，不能随意缩放；&lt;/li>
&lt;li>图像尺寸越大，文件也就越大；图像色彩越丰富，文件也就越大。&lt;/li>
&lt;li>打印和输出的精度是有限的；&lt;/li>
&lt;li>&lt;strong>位图的文件格式&lt;/strong>：比如.tiff、.bmp、.gif、.jpg、.png、.psd 等。&lt;/li>
&lt;li>&lt;strong>常用的位图编辑软件&lt;/strong>：Photoshop 等。&lt;/li>
&lt;/ul>
&lt;h3 id="矢量图">矢量图&lt;/h3>
&lt;p>&lt;strong>矢量&lt;/strong>又称为“向量”，矢量图像中的图形元素（点和线段）称为对象，每个对象都是一个单独的个体，它具有大小、方向、轮廓、颜色和屏幕位置等属性。简单地说，矢量图形软件就是用数学的方法来绘制矩形等基本形状的。&lt;/p>
&lt;p>&lt;strong>矢量图特点&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>可以无限放大，同时又不用担心失真；&lt;/li>
&lt;li>矢量图可以轻松地转化为位图，而位图转化为矢量图就需要通过图像临摹之类的方式，但完美转成矢量图还是有些难度。&lt;/li>
&lt;li>&lt;strong>矢量图的文件格式&lt;/strong> ：比如 Adobe Illustrator 的.AI、.EPS、.SVG，.PDF，AutoCAD 的.dwg 和.dxf，windows 标准图元文件*.wmf 和增强型图元文件*.emf 等。&lt;/li>
&lt;li>&lt;strong>常用的矢量图编辑软件&lt;/strong>：Illustrator、CorelDraw、AutoCAD 等。&lt;/li>
&lt;/ul>
&lt;h3 id="像素dpi-与打印尺寸之间的关系">像素、DPI 与打印尺寸之间的关系&lt;/h3>
&lt;p>图像分辨率，像素数和打印尺寸在数学上的关系为：像素=分辨率（DPI）× 打印尺寸（以英寸为单位）。&lt;/p>
&lt;p>其中，DPI 为每平方英寸像素数目，也就是图像细节程度的度量。理解了上述概念我们就可以通过上述概念推测出图像的尺寸大小，比如说，我想打印一副 8 英寸 * 10 英寸，300DPI 的图片，那么怎样设置图像的像素长宽度呢？你只要简单地把这两者相乘就可以了，$8 \times 300=2400$ ，$10 \times 300=3000$ ，所以这幅图像的像素尺寸就是 $2400 \times 3000$ 。&lt;/p>
&lt;h3 id="杂志要求">杂志要求&lt;/h3>
&lt;p>这里以著名出版商&lt;a class="link" href="https://www.elsevier.com/authors/author-schemas/artwork-and-media-instructions/artwork-sizing" target="_blank" rel="noopener" >艾斯维尔（Elsevier）的要求
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
为例：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">TARGET SIZE&lt;/th>
&lt;th style="text-align:center">Image Width&lt;/th>
&lt;th style="text-align:center">Pixels at 300 dpi&lt;/th>
&lt;th style="text-align:center">Pixels at 500 dpi&lt;/th>
&lt;th style="text-align:center">Pixels at 1000 dpi&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">Minimal size&lt;/td>
&lt;td style="text-align:center">30 mm (85 pt)&lt;/td>
&lt;td style="text-align:center">354&lt;/td>
&lt;td style="text-align:center">591&lt;/td>
&lt;td style="text-align:center">1181&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">Single column&lt;/td>
&lt;td style="text-align:center">90 mm (255 pt)&lt;/td>
&lt;td style="text-align:center">1063&lt;/td>
&lt;td style="text-align:center">1772&lt;/td>
&lt;td style="text-align:center">3543&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1.5 column&lt;/td>
&lt;td style="text-align:center">140 mm (397 pt)&lt;/td>
&lt;td style="text-align:center">1654&lt;/td>
&lt;td style="text-align:center">2756&lt;/td>
&lt;td style="text-align:center">5512&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">Double column (full width)&lt;/td>
&lt;td style="text-align:center">190 mm (539 pt)&lt;/td>
&lt;td style="text-align:center">2244&lt;/td>
&lt;td style="text-align:center">3740&lt;/td>
&lt;td style="text-align:center">7480&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>通过学习上面图像尺寸的内容我们可以知道打印尺寸与像素和 dpi 之间的关系。例如，表格中红色要求图像最小尺寸为 $30 \mathrm{mm}$ ，我们可以通过公式验证一下在 300dpi 分辨率下 354 像素宽打印出来的尺寸是不是 $30 \mathrm{mm}$ ：$354 \div 300 \times 2.54 \times 10 = 29.97 \mathrm{mm}$ ， 最后相乘的两个数据是把英寸换算成毫米，正好是 $30 \mathrm{mm}$ 。所以知道了上述关系我们就可以利用 Photoshop 来编辑我们的图片了；&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/attachments-2018-07-4Fzft7fc5b5ace58ae9dd-2024-02-28.webp"
alt="attachments-2018-07-4Fzft7fc5b5ace58ae9dd-2024-02-28" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>例如一张图片，来自于 Mapman，用 Photoshop 打开，显示尺寸如下：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/attachments-2018-08-ZdVKUJMx5b63ec8d64919-2024-02-28.webp"
alt="attachments-2018-08-ZdVKUJMx5b63ec8d64919-2024-02-28" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>由于图片尺寸太大，宽度 $124.99 \mathrm{cm}$ ，而且分辨率是 $72$ ，不符合杂志要求。这里利用上面学到的知识在不损失图片像素的情况下调整一下图片尺寸；&lt;/p>
&lt;p>现在我们要把图片宽度调整到双栏的尺寸也就是 $19\mathrm{cm}$ ；通过公式：像素=分辨率（DPI）× 打印尺寸（以英寸为单位）&lt;/p>
&lt;p>在像素不变的情况下，我们要提高分辨率，来缩小图片的打印尺寸，根据比例计算应该提高到多少 dpi： $124.99 \div 19 \times 72=473.6 \mathrm{dpi}$ ；&lt;/p>
&lt;p>所以修改宽度和分辨率这两个数值就可以了，而且图片的像素数是不变的，达到了无损改变图片的大小；而且 473dpi 大于最小的 300dpi。&lt;/p>
&lt;h2 id="matplotlib-python-库">Matplotlib Python 库&lt;/h2>
&lt;p>作为 Python 生态中最基础且最广泛使用的数据可视化库，Matplotlib 提供了丰富的 2D 和 3D 图形绘制能力，尤其适合制作线图、柱状图、散点图等常见科研图表，并能高度定制化输出样式以符合各类学术期刊的标准。&lt;/p>
&lt;p>它可以用来绘制各种静态，动态，交互式的图表。我们可以使用该工具将很多数据通过图表的形式更直观的呈现出来，包括绘制线图、散点图、等高线图、条形图、柱状图、3D 图形、甚至是图形动画等等。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/matplotlib-graphs-2048x1153-2024-02-28.webp"
alt="matplotlib-graphs-2048x1153-2024-02-28" width="auto" loading="lazy"/>
&lt;/figure>
&lt;hr>
&lt;ul>
&lt;li>Matplitlib Cheat Sheet&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/cheatsheets-1-2024-02-28.webp"
alt="cheatsheets-1-2024-02-28" width="auto" loading="lazy"/>
&lt;/figure>
&lt;h2 id="seaborn-python-库">Seaborn Python 库&lt;/h2>
&lt;p>构建于 Matplotlib 之上，Seaborn 进一步强化了统计图表的功能，它内置了许多高级统计图表样式，如热力图、箱型图和时间序列分析图表，使复杂数据关系的展现更为直观易读。既然是基于 matplotlib，所以 seaborn 的很多图表接口和参数设置与其很是接近，使得作图更加方便快捷。即便是没有什么基础的人，也能通过极简的代码，做出具有分析价值而又十分美观的图形。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/Seaborn-gallery-2024-02-28.webp"
alt="Seaborn-gallery-2024-02-28" width="auto" loading="lazy"/>
&lt;/figure>
&lt;hr>
&lt;ul>
&lt;li>Seaborn Cheat Sheet
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/Python_Seaborn_Cheat_Sheet_q074wv-2024-02-28.webp"
alt="Python_Seaborn_Cheat_Sheet_q074wv-2024-02-28" width="auto" loading="lazy"/>
&lt;/figure>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;ul>
&lt;li>优秀教程：&lt;a class="link" href="https://zhuanlan.zhihu.com/p/81553421" target="_blank" rel="noopener" >数据可视化，Seaborn 画图原来这么好看
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/li>
&lt;/ul>
&lt;h2 id="visio-矢量图软件框架流程绘制与算法结构">Visio 矢量图软件（框架流程绘制与算法结构）&lt;/h2>
&lt;p>对于非数据密集型但逻辑严密的图表设计，如实验流程图、系统架构图或算法流程图，Microsoft Visio 凭借其强大的矢量编辑能力和海量预设模板，成为了构建清晰、规范流程图的理想选择。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/data-graphics-2024-02-28.webp"
alt="data-graphics-2024-02-28" width="auto" loading="lazy"/>
&lt;/figure>
&lt;h2 id="origin-矢量图软件数学分析与函数绘制">Origin 矢量图软件（数学分析与函数绘制）&lt;/h2>
&lt;p>Origin 是由 OriginLab 公司开发的一个科学绘图、数据分析软件，支持在 Microsoft Windows 下运行。Origin 支持各种各样的 2D/3D 图形。Origin 中的数据分析功能包括统计，信号处理，曲线拟合以及峰值分析。Origin 中的曲线拟合是采用基于 Levernberg-Marquardt 算法（LMA）的非线性最小二乘法拟合。Origin 强大的数据导入功能，支持多种格式的数据，包括 ASCII、Excel、NI TDM、DIADem、NetCDF、SPC 等等。图形输出格式多样，例如 JPEG，GIF，EPS，TIFF 等。内置的查询工具可通过 ADO 访问数据库数据。&lt;/p>
&lt;p>在物理、化学、生物等领域享有盛誉，Origin 专为科研数据分析打造，以其强大的数学分析和函数绘制能力著称，特别适用于绘制精密的信号曲线、频谱分析图和其他复杂科研图形。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/Picture1_revised%20text-2024-02-28.webp"
alt="Picture1_revised text-2024-02-28" width="auto" loading="lazy"/>
&lt;/figure>
&lt;h2 id="aiadobe-illustrator矢量图软件">AI（Adobe Illustrator）矢量图软件&lt;/h2>
&lt;p>作为行业标准级矢量图形处理软件，Illustrator 不仅适用于高精度的出版级图表设计，还能创建高质量的科学插图，确保在任何尺寸下都能保持清晰细腻的效果。它是一种应用于出版、多媒体和在线图像的工业标准矢量插画的软件。该软件主要应用于印刷出版、海报书籍排版、专业插画、多媒体图像处理和互联网页面的制作等，也可以为线稿提供较高的精度和控制，适合生产任何小型设计到大型的复杂项目。&lt;/p>
&lt;p>在图表绘制中，主要应用在：直接绘图-计科和控制类的用的很少，有生化环材方向的同学利用 AI 实现细胞结构，心室高亮等操作；整合之前导出的单个矢量图；将非矢量图转化为矢量图&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/attachments-2018-07-NTyyj78C5b500737d0ac8-2024-02-28.webp"
alt="attachments-2018-07-NTyyj78C5b500737d0ac8-2024-02-28" width="auto" loading="lazy"/>
&lt;/figure>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/attachments-2018-07-Mz7UCtYZ5b500821eb556-2024-02-28.webp"
alt="attachments-2018-07-Mz7UCtYZ5b500821eb556-2024-02-28" width="auto" loading="lazy"/>
&lt;/figure>
&lt;h2 id="inkscape-矢量图软件">Inkscape 矢量图软件&lt;/h2>
&lt;p>AI 的平替版，优点在于&lt;strong>开源免费&lt;/strong>。 作为开源界的矢量图形编辑器翘楚，Inkscape 提供了一套完整的 SVG 编辑工具，科研人员可以免费使用它来创作复杂的矢量图表，并确保跨平台兼容性和无损缩放性。官方中文地址：&lt;a class="link" href="https://inkscape.org/zh-hans/" target="_blank" rel="noopener" >Inkscape
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/INKSCAPE-2024-02-28.webp"
alt="INKSCAPE-2024-02-28" width="auto" loading="lazy"/>
&lt;/figure>
&lt;hr>
&lt;ul>
&lt;li>
&lt;p>详细介绍：&lt;a class="link" href="https://zhuanlan.zhihu.com/p/642526806" target="_blank" rel="noopener" >Inkscape - 免费开源、跨平台的矢量图形设计软件，代替 Adobe Illustrator (AI) 和 CorelDRAW
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/p>
&lt;/li>
&lt;li>
&lt;p>推荐视频教程：&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class="video-wrapper">
&lt;iframe src="https://player.bilibili.com/player.html?autoplay=0&amp;as_wide=1&amp;amp;high_quality=1&amp;amp;page=1&amp;bvid=BV1mA411e7FM"
scrolling="no"
frameborder="no"
framespacing="0"
allowfullscreen="true"
>
&lt;/iframe>
&lt;/div></description></item><item><title>RDMA 基本服务类型</title><link>https://cuterwrite.top/p/rdma-service-types/</link><pubDate>Sun, 25 Feb 2024 22:04:01 +0000</pubDate><guid>https://cuterwrite.top/p/rdma-service-types/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/f71da3ec40dd74648e15471d47ba3b84195413_crop-2024-02-26.webp" alt="Featured image of post RDMA 基本服务类型" />&lt;h1 id="rdma-基本服务类型">RDMA 基本服务类型&lt;/h1>
&lt;p>&lt;strong>本文欢迎非商业转载，转载请注明出处。&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>声明：仅用于收藏，便于阅读&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/144099636">&lt;cite>知乎专栏：5. RDMA 基本服务类型&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>我们在 &lt;a class="link" href="https://cuterwrite.top/p/rdma-element/" >“3. RDMA 基本元素”
&lt;/a>
一文中提到过，&lt;strong>RDMA 的基本通信单元是 QP&lt;/strong>，而基于 QP 的通信模型有很多种，我们在 RDMA 领域称其为“服务类型”。IB 协议中通过“可靠”和“连接”两个维度来描述一种服务类型。&lt;/p>
&lt;h2 id="可靠">可靠&lt;/h2>
&lt;p>通信中的可靠性指的是通过一些机制保证发出去的数据包都能够被正常接收。IB 协议中是这样描述可靠服务的：&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Reliable Service&lt;/strong> provides a guarantee that messages are delivered from a requester to a responder at most once, in order and without corruption.&lt;/p>
&lt;/blockquote>
&lt;p>即“可靠服务在发送和接受者之间保证了信息最多只会传递一次，并且能够保证其按照发送顺序完整的被接收”。&lt;/p>
&lt;p>IB 通过以下三个机制来保证可靠性：&lt;/p>
&lt;h2 id="应答机制">应答机制&lt;/h2>
&lt;p>假设 A 给 B 发了一个数据包，A 怎样才能知道 B 收到了呢，自然是 B 回复一个“我收到了”消息给 A。在通信领域我们一般称这个回复为应答包或者 ACK（Acknowledge）。在 IB 协议的可靠服务类型中，使用了应答机制来保证数据包被对方收到。IB 的可靠服务类型中，接收方不是每一个包都必须回复，也可以一次回复多个包的 ACK，以后我们再展开讨论。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/ib_ack-2024-02-26.webp"
alt="ib_ack-2024-02-26" width="auto" loading="lazy"/>
&lt;/figure>
&lt;h2 id="数据校验机制">数据校验机制&lt;/h2>
&lt;p>这个比较好理解，发端会对 Header 和 Payload（有效载荷，也就是真正要收发的数据）通过一定的算法得到一个校验值放到数据包的末尾。对端收到数据包后，也会用相同的算法计算出校验值，然后与数据包中的校验值比对，如果不一致，说明数据中包含错误（一般是链路问题导致的），那么接收端就会丢弃这个数据包。IB 协议使用的 CRC 校验，本文对 CRC 不做展开介绍。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/crc-2024-02-26.png"
alt="crc-2024-02-26" width="auto" loading="lazy"/>
&lt;/figure>
&lt;h2 id="保序机制">保序机制&lt;/h2>
&lt;p>保序指的是，保证先被发送到物理链路上的数据包一定要先于后发送的数据包被接收方收到。有一些业务对数据包的先后顺序是有严格要求的，比如语音或者视频。IB 协议中有 PSN（Packet Sequence Number，包序号）的概念，即每个包都有一个递增的编号。PSN 可以用来检测是否丢包，比如收端收到了 1，但是在没收到 2 的情况下就收到了 3，那么其就会认为传输过程中发生了错误，之后会回复一个 NAK 给发端，让其重发丢失的包。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/psn-2024-02-26.webp"
alt="psn-2024-02-26" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>不可靠服务，没有上述这些机制来保证数据包被正确的接收，属于“发出去就行，我不关心有没有被收到”的服务类型。&lt;/p>
&lt;h2 id="连接与数据报">连接与数据报&lt;/h2>
&lt;p>&lt;strong>连接（Connection）&lt;/strong> 在这里指的是一个抽象的逻辑概念，需要区别于物理连接，熟悉 Socket 的读者一定对这个其不陌生。连接是一条通信的“管道”，一旦管道建立好了，管道这端发出的数据一定会沿着这条管道到达另一端。&lt;/p>
&lt;p>对于“连接”或者说“面向连接”的定义有很多种，有的侧重于保证消息顺序，有的侧重于消息的传递路径唯一，有的强调需要软硬件开销来维护连接，有的还和可靠性的概念有交集。本专栏既然是介绍 RDMA 技术，那么我们就看一下 IB 协议 3.2.2 节中对其的描述：&lt;/p>
&lt;blockquote>
&lt;p>IBA supports both connection oriented and datagram service. For connected service, each QP is associated with exactly one remote consumer. In this case the QP context is configured with the identity of the remote consumer’s queue pair. &amp;hellip; During the communication establishment process, this and other information is exchanged between the two nodes.&lt;/p>
&lt;/blockquote>
&lt;p>即“IBA 支持基于连接和数据报的服务。对于基于连接的服务来说，每个 QP 都和另一个远端节点相关联。在这种情况下，QP Context 中包含有远端节点的 QP 信息。在建立通信的过程中，两个节点会交换包括稍后用于通信的 QP 在内的对端信息&amp;quot;。&lt;/p>
&lt;p>上面这端描述中的 Context 一般被翻译成上下文，QP Context（简称 QPC）可以简单理解为是记录一个 QP 相关信息的表格。我们知道 QP 是两个队列，除了这两个队列之外，我们还需要把关于 QP 的信息记录到一张表里面，这些信息可能包括队列的深度，队列的编号等等，后面我们会展开讲。&lt;/p>
&lt;p>可能还是有点抽象，我们用图说话：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/QPC-2024-02-26.webp"
alt="QPC-2024-02-26" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>A、B 和 A、C 节点的网卡在物理上是连接在一起的，A 上面的 QP2 和 B 上面的 QP7、A 上面的 QP4 和 B 上面的 QP2 建立了逻辑上的连接，或者说“绑定到了一起”。&lt;strong>在连接服务类型中的每个 QP，都和唯一的另一个 QP 建立了连接，也就是说 QP 下发的每个 WQE 的目的地都是唯一的&lt;/strong>。拿上图来说，对于 A 的 QP2 下发的每个 WQE，硬件都可以通过 QPC 得知其目的为 B 的 QP7，就会把组装好的数据包发送给 B，然后 B 会根据 QP7 下发的 RQ WQE 来存放数据；同理，对于 A 的 QP4 下发的每个 WQE，A 的硬件都知道应该把数据发给 Node C 的 QP2。&lt;/p>
&lt;p>“连接”是如何维护的呢？其实就是在 QPC 里面的一个记录而已。如果 A 的 QP2 想断开与 B 的 QP7 的“连接”然后与其他 QP 相“连接”，只需要修改 QPC 就可以了。两个节点在建立连接的过程中，会交换稍后用于数据交互的 QP Number，然后分别记录在 QPC 中。&lt;/p>
&lt;p>&lt;strong>数据报（Datagram）&lt;/strong> 与连接相反，发端和收端间不需要“建立管道”的步骤，只要发端到收端物理上是可以到达的，那么我就可能从任何路径发给任意的收端节点。IB 协议对其的定义是这样的：&lt;/p>
&lt;blockquote>
&lt;p>For datagram service, a QP is not tied to a single remote consumer, but rather information in the WQE identifies the destination. A communication setup process similar to the connection setup process needs to occur with each destination to exchange that information.&lt;/p>
&lt;p>即“对于数据报服务来说，QP 不会跟一个唯一的远端节点绑定，而是通过 WQE 来指定目的节点。和连接类型的服务一样，建立通信的过程也需要两端交换对端信息，但是数据报服务对于每个目的节点都需要执行一次这个交换过程。”&lt;/p>
&lt;/blockquote>
&lt;p>我们举个例子：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/Datagram-2024-02-26.webp"
alt="Datagram-2024-02-26" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>在数据报类型的 QP 的 Context 中，不包含对端信息，即每个 QP 不跟另一个 QP 绑定。&lt;strong>QP 下发给硬件的每个 WQE 都可能指向不同的目的地&lt;/strong>。比如节点 A 的 QP2 下发的第一个 WQE，指示给节点 C 的 QP3 发数据；而下一个 WQE，可以指示硬件发给节点 B 的 QP7。&lt;/p>
&lt;p>与连接服务类型一样，本端 QP 可以和哪个对端 QP 发送数据，是在准备阶段提前通过某些方式相互告知的。这也是上文“数据报服务对于每个目的节点都需要执行一次这个交换过程”的含义。&lt;/p>
&lt;h2 id="服务类型">服务类型&lt;/h2>
&lt;p>上面介绍的两个维度两两组合就形成了 IB 的四种基本服务类型：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>可靠(Reliable)&lt;/th>
&lt;th>不可靠(Unreliable)&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>连接(Connection)&lt;/td>
&lt;td>RC（Reliable Connection）&lt;/td>
&lt;td>UC（Unreliable Connection）&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>数据报(Datagram)&lt;/td>
&lt;td>RD（Reliable Datagram）&lt;/td>
&lt;td>UD（Unreliable Datagram）&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>RC 和 UD 是应用最多也是最基础的两种服务类型，我们可以将他们分别类比成 TCP/IP 协议栈传输层的 TCP 和 UDP。&lt;/p>
&lt;p>RC 用于对数据完整性和可靠性要求较高的场景，跟 TCP 一样，因为需要各种机制来保证可靠，所以开销自然会大一些。另外由于 RC 服务类型和每个节点间需要各自维护一个 QP，假设有 N 个节点要相互通信，那么至少需要 &lt;strong>N * (N - 1)&lt;/strong> 个 QP，而 QP 和 QPC 本身是需要占用网卡资源或者内存的，当节点数很多时，存储资源消耗将会非常大。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/RC_Connect-2024-02-26.webp"
alt="RC_Connect-2024-02-26" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>UD 硬件开销小并且节省存储资源，比如 N 个节点需要相互通信，只需要创建 &lt;strong>N&lt;/strong> 个 QP 就可以了，但是可靠性跟 UDP 一样没法保证。用户如果想基于 UD 服务类型实现可靠性，那么需要自己基于 IB 传输层实现应用层的可靠传输机制。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/UD_Connect-2024-02-26.webp"
alt="UD_Connect-2024-02-26" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>除此之外，还有 RD 和 UC 类型，以及 XRC（Extended Reliable Connection），SRD（Scalable Reliable Datagram）等更复杂的服务类型，我们将在协议解析部分对其进行详细的描述。&lt;/p>
&lt;p>更多关于 QP 类型选择的信息可以参考 RDMAmojo 上的&lt;a class="link" href="https://www.rdmamojo.com/2013/06/01/which-queue-pair-type-to-use/" target="_blank" rel="noopener" >Which Queue Pair type to use?
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
这篇文章，感谢 &lt;a class="link" href="https://www.zhihu.com/people/fc04fe143ad43b66fabb7050dadef923" target="_blank" rel="noopener" >@sinkinben
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
同学在评论区指路。&lt;/p>
&lt;h2 id="代码示例">代码示例&lt;/h2>
&lt;p>在 RDMA 编程中，我们可以通过 &lt;code>ibv_create_qp&lt;/code> 函数来创建 QP，其中的 &lt;code>struct ibv_qp_init_attr&lt;/code> 结构体中的 &lt;code>qp_type&lt;/code> 字段就是用来指定 QP 的服务类型的。下面是一个简单的示例代码：&lt;/p>
&lt;pre>&lt;code class="language-c">struct ibv_qp_init_attr qp_init_attr;
qp_init_attr.qp_type = IBV_QPT_RC; // RC 类型
qp_init_attr.sq_sig_all = 1; // 1 表示 SQ 中的每个 WQE 都需要对应的接收一个 CQE
qp_init_attr.send_cq = cq; // 发送 CQ
qp_init_attr.recv_cq = cq; // 接收 CQ
qp_init_attr.cap.max_send_wr = 1024; // SQ 的深度
struct ibv_qp *qp = ibv_create_qp(pd, &amp;amp;qp_init_attr);
&lt;/code>&lt;/pre></description></item><item><title>RDMA 操作类型</title><link>https://cuterwrite.top/p/rdma-op/</link><pubDate>Sat, 24 Feb 2024 03:09:01 +0000</pubDate><guid>https://cuterwrite.top/p/rdma-op/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/bcb5351691a864a6827138cf4c2e0642195413_crop-2024-02-25.webp" alt="Featured image of post RDMA 操作类型" />&lt;h1 id="rdma-操作类型">RDMA 操作类型&lt;/h1>
&lt;p>&lt;strong>本文欢迎非商业转载，转载请注明出处。&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>声明：仅用于收藏，便于阅读&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/142175657">&lt;cite>知乎专栏：4. RDMA 操作类型&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>前面几篇涉及 RDMA 的通信流程时一直在讲 SEND-RECV，然而它其实称不上是“RDMA”，只是一种加入了 0 拷贝和协议栈卸载的传统收发模型的“升级版”，这种操作类型没有完全发挥 RDMA 技术全部实力，常用于两端交换控制信息等场景。当涉及大量数据的收发时，更多使用的是两种 RDMA 独有的操作：WRITE 和 READ。&lt;/p>
&lt;p>我们先来复习下双端操作——SEND 和 RECV，然后再对比介绍单端操作——WRITE 和 READ。&lt;/p>
&lt;h2 id="send--recv">SEND &amp;amp; RECV&lt;/h2>
&lt;p>SEND 和 RECV 是两种不同的操作类型，但是因为如果一端进行 SEND 操作，对端必须进行 RECV 操作，所以通常都把他们放到一起描述。&lt;/p>
&lt;p>为什么称之为“双端操作”？因为&lt;strong>完成一次通信过程需要两端 CPU 的参与&lt;/strong>，并且收端需要提前显式的下发 WQE。下图是一次 SEND-RECV 操作的过程示意图。原图来自于[1]，我做了一些修改。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/rdma-op-1-2024-02-25.webp"
alt="rdma-op-1-2024-02-25" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>上一篇我们讲过，上层应用通过 WQE（WR）来给硬件下任务。在 SEND-RECV 操作中，不止发送端需要下发 WQE，接收端也需要下发 WQE 来告诉硬件收到的数据需要放到哪个地址。发送端并不知道发送的数据会放到哪里，每次发送数据，接收端都要提前准备好接收 Buffer，而接收端 CPU 自然会感知这一过程。&lt;/p>
&lt;p>为了下文对比 SEND/RECV 与 WRITE/READ 的异同，我们将上一篇的 SEND-RECV 流程中补充内存读写这一环节，即下图中的步骤④——发送端硬件根据 WQE 从内存中取出数据封装成可在链路上传输数据包和步骤⑦——接收端硬件将数据包解析后根据 WQE 将数据放到指定内存区域，其他步骤不再赘述。另外再次强调一下，收发端的步骤未必是图中这个顺序，比如步骤⑧⑪⑫和步骤⑨⑩的先后顺序就是不一定的。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/rdma-op-2-2024-02-25.webp"
alt="rdma-op-2-2024-02-25" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>下面将介绍 WRITE 操作，对比之后相信大家可以理解的更好。&lt;/p>
&lt;h2 id="write">WRITE&lt;/h2>
&lt;p>WRITE 全称是 RDMA WRITE 操作，是本端主动写入远端内存的行为，除了准备阶段，远端 CPU 不需要参与，也不感知何时有数据写入、数据在何时接收完毕。所以这是一种单端操作。&lt;/p>
&lt;p>通过下图我们对比一下 WRITE 和 SEND-RECV 操作的差异，本端在准备阶段通过数据交互，获取了对端某一片可用的内存的&lt;strong>地址&lt;/strong>和“&lt;strong>钥匙&lt;/strong>” ，相当于获得了这片远端内存的读写权限。拿到权限之后，本端就可以像访问自己的内存一样&lt;strong>直接对这一远端内存区域进行读写&lt;/strong>，这也是 RDMA——远程直接地址访问的内涵所在。&lt;/p>
&lt;p>WRITE/READ 操作中的目的地址和钥匙是如何获取的呢？通常可以通过我们刚刚讲过的 SEND-RECV 操作来完成，因为拿到钥匙这个过程总归是要由远端内存的控制者——CPU 允许的。虽然准备工作还比较复杂， 但是一旦完成准备工作，RDMA 就可以发挥其优势，对大量数据进行读写。一旦远端的 CPU 把内存授权给本端使用，它便不再会参与数据收发的过程，这就解放了远端 CPU，也降低了通信的时延。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/rdma-op-3-2024-02-25.webp"
alt="rdma-op-3-2024-02-25" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>需要注意的是，本端是通过&lt;strong>虚拟地址&lt;/strong>来读写远端内存的，上层应用可以非常方便的对其进行操作。实际的虚拟地址—物理地址的转换是由 RDMA 网卡完成的。具体是如何转换的，将在后面的文章介绍。&lt;/p>
&lt;p>忽略准备阶段 key 和 addr 的获取过程，下面我们描述一次 WRITE 操作的流程，此后我们不再将本端和对端称为“发送”和“接收”端，而是改为“请求”和“响应”端，这样对于描述 WRITE 和 READ 操作都更恰当一些，也不容易产生歧义。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/rdma-op-4-2024-02-25.webp"
alt="rdma-op-4-2024-02-25" width="auto" loading="lazy"/>
&lt;/figure>
&lt;ol>
&lt;li>请求端 APP 以 WQE（WR）的形式下发一次 WRITE 任务。&lt;/li>
&lt;li>请求端硬件从 SQ 中取出 WQE，解析信息。&lt;/li>
&lt;li>请求端网卡根据 WQE 中的虚拟地址，转换得到物理地址，然后从内存中拿到待发送数据，组装数据包。&lt;/li>
&lt;li>请求端网卡将数据包通过物理链路发送给响应端网卡。&lt;/li>
&lt;li>响应端收到数据包，解析目的虚拟地址，转换成本地物理地址，解析数据，将数据放置到指定内存区域。&lt;/li>
&lt;li>响应端回复 ACK 报文给请求端。&lt;/li>
&lt;li>请求端网卡收到 ACK 后，生成 CQE，放置到 CQ 中。&lt;/li>
&lt;li>请求端 APP 取得任务完成信息。&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>注：严谨地说，第 6 步回复 ACK 之时，RDMA 网卡只能保证数据包中的 Payload 已经被”暂存“了下来，但不能保证一定已经把数据放到目的内存里面了。不过这一点不影响我们对整理流程的理解，感谢@nekomii 同学的提醒。&lt;/p>
&lt;p>IB Spec. 9.7.5.1.6 ACKNOWLEDGE MESSAGE SCHEDULING 原文：”For SEND or RDMA WRITE requests, an ACK may be scheduled before data is actually written into the responder’s memory. The ACK simply indicates that the data has successfully reached the fault domain of the responding node. That is, the data has been received by the channel adapter and the channel adapter will write that data to the memory system of the responding node, or the responding application will at least be informed of the failure.“&lt;/p>
&lt;/blockquote>
&lt;h2 id="read">READ&lt;/h2>
&lt;p>顾名思义，READ 跟 WRITE 是相反的过程，是本端主动读取远端内存的行为。同 WRITE 一样，远端 CPU 不需要参与，也不感知数据在内存中被读取的过程。&lt;/p>
&lt;p>获取 key 和虚拟地址的流程也跟 WRITE 没有区别，需要注意的是 &lt;strong>&amp;ldquo;读”这个动作所请求的数据&lt;/strong>，是在对端回复的报文中携带的。&lt;/p>
&lt;p>下面描述一次 READ 操作的流程，注意跟 WRITE 只是方向和步骤顺序的差别。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/rdma5-2024-02-25.webp"
alt="rdma5-2024-02-25" width="auto" loading="lazy"/>
&lt;/figure>
&lt;ol>
&lt;li>请求端 APP 以 WQE 的形式下发一次 READ 任务。&lt;/li>
&lt;li>请求端网卡从 SQ 中取出 WQE，解析信息。&lt;/li>
&lt;li>请求端网卡将 READ 请求包通过物理链路发送给响应端网卡。&lt;/li>
&lt;li>响应端收到数据包，解析目的虚拟地址，转换成本地物理地址，解析数据，从指定内存区域取出数据。&lt;/li>
&lt;li>响应端硬件将数据组装成回复数据包发送到物理链路。&lt;/li>
&lt;li>请求端硬件收到数据包，解析提取出数据后放到 READ WQE 指定的内存区域中。&lt;/li>
&lt;li>请求端网卡生成 CQE，放置到 CQ 中。&lt;/li>
&lt;li>请求端 APP 取得任务完成信息。&lt;/li>
&lt;/ol>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>我们忽略各种细节进行抽象，RDMA WRITE 和 READ 操作就是在利用网卡完成下面左图的内存拷贝操作而已，只不过复制的过程是由 RDMA 网卡通过网络链路完成的；而本地内存拷贝则如下面右图所示由 CPU 通过总线完成的：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/rdma-op-6-2024-02-25.webp"
alt="rdma-op-6-2024-02-25" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>RDMA 标准定义上述几种操作的时候使用的单词是非常贴切的，“收”和“发”是需要有对端主动参与的语义 ，而‘读“和”写“更像是本端对一个没有主动性的对端进行操作的语义。&lt;/p>
&lt;p>通过对比 SEND/RECV 和 WRITE/READ 操作，我们可以发现传输数据时不需要响应端 CPU 参与的 WRITE/READ 有更大的优势，缺点就是请求端需要在准备阶段获得响应端的一段内存的读写权限。但是实际数据传输时，这个准备阶段的功率和时间损耗都是可以忽略不计的，所以 RDMA WRITE/READ 才是大量传输数据时所应用的操作类型，SEND/RECV 通常只是用来传输一些控制信息。&lt;/p>
&lt;p>除了本文介绍的几种操作之外，还有 ATOMIC 等更复杂一些的操作类型，将在后面的协议解读部分详细分析。本篇就到这里，下一篇将介绍 RDMA 基本服务类型。&lt;/p>
&lt;h2 id="代码示例">代码示例&lt;/h2>
&lt;p>本文中的操作类型都是通过 WQE 来下发的，下面是一个简单的例子，展示了如何使用 libibverbs 来创建一个 QP，然后通过 WQE 来下发一个 WRITE 操作。&lt;/p>
&lt;pre>&lt;code class="language-c">#include &amp;lt;infiniband/verbs.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
int main() {
struct ibv_device **dev_list = ibv_get_device_list(NULL);
struct ibv_context *ctx = ibv_open_device(dev_list[0]);
struct ibv_pd *pd = ibv_alloc_pd(ctx);
struct ibv_cq *cq = ibv_create_cq(ctx, 10, NULL, NULL, 0);
struct ibv_qp *qp;
struct ibv_qp_init_attr qp_init_attr = {
.send_cq = cq,
.recv_cq = cq,
.qp_type = IBV_QPT_RC,
};
qp = ibv_create_qp(pd, &amp;amp;qp_init_attr);
struct ibv_mr *mr;
char *buf = malloc(1024);
mr = ibv_reg_mr(pd, buf, 1024, IBV_ACCESS_LOCAL_WRITE | IBV_ACCESS_REMOTE_WRITE);
struct ibv_sge sge = {
.addr = (uintptr_t)buf,
.length = 1024,
.lkey = mr-&amp;gt;lkey,
};
struct ibv_send_wr wr = {
.wr_id = 1,
.sg_list = &amp;amp;sge,
.num_sge = 1,
.opcode = IBV_WR_RDMA_WRITE,
.send_flags = IBV_SEND_SIGNALED,
};
struct ibv_send_wr *bad_wr;
ibv_post_send(qp, &amp;amp;wr, &amp;amp;bad_wr);
return 0;
}
&lt;/code>&lt;/pre>
&lt;h2 id="参考资料">参考资料&lt;/h2>
&lt;p>[1] part1-OFA_Training_Sept_2016.pdf&lt;/p></description></item><item><title>搭建玄铁 900 系列工具链与 xuantie-qemu 环境</title><link>https://cuterwrite.top/p/thead-tools/</link><pubDate>Tue, 20 Feb 2024 01:51:00 +0000</pubDate><guid>https://cuterwrite.top/p/thead-tools/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/59aa9fecb7e1a3a2b2c88811e6360647195413.jpg@1256w_774h_!web-article-pic-2024-02-20.webp" alt="Featured image of post 搭建玄铁 900 系列工具链与 xuantie-qemu 环境" />&lt;h1 id="搭建玄铁-900-系列工具链与-xuantie-qemu-环境">搭建玄铁 900 系列工具链与 xuantie-qemu 环境&lt;/h1>
&lt;h2 id="一搭建平台">一、搭建平台&lt;/h2>
&lt;ul>
&lt;li>Linux 发行版：CentOS Linux release 7.6.1810 (Core)&lt;/li>
&lt;li>内核版本：3.10.0-957.el7.x86_64&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-bash">$ cat /etc/centos-release
CentOS Linux release 7.6.1810 (Core)
$ uname -r
3.10.0-957.el7.x86_64
&lt;/code>&lt;/pre>
&lt;h2 id="二搭建玄铁-900-系列工具链环境">二、搭建玄铁 900 系列工具链环境&lt;/h2>
&lt;h3 id="1-下载玄铁-900-系列工具链">1. 下载玄铁 900 系列工具链&lt;/h3>
&lt;p>首先，我们需要下载适用于 RISC-V 架构的 Xuantie GNU 工具链。前往&lt;a class="link" href="https://www.xrvm.cn/" target="_blank" rel="noopener" >玄铁官网
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
获取最新版本的预编译包，并根据你的操作系统进行安装。在 Linux 系统中，通常解压后通过添加 &lt;code>bin&lt;/code> 路径到 &lt;code>$PATH&lt;/code> 环境变量即可。&lt;/p>
&lt;p>工具链安装包由于执行平台和目标程序平台的不同分为不同的版本，如 Xuantie-&lt;em>-elf-&lt;/em>-x86_64-V*-.tar.gz 是 64 位 linux 平台的 riscv 裸程序工具链套件。具体分类如下：&lt;/p>
&lt;ul>
&lt;li>根据执行平台
&lt;ul>
&lt;li>x86_64：64 位 linux 平台&lt;/li>
&lt;li>i386：32 位 linux 平台&lt;/li>
&lt;li>mingw：Windows Mingw 平台&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>根据目标程序平台
&lt;ul>
&lt;li>elf：裸程序编译套件&lt;/li>
&lt;li>linux：linux 应用程序编译套件&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>这里我们下载最新的版本为 2.8.1 的适用于 64 位 linux 平台的 linux 应用程序编译套件，即 Xuantie-900-gcc-linux-5.10.4-glibc-x86_64 。&lt;/p>
&lt;pre>&lt;code class="language-bash">wget https://occ-oss-prod.oss-cn-hangzhou.aliyuncs.com/resource//1705395627867/Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.1-20240115.tar.gz
tar -xzvf Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.1-20240115.tar.gz
sudo mv Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.1-20240115 /opt
export PATH=/opt/Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.1-20240115/bin:$PATH
&lt;/code>&lt;/pre>
&lt;h3 id="2-验证工具链安装">2. 验证工具链安装&lt;/h3>
&lt;pre>&lt;code class="language-bash">$ riscv64-unknown-linux-gnu-gcc -v
Using built-in specs.
COLLECT_GCC=riscv64-unknown-linux-gnu-gcc
COLLECT_LTO_WRAPPER=/opt/Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.0/bin/../libexec/gcc/riscv64-unknown-linux-gnu/10.4.0/lto-wrapper
Target: riscv64-unknown-linux-gnu
Configured with: /mnt/ssd/jenkins_iotsw/slave/workspace/Toolchain/build-gnu-riscv_4/./source/riscv/riscv-gcc/configure --target=riscv64-unknown-linux-gnu --with-gmp=/mnt/ssd/jenkins_iotsw/slave/workspace/Toolchain/build-gnu-riscv_4/build-gcc-riscv64-unknown-linux-gnu/build-Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.0/lib-for-gcc-x86_64-linux --with-mpfr=/mnt/ssd/jenkins_iotsw/slave/workspace/Toolchain/build-gnu-riscv_4/build-gcc-riscv64-unknown-linux-gnu/build-Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.0/lib-for-gcc-x86_64-linux --with-mpc=/mnt/ssd/jenkins_iotsw/slave/workspace/Toolchain/build-gnu-riscv_4/build-gcc-riscv64-unknown-linux-gnu/build-Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.0/lib-for-gcc-x86_64-linux --with-libexpat-prefix=/mnt/ssd/jenkins_iotsw/slave/workspace/Toolchain/build-gnu-riscv_4/build-gcc-riscv64-unknown-linux-gnu/build-Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.0/lib-for-gcc-x86_64-linux --with-libmpfr-prefix=/mnt/ssd/jenkins_iotsw/slave/workspace/Toolchain/build-gnu-riscv_4/build-gcc-riscv64-unknown-linux-gnu/build-Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.0/lib-for-gcc-x86_64-linux --with-pkgversion='Xuantie-900 linux-5.10.4 glibc gcc Toolchain V2.8.0 B-20231018' CXXFLAGS='-g -O2 -DTHEAD_VERSION_NUMBER=2.8.0 ' --prefix=/mnt/ssd/jenkins_iotsw/slave/workspace/Toolchain/build-gnu-riscv_4/build-gcc-riscv64-unknown-linux-gnu/Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.0 --with-sysroot=/mnt/ssd/jenkins_iotsw/slave/workspace/Toolchain/build-gnu-riscv_4/build-gcc-riscv64-unknown-linux-gnu/Xuantie-900-gcc-linux-5.10.4-glibc-x86_64-V2.8.0/sysroot --with-system-zlib --enable-shared --enable-tls --enable-languages=c,c++,fortran --disable-libmudflap --disable-libssp --disable-libquadmath --enable-libsanitizer --disable-nls --disable-bootstrap --src=https://cuterwrite.top/mnt/ssd/jenkins_iotsw/slave/workspace/Toolchain/build-gnu-riscv_4/./source/riscv/riscv-gcc --enable-multilib --with-abi=lp64d --with-arch=rv64gc_zfh_xtheadc 'CFLAGS_FOR_TARGET=-O2 -mcmodel=medany' 'CXXFLAGS_FOR_TARGET=-O2 -mcmodel=medany'
Thread model: posix
Supported LTO compression algorithms: zlib
gcc version 10.4.0 (Xuantie-900 linux-5.10.4 glibc gcc Toolchain V2.8.0 B-20231018)
&lt;/code>&lt;/pre>
&lt;p>可以看到输出了 gcc 的版本信息，说明工具链安装成功。&lt;/p>
&lt;h2 id="三搭建-xuantie-qemu-环境">三、搭建 xuantie-qemu 环境&lt;/h2>
&lt;h3 id="1-前提条件">1. 前提条件&lt;/h3>
&lt;p>在安装 xuantie-qemu 之前，需要确保系统含有以下工具或库。&lt;/p>
&lt;ul>
&lt;li>gcc 编译器&lt;/li>
&lt;li>automake&lt;/li>
&lt;li>autoconf&lt;/li>
&lt;li>libtool&lt;/li>
&lt;li>glib2 库&lt;/li>
&lt;li>其它&amp;hellip;..&lt;/li>
&lt;/ul>
&lt;p>通过以下命令安装上述工具或库。&lt;/p>
&lt;pre>&lt;code class="language-bash">sudo yum update -y
sudo yum install -y autoconf automake libtool make gcc gcc-c++ gawk bison flex texinfo gperf patchutils bc \
zlib-devel mpfr-devel gmp-devel curl-devel expat-devel git \
glib2-devel libfdt-devel pixman-devel ncurses-devel ncurses-compat-libs
&lt;/code>&lt;/pre>
&lt;p>如果是 Ubuntu/Dedian 系统，可以使用以下命令安装。&lt;/p>
&lt;pre>&lt;code class="language-bash">sudo apt-get update
sudo apt-get install -y autoconf automake autotools-dev curl libmpc-dev libmpfr-dev libgmp-dev \
gawk build-essential bison flex texinfo gperf libtool patchutils bc \
zlib1g-dev libexpat-dev git \
libglib2.0-dev libfdt-dev libpixman-1-dev \
libncurses5-dev libncursesw5-dev
&lt;/code>&lt;/pre>
&lt;h3 id="2-下载并安装-xuantie-qemu">2. 下载并安装 xuantie-qemu&lt;/h3>
&lt;p>访问 &lt;a class="link" href="https://github.com/T-head-Semi/qemu.git" target="_blank" rel="noopener" >Xuantie QEMU 官方仓库
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
，获取适用于玄铁 900 系列芯片的 xuantie-qemu 源代码，然后按照常规步骤编译安装：&lt;/p>
&lt;pre>&lt;code class="language-bash">git clone https://github.com/T-head-Semi/qemu.git
git checkout xuantie-qemu-6.1.0
&lt;/code>&lt;/pre>
&lt;h3 id="3-编译安装-xuantie-qemu">3. 编译安装 xuantie-qemu&lt;/h3>
&lt;pre>&lt;code class="language-bash">cd qemu
mkdir build
cd build
../configure --target-list=riscv64-softmmu,riscv64-linux-user --prefix=/opt/qemu/6.1.0-xuantie
make -j $(nproc)
sudo make install
export PATH=/opt/qemu/6.1.0-xuantie/bin:$PATH
&lt;/code>&lt;/pre>
&lt;h3 id="4-验证-xuantie-qemu-安装">4. 验证 xuantie-qemu 安装&lt;/h3>
&lt;p>安装完毕后如果执行如下命令后能够查看到 qemu 的具体版本，则说明安装成功&lt;/p>
&lt;pre>&lt;code class="language-bash">$ qemu-riscv64 --version
qemu-riscv64 version 6.0.94 (v6.1.0-12-g03813c9)
Copyright (c) 2003-2021 Fabrice Bellard and the QEMU Project developers
&lt;/code>&lt;/pre>
&lt;p>编写一段 C 语言程序，如下所示：&lt;/p>
&lt;pre>&lt;code class="language-c">#include &amp;lt;stdio.h&amp;gt;
int main() {
printf(&amp;quot;Hello RISC-V \n&amp;quot;);
return 0;
}
&lt;/code>&lt;/pre>
&lt;p>使用 Xuantie 900 系列工具链编译该程序，并使用用户模式的 xuantie-qemu 运行程序。&lt;/p>
&lt;pre>&lt;code class="language-bash">$ riscv64-unknown-linux-gnu-gcc -static -o hello hello.c
$ qemu-riscv64 ./hello
Hello RISC-V
&lt;/code>&lt;/pre>
&lt;p>再写一段 RVV 向量化的 C 语言程序，如下所示：&lt;/p>
&lt;details>
&lt;summary>&lt;strong>RVV 向量化 C 语言程序&lt;/strong>&lt;/summary>
&lt;pre>&lt;code class="language-c">#include &amp;lt;riscv_vector.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;
#define N 15
float vsum(float* v, int n) {
vfloat32m1_t vs, vv, vtmp;
float s = 0.0;
int i;
int vlmax;
vlmax = vsetvlmax_e32m1();
printf(&amp;quot;vlmax:%d\n&amp;quot;, vlmax);
vs = vfmv_v_f_f32m1(0.0, vlmax);
vtmp = vfmv_v_f_f32m1(0.0, vlmax);
for (i = 0; i &amp;lt; n - vlmax; i += vlmax) {
vv = vle32_v_f32m1(&amp;amp;v[i], vlmax);
vtmp = vfadd_vv_f32m1(vtmp, vv, vlmax);
}
vs = vfredusum_vs_f32m1_f32m1(vs, vtmp, vs, vlmax);
s = vfmv_f_s_f32m1_f32(vs);
for (; i &amp;lt; n; i++) {
s += v[i];
}
return s;
}
float vsum1(float* v, int n) {
vfloat32m1_t vs, vv;
float s;
int i;
int vl, vlmax;
vlmax = vsetvlmax_e32m1();
vs = vfmv_v_f_f32m1(0.0, vlmax);
for (i = 0; n &amp;gt; 0; i += vl, n -= vl) {
vl = vsetvl_e32m1(n);
printf(&amp;quot;vl:%d\n&amp;quot;, vl);
vv = vle32_v_f32m1(&amp;amp;v[i], vl);
vs = vfredusum_vs_f32m1_f32m1(vs, vv, vs, vl);
}
s = vfmv_f_s_f32m1_f32(vs);
return s;
}
float vsum2(float* v, int n) {
vfloat32m2_t vv;
vfloat32m1_t vs;
float s;
int i;
int vl, vlmax;
vlmax = vsetvlmax_e32m1();
vs = vfmv_v_f_f32m1(0.0, vlmax);
for (i = 0; n &amp;gt; 0; i += vl, n -= vl) {
vl = vsetvl_e32m2(n);
printf(&amp;quot;vl:%d\n&amp;quot;, vl);
vv = vle32_v_f32m2(&amp;amp;v[i], vl);
vs = vfredusum_vs_f32m2_f32m1(vs, vv, vs, vl);
}
s = vfmv_f_s_f32m1_f32(vs);
return s;
}
int main() {
int i;
float v[N], sum = 0.0;
printf(&amp;quot;Hello RISC-V!\n&amp;quot;);
for (i = 0; i &amp;lt; N; i++) {
v[i] = i;
}
sum = vsum(v, N);
printf(&amp;quot;%f\n&amp;quot;, sum);
return 0;
}
&lt;/code>&lt;/pre>
&lt;/details>
&lt;p>编译并运行该程序（这时需要指定 &lt;code>-cpu&lt;/code> ，否则会报非法指定的异常，即 Illegal instruction (core dumped)）：&lt;/p>
&lt;pre>&lt;code class="language-bash">$ riscv64-unknown-linux-gnu-gcc -static -O3 -march=rv64imafdcv0p7_zfh_xtheadc -o test_vec test_vec.c
$ qemu-riscv64 -cpu c920 ./test_vec
Hello RISC-V!
vlmax:4
105.000000
&lt;/code>&lt;/pre>
&lt;h2 id="四在-qemu-上运行-risc-v-64-位-linux-系统">四、在 QEMU 上运行 RISC-V 64 位 Linux 系统&lt;/h2>
&lt;h3 id="1-制作内核">1. 制作内核&lt;/h3>
&lt;h4 id="11-下载内核源码">1.1 下载内核源码&lt;/h4>
&lt;pre>&lt;code class="language-bash">$ wget https://mirrors.edge.kernel.org/pub/linux/kernel/v5.x/linux-5.10.42.tar.gz
$ tar -xzvf linux-5.10.42.tar.gz
&lt;/code>&lt;/pre>
&lt;p>下载后进入内核源码目录&lt;/p>
&lt;pre>&lt;code class="language-bash">$ cd linux-5.10.42
&lt;/code>&lt;/pre>
&lt;h4 id="12-配置和编译内核">1.2 配置和编译内核&lt;/h4>
&lt;pre>&lt;code class="language-bash">$ make ARCH=riscv CROSS_COMPILE=riscv64-unknown-linux-gnu- defconfig
$ make ARCH=riscv CROSS_COMPILE=riscv64-unknown-linux-gnu- -j $(nproc)
...
AR drivers/built-in.a
GEN .version
CHK include/generated/compile.h
LD vmlinux.o
MODPOST vmlinux.symvers
MODINFO modules.builtin.modinfo
GEN modules.builtin
LD .tmp_vmlinux.kallsyms1
KSYMS .tmp_vmlinux.kallsyms1.S
AS .tmp_vmlinux.kallsyms1.S
LD .tmp_vmlinux.kallsyms2
KSYMS .tmp_vmlinux.kallsyms2.S
AS .tmp_vmlinux.kallsyms2.S
LD vmlinux
SYSMAP System.map
MODPOST modules-only.symvers
GEN Module.symvers
CC [M] fs/efivarfs/efivarfs.mod.o
OBJCOPY arch/riscv/boot/Image
GZIP arch/riscv/boot/Image.gz
LD [M] fs/efivarfs/efivarfs.ko
Kernel: arch/riscv/boot/Image.gz is ready
&lt;/code>&lt;/pre>
&lt;h3 id="2-制作-rootfs">2. 制作 rootfs&lt;/h3>
&lt;h4 id="21-下载-busybox-源码">2.1 下载 busybox 源码&lt;/h4>
&lt;pre>&lt;code class="language-bash">$ wget https://busybox.net/downloads/busybox-1.33.1.tar.bz2
&lt;/code>&lt;/pre>
&lt;p>下载完后进入 busybox 源码目录&lt;/p>
&lt;pre>&lt;code class="language-bash">cd busybox-1.33.1
&lt;/code>&lt;/pre>
&lt;h4 id="22-配置-busybox">2.2 配置 busybox&lt;/h4>
&lt;pre>&lt;code class="language-bash">$ make ARCH=riscv CROSS_COMPILE=riscv64-unknown-linux-gnu- defconfig
$ make ARCH=riscv CROSS_COMPILE=riscv64-unknown-linux-gnu- menuconfig
&lt;/code>&lt;/pre>
&lt;p>打开配置菜单后进入第一行的 &amp;ldquo;Settings&amp;rdquo;，在 &amp;ldquo;Build Options&amp;rdquo; 节中，选中 “Build static binary (no shared libs)”，设置好后退出保存配置。&lt;/p>
&lt;p>检查 &lt;code>.config&lt;/code> 文件中是否有 &lt;code>CONFIG_STATIC=y&lt;/code> ，如果没有则手动添加。&lt;/p>
&lt;h4 id="23-编译和安装-busybox">2.3 编译和安装 busybox&lt;/h4>
&lt;pre>&lt;code class="language-bash">$ make ARCH=riscv CROSS_COMPILE=riscv64-unknown-linux-gnu- -j $(nproc)
$ make ARCH=riscv CROSS_COMPILE=riscv64-unknown-linux-gnu- install
&lt;/code>&lt;/pre>
&lt;p>此时源码目录 busyboxsource 下会新出现一个 &lt;code>_install&lt;/code> 目录 ，可以看到生成的东西。&lt;/p>
&lt;pre>&lt;code class="language-bash">$ ls _install
bin linuxrc sbin usr
&lt;/code>&lt;/pre>
&lt;p>进入 &lt;code>_install&lt;/code> 目录，创建以下目录&lt;/p>
&lt;pre>&lt;code class="language-bash">$ cd _install
$ mkdir proc sys dev etc etc/init.d
$ ls
bin dev etc linuxrc proc sbin sys usr
&lt;/code>&lt;/pre>
&lt;p>然后另外再新建一个最简单的 init 的 RC 文件：&lt;/p>
&lt;pre>&lt;code class="language-bash">$ cd etc/init.d/
$ touch rcS
$ vim rcS
&lt;/code>&lt;/pre>
&lt;p>编辑该文件内容为：&lt;/p>
&lt;pre>&lt;code class="language-bash">#!/bin/sh
mount -t proc none /proc
mount -t sysfs none /sys
/sbin/mdev -s
&lt;/code>&lt;/pre>
&lt;p>然后修改 rcS 文件权限，加上可执行权限&lt;/p>
&lt;pre>&lt;code class="language-bash">$ chmod +x rcS
&lt;/code>&lt;/pre>
&lt;h4 id="24-制作文件系统">2.4 制作文件系统&lt;/h4>
&lt;p>继续在 &lt;code>_install&lt;/code> 目录下执行如下命令：&lt;/p>
&lt;pre>&lt;code class="language-bash">$ find -print0 | cpio -0oH newc | gzip -9 &amp;gt; ../rootfs.img
3276 blocks
&lt;/code>&lt;/pre>
&lt;h3 id="3-启动运行">3. 启动运行&lt;/h3>
&lt;p>创建一个新的目录，将编译好的内核 &lt;code>Image&lt;/code> 和制作好的 &lt;code>rootfs.img&lt;/code> 移动到该目录下。&lt;/p>
&lt;pre>&lt;code class="language-bash">$ mkdir riscv64-linux
$ cd riscv64-linux
$ cp ../linux-5.10.42/arch/riscv/boot/Image .
$ cp ../busybox-1.33.1/rootfs.img .
&lt;/code>&lt;/pre>
&lt;p>执行如下命令：&lt;/p>
&lt;pre>&lt;code class="language-bash">$ qemu-system-riscv64 \
-nographic -machine virt \
-kernel Image \
-initrd rootfs.img \
-append &amp;quot;root=/dev/ram rdinit=/sbin/init&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>将显示 Linux Kernel 启动流程：&lt;/p>
&lt;details>
&lt;summary>&lt;strong>点击展开&lt;/strong>&lt;/summary>
&lt;pre>&lt;code class="language-bash">OpenSBI v0.9
____ _____ ____ _____
/ __ \ / ____| _ \_ _|
| | | |_ __ ___ _ __ | (___ | |_) || |
| | | | '_ \ / _ \ '_ \ \___ \| _ &amp;lt; | |
| |__| | |_) | __/ | | |____) | |_) || |_
\____/| .__/ \___|_| |_|_____/|____/_____|
| |
|_|
Platform Name : riscv-virtio,qemu
Platform Features : timer,mfdeleg
Platform HART Count : 1
Firmware Base : 0x80000000
Firmware Size : 100 KB
Runtime SBI Version : 0.2
Domain0 Name : root
Domain0 Boot HART : 0
Domain0 HARTs : 0*
Domain0 Region00 : 0x0000000080000000-0x000000008001ffff ()
Domain0 Region01 : 0x0000000000000000-0xffffffffffffffff (R,W,X)
Domain0 Next Address : 0x0000000080200000
Domain0 Next Arg1 : 0x0000000087000000
Domain0 Next Mode : S-mode
Domain0 SysReset : yes
Boot HART ID : 0
Boot HART Domain : root
Boot HART ISA : rv64imafdcvsu
Boot HART Features : scounteren,mcounteren,time
Boot HART PMP Count : 16
Boot HART PMP Granularity : 4
Boot HART PMP Address Bits: 54
Boot HART MHPM Count : 0
Boot HART MHPM Count : 0
Boot HART MIDELEG : 0x0000000000000222
Boot HART MEDELEG : 0x000000000000b109
[ 0.000000] Linux version 5.10.42 (root@centos) (riscv64-unknown-linux-gnu-gcc (Xuantie-900 linux-5.10.4 glibc gcc Toolchain V2.8.0 B-20231018) 10.4.0, GNU ld (GNU Binutils) 2.35) #1 SMP Wed Feb 21 02:07:46 CST 2024
[ 0.000000] OF: fdt: Ignoring memory range 0x80000000 - 0x80200000
[ 0.000000] efi: UEFI not found.
[ 0.000000] Initial ramdisk at: 0x(____ptrval____) (1085440 bytes)
[ 0.000000] Zone ranges:
[ 0.000000] DMA32 [mem 0x0000000080200000-0x0000000087ffffff]
[ 0.000000] Normal empty
[ 0.000000] Movable zone start for each node
[ 0.000000] Early memory node ranges
[ 0.000000] node 0: [mem 0x0000000080200000-0x0000000087ffffff]
[ 0.000000] Initmem setup node 0 [mem 0x0000000080200000-0x0000000087ffffff]
[ 0.000000] software IO TLB: Cannot allocate buffer
[ 0.000000] SBI specification v0.2 detected
[ 0.000000] SBI implementation ID=0x1 Version=0x9
[ 0.000000] SBI v0.2 TIME extension detected
[ 0.000000] SBI v0.2 IPI extension detected
[ 0.000000] SBI v0.2 RFENCE extension detected
[ 0.000000] SBI v0.2 HSM extension detected
[ 0.000000] riscv: ISA extensions acdfimsuv
[ 0.000000] riscv: ELF capabilities acdfim
[ 0.000000] percpu: Embedded 17 pages/cpu s32360 r8192 d29080 u69632
[ 0.000000] Built 1 zonelists, mobility grouping on. Total pages: 31815
[ 0.000000] Kernel command line: root=/dev/ram rdinit=/sbin/init
[ 0.000000] Dentry cache hash table entries: 16384 (order: 5, 131072 bytes, linear)
[ 0.000000] Inode-cache hash table entries: 8192 (order: 4, 65536 bytes, linear)
[ 0.000000] Sorting __ex_table...
[ 0.000000] mem auto-init: stack:off, heap alloc:off, heap free:off
[ 0.000000] Memory: 108240K/129024K available (7084K kernel code, 3993K rwdata, 4096K rodata, 223K init, 342K bss, 20784K reserved, 0K cma-reserved)
[ 0.000000] Virtual kernel memory layout:
[ 0.000000] fixmap : 0xffffffcefee00000 - 0xffffffceff000000 (2048 kB)
[ 0.000000] pci io : 0xffffffceff000000 - 0xffffffcf00000000 ( 16 MB)
[ 0.000000] vmemmap : 0xffffffcf00000000 - 0xffffffcfffffffff (4095 MB)
[ 0.000000] vmalloc : 0xffffffd000000000 - 0xffffffdfffffffff (65535 MB)
[ 0.000000] lowmem : 0xffffffe000000000 - 0xffffffe007e00000 ( 126 MB)
[ 0.000000] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=1, Nodes=1
[ 0.000000] rcu: Hierarchical RCU implementation.
[ 0.000000] rcu: RCU restricting CPUs from NR_CPUS=8 to nr_cpu_ids=1.
[ 0.000000] rcu: RCU debug extended QS entry/exit.
[ 0.000000] Tracing variant of Tasks RCU enabled.
[ 0.000000] rcu: RCU calculated value of scheduler-enlistment delay is 25 jiffies.
[ 0.000000] rcu: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=1
[ 0.000000] NR_IRQS: 64, nr_irqs: 64, preallocated irqs: 0
[ 0.000000] riscv-intc: 64 local interrupts mapped
[ 0.000000] plic: plic@c000000: mapped 53 interrupts with 1 handlers for 2 contexts.
[ 0.000000] random: get_random_bytes called from start_kernel+0x31a/0x48c with crng_init=0
[ 0.000000] riscv_timer_init_dt: Registering clocksource cpuid [0] hartid [0]
[ 0.000000] clocksource: riscv_clocksource: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns
[ 0.000150] sched_clock: 64 bits at 10MHz, resolution 100ns, wraps every 4398046511100ns
[ 0.003557] Console: colour dummy device 80x25
[ 0.008887] printk: console [tty0] enabled
[ 0.012368] Calibrating delay loop (skipped), value calculated using timer frequency.. 20.00 BogoMIPS (lpj=40000)
[ 0.012666] pid_max: default: 32768 minimum: 301
[ 0.014227] Mount-cache hash table entries: 512 (order: 0, 4096 bytes, linear)
[ 0.014306] Mountpoint-cache hash table entries: 512 (order: 0, 4096 bytes, linear)
[ 0.040922] rcu: Hierarchical SRCU implementation.
[ 0.042741] EFI services will not be available.
[ 0.044926] smp: Bringing up secondary CPUs ...
[ 0.045062] smp: Brought up 1 node, 1 CPU
[ 0.054128] devtmpfs: initialized
[ 0.061463] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 7645041785100000 ns
[ 0.061753] futex hash table entries: 256 (order: 2, 16384 bytes, linear)
[ 0.067460] NET: Registered protocol family 16
[ 0.131233] vgaarb: loaded
[ 0.132530] SCSI subsystem initialized
[ 0.134485] usbcore: registered new interface driver usbfs
[ 0.134834] usbcore: registered new interface driver hub
[ 0.135035] usbcore: registered new device driver usb
[ 0.150024] clocksource: Switched to clocksource riscv_clocksource
[ 0.167109] NET: Registered protocol family 2
[ 0.168330] IP idents hash table entries: 2048 (order: 2, 16384 bytes, linear)
[ 0.172076] tcp_listen_portaddr_hash hash table entries: 128 (order: 0, 5120 bytes, linear)
[ 0.172242] TCP established hash table entries: 1024 (order: 1, 8192 bytes, linear)
[ 0.172480] TCP bind hash table entries: 1024 (order: 3, 32768 bytes, linear)
[ 0.172690] TCP: Hash tables configured (established 1024 bind 1024)
[ 0.173861] UDP hash table entries: 256 (order: 2, 24576 bytes, linear)
[ 0.174481] UDP-Lite hash table entries: 256 (order: 2, 24576 bytes, linear)
[ 0.175963] NET: Registered protocol family 1
[ 0.179024] RPC: Registered named UNIX socket transport module.
[ 0.179111] RPC: Registered udp transport module.
[ 0.179150] RPC: Registered tcp transport module.
[ 0.179186] RPC: Registered tcp NFSv4.1 backchannel transport module.
[ 0.179332] PCI: CLS 0 bytes, default 64
[ 0.182716] Unpacking initramfs...
[ 0.263706] Freeing initrd memory: 1056K
[ 0.265678] workingset: timestamp_bits=62 max_order=15 bucket_order=0
[ 0.281052] NFS: Registering the id_resolver key type
[ 0.282003] Key type id_resolver registered
[ 0.282074] Key type id_legacy registered
[ 0.282505] nfs4filelayout_init: NFSv4 File Layout Driver Registering...
[ 0.282631] nfs4flexfilelayout_init: NFSv4 Flexfile Layout Driver Registering...
[ 0.283481] 9p: Installing v9fs 9p2000 file system support
[ 0.284918] NET: Registered protocol family 38
[ 0.285416] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 251)
[ 0.285593] io scheduler mq-deadline registered
[ 0.285692] io scheduler kyber registered
[ 0.295484] pci-host-generic 30000000.pci: host bridge /soc/pci@30000000 ranges:
[ 0.296336] pci-host-generic 30000000.pci: IO 0x0003000000..0x000300ffff -&amp;gt; 0x0000000000
[ 0.296861] pci-host-generic 30000000.pci: MEM 0x0040000000..0x007fffffff -&amp;gt; 0x0040000000
[ 0.296961] pci-host-generic 30000000.pci: MEM 0x0400000000..0x07ffffffff -&amp;gt; 0x0400000000
[ 0.299940] pci-host-generic 30000000.pci: ECAM at [mem 0x30000000-0x3fffffff] for [bus 00-ff]
[ 0.301083] pci-host-generic 30000000.pci: PCI host bridge to bus 0000:00
[ 0.301328] pci_bus 0000:00: root bus resource [bus 00-ff]
[ 0.301486] pci_bus 0000:00: root bus resource [io 0x0000-0xffff]
[ 0.301528] pci_bus 0000:00: root bus resource [mem 0x40000000-0x7fffffff]
[ 0.301568] pci_bus 0000:00: root bus resource [mem 0x400000000-0x7ffffffff]
[ 0.302864] pci 0000:00:00.0: [1b36:0008] type 00 class 0x060000
[ 0.377412] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled
[ 0.389894] 10000000.uart: ttyS0 at MMIO 0x10000000 (irq = 2, base_baud = 230400) is a 16550A
[ 0.428017] printk: console [ttyS0] enabled
[ 0.430410] [drm] radeon kernel modesetting enabled.
[ 0.457312] loop: module loaded
[ 0.460726] libphy: Fixed MDIO Bus: probed
[ 0.464996] e1000e: Intel(R) PRO/1000 Network Driver
[ 0.465383] e1000e: Copyright(c) 1999 - 2015 Intel Corporation.
[ 0.466272] ehci_hcd: USB 2.0 'Enhanced' Host Controller (EHCI) Driver
[ 0.466724] ehci-pci: EHCI PCI platform driver
[ 0.467203] ehci-platform: EHCI generic platform driver
[ 0.467683] ohci_hcd: USB 1.1 'Open' Host Controller (OHCI) Driver
[ 0.468129] ohci-pci: OHCI PCI platform driver
[ 0.468593] ohci-platform: OHCI generic platform driver
[ 0.469968] usbcore: registered new interface driver uas
[ 0.470477] usbcore: registered new interface driver usb-storage
[ 0.471603] mousedev: PS/2 mouse device common for all mice
[ 0.475055] goldfish_rtc 101000.rtc: registered as rtc0
[ 0.476070] goldfish_rtc 101000.rtc: setting system clock to 2024-02-20T19:37:51 UTC (1708457871)
[ 0.478889] syscon-poweroff soc:poweroff: pm_power_off already claimed (____ptrval____) sbi_shutdown
[ 0.479494] syscon-poweroff: probe of soc:poweroff failed with error -16
[ 0.480977] usbcore: registered new interface driver usbhid
[ 0.481324] usbhid: USB HID core driver
[ 0.483516] NET: Registered protocol family 10
[ 0.491589] Segment Routing with IPv6
[ 0.492256] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver
[ 0.495528] NET: Registered protocol family 17
[ 0.497086] 9pnet: Installing 9P2000 support
[ 0.497667] Key type dns_resolver registered
[ 0.498706] debug_vm_pgtable: [debug_vm_pgtable ]: Validating architecture page table helpers
[ 0.533266] Freeing unused kernel memory: 220K
[ 0.539682] Run /sbin/init as init process
Please press Enter to activate this console.
&lt;/code>&lt;/pre>
&lt;/details>
&lt;p>见到 &lt;code>&amp;quot;Please press Enter to activate this console.&amp;quot;&lt;/code> 提示后直接回车，无需密码就进入系统了。&lt;/p>
&lt;p>执行几个常用命令测试一下，都能正常工作：&lt;/p>
&lt;pre>&lt;code class="language-bash">/ # ls
bin etc proc sbin usr
dev linuxrc root sys
/ # pwd
/
/ # cd bin
/bin #
/ # ls
arch dumpkmap kill netstat setarch
ash echo link nice setpriv
base32 ed linux32 nuke setserial
base64 egrep linux64 pidof sh
busybox false ln ping sleep
cat fatattr login ping6 stat
chattr fdflush ls pipe_progress stty
chgrp fgrep lsattr printenv su
chmod fsync lzop ps sync
chown getopt makemime pwd tar
conspy grep mkdir reformime touch
cp gunzip mknod resume true
cpio gzip mktemp rev umount
cttyhack hostname more rm uname
date hush mount rmdir usleep
dd ionice mountpoint rpm vi
df iostat mpstat run-parts watch
dmesg ipcalc mt scriptreplay zcat
dnsdomainname kbd_mode mv sed
/bin #
&lt;/code>&lt;/pre>
&lt;p>退出 QEMU 的方法是按下 &lt;code>Ctrl + A&lt;/code> ，松开后再按下 &lt;code>x&lt;/code> 键即可退出 QEMU 。&lt;/p>
&lt;p>如果想要往 QEMU 里面传输文件，可以使用挂载的方式，如下所示：&lt;/p>
&lt;pre>&lt;code class="language-bash">$ mkdir rootfs
$ sudo mount -o loop rootfs.img rootfs
$ cp [-r] [file] ./rootfs/
$ sudo umount rootfs
&lt;/code>&lt;/pre>
&lt;h2 id="五总结">五、总结&lt;/h2>
&lt;p>至此，我们已经成功搭建了玄铁 900 系列的工具链环境以及 xuantie-qemu 仿真环境，这为后续的开发、编译、链接以及运行和调试基于玄铁 900 系列芯片的 RISC-V 应用程序奠定了基础。&lt;/p></description></item><item><title>OpenMP 简介</title><link>https://cuterwrite.top/p/openmp-intro/</link><pubDate>Mon, 19 Feb 2024 01:36:00 +0000</pubDate><guid>https://cuterwrite.top/p/openmp-intro/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/c17b7451a44c1d4370d5ba2b966298ea195413_crop-2024-02-19.webp" alt="Featured image of post OpenMP 简介" />&lt;h1 id="openmp-简介">OpenMP 简介&lt;/h1>
&lt;h2 id="简介">简介&lt;/h2>
&lt;h3 id="什么是-openmp">什么是 OpenMP？&lt;/h3>
&lt;p>OpenMP（Open Multi-Processing）是一种广泛应用的多线程并行编程模型，它为共享内存系统上的并行计算提供了丰富的指令集和 API。起源于 1997 年，OpenMP 由多个领先硬件和软件供应商共同制定标准，旨在简化并行程序的设计与实现过程，以充分利用现代多核处理器的计算能力。&lt;/p>
&lt;p>OpenMP 支持多种编程语言，包括 C、C++ 以及 Fortran 等，并通过在源代码中插入特定的编译指示（pragma），使得开发者能够轻松地将串行代码转化为高效的并行代码。其主要优势在于其简洁性和易用性，允许程序员使用熟悉的编程语言和开发环境，同时提供良好的可移植性和扩展性。&lt;/p>
&lt;p>OpenMP 由非营利性组织管理，由多家软硬件厂家参与，包括 Arm，IBM，Intel，AMD，NVIDIA，Cray，Oracle 等。&lt;/p>
&lt;h3 id="历史版本">历史版本&lt;/h3>
&lt;ul>
&lt;li>在 &lt;a class="link" href="https://www.openmp.org/" target="_blank" rel="noopener" >官网页面
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
可以查询到 OpenMP 的历史版本和发布日期。&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>版本&lt;/th>
&lt;th>发布日期&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Fortran 1.0&lt;/td>
&lt;td>October 1997&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>C/C++ 1.0&lt;/td>
&lt;td>October 1998&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>C/C++ 2.0&lt;/td>
&lt;td>March 2002&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>OpenMP 2.5&lt;/td>
&lt;td>May 2005&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>OpenMP 3.0&lt;/td>
&lt;td>May 2008&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>OpenMP 3.1&lt;/td>
&lt;td>July 2011&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>OpenMP 4.0&lt;/td>
&lt;td>July 2013&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>OpenMP 4.5&lt;/td>
&lt;td>November 2015&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>OpenMP 5.0&lt;/td>
&lt;td>November 2018&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>OpenMP 5.1&lt;/td>
&lt;td>November 2020&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>OpenMP 5.2&lt;/td>
&lt;td>November 2021&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="基础知识">基础知识&lt;/h2>
&lt;h3 id="技术框架">技术框架&lt;/h3>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/openmp-arch-2024-02-20.webp"
alt="openmp-arch-2024-02-20" width="auto" loading="lazy"/>&lt;figcaption>
&lt;h4>OpenMP 技术框架&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>&lt;strong>OpenMP Runtime Library&lt;/strong> 是 OpenMP 规范中定义的一组函数和运行时支持结构，它是 OpenMP 并行编程框架的关键组成部分。这个库在编译器的支持下与用户程序链接，在程序执行时负责管理线程的创建、同步、调度以及数据共享等任务。它实现了 OpenMP 编译指导所指示的所有并行化机制。&lt;/p>
&lt;p>&lt;strong>OpenMP Runtime Library&lt;/strong> 包括了如下功能：&lt;/p>
&lt;ul>
&lt;li>线程管理（创建、销毁、同步）
= 工作共享（动态工作分配给各个线程）
= 任务调度
= 同步原语（如 barriers, locks, atomic operations）
= 动态调整线程数量&lt;/li>
&lt;li>内存模型支持（数据环境变量、private, shared, reduction 变量等）&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Compiler Directives&lt;/strong> 编译指导是以 &lt;code>#pragma omp&lt;/code> 开头的预处理器指令，程序员在源代码中插入这些指令来指导编译器如何将串行程序转换为并行程序。例如，使用 &lt;code>#pragma omp parallel&lt;/code> 指令定义一个并行区域，编译器会在此区域内生成多线程执行逻辑。&lt;/p>
&lt;p>&lt;strong>Environment Variables&lt;/strong> 环境变量是 OpenMP 运行时库的一部分，它们用于控制运行时行为，例如线程数量、调度策略等。&lt;/p>
&lt;p>&lt;strong>OpenMP Library&lt;/strong> 是一组函数库，包括了一些用于线程同步、原子操作、锁、并行循环等的函数。这些函数可以在用户程序中直接调用，以实现更细粒度的并行化。&lt;/p>
&lt;p>总的来说，OpenMP 技术框架包括了编译器指导、运行时库、环境变量和函数库等多个组成部分，它们共同构成了一个完整的并行编程环境，共同协作以支持在共享内存系统上的并行编程。&lt;/p>
&lt;h3 id="执行模型fork-join-model">执行模型：Fork-Join Model&lt;/h3>
&lt;p>OpenMP 的执行模型采用的是 Fork-Join 机制，这是一种用于并行编程中的同步原语模型。在该模型下，程序执行遵循以下步骤：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Fork（派生）阶段&lt;/strong>： 程序开始时以单个主线程执行，当遇到 OpenMP 编译指导（pragma）指示的并行区域时，主线程会通过 Runtime Library 创建一个或多个工作线程（worker threads）。这些工作线程是对主线程的派生，每个线程负责执行并行区域内的部分任务。并行区域可以是循环、段（sections）、单一任务或其他可并行化的代码块。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Parallel Execution（并行执行）阶段&lt;/strong>： 创建出的工作线程独立并发地执行分配给它们的任务，并且能够访问共享的数据结构。OpenMP 提供了一套丰富的指令来管理数据的同步和通信，确保在多线程环境下的正确性和一致性。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Join（合并）阶段&lt;/strong>： 当所有工作线程完成其在并行区域内的任务后，它们会自动或者通过显式同步指令（如 &lt;code>omp barrier&lt;/code> ）汇聚到 join 点。在此阶段，所有线程等待直至所有其他线程都到达了同步点，随后 join 操作发生。这意味着主线程和其他工作线程重新同步，恢复为串行执行模式或继续执行后续的非并行代码。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Synchronization and Data Consistency（同步与数据一致性）&lt;/strong>： Fork-Join 模型确保了在并行执行过程中，通过适当的锁机制、原子操作和同步原语保证了对共享资源的互斥访问以及数据的一致性。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>总结来说，OpenMP 的 Fork-Join 执行模型是一种基于动态线程创建和同步的并行处理框架，它允许开发者方便地将串行代码转化为并行执行的代码片段，同时简化了并行编程中常见的复杂性，如线程管理和数据同步问题。&lt;/p>
&lt;h3 id="线程与进程">线程与进程&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>进程&lt;/p>
&lt;ul>
&lt;li>每个进程都有自己独立的地址空间&lt;/li>
&lt;li>CPU 在进程间切换时需要进行上下文切换&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>线程&lt;/p>
&lt;ul>
&lt;li>一个进程下的线程共享相同的地址空间&lt;/li>
&lt;li>CPU 在线程之间切换开销较小&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>操作系统的线程设计&lt;/p>
&lt;ul>
&lt;li>现代操作系统如 Linux、Windows 等都支持一个进程下有多个线程。&lt;/li>
&lt;li>线程是操作系统调度的基本单位，进程是资源分配的基本单位。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/slide_10-2024-02-20.webp"
alt="slide_10-2024-02-20" width="80%" loading="lazy"/>&lt;figcaption>
&lt;h4>操作系统的线程设计&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;h3 id="线程的硬件调度">线程的硬件调度&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>硬件调度机制与操作系统协同，负责将线程智能地映射至可用的 CPU 物理核心上执行。&lt;/strong>&lt;/li>
&lt;li>因此，在多线程应用中，当活跃线程数超过了实际 CPU 物理核心的数量时，操作系统将不得不进行密集的上下文切换，以确保多个线程在有限的核心资源上交替运行，这种线程竞争过载的现象会导致整体性能瓶颈和效率下降。&lt;/li>
&lt;li>&lt;strong>超线程技术（Hyper-Threading）&lt;/strong> 通过在单个物理 CPU 核心上虚拟化出额外的逻辑处理单元，当前通常配置为每个物理核心承载两个逻辑核心。这些逻辑核心能够并行执行独立的任务流，尽管它们共享同一物理核心的基础计算资源，如执行引擎、缓存和其他底层硬件结构。通过这种方式，超线程旨在提高资源利用率和并发处理能力，尤其是在存在大量并行任务且其对计算资源需求相对较小的情况下，可以有效提升系统的总体吞吐量。然而，在某些高度依赖单一核心性能或内存带宽的应用场景下，如部分对 CPU 敏感的游戏或特定类型的数据密集型运算，增加逻辑核心可能并不一定能带来显著的性能提升。&lt;/li>
&lt;/ul>
&lt;h3 id="硬件的内存模型">硬件的内存模型&lt;/h3>
&lt;ul>
&lt;li>在现代多核处理器体系结构中，每个 CPU 核心为了进一步提升数据访问速度，在与主存之间设计有多级缓存层次结构。最靠近 CPU 核心的是 L1 缓存，通常其后是 L2 缓存，部分高端架构还包含 L3 缓存，这些高速缓存层级存储容量逐层增大，但访问延迟逐层增加。&lt;/li>
&lt;li>L1 和 L2 缓存通常是与特定 CPU 核心紧密耦合且私有的，这意味着每个核心拥有自己的独立缓存空间，以降低数据访问冲突并提高缓存命中率。L1 缓存由于距离计算单元最近，其访问速度最快，但容量最小；而 L2 缓存作为 L1 缓存的有效补充，具有相对较大的容量。&lt;/li>
&lt;li>为确保在多核环境中不同 CPU 核心的缓存中对共享数据的一致性，硬件和操作系统共同实现了缓存一致性协议（如 MESI 协议）。这种机制允许系统自动维护一个全局一致的数据视图，即使数据在多个核心的缓存中存在副本也能保证它们同步更新，这一特性在某些架构中被称作 &lt;strong>ccNUMA（cache-coherent non-uniform memory access）&lt;/strong> ，即缓存一致性非统一内存访问。&lt;/li>
&lt;li>然而，这种缓存一致性管理也带来了一些挑战，其中之一就是“伪共享”(False Sharing)问题。当不同的线程修改位于同一缓存行内的各自独立变量时，尽管这些变量本身并无关联，但由于它们物理上相邻而被存储在同一缓存行内，因此任何针对其中一个变量的写操作都会导致整个缓存行失效并在所有核心间重新同步。这会引发不必要的缓存无效化与重新填充操作，从而显著降低性能。解决伪共享问题通常需要精心设计数据布局或利用缓存行对齐等技术手段来避免无关数据之间的争用。&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/20170115165700476-2024-02-20.webp"
alt="20170115165700476-2024-02-20" width="auto" loading="lazy"/>&lt;figcaption>
&lt;h4>典型的现代 CPU 内存结构&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;h3 id="线程亲和性和线程绑定">线程亲和性和线程绑定&lt;/h3>
&lt;ul>
&lt;li>线程亲和性（Thread Affinity）是指操作系统或应用程序控制特定线程与处理器核心之间关联的能力。在多核或多处理器系统中，线程亲和性允许程序员或调度器决定将某个线程固定在特定的 CPU 核心上运行，而不是让操作系统自由地在所有可用的核心间进行动态调度。这种机制有助于减少上下文切换开销，提高缓存命中率，并且对于需要保持数据局部性的并行计算任务特别有益。&lt;/li>
&lt;li>线程绑定（Thread Pinning）是实现线程亲和性的具体技术手段，它指明了将特定线程与特定硬件资源（如 CPU 核心或 NUMA 节点）之间的强制关联。通过线程绑定，可以确保指定的线程始终在其分配的核心上执行，避免被操作系统迁移到其他核心，从而优化性能、减少延迟并解决伪共享等问题。在 OpenMP 等并行编程模型中，可以通过相关的环境变量或编译指导来设置线程绑定策略，以适应不同的并行计算需求和硬件特性。&lt;/li>
&lt;li>同一个插槽上的 CPU 对 L3 缓存的访问延迟是一致的，但不同插槽上的 CPU 对 L3 缓存的访问延迟是不一致的。因此，线程绑定的目的是为了减少线程在不同 CPU 之间的迁移，从而减少访存延迟。&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/u=237293070,3563798054&amp;amp;fm=253&amp;amp;app=138&amp;amp;f=JPEG-2024-02-20.webp"
alt="u=237293070,3563798054&amp;amp;fm=253&amp;amp;app=138&amp;amp;f=JPEG-2024-02-20" width="auto" loading="lazy"/>&lt;figcaption>
&lt;h4>线程亲和性和线程绑定&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;ul>
&lt;li>OpenMP 支持控制线程的绑定
&lt;ul>
&lt;li>环境变量 &lt;code>OMP_PROC_BIND&lt;/code> 或从句 &lt;code>proc_bind(master|close|spread)&lt;/code> 控制线程绑定与否，以及线程对于绑定单元（称为 place）分布&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="openmp-编程">OpenMP 编程&lt;/h2>
&lt;h3 id="安装">安装&lt;/h3>
&lt;p>对于 Linux 系统，GCC 是常用的编译器，现代版本的 GCC 一般已默认支持 OpenMP。例如在 Ubuntu 20.04 LTS 上，可以通过以下命令安装含有 OpenMP 的 build-essential 包：&lt;/p>
&lt;pre>&lt;code class="language-bash">$ sudo apt-get update
$ sudo apt-get install -y build-essential
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>查看 OpenMP 版本&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-bash">$ echo |cpp -fopenmp -dM |grep -i open
#define _OPENMP 201511
&lt;/code>&lt;/pre>
&lt;h3 id="编译使用">编译使用&lt;/h3>
&lt;ul>
&lt;li>直接在编译语句中添加 &lt;code>-fopenmp&lt;/code> 选项即可开启 OpenMP 支持。&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-bash">g++ -O2 -std=c++17 -fopenmp hello.cpp -o hello
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>如果使用 CMake 构建项目, 加入 &lt;code>-Wunknown-pragmas&lt;/code> 选项可以在编译时报告未处理的 &lt;code>#pragma&lt;/code> 指令。&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-cmake">find_package(OpenMP REQUIRED)
add_compile_options(-Wunknown-pragmas)
add_executable(hello hello.cpp)
target_link_libraries(hello PRIVATE OpenMP::OpenMP_CXX)
&lt;/code>&lt;/pre>
&lt;h3 id="hello-world">Hello World!&lt;/h3>
&lt;ul>
&lt;li>第一个 OpenMP 程序&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-c">#include &amp;lt;omp.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;
int main() {
#pragma omp parallel num_threads(8)
{
int id = omp_get_thread_num();
int num_threads = omp_get_num_threads();
printf(&amp;quot;Hello World from thread %d of %d \n&amp;quot;, id, num_threads);
}
return 0;
}
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>运行结果&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-bash">$ gcc -fopenmp hello.c -o hello
$ ./hello
Hello World from thread 7 of 8
Hello World from thread 6 of 8
Hello World from thread 0 of 8
Hello World from thread 3 of 8
Hello World from thread 1 of 8
Hello World from thread 2 of 8
Hello World from thread 5 of 8
Hello World from thread 4 of 8
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>同一类 openmp 制导语句称为一种构造(construct)&lt;/li>
&lt;li>形式为 &lt;code>#pragma omp &amp;lt;directive name&amp;gt; &amp;lt;clause&amp;gt;&lt;/code>&lt;/li>
&lt;li>使用 &lt;code>{}&lt;/code> 包裹的代码块称为并行区域(parallel region)&lt;/li>
&lt;/ul>
&lt;h3 id="线程数设置">线程数设置&lt;/h3>
&lt;ul>
&lt;li>优先级由低到高
&lt;ul>
&lt;li>什么都不做，系统选择运行线程数&lt;/li>
&lt;li>设置环境变量 &lt;code>export OMP_NUM_THREADS=4&lt;/code>&lt;/li>
&lt;li>代码中使用库函数 &lt;code>void omp_set_num_threads(int)&lt;/code>&lt;/li>
&lt;li>通过制导语句 &lt;code>num_threads(4)&lt;/code>&lt;/li>
&lt;li>if 从句判断串行还是并行执行&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="常用库函数">常用库函数&lt;/h3>
&lt;ul>
&lt;li>设置并行区运行线程数：&lt;code>void omp_set_num_threads(int)&lt;/code>&lt;/li>
&lt;li>获取并行区运行线程数：&lt;code>int omp_get_num_threads()&lt;/code>&lt;/li>
&lt;li>获取当前线程编号：&lt;code>int omp_get_thread_num()&lt;/code>&lt;/li>
&lt;li>获得 OpenMP Wall Clock 时间（单位：秒）：&lt;code>double omp_get_wtime()&lt;/code>&lt;/li>
&lt;li>获得时间精度：&lt;code>double omp_get_wtick()&lt;/code>&lt;/li>
&lt;/ul>
&lt;h3 id="parallel-构造">Parallel 构造&lt;/h3>
&lt;p>&lt;strong>支持的从句&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;code>if(scalar_expression)&lt;/code>：如果 &lt;code>scalar_expression&lt;/code> 为真，则并行执行，否则串行执行。&lt;/li>
&lt;li>&lt;code>num_threads(integer_expression)&lt;/code>：指定并行区域中的线程数。&lt;/li>
&lt;li>&lt;code>default(shared|none)&lt;/code>：指定变量的默认共享性。
&lt;ul>
&lt;li>&lt;code>shared&lt;/code>：所有变量默认为共享。&lt;/li>
&lt;li>&lt;code>none&lt;/code>：无默认变量类型，每个变量都需要显式声明共享或私有。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>shared(list)&lt;/code>：指定共享变量列表。
&lt;ul>
&lt;li>共享变量在内存中只有一份，所有线程都可以访问。&lt;/li>
&lt;li>请保证共享变量访问不会冲突。&lt;/li>
&lt;li>不特别指定并行区变量默认为 &lt;strong>shared&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>private(list)&lt;/code>：指定私有变量列表。
&lt;ul>
&lt;li>私有变量在每个线程中都有一份独立的拷贝。&lt;/li>
&lt;li>变量需要 &lt;strong>重新初始化&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>firstprivate(list)&lt;/code>：指定首次私有变量列表。
&lt;ul>
&lt;li>同 &lt;code>private&lt;/code>&lt;/li>
&lt;li>对变量根据主线程中的数据进行初始化。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;div class="notice notice-info" >
&lt;div class="notice-title">&lt;svg t="1705940100069" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6252" width="200" height="200">&lt;path d="M512 64C264.6 64 64 264.6 64 512s200.6 448 448 448 448-200.6 448-448S759.4 64 512 64z m32 664c0 4.4-3.6 8-8 8h-48c-4.4 0-8-3.6-8-8V456c0-4.4 3.6-8 8-8h48c4.4 0 8 3.6 8 8v272z m-32-344c-26.5 0-48-21.5-48-48s21.5-48 48-48 48 21.5 48 48-21.5 48-48 48z" p-id="6253" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>示例 1： no clause、private、firstprivate&lt;/p>&lt;/div>
&lt;pre>&lt;code class="language-c">int results[4];
int cnt;
cnt = 1;
#pragma omp parallel num_threads(4)
{
int tid = omp_get_thread_num();
for (int i = 0; i &amp;lt; 4; i++) {
cnt += 1;
}
results[tid] = cnt;
}
printf(&amp;quot;no clause: &amp;quot;);
for (int i = 0; i &amp;lt; 4; i++) {
printf(&amp;quot;%d &amp;quot;, results[i]);
}
printf(&amp;quot;\n&amp;quot;);
cnt = 1;
#pragma omp parallel num_threads(4) private(cnt)
{
int tid = omp_get_thread_num();
for (int i = 0; i &amp;lt; 4; i++) {
cnt += 1;
}
results[tid] = cnt;
}
printf(&amp;quot;private(not init): &amp;quot;);
for (int i = 0; i &amp;lt; 4; i++) {
printf(&amp;quot;%d &amp;quot;, results[i]);
}
printf(&amp;quot;\n&amp;quot;);
cnt = 1;
#pragma omp parallel num_threads(4) firstprivate(cnt)
{
int tid = omp_get_thread_num();
for (int i = 0; i &amp;lt; 4; i++) {
cnt += 1;
}
results[tid] = cnt;
}
printf(&amp;quot;firstprivate: &amp;quot;);
for (int i = 0; i &amp;lt; 4; i++) {
printf(&amp;quot;%d &amp;quot;, results[i]);
}
printf(&amp;quot;\n&amp;quot;);
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>打印结果&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-bash">no clause: 5 9 13 17
private(not init): 4 1572916964 1572916964 1572916964
firstprivate: 5 5 5 5
&lt;/code>&lt;/pre>
&lt;h3 id="for-构造">For 构造&lt;/h3>
&lt;ul>
&lt;li>最常用的并行化构造之一&lt;/li>
&lt;/ul>
&lt;div class="notice notice-info" >
&lt;div class="notice-title">&lt;svg t="1705940100069" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6252" width="200" height="200">&lt;path d="M512 64C264.6 64 64 264.6 64 512s200.6 448 448 448 448-200.6 448-448S759.4 64 512 64z m32 664c0 4.4-3.6 8-8 8h-48c-4.4 0-8-3.6-8-8V456c0-4.4 3.6-8 8-8h48c4.4 0 8 3.6 8 8v272z m-32-344c-26.5 0-48-21.5-48-48s21.5-48 48-48 48 21.5 48 48-21.5 48-48 48z" p-id="6253" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>示例 2：并行化 for 循环&lt;/p>&lt;/div>
&lt;pre>&lt;code class="language-c">#pragma omp parallel num_threads(8)
{
int tid = omp_get_thread_num();
int num_threads = omp_get_num_threads();
#pragma omp for
for (int i = 0; i &amp;lt; num_threads; i++) {
#pragma omp ordered
printf(&amp;quot;Hello from thread %d of %d \n&amp;quot;, tid, num_threads);
}
}
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>打印结果&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-bash">Hello from thread 0 of 8
Hello from thread 1 of 8
Hello from thread 2 of 8
Hello from thread 3 of 8
Hello from thread 4 of 8
Hello from thread 5 of 8
Hello from thread 6 of 8
Hello from thread 7 of 8
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>在并行区内对 for 循环进行线程划分，且 for 循环满足格式要求
&lt;ul>
&lt;li>init-expr:需要是 &lt;code>var=lb&lt;/code> 形式，类型也有限制&lt;/li>
&lt;li>test-expr:限制为 &lt;code>var relational-opb&lt;/code> 或者 &lt;code>b relational-op var&lt;/code>&lt;/li>
&lt;li>incr-expr:仅限加减法&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="parallel-for-构造">Parallel for 构造&lt;/h3>
&lt;ul>
&lt;li>常常将 &lt;code>parallel&lt;/code> 和 &lt;code>for&lt;/code> 结合使用，合并为 &lt;code>parallel for&lt;/code> 制导语句&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>parallel&lt;/th>
&lt;th>for   &lt;/th>
&lt;th>parallel for&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>if&lt;/td>
&lt;td>✅&lt;/td>
&lt;td>❌&lt;/td>
&lt;td>✅&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>num_threads&lt;/td>
&lt;td>✅&lt;/td>
&lt;td>❌&lt;/td>
&lt;td>✅&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>default&lt;/td>
&lt;td>✅&lt;/td>
&lt;td>❌&lt;/td>
&lt;td>✅&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>copyin&lt;/td>
&lt;td>✅&lt;/td>
&lt;td>❌&lt;/td>
&lt;td>✅&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>private&lt;/td>
&lt;td>✅&lt;/td>
&lt;td>✅&lt;/td>
&lt;td>✅&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>firstprivate&lt;/td>
&lt;td>✅&lt;/td>
&lt;td>✅&lt;/td>
&lt;td>✅&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>shared&lt;/td>
&lt;td>✅&lt;/td>
&lt;td>✅&lt;/td>
&lt;td>✅&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>reduction&lt;/td>
&lt;td>✅&lt;/td>
&lt;td>✅&lt;/td>
&lt;td>✅&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>lastprivate&lt;/td>
&lt;td>❌&lt;/td>
&lt;td>✅&lt;/td>
&lt;td>✅&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>schedule&lt;/td>
&lt;td>❌&lt;/td>
&lt;td>✅&lt;/td>
&lt;td>✅&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ordered&lt;/td>
&lt;td>❌&lt;/td>
&lt;td>✅&lt;/td>
&lt;td>✅&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>collapse&lt;/td>
&lt;td>❌&lt;/td>
&lt;td>✅&lt;/td>
&lt;td>✅&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>nowait&lt;/td>
&lt;td>❌&lt;/td>
&lt;td>✅&lt;/td>
&lt;td>❌&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ul>
&lt;li>
&lt;p>&lt;code>lastprivate(list)&lt;/code>&lt;/p>
&lt;ul>
&lt;li>同 &lt;code>private&lt;/code>&lt;/li>
&lt;li>执行完 for 循环后，将最后一个线程的值赋给主线程的变量。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>nowait&lt;/code>：取消代码块结束时的栅栏同步(barrier)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>collapse(n)&lt;/code>：应用于 n 重循环，合并(展开)循环&lt;/p>
&lt;ul>
&lt;li>注意循环之间是否有数据依赖&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>ordered&lt;/code>：声明有潜在的顺序执行部分&lt;/p>
&lt;ul>
&lt;li>使用 &lt;code>#pragma omp ordered&lt;/code> 标记顺序执行代码(搭配使用)&lt;/li>
&lt;li>ordered 区内的语句任意时刻仅由最多一个线程执行&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>shedule(type[,chunk])&lt;/code>&lt;/p>
&lt;ul>
&lt;li>&lt;code>type&lt;/code>：指定循环迭代的调度策略
&lt;ul>
&lt;li>&lt;code>static&lt;/code>：静态调度，chunk 大小固定（默认 n/p ）&lt;/li>
&lt;li>&lt;code>dynamic&lt;/code>：动态调度，chunk 大小固定（默认为 1）&lt;/li>
&lt;li>&lt;code>guided&lt;/code>：引导调度，chunk 大小动态调整&lt;/li>
&lt;li>&lt;code>runtime&lt;/code>：由系统环境变量 &lt;code>OMP_SCHEDULE&lt;/code> 指定&lt;/li>
&lt;li>&lt;code>auto&lt;/code>：自动调度&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>chunk&lt;/code>：指定每个线程获取的迭代次数&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="特殊的数据从句reduction">特殊的数据从句：Reduction&lt;/h3>
&lt;p>在 OpenMP 中，reduction 是一种并行编程技术，用于解决多线程环境下的数据竞争问题，特别是在计算全局变量的累加或类似操作时。当多个线程需要同时修改同一个共享变量，并且这些修改可以通过某种二元运算符（如加法、乘法等）将所有线程的结果合并成一个最终结果时，可以使用 &lt;code>reduction&lt;/code> 子句。&lt;/p>
&lt;p>具体来说，reducton 的执行过程为：&lt;/p>
&lt;ul>
&lt;li>fork 线程并分配任务&lt;/li>
&lt;li>每一个线程定义一个私有变量 &lt;code>omp_priv&lt;/code>
&lt;ul>
&lt;li>同 &lt;code>private&lt;/code>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>各个线程执行计算&lt;/li>
&lt;li>所有 &lt;code>omp_priv&lt;/code> 和 &lt;code>omp_in&lt;/code> 一起顺序进行 reduction，写回原变量。&lt;/li>
&lt;/ul>
&lt;p>相比之下，&lt;strong>atomic&lt;/strong> 是 OpenMP 提供的另一种同步机制，它确保对单个内存位置的访问在多线程环境中是原子性的，即一次只允许一个线程对该内存位置进行读取或写入操作。通过 &lt;code>#pragma omp atomic&lt;/code> 指令，可以保证一条简单的赋值语句（或某些特定类型的读改写操作）在并发环境下不会发生数据竞争。&lt;/p>
&lt;div class="notice notice-info" >
&lt;div class="notice-title">&lt;svg t="1705940100069" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6252" width="200" height="200">&lt;path d="M512 64C264.6 64 64 264.6 64 512s200.6 448 448 448 448-200.6 448-448S759.4 64 512 64z m32 664c0 4.4-3.6 8-8 8h-48c-4.4 0-8-3.6-8-8V456c0-4.4 3.6-8 8-8h48c4.4 0 8 3.6 8 8v272z m-32-344c-26.5 0-48-21.5-48-48s21.5-48 48-48 48 21.5 48 48-21.5 48-48 48z" p-id="6253" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>示例 3：Reduction&lt;/p>&lt;/div>
&lt;pre>&lt;code class="language-c">int sum = 0;
double start = omp_get_wtime();
#pragma omp parallel for num_threads(8) reduction(+ : sum)
for (int i = 0; i &amp;lt; 100000; i++) {
sum += i;
}
printf(&amp;quot;sum = %d\n&amp;quot;, sum);
printf(&amp;quot;Reduction time: %.5lf s\n&amp;quot;, omp_get_wtime() - start);
// no reduction
sum = 0;
start = omp_get_wtime();
#pragma omp parallel for num_threads(8)
for (int i = 0; i &amp;lt; 100000; i++) {
#pragma omp atomic
sum += i;
}
printf(&amp;quot;sum = %d\n&amp;quot;, sum);
printf(&amp;quot;Atomic time: %.5lf s\n&amp;quot;, omp_get_wtime() - start);
return 0;
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>打印结果&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-bash">sum = 704982704
Reduction time: 0.00062 s
sum = 704982704
Atomic time: 0.01021 s
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>两者结果相同，但是 reduction 的执行时间更短，这是因为 reduction 通过为每个线程分配一个私有副本，线程可以在其私有空间内自由地执行归约操作，而不需要在更新全局结果时与其他线程争夺锁资源，加上高效的数据合并方法等。&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/reduction-omp-2024-02-20.webp"
alt="reduction-omp-2024-02-20" width="auto" loading="lazy"/>&lt;figcaption>
&lt;h4>OpenMP reducton operation&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;h3 id="同步构造">同步构造&lt;/h3>
&lt;h4 id="sections-构造">Sections 构造&lt;/h4>
&lt;ul>
&lt;li>将并行区的代码块划分为多个 section 分配执行。&lt;/li>
&lt;li>可以搭配 parallel 合成为 parallel sections 构造。&lt;/li>
&lt;li>每个 section 由一个线程执行
&lt;ul>
&lt;li>线程数大于 section 数目：部分线程空闲&lt;/li>
&lt;li>线程数小于 section 数目：部分线程分配多个 section&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>示例代码：&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-c">#pragma omp sections
{
#pragma omp section
method1();
#pragma omp section
method2();
}
&lt;/code>&lt;/pre>
&lt;h4 id="barrier-构造">Barrier 构造&lt;/h4>
&lt;ul>
&lt;li>在特定位置进行栅栏同步&lt;/li>
&lt;li>在存在数据依赖的情况下，可以使用 barrier 保证数据的一致性&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/Barrier-2024-02-20.webp"
alt="Barrier-2024-02-20" width="auto" loading="lazy"/>&lt;figcaption>
&lt;h4>Barrier 同步示意图&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;h4 id="single-构造">Single 构造&lt;/h4>
&lt;ul>
&lt;li>用于标记只有一个线程执行的代码块，带有隐式的 barrier 同步，可以使用 nowait 取消隐式的 barrier 同步。&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/omp-single-2024-02-20.webp"
alt="omp-single-2024-02-20" width="70%" loading="lazy"/>&lt;figcaption>
&lt;h4>pragma single&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;h4 id="atomic-构造">Atomic 构造&lt;/h4>
&lt;ul>
&lt;li>用于保证对共享变量的原子操作，避免数据竞争。&lt;/li>
&lt;/ul>
&lt;h3 id="false-sharing">False Sharing&lt;/h3>
&lt;ul>
&lt;li>伪共享简单来说就是指多个线程同时访问同一缓存行的不同部分，导致缓存行的无效化和重新填充，从而降低了程序的性能。&lt;/li>
&lt;li>不同核心对同一 Cache line 的同时读写会造成严重的冲突，导致改级缓存失效。&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/false-sharing-2024-02-20.webp"
alt="false-sharing-2024-02-20" width="auto" loading="lazy"/>&lt;figcaption>
&lt;h4>False Sharing 问题&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;ul>
&lt;li>在 OpenMP 中，解决伪共享的方法主要有：
&lt;ul>
&lt;li>&lt;strong>数据结构对齐&lt;/strong> ：通过使用编译器提供的对齐指令或关键字确保相关变量分别处于不同的缓存行中。例如，在 C++中可以使用 &lt;code>alignas&lt;/code> 关键字来指定变量的内存对齐方式，确保每个线程的数据独立位于不同的缓存行。&lt;/li>
&lt;li>&lt;strong>增大缓存行之间的间距&lt;/strong> ：在相邻变量之间插入足够的填充空间，使得它们不会出现在同一个缓存行内。&lt;/li>
&lt;li>&lt;strong>避免无意义的竞争&lt;/strong> ：设计算法和数据结构以减少不必要的共享数据访问。如果可能，尽量让线程操作各自独立的数据段。&lt;/li>
&lt;li>&lt;strong>自定义内存分配&lt;/strong> ：使用特殊的内存分配函数，确保分配的连续内存区域对齐到缓存行边界，这样分配给不同线程的数据就不会落在同一缓存行上。&lt;/li>
&lt;li>在某些情况下，可以利用特定平台提供的硬件特性或者编译器支持的扩展，比如 Intel 的 &lt;code>__declspec(align(#))&lt;/code> 属性（对于 MSVC）或者 &lt;code>__attribute__((aligned(#)))&lt;/code>（对于 GCC/Clang）。&lt;/li>
&lt;li>也可以通过控制变量的作用域或者利用动态创建私有副本等技术来间接避免伪共享问题。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="任务构造">任务构造&lt;/h3>
&lt;ul>
&lt;li>除了 Fork-Join 模型外，OpenMP 还支持任务并行模型，通过 &lt;code>task&lt;/code> 制导语句来实现。&lt;/li>
&lt;li>即动态地管理线程池和任务池，线程池中的线程可以动态地获取任务池中的任务进行执行，从而实现任务的并行执行。&lt;/li>
&lt;/ul>
&lt;div class="notice notice-info" >
&lt;div class="notice-title">&lt;svg t="1705940100069" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="6252" width="200" height="200">&lt;path d="M512 64C264.6 64 64 264.6 64 512s200.6 448 448 448 448-200.6 448-448S759.4 64 512 64z m32 664c0 4.4-3.6 8-8 8h-48c-4.4 0-8-3.6-8-8V456c0-4.4 3.6-8 8-8h48c4.4 0 8 3.6 8 8v272z m-32-344c-26.5 0-48-21.5-48-48s21.5-48 48-48 48 21.5 48 48-21.5 48-48 48z" p-id="6253" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>示例 4：任务并行&lt;/p>&lt;/div>
&lt;pre>&lt;code class="language-c">#include &amp;lt;iostream&amp;gt;
#include &amp;lt;omp.h&amp;gt;
#include &amp;lt;unistd.h&amp;gt;
#include &amp;lt;iomanip&amp;gt;
void big_task(int i) {
sleep(10);
}
void small_task(int i) {
sleep(1);
}
int main() {
int ntasks = 8;
double start = omp_get_wtime();
#pragma omp parallel
{
#pragma omp single
{
std::cout &amp;lt;&amp;lt; &amp;quot;Task 0 Created&amp;quot; &amp;lt;&amp;lt; std::endl;
#pragma omp task
big_task(0);
std::cout &amp;lt;&amp;lt; &amp;quot;Task 1 Created&amp;quot; &amp;lt;&amp;lt; std::endl;
#pragma omp task
big_task(1);
for (int i = 2; i &amp;lt; ntasks; i++) {
std::cout &amp;lt;&amp;lt; &amp;quot;Task &amp;quot; &amp;lt;&amp;lt; i &amp;lt;&amp;lt; &amp;quot; Created&amp;quot; &amp;lt;&amp;lt; std::endl;
#pragma omp task
small_task(i);
}
}
#pragma omp taskwait
}
std::cout &amp;lt;&amp;lt; &amp;quot;All tasks finished&amp;quot; &amp;lt;&amp;lt; std::endl;
std::cout &amp;lt;&amp;lt; &amp;quot;Time: &amp;quot; &amp;lt;&amp;lt; std::fixed &amp;lt;&amp;lt; std::setprecision(2) &amp;lt;&amp;lt; omp_get_wtime() - start &amp;lt;&amp;lt; &amp;quot;s&amp;quot; &amp;lt;&amp;lt; std::endl;
return 0;
}
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>运行结果&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-bash">$ g++ -fopenmp task.cpp -o task
$ ./task
Task 0 Created
Task 1 Created
Task 2 Created
Task 3 Created
Task 4 Created
Task 5 Created
Task 6 Created
Task 7 Created
All tasks finished
Time: 10.00s
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>这段代码中，我们使用了 &lt;code>#pragma omp task&lt;/code> 制导语句来创建任务，任务的执行由线程池中的线程动态获取并执行。在任务创建后，我们使用 &lt;code>#pragma omp taskwait&lt;/code> 来等待所有任务执行完毕。达到了一个异步执行的效果。&lt;/li>
&lt;/ul>
&lt;h3 id="向量化simd-构造">向量化：SIMD 构造&lt;/h3>
&lt;ul>
&lt;li>SIMD（Single Instruction, Multiple Data）是一种并行计算模式，它通过一条指令同时对多个数据进行操作，从而实现高效的数据并行计算。&lt;/li>
&lt;li>在 OpenMP 中，可以使用 &lt;code>#pragma omp simd&lt;/code> 制导语句来实现向量化并行计算。
&lt;ul>
&lt;li>&lt;code>aligned&lt;/code> 用于列出内存对齐的指针&lt;/li>
&lt;li>&lt;code>safelen&lt;/code> 用于标记循环展开时的数据依赖&lt;/li>
&lt;li>&lt;code>linear&lt;/code> 用于标记循环变量的线性关系&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>编译器例如 gcc 也自带向量化功能，一般使用以下编译选项
&lt;ul>
&lt;li>-O3&lt;/li>
&lt;li>-ffast-math&lt;/li>
&lt;li>-fivopts&lt;/li>
&lt;li>-march=native&lt;/li>
&lt;li>-fopt-info-vec&lt;/li>
&lt;li>-fopt-info-vec-missed&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item></channel></rss>