<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>高性能计算 on Cuterwrite's Blog</title><link>https://cuterwrite.top/categories/hpc/</link><description>Recent content in 高性能计算 on Cuterwrite's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>cuterwrite</copyright><lastBuildDate>Tue, 13 Aug 2024 22:44:00 +0000</lastBuildDate><atom:link href="https://cuterwrite.top/categories/hpc/index.xml" rel="self" type="application/rss+xml"/><item><title>Arm 矩阵加速：可伸缩矩阵扩展 SME</title><link>https://cuterwrite.top/p/arm-sme-for-performance/</link><pubDate>Tue, 13 Aug 2024 22:44:00 +0000</pubDate><guid>https://cuterwrite.top/p/arm-sme-for-performance/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-14_117622407_p0_master1200.webp" alt="Featured image of post Arm 矩阵加速：可伸缩矩阵扩展 SME" />&lt;h1 id="arm-矩阵加速可伸缩矩阵扩展-sme">
&lt;a href="#arm-%e7%9f%a9%e9%98%b5%e5%8a%a0%e9%80%9f%e5%8f%af%e4%bc%b8%e7%bc%a9%e7%9f%a9%e9%98%b5%e6%89%a9%e5%b1%95-sme" class="header-anchor">#&lt;/a>
Arm 矩阵加速：可伸缩矩阵扩展 SME
&lt;/h1>
&lt;h2 id="1-sme-简介">
&lt;a href="#1-sme-%e7%ae%80%e4%bb%8b" class="header-anchor">#&lt;/a>
1. SME 简介
&lt;/h2>
&lt;p>可伸缩矩阵扩展 SME (Scalable Matrix Extension) SME 是在可伸缩向量扩展（Scalable Vector Extensions， SVE 和 SVE2）的基础上建立的，并增加了有效处理矩阵的能力，主要功能包括：&lt;/p>
&lt;ul>
&lt;li>计算 SVE 向量的外积（Outer product）&lt;/li>
&lt;li>矩阵块（tile） 存储&lt;/li>
&lt;li>tile 向量的加载、存储、插入和提取（包括动态转置）&lt;/li>
&lt;li>Streaming SVE 模式&lt;/li>
&lt;/ul>
&lt;p>下表总结了 SME、SVE 和 SVE2 的主要功能：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: left">SME&lt;/th>
&lt;th style="text-align: left">SVE&lt;/th>
&lt;th style="text-align: left">SVE2&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: left">Streaming SVE 模式&lt;/td>
&lt;td style="text-align: left">NEON DSP++&lt;/td>
&lt;td style="text-align: left">可伸缩向量&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">动态矩阵转置&lt;/td>
&lt;td style="text-align: left">多精度算术&lt;/td>
&lt;td style="text-align: left">per-lane predication&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">向量外积&lt;/td>
&lt;td style="text-align: left">匹配检测和直方图&lt;/td>
&lt;td style="text-align: left">Gather-load 与 Scatter-store&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">加载、存储、插入和提取矩阵向量&lt;/td>
&lt;td style="text-align: left">非时间性 scatter/gather&lt;/td>
&lt;td style="text-align: left">预测向量化&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">&lt;/td>
&lt;td style="text-align: left">按位置换（bitwise permute）&lt;/td>
&lt;td style="text-align: left">ML 扩展（FP16 + DOT）&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">&lt;/td>
&lt;td style="text-align: left">AE、SHA3、SM4、Crypto&lt;/td>
&lt;td style="text-align: left">V8.6 BF16, FP 与 Int8 支持&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>SME 定义了以下新功能：&lt;/p>
&lt;ul>
&lt;li>新的架构状态，可以用来存储二维矩阵 tile&lt;/li>
&lt;li>Streaming SVE 模式，支持执行向量长度与 tile 长度匹配的 SVE2 指令。&lt;/li>
&lt;li>将两个向量的外积累加（或累减）到一个矩阵 tile 中的新指令。&lt;/li>
&lt;li>新的加载、存储和移动指令：可以将向量写入到矩阵 tile 的一行或一列，也可以将矩阵 tile 的一行或一列读取到向量。&lt;/li>
&lt;/ul>
&lt;p>与 SVE2 类似，SME 也是一种支持可伸缩向量长度的扩展，可实现向量长度无关性 (VLA)、per-lane predication、predication 驱动的循环控制和管理功能。&lt;/p>
&lt;h2 id="2-streaming-sve-模式">
&lt;a href="#2-streaming-sve-%e6%a8%a1%e5%bc%8f" class="header-anchor">#&lt;/a>
2. Streaming SVE 模式
&lt;/h2>
&lt;p>SME 引入了 Streaming SVE 模式，该模式实现了 SVE2 指令集的一个子集，并增加了新的 SME 专用指令。&lt;/p>
&lt;p>Streaming SVE 模式支持对大型数据集进行高吞吐量地流式数据处理，流式数据通常具有简单的循环控制流和有限的条件性。&lt;/p>
&lt;p>在 Non-streaming SVE 模式下，支持完整的 SVE2 指令集，通常处理复杂的数据结构和复杂的判断。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-14_3443.webp"
alt="Streaming SVE 模式与 Non-streaming SVE 模式" width="80%" loading="lazy">&lt;figcaption>
&lt;h4>Streaming SVE 模式与 Non-streaming SVE 模式&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>大多数 SME 指令仅在 Streaming SVE 模式下可用。Streaming SVE 模式下的流向量长度（SVL）可能与非流向量长度（NSVL）不同。&lt;/p>
&lt;p>预期是：SVL 要比 NSVL 更长或是相同，也就是 SVL &amp;gt;= NSVL。例如，NSVL 的长度可以为 128-bit , 而 SVL 的长度可以为 512-bit 。&lt;/p>
&lt;p>SME 的 SVL 可以是 128-bit , 256-bit , 512-bit, 1024-bit 或是 2048-bit 。SVL 需要是 2 的次幂，而 NSVL 需要是 128 的整数倍。&lt;/p>
&lt;p>与 SVE2 类似，软件可以控制 &lt;code>SMCR_ELx.LEN&lt;/code> 寄存器位来设置 EL1, EL2, EL3 想用的有效 SVL 长度（可以设置为比硬件支持的 SVL 更短）。&lt;/p>
&lt;p>有关 Streaming SVE 模式的更多信息，请参阅《Arm 架构参考手册》第 B1.4.6 节（A-profile 架构）。&lt;/p>
&lt;h2 id="3-切换-non-streaming-和-streaming-sve-模式">
&lt;a href="#3-%e5%88%87%e6%8d%a2-non-streaming-%e5%92%8c-streaming-sve-%e6%a8%a1%e5%bc%8f" class="header-anchor">#&lt;/a>
3. 切换 Non-streaming 和 Streaming SVE 模式
&lt;/h2>
&lt;p>如果 CPU 硬件实现既支持 Streaming SVE 模式的 SME ，又支持 Non-streaming SVE 模式的 SVE2 ，应用程序可以根据自己的需求动态切换这两个操作模式。&lt;/p>
&lt;p>为 SME 提供一个独立的操作模式，使 CPU 硬件实现可以为同一应用提供不同的向量长度。比如 CPU 硬件实现可以选择支持一个更长的 Streaming SVE 模式向量长度，并针对适用于高吞吐量的流操作对硬件进行优化。&lt;/p>
&lt;p>应用程序很容易在 Streaming SVE 模式和 Non-streaming SVE 模式之间动态切换。SME 引入的 &lt;code>PSTATE.{SM, ZA}&lt;/code> 位可以可启用和禁用 Streaming SVE 模式和 SME ZA 存储：&lt;/p>
&lt;ul>
&lt;li>SM: 启用与禁用 Streaming SVE 模式&lt;/li>
&lt;li>ZA：启用和禁用 ZA 存储访问&lt;/li>
&lt;/ul>
&lt;p>可以通过 &lt;code>MSR/MRS&lt;/code> 指令操作 Streaming Vector Control Register (SVCR) 来设置和读取 &lt;code>PSTATE.{SM, ZA}&lt;/code> 位，具体操作如下：&lt;/p>
&lt;ul>
&lt;li>&lt;code>MSR SVCRSM, #&amp;lt;imm&amp;gt; MSR SVCRSM，#&lt;/code>&lt;/li>
&lt;li>&lt;code>MSR SVCRZA, #&amp;lt;imm&amp;gt;&lt;/code>&lt;/li>
&lt;li>&lt;code>MSR SVCRSMZA, #&amp;lt;imm&amp;gt;&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>SMSTART 指令是设置 &lt;code>PSTATE.SM&lt;/code> 和 &lt;code>PSTATE.ZA&lt;/code> 的 &lt;code>MSR&lt;/code> 指令的别名&lt;/p>
&lt;ul>
&lt;li>&lt;code>SMSTART&lt;/code>：同时启用 Streaming SVE 模式和 ZA 存储访问&lt;/li>
&lt;li>&lt;code>SMSTART SM&lt;/code>：启用 Streaming SVE 模式&lt;/li>
&lt;li>&lt;code>SMSTART ZA&lt;/code>：启用 ZA 存储访问&lt;/li>
&lt;/ul>
&lt;p>SMSTOP 指令则是清除 &lt;code>PSTATE.SM&lt;/code> 和 &lt;code>PSTATE.ZA&lt;/code> 的 &lt;code>MSR&lt;/code> 指令的别名。&lt;/p>
&lt;ul>
&lt;li>&lt;code>SMSTOP&lt;/code>：同时禁用 Streaming SVE 模式和 ZA 存储访问&lt;/li>
&lt;li>&lt;code>SMSTOP SM&lt;/code>：禁用 Streaming SVE 模式&lt;/li>
&lt;li>&lt;code>SMSTOP ZA&lt;/code>：禁用 ZA 存储访问&lt;/li>
&lt;/ul>
&lt;p>下图展示了应用程序是如何在 Streaming SVE 模式和 Non-streaming SVE 模式之间切换的：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-15_Scalable_Matrix_p1.webp"
alt="应用程序切换 Streaming SVE 模式和 Non-streaming SVE 模式" width="50%" loading="lazy">&lt;figcaption>
&lt;h4>应用程序切换 Streaming SVE 模式和 Non-streaming SVE 模式&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>有关使用 SMSTART 和 SMSTOP 在 Streaming SVE 模式和 Non-Streaming SVE 模式之间切换的更多信息，请参阅《Arm 架构参考手册》中有关 A-profile 架构的 C6.2.327 和 C6.2.328 节。&lt;/p>
&lt;h2 id="4-sme-架构状态">
&lt;a href="#4-sme-%e6%9e%b6%e6%9e%84%e7%8a%b6%e6%80%81" class="header-anchor">#&lt;/a>
4. SME 架构状态
&lt;/h2>
&lt;p>与 SVE2 类似，在 Streaming SVE 模式，它有 &lt;code>Z0-Z31&lt;/code> 向量寄存器，和 &lt;code>P0-P15&lt;/code> Predicate 寄存器。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-15_4130_ARM2799_3_Scalable_Matrix_p1.webp"
alt="Streaming mode registers" width="70%" loading="lazy">
&lt;/figure>
&lt;p>SVE 向量寄存器的最低编号位 &lt;code>Zn&lt;/code> 也保存着固定长度的 &lt;code>Vn、Qn、Dn、Sn、Hn&lt;/code> 和 &lt;code>Bn&lt;/code> 寄存器。&lt;/p>
&lt;p>进入 Streaming SVE 模式（ &lt;code>PSTATE.SM&lt;/code> 由 0 变为 1）或退出 Streaming SVE 模式（ &lt;code>PSTATE.SM&lt;/code> 由 1 变为 0）时，所有这些寄存器都将置零。&lt;/p>
&lt;p>大多数 Non-streaming SVE2 指令可用于 Streaming SVE 模式，但&lt;strong>可能使用不同的向量长度&lt;/strong>（流模式使用 VSL 长度，非流模式使用 NVSL 长度）。可以使用 &lt;code>RDSVL&lt;/code> 指令读取当前的有效向量长度 VL。&lt;/p>
&lt;pre>&lt;code class="language-armasm">//Read multiple of Streaming SVE vector register size to Xd
RDSVL &amp;lt;Xd&amp;gt;, #&amp;lt;imm&amp;gt;
&lt;/code>&lt;/pre>
&lt;blockquote class="alert-blockquote alert-note">
&lt;p class="alert-heading">
&lt;svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16">
&lt;path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z">&lt;/path>
&lt;/svg>
&lt;span>注释&lt;/span>
&lt;/p>
&lt;p>因为 SME 支持 Vector Length Agnostic (VLA) ，在 Streaming SVE 模式下，软件很少需要明确读 SVL 向量长度。在 Non-streaming SVE 模式下，通常使用 RDSVL 指令来确定 SVL 的值。&lt;/p>
&lt;/blockquote>
&lt;h2 id="5-za-array">
&lt;a href="#5-za-array" class="header-anchor">#&lt;/a>
5. ZA array
&lt;/h2>
&lt;p>SME 新引入的 ZA (Z Array, ZA Storage) 是一个二维（2D）正方形数组，大小是 SVL x SVL。之所以叫 Z Array，也是因为它行与列的长度与 Streaming SVE 模式下的 Zn 寄存器一致。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-15_4314_ARM2799_4_Scalable_Matrix_p1.webp"
alt="ZA array" width="50%" loading="lazy">&lt;figcaption>
&lt;h4>ZA array&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>例如：如果 Streaming SVE 模式下的向量长度为 256-bit，即 Zn 寄存器的长度为 256-bit，那么 ZA 的大小为 (256/8 bytes) x (256/8 bytes) 。&lt;/p>
&lt;p>ZA array 可以通过以下方式访问：&lt;/p>
&lt;ul>
&lt;li>ZA array vector 访问&lt;/li>
&lt;li>ZA tiles&lt;/li>
&lt;li>ZA tile slices&lt;/li>
&lt;/ul>
&lt;h3 id="51-za-array-vector-访问">
&lt;a href="#51-za-array-vector-%e8%ae%bf%e9%97%ae" class="header-anchor">#&lt;/a>
5.1 ZA array vector 访问
&lt;/h3>
&lt;p>ZA array 的一行可以当成一个 SVL 长度的向量来访问，这个向量可以放数据类型长度为 8-bit, 16-bit, 32-bit, 64-bit 或 128-bit 的元素，比如 32-bit 的 fp32 浮点数。&lt;/p>
&lt;pre>&lt;code class="language-c">ZA.B[N], ZA.H[N], ZA.S[N], ZA.D[N], ZA.Q[N]
&lt;/code>&lt;/pre>
&lt;p>其中 &lt;code>B，H，S，D，Q&lt;/code> 分别表示 8-bit , 16-bit , 32-bit , 64-bit , 128-bit。&lt;/p>
&lt;p>ZA array vector 的数量与 SVL 中的字节数相同，例如，如果 SLV 是 256-bit ，那么 ZA array vector 的数量是 32 个，N 的范围是 0 到 31。&lt;/p>
&lt;p>为了支持上下文切换，SME 引入了新的 &lt;code>LDR&lt;/code> 和 &lt;code>STR&lt;/code> 指令，用于从内存加载和存储一个 ZA array vector。&lt;/p>
&lt;pre>&lt;code class="language-armasm">LDR ZA[&amp;lt;Wv&amp;gt;, &amp;lt;imm&amp;gt;], [&amp;lt;Xn|SP&amp;gt;{, #&amp;lt;imm&amp;gt;, MUL VL}]
STR ZA[&amp;lt;Wv&amp;gt;, &amp;lt;imm&amp;gt;], [&amp;lt;Xn|SP&amp;gt;{, #&amp;lt;imm&amp;gt;, MUL VL}]
&lt;/code>&lt;/pre>
&lt;h3 id="52-za-tiles">
&lt;a href="#52-za-tiles" class="header-anchor">#&lt;/a>
5.2 ZA tiles
&lt;/h3>
&lt;p>ZA tile 是在 ZA 中的正方形的二维子矩阵。ZA tile 的宽度始终是 SVL，与 ZA array 的宽度相同。&lt;/p>
&lt;p>ZA 可以分成多少个可用的 ZA tile 是由元素的数据类型大小决定的：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: left">元素数据类型大小&lt;/th>
&lt;th style="text-align: left">tile 数量&lt;/th>
&lt;th style="text-align: left">tile 名称&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: left">8-bit&lt;/td>
&lt;td style="text-align: left">1&lt;/td>
&lt;td style="text-align: left">ZA0.B&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">16-bit&lt;/td>
&lt;td style="text-align: left">2&lt;/td>
&lt;td style="text-align: left">ZA0.H-ZA1.H&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">32-bit&lt;/td>
&lt;td style="text-align: left">4&lt;/td>
&lt;td style="text-align: left">ZA0.S-ZA3.S&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">64-bit&lt;/td>
&lt;td style="text-align: left">8&lt;/td>
&lt;td style="text-align: left">ZA0.D-ZA7.D&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">128-bit&lt;/td>
&lt;td style="text-align: left">16&lt;/td>
&lt;td style="text-align: left">ZA0.Q-ZA15.Q&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ul>
&lt;li>当元素数据类型为 8-bit 时，ZA 只能作为一个 ZA tile (ZA0.B) 被访问。&lt;/li>
&lt;li>当元素数据类型为 16-bit 时，ZA 可以作为 2 个 ZA tile (ZA0.H 和 ZA1.H) 被访问。&lt;/li>
&lt;li>当元素数据类型为 32-bit 时，ZA 可以作为 4 个 ZA tile (ZA0.S 到 ZA3.S) 被访问。&lt;/li>
&lt;li>当元素数据类型为 64-bit 时，ZA 可以作为 8 个 ZA tile (ZA0.D 到 ZA7.D) 被访问。&lt;/li>
&lt;li>当元素数据类型为 128-bit 时，ZA 可以作为 16 个 ZA tile (ZA0.Q 到 ZA15.Q) 被访问。&lt;/li>
&lt;/ul>
&lt;p>例如，如果 SVL 为 256-bit，元素数据类型大小为 8-bit，则 ZA 可以视为 ZA0.B，也可视为 32 个向量（32 行，每行大小为 32 x 8-bit，即每行 32 个元素）。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-15_ZA0B.webp"
alt="ZA0.B" width="50%" loading="lazy">
&lt;/figure>
&lt;p>如果 SVL 为 256-bit，元素数据类型大小为 16-bit，则 ZA 可以视为 2 个 ZA tile (ZA0.H 和 ZA1.H)，每个 tile 视为 16 个向量（16 行，每行大小为 16 x 16-bit，即每行 16 个元素）。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-15_ZA0H_ZA1H.webp"
alt="ZA0.H 和 ZA1.H" width="40%" loading="lazy">
&lt;/figure>
&lt;p>这样做的好处是充分利用了 ZA storage，在实际应用中，比如说当 SVL 为 256-bit，元素数据类型大小为 32-bit，ZA 的大小为 256-bit x 256-bit 时，&lt;strong>要对两个 Z 寄存器里的向量做外积运算&lt;/strong>，计算得到的外积结果是 8 x 8 的二维浮点数数组，这个外积只需要 ZA 的 1/4 的存储空间。将 ZA 分成 4 个 ZA tile，这样就可以充分利用 ZA storage。&lt;/p>
&lt;h3 id="53-za-tile-slices">
&lt;a href="#53-za-tile-slices" class="header-anchor">#&lt;/a>
5.3 ZA tile slices
&lt;/h3>
&lt;p>一个 ZA tile 可以作为一个整体来访问，也可以以一个个 ZA tile slice 的方式访问。&lt;/p>
&lt;p>当作为一个整体访问时，指令可以使用 tile 的名字访问：&lt;/p>
&lt;pre>&lt;code class="language-text">ZA0.B, ZA0.H-ZA1.H, ZA0.S-ZA3.S, ZA0.D-ZA7.D or ZA0.Q-ZA15.Q
&lt;/code>&lt;/pre>
&lt;p>一个 ZA tile slice 是由其 ZA tile 中&lt;strong>水平方向或是垂直方向的连续元素组成的一维数组&lt;/strong>，即在 ZA tile 中的一行或是一列。&lt;/p>
&lt;p>对一个 ZA tile 的向量访问即是读写一个 ZA tile slice ：&lt;/p>
&lt;ul>
&lt;li>水平或垂直方向的 ZA tile slice 访问，由 ZA tile 名字后的 &lt;code>H&lt;/code> 或 &lt;code>V&lt;/code> 后缀来表示。&lt;/li>
&lt;li>具体的 ZA tile slice 由一个索引来表示，由 ZA tile 名字后的切片索引 &lt;code>[N]&lt;/code> 来表示。&lt;/li>
&lt;/ul>
&lt;p>例如，如果 SVL 为 128 位，元素数据类型大小为 8-bit，那么其水平的和垂直的 ZA tile slice 可由下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-15_6724_ARM2799_7_Scalable_Matrix_p1.webp"
alt="ZA tile slices" width="50%" loading="lazy">
&lt;/figure>
&lt;p>再例如，如果 SVL 为 128 位，元素数据类型大小为 16-bit，那么其水平的和垂直的 ZA tile slice 可由下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-15_6888_ARM2799_8_Scalable_Matrix_p1.webp"
alt="ZA tile slices" width="50%" loading="lazy">
&lt;/figure>
&lt;p>为了提高硬件访问 ZA tile 和 ZA tile slices 的效率，ZA tile 的 ZA tile slices 是交错排列的。&lt;/p>
&lt;p>下图显示了这种交错排列的示例。在此示例中，SVL 为 256 位，元素数据类型大小为 16 位。这意味着，ZA 可被视为两个 ZA tile（ZA0H 和 ZA1H），并具有交错的水平 tile slices ：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-15_4885_SME_interleave.webp"
alt="ZA tile slices" width="auto" loading="lazy">
&lt;/figure>
&lt;p>下图展示了不同的元素数据类型大小的水平和垂直方向 ZA tile slice 的混合视图:&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-15_7673_SME_V_H.webp"
alt="ZA tile slices" width="auto" loading="lazy">
&lt;/figure>
&lt;p>左侧各栏显示了 ZA 存储器每一行的不同处理方式。&lt;/p>
&lt;p>设 SIZE 为向量元素的大小，其中 SIZE 为 1、2、4、8、16，分别代表数据类型 B、H、S、D 或 Q。&lt;/p>
&lt;p>设 NUM_OF_ELEMENTS 为向量中的元素个数，即 bytes_of(SVL)/SIZE。&lt;/p>
&lt;p>水平 tile slice， &lt;code>ZAnH.&amp;lt;B|H|S|D|Q&amp;gt;[m]&lt;/code> 访问一个向量，该向量包含 ZA storage 中的整行（m x SIZE + n）。该向量包含数据类型为 B、H、S、D 或 Q 的元素。&lt;/p>
&lt;p>垂直 tile slice，&lt;code>ZAnV.&amp;lt;B|H|S|D|Q&amp;gt;[m] &lt;/code> 访问一个向量，该向量包含 ZA storage 中的整列（m x SIZE）。该向量包含数据类型为 B、H、S、D 或 Q 的元素。&lt;/p>
&lt;p>&lt;code>ZAnV.[m] &lt;/code> 访问一个包含列（m x SIZE）和行元素（i x SIZE + n）的向量，其中 i 为 0 ~ NUM_OF_ELEMENTS-1。该向量包含数据类型为 B、H、S、D 或 Q 的元素。&lt;/p>
&lt;p>使用混合元素数据类型大小以及水平和垂直 tile slice 的应用应小心处理重叠。&lt;/p>
&lt;p>有关 ZA Array、ZA array vectors、tile 和 tile slices 的更多信息，请参阅《Arm 架构参考手册》中有关 A-profile 架构的 B1.4.8 至 B1.4.12 节。&lt;/p>
&lt;h2 id="6-steaming-sve-模式下支持的指令">
&lt;a href="#6-steaming-sve-%e6%a8%a1%e5%bc%8f%e4%b8%8b%e6%94%af%e6%8c%81%e7%9a%84%e6%8c%87%e4%bb%a4" class="header-anchor">#&lt;/a>
6. Steaming SVE 模式下支持的指令
&lt;/h2>
&lt;p>某些指令在 Streaming SVE 模式下有限制：&lt;/p>
&lt;ul>
&lt;li>一些 SVE/SVE2 指令变为非法执行
&lt;ul>
&lt;li>Gathed-load 和 Scatter-store 指令&lt;/li>
&lt;li>使用 First Fault 寄存器的 SVE2 指令&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>大多的 NEON 指令变为 UNDEFINED&lt;/li>
&lt;/ul>
&lt;p>有关受 Streaming SVE 模式影响的指令的更多信息，请参阅文档 《Arm 架构参考手册》。&lt;/p>
&lt;p>SME 增加了几条新指令，其中包括：&lt;/p>
&lt;ul>
&lt;li>矩阵外积和累加或减法指令，包括 FMOPA、UMOPA 和 BFMOPA。
&lt;ul>
&lt;li>SVE2 向量寄存器（Z0-Z31）作为外积运算的行和列输入。&lt;/li>
&lt;li>ZA storage 保存二维矩阵 tile 的输出结果。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>将 SVE2 Z 向量与 ZA 的行或列做加法运算的指令&lt;/li>
&lt;li>对 ZA tiles 的清零操作指令&lt;/li>
&lt;li>增加了一些在 Streaming 和 Non-streaming 模式下都能使用的指令&lt;/li>
&lt;/ul>
&lt;h2 id="7-sme-指令">
&lt;a href="#7-sme-%e6%8c%87%e4%bb%a4" class="header-anchor">#&lt;/a>
7. SME 指令
&lt;/h2>
&lt;p>操作 ZA storage 的 SME 指令主要包括：&lt;/p>
&lt;ul>
&lt;li>计算两个向量的外积，并累加或累减，然后将结果放入一个 ZA tile 的指令&lt;/li>
&lt;li>将 SVE 向量（Z 寄存器）存入或取出 ZA tile 的行或列的指令&lt;/li>
&lt;li>水平或垂直方向上，一个 SVE 向量与 ZA tile 的加法指令&lt;/li>
&lt;li>给一个标量寄存器加上 Streaming SVE 模式下向量长度的倍数的指令&lt;/li>
&lt;/ul>
&lt;h3 id="71-外积并累加或累减指令">
&lt;a href="#71-%e5%a4%96%e7%a7%af%e5%b9%b6%e7%b4%af%e5%8a%a0%e6%88%96%e7%b4%af%e5%87%8f%e6%8c%87%e4%bb%a4" class="header-anchor">#&lt;/a>
7.1 外积并累加或累减指令
&lt;/h3>
&lt;p>为了帮助理解外积并累加或累减指令，让我们看看如何使用外积操作来做矩阵乘法。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_2313_Picture1_png-1280x960.webp"
alt="Outer product" width="auto" loading="lazy">
&lt;/figure>
&lt;p>计算两个向量 a 和 b 的外积会得到一个包含外积的结果矩阵 C：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_1665_Picture2_png-1280x960.webp"
alt="Outer product" width="auto" loading="lazy">
&lt;/figure>
&lt;p>现在考虑两个矩阵 a 和 b 的矩阵乘运算：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_8117_Picture3_png-1280x960.webp"
alt="Matrix multiplication" width="auto" loading="lazy">
&lt;/figure>
&lt;p>这个矩阵乘可以通过计算两次外积操作和两个结果矩阵的累加来实现（就是常用的手写计算的方法），如下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_3731_Picture4_png-1280x960.webp"
alt="Matrix multiplication with outer product" width="auto" loading="lazy">
&lt;/figure>
&lt;p>SME 为以下数据类型引入了高效的外积并累加或减法指令：&lt;/p>
&lt;ul>
&lt;li>8-bit, 16-bit 整数&lt;/li>
&lt;li>FP16, BF16, FP32 和 FP64 浮点数&lt;/li>
&lt;/ul>
&lt;p>这些指令计算两个 Z 向量寄存器（Zn 和 Zm）中两个向量的外积，将结果数组与一个 ZA tile（ZAda）中已有数据进行累加或累减，并将结果存入同一 ZA tile（ZAda）中。每个源向量由相应的控制 predicate 寄存器（Pn 和 Pm）独立地 predicate。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: left">输出数组&lt;/th>
&lt;th style="text-align: left">输入向量&lt;/th>
&lt;th style="text-align: left">描述&lt;/th>
&lt;th style="text-align: left">示例&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: left">INT32&lt;/td>
&lt;td style="text-align: left">INT8, INT8&lt;/td>
&lt;td style="text-align: left">将四个 INT8 外积之和存入每个 INT32 元素&lt;/td>
&lt;td style="text-align: left">SMOPA 或 SMOPS 或 UMOPA 或 UMOPS：带符号或无符号整数外积和，并累加或累减。例如： &lt;code>UMOPS &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.B, &amp;lt;Zm&amp;gt;.B&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">INT32&lt;/td>
&lt;td style="text-align: left">INT16, INT16&lt;/td>
&lt;td style="text-align: left">将两个 INT16 外积之和存入每个 INT32 元素&lt;/td>
&lt;td style="text-align: left">SMOPA 或 SMOPS 或 UMOPA 或 UMOPS：带符号或无符号整数外积和，并累加或累减。例如： &lt;code>UMOPS &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.H, &amp;lt;Zm&amp;gt;.H&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">INT64&lt;/td>
&lt;td style="text-align: left">INT16, INT16&lt;/td>
&lt;td style="text-align: left">如果实现了 FEAT_SME_I16I64，则将四个 INT16 外积之和存入每个 INT64 元素&lt;/td>
&lt;td style="text-align: left">SMOPA 或 SMOPS 或 UMOPA 或 UMOPS：带符号或无符号整数外积和，并累加或累减。例如： &lt;code>UMOPS &amp;lt;ZAda&amp;gt;.D, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.H, &amp;lt;Zm&amp;gt;.H&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">FP32&lt;/td>
&lt;td style="text-align: left">BF16, BF16&lt;/td>
&lt;td style="text-align: left">将两个 BF16 外积之和存入每个 FP32 元素&lt;/td>
&lt;td style="text-align: left">BFMOPA 或 BFMOPS：BFloat16 外积和，并累加或累减。例如： &lt;code>BFMOPS &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.H, &amp;lt;Zm&amp;gt;.H&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">FP32&lt;/td>
&lt;td style="text-align: left">FP16, FP16&lt;/td>
&lt;td style="text-align: left">将两个 FP16 外积之和存入每个 FP32 元素&lt;/td>
&lt;td style="text-align: left">FMOPA 或 FMOPS：半精度浮点外积和，并累加或累减。例如： &lt;code>FMOPS &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.H, &amp;lt;Zm&amp;gt;.H&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">FP32&lt;/td>
&lt;td style="text-align: left">FP32, FP32&lt;/td>
&lt;td style="text-align: left">简单的 FP32 外积&lt;/td>
&lt;td style="text-align: left">FMOPA 或 FMOPS：浮点外积和，并累加或累减。例如： &lt;code>FMOPS &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.S, &amp;lt;Zm&amp;gt;.S&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">FP64&lt;/td>
&lt;td style="text-align: left">FP64, FP64&lt;/td>
&lt;td style="text-align: left">如果实现了 FEAT_SME_F64F64，则进行简单的 FP64 外积&lt;/td>
&lt;td style="text-align: left">FMOPA 或 FMOPS：浮点外积和，并累加或累减。例如： &lt;code>FMOPS &amp;lt;ZAda&amp;gt;.D, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.D, &amp;lt;Zm&amp;gt;.D&lt;/code>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h4 id="711-fp32-fp64-外积并累加或累减指令">
&lt;a href="#711-fp32-fp64-%e5%a4%96%e7%a7%af%e5%b9%b6%e7%b4%af%e5%8a%a0%e6%88%96%e7%b4%af%e5%87%8f%e6%8c%87%e4%bb%a4" class="header-anchor">#&lt;/a>
7.1.1 FP32, FP64 外积并累加或累减指令
&lt;/h4>
&lt;p>那些输入向量和输出数组有同样数据类型（FP32， FP64）的指令相对简单。&lt;/p>
&lt;p>下例展示了 FP32 类型的外积并累加或累减指令。&lt;/p>
&lt;pre>&lt;code class="language-armasm">FMOPA &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.S, &amp;lt;Zm&amp;gt;.S
FMOPS &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.S, &amp;lt;Zm&amp;gt;.S
&lt;/code>&lt;/pre>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_3613751670-667e5f923c64.webp"
alt="FMOPA and FMOPS" width="auto" loading="lazy">
&lt;/figure>
&lt;p>这个例子中，假设 SVL 向量长度为 128，&lt;code>Zn.S&lt;/code> 和 &lt;code>Zm.S&lt;/code> 中存放了 4 个 FP32 数组成的向量，此指令计算 &lt;code>Zn.S&lt;/code> 和 &lt;code>Zm.S&lt;/code> 的外积，外积结果为图中灰色的矩阵，然后将此外积结果累加或累减 &lt;code>ZAda.S&lt;/code> 这个 ZA tile 中原有的值，将结果存入同一 ZA tile。&lt;/p>
&lt;h4 id="712-fp16-bf16-int16-int8-i16i64-类型的外积并累加或累减指令">
&lt;a href="#712-fp16-bf16-int16-int8-i16i64-%e7%b1%bb%e5%9e%8b%e7%9a%84%e5%a4%96%e7%a7%af%e5%b9%b6%e7%b4%af%e5%8a%a0%e6%88%96%e7%b4%af%e5%87%8f%e6%8c%87%e4%bb%a4" class="header-anchor">#&lt;/a>
7.1.2 FP16, BF16, INT16, INT8, I16I64 类型的外积并累加或累减指令
&lt;/h4>
&lt;p>由于这些指令会扩大计算结果数据类型，因此这些操作不像前面 FP32，FP64 类型指令那么简单明了。&lt;/p>
&lt;ul>
&lt;li>BF16 指令计算两个 BF16 的外积的和，扩大结果类型为 FP32, 然后将结果与目标 tile 进行破坏性相加或相减。&lt;/li>
&lt;li>INT8 指令计算四个 INT8 的外积的和，扩大结果类型为 INT32，然后将结果与目标 tile 进行破坏性相加或相减。&lt;/li>
&lt;li>INT16 指令计算两个 INT16 的外积的和，扩大结果类型为 INT32，然后将结果与目标 tile 进行破坏性相加或相减。&lt;/li>
&lt;li>FP16 指令计算两个 FP16 的外积的和，扩大结果类型为 FP32，然后将结果与目标 tile 进行破坏性相加或相减。&lt;/li>
&lt;li>如果实现了 FEAT_SME_I16I64，I16I64 指令计算四个 INT16 的外积的和，扩大结果类型为 INT64, 然后将结果与目标 tile 进行破坏性相加或相减。&lt;/li>
&lt;/ul>
&lt;p>以下例子展示了 SVL 向量长度为 128 的 INT8 UMOPA 指令进行的操作：&lt;/p>
&lt;pre>&lt;code class="language-armasm">UMOPA &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.B, &amp;lt;Zm&amp;gt;.B
&lt;/code>&lt;/pre>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_1030_Picture6_png-1280x960.webp"
alt="INT8 UMOPA" width="auto" loading="lazy">
&lt;/figure>
&lt;p>每个输入寄存器（&lt;code>Zn.B&lt;/code>、&lt;code>Zm.B&lt;/code>）都被视为一个包含 4x4 元素的矩阵，可以看作是 4 个连续元素组成的块（如图中红线所标）被转置了。&lt;/p>
&lt;p>在这个例子中，因为 SVL 向量长度为 128-bit：&lt;/p>
&lt;ul>
&lt;li>第一源向量 &lt;code>Zn.B&lt;/code> ，包含一个无符号 8-bit 整数的 4x4 子矩阵。&lt;/li>
&lt;li>第二源向量 &lt;code>Zm.B&lt;/code> ，包含一个无符号 8-bit 整数的 4x4 子矩阵。&lt;/li>
&lt;li>UMOPA 指令计算出 4x4 扩大了的 32-bit 整数外积的和，然后破坏性地累加上目标 tile（ZAda）中的整数。&lt;/li>
&lt;/ul>
&lt;p>更笼统地说，UMOPA 指令是将第一个源向量中的子矩阵与第二个源向量中的子矩阵相乘。每个源向量包含一个(SVL/32) x 4 的无符号 8-bit 整数的子矩阵。然后将得到的 (SVL/32) x (SVL/32)扩大了的 32-bit 整数外积和破坏性地加上一个 32-bit 整数目标 tile。&lt;/p>
&lt;p>下面的例子展示了 SVL 为 128-bit 的 BF16 BFMOPA 进行的操作：&lt;/p>
&lt;pre>&lt;code class="language-armasm">BFMOPA &amp;lt;ZAda&amp;gt;.S, &amp;lt;Pn&amp;gt;/M, &amp;lt;Pm&amp;gt;/M, &amp;lt;Zn&amp;gt;.H, &amp;lt;Zm&amp;gt;.H
&lt;/code>&lt;/pre>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_6545_Picture7_png-1280x960.webp"
alt="BF16 BFMOPA" width="auto" loading="lazy">
&lt;/figure>
&lt;p>在这个例子中，因为 SVL 向量长度为 128-bit：&lt;/p>
&lt;ul>
&lt;li>第一源向量 &lt;code>Zn.H&lt;/code> ，包含一个 BF16 整数的 4x2 子矩阵，它被扩大成单精度浮点数。&lt;/li>
&lt;li>第二源向量 &lt;code>Zm.H&lt;/code> ，包含一个 BF16 整数的 2x4 子矩阵，它被扩大成单精度浮点数。&lt;/li>
&lt;li>BMOPA 指令计算出 4x4 单精度外积的和，然后破坏性地累加上目标 tile（ZAda）中的单精度浮点数。&lt;/li>
&lt;/ul>
&lt;p>更笼统地说，BFMOPA 指令扩大了存放在第一源向量里的(SVL/32) x2 BF16 子矩阵的类型为单精度，扩大了存放在第二源向量里的 2x (SVL/32) BF16 子矩阵的类型为单精度，将这两个子矩阵相乘。然后将得到的 (SVL/32) x (SVL/32)单精度外积和破坏性地加上一个单精度目标 tile。&lt;/p>
&lt;p>以下表格显示了几种数据类型和 SVL 长度的一条外积并累加或累减指令所做的对应数据类型的 MAC(乘累加)数量：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: left">&lt;/th>
&lt;th style="text-align: left">128-bit&lt;/th>
&lt;th style="text-align: left">256-bit&lt;/th>
&lt;th style="text-align: left">512-bit&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: left">FP32&lt;/td>
&lt;td style="text-align: left">16&lt;/td>
&lt;td style="text-align: left">64&lt;/td>
&lt;td style="text-align: left">256&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">FP64&lt;/td>
&lt;td style="text-align: left">4&lt;/td>
&lt;td style="text-align: left">16&lt;/td>
&lt;td style="text-align: left">64&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">INT8&lt;/td>
&lt;td style="text-align: left">64&lt;/td>
&lt;td style="text-align: left">256&lt;/td>
&lt;td style="text-align: left">1024&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">INT16&lt;/td>
&lt;td style="text-align: left">32&lt;/td>
&lt;td style="text-align: left">128&lt;/td>
&lt;td style="text-align: left">512&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">BF16&lt;/td>
&lt;td style="text-align: left">32&lt;/td>
&lt;td style="text-align: left">128&lt;/td>
&lt;td style="text-align: left">512&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">FP16&lt;/td>
&lt;td style="text-align: left">32&lt;/td>
&lt;td style="text-align: left">128&lt;/td>
&lt;td style="text-align: left">512&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="72-带-predication-的-sme-指令">
&lt;a href="#72-%e5%b8%a6-predication-%e7%9a%84-sme-%e6%8c%87%e4%bb%a4" class="header-anchor">#&lt;/a>
7.2 带 Predication 的 SME 指令
&lt;/h3>
&lt;p>每个源向量都可以被其相应的控制 predicate 寄存器独立地 predicate:&lt;/p>
&lt;ul>
&lt;li>外积并累加或累减指令使用 Pn/M 和 Pn/M (没有/Z 形式)：Inactive 的源元素被当成具有 0 值。&lt;/li>
&lt;li>Slice move 指令使用 Pg/M: 目标 slice 中 Inactive 的元素保持不变。&lt;/li>
&lt;li>Tile slice load 指令使用 Pg/Z: 目标 tile slice 中的 Inactive 元素被设置为 0。&lt;/li>
&lt;li>Tile slice store 指令使用 Pg: Inactive 的元素不会写入内存。&lt;/li>
&lt;/ul>
&lt;p>Predication 让矩阵的维数不是 SVL 的倍数的情况更容易处理。&lt;/p>
&lt;p>例如下图的指令：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_2656_Picture12_png-600x0.webp"
alt="SME predication" width="auto" loading="lazy">
&lt;/figure>
&lt;p>输入向量 &lt;code>Z0&lt;/code> 被 &lt;code>P0&lt;/code> predicate，&lt;code>Z1&lt;/code> 被 &lt;code>P1&lt;/code> predicate。&lt;/p>
&lt;p>在这个例子中：&lt;/p>
&lt;ul>
&lt;li>SVL 向量长度为 512-bit。&lt;/li>
&lt;li>Z 寄存器中包含 16 个 FP32 数组成的向量。&lt;/li>
&lt;li>&lt;code>P0&lt;/code> 中最后两个元素是 inactive 的。&lt;/li>
&lt;li>&lt;code>P1&lt;/code> 中最后一个元素是 inactive 的。&lt;/li>
&lt;/ul>
&lt;p>这条指令更新 &lt;code>ZA0.S&lt;/code> 中 (16-2) x (16-1) 个 FP32 元素，因为使用了 &lt;code>Pn/M&lt;/code> , &lt;code>ZA0.S&lt;/code> 中剩下的元素保持不变。&lt;/p>
&lt;p>下图展示了更多的 predicated 外积并累加或累减的例子。图中被划线的文字表示被 inactive predicate 元素影响的计算部分。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_2072_Picture14_png-1280x960.webp"
alt="SME predication FMOPA" width="auto" loading="lazy">
&lt;/figure>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_3513_Picture16_png-1280x960.webp"
alt="SME predication UMOPA" width="auto" loading="lazy">
&lt;/figure>
&lt;h3 id="73-za-tile-与一个-z-向量的加运算">
&lt;a href="#73-za-tile-%e4%b8%8e%e4%b8%80%e4%b8%aa-z-%e5%90%91%e9%87%8f%e7%9a%84%e5%8a%a0%e8%bf%90%e7%ae%97" class="header-anchor">#&lt;/a>
7.3 ZA tile 与一个 Z 向量的加运算
&lt;/h3>
&lt;p>SME 包括 ZA tile 的行或列都加上一个向量的指令，这些指令也有 predication 的支持。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: left">指令&lt;/th>
&lt;th style="text-align: left">说明&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: left">ADDHA&lt;/td>
&lt;td style="text-align: left">将源向量添加到 ZA tile 的每个水平 slice 上&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">ADDVA&lt;/td>
&lt;td style="text-align: left">将源向量添加到 ZA tile 的每个垂直 slice 上&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>例如：&lt;/p>
&lt;pre>&lt;code class="language-armasm">ADDHA ZA0.S, P0/M, P1/M, Z1.S
&lt;/code>&lt;/pre>
&lt;p>将执行以下操作：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_ARM2799_9_Scalable_Matrix_p2_png-1200x0.webp"
alt="SME ADDHA" width="auto" loading="lazy">
&lt;/figure>
&lt;p>这个 ADDHA 指令将源向量 Z1 中的每个元素加上 ZA0.S tile 每一水平 slice 的相应 active 元素。&lt;/p>
&lt;p>Tile 中元素被一对 governing predicate 进行 predicate。 一个水平 slice 中的一个元素在下面情况下可以认为是 active：&lt;/p>
&lt;ul>
&lt;li>它在第二 governing predicate 对应的元素是 TRUE, 并且&lt;/li>
&lt;li>它在第一 governing predicate 对应的水平 slice 行号也为 TRUE,目标 tile 中 inactive 元素保持不变。&lt;/li>
&lt;/ul>
&lt;h3 id="74-tile-load-store-move-指令">
&lt;a href="#74-tile-load-store-move-%e6%8c%87%e4%bb%a4" class="header-anchor">#&lt;/a>
7.4 Tile load, store, move 指令
&lt;/h3>
&lt;p>SME tile load, store, move 指令可以：&lt;/p>
&lt;ul>
&lt;li>从内存读取数据，放入 ZA tile 的行或列&lt;/li>
&lt;li>将 ZA tile 的行或列写入内存&lt;/li>
&lt;li>将 ZA tile 的行移动到 SVE Z 向量寄存器&lt;/li>
&lt;li>将 SVE Z 向量寄存器移动到 ZA tile 行或列&lt;/li>
&lt;/ul>
&lt;h4 id="741-tile-slice-load-和-store-指令">
&lt;a href="#741-tile-slice-load-%e5%92%8c-store-%e6%8c%87%e4%bb%a4" class="header-anchor">#&lt;/a>
7.4.1 Tile slice load 和 store 指令
&lt;/h4>
&lt;p>LD1B、LD1H、LD1S、LD1D 和 LD1Q 指令分别将连续内存值加载到具有 8-bit、16-bit、32-bit、64-bit 或 128-bit 元素的 ZA tile slice 中。&lt;/p>
&lt;p>ST1B、ST1H、ST1S、ST1D 和 ST1Q 指令分别将包含 8-bit、16-bit、32-bit、64-bit 或 128-bit 元素的 ZA tile slice 存储到连续内存中。&lt;/p>
&lt;p>这些指令也支持 predication ，例如：&lt;/p>
&lt;pre>&lt;code class="language-armasm">LD1B ZA0H.B[W0, #imm], P0/Z, [X1, X2]
&lt;/code>&lt;/pre>
&lt;p>此 LD1B 指令执行 predicated 的连续 byte 读取，它从地址为(X1+X2)的内存读取数据到 ZA0 中行号为（W0+imm）的这个水平 tile slice 中。目标 tile slice 中 Inactive 的元素被设置为 0。&lt;/p>
&lt;pre>&lt;code class="language-armasm">ST1H ZA1V.H[W0, #imm], P2, [X1, X2, LSL #1]
&lt;/code>&lt;/pre>
&lt;p>此 ST1H 指令执行 predicated 连续 halfword 的存操作，它将 ZA1 中列号为（W0+imm）的垂直 tile slice 存到地址为（X1+X2*2）的内存， tile slice 中 Inactive 的元素不写入内存。&lt;/p>
&lt;h4 id="742-tile-slice-move-指令">
&lt;a href="#742-tile-slice-move-%e6%8c%87%e4%bb%a4" class="header-anchor">#&lt;/a>
7.4.2 Tile slice move 指令
&lt;/h4>
&lt;p>MOV 指令（MOVA 指令的别名）将一个 Z 向量寄存器的值移动到一个 ZA tile slice，或将一个 ZA tile slice 中的值移动到一个 Z 向量寄存器。这条指令操作带指定元素大小的 ZA tile 的单个水平或垂直 tile slice。 Slice 的行号/列号由 slice 的检索寄存器加上立即数偏移指定。目标 slice 中 Inactive 的元素保持不变。&lt;/p>
&lt;p>例如：&lt;/p>
&lt;pre>&lt;code class="language-armasm">MOV ZA0H.B[W0, #imm], P0/M, Z0.B
&lt;/code>&lt;/pre>
&lt;p>或&lt;/p>
&lt;pre>&lt;code class="language-armasm">MOVA ZA0H.B[W0, #imm], P0/M, Z0.B
&lt;/code>&lt;/pre>
&lt;p>此指令将向量寄存器 &lt;code>Z0.B&lt;/code> 中的值移动到 &lt;code>ZA0H.B[W0,#imm]&lt;/code> 这个水平 ZA tile slice 中，使用 &lt;code>P0&lt;/code> 作为 predication 寄存器。目标 tile slice 中 Inactive 的元素保持不变。&lt;/p>
&lt;h3 id="75-za-array-vector-loadstore-指令">
&lt;a href="#75-za-array-vector-loadstore-%e6%8c%87%e4%bb%a4" class="header-anchor">#&lt;/a>
7.5 ZA array vector load/store 指令
&lt;/h3>
&lt;p>SME LDR 指令从内存读取数据到一个 ZA array 向量，SME STR 指令将一个 ZA array 向量中的值存入内存。
这些指令是不带 predication 功能的。它们主要是为了软件的 context switching 时对 ZA storage 进行 save/restore。SME LDR/STR 指令也可以在 Non-streaming SVE 模式下，当 PSTATE.ZA 使能的情况下使用。
例如，下面的 STR 指令的 ZA array 向量是由一个向量选择寄存器 Wv（标量寄存器 W）加上可选的立即数（Wv+Imm）指定。访问内存的地址为：一个标量寄存器作为 base，加上相同的可选立即数偏移乘以当前向量长度 byte 数。&lt;/p>
&lt;pre>&lt;code class="language-armasm">STR ZA[&amp;lt;Wv&amp;gt;, &amp;lt;imm&amp;gt;], [&amp;lt;Xn|SP&amp;gt;{, #&amp;lt;imm&amp;gt;, MUL VL}]
&lt;/code>&lt;/pre>
&lt;h3 id="76-za-tile-清零指令">
&lt;a href="#76-za-tile-%e6%b8%85%e9%9b%b6%e6%8c%87%e4%bb%a4" class="header-anchor">#&lt;/a>
7.6 ZA tile 清零指令
&lt;/h3>
&lt;p>SME ZERO 指令可以清零一组 64-bit ZA tile:&lt;/p>
&lt;pre>&lt;code class="language-armasm">ZERO { &amp;lt;mask&amp;gt;}
&lt;/code>&lt;/pre>
&lt;p>ZERO 指令可以清零多到 8 个名为 &lt;code>ZA0.D&lt;/code> 到 &lt;code>ZA8.D&lt;/code> 的 ZA tile，那些 tile 要清零由指令中的 mask 指定，剩下的其他 tile 保持不变。&lt;/p>
&lt;p>这条指令也可以在 Non-streaming SVE 模式，当 &lt;code>PSTATE.ZA&lt;/code> 开启的情况下使用。&lt;/p>
&lt;p>如果要清零整个 ZA array, 可以使用一个指令别名，&lt;code>ZERO {ZA}&lt;/code> 。&lt;/p>
&lt;h3 id="77-新的-sve2-指令">
&lt;a href="#77-%e6%96%b0%e7%9a%84-sve2-%e6%8c%87%e4%bb%a4" class="header-anchor">#&lt;/a>
7.7 新的 SVE2 指令
&lt;/h3>
&lt;p>SME 构架扩展加入了一些新的 SVE2 指令，这些指令也可以在 PE 实现了 SVE2, 处于 Non-streaming SVE 模式时使用。这些指令包括：&lt;/p>
&lt;ul>
&lt;li>选择一个 predicate 寄存器或是 all-false 的 Predicate select 指令&lt;/li>
&lt;li>翻转（Reverse）64-bit double word 元素的指令&lt;/li>
&lt;li>有符号/无符号钳位为更小/更大值向量的指令&lt;/li>
&lt;/ul>
&lt;p>下面介绍以下 Predicate select 指令。&lt;/p>
&lt;h4 id="771-psel-指令">
&lt;a href="#771-psel-%e6%8c%87%e4%bb%a4" class="header-anchor">#&lt;/a>
7.7.1 PSEL 指令
&lt;/h4>
&lt;p>PSEL 指令选择一个 predicate 寄存器或是 all-false 到目标 predicate 寄存器，如下所示：&lt;/p>
&lt;pre>&lt;code class="language-armasm">PSEL &amp;lt;Pd&amp;gt;, &amp;lt;Pn&amp;gt;, &amp;lt;Pm&amp;gt;.&amp;lt;T&amp;gt;[&amp;lt;Wv&amp;gt;, &amp;lt;imm&amp;gt;]
&lt;/code>&lt;/pre>
&lt;p>如果指令中第二源 predicate 寄存器（Pm）中指定的元素为 True, 这条指令将第一源 predicate 寄存器(Pn)的内容放到目标 predicate 寄存器(Pd), 否者设置目标 predicate 寄存器的值全部为 false。
例如以下指令，假设 W12 的值为 0：&lt;/p>
&lt;pre>&lt;code class="language-armasm">PSEL P0, P1, P2.B[W12, #0]
&lt;/code>&lt;/pre>
&lt;p>第二源 predicate 寄存器的[W12+0]即[0]个元素为 False, 因此目标寄存器 P0 被设置为全 0（all-false），如下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_4401_Picture10_png-1280x960.webp"
alt="SME PSEL" width="auto" loading="lazy">
&lt;/figure>
&lt;p>现在看看如下指令，仍然假设 W12 的值为 0，但这次立即数偏移为 1：&lt;/p>
&lt;pre>&lt;code class="language-armasm">PSEL P0, P1, P2.B[W12, #1]
&lt;/code>&lt;/pre>
&lt;p>第二源 predicate 寄存器的[W12+1]即[1]个元素为 True, 因此选择第一源 predicate 寄存器的值到目标寄存器 P0，如下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-16_0116_Picture11_png-1280x960.webp"
alt="SME PSEL" width="auto" loading="lazy">
&lt;/figure>
&lt;h2 id="参考文献">
&lt;a href="#%e5%8f%82%e8%80%83%e6%96%87%e7%8c%ae" class="header-anchor">#&lt;/a>
参考文献
&lt;/h2>
&lt;ul>
&lt;li>&lt;a class="link" href="https://community.arm.com/arm-community-blogs/b/architectures-and-processors-blog/posts/arm-scalable-matrix-extension-introduction" target="_blank" rel="noopener" >Arm Scalable Matrix Extension (SME) Introduction
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/li>
&lt;li>&lt;a class="link" href="https://community.arm.com/arm-community-blogs/b/architectures-and-processors-blog/posts/arm-scalable-matrix-extension-introduction-p2" target="_blank" rel="noopener" >Arm Scalable Matrix Extension (SME) Instructions
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/li>
&lt;/ul></description></item><item><title>Arm 性能优化：可伸缩向量扩展 SVE</title><link>https://cuterwrite.top/p/arm-sve-for-performance/</link><pubDate>Sun, 11 Aug 2024 02:13:00 +0000</pubDate><guid>https://cuterwrite.top/p/arm-sve-for-performance/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-29_117622464_p0_master1200.webp" alt="Featured image of post Arm 性能优化：可伸缩向量扩展 SVE" />&lt;h1 id="arm-性能优化可伸缩向量扩展-sve">
&lt;a href="#arm-%e6%80%a7%e8%83%bd%e4%bc%98%e5%8c%96%e5%8f%af%e4%bc%b8%e7%bc%a9%e5%90%91%e9%87%8f%e6%89%a9%e5%b1%95-sve" class="header-anchor">#&lt;/a>
Arm 性能优化：可伸缩向量扩展 SVE
&lt;/h1>
&lt;h2 id="1-sve-介绍">
&lt;a href="#1-sve-%e4%bb%8b%e7%bb%8d" class="header-anchor">#&lt;/a>
1. SVE 介绍
&lt;/h2>
&lt;p>继固定 128 位向量长度指令集的 Neon 架构扩展之后，Arm 设计了可伸缩向量扩展 (SVE) 作为 AArch64 的下一代 SIMD 扩展。SVE 引入可伸缩概念，允许灵活的向量长度实现，并在 CPU 实现中提供一系列可能的值。向量长度可以从最小 128 位到最大 2048 位不等，以 128 位为增量。&lt;strong>SVE 设计保证相同的应用程序可以在支持 SVE 的不同实现上运行，而无需重新编译代码&lt;/strong>。SVE 提高了该架构对高性能计算 (HPC) 和机器学习 (ML) 应用程序的适用性，这些应用程序需要非常大量的数据处理。SVE2 是 SVE 和 Neon 的超集。SVE2 允许在数据级并行中使用更多功能域。SVE2 继承了 SVE 的概念、向量寄存器和操作原理。SVE 和 SVE2 定义了 32 个可伸缩向量寄存器。芯片合作伙伴可以选择合适的向量长度设计实现，硬件可在 128 位到 2048 位之间（以 128 位为增量）变化。SVE 和 SVE2 的优势在于，只有一个向量指令集使用可伸缩变量。&lt;/p>
&lt;p>SVE 设计理念使开发人员能够编写和构建一次软件，然后在具有各种 SVE 向量长度实现的不同 AArch64 硬件上运行相同的二进制文件。二进制文件的可移植性意味着开发人员不必知道其系统的向量长度实现。消除了重建二进制文件的需求，使软件更容易移植。除了可伸缩向量之外，SVE 和 SVE2 还包括：&lt;/p>
&lt;ul>
&lt;li>per-lane predication&lt;/li>
&lt;li>Gather Load/Scatter Store&lt;/li>
&lt;li>推测性向量化&lt;/li>
&lt;/ul>
&lt;p>这些特性有助于在处理大型数据集时对循环进行向量化和优化。&lt;/p>
&lt;p>SVE2 和 SVE 的主要区别在于指令集的功能覆盖范围。SVE 专为 HPC 和 ML 应用而设计。SVE2 扩展了 SVE 指令集，使其能够加速 HPC 和 ML 以外领域的数据处理。SVE2 指令集还可以加速以下应用中使用的常见算法：&lt;/p>
&lt;ul>
&lt;li>计算机视觉&lt;/li>
&lt;li>多媒体&lt;/li>
&lt;li>LTE 基处理&lt;/li>
&lt;li>基因组学&lt;/li>
&lt;li>内存数据库&lt;/li>
&lt;li>Web 服务&lt;/li>
&lt;li>通用软件&lt;/li>
&lt;/ul>
&lt;p>SVE 和 SVE2 都支持收集和处理大量数据。SVE 和 SVE2 不是 Neon 指令集的扩展。相反，SVE 和 SVE2 经过重新设计，以提供比 Neon 更好的数据并行性。但是，SVE 和 SVE2 的硬件逻辑覆盖了 Neon 硬件的实现。当微架构支持 SVE 或 SVE2 时，它也支持 Neon。要使用 SVE 和 SVE2，在该微架构上运行的软件必须首先支持 Neon。&lt;/p>
&lt;h2 id="2-sve-架构基础">
&lt;a href="#2-sve-%e6%9e%b6%e6%9e%84%e5%9f%ba%e7%a1%80" class="header-anchor">#&lt;/a>
2. SVE 架构基础
&lt;/h2>
&lt;p>本节介绍 SVE 和 SVE2 共享的基本架构特性。与 SVE 一样，SVE2 也基于可扩展向量。除了 Neon 提供的现有寄存器库之外，SVE 和 SVE2 还添加了以下寄存器：&lt;/p>
&lt;ul>
&lt;li>32 个可伸缩向量寄存器，&lt;code>Z0-Z31&lt;/code>&lt;/li>
&lt;li>16 个可伸缩 Predicate 寄存器，&lt;code>P0-P15&lt;/code>
&lt;ul>
&lt;li>1 个 首故障 Predicate 寄存器，&lt;code>FFR&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>可伸缩向量系统控制寄存器, &lt;code>ZCR_ELx&lt;/code>&lt;/li>
&lt;/ul>
&lt;h3 id="21-可伸缩向量寄存器">
&lt;a href="#21-%e5%8f%af%e4%bc%b8%e7%bc%a9%e5%90%91%e9%87%8f%e5%af%84%e5%ad%98%e5%99%a8" class="header-anchor">#&lt;/a>
2.1 可伸缩向量寄存器
&lt;/h3>
&lt;p>可伸缩向量寄存器 &lt;code>Z0-Z31&lt;/code> 可以在微架构中实现为 128-2048 位。最低的 128 位与 Neon 的固定 128 位向量 &lt;code>V0-V31&lt;/code> 共享。&lt;/p>
&lt;p>下图显示了可伸缩向量寄存器 &lt;code>Z0-Z31&lt;/code>：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_Z-register.webp"
alt="Z 寄存器-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>可伸缩向量寄存器 Z0-Z31&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>可伸缩向量：&lt;/p>
&lt;ul>
&lt;li>可以容纳 64、32、16 和 8 位元素&lt;/li>
&lt;li>支持整数、双精度、单精度和半精度浮点元素&lt;/li>
&lt;li>可以针对每个异常级别（EL）配置向量长度&lt;/li>
&lt;/ul>
&lt;h3 id="22-可伸缩-predicate-寄存器">
&lt;a href="#22-%e5%8f%af%e4%bc%b8%e7%bc%a9-predicate-%e5%af%84%e5%ad%98%e5%99%a8" class="header-anchor">#&lt;/a>
2.2 可伸缩 Predicate 寄存器
&lt;/h3>
&lt;p>为了控制哪些活动元素参与运算，Predicate 寄存器（简称为 P 寄存器）在许多 SVE 指令中用作掩码，这也为向量运算提供了灵活性。下图显示了可伸缩 Predicate 寄存器 &lt;code>P0-P15&lt;/code> ：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_Predicate-register.webp"
alt="P 寄存器-2024-08-12" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>可伸缩 Predicate 寄存器 P0-P15&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>P 寄存器通常用作数据操作的位掩码：&lt;/p>
&lt;ul>
&lt;li>每个 P 寄存器是 Z 寄存器长度的 1/8&lt;/li>
&lt;li>&lt;code>P0-P7&lt;/code> 用于加载、存储和算术运算&lt;/li>
&lt;li>&lt;code>P8-P15&lt;/code> 用于循环管理&lt;/li>
&lt;li>FFR 是一个特殊的 P 寄存器，由 first-fault vector load 指令和 store 指令设置，用于指示每个元素的加载和存储操作的成功情况。FFR 旨在支持推测性内存访问，这使得在许多情况下向量化更容易和更安全。&lt;/li>
&lt;/ul>
&lt;h3 id="23-可伸缩向量系统控制寄存器">
&lt;a href="#23-%e5%8f%af%e4%bc%b8%e7%bc%a9%e5%90%91%e9%87%8f%e7%b3%bb%e7%bb%9f%e6%8e%a7%e5%88%b6%e5%af%84%e5%ad%98%e5%99%a8" class="header-anchor">#&lt;/a>
2.3 可伸缩向量系统控制寄存器
&lt;/h3>
&lt;p>下图展示了可伸缩向量系统控制寄存器 &lt;code>ZCR_ELx&lt;/code> ：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_ZCR_Elx.webp"
alt="ZCR_Elx-2024-08-12" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>可伸缩向量系统控制寄存器 ZCR_Elx&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>可伸缩向量系统控制寄存器指示 SVE 实现特性：&lt;/p>
&lt;ul>
&lt;li>&lt;code>ZCR_Elx.LEN&lt;/code> 字段用于当前和较低异常级别的向量长度。&lt;/li>
&lt;li>大多数位当前保留供将来使用。&lt;/li>
&lt;/ul>
&lt;h3 id="24-sve-汇编语法">
&lt;a href="#24-sve-%e6%b1%87%e7%bc%96%e8%af%ad%e6%b3%95" class="header-anchor">#&lt;/a>
2.4 SVE 汇编语法
&lt;/h3>
&lt;p>SVE 汇编语法格式由操作码、目标寄存器、P 寄存器（如果指令支持 Predicate 掩码）和输入操作数组成。以下指令示例将详细说明此格式。&lt;/p>
&lt;p>示例 1:&lt;/p>
&lt;pre>&lt;code class="language-armasm">LDFF1D {&amp;lt;Zt&amp;gt;.D}, &amp;lt;Pg&amp;gt;/Z, [&amp;lt;Xn|SP&amp;gt;, &amp;lt;Zm&amp;gt;.D, LSL #3]
&lt;/code>&lt;/pre>
&lt;p>其中：&lt;/p>
&lt;ul>
&lt;li>&lt;code>&amp;lt;Zt&amp;gt;&lt;/code> 是 Z 寄存器, &lt;code>Z0-Z31&lt;/code>&lt;/li>
&lt;li>&lt;code>&amp;lt;Zt&amp;gt;&lt;/code>.D 和 &lt;code>&amp;lt;Zm&amp;gt;.D&lt;/code> 指定目标和操作数向量的元素类型，不需要指定元素的数量。&lt;/li>
&lt;li>&lt;code>&amp;lt;Pg&amp;gt;&lt;/code> 是 P 寄存器, &lt;code>P0-P15&lt;/code>&lt;/li>
&lt;li>&lt;code>&amp;lt;Pg&amp;gt;/Z&lt;/code> 是对 P 寄存器归零。&lt;/li>
&lt;li>&lt;code>&amp;lt;Zm&amp;gt;&lt;/code> 指定 Gather Load 地址模式的偏移量。&lt;/li>
&lt;/ul>
&lt;p>示例 2:&lt;/p>
&lt;pre>&lt;code class="language-armasm">ADD &amp;lt;Zdn&amp;gt;.&amp;lt;T&amp;gt;, &amp;lt;Pg&amp;gt;/M, &amp;lt;Zdn&amp;gt;.&amp;lt;T&amp;gt;, &amp;lt;Zm&amp;gt;.&amp;lt;T&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>其中：&lt;/p>
&lt;ul>
&lt;li>&lt;code>&amp;lt;Pg&amp;gt;/M&lt;/code> 是合并 P 寄存器。&lt;/li>
&lt;li>&lt;code>&amp;lt;Zdn&amp;gt;&lt;/code> 既是目标寄存器，也是输入操作数之一。指令语法在两个位置都显示 &lt;code>&amp;lt;Zdn&amp;gt;&lt;/code> ，是为了方便起见。在汇编编码中，为了简化，它们只被编码一次。&lt;/li>
&lt;/ul>
&lt;p>示例 3:&lt;/p>
&lt;pre>&lt;code class="language-armasm">ORRS &amp;lt;Pd&amp;gt;.B, &amp;lt;Pg&amp;gt;.Z, &amp;lt;Pn&amp;gt;.B, &amp;lt;Pm&amp;gt;.B
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;code>S&lt;/code> 是 P 寄存器条件标志 &lt;code>NZCV&lt;/code> 的新解释。&lt;/li>
&lt;li>&lt;code>&amp;lt;Pg&amp;gt;&lt;/code> 控制 P 寄存器在示例操作中充当位掩码。&lt;/li>
&lt;/ul>
&lt;h3 id="25-sve-架构特性">
&lt;a href="#25-sve-%e6%9e%b6%e6%9e%84%e7%89%b9%e6%80%a7" class="header-anchor">#&lt;/a>
2.5 SVE 架构特性
&lt;/h3>
&lt;p>SVE 包括以下关键架构特性：&lt;/p>
&lt;ul>
&lt;li>per-lane predication&lt;/li>
&lt;/ul>
&lt;p>为了允许对所选元素进行灵活的操作，SVE 引入了 16 个 P 寄存器， &lt;code>P0-P15&lt;/code> ，用于指示对向量活动通道的有效操作。例如：&lt;/p>
&lt;pre>&lt;code class="language-armasm">ADD Z0.D, P0/M, Z0.D, Z1.D
&lt;/code>&lt;/pre>
&lt;p>活动元素 &lt;code>Z0&lt;/code> 和 &lt;code>Z1&lt;/code> 相加并将结果放入 &lt;code>Z0&lt;/code> 中，&lt;code>P0&lt;/code> 指示操作数的哪些元素是活动的和非活动的。&lt;code>P0&lt;/code> 后面的 &lt;strong>M&lt;/strong> 表示 Merging ，表示将非活动元素合并，因此 &lt;code>Z0&lt;/code> 的非活动元素在 &lt;code>ADD&lt;/code> 操作后将保持其初始值。如果 &lt;code>P0&lt;/code> 后面是 &lt;strong>Z&lt;/strong> ，则非活动元素将被清零，目标寄存器的非活动元素将在操作后归零。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_Per-lane_Predication.webp"
alt="Per-lane_Predication-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Per-lane predication merging&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>如果使用的是 &lt;strong>\Z&lt;/strong> ，则非活动元素将被清零，目标寄存器的非活动元素将在操作后归零。例如&lt;/p>
&lt;pre>&lt;code class="language-armasm">CPY Z0.B, P0/Z, #0xFF
&lt;/code>&lt;/pre>
&lt;p>表示将有符号整数 0xFF 复制到 &lt;code>Z0&lt;/code> 的活动通道中，而非活动通道将被清零。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_Per-lane_Predicate_Zeroing.webp"
alt="Per-lane_Predicate_Zeroing-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Per-lane predication zeroing&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;blockquote class="alert-blockquote alert-note">
&lt;p class="alert-heading">
&lt;svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="16" height="16">
&lt;path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z">&lt;/path>
&lt;/svg>
&lt;span>注释&lt;/span>
&lt;/p>
&lt;p>并非所有指令都具有 Predicate 选项。此外，并非所有 Predicate 操作都同时具有合并和清零选项。您必须参考 &lt;a class="link" href="https://developer.arm.com/documentation/ddi0487/latest/t" target="_blank" rel="noopener" >AArch64 SVE Supplement
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
以了解每个指令的规范细节。&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>Gather Load 和 Scatter Store&lt;/li>
&lt;/ul>
&lt;p>SVE 中的寻址模式允许将向量用作 Gather Load 和 Scatter Store 指令中的基地址和偏移量，这使得能够访问非连续的内存位置。例如：&lt;/p>
&lt;pre>&lt;code class="language-armasm">LD1SB Z0.S, P0/Z, [Z1.S] // 将有符号字节从由 32 位向量基地址 Z1 生成的内存地址 Gather Load 到 Z0 的活动 32 位元素中。
LD1SB Z0.D, P0/Z, [X0, Z1.D] // 将有符号字节从由 64 位标量基地址 X0 加上 Z1.D 中的向量索引生成的内存地址 Gather Load 到 Z0 的活动元素中。
&lt;/code>&lt;/pre>
&lt;p>以下示例显示了加载操作 &lt;code>LD1SB Z0.S, P0/Z, [Z1.S]&lt;/code> ，其中 &lt;code>P0&lt;/code> 包含所有真元素，&lt;code>Z1&lt;/code> 包含分散的地址。加载后，&lt;code>Z0.S&lt;/code> 的每个元素的低位字节将用从分散内存位置获取的数据更新。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_gather-load_and_scatter_store_example.webp"
alt="gather-load_and_scatter_store_example-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Gather-load 与 Scatter-store 示例&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;ul>
&lt;li>P 寄存器驱动的循环控制和管理&lt;/li>
&lt;/ul>
&lt;p>作为 SVE 的一项关键特性，P 寄存器不仅可以灵活地控制向量运算的各个元素，还可以实现 P 寄存器驱动的循环控制。P 寄存器驱动的循环控制和管理使循环控制高效且灵活。此功能通过在 P 寄存器中注册活动和非活动元素索引，消除了处理部分向量的额外循环头和尾的开销。P 寄存器驱动的循环控制和管理意味着，在接下来的循环迭代中，只有活动元素才会执行预期的操作。例如：&lt;/p>
&lt;pre>&lt;code class="language-armasm">WHILEL0 P0.S, x8, x9 // 在 P0 中生成一个谓词，从最低编号的元素开始，当第一个无符号标量操作数 X8 的递增值小于第二个标量操作数 X9 时为真，之后为假，直到最高编号的元素。
B.FIRST Loop_start // B.FIRST（等效于 B.MI）或 B.NFRST（等效于 B.PL）通常用于根据上述指令测试结果进行分支，判断 P0 的第一个元素是真还是假，作为循环的结束或继续条件。
&lt;/code>&lt;/pre>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_Predicate-driver_loop_control_and_management_example.webp"
alt="Predicate-driver_loop_control_and_management_example-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>P 寄存器驱动的循环控制和管理示例&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;ul>
&lt;li>用于软件管理推测的向量分区&lt;/li>
&lt;/ul>
&lt;p>推测性加载可能会给传统向量的内存读取带来挑战，&lt;strong>如果在读取过程中某些元素发生错误，则难以逆转加载操作并跟踪哪些元素加载失败&lt;/strong>。Neon 不允许推测性加载。为了允许对向量进行推测性加载（例如 LDRFF），SVE 引入了 first-fault vector load 指令。为了允许向量访问跨越无效页面，SVE 还引入了 FFR 寄存器。&lt;strong>使用 first-fault vector load 指令加载到 SVE 向量时，FFR 寄存器会更新每个元素的加载成功或失败结果&lt;/strong>。当发生加载错误时，FFR 会立即注册相应的元素，将其余元素注册为 0 或 false，并且不会触发异常。通常，RDFFR 指令用于读取 FFR 状态。当第一个元素为假时，RDFFR 指令结束迭代。如果第一个元素为真，RDFFR 指令继续迭代。FFR 的长度与 P 向量相同。可以使用 SETFFR 指令初始化该值。以下示例使用 LDFF1D 从内存中读取数据，FFR 会相应地更新：&lt;/p>
&lt;pre>&lt;code class="language-armasm">LDFF1D Z0.D, P0/Z, [Z1.D, #0] // 使用首个故障行为将双字从由向量基地址 Z1 加 0 生成的内存地址收集加载到 Z0 的活动元素中。非活动元素不会读取设备内存或发出故障信号，并在目标向量中设置为零。从有效内存成功加载将 FFR 中的对应元素设置为真。首个故障加载将 FFR 中的对应元素和其余元素设置为假或 0。
&lt;/code>&lt;/pre>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_Vector-partioning-for-software-managed-speculation-example.webp"
alt="Vector-partioning-for-software-managed-speculation-example-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>用于软件管理推测的向量分区示例&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;ul>
&lt;li>扩展的浮点和水平规约&lt;/li>
&lt;/ul>
&lt;p>为了允许在向量中进行高效的归约操作，并满足对精度的不同要求，SVE 增强了浮点和水平归约操作。这些指令可能具有顺序（从低到高）或基于树（成对）的浮点归约顺序，其中操作顺序可能会导致不同的舍入结果。这些操作需要在可重复性和性能之间进行权衡。例如：&lt;/p>
&lt;pre>&lt;code class="language-armasm">FADDA D0, P0/M, D1, Z2.D // 从源头向量的低位到高位元素进行浮点加严格顺序归约，将结果累积到 SIMD&amp;amp;FP 标量寄存器中。该示例指令将 D1 与 Z2.D 的所有活动元素相加，并将结果存储到标量寄存器 D0 中。向量元素按从低到高的顺序严格处理，标量源 D1 提供初始值。源向量中的非活动元素将被忽略。而 FADDV 将执行递归成对归约，并将结果存储到标量寄存器中。
&lt;/code>&lt;/pre>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_Extended_Floating-poing-and-horizontal-reductions-example.webp"
alt="Extended_Floating-poing-and-horizontal-reductions-example-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>扩展的浮点和水平规约示例&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;h2 id="3-sve2-新增特性">
&lt;a href="#3-sve2-%e6%96%b0%e5%a2%9e%e7%89%b9%e6%80%a7" class="header-anchor">#&lt;/a>
3. SVE2 新增特性
&lt;/h2>
&lt;p>本节介绍 SVE2 为 Arm AArch64 架构新增的特性。为了实现可伸缩的性能，SVE2 基于 SVE 构建，允许向量实现高达 2048 位。&lt;/p>
&lt;p>在 SVE2 中，添加了许多复制 Neon 中现有指令的指令，包括：&lt;/p>
&lt;ul>
&lt;li>转换后的 Neon 整数运算，例如，带符号绝对差累加 (SAB) 和带符号减半加法 (SHADD)。&lt;/li>
&lt;li>转换后的 Neon 扩展、缩小和成对运算，例如，无符号长加法 - 底部 (UADDLB) 和无符号长加法 - 顶部 (UADDLT)。&lt;/li>
&lt;/ul>
&lt;p>元素处理顺序发生了变化。SVE2 对交错的偶数和奇数元素进行处理，而 Neon 对窄或宽操作的低半部分和高半部分元素进行处理。下图说明了 Neon 和 SVE2 处理之间的区别：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_transformed_neon_widen_narraow_pairwise_operations.webp"
alt="transformed_neon_widen_narraow_pairwise_operations-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>转换后的 Neon 窄或宽操作对比&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;ul>
&lt;li>复数操作，例如带旋转的复整数乘加 (CMLA)。&lt;/li>
&lt;li>多精度运算，用于大整数运算和密码学，例如，带进位长加法 - 底部 (ADCLB)、带进位长加法 - 顶部 (ADCLT) 以及 SM4 加密和解密 (SM4E)。&lt;/li>
&lt;/ul>
&lt;p>为了向后兼容，最新架构中需要 Neon 和 VFP。虽然 SVE2 包含 SVE 和 Neon 的一些功能，但 SVE2 并不排除 Neon 在芯片上的存在。&lt;/p>
&lt;p>SVE2 支持针对 HPC 市场以外的新兴应用进行优化，例如，在机器学习 (ML)（UDOT 指令）、计算机视觉（TBL 和 TBX 指令）、基带网络（CADD 和 CMLA 指令）、基因组学（BDEP 和 BEXT 指令）和服务器（MATCH 和 NMATCH 指令）中。&lt;/p>
&lt;p>SVE2 增强了通用处理器大量数据操作的整体性能，而无需其他片外加速器。&lt;/p>
&lt;h2 id="4-使用-sve-编程">
&lt;a href="#4-%e4%bd%bf%e7%94%a8-sve-%e7%bc%96%e7%a8%8b" class="header-anchor">#&lt;/a>
4. 使用 SVE 编程
&lt;/h2>
&lt;p>本节介绍支持 SVE2 应用程序开发的软件工具和库。本节还介绍了如何为支持 SVE2 的目标开发应用程序，在支持 SVE2 的硬件上运行该应用程序，以及在任何 Armv8-A 硬件上模拟该应用程序。&lt;/p>
&lt;h3 id="41-软件和库支持">
&lt;a href="#41-%e8%bd%af%e4%bb%b6%e5%92%8c%e5%ba%93%e6%94%af%e6%8c%81" class="header-anchor">#&lt;/a>
4.1 软件和库支持
&lt;/h3>
&lt;p>要构建 SVE 或 SVE2 应用程序，你必须选择支持 SVE 和 SVE2 功能的编译器。&lt;/p>
&lt;ul>
&lt;li>GNU 工具 8.0+ 版本支持 SVE。&lt;/li>
&lt;li>&lt;a class="link" href="https://developer.arm.com/tools-and-software/server-and-hpc/compile/arm-compiler-for-linux" target="_blank" rel="noopener" >Arm Compiler for Linux
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
18.0+ 版本支持 SVE，20.0+ 版本支持 SVE 和 SVE2。&lt;/li>
&lt;li>GNU 和 Arm Compiler for Linux 编译器都支持优化 C/C++/Fortran 代码。&lt;/li>
&lt;li>LLVM（开源 Clang）5 及更高版本包括对 SVE 的支持，9 及更高版本包括对 SVE2 的支持。要了解 LLVM 工具的每个版本支持哪些 SVE 或 SVE2 功能，请参阅 &lt;a class="link" href="https://developer.arm.com/tools-and-software/open-source-software/developer-tools/llvm-toolchain/sve-support" target="_blank" rel="noopener" >LLVM 工具链 SVE 支持页面
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
。&lt;/li>
&lt;/ul>
&lt;p>&lt;a class="link" href="https://developer.arm.com/Tools%20and%20Software/Arm%20Performance%20Libraries" target="_blank" rel="noopener" >Arm Performance Libraries
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
针对数学例程进行了高度优化，可以链接到你的应用程序。Arm Performance Libraries 19.3+ 版本支持 SVE 的数学库。&lt;/p>
&lt;p>Arm Compiler for Linux 是 Arm Allinea Studio 的一部分，包含 Arm C/C++ 编译器、Arm Fortran 编译器和 Arm Performance Libraries。&lt;/p>
&lt;h3 id="42-如何使用-sve2-编程">
&lt;a href="#42-%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8-sve2-%e7%bc%96%e7%a8%8b" class="header-anchor">#&lt;/a>
4.2 如何使用 SVE2 编程
&lt;/h3>
&lt;p>编写或生成 SVE 和 SVE2 代码的方法有多种。在本小节中，我们将探讨其中的一些方法。&lt;/p>
&lt;p>要编写或生成 SVE 和 SVE2 代码，你可以：&lt;/p>
&lt;ul>
&lt;li>编写 SVE 汇编代码&lt;/li>
&lt;li>使用 SVE 内部函数编程&lt;/li>
&lt;li>自动向量化&lt;/li>
&lt;li>使用 SVE 优化库&lt;/li>
&lt;/ul>
&lt;p>让我们更详细地了解这四种选择。&lt;/p>
&lt;h4 id="421-编写-sve-汇编代码">
&lt;a href="#421-%e7%bc%96%e5%86%99-sve-%e6%b1%87%e7%bc%96%e4%bb%a3%e7%a0%81" class="header-anchor">#&lt;/a>
4.2.1 编写 SVE 汇编代码
&lt;/h4>
&lt;p>你可以将 SVE 指令作为内联汇编编写到 C/C++ 代码中，或者作为完整的函数编写到汇编源代码中。例如：&lt;/p>
&lt;pre>&lt;code class="language-armasm"> .globl subtract_arrays // -- Begin function
.p2align 2
.type subtract_arrays, @function
subtract_arrays: // @subtract_arrays
.cfi_startproc
// %bb.0:
orr w9, wzr, #0x400
mov x8, xzr
whilelo p0.s, xzr, x9
.LBB0_1: // =&amp;gt;This Inner Loop Header: Depth=1
ld1w { z0.s }, p0/z, [x1, x8, lsl #2]
ld1w { z1.s }, p0/z, [x2, x8, lsl #2]
sub z0.s, z0.s, z1.s
st1w { z0.s }, p0, [x0, x8, lsl #2]
incw x8
whilelo p0.s, x8, x9
b.mi .LBB0_1
// %bb.2:
ret
.Lfunc_end0:
.size subtract_arrays, .Lfunc_end0-subtract_arrays
.cfi_endproc
&lt;/code>&lt;/pre>
&lt;p>如果你混合使用高级语言和汇编语言编写的函数，则必须熟悉针对 SVE 更新的&lt;a class="link" href="https://developer.arm.com/documentation/ihi0036/latest/" target="_blank" rel="noopener" >应用程序二进制接口 (ABI)
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
标准。&lt;a class="link" href="https://developer.arm.com/documentation/ihi0055/latest" target="_blank" rel="noopener" >Arm 架构过程调用标准 (AAPCS)
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
指定了数据类型和寄存器分配，并且与汇编编程最相关。AAPCS 要求：&lt;/p>
&lt;ul>
&lt;li>&lt;code>Z0-Z7&lt;/code> 和 &lt;code>P0-P3 &lt;/code>用于传递可伸缩向量参数和结果。&lt;/li>
&lt;li>&lt;code>Z8-Z15&lt;/code> 和 &lt;code>P4-P15&lt;/code> 是被调用者保存的。&lt;/li>
&lt;li>所有其他向量寄存器（&lt;code>Z16-Z31&lt;/code>）都可能被被调用函数破坏，调用函数负责在需要时备份和恢复它们。&lt;/li>
&lt;/ul>
&lt;h4 id="422-使用-sve-instruction-函数intrinsics">
&lt;a href="#422-%e4%bd%bf%e7%94%a8-sve-instruction-%e5%87%bd%e6%95%b0intrinsics" class="header-anchor">#&lt;/a>
4.2.2 使用 SVE instruction 函数（Intrinsics）
&lt;/h4>
&lt;p>SVE 内部函数是由编译器支持的函数，可以替换为相应的指令。程序员可以直接在 C 和 C++ 等高级语言中调用指令函数。SVE 的 ACLE（Arm C 语言扩展）定义了哪些 SVE 指令函数可用、它们的参数以及它们的功能。支持 ACLE 的编译器可以在编译期间将内部函数替换为映射的 SVE 指令。要使用 ACLE 内部函数，你必须包含头文件 &lt;code>arm_sve.h&lt;/code>，其中包含可在 C/C++ 中使用的向量类型和指令函数（针对 SVE）列表。每种数据类型都描述了向量中元素的大小和数据类型：&lt;/p>
&lt;ul>
&lt;li>&lt;code>svint8_t svuint8_t&lt;/code>&lt;/li>
&lt;li>&lt;code>svint16_t svuint16_t svfloat16_t&lt;/code>&lt;/li>
&lt;li>&lt;code>svint32_t svuint32_t svfloat32_t&lt;/code>&lt;/li>
&lt;li>&lt;code>svint64_t svuint64_t svfloat64_t&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>例如，&lt;code>svint64_t&lt;/code> 表示 64 位有符号整数向量，&lt;code>svfloat16_t&lt;/code> 表示半精度浮点数向量。&lt;/p>
&lt;p>以下示例 C 代码已使用 SVE 内部函数进行了手动优化：&lt;/p>
&lt;pre>&lt;code class="language-c">// intrinsic_example.c
#include &amp;lt;arm_sve.h&amp;gt;
svuint64_t uaddlb_array(svuint32_t Zs1, svuint32_t Zs2)
{
// widening add of even elements
svuint64_t result = svaddlb(Zs1, Zs2);
return result;
}
&lt;/code>&lt;/pre>
&lt;p>包含 &lt;code>arm_sve.h&lt;/code> 头文件的源代码可以使用 SVE 向量类型，就像数据类型可以用于变量声明和函数参数一样。要使用 Arm C/C++ 编译器编译代码并以支持 SVE 的 Armv8-A 架构为目标，请使用：&lt;/p>
&lt;pre>&lt;code class="language-bash">armclang -O3 -S -march=armv8-a+sve2 -o intrinsic_example.s intrinsic_example.c
&lt;/code>&lt;/pre>
&lt;p>此命令生成以下汇编代码：&lt;/p>
&lt;pre>&lt;code class="language-armasm">// instrinsic_example.s
uaddlb_array: // @uaddlb_array
.cfi_startproc
// %bb.0:
uaddlb z0.d, z0.s, z1.s
ret
&lt;/code>&lt;/pre>
&lt;h4 id="423-自动向量化">
&lt;a href="#423-%e8%87%aa%e5%8a%a8%e5%90%91%e9%87%8f%e5%8c%96" class="header-anchor">#&lt;/a>
4.2.3 自动向量化
&lt;/h4>
&lt;p>C/C++/Fortran 编译器（例如，适用于 Arm 平台的原生 &lt;a class="link" href="https://developer.arm.com/tools-and-software/server-and-hpc/compile/arm-compiler-for-linux" target="_blank" rel="noopener" >Arm Compiler for Linux
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
和 GNU 编译器）支持使用 SVE 或 SVE2 指令对 C、C++ 和 Fortran 循环进行向量化。要生成 SVE 或 SVE2 代码，请选择适当的编译器选项。例如，使用 armclang 启用 SVE2 优化的一个选项是 &lt;code>-march=armv8-a+sve2&lt;/code> 。如果要使用 SVE 版本的库，请将 &lt;code>-march=armv8-a+sve2&lt;/code> 与 &lt;code>-armpl=sve&lt;/code> 结合使用。&lt;/p>
&lt;h4 id="424-使用-svesve2-优化库">
&lt;a href="#424-%e4%bd%bf%e7%94%a8-svesve2-%e4%bc%98%e5%8c%96%e5%ba%93" class="header-anchor">#&lt;/a>
4.2.4 使用 SVE/SVE2 优化库
&lt;/h4>
&lt;p>使用针对 SVE/SVE2 高度优化的库，例如 &lt;a class="link" href="https://developer.arm.com/Tools%20and%20Software/Arm%20Performance%20Libraries" target="_blank" rel="noopener" >Arm Performance Libraries
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
和 Arm Compute Libraries。Arm Performance Libraries 包含针对 BLAS、LAPACK、FFT、稀疏线性代数和 libamath 优化的数学函数的高度优化实现。要能够链接任何 Arm Performance Libraries 函数，您必须安装 Arm Allinea Studio 并在代码中包含 armpl.h。要使用 Arm Compiler for Linux 和 Arm Performance Libraries 构建应用程序，您必须在命令行中指定 &lt;code>-armpl=&amp;lt;arg&amp;gt;&lt;/code> 。如果您使用 GNU 工具，则必须使用 &lt;code>-L&amp;lt;armpl_install_dir&amp;gt;/lib&lt;/code> 将 Arm Performance Libraries 安装路径包含在链接器命令行中，并指定与 Arm Compiler for Linux &lt;code>-armpl=&amp;lt;arg&amp;gt;&lt;/code> 选项等效的 GNU 选项，即 &lt;code>-larmpl_lp64&lt;/code> 。有关更多信息，请参阅 Arm Performance Libraries 入门指南。&lt;/p>
&lt;h3 id="43-如何运行-svesve2-程序">
&lt;a href="#43-%e5%a6%82%e4%bd%95%e8%bf%90%e8%a1%8c-svesve2-%e7%a8%8b%e5%ba%8f" class="header-anchor">#&lt;/a>
4.3 如何运行 SVE/SVE2 程序
&lt;/h3>
&lt;p>如果您无法访问 SVE 硬件，则可以使用模型或仿真器来运行代码。你可以选择以下几种模型和仿真器：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>QEMU&lt;/strong>： 交叉编译和原生模型，支持在具有 SVE 的 Arm AArch64 平台上进行建模。&lt;/li>
&lt;li>&lt;strong>Fast Models&lt;/strong>： 跨平台模型，支持在基于 x86 的主机上运行的具有 SVE 的 Arm AArch64 平台进行建模。支持 SVE2 的 架构包络模型 AEM 只对主要合作伙伴可用。&lt;/li>
&lt;li>&lt;strong>Arm Instruction Emulator (ArmIE)&lt;/strong>： 直接在 Arm 平台上运行。支持 SVE，并从 19.2+ 版本开始支持 SVE2。&lt;/li>
&lt;/ul>
&lt;h2 id="5-acle-intrinsics">
&lt;a href="#5-acle-intrinsics" class="header-anchor">#&lt;/a>
5. ACLE Intrinsics
&lt;/h2>
&lt;h3 id="51-acle-简介">
&lt;a href="#51-acle-%e7%ae%80%e4%bb%8b" class="header-anchor">#&lt;/a>
5.1 ACLE 简介
&lt;/h3>
&lt;p>ACLE (Arm C 语言扩展) 是在 C 和 C++ 代码中利用内部函数和其他特性来支持 Arm 的功能。&lt;/p>
&lt;ul>
&lt;li>ACLE (ARM C 语言扩展) 通过特定于 Arm 的特性扩展了 C/C++ 语言。
&lt;ul>
&lt;li>预定义宏：&lt;code>__ARM_ARCH_ISA_A64&lt;/code> 、 &lt;code>__ARM_BIG_ENDIAN&lt;/code> 等。&lt;/li>
&lt;li>内部函数：&lt;code>__clz(uint32_t x)&lt;/code> 、 &lt;code>__cls(uint32_t x)&lt;/code> 等。&lt;/li>
&lt;li>数据类型：SVE、NEON 和 FP16 数据类型。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>用于 SVE 的 ACLE 支持使用 ACLE 进行可变长度向量 (VLA) 编程。
&lt;ul>
&lt;li>几乎每个 SVE 指令都有一个对应的内部函数。&lt;/li>
&lt;li>数据类型用于表示 SVE 内部函数所使用的无大小向量。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>适用于以下用户的场景：
&lt;ul>
&lt;li>希望手动调整 SVE 代码的用户。&lt;/li>
&lt;li>希望适配或手动优化应用程序和库的用户。&lt;/li>
&lt;li>需要对 Arm 目标进行底层访问的用户。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="52-如何使用-acle">
&lt;a href="#52-%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8-acle" class="header-anchor">#&lt;/a>
5.2 如何使用 ACLE
&lt;/h3>
&lt;ul>
&lt;li>引入头文件
&lt;ul>
&lt;li>&lt;code>arm_acle.h&lt;/code> ：核心 ACLE&lt;/li>
&lt;li>&lt;code>arm_fp16.h&lt;/code> ：添加 FP16 数据类型。
&lt;ul>
&lt;li>目标平台需支持 FP16，即 &lt;code>march=armv8-a+fp16&lt;/code>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>arm_neon.h&lt;/code> ：添加 NEON Intrinsics 和数据类型。
&lt;ul>
&lt;li>目标平台需支持 NEON，即 &lt;code>march=armv8-a+simd&lt;/code>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>arm_sve.h&lt;/code> ：添加 SVE Intrinsics 和数据类型。
&lt;ul>
&lt;li>目标平台需支持 SVE，即 &lt;code>march=armv8-a+sve&lt;/code>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="53-sve-acle">
&lt;a href="#53-sve-acle" class="header-anchor">#&lt;/a>
5.3 SVE ACLE
&lt;/h3>
&lt;ul>
&lt;li>首先需要做的是引入头文件&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-c">#include &amp;lt;arm_sve.h&amp;gt;
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>VLA 数据类型
&lt;ul>
&lt;li>&lt;code>svfloat64_t&lt;/code>, &lt;code>svfloat16_t&lt;/code>, &lt;code>svuint32_t&lt;/code> 等。&lt;/li>
&lt;li>命名规则：&lt;code>sv&amp;lt;datatype&amp;gt;&amp;lt;datasize&amp;gt;_t&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Predication
&lt;ul>
&lt;li>合并：&lt;code>_m&lt;/code>&lt;/li>
&lt;li>置零：&lt;code>_z&lt;/code>&lt;/li>
&lt;li>不确定：&lt;code>_x&lt;/code>&lt;/li>
&lt;li>P 寄存器的数据类型：&lt;code>svbool_t&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>使用泛型做函数重载，比如函数 &lt;code>svadd&lt;/code> 会根据参数类型自动选择对应的函数。&lt;/li>
&lt;li>函数命名规则：&lt;code>svbase[disambiguator][type0][type1]...[predication]&lt;/code>
&lt;ul>
&lt;li>base 指的是基本操作，比如 &lt;code>add&lt;/code>、&lt;code>mul&lt;/code>、&lt;code>sub&lt;/code> 等。&lt;/li>
&lt;li>disambiguator 用于区分相同基本操作的不同变体。&lt;/li>
&lt;li>typeN 指定了向量和 P 寄存器的类型。&lt;/li>
&lt;li>predication 指定了非活动元素的处理方式。&lt;/li>
&lt;li>例如： &lt;code>svfloat64_t svld1_f64&lt;/code>, &lt;code>svbool_t svwhilelt_b8&lt;/code>, &lt;code>svuint32_t svmla_u32_z&lt;/code>, &lt;code>svuint32_t svmla_u32_m&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="54-sve-常用-intrinsics">
&lt;a href="#54-sve-%e5%b8%b8%e7%94%a8-intrinsics" class="header-anchor">#&lt;/a>
5.4 SVE 常用 Intrinsics
&lt;/h3>
&lt;ul>
&lt;li>Predicate
&lt;ul>
&lt;li>Predicate 是一个 bool 类型的向量，用于控制计算过程中向量中对应位置是否参与运算&lt;/li>
&lt;li>&lt;code>svbool_t pg = svwhilelt_b32(i, num)&lt;/code> 产生 (i, i + 1, i + 2, &amp;hellip;, i + vl - 1) &amp;lt; num 的 predicate&lt;/li>
&lt;li>&lt;code>svbool_t pg = svptrue_b32()&lt;/code> 产生一个全为 true 的 predicate&lt;/li>
&lt;li>其中，b32 对应处理 32 位数据（int/float），此外还有 b8, b16, b64 对应的 intrinsic&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>内存数据存取
&lt;ul>
&lt;li>&lt;code>svld1(pg, *base)&lt;/code>： 从地址 base 中加载连续向量。&lt;/li>
&lt;li>&lt;code>svst1(pg, *base, vec)&lt;/code>： 将向量 vec 存储到地址 base 中。&lt;/li>
&lt;li>&lt;code>svld1_gather_index(pg, *base, vec_index)&lt;/code>： 从地址 base 中加载向量索引对应的数据。&lt;/li>
&lt;li>&lt;code>svst1_scatter_index(pg, *base, vec_index, vec)&lt;/code>： 将向量 vec 中数据存储到向量索引对应的位置。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>基础计算
&lt;ul>
&lt;li>&lt;code>svadd_z(pg, sv_vec1, sv_vec2)&lt;/code>&lt;/li>
&lt;li>&lt;code>svadd_m(pg, sv_vec1, sv_vec2)&lt;/code>&lt;/li>
&lt;li>&lt;code>svadd_x(pg, sv_vec1, sv_vec2)&lt;/code>&lt;/li>
&lt;li>&lt;code>svadd_x(pg, sv_vec1, x)&lt;/code>&lt;/li>
&lt;li>其中，&lt;code>_z&lt;/code> 表示将 pg 为 false 的位置置零，&lt;code>_m&lt;/code> 表示保留原值，&lt;code>_x&lt;/code> 表示不确定（什么值都有可能）。&lt;/li>
&lt;li>第二个操作数可以为标量数据。&lt;/li>
&lt;li>&lt;code>svmul&lt;/code>, &lt;code>svsub&lt;/code>, &lt;code>svsubr&lt;/code>, &lt;code>svdiv&lt;/code>, &lt;code>svdivr&lt;/code>：其中，&lt;code>svsubr&lt;/code> 相比 &lt;code>svsub&lt;/code> 交换了减数与被减数的位置。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>其它
&lt;ul>
&lt;li>&lt;code>svdup_f64(double x)&lt;/code>： 生成一个所有元素都为 x 的向量。&lt;/li>
&lt;li>&lt;code>svcntd()&lt;/code>：返回 64-bit 数据的向量长度：&lt;code>svcntb&lt;/code> 对应 8 位， &lt;code>svcnth&lt;/code> 对应 16 位，&lt;code>svcntw&lt;/code> 对应 32 位。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="55-sve-结构体-intrinsics">
&lt;a href="#55-sve-%e7%bb%93%e6%9e%84%e4%bd%93-intrinsics" class="header-anchor">#&lt;/a>
5.5 SVE 结构体 Intrinsics
&lt;/h3>
&lt;p>对应结构体数据，SVE 提供了一些特殊的 Intrinsics，比如：&lt;code>svld3&lt;/code>, &lt;code>svget3&lt;/code>, &lt;code>svset3&lt;/code>, &lt;code>svst3&lt;/code> 等。这些 Intrinsics 用于处理结构体数据。&lt;/p>
&lt;p>例如，对于粒子结构体：&lt;/p>
&lt;pre>&lt;code class="language-c">typedef struct {
float x;
float y;
float z;
} Particle;
&lt;/code>&lt;/pre>
&lt;p>可以使用 &lt;code>svld3&lt;/code> 加载结构体中全部的数据为 3 个向量的组，然后使用 &lt;code>svget3&lt;/code> 从 3 个向量的组中提取一个向量, index 的值为 0, 1, 2 分别对应 x, y, z。&lt;/p>
&lt;pre>&lt;code class="language-c">Particle *ps;
float factor = 2.2;
// 初始化部分省略
for (int i = 0; i &amp;lt; num; i += svcntw()) {
svbool_t pg = svwhilelt_b32(i, num);
svfloat32x3_t sv_ps = svld3(pg, (float32_t *)&amp;amp;ps[i]);
svfloat32_t sv_ps_x = svget3(sv_ps, 0);
svfloat32_t sv_ps_y = svget3(sv_ps, 1);
// 执行计算
sv_ps_x = svmul_x(pg, sv_ps_x, factor);
sv_ps_y = svmul_x(pg, sv_ps_y, factor);
//保存结果
sv_ps = svset3(sv_ps, 0, sv_ps_x);
sv_ps = svset3(sv_ps, 1, sv_ps_y);
svst3(pg, (float32_t *)&amp;amp;ps[i], sv_ps);
}
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;code>svld3(pg, *base)&lt;/code>： 加载结构体中全部的数据为 3 个向量的组；其中，base 是 3 个元素结构体数组的地址。&lt;/li>
&lt;li>&lt;code>svget3(tuple, index)&lt;/code>： 从 3 个向量的组中提取一个向量；index 的值为 0、1 或 2。&lt;/li>
&lt;li>&lt;code>svset3(tuple, index, vec)&lt;/code>： 设置 3 个向量的组中的一个向量；index 的值为 0、1 或 2。&lt;/li>
&lt;li>&lt;code>svst3(pg, *base, vec)&lt;/code>： 将 3 个向量的组存储到结构体中；其中，base 是 3 个元素结构体数组的地址。&lt;/li>
&lt;/ul>
&lt;h3 id="56-sve-条件选择">
&lt;a href="#56-sve-%e6%9d%a1%e4%bb%b6%e9%80%89%e6%8b%a9" class="header-anchor">#&lt;/a>
5.6 SVE 条件选择
&lt;/h3>
&lt;p>SVE 中提供了 &lt;code>svcmplt&lt;/code>、&lt;code>svcompact&lt;/code>、&lt;code>svcntp_b32&lt;/code> 等方法，可以根据条件选择保留向量中的元素。&lt;/p>
&lt;p>例如，对于无向量化的代码：&lt;/p>
&lt;pre>&lt;code class="language-c">for (int i = 0; i &amp;lt; num; i++) {
float tmp = provided[i];
if (tmp &amp;lt; mark) {
selected[count++] = tmp;
if (count &amp;gt;= maxSize) {
break;
}
}
}
&lt;/code>&lt;/pre>
&lt;p>该代码的作用是从 provided 数组中选择小于 mark 的元素，存储到 selected 数组中，直到 selected 数组满。&lt;/p>
&lt;p>用 SVE Intrinsic 改写：&lt;/p>
&lt;pre>&lt;code class="language-c">for (int i = 0; i &amp;lt; num; i += svcntw()) {
svbool_t pg = svwhilelt_b32(i, num);
svfloat32_t sv_tmp = svld1(pg, &amp;amp;provided[i]);
svbool_t pg_sel = svcmplt(pg, sv_tmp, mark);
sv_tmp = svcompact(pg_sel, sv_tmp);
svst1(pg, &amp;amp;selected[count], sv_tmp);
count += svcntp_b32(pg, pg_sel);
if (count &amp;gt;= maxSize) {
break;
}
}
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;code>svcmplt(pg, vec1, vec2)&lt;/code> ：比较两个向量的大小，返回一个 predicate，表示 vec1 中小于 vec2 的位置。&lt;/li>
&lt;li>&lt;code>svcompact(pg, sv_tmp)&lt;/code> ：压缩向量，将 pg 为 active 的数据按序移动到向量低位，其余位置置零。&lt;/li>
&lt;li>&lt;code>svcntp_b32(pg, pg2)&lt;/code> ：返回 pg2 中 active 的元素个数&lt;/li>
&lt;li>这段代码先将 provided 数组中的数据加载到 sv_tmp 中，然后使用 &lt;code>svcmplt&lt;/code> 生成一个 predicate，表示小于 mark 的位置。接着使用 &lt;code>svcompact&lt;/code> 压缩 sv_tmp，得到小于 mark 的数据，再通过 &lt;code>svst1&lt;/code> 存储到 selected 数组中。最后，使用 &lt;code>svcntp_b32&lt;/code> 统计 active 的元素个数，更新 count。&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_compact.webp"
alt="compact-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>svcompact 示意图（256-bit 向量）&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>由于进行了 compact 操作，所以 selected 数组从 count 位置连续存储新的小于 mark 的数据，剩下的位置被置零。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-08-13_svst1.webp"
alt="svst1-2024-08-13" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>svst1 示意图（256-bit 向量）&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;h3 id="57-sve-向量化循环交织">
&lt;a href="#57-sve-%e5%90%91%e9%87%8f%e5%8c%96%e5%be%aa%e7%8e%af%e4%ba%a4%e7%bb%87" class="header-anchor">#&lt;/a>
5.7 SVE 向量化循环交织
&lt;/h3>
&lt;p>SVE Intrinsic 实现的向量化循环交织，相比编译器自动向量化能大大减少读取向量的次数。&lt;/p>
&lt;p>例如，对于无向量化的代码：&lt;/p>
&lt;pre>&lt;code class="language-c">for (int j = offset; j &amp;lt; outerLen - offset; j++) {
int m2index = (j - offset) * innerLen;
int m1index = m2index + innerLen;
int m0index = m1index + innerLen;
int p1index = m0index + innerLen;
int p2index = p1index + innerLen;
for (int i = 0; i &amp;lt; innerLen; i++) {
res[m0index + i] = m2factor * field[m2index + i] +
m1factor * field[m1index + i] +
m0factor * field[m0index + i] +
p1factor * field[p1index + i] +
p2factor * field[p2index + i];
}
}
&lt;/code>&lt;/pre>
&lt;p>编译器对该代码进行自动向量化后，每次迭代需读取五次不同向量的数据，效率较低。&lt;/p>
&lt;p>用 SVE Intrinsic 改写：&lt;/p>
&lt;pre>&lt;code class="language-c">for (int i = 0; i &amp;lt; innerLen; i += svcntd()) {
svbool_t pg = svwhilelt_b32(i, innerLen);
int dataIndex = i;
svfloat64_t jm2Field = svld1(pg, &amp;amp;field[dataIndex]);
dataIndex += innerLen;
svfloat64_t jm1Field = svld1(pg, &amp;amp;field[dataIndex]);
dataIndex += innerLen;
svfloat64_t jm0Field = svld1(pg, &amp;amp;field[dataIndex]);
dataIndex += innerLen;
svfloat64_t jp1Field = svld1(pg, &amp;amp;field[dataIndex]);
for (int j = offset; j &amp;lt; outerLen - offset; j += 1) {
svfloat64_t jp2Field = svld1(pg, &amp;amp;field[(j + offset) * innerLen + i]);
svfloat64_t svRes = svmul_x(pg, jm2Field, m2factor);
svRes = svmad_x(pg, jm1Field, m1factor, svRes);
svRes = svmad_x(pg, jm0Field, m0factor, svRes);
svRes = svmad_x(pg, jp1Field, p1factor, svRes);
svRes = svmad_x(pg, jp2Field, p2factor, svRes);
svst1(pg, &amp;amp;res[j * innerLen + 1], svRes);
jm2Field = jm1Field;
jm1Field = jm0Field;
jm0Field = jp1Field;
jp1Field = jp2Field;
}
}
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;code>svmad_x(pg, vec1, vec2, vec3)&lt;/code> ：计算 vec1 * vec2 + vec3，返回一个向量。&lt;/li>
&lt;li>这段代码每次迭代只需读取一个向量，大大减少向量读取的次数。&lt;/li>
&lt;/ul>
&lt;h2 id="参考文献">
&lt;a href="#%e5%8f%82%e8%80%83%e6%96%87%e7%8c%ae" class="header-anchor">#&lt;/a>
参考文献
&lt;/h2>
&lt;ol>
&lt;li>&lt;a class="link" href="https://developer.arm.com/-/media/Arm%20Developer%20Community/PDF/102340_0001_02_en_introduction-to-sve2.pdf?revision=b208e56b-6569-4ae2-b6f3-cd7d5d1ecac3" target="_blank" rel="noopener" >Introduction to SVE2
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/li>
&lt;li>&lt;a class="link" href="https://www.stonybrook.edu/commcms/ookami/support/_docs/5%20-%20Advanced%20SVE.pdf" target="_blank" rel="noopener" >SVE Deep Dive
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/li>
&lt;li>&lt;a class="link" href="https://arm-software.github.io/acle/main/acle.html" target="_blank" rel="noopener" >Arm C Language Extensions
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
&lt;/li>
&lt;/ol></description></item><item><title>RDMA 之 Memory Window</title><link>https://cuterwrite.top/p/rdma-memory-window/</link><pubDate>Wed, 26 Jun 2024 23:55:00 +0000</pubDate><guid>https://cuterwrite.top/p/rdma-memory-window/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-16_116373724_p0_master1200.webp" alt="Featured image of post RDMA 之 Memory Window" />&lt;h1 id="rdma-之-memory-window">
&lt;a href="#rdma-%e4%b9%8b-memory-window" class="header-anchor">#&lt;/a>
RDMA 之 Memory Window
&lt;/h1>
&lt;p>&lt;strong>本文欢迎非商业转载，转载请注明出处。&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>声明：仅用于收藏，便于阅读&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/353590347">&lt;cite>知乎专栏：14. RDMA 之 Memory Window&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>&lt;strong>本文是“RDMA 杂谈”专栏文章的第 14 篇，欢迎转载，转载请注明出处&lt;/strong>&lt;/p>
&lt;p>我们在 &lt;a class="link" href="https://cuterwrite.top/p/rdma-mr/" >【RDMA 之 Memory Region】
&lt;/a>
一文中介绍过 Memory Region，它是一片由用户注册的特殊的内存区域：一方面其中的内容不会被换页到硬盘中，另一方面 RDMA 网卡中记录了它的地址转换关系，使得硬件拿到用户指定在 WR 中的虚拟地址之后找到对应的物理地址。&lt;/p>
&lt;p>本文我们来讲解 Memory Window 的概念，它是一种基于 Memory Region 的、更灵活的内存管理单元。除了 MW 的概念之外，本文也会更详细的介绍一些 RDMA 领域的内存相关概念，比如 L_Key/R_Key 等。本文配合 &lt;a class="link" href="https://cuterwrite.top/p/rdma-mr/" >【RDMA 之 Memory Region】
&lt;/a>
阅读效果更佳，建议先读者温习一下。&lt;/p>
&lt;h2 id="memory-window-是什么">
&lt;a href="#memory-window-%e6%98%af%e4%bb%80%e4%b9%88" class="header-anchor">#&lt;/a>
Memory Window 是什么
&lt;/h2>
&lt;p>Memory Window 简称 MW，中文就翻译成内存窗口吧。是一种由用户申请的，用于让远端节点访问本端内存区域的 RDMA 资源。每个 MW 都会绑定（称为 bind）在一个已经注册的 MR 上，但是它相比于 MR 可以提供更灵活的权限控制。MW 可以粗略理解为是 MR 的子集，一个 MR 上可以划分出很多 MW，每个 MW 都可以设置自己的权限。MW 和 MR 的关系如下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-28_12_1.webp"
alt="2024-06-28_12_1" width="30%" loading="lazy">&lt;figcaption>
&lt;h4>MR 与 MW 的关系&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;h2 id="内存的访问权限控制">
&lt;a href="#%e5%86%85%e5%ad%98%e7%9a%84%e8%ae%bf%e9%97%ae%e6%9d%83%e9%99%90%e6%8e%a7%e5%88%b6" class="header-anchor">#&lt;/a>
内存的访问权限控制
&lt;/h2>
&lt;p>为了后文说明为何设计 MW，我们先来把 MR 和 MW 都涉及的权限控制讲解一下。&lt;/p>
&lt;h3 id="mrmw-的权限配置">
&lt;a href="#mrmw-%e7%9a%84%e6%9d%83%e9%99%90%e9%85%8d%e7%bd%ae" class="header-anchor">#&lt;/a>
MR/MW 的权限配置
&lt;/h3>
&lt;p>这里的权限，指的是本端/对端节点，对于本端内存的读/写权限，它们两两组合形成了四种权限：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: left">&lt;/th>
&lt;th style="text-align: left">本端&lt;/th>
&lt;th style="text-align: left">对端&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: left">读&lt;/td>
&lt;td style="text-align: left">Local Read&lt;/td>
&lt;td style="text-align: left">Remote Read&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">写&lt;/td>
&lt;td style="text-align: left">Local Write&lt;/td>
&lt;td style="text-align: left">Remote Write&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>除了这四种权限之外，还有 Atomic 权限等，不在本文讨论范围内。&lt;/p>
&lt;p>上表中这四种权限中最低的是本地读（Local Read），是用户必须赋予 MR/MW 的权限，因为如果一块内存本地的用户都无法访问的话，那就失去意义了；另外还有个限制，如果某个 MR 需要配置远端写（Remote Write）或者还没介绍的远端原子操作权限（Remote Atomic），那么也一定要配置本地写（Local Write）权限。在此约束之下，每个 MR 或者 MW 都可以按需配置权限，比如我们注册的一个 MR 需要允许远端节点写入数据，而不允许读，那么我们就打开 Remote Write 权限，关闭 Remote Read 权限。这样 HCA（网卡）收到对端发起的对这个 MR 范围内的某个地址的 WRITE 请求之后，就可以予以放行；而 HCA 收到对端对这个 MR 的 READ 操作时，就会拒绝这个请求，并返回错误信息给对端。&lt;/p>
&lt;h3 id="memory-key">
&lt;a href="#memory-key" class="header-anchor">#&lt;/a>
Memory Key
&lt;/h3>
&lt;p>上述的访问权限配置，并不能杜绝恶意用户对于本地或者远端内存的访问。比如某个节点给了一块内存区域的 Remote Write 权限，那么岂不是任意远端节点（进程）只要传入了合法的地址信息，都可以对这片区域进行写入了？因此，IB 规范设计了 Memory Key，简单理解它就是访问 MR 的钥匙机制，只有持有正确的钥匙，才能打开 MR/MW 的大门。&lt;/p>
&lt;p>Key 是一串数字，由两部分组成：24bit 的 Index 以及 8bit 的 Key：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-28_12_2.webp"
alt="2024-06-28_12_2" width="60%" loading="lazy">&lt;figcaption>
&lt;h4>L_Key/R_Key 的组成&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>其中，Index 用于 HCA 快速索引到本地的虚拟-物理地址转换表等 MR 相关的信息，而 Key 用于校验整个字段的合法性，以防止未授权的用户任意传递 Index。&lt;/p>
&lt;p>Memory Key 按照用途分为两种，Local Key 和 Remote Key：&lt;/p>
&lt;h4 id="l_key">
&lt;a href="#l_key" class="header-anchor">#&lt;/a>
L_Key
&lt;/h4>
&lt;p>即 Local Key，关联到一个 MR 上，用于 HCA 访问本端内存。当本端的某个进程试图使用一个已经注册的 MR 的内存时，HCA 会校验其传递的 L_Key。并且利用 L_Key 中的索引查找地址转换表，把虚拟地址翻译成物理地址然后访问内存。&lt;/p>
&lt;p>我们在 &lt;a class="link" href="https://cuterwrite.top/p/rdma-shared-receive-queue/" >【RDMA 之 Shared Receive Queue】
&lt;/a>
一文中描述过 sge，sge 由起始地址、长度和秘钥组成。用户在填写 WR 时，如果需要 HCA 访问本端内存，那么就需要通过一个 sge 的链表（sgl）来描述内存块，这里 sge 的秘钥填的就是 L_Key，也就是下图中的 key1 和 key3，他们分别是 MR1 的 L_Key 和 MR2 的 L_Key。如果没有 L_Key，那么任何一个本地用户进程都可以指挥硬件访问其他本地用户注册的 MR 的内容，硬件也难以高效的将虚拟地址翻译成物理地址。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-28_12_3.webp"
alt="2024-06-28_12_3" width="50%" loading="lazy">&lt;figcaption>
&lt;h4>L_Key 的作用&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;h4 id="r_key">
&lt;a href="#r_key" class="header-anchor">#&lt;/a>
R_Key
&lt;/h4>
&lt;p>即 Remote Key，关联到一个 MR 或者 MW 上，用于远端节点访问本端内存。当远端节点试图访问本端的内存时，一方面本端的 HCA 会校验 R_Key 是否合法，另一方面会利用 R_Key 中的索引查地址转换表，把虚拟地址翻译成物理地址然后访问内存。&lt;/p>
&lt;p>凡是 RDMA 操作（即 Write/Read/Atomic），用户都要在 WR 中携带远端内存区域的 R_Key。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-28_12_4.webp"
alt="2024-06-28_12_4" width="70%" loading="lazy">&lt;figcaption>
&lt;h4>R_Key 的作用&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>IB 规范通过上述两种机制，来确保 MR 可以按照用户的期望被正确且安全的访问。我们用一个比喻来总结下 MR/MW 权限控制相关的内容：&lt;/p>
&lt;p>A 给自己的房间（MR）配了两把钥匙（Memory Key），一把留作自用（L_Key），另一把钥匙（R_Key）邮寄（可以是任何通信方式）给了 B。B 可以在 A 不在家的时候（本端 CPU 不感知远端节点对本地内存的 RDMA 操作），通过钥匙（R_Key）打开门。打开门之后，可能 B 只能隔着玻璃查看房间的摆设（A 只给了这个 MR 远程读权限），或者进入房间内发现漆黑一片什么也看不到，但是可以向房间里放物品（A 只给了这个 MR 远程写权限），当然也有可能没有玻璃也开了灯（同时给了远程读写权限）。&lt;/p>
&lt;h2 id="为什么要有-mw">
&lt;a href="#%e4%b8%ba%e4%bb%80%e4%b9%88%e8%a6%81%e6%9c%89-mw" class="header-anchor">#&lt;/a>
为什么要有 MW
&lt;/h2>
&lt;p>简而言之，设计 MW 的目的就是想更灵活的控制内存的远程访问权限。&lt;/p>
&lt;p>&lt;a class="link" href="https://cuterwrite.top/p/rdma-mr/" >【RDMA 之 Memory Region】
&lt;/a>
一文中我们介绍过用户注册 MR 的过程，需要从用户态陷入内核态，调用内核提供的函数 pin 住内存（防止换页），然后制作虚拟-物理地址映射表并下发给硬件。&lt;/p>
&lt;p>因为 MR 是由内核管理的，如果用户想修改一个已经存在的 MR 的信息，比如我想收回某个 MR 的远端写权限，只保留远端读权限；或者想要使一个之前已经授权给远端节点的 R_Key 失效，那么用户需要通过重注册 MR（Reregister MR）接口来进行修改，该接口等价于先取消注册 MR（Deregister MR），然后注册 MR（Register MR）。&lt;strong>上述流程需要陷入内核态来完成，而这个过程是耗时较长的&lt;/strong>。&lt;/p>
&lt;p>不同于需要通过控制路径修改权限的 MR，&lt;strong>MW 在创建好之后，可以通过数据路径（即通过用户态直接下发 WR 到硬件的方式）动态的绑定到一个已经注册的 MR 上，并同时设置或者更改其访问权限，这个过程的速度远远超过重新注册 MR 的过程&lt;/strong>。&lt;/p>
&lt;p>那么现在为了使一片内存能够被远端节点进行 RDMA WRITE/READ 操作，我们就拥有了注册 MR 以及注册 MW 然后绑定到一个已注册的 MR 两种方式，它们都会产生一个 R_Key 来提供给远端节点。前一种方式准备阶段的步骤简单，但是不够灵活，一旦注册之后修改起来会比较麻烦；后一种方式相比前一种多了注册 MW 和绑定 MW 到 MR 两种操作，但是可以方便迅速的控制远端访问权限。&lt;/p>
&lt;h2 id="mw-和-mr-权限的关系">
&lt;a href="#mw-%e5%92%8c-mr-%e6%9d%83%e9%99%90%e7%9a%84%e5%85%b3%e7%b3%bb" class="header-anchor">#&lt;/a>
MW 和 MR 权限的关系
&lt;/h2>
&lt;p>也许有的读者会想到，MR 申请时配置了自己的权限，MW 绑定到 MR 时也会配置自己的权限，这两者的权限是什么关系呢？IB 规范在 10.6.7.2.2 节有专门介绍：&lt;/p>
&lt;blockquote>
&lt;p>When binding a Memory Window, a Consumer can request any combination of remote access rights for the Window. However, if the associated Region does not have local write access enabled and the Consumer requests remote write or remote atomic access for the Window, the Channel Interface must return an error either at bind time or access time.&lt;/p>
&lt;/blockquote>
&lt;p>总结来说，&lt;strong>如果想要给 MW 配置远程写或者远程原子操作（Atomic）权限，那么它绑定到的 MR 必须有本地写权限，其他情况下两者权限互不干扰&lt;/strong>：远端用户用 MW，就要遵循 MW 的权限配置；远端用户用 MR，就要遵循 MR 的权限配置。&lt;/p>
&lt;h2 id="用户接口">
&lt;a href="#%e7%94%a8%e6%88%b7%e6%8e%a5%e5%8f%a3" class="header-anchor">#&lt;/a>
用户接口
&lt;/h2>
&lt;p>老样子，用户接口时我们按照控制路径和数据路径来分类：&lt;/p>
&lt;h3 id="控制路径">
&lt;a href="#%e6%8e%a7%e5%88%b6%e8%b7%af%e5%be%84" class="header-anchor">#&lt;/a>
控制路径
&lt;/h3>
&lt;p>MW 支持增、删和查，不能直接修改：&lt;/p>
&lt;h4 id="创建allocate-mw">
&lt;a href="#%e5%88%9b%e5%bb%baallocate-mw" class="header-anchor">#&lt;/a>
创建——Allocate MW
&lt;/h4>
&lt;p>申请 MW，主要是创建 MW 相关的软件结构和让硬件做好准备，用户需要指定后文中介绍的 MW 的类型。这个接口会产生一个 Memory Window 的句柄，用户以后可以用这个句柄指代这个 MW。&lt;/p>
&lt;p>注意此时 MW 没有绑定到 MR 上，处于不可从远端访问的状态。&lt;/p>
&lt;h4 id="删除deallocate-mw">
&lt;a href="#%e5%88%a0%e9%99%a4deallocate-mw" class="header-anchor">#&lt;/a>
删除——Deallocate MW
&lt;/h4>
&lt;p>取消注册 MW。很好理解，就是销毁相关资源。&lt;/p>
&lt;h4 id="查询query-mw">
&lt;a href="#%e6%9f%a5%e8%af%a2query-mw" class="header-anchor">#&lt;/a>
查询——Query MW
&lt;/h4>
&lt;p>查询 MW 的信息，包括 R_Key 及其状态、MW 类型以及 PD 等。&lt;/p>
&lt;p>需要再次强调的是，虽然这个 Verbs 在 IB 规范中有描述，但是并没有在 RDMA 软件栈中实现相关的 API。类似情况的 Verbs 接口还有不少，RDMA 软件栈以实用为原则，没有用户需求的接口一般都没有实现。&lt;/p>
&lt;h3 id="数据路径">
&lt;a href="#%e6%95%b0%e6%8d%ae%e8%b7%af%e5%be%84" class="header-anchor">#&lt;/a>
数据路径
&lt;/h3>
&lt;p>MW 在数据路径有一套独特的接口，分为 Bind 和 Invalidate 两类：&lt;/p>
&lt;h4 id="绑定bind">
&lt;a href="#%e7%bb%91%e5%ae%9abind" class="header-anchor">#&lt;/a>
绑定——Bind
&lt;/h4>
&lt;p>Bind(ing)意为“绑定”，指的是将一个 MW“关联”到一个已经注册的 MR 的指定范围上，并配置一定的读写权限。绑定的结果会产生一个 R_key，用户可以把这个 R_Key 传递给远端节点用于远程访问。注意一个 MW 可以被多次绑定，一个 MR 上也可以绑定多个 MW。如果一个 MR 还有被绑定的 MW，那么这个 MR 是不能被取消注册的。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-28_12_5.webp"
alt="2024-06-28_12_5" width="90%" loading="lazy">&lt;figcaption>
&lt;h4>Bind 的软硬件交互&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>Bind 有两种方式，一种是调用 Post Send 接口下发 Bind MW WR，一种是调用 Bind MW 接口。&lt;/p>
&lt;ul>
&lt;li>Post Send Bind MW WR&lt;/li>
&lt;/ul>
&lt;p>前文我们讲过，相比于 MR，MW 最大的优势就是可以从数据路径快速的配置权限。Post Send Bind MW WR 操作，指的就是用户通过 post send 接口（比如 ibv_post_send()）下发一个 WR 到 SQ 中，这个 WR 的操作类型（比如 SEND/RDMA WRITE/RDMA READ）被指定为 BIND MW，此外 WR 中还携带有权限和要绑定到的 MR 的范围信息。与其他 WR 不同，下发 Bind MW 的 WR 之后，硬件并不会发送任何数据包，而是将 MW 绑定到了指定 MR 上。&lt;/p>
&lt;p>这种方式仅适用于后文介绍的 Type 2 的 MW。&lt;/p>
&lt;ul>
&lt;li>Bind MW&lt;/li>
&lt;/ul>
&lt;p>虽然这是一个独立的接口，但是实际是在 Post Send Bind MW WR 外面又封装了一层。用户传入 MW 绑定的相关信息，包括权限及要绑定的 MR 的信息，驱动程序负责组装和下发 WR 到硬件中。该接口成功后，会将新生成的 R_Key 返回给用户。&lt;/p>
&lt;p>这种方式仅适用于后文介绍的 Type 1 的 MW。&lt;/p>
&lt;p>上述两种操作的关系是这样的：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-28_12_6.webp"
alt="2024-06-28_12_6" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>两种 Bind 操作的关系&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;h4 id="无效化invalidate">
&lt;a href="#%e6%97%a0%e6%95%88%e5%8c%96invalidate" class="header-anchor">#&lt;/a>
无效化——Invalidate
&lt;/h4>
&lt;p>Invalidate 意为无效化，指的是用户通过下发一个带有 Invalidate 操作码的 WR 到硬件而使一个 R_Key 无效的操作。&lt;/p>
&lt;p>&lt;strong>需要强调的是，Invalidate 操作的对象是 R_Key 而不是 MW 本身，即 Invalidate 之后的效果是：远端用户无法再使用这个 R_Key 访问对应的 MW，而 MW 资源仍然存在，以后仍然可以生成新的 R_Key 给远端使用。&lt;/strong>&lt;/p>
&lt;p>Invalidate 操作只能用于下文介绍的 Type 2 的 MW。&lt;/p>
&lt;p>按照 Invalidate 操作的发起方不同，又可以进一步分成两种：&lt;/p>
&lt;ul>
&lt;li>Local Invalidate&lt;/li>
&lt;/ul>
&lt;p>本地无效操作。上层用户如果想在不回收 MW 资源的情况下，收回某个远端的用户的 R_Key 的权限。那么就可以下发一个 Local Invalidate 操作到 SQ 中，硬件收到之后会对相应的 MR 的配置进行修改。成功执行之后，如果持有这个 R_Key 的远端用户想要对 MW 进行 RDMA 操作，将会被本地的硬件拒绝并返回错误。&lt;/p>
&lt;p>因为是本地操作，所以硬件收到这个 WR 之后也不会发送消息到链路上。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-28_12_7.webp"
alt="2024-06-28_12_7" width="60%" loading="lazy">&lt;figcaption>
&lt;h4>Local Invalidate 操作的软硬件交互&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;ul>
&lt;li>Remote Invalidate&lt;/li>
&lt;/ul>
&lt;p>远端无效操作。当一个远端用户不再使用一个 R_Key 之后，可以主动发送消息，让本端回收这个 R_Key。远端用户下发一个带有此操作码的 WR 到 SQ 中，其硬件收到后，将会组装一个报文并发送到本端。本端硬件收到远端的 Remote Invalidate 操作之后，将会把对应的 R_Key 置为不可用状态。同 Local Invalidate 一样，此后对端将无法使用这个 R_Key 对对应的 MW 进行 RDMA 操作。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-28_12_8.webp"
alt="2024-06-28_12_8" width="90%" loading="lazy">&lt;figcaption>
&lt;h4>Remote Invalidate 操作的软硬件交互&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;h2 id="mw-的类型">
&lt;a href="#mw-%e7%9a%84%e7%b1%bb%e5%9e%8b" class="header-anchor">#&lt;/a>
MW 的类型
&lt;/h2>
&lt;p>根据实现和应用场景的不同，IB 规范对 MW 进行了分类：&lt;/p>
&lt;h3 id="type-1">
&lt;a href="#type-1" class="header-anchor">#&lt;/a>
Type 1
&lt;/h3>
&lt;p>Type 1 的 MW 通过 PD 和一个 QP 关联，不会绑定到一个 QP 上，所以也不会影响销毁同一个 PD 下的 QP。&lt;/p>
&lt;p>Type 1 的 MW 的 R_Key 的 key 域段由驱动和硬件掌握，这里“掌握”的意思是，由驱动和硬件分配 key，而不是上层用户。这也是前文中说 Type 1 的 MW 不能被执行 Invalidate 操作的原因。如果 Type 1 MW 的用户想要使一个 R_Key 失效，那么重新通过 Bind MW 接口绑定一次这个 MW，硬件或者驱动就回自动分配一个新的 R_Key 的 key 域段，原有的 R_Key 也就失效了。&lt;/p>
&lt;p>此外，如果用户暂时想要使一个 MW 不再绑定到任何 MR，但是又想保留相关的资源而不是销毁这个 MW，那么可以通过调用 Bind MW 接口，并将 MW 长度设置为 0 来实现。&lt;/p>
&lt;p>IB 规范允许多个 Type 1 MW 绑定到同一个 MR 上，范围可以相互覆盖。&lt;/p>
&lt;h3 id="type-2">
&lt;a href="#type-2" class="header-anchor">#&lt;/a>
Type 2
&lt;/h3>
&lt;p>Type 2 的 MW 赋予了用户更大的自由度，其 R_Key 的 key 域段由用户掌握，即用户想怎么分配就怎么分配。前文已经讲过，用户通过 Post Send Bind MW WR 操作来进行绑定，这个过程并不会返回 R_Key。用户必须记住 Allocate MW 时的 index，并且和其选择的 8 bit key 组成 R_Key 并发送给对端。&lt;/p>
&lt;p>用户可以通过前文介绍过的 Invalidate 操作来使一个 R_Key 无效，如果想要分配一个新的 R_Key 到 MW 上，必须先通过 Invalidate 操作无效之前的 R_Key。&lt;/p>
&lt;p>与 Type 1 不同，Type 2 的 MW 不支持 0 长度的绑定。&lt;/p>
&lt;p>IB 规范同样也允许多个 Type 2 绑定到同一个 MR 上，范围可以相互覆盖。&lt;/p>
&lt;p>此外，根据绑定关系不同，Type 2 还可以分为两种实现方式，它们的差异仅在于和 QP 的绑定关系上。&lt;/p>
&lt;h4 id="type-2a">
&lt;a href="#type-2a" class="header-anchor">#&lt;/a>
Type 2A
&lt;/h4>
&lt;p>通过 QPN 和一个 QP 关联，也就是说远端访问这个 MW 范围内的内存时候，除了 R_Key 之外，还必须指定正确的 QPN。如果一个 QP 上还有绑定的 Type 2A 的 MW，那么这个 QP 不可以被销毁。&lt;/p>
&lt;h4 id="type-2b">
&lt;a href="#type-2b" class="header-anchor">#&lt;/a>
Type 2B
&lt;/h4>
&lt;p>通过 QPN 和 PD 与一个 QP 关联，比 Type 2A 多了个 PD 的校验，即远端通过 RDMA 操作访问 MW 的内存时，除了 QPN 要正确之外，其指定的本端 QP 的 PD 要与绑定这个 MW 时的 PD 相同。另外，与 Type 2A 不同，QP 如果还有 Type 2B MW 绑定关系时是可以被销毁的。&lt;/p>
&lt;p>这里 IB 规范中原有的介绍就比较分散，我们来简单总结一下几种 MW 的异同：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: left">&lt;/th>
&lt;th style="text-align: left">Type 1&lt;/th>
&lt;th style="text-align: left">Type 2A&lt;/th>
&lt;th style="text-align: left">Type 2B&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: left">关联关系&lt;/td>
&lt;td style="text-align: left">PD&lt;/td>
&lt;td style="text-align: left">QP&lt;/td>
&lt;td style="text-align: left">PD + QP&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">R_Key 的 key 域归属&lt;/td>
&lt;td style="text-align: left">驱动+硬件&lt;/td>
&lt;td style="text-align: left">用户&lt;/td>
&lt;td style="text-align: left">用户&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">绑定方式&lt;/td>
&lt;td style="text-align: left">Bind MW 绑定后之前的 R_Key 自动失效&lt;/td>
&lt;td style="text-align: left">Post Send Bind MWWR 绑定前需要先使之前的 R_Key 无效化&lt;/td>
&lt;td style="text-align: left">Post Send Bind MWWR 绑定前需要先使之前的 R_Key 无效化&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">是否支持零长度&lt;/td>
&lt;td style="text-align: left">是&lt;/td>
&lt;td style="text-align: left">否&lt;/td>
&lt;td style="text-align: left">否&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">是否支持 Invalidate&lt;/td>
&lt;td style="text-align: left">否&lt;/td>
&lt;td style="text-align: left">是&lt;/td>
&lt;td style="text-align: left">是&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">关联的 QP 是否可以被销毁&lt;/td>
&lt;td style="text-align: left">-&lt;/td>
&lt;td style="text-align: left">否&lt;/td>
&lt;td style="text-align: left">是&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>此外，IB 规范中对上述几种类型还有如下描述：HCA 必须实现 Type 1 的 MW，另外可以仅选择实现 Type 2A 和 2B 中的一种。Type 1 和 Type 2 的 MW 可以同时关联到同一个 MR 上。因为我了解到的应用程序中使用 MW 的情况不多，所以具体在什么场景下应该使用哪种 MW 也说不出所以然来，如果读者有对这方面的了解欢迎一起交流。&lt;/p>
&lt;p>好了，MW 就讲到这里，到此为止 RDMA 技术中常见的资源就都介绍完了。&lt;/p>
&lt;p>鉴于一般支持 RDMA 的设备都比较昂贵，下一篇我将介绍如何通过软件模拟设备的方式——即 Soft-RoCE 进行一些编程实验。&lt;/p>
&lt;h2 id="ib-规范相关章节">
&lt;a href="#ib-%e8%a7%84%e8%8c%83%e7%9b%b8%e5%85%b3%e7%ab%a0%e8%8a%82" class="header-anchor">#&lt;/a>
IB 规范相关章节
&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>3.5.3 Memory Keys 介绍&lt;/p>
&lt;/li>
&lt;li>
&lt;p>9.4.1.1 Invalidate 操作&lt;/p>
&lt;/li>
&lt;li>
&lt;p>10.6.7 权限管理&lt;/p>
&lt;/li>
&lt;li>
&lt;p>11.2.10.9~12 相关 Verbs 介绍&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="参考文档">
&lt;a href="#%e5%8f%82%e8%80%83%e6%96%87%e6%a1%a3" class="header-anchor">#&lt;/a>
参考文档
&lt;/h2>
&lt;p>[1] IB Specification Vol 1-Release-1.4&lt;/p>
&lt;p>[2] Linux Kernel Networking - Implementation and Theory. Chapter 13&lt;/p></description></item><item><title>RDMA 之 Shared Receive Queue</title><link>https://cuterwrite.top/p/rdma-shared-receive-queue/</link><pubDate>Wed, 26 Jun 2024 23:34:00 +0000</pubDate><guid>https://cuterwrite.top/p/rdma-shared-receive-queue/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-16_116373922_p0_master1200.webp" alt="Featured image of post RDMA 之 Shared Receive Queue" />&lt;h1 id="rdma-之-shared-receive-queue">
&lt;a href="#rdma-%e4%b9%8b-shared-receive-queue" class="header-anchor">#&lt;/a>
RDMA 之 Shared Receive Queue
&lt;/h1>
&lt;p>&lt;strong>本文欢迎非商业转载，转载请注明出处。&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>声明：仅用于收藏，便于阅读&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/279904125">&lt;cite>知乎专栏：11. RDMA 之 Shared Receive Queue&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>我们曾在 &lt;a class="link" href="https://cuterwrite.top/p/rdma-element/" >【3. RDMA 基本元素】
&lt;/a>
中简单介绍了 SRQ 的概念，本文将带大家了解更多关于 SRQ 的细节。&lt;/p>
&lt;h2 id="基本概念">
&lt;a href="#%e5%9f%ba%e6%9c%ac%e6%a6%82%e5%bf%b5" class="header-anchor">#&lt;/a>
基本概念
&lt;/h2>
&lt;h3 id="什么是-srq">
&lt;a href="#%e4%bb%80%e4%b9%88%e6%98%af-srq" class="header-anchor">#&lt;/a>
什么是 SRQ
&lt;/h3>
&lt;p>全称为 Shared Receive Queue，直译为共享接收队列。我们知道，RDMA 通信的基本单位是 QP，每个 QP 都由一个发送队列 SQ 和接收队列 RQ 组成。&lt;/p>
&lt;p>SRQ 是 IB 协议为了给接收端节省资源而设计的。我们可以把一个 RQ 共享给所有关联的 QP 使用，这个公用的 RQ 就称为 SRQ。当与其关联的 QP 想要下发接收 WQE 时，都填写到这个 SRQ 中。然后每当硬件接收到数据后，就根据 SRQ 中的下一个 WQE 的内容把数据存放到指定位置。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-28_11_1.webp"
alt="2024-06-28_11_1" width="80%" loading="lazy">
&lt;/figure>
&lt;h3 id="为什么要用-srq">
&lt;a href="#%e4%b8%ba%e4%bb%80%e4%b9%88%e8%a6%81%e7%94%a8-srq" class="header-anchor">#&lt;/a>
为什么要用 SRQ
&lt;/h3>
&lt;p>通常情况下，我们向 SQ 中下任务的数量要远远超过向 RQ 中下发任务的数量。为什么呢？请先回忆一下哪些操作类型会用到 SQ，哪些又会用到 RQ。&lt;/p>
&lt;p>SEND/WRITE/READ 都需要通信发起方向 SQ 中下发一个 WR，而只有和 SEND 配合的 RECV 操作才需要通信响应方下发 WR 到 RQ 中（带立即数的 Write 操作也会消耗 Receive WR，我们还没讲到）。而我们又知道，SEND-RECV 这一对操作通常都是用于传递控制信息，WRITE 和 READ 才是进行大量远端内存读写操作时的主角，所以自然 SQ 的使用率是远远高于 RQ 的。&lt;/p>
&lt;p>每个队列都是有实体的，占用着内存以及网卡的片上存储空间。在商用场景下，QP 的数量是可能达到十万级甚至更高的，对内存容量提出了很高的要求，内存都是白花花的银子买的，SRQ 就是 IB 协议为了节省用户的内存而设计的一种机制。&lt;/p>
&lt;p>来看一下协议中对为什么要使用 SRQ 的官方解释（10.2.9.1 章节）：&lt;/p>
&lt;blockquote>
&lt;p>Without SRQ, an RC, UC or UD Consumer must post the number of receive WRs necessary to handle incoming receives on a given QP. If the Consumer cannot predict the incoming rate on a given QP, because, for example, the connection has a bursty nature, the Consumer must either: post a sufficient number of RQ WRs to handle the highest incoming rate for each connection, or, for RC, let message flow control cause the remote sender to back off until local Consumer posts more WRs.&lt;/p>
&lt;p>• Posting sufficient WRs on each QP to hold the possible incoming rate, wastes WQEs, and the associated Data Segments, when the Receive Queue is inactive. Furthermore, the HCA doesn’t provide a way of reclaiming these WQEs for use on other connections.&lt;/p>
&lt;p>• Letting the RC message flow control cause the remote sender to back off can add unnecessary latencies, specially if the local Consumer is unaware that the RQ is starving.&lt;/p>
&lt;/blockquote>
&lt;p>简单来说，就是没有 SRQ 的情况下，因为 RC/UC/UD 的接收方不知道对端什么时候会发送过来多少数据，所以必须做好最坏的打算，做好突发性收到大量数据的准备，也就是向 RQ 中下发足量的接收 WQE；另外 RC 服务类型可以利用流控机制来反压发送方，也就是告诉对端”我这边 RQ WQE 不够了“，这样发送端就会暂时放缓或停止发送数据。&lt;/p>
&lt;p>但是正如我们前文所说，第一种方法由于是为最坏情况准备的，大部分时候有大量的 RQ WQE 处于空闲状态未被使用，这对内存是一种极大地浪费；第二种方法虽然不用下发那么多 RQ WQE 了，但是流控是有代价的，即会增加通信时延。&lt;/p>
&lt;p>而 SRQ 通过允许很多 QP 共享接收 WQE（以及用于存放数据的内存空间）来解决了上面的问题。当任何一个 QP 收到消息后，硬件会从 SRQ 中取出一个 WQE，根据其内容存放接收到的数据，然后硬件通过 Completion Queue 来返回接收任务的完成信息给对应的上层用户。&lt;/p>
&lt;p>我们来看一下使用 SRQ 比使用普通的 RQ 可以节省多少内存&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>：&lt;/p>
&lt;p>假设接受数据的节点上有 N 对 QP，并且每个 QP 都可能在随机的时间收到连续的 M 个消息（每个消息都需要消耗一个 RQ 中的 WQE），&lt;/p>
&lt;ul>
&lt;li>如果不使用 SRQ 的话，用户一共需要下发 N * M 个 RQ WQE。&lt;/li>
&lt;li>如果使用 SRQ 的话，用户只需要下发 K * M 个 RQ WQE，而 K 远小于 N。&lt;/li>
&lt;/ul>
&lt;p>这个 K 是可以由用户根据业务来配置的，如果存在大量的并发接收的情况，那么就把 K 设置大一点，否则 K 设置成个位数就足够应付一般的情况了。&lt;/p>
&lt;p>我们一共节省了 (N - K) * M 个 RQ WQE，RQ WQE 本身其实不是很大，大约在几个 KB 的样子，看起来好像占不了多少内存。但是如前文所说，实际上节省的还有用于&lt;strong>存放数据的内存空间&lt;/strong>，这可是很大一块内存了，我们用图来说明：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-28_11_2.webp"
alt="2024-06-28_11_2" width="80%" loading="lazy">
&lt;/figure>
&lt;p>上图中的 SRQ 中有两个 RQ WQE，我们看一下 RQ WQE 的内容，它们是由数个 sge（Scatter/Gather Element）组成的，每个 sge 由一个内存地址，长度和秘钥组成。有了起始地址和长度，sge 就可以指向一块连续的内存区域，那么多个 sge 就可以表示多个彼此离散的连续内存块，我们称多个 sge 为 sgl（Scatter/Gather List）。sge 在 IB 软件协议栈中随处可见（其实在整个 Linux 都很常见），可以用非常少的空间表示非常大的内存区域，IB 的用户都使用 sge 来指定发送和接收区域的。&lt;/p>
&lt;p>可以简单估算下每个 sge 可以指向多大的内存区域，length 是一个 32bit 的无符号整型，可以表示 4GB 的空间。假设一个 RQ WQE 最大可以存放 256 个 sge，那么一个 RQ WQE 一共就是 1TB。当然实际上不可能这么大，这里只是想直观的告诉读者 RQ WQE 背后可能占用着多大的内存空间。&lt;/p>
&lt;h3 id="srqc">
&lt;a href="#srqc" class="header-anchor">#&lt;/a>
SRQC
&lt;/h3>
&lt;p>即 SRQ Context。同 QPC 一样，SRQC 是用来告知硬件跟 SRQ 有关的属性的，包括深度、WQE 大小等信息，本文不再赘述了。&lt;/p>
&lt;h3 id="srqn">
&lt;a href="#srqn" class="header-anchor">#&lt;/a>
SRQN
&lt;/h3>
&lt;p>即 SRQ Number。同 QP 一样，每个节点中可能存在多个 SRQ，为了标识和区分这些 SRQ，每个 SRQ 都有一个序号，称为 SRQN。&lt;/p>
&lt;h3 id="srq-的-pd">
&lt;a href="#srq-%e7%9a%84-pd" class="header-anchor">#&lt;/a>
SRQ 的 PD
&lt;/h3>
&lt;p>我们在 &lt;a class="link" href="https://cuterwrite.top/p/rdma-protection-domain/" >【7. RDMA 之 Protection Domain】
&lt;/a>
中介绍过 Protection Domain 的概念，它用来隔离不同的 RDMA 资源。每个 SRQ 都必须指定一个自己的 PD，可以跟自己关联的 QP 的 PD 相同，也可以不同；SRQ 之间也可以使用相同的 PD。&lt;/p>
&lt;p>如果在使用 SRQ 的时候，收到了数据包，那么只有在要访问的 MR 和 SRQ 处于同一个 PD 下，才会正常接收这个数据包，否则会产生立即错误。&lt;/p>
&lt;h2 id="异步事件">
&lt;a href="#%e5%bc%82%e6%ad%a5%e4%ba%8b%e4%bb%b6" class="header-anchor">#&lt;/a>
异步事件
&lt;/h2>
&lt;p>我们在 &lt;a class="link" href="https://cuterwrite.top/p/rdma-completion-queue/" >【10. RDMA 之 Completion Queue】
&lt;/a>
一文中介绍过，IB 协议根据错误的上报方式将错误类型分为立即错误，完成错误和异步错误。其中的异步错误类似于中断/事件，所以我们有时候也称其为异步事件。每个 HCA 都会注册一个事件处理函数专门用来处理异步事件，收到异步事件后，驱动程序会对其进行必要的处理和进一步上报给用户。&lt;/p>
&lt;p>关于 SRQ 有一个特殊的异步事件，用来及时通知上层用户 SRQ 的状态，即 SRQ Limit Reached 事件。&lt;/p>
&lt;h3 id="srq-limit">
&lt;a href="#srq-limit" class="header-anchor">#&lt;/a>
SRQ Limit
&lt;/h3>
&lt;p>SRQ 可以设置一个水线/阈值，当队列中剩余的 WQE 数量小于水线时，这个 SRQ 会就上报一个异步事件。提醒用户“队列中的 WQE 快用完了，请下发更多 WQE 以防没有地方接收新的数据”。这个水线/阈值就被称为 SRQ Limit，这个上报的事件就被称为 SRQ Limit Reached。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-28_11_3.webp"
alt="2024-06-28_11_3" width="30%" loading="lazy">
&lt;/figure>
&lt;p>因为 SRQ 是多个 QP 共享的，所以如果深度比较小的情况下，很有可能突然里面的 WQE 就用完了。所以协议设计了这种机制，来保证用户能够及时干预 WQE 不够的情况。&lt;/p>
&lt;p>上报异步事件之后，SRQ Limit 的值会被硬件重新设置为 0（应该是为了防止一直上报异步事件给上层）。当然用户可以不使用这个机制，只需要将 SRQ Limit 的值设为 0 即可。&lt;/p>
&lt;h2 id="用户接口">
&lt;a href="#%e7%94%a8%e6%88%b7%e6%8e%a5%e5%8f%a3" class="header-anchor">#&lt;/a>
用户接口
&lt;/h2>
&lt;h3 id="控制面">
&lt;a href="#%e6%8e%a7%e5%88%b6%e9%9d%a2" class="header-anchor">#&lt;/a>
控制面
&lt;/h3>
&lt;p>还是老四样——“增、删、改、查”：&lt;/p>
&lt;ul>
&lt;li>创建——Create SRQ&lt;/li>
&lt;/ul>
&lt;p>创建 SRQ 的时候，跟 QP 一样会申请所有 SRQ 相关的软硬件资源，比如驱动程序会申请 SRQN，申请 SRQC 的空间并向其中填写配置。创建 SRQ 时还必须指定每个 SRQ 的深度（能存放多少 WQE）以及每个 WQE 的最大 sge 数量。&lt;/p>
&lt;ul>
&lt;li>销毁——Destroy SRQ&lt;/li>
&lt;/ul>
&lt;p>销毁 SRQ 的所有相关软硬件资源。&lt;/p>
&lt;ul>
&lt;li>修改——Modify SRQ&lt;/li>
&lt;/ul>
&lt;p>除了 SRQ 深度等属性外，SRQ Limit 的值也是通过这个接口设置的。因为每次产生 SRQ Limit Reached 事件之后，水线的值都会被清零，所以每次都需要用户调用 Modify SRQ 重新设置水线。&lt;/p>
&lt;ul>
&lt;li>查询——Query SRQ&lt;/li>
&lt;/ul>
&lt;p>通常是用来查询水线的配置的。&lt;/p>
&lt;h3 id="数据面">
&lt;a href="#%e6%95%b0%e6%8d%ae%e9%9d%a2" class="header-anchor">#&lt;/a>
数据面
&lt;/h3>
&lt;h3 id="post-srq-receive">
&lt;a href="#post-srq-receive" class="header-anchor">#&lt;/a>
Post SRQ Receive
&lt;/h3>
&lt;p>跟 Post Receive 一样，就是向 SRQ 中下发接收 WQE，里面包含了作为接收缓冲区的内存块的信息。需要注意的是，&lt;strong>主语是 SRQ，与 QP 没有任何关系&lt;/strong>，现在用户是不关心这个 SRQ 被哪些 QP 关联的。&lt;/p>
&lt;h2 id="srq-和-rq-的区别">
&lt;a href="#srq-%e5%92%8c-rq-%e7%9a%84%e5%8c%ba%e5%88%ab" class="header-anchor">#&lt;/a>
SRQ 和 RQ 的区别
&lt;/h2>
&lt;p>从功能上来说，SRQ 和 RQ 一样都是用来储存接收任务书的，但是由于 SRQ 的共享性，所以其和 RQ 有一些差异。&lt;/p>
&lt;h3 id="状态机">
&lt;a href="#%e7%8a%b6%e6%80%81%e6%9c%ba" class="header-anchor">#&lt;/a>
状态机
&lt;/h3>
&lt;p>我们在 &lt;a class="link" href="https://cuterwrite.top/p/rdma-queue-pair/" >【9. RDMA 之 Queue Pair】
&lt;/a>
中介绍过，QP 有着复杂的状态机，不同的状态下 QP 的收发能力存在差异。而 SRQ 只有非错误和错误两种状态：&lt;/p>
&lt;p>无论是哪种状态下，用户都可以向 SRQ 中下发 WQE，但是在错误状态下，相关联的 QP 不能从这个 SRQ 中获得收到的数据。另外在错误状态下，用户也无法查询和修改 SRQ 的属性。&lt;/p>
&lt;p>QP 处于错误状态时，可以通过 Modify QP 来使其回到 RESET 状态，但是对 SRQ 来说，只能通过销毁它来退出错误状态。&lt;/p>
&lt;h3 id="接收流程">
&lt;a href="#%e6%8e%a5%e6%94%b6%e6%b5%81%e7%a8%8b" class="header-anchor">#&lt;/a>
接收流程
&lt;/h3>
&lt;p>对于一个 QP 来说，RQ 和 SRQ 不能同时使用，两者需选其一，如果对一个已经关联 SRQ 的 QP 的 RQ 下发 WQE，那么会返回一个立即错误。&lt;/p>
&lt;p>下面我们来对比看一下 SRQ 和 RQ 的接收流程。本小结的内容是本文的重点，相信读者看过之后，就对 SRQ 的机制有比较完整的了解了。&lt;/p>
&lt;h3 id="rq-的接收流程">
&lt;a href="#rq-%e7%9a%84%e6%8e%a5%e6%94%b6%e6%b5%81%e7%a8%8b" class="header-anchor">#&lt;/a>
RQ 的接收流程
&lt;/h3>
&lt;p>首先，我们重温一下普通 RQ 的接收流程（结合发送端的完整流程请阅读 &lt;a class="link" href="https://cuterwrite.top/p/rdma-op/" >【4. RDMA 操作类型】
&lt;/a>
）一文）：&lt;/p>
&lt;ol start="0">
&lt;li>
&lt;p>创建 QP。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>通过 Post Recv 接口，用户分别向 QP2 和 QP3 的 RQ 下发接收 WQE，WQE 中包含接收到数据后放到哪块内存区域的信息。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>硬件收到数据。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>硬件发现是发给 QP3 的，那么从 QP3 的 RQ 中取出 WQE1，将接收到的数据放到 WQE1 指定的内存区域。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>硬件完成数据存放后，向 QP3 的 RQ 关联的 CQ3 产生一个 CQE，上报任务完成信息。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>用户从 CQ3 中取出 WC（CQE），然后从指定内存区域取走数据。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>硬件收到数据。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>硬件发现是发送给 QP2 的，那么从 QP2 的 RQ 中取出 WQE1，将接收到的数据放到 WQE1 指定的内存区域。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>硬件完成数据存放后，向 QP2 的 RQ 关联的 CQ2 产生一个 CQE，上报任务完成信息。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>用户从 CQ2 中取出 WC（CQE），然后从指定内存区域取走数据。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-28_11_4.webp"
alt="2024-06-28_11_4" width="90%" loading="lazy">
&lt;/figure>
&lt;h3 id="srq-的接收流程">
&lt;a href="#srq-%e7%9a%84%e6%8e%a5%e6%94%b6%e6%b5%81%e7%a8%8b" class="header-anchor">#&lt;/a>
SRQ 的接收流程
&lt;/h3>
&lt;p>而 SRQ 的接收流程有一些区别：&lt;/p>
&lt;ol start="0">
&lt;li>
&lt;p>创建 SRQ1，并创建 QP2 和 QP3，都关联到 SRQ1 上。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>通过 Post SRQ Recv 接口，用户向 SRQ1 中下发两个接收 WQE，WQE 中包含接收到数据后放到哪块内存区域的信息。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>硬件收到数据。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>硬件发现是发给 QP3 的，从 SRQ1 中取出第一个 WQE（现在是 WQE1），根据 WQE 内容存放收到的数据。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>SRQ 中的每个 WQE 是“无主的“，不关联到任何一个 QP，硬件按队列顺序依次取出 WQE 就把数据放到里面了。&lt;/p>
&lt;/blockquote>
&lt;ol start="4">
&lt;li>
&lt;p>硬件发现 QP3 的 RQ 关联的 CQ 是 CQ3，所以向其中产生一个 CQE。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>用户从 CQ3 中取出 CQE，从指定内存区域取走数据。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>细心地读者可能会问，用户下发 WR 时，每个 WR 都指定了一些未来用来存放数据的内存区域。但是 SRQ 是一个池子，里面每个 WQE 都指向了不同的若干段内存区域。用户收到某个 QP 对应的 CQ 中的 WC 后如何知道接收到的数据存放到哪里了呢？&lt;/p>
&lt;p>WC 中其实有 wr_id 信息，告知用户数据放到哪个 WR（WQE）指定的内存区域了，既然 WR 是用户下发的，用户自然知道其指向的具体位置。&lt;/p>
&lt;/blockquote>
&lt;ol start="6">
&lt;li>
&lt;p>硬件收到数据&lt;/p>
&lt;/li>
&lt;li>
&lt;p>硬件发现是发给 QP2 的，从 SRQ1 中取出第一个 WQE（现在是 WQE2），根据 WQE 内容存放收到的数据。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>硬件发现 QP2 的 RQ 关联的 CQ 是 CQ2，所以向其中产生一个 CQE。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>用户从 CQ2 中取出 CQE，从指定内存区域取走数据。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-28_11_5.webp"
alt="2024-06-28_11_5" width="90%" loading="lazy">
&lt;/figure>
&lt;h2 id="总结">
&lt;a href="#%e6%80%bb%e7%bb%93" class="header-anchor">#&lt;/a>
总结
&lt;/h2>
&lt;p>本文首先介绍了 SRQ 的基本概念，然后是其设计初衷、相关机制和用户接口，最后对比 RQ 描述了 SRQ 的接收流程。在实际业务中，SRQ 的使用率还是蛮高的，希望读者能够深入理解。&lt;/p>
&lt;p>就写到这里吧，感谢阅读。下一篇我将给大家介绍下 Memeory Window。&lt;/p>
&lt;h2 id="协议相关章节">
&lt;a href="#%e5%8d%8f%e8%ae%ae%e7%9b%b8%e5%85%b3%e7%ab%a0%e8%8a%82" class="header-anchor">#&lt;/a>
协议相关章节
&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>10.2.9 SRQ 的设计思想以及相关操作&lt;/p>
&lt;/li>
&lt;li>
&lt;p>10.2.3 SRQ 和 QP 的 PD&lt;/p>
&lt;/li>
&lt;li>
&lt;p>10.8.2 关联 SRQ 的 QP 和不使用 SRQ 的 QP 的关系&lt;/p>
&lt;/li>
&lt;li>
&lt;p>10.8.5 SRQ 相关的返回 WC&lt;/p>
&lt;/li>
&lt;li>
&lt;p>11.5.2.4 异步事件&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="其他参考资料">
&lt;a href="#%e5%85%b6%e4%bb%96%e5%8f%82%e8%80%83%e8%b5%84%e6%96%99" class="header-anchor">#&lt;/a>
其他参考资料
&lt;/h2>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>Linux Kernel Networking - Implement and Theory. Chapter 13. Shared Receive Queue&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>RDMA 之 Completion Queue</title><link>https://cuterwrite.top/p/rdma-completion-queue/</link><pubDate>Wed, 26 Jun 2024 23:11:00 +0000</pubDate><guid>https://cuterwrite.top/p/rdma-completion-queue/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-16_116903369_p0_master1200.webp" alt="Featured image of post RDMA 之 Completion Queue" />&lt;h1 id="rdma-之-completion-queue">
&lt;a href="#rdma-%e4%b9%8b-completion-queue" class="header-anchor">#&lt;/a>
RDMA 之 Completion Queue
&lt;/h1>
&lt;p>&lt;strong>本文欢迎非商业转载，转载请注明出处。&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>声明：仅用于收藏，便于阅读&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/259650980">&lt;cite>知乎专栏：10. RDMA 之 Completion Queue&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>我们曾经在前面的文章中简单介绍过 CQ，本文将更深入的讲解关于它的一些细节。阅读本文前，读者可以先温习一下这篇文章： &lt;a class="link" href="https://cuterwrite.top/p/rdma-element/" >【“3. RDMA 基本元素”】
&lt;/a>
。&lt;/p>
&lt;h2 id="基本概念">
&lt;a href="#%e5%9f%ba%e6%9c%ac%e6%a6%82%e5%bf%b5" class="header-anchor">#&lt;/a>
基本概念
&lt;/h2>
&lt;p>我们先回顾下 CQ 的作用。CQ 意为完成队列，它的作用和 WQ（SQ 和 RQ）相反，硬件通过 CQ 中的 CQE/WC 来告诉软件某个 WQE/WR 的完成情况。再次提醒读者，对于上层用户来说一般用 WC，对于驱动程序来说，一般称为 CQE，本文不对两者进行区分。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-27_10_1.webp"
alt="2024-06-27_10_1" width="80%" loading="lazy">
&lt;/figure>
&lt;p>CQE 可以看作一份“报告”，其中写明了某个任务的执行情况，其中包括：&lt;/p>
&lt;ul>
&lt;li>本次完成了哪个 QP 的哪一个 WQE 指定的任务（QP Number 和 WR ID）&lt;/li>
&lt;li>本次任务执行了什么操作（Opcode 操作类型）&lt;/li>
&lt;li>本次任务执行成功/失败，失败原因是 XXX（Status 状态和错误码）&lt;/li>
&lt;li>&amp;hellip;&lt;/li>
&lt;/ul>
&lt;p>每当硬件处理完一个 WQE 之后，都会产生一个 CQE 放在 CQ 队列中。如果一个 WQE 对应的 CQE 没有产生，那么这个 WQE 就会一直被认为还未处理完，这意味着什么呢？&lt;/p>
&lt;ul>
&lt;li>涉及从内存中取数据的操作（SEND 和 WRITE）&lt;/li>
&lt;/ul>
&lt;p>在产生 CQE 之前，硬件可能还未发送消息，可能正在发送消息，可能对端有接收到正确的消息。由于内存区域是在发送前申请好的，所以上层软件收到对应的 CQE 之前，其必须认为这片内存区域仍在使用中，不能将所有相关的内存资源进行释放。&lt;/p>
&lt;ul>
&lt;li>涉及向内存中存放数据的操作（RECV 和 READ）&lt;/li>
&lt;/ul>
&lt;p>在产生 CQE 之前，有可能硬件还没有开始写入数据，有可能数据才写了一半，也有可能数据校验出错。所以上层软件在获得 CQE 之前，这段用于存放接收数据的内存区域中的内容是不可信的。&lt;/p>
&lt;p>总之，用户必须获取到 CQE 并确认其内容之后才能认为消息收发任务已经完成。&lt;/p>
&lt;h3 id="何时产生">
&lt;a href="#%e4%bd%95%e6%97%b6%e4%ba%a7%e7%94%9f" class="header-anchor">#&lt;/a>
何时产生
&lt;/h3>
&lt;p>我们将按照服务类型（本篇只讲 RC 和 UD）和操作类型来分别说明，因为不同的情况产生 CQE 的时机和含义都不同，建议读者回顾第 4 篇&lt;a class="link" href="https://cuterwrite.top/p/rdma-op/" >【“4. RDMA 基本操作”】
&lt;/a>
和第 5 篇&lt;a class="link" href="https://cuterwrite.top/p/rdma-service-types/" >【“5. RDMA 基本服务类型”】
&lt;/a>
。&lt;/p>
&lt;ul>
&lt;li>可靠服务类型（RC）&lt;/li>
&lt;/ul>
&lt;p>前面的文章说过，&lt;strong>可靠意味着本端关心发出的消息能够被对端准确的接收&lt;/strong>，这是通过 ACK、校验和重传等机制保证的。&lt;/p>
&lt;ul>
&lt;li>SEND&lt;/li>
&lt;/ul>
&lt;p>SEND 操作需要硬件从内存中获取数据，然后组装成数据包通过物理链路发送到对端。对 SEND 来说，Client 端产生 CQE 表示&lt;strong>对端已准确无误的收到数据&lt;/strong>，对端硬件收到数据并校验之后，会回复 ACK 包给发送方。发送方收到这 ACK 之后才会产生 CQE，从而告诉用户这个任务成功执行了。如图所示，左侧 Client 端在红点的位置产生了本次任务的 CQE。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-27_10_2.webp"
alt="2024-06-27_10_2" width="50%" loading="lazy">
&lt;/figure>
&lt;ul>
&lt;li>RECV&lt;/li>
&lt;/ul>
&lt;p>RECV 操作需要硬件将收到的数据放到用户 WQE 中指定的内存区域，完成校验和数据存放动作后，硬件就会产生 CQE。如上图右侧 Server 端所示。&lt;/p>
&lt;ul>
&lt;li>WRITE&lt;/li>
&lt;/ul>
&lt;p>对于 Client 端来说，WRITE 操作和 SEND 操作是一样的，硬件会从内存中取出数据，并等待对端回复 ACK 后，才会产生 CQE。差别在于，因为 WRITE 是 RDMA 操作，对端 CPU 不感知，自然用户也不感知，所以上面的图变成了这样：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-27_10_3.webp"
alt="2024-06-27_10_3" width="50%" loading="lazy">
&lt;/figure>
&lt;ul>
&lt;li>READ&lt;/li>
&lt;/ul>
&lt;p>READ 和 RECV 有点像，Client 端发起 READ 操作后，对端会回复我们想读取的数据，然后本端校验没问题后，会把数据放到 WQE 中指定的位置。完成上述动作后，本端会产生 CQE。READ 同样是 RDMA 操作，对端用户不感知，自然也没有 CQE 产生。这种情况上图变成了这样：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-27_10_4.webp"
alt="2024-06-27_10_4" width="50%" loading="lazy">
&lt;/figure>
&lt;ul>
&lt;li>不可靠服务类型（UD）&lt;/li>
&lt;/ul>
&lt;p>因为不可靠的服务类型没有重传和确认机制，所以产生 CQE 表示硬件&lt;strong>已经将对应 WQE 指定的数据发送出去了&lt;/strong>。以前说过 UD 只支持 SEND-RECV 操作，不支持 RDMA 操作。所以对于 UD 服务的两端，CQE 产生时机如下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-27_10_5.webp"
alt="2024-06-27_10_5" width="50%" loading="lazy">
&lt;/figure>
&lt;h3 id="wq-和-cq-的对应关系">
&lt;a href="#wq-%e5%92%8c-cq-%e7%9a%84%e5%af%b9%e5%ba%94%e5%85%b3%e7%b3%bb" class="header-anchor">#&lt;/a>
WQ 和 CQ 的对应关系
&lt;/h3>
&lt;p>&lt;strong>每个 WQ 都必须关联一个 CQ，而每个 CQ 可以关联多个 SQ 和 RQ。&lt;/strong>&lt;/p>
&lt;p>这里的所谓“关联”，指的是一个 WQ 的所有 WQE 对应的 CQE，都会被硬件放到绑定的 CQ 中，需要注意同属于一个 QP 的 SQ 和 RQ 可以各自关联不同的 CQ。如下图所示，QP1 的 SQ 和 RQ 都关联了 CQ1，QP2 的 RQ 关联到了 CQ1、SQ 关联到了 CQ2。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-27_10_6.webp"
alt="2024-06-27_10_6" width="auto" loading="lazy">
&lt;/figure>
&lt;p>因为每个 WQ 必须关联一个 CQ，所以用户创建 QP 前需要提前创建好 CQ，然后分别指定 SQ 和 RQ 将会使用的 CQ。&lt;/p>
&lt;p>&lt;strong>同一个 WQ 中的 WQE，其对应的 CQE 间是保序的&lt;/strong>&lt;/p>
&lt;p>硬件是按照“先进先出”的 FIFO 顺序从某一个 WQ（SQ 或者 RQ）中取出 WQE 并进行处理的，而向 WR 关联的 CQ 中存放 CQE 时，也是遵从这些 WQE 被放到 WQ 中的顺序的。简单来说，就是谁先被放到队列里，谁就先被完成。该过程如下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-27_10_7.webp"
alt="2024-06-27_10_7" width="auto" loading="lazy">
&lt;/figure>
&lt;p>需要注意的是，使用 SRQ 的情况以及 RD 服务类型的 RQ 这两种情况是不保序的，本文中不展开讨论。&lt;/p>
&lt;p>&lt;strong>不同 WQ 中的 WQE，其对应的 CQE 间是不保序的&lt;/strong>&lt;/p>
&lt;p>前文中我们说过，一个 CQ 可能会被多个 WQ 共享。这种情况下，是不能保证这些 WQE 对应的 CQE 的产生顺序的。如下图所示（WQE 编号表示下发的次序，即 1 最先被下发，6 最后被下发）：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-27_10_8.webp"
alt="2024-06-27_10_8" width="auto" loading="lazy">
&lt;/figure>
&lt;p>上面的描述其实还包含了“同一个 QP 的 SQ 和 RQ 中的 WQE，其对应的 CQE 间是不保序的”的情况，这一点其实比较容易理解，SQ 和 RQ，一个负责主动发起的任务，一个负责被动接收的任务，它们本来就可以是认为是两条不同方向的通道，自然不应该相互影响。假设用户对同一个 QP 先下发了一个 Receive WQE，又下发一个 Send WQE，总不能对端不给本端发送消息，本端就不能发送消息给对端了吧？&lt;/p>
&lt;p>既然这种情况下 CQE 产生的顺序和获取 WQE 的顺序是不相关的，那么上层应用和驱动是如何知道收到的 CQE 关联的是哪个 WQE 呢？其实很简单，&lt;strong>CQE 中指明它所对应的 WQE 的编号&lt;/strong>就可以了。&lt;/p>
&lt;p>另外需要注意的是，即使在多个 WQ 共用一个 CQ 的情况下，“同一个 WQ 中的 WQE，其对应的 CQE 间是保序的”这一点也是一定能够保证的，即上图中的属于 WQ1 的 WQE 1、3、4 对应的 CQE 一定是按照顺序产生的，对于属于 WQ2 的 WQE 2、5、6 也是如此。&lt;/p>
&lt;h3 id="cqc">
&lt;a href="#cqc" class="header-anchor">#&lt;/a>
CQC
&lt;/h3>
&lt;p>同 QP 一样，CQ 只是一段存放 CQE 的队列内存空间。硬件除了知道首地址以外，对于这片区域可以说是一无所知。所以需要提前跟软件约定好格式，然后驱动将申请内存，并按照格式把 CQ 的基本信息填写到这片内存中供硬件读取，这片内存就是 CQC。CQC 中包含了 CQ 的容量大小，当前处理的 CQE 的序号等等信息。所以把 QPC 的图稍微修改一下，就能表示出 CQC 和 CQ 的关系：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-27_10_9.webp"
alt="2024-06-27_10_9" width="auto" loading="lazy">
&lt;/figure>
&lt;h3 id="cqn">
&lt;a href="#cqn" class="header-anchor">#&lt;/a>
CQN
&lt;/h3>
&lt;p>CQ Number，就是 CQ 的编号，用来区别不同的 CQ。CQ 没有像 QP0 和 QP1 一样的特殊保留编号，本文中不再赘述了。&lt;/p>
&lt;h2 id="完成错误">
&lt;a href="#%e5%ae%8c%e6%88%90%e9%94%99%e8%af%af" class="header-anchor">#&lt;/a>
完成错误
&lt;/h2>
&lt;p>IB 协议中有三种错误类型，立即错误（immediate error）、完成错误（Completion Error）以及异步错误（Asynchronous Errors)。&lt;/p>
&lt;p>立即错误的是“立即停止当前操作，并返回错误给上层用户”；完成错误指的是“通过 CQE 将错误信息返回给上层用户”；而异步错误指的是“通过中断事件的方式上报给上层用户”。可能还是有点抽象，我们来举个例子说明这两种错误都会在什么情况下产生：&lt;/p>
&lt;ul>
&lt;li>用户在 Post Send 时传入了非法的操作码，比如想在 UD 的时候使用 RDMA WRITE 操作。&lt;/li>
&lt;/ul>
&lt;p>结果：产生立即错误（有的厂商在这种情况会产生完成错误）&lt;/p>
&lt;p>一般这种情况下，驱动程序会直接退出 post send 流程，并返回错误码给上层用户。注意此时 WQE 还没有下发到硬件就返回了。&lt;/p>
&lt;ul>
&lt;li>用户下发了一个 WQE，操作类型为 SEND，但是长时间没有受到对方的 ACK。&lt;/li>
&lt;/ul>
&lt;p>结果：产生完成错误&lt;/p>
&lt;p>因为 WQE 已经到达了硬件，所以硬件会产生对应的 CQE，CQE 中包含超时未响应的错误详情。&lt;/p>
&lt;ul>
&lt;li>用户态下发了多个 WQE，所以硬件会产生多个 CQE，但是软件一直没有从 CQ 中取走 CQE，导致 CQ 溢出。
结果：产生异步错误&lt;/li>
&lt;/ul>
&lt;p>因为软件一直没取 CQE，所以自然不会从 CQE 中得到信息。此时 IB 框架会调用软件注册的事件处理函数，来通知用户处理当前的错误。&lt;/p>
&lt;p>由此可见，它们都是底层向上层用户报告错误的方式，只是产生的时机不一样而已。IB 协议中对不同情况的错误应该以哪种方式上报做了规定，比如下图中，对于 Modify QP 过程中修改非法的参数，应该返回立即错误。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-27_10_10.webp"
alt="2024-06-27_10_10" width="auto" loading="lazy">
&lt;/figure>
&lt;p>本文的重点在于 CQ，所以介绍完错误类型之后，我们着重来看一下完成错误。完成错误是硬件通过在 CQE 中填写错误码来实现上报的，一次通信过程需要发起端（Requester）和响应端（Responder）参与，具体的错误原因也分为本端和对端。我们先来看一下错误检测是在什么阶段进行的（下图对 IB 协议中 Figure 118 进行了重画）：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-27_10_11.webp"
alt="2024-06-27_10_11" width="auto" loading="lazy">
&lt;/figure>
&lt;p>Requester 的错误检测点有两个：&lt;/p>
&lt;ol>
&lt;li>本地错误检测&lt;/li>
&lt;/ol>
&lt;p>即对 SQ 中的 WQE 进行检查，如果检测到错误，就从本地错误检查模块直接产生 CQE 到 CQ，不会发送数据到响应端了；如果没有错误，则发送数据到对端。&lt;/p>
&lt;ol start="2">
&lt;li>远端错误检测&lt;/li>
&lt;/ol>
&lt;p>即检测响应端的 ACK 是否异常，ACK/NAK 是由对端的本地错误检测模块检测后产生的，里面包含了响应端是否有错误，以及具体的错误类型。无论远端错误检测的结果是否有问题，都会产生 CQE 到 CQ 中。&lt;/p>
&lt;p>Responder 的错误检测点只有一个：&lt;/p>
&lt;ol>
&lt;li>本地错误检测&lt;/li>
&lt;/ol>
&lt;p>实际上检测的是对端报文是否有问题，IB 协议也将其称为“本地”错误检测。如果检测到错误，则会体现在 ACK/NAK 报文中回复给对端，以及在本地产生一个 CQE。&lt;/p>
&lt;p>需要注意的是，上述的产生 ACK 和远端错误检测只对面向连接的服务类型有效，无连接的服务类型。比如 UD 类型并不关心对端是否收到，接收端也不会产生 ACK，所以在 Requester 的本地错误检测之后就一定会产生 CQE，无论是否有远端错误。&lt;/p>
&lt;p>然后我们简单介绍下几种常见的完成错误：&lt;/p>
&lt;ul>
&lt;li>RC 服务类型的 SQ 完成错误&lt;/li>
&lt;li>Local Protection Error
&lt;ul>
&lt;li>本地保护域错误。本地 WQE 中指定的数据内存地址的 MR 不合法，即用户试图使用一片未注册的内存中的数据。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Remote Access Error
&lt;ul>
&lt;li>远端权限错误。本端没有权限读/写指定的对端内存地址。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Transport Retry Counter Exceeded Error
&lt;ul>
&lt;li>重传超次错误。对端一直未回复正确的 ACK，导致本端多次重传，超过了预设的次数。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>RC 服务类型的 RQ 完成错误&lt;/li>
&lt;li>Local Access Error
&lt;ul>
&lt;li>本地访问错误。说明对端试图写入其没有权限写入的内存区域。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Local Length Error
&lt;ul>
&lt;li>本地长度错误。本地 RQ 没有足够的空间来接收对端发送的数据。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>完整的完成错误类型列表请参考 IB 协议的 10.10.3 节。&lt;/p>
&lt;h2 id="用户接口">
&lt;a href="#%e7%94%a8%e6%88%b7%e6%8e%a5%e5%8f%a3" class="header-anchor">#&lt;/a>
用户接口
&lt;/h2>
&lt;p>同 QP 一样，我们依然从通信准备阶段（控制面）和通信进行阶段（数据面）来介绍 IB 协议对上层提供的关于 CQ 的接口。&lt;/p>
&lt;h3 id="控制面">
&lt;a href="#%e6%8e%a7%e5%88%b6%e9%9d%a2" class="header-anchor">#&lt;/a>
控制面
&lt;/h3>
&lt;p>同 QP 一样，还是“增删改查”四种，但是可能因为对于 CQ 来说，上层用户是资源使用者而不是管理者，只能从 CQ 中读数据而不能写数据，所以对用户开放的可配的参数就只有“CQ 规格”一种。&lt;/p>
&lt;ul>
&lt;li>创建——Create CQ&lt;/li>
&lt;/ul>
&lt;p>创建的时候用户必须指定 CQ 的规格，即能够储存多少个 CQE，另外用户还可以填写一个 CQE 产生后的回调函数指针（下文会涉及）。内核态驱动会将其他相关的参数配置好，填写到跟硬件约定好的 CQC 中告知硬件。&lt;/p>
&lt;ul>
&lt;li>销毁——Destroy CQ&lt;/li>
&lt;/ul>
&lt;p>释放一个 CQ 软硬件资源，包含 CQ 本身及 CQC，另外 CQN 自然也将失效。&lt;/p>
&lt;ul>
&lt;li>修改——Resize CQ&lt;/li>
&lt;/ul>
&lt;p>这里名字稍微有点区别，因为 CQ 只允许用户修改规格大小，所以就用的 Resize 而不是 Modify。&lt;/p>
&lt;ul>
&lt;li>查询——Query CQ&lt;/li>
&lt;/ul>
&lt;p>查询 CQ 的当前规格，以及用于通知的回调函数指针。&lt;/p>
&lt;blockquote>
&lt;p>通过对比 RDMA 规范和软件协议栈，可以发现很多 verbs 接口并不是按照规范实现的。所以读者如果发现软件 API 和协议有差异时也无须感到疑惑，RDMA 技术本身一直还在演进，软件框架也处于活跃更新的状态。如果更关心编程实现，那么请以软件协议栈的 API 文档为准；如果更关心学术上的研究，那么请以 RDMA 规范为准。&lt;/p>
&lt;/blockquote>
&lt;h3 id="数据面">
&lt;a href="#%e6%95%b0%e6%8d%ae%e9%9d%a2" class="header-anchor">#&lt;/a>
数据面
&lt;/h3>
&lt;p>CQE 是硬件将信息传递给软件的媒介，虽然软件知道在什么情况下会产生 CQE，但是软件并不知道具体什么时候硬件会把 CQE 放到 CQ 中。在通信和计算机领域，我们把这种接收方不知道发送方什么时候发送的模式称为“异步”。我们先来举一个网卡的例子，再来说明用户如何通过数据面接口获取 CQE（WC）。&lt;/p>
&lt;p>网卡收到数据包后如何让 CPU 知道这件事，并进行数据包处理，有两种常见的模式：&lt;/p>
&lt;ul>
&lt;li>中断模式&lt;/li>
&lt;/ul>
&lt;p>当数据量较少，或者说偶发的数据交换较多时，适合采用中断模式——即 CPU 平常在做其他事情，当网卡收到数据包时，会上报中断打断 CPU 当前的任务，CPU 转而来处理数据包（比如 TCP/IP 协议栈的各层解析）。处理完数据之后，CPU 跳回到中断前的任务继续执行。&lt;/p>
&lt;p>每次中断都需要保护现场，也就是把当前各个寄存器的值、局部变量的值等等保存到栈中，回来之后再恢复现场（出栈），这本身是有开销的。如果业务负载较重，网卡一直都在接收数据包，那么 CPU 就会一直收到中断，CPU 将一直忙于中断切换，导致其他任务得不到调度。&lt;/p>
&lt;ul>
&lt;li>轮询模式&lt;/li>
&lt;/ul>
&lt;p>所以除了中断模式之外，网卡还有一种轮询模式，即收到数据包后都先放到缓冲区里，CPU 每隔一段时间会去检查网卡是否受到数据。如果有数据，就把缓冲区里的数据一波带走进行处理，没有的话就接着处理别的任务。&lt;/p>
&lt;p>通过对比中断模式我们可以发现，轮询模式虽然每隔一段时间需要 CPU 检查一次，带来了一定的开销，但是当业务繁忙的时候采用轮询模式能够极大的减少中断上下文的切换次数，反而减轻了 CPU 的负担。&lt;/p>
&lt;p>现在的网卡，一般都是中断+轮询的方式，也就是根据业务负载动态切换。&lt;/p>
&lt;p>在 RDMA 协议中，CQE 就相当于是网卡收到的数据包，RDMA 硬件把它传递给 CPU 去处理。RDMA 框架定义了两种对上层的接口，分别是 poll 和 notify，对应着轮询和中断模式。&lt;/p>
&lt;h3 id="poll-completion-queue">
&lt;a href="#poll-completion-queue" class="header-anchor">#&lt;/a>
Poll completion queue
&lt;/h3>
&lt;p>很直白，poll 就是轮询的意思。用户调用这个接口之后，CPU 就会定期去检查 CQ 里面是否有新鲜的 CQE，如果有的话，就取出这个 CQE（注意取出之后 CQE 就被“消耗”掉了），解析其中的信息并返回给上层用户。&lt;/p>
&lt;h3 id="request-completion-notification">
&lt;a href="#request-completion-notification" class="header-anchor">#&lt;/a>
Request completion notification
&lt;/h3>
&lt;p>直译过来是请求完成通知，用户调用这个接口之后，相当于向系统注册了一个中断。这样当硬件将 CQE 放到 CQ 中后，会立即触发一个中断给 CPU，CPU 进而就会停止手上的工作取出 CQE，处理后返回给用户。&lt;/p>
&lt;p>同样的，这两种接口使用哪种，取决于用户对于实时性的要求，以及实际业务的繁忙程度。&lt;/p>
&lt;p>感谢阅读，CQ 就介绍到这里，下篇打算详细讲讲 SRQ。&lt;/p>
&lt;h2 id="协议相关章节">
&lt;a href="#%e5%8d%8f%e8%ae%ae%e7%9b%b8%e5%85%b3%e7%ab%a0%e8%8a%82" class="header-anchor">#&lt;/a>
协议相关章节
&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>9.9 CQ 错误检测和恢复&lt;/p>
&lt;/li>
&lt;li>
&lt;p>10.2.6 CQ 和 WQ 的关系&lt;/p>
&lt;/li>
&lt;li>
&lt;p>10.10 错误类型及其处理&lt;/p>
&lt;/li>
&lt;li>
&lt;p>11.2.8 CQ 相关控制面接口&lt;/p>
&lt;/li>
&lt;li>
&lt;p>11.4.2 CQ 相关数据面接口&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="其他参考资料">
&lt;a href="#%e5%85%b6%e4%bb%96%e5%8f%82%e8%80%83%e8%b5%84%e6%96%99" class="header-anchor">#&lt;/a>
其他参考资料
&lt;/h2>
&lt;p>[1] Linux Kernel Networking - Implement and Theory. Chapter 13. Completion Queue&lt;/p></description></item><item><title>RDMA 之 Queue Pair</title><link>https://cuterwrite.top/p/rdma-queue-pair/</link><pubDate>Tue, 25 Jun 2024 02:21:00 +0000</pubDate><guid>https://cuterwrite.top/p/rdma-queue-pair/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-16_116342820_p0_master1200.webp" alt="Featured image of post RDMA 之 Queue Pair" />&lt;h1 id="rdma-之-queue-pair">
&lt;a href="#rdma-%e4%b9%8b-queue-pair" class="header-anchor">#&lt;/a>
RDMA 之 Queue Pair
&lt;/h1>
&lt;p>&lt;strong>本文欢迎非商业转载，转载请注明出处。&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>声明：仅用于收藏，便于阅读&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/195757767">&lt;cite>知乎专栏：9. RDMA 基本服务类型&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;h2 id="queue-pair">
&lt;a href="#queue-pair" class="header-anchor">#&lt;/a>
Queue Pair
&lt;/h2>
&lt;p>我们曾经在 &lt;a class="link" href="https://cuterwrite.top/p/rdma-element/" >【“3. RDMA 基本元素”】
&lt;/a>
一文中简单的介绍了 QP 的概念，本文将更深入的讲解一些关于 QP 的细节。&lt;/p>
&lt;h2 id="基本概念回顾">
&lt;a href="#%e5%9f%ba%e6%9c%ac%e6%a6%82%e5%bf%b5%e5%9b%9e%e9%a1%be" class="header-anchor">#&lt;/a>
基本概念回顾
&lt;/h2>
&lt;p>首先我们来简单回顾下关于 QP 的基础知识：&lt;/p>
&lt;p>根据 IB 协议中的描述，QP 是硬件和软件之间的一个虚拟接口。QP 是队列结构，按顺序存储着软件给硬件下发的任务（WQE），WQE 中包含从哪里取出多长的数据，并且发送给哪个目的地等等信息。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-26_9_1.webp"
alt="2024-06-26_9_1" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>QP 的概念&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>每个 QP 间都是独立的，彼此通过 PD 隔离，因此一个 QP 可以被视为某个用户独占的一种资源，一个用户也可以同时使用多个 QP。&lt;/p>
&lt;p>QP 有很多种服务类型，包括 RC、UD、RD 和 UC 等，所有的源 QP 和目的 QP 必须为同一种类型才能进行数据交互。&lt;/p>
&lt;p>虽然 IB 协议将 QP 称为“虚拟接口”，但是它是有实体的：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>硬件上，QP 是一段包含着若干个 WQE 的存储空间，IB 网卡会从这段空间中读取 WQE 的内容，并按照用户的期望去内存中存取数据。至于这个存储空间是内存空间还是 IB 网卡的片内存储空间，IB 协议并未做出限制，每个厂商有各自的实现&lt;/p>
&lt;/li>
&lt;li>
&lt;p>软件上，QP 是一个由 IB 网卡的驱动程序所维护的数据结构，其中包含 QP 的地址指针以及一些相关的软件属性。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="qpc">
&lt;a href="#qpc" class="header-anchor">#&lt;/a>
QPC
&lt;/h3>
&lt;p>&lt;a class="link" href="https://cuterwrite.top/p/rdma-service-types/" >【“5. RDMA 基本服务类型”】
&lt;/a>
一文中，我们曾经提到过 QPC 全称是 Queue Pair Context，用于存储 QP 相关属性。驱动程序里面是有储存 QP 的软件属性的，既然我们可以在软件里储存 QP 的属性，为什么还要用使用 QPC 呢？&lt;/p>
&lt;p>这是因为&lt;strong>QPC 主要是给硬件看的，也会用来在软硬件之间同步 QP 的信息。&lt;/strong>&lt;/p>
&lt;p>我们说过 QP 在硬件上的实体只是一段存储空间而已，硬件除了知道这段空间的起始地址和大小之外一无所知，甚至连这个 QP 服务类型都不知道。还有很多其他的重要信息，比如某个 QP 中包含了若干个 WQE，硬件怎么知道有多少个，当前应该处理第几个呢？&lt;/p>
&lt;p>所有上述的这些信息，软件是可以设计一定的数据结构并为其申请内存空间的，但是软件看到的都是虚拟地址，这些内存空间在物理上是离散的，硬件并不知道这些数据存放到了哪里。所以就需要软件通过操作系统提前申请好一大片连续的空间，即 QPC 来承载这些信息给硬件看。网卡及其配套的驱动程序提前约定好了 QPC 中都有哪些内容，这些内容分别占据多少空间，按照什么顺序存放。这样驱动和硬件就可以通过通过 QPC 这段空间来读写 QP 的状态等等信息。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-26_9_2_QPC.webp"
alt="2024-06-26_9_2" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>QPC 的概念&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>如上图所示，硬件其实只需要知道 QPC 的地址 0x12350000 就可以了，因为它可以解析 QPC 的内容，从而得知 QP 的位置，QP 序号，QP 大小等等信息。进而就能找到 QP，知道应该取第几个 WQE 去处理。不同的厂商可能实现有些差异，但是大致的原理就是这样。&lt;/p>
&lt;p>IB 软件栈中还有很多 Context 的概念，除了 QPC 之外，还有 Device Context，SRQC，CQC，EQC（Event Queue Context，事件队列上下文）等，它们的作用与 QPC 类似，都是用来在记录和同步某种资源的相关属性。&lt;/p>
&lt;h3 id="qp-number">
&lt;a href="#qp-number" class="header-anchor">#&lt;/a>
QP Number
&lt;/h3>
&lt;p>简称为 QPN，就是每个 QP 的编号。IB 协议中规定用 $2^{24}$ 个 bit 来表示 QPN，即每个节点最大可以同时使用 $2^{24}$ 个 QP，这已经是一个很大的数量了，几乎不可能用完。每个节点都各自维护着 QPN 的集合，相互之间是独立的，即不同的节点上可以存在编号相同的 QP。&lt;/p>
&lt;p>QPN 的概念本身非常简单，但是有两个特殊的保留编号需要额外注意一下：&lt;/p>
&lt;h4 id="qp0">
&lt;a href="#qp0" class="header-anchor">#&lt;/a>
QP0
&lt;/h4>
&lt;p>编号为 0 的 QP 用于子网管理接口 SMI（Subnet Management Interface），用于管理子网中的全部节点，说实话我也还没搞清楚这个接口的作用，暂且按下不表。&lt;/p>
&lt;h4 id="qp1">
&lt;a href="#qp1" class="header-anchor">#&lt;/a>
QP1
&lt;/h4>
&lt;p>编号为 1 的 QP 用于通用服务接口 GSI（General Service Interface），GSI 是一组管理服务，其中最出名的就是 CM（Communication Management），是一种在通信双方节点正式建立连接之前用来交换必须信息的一种方式。其细节将在后面的文章中专门展开介绍。&lt;/p>
&lt;p>这也就是我们之前的文章画的关于 QP 的图中，没有出现过 QP0 和 QP1 的原因了。这两个 QP 之外的其他 QP 就都是普通 QP 了。用户在创建 QP 的时候，驱动或者硬件会给这个新 QP 分配一个 QPN，一般的 QPN 都是 2、3、4 这样按顺序分配的。当 QP 被销毁之后，它的 QPN 也会被重新回收，并在合适的时候分配给其他新创建的 QP。&lt;/p>
&lt;h2 id="用户接口">
&lt;a href="#%e7%94%a8%e6%88%b7%e6%8e%a5%e5%8f%a3" class="header-anchor">#&lt;/a>
用户接口
&lt;/h2>
&lt;p>我们从控制层面和数据层面来分类介绍用户接口，控制面即用户对某种资源进行某种设置，一般都是在正式收发数据之前进行；而数据面自然就是真正的数据收发过程中进行的操作。&lt;/p>
&lt;h3 id="控制面">
&lt;a href="#%e6%8e%a7%e5%88%b6%e9%9d%a2" class="header-anchor">#&lt;/a>
控制面
&lt;/h3>
&lt;p>接触过算法的读者应该都了解，链表的节点涉及到“增、删、改、查”四个操作，链表的节点是一片内存区域，是一种软件资源。&lt;/p>
&lt;p>“增”即向操作系统申请一片内存用来存放数据，系统将在内存中划分一块空间，并将其标记为“已被进程 XX 使用”，其他没有权限的进程将无法覆盖甚至读取这片内存空间。&lt;/p>
&lt;p>“删”即通知操作系统，这片空间我不使用了，可以标记成“未使用”并给其它进程使用了。&lt;/p>
&lt;p>“改”就是写，即修改这片内存区域的内容。&lt;/p>
&lt;p>&amp;ldquo;查&amp;quot;就是读，即获取这片内存区域的内容。&lt;/p>
&lt;p>QP 作为 RDMA 技术中最重要的一种资源，在生命周期上与链表并无二致：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: left">操作&lt;/th>
&lt;th style="text-align: left">链表节点&lt;/th>
&lt;th style="text-align: left">QP&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: left">增&lt;/td>
&lt;td style="text-align: left">struct ListNode *node = malloc(sizeof(struct ListNode *));&lt;/td>
&lt;td style="text-align: left">Create QP&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">删&lt;/td>
&lt;td style="text-align: left">free(node);&lt;/td>
&lt;td style="text-align: left">Destroy QP&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">改&lt;/td>
&lt;td style="text-align: left">node-&amp;gt;val = xxx;&lt;/td>
&lt;td style="text-align: left">Modify QP&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">查&lt;/td>
&lt;td style="text-align: left">xxx = node-&amp;gt;val;&lt;/td>
&lt;td style="text-align: left">Query QP&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>这四种操作，其实就是 Verbs（RDMA 对上层应用的 API）在控制面上对上层用户提供给用户的几个接口：&lt;/p>
&lt;h4 id="create-qp">
&lt;a href="#create-qp" class="header-anchor">#&lt;/a>
Create QP
&lt;/h4>
&lt;p>创建一个 QP 的软硬件资源，包含 QP 本身以及 QPC。用户创建时会写传入一系列的初始化属性，包含该 QP 的服务类型，可以储存的 WQE 数量等信息&lt;/p>
&lt;h4 id="destroy-qp">
&lt;a href="#destroy-qp" class="header-anchor">#&lt;/a>
Destroy QP
&lt;/h4>
&lt;p>释放一个 QP 的全部软硬件资源，包含 QP 本身及 QPC。销毁 QP 后，用户将无法通过 QPN 索引到这个 QP。&lt;/p>
&lt;h4 id="modify-qp">
&lt;a href="#modify-qp" class="header-anchor">#&lt;/a>
Modify QP
&lt;/h4>
&lt;p>修改一个 QP 的某些属性，比如 QP 的状态，路径的 MTU 等等。这个修改过程既包括软件数据结构的修改，也包括对 QPC 的修改。&lt;/p>
&lt;h4 id="query-qp">
&lt;a href="#query-qp" class="header-anchor">#&lt;/a>
Query QP
&lt;/h4>
&lt;p>查询一个 QP 当前的状态和一些属性，查询到的数据来源于驱动以及 QPC 的内容。&lt;/p>
&lt;p>这四种操作都有配套的 Verbs 接口，类似于 &lt;code>ibv_create_qp()&lt;/code> 这种形式，我们编写 APP 时直接调用就可以了。更多关于对上层的 API 的细节，我们将在后面专门进行介绍。&lt;/p>
&lt;h2 id="数据面">
&lt;a href="#%e6%95%b0%e6%8d%ae%e9%9d%a2" class="header-anchor">#&lt;/a>
数据面
&lt;/h2>
&lt;p>数据面上，一个 QP 对上层的接口其实只有两种，分别用于向 QP 中填写发送和接收请求。&lt;strong>这里的“发送”和“接收”并不是指的发送和接收数据，而是指的是一次通信过程的“发起方”（Requestor）和“接收方”（Responser）&lt;/strong>。&lt;/p>
&lt;p>在行为上都是软件向 QP 中填写一个 WQE（对应用层来说叫 WR），请求硬件执行一个动作。所以这两种行为都叫做“Post XXX Request”的形式，即下发 XXX 请求。&lt;/p>
&lt;h3 id="post-send-request">
&lt;a href="#post-send-request" class="header-anchor">#&lt;/a>
Post Send Request
&lt;/h3>
&lt;p>再强调一下，Post Send 本身不是指这个 WQE 的操作类型是 Send，而是表示这个 WQE 属于通信发起方。这个流程中填写到 QP 中的 WQE/WR 可以是 Send 操作，RDMA Write 操作以及 RDMA Read 操作等。&lt;/p>
&lt;p>用户需要提前准备好数据缓冲区、目的地址等信息，然后调用接口将 WR 传给驱动，驱动再把 WQE 填写到 QP 中。&lt;/p>
&lt;h3 id="post-receive-request">
&lt;a href="#post-receive-request" class="header-anchor">#&lt;/a>
Post Receive Request
&lt;/h3>
&lt;p>Post Recv 的使用场景就相对比较少了，一般只在 Send-Recv 操作的接收端执行，接收端需要提前准备好接收数据的缓冲区，并将缓冲区地址等信息以 WQE 的形式告知硬件。&lt;/p>
&lt;h2 id="qp-状态机">
&lt;a href="#qp-%e7%8a%b6%e6%80%81%e6%9c%ba" class="header-anchor">#&lt;/a>
QP 状态机
&lt;/h2>
&lt;p>说到 QP 的状态，就不得不祭出下面这张图（取自 IB 协议 10.3.1 节）：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-26_9_3.webp"
alt="2024-06-26_9_3" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>QP 状态机&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>所谓状态机，就是描述一个对象的不同状态，以及触发状态间跳转的条件。为一个对象设计状态机可以使这个对象的生命周期变得非常明确，实现上也会使得逻辑更加清晰。&lt;/p>
&lt;p>对于 QP 来说，IB 规范也为其设计了几种状态，处于不同状态的 QP 的功能是有差异的，比如只有进入到 Ready to Send 状态之后，QP 才能够进行 Post Send 数据操作。正常状态（绿色的）之间的状态转换都是由用户通过上文介绍的 Modify QP 的用户接口来主动触发的；而错误状态（红色的）往往是出错之后自动跳转的，当一个 QP 处于错误状态之后就无法执行正常的业务了，就需要上层通过 Modify QP 将其重新配置到正常状态上。&lt;/p>
&lt;p>上图中我们只关注 QP 的部分，EE（End-to-End Context）是专门给 RD 服务类型使用的一个概念，我们暂不涉及。我们通过 Create QP 接口来进入这个状态图，通过 Destroy QP 接口来离开这个状态图。&lt;/p>
&lt;p>QP 有以下几种状态，我们仅介绍一下比较重要的点：&lt;/p>
&lt;h3 id="rstreset">
&lt;a href="#rstreset" class="header-anchor">#&lt;/a>
RST（Reset）
&lt;/h3>
&lt;p>复位状态。当一个 QP 通过 Create QP 创建好之后就处于这个状态，相关的资源都已经申请好了，但是这个 QP 目前什么都做不了，其无法接收用户下发的 WQE，也无法接受对端某个 QP 的消息。&lt;/p>
&lt;h3 id="initinitialized">
&lt;a href="#initinitialized" class="header-anchor">#&lt;/a>
INIT（Initialized）
&lt;/h3>
&lt;p>已初始化状态。这个状态下，用户可以通过 Post Receive 给这个 QP 下发 Receive WR，但是接收到的消息并不会被处理，会被静默丢弃；如果用户下发了一个 Post Send 的 WR，则会报错。&lt;/p>
&lt;h3 id="rtrready-to-receive">
&lt;a href="#rtrready-to-receive" class="header-anchor">#&lt;/a>
RTR（Ready to Receive）
&lt;/h3>
&lt;p>准备接收状态。在 INIT 状态的基础上，RQ 可以正常工作，即对于接收到的消息，可以按照其中 WQE 的指示搬移数据到指定内存位置。此状态下 SQ 仍然不能工作。&lt;/p>
&lt;h3 id="rtsready-to-send">
&lt;a href="#rtsready-to-send" class="header-anchor">#&lt;/a>
RTS（Ready to Send）
&lt;/h3>
&lt;p>准备发送状态。在 RTR 基础上，SQ 可以正常工作，即用户可以进行 Post Send，并且硬件也会根据 SQ 的内容将数据发送出去。进入该状态前，QP 必须已于对端建立好链接。&lt;/p>
&lt;h3 id="sqdsend-queue-drain">
&lt;a href="#sqdsend-queue-drain" class="header-anchor">#&lt;/a>
SQD（Send Queue Drain）
&lt;/h3>
&lt;p>SQ 排空状态。顾名思义，该状态会将 SQ 队列中现存的未处理的 WQE 全部处理掉，这个时候用户还可以下发新的 WQE 下来，但是这些 WQE 要等到旧的 WQE 全处理之后才会被处理。&lt;/p>
&lt;h3 id="sqersend-queue-error">
&lt;a href="#sqersend-queue-error" class="header-anchor">#&lt;/a>
SQEr（Send Queue Error）
&lt;/h3>
&lt;p>SQ 错误状态。当某个 Send WR 发生完成错误（即硬件通过 CQE 告知驱动发生的错误）时，会导致 QP 进入此状态。&lt;/p>
&lt;h3 id="errerror">
&lt;a href="#errerror" class="header-anchor">#&lt;/a>
ERR（Error）
&lt;/h3>
&lt;p>即错误状态。其他状态如果发生了错误，都可能进入该状态。Error 状态时，QP 会停止处理 WQE，已经处理到一半的 WQE 也会停止。上层需要在修复错误后再将 QP 重新切换到 RST 的初始状态。&lt;/p>
&lt;h2 id="总结">
&lt;a href="#%e6%80%bb%e7%bb%93" class="header-anchor">#&lt;/a>
总结
&lt;/h2>
&lt;p>本文先回顾了 QP 的一些重要基本概念，然后讲解了 QPC、QPN 等 QP 强相关的概念，最后介绍了用户操作 QP 常用的接口以及 QP 状态机，相信本文过后读者一定对 QP 有了更深的了解。&lt;/p>
&lt;p>其实作为 RDMA 的核心概念，QP 的内容很多，本文难以全部囊括。我将在后面的文章中逐渐把相关的内容补全，比如 QKey 的概念将在后续专门介绍各种 Key 的文章中讲解。&lt;/p>
&lt;p>好了，本文就到这了，感谢阅读。预告下一篇文章将详细讲解 CQ。&lt;/p>
&lt;h2 id="协议相关章节">
&lt;a href="#%e5%8d%8f%e8%ae%ae%e7%9b%b8%e5%85%b3%e7%ab%a0%e8%8a%82" class="header-anchor">#&lt;/a>
协议相关章节
&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>3.5.1 10.2.4 QP 的基本概念&lt;/p>
&lt;/li>
&lt;li>
&lt;p>10.3 QP 状态机&lt;/p>
&lt;/li>
&lt;li>
&lt;p>10.2.5 QP 相关的软件接口&lt;/p>
&lt;/li>
&lt;li>
&lt;p>11.4 Post Send Post Recv&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>RDMA 之 Address Handle</title><link>https://cuterwrite.top/p/rdma-address-handle/</link><pubDate>Sat, 15 Jun 2024 01:00:00 +0000</pubDate><guid>https://cuterwrite.top/p/rdma-address-handle/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-16_116373922_p9_master1200.webp" alt="Featured image of post RDMA 之 Address Handle" />&lt;h1 id="rdma-之-address-handle">
&lt;a href="#rdma-%e4%b9%8b-address-handle" class="header-anchor">#&lt;/a>
RDMA 之 Address Handle
&lt;/h1>
&lt;p>&lt;strong>本文欢迎非商业转载，转载请注明出处。&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>声明：仅用于收藏，便于阅读&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/163552044">&lt;cite>知乎专栏：8. RDMA 之 Address Handle&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>前面已经介绍过，RDMA 通信的基本单元是 QP。我们来思考一个问题，假设 A 节点的某个 QP 要跟 B 节点的某个 QP 交换信息，除了要知道 B 节点的 QP 序号——QPN 之外，还需要什么信息？要知道，QPN 是每个节点独立维护的序号，不是整个网络中唯一的。比如 A 的 QP 3 要跟 B 的 QP 5 通信，网络中可不止一个 QP5，可能有很多个节点都有自己的 QP 5。所以我们自然可以想到，还需要找到让每个节点都有一个独立的标识。&lt;/p>
&lt;p>在传统 TCP-IP 协议栈中，使用了家喻户晓的 IP 地址来标识网络层的每个节点。而 IB 协议中的这个标识被称为&lt;strong>GID（Global Identifier，全局 ID）&lt;/strong>，是一个 128 bits 的序列。关于 GID 本篇不展开讨论，将在后面介绍。&lt;/p>
&lt;h2 id="ah-是什么">
&lt;a href="#ah-%e6%98%af%e4%bb%80%e4%b9%88" class="header-anchor">#&lt;/a>
AH 是什么
&lt;/h2>
&lt;p>AH 全称为 Address Handle，没有想到特别合适的中文翻译，就先直译为“地址句柄”吧。这里的地址，指的是一组用于找到某个远端节点的信息的集合，在 IB 协议中，地址指的是 GID、端口号等等信息；而所谓句柄，我们可以理解为一个指向某个对象的指针。&lt;/p>
&lt;p>大家是否还记得 IB 协议中有四种基本服务类型——RC、UD、RD 和 UC，其中最常用的是 RC 和 UD。RC 的特点是两个节点的 QP 之间会建立可靠的连接，一旦建立连接关系便不容易改变，对端的信息是创建 QP 的时候储存在 QP Context 中的；&lt;/p>
&lt;p>而对于 UD 来说，QP 间没有连接关系，用户想发给谁，就在 WQE 中填好对端的地址信息就可以了。&lt;strong>用户不是直接把对端的地址信息填到 WQE 中的，而是提前准备了一个“地址薄”，每次通过一个索引来指定对端节点的地址信息，而这个索引就是 AH。&lt;/strong>&lt;/p>
&lt;p>AH 的概念大致可以用下图表示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-16_8_1.webp"
alt="2024-06-16_8_1" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>Address Handle 功能示意图&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>对于每一个目的节点，本端都会创建一个对应的 AH，而同一个 AH 可以被多个 QP 共同使用。&lt;/p>
&lt;h2 id="ah-的作用">
&lt;a href="#ah-%e7%9a%84%e4%bd%9c%e7%94%a8" class="header-anchor">#&lt;/a>
AH 的作用
&lt;/h2>
&lt;p>每次进行 UD 服务类型的通信之前，用户都需要先通过 IB 框架提供的接口，来&lt;strong>为每一个可能的对端节点创建一个 AH&lt;/strong>，然后这些 AH 会被驱动放到一个“安全”的区域，并返回一个索引（指针/句柄）给用户。用户真正下发 WR（Work Request）时，就把这个索引传递进来就可以了。&lt;/p>
&lt;p>上述过程如下图所示，A 节点收到用户的这样一个任务——使用本端的 QP4 与 B 节点（通过 AH 指定）的 QP3 进行数据交换：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-16_8_2.webp"
alt="2024-06-16_8_2" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>UD 服务类型使用 AH 指定对端节点&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>IB 协议中并没有对为什么使用 AH 做出解释，我认为定义 AH 的概念的原因有以下三种：&lt;/p>
&lt;ol>
&lt;li>保证目的地址可用，提高效率&lt;/li>
&lt;/ol>
&lt;p>因为 UD 无连接的特点，用户可以在用户态直接通过 WR 来指定目的地。而如果让用户随意填写地址信息，然后硬件就根据这些信息进行组包的话，是会带来问题的。比如有这样一种场景：用户通过 WR 告诉硬件请给 GID 为 X，MAC 地址为 Y 的节点的端口 Z 发送数据。然而 X，Y，Z 可能不是一个合法的组合，或者 GID 为 X 的节点压根都不存在于网络中，而硬件是无力校验这些内容的，只能乖乖的组包、发送数据，这个目的地无效的数据包就白白发送出去了。&lt;/p>
&lt;p>而提前准备好地址信息，则可以避免上述情况。用户在创建 AH 时会陷入内核态，如果用户传递的参数有效，内核会把这些目的节点信息储存起来，生成一个指针返回给用户；如果用户传递的参数无效，AH 将创建失败。这一过程可以保证地址信息是有效的。用户通过指针就可以快速指定目的节点，加快数据交互流程。&lt;/p>
&lt;p>可能有人会问，既然内核是可信的，为什么不能在发送数据时陷入内核态去校验用户传递的地址信息呢？请别忘了 RDMA 技术的一大优势在哪里——数据流程可以直接从用户空间到硬件，完全绕过内核，这样可以避免系统调用和拷贝的开销。如果每次发送都要检验地址合法性的话，必然会降低通信速率。&lt;/p>
&lt;ol start="2">
&lt;li>向用户隐藏底层地址细节&lt;/li>
&lt;/ol>
&lt;p>用户创建 AH 时，只需要传递 gid、端口号、静态速率等信息，而其他通信所需的地址信息（主要是 MAC 地址）是内核驱动通过查询系统邻居表等方式解析到的，底层没有必要暴露这些额外的信息给用户层。&lt;/p>
&lt;ol start="3">
&lt;li>可以使用 PD 对目的地址进行管理&lt;/li>
&lt;/ol>
&lt;p>前文我们介绍保护域时曾经提过，除了 QP、MR 之外，AH 也由 PD 来进行资源划分。当定义了 AH 这个软件实体之后，我们就可以对所有的 QP 可达的目的地进行相互隔离和管理。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/2024-06-16_8_3.webp"
alt="2024-06-16_8_3" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>使用 PD 隔离 AH&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>​比如上图中，AH1~3 只能被同一个 PD 下的 QP3 和 QP9 使用，而 AH4 只能被 QP5 使用。&lt;/p>
&lt;h2 id="协议相关章节">
&lt;a href="#%e5%8d%8f%e8%ae%ae%e7%9b%b8%e5%85%b3%e7%ab%a0%e8%8a%82" class="header-anchor">#&lt;/a>
协议相关章节
&lt;/h2>
&lt;p>协议中关于 AH 的篇幅并不多，甚至没有独立介绍其概念的章节：&lt;/p>
&lt;p>[1] 9.8.3 UD 服务类型中的目的地址由哪些部分组成：包括 AH、 QPN 和 Q_key&lt;/p>
&lt;p>[2] 10.2.2.2 目的地址的相关注意事项&lt;/p>
&lt;p>[3] 11.2.2.1 AH 相关的 Verbs 接口&lt;/p>
&lt;p>AH 就介绍到这里，感谢阅读。下一篇打算向大家描述更多关于 QP 的细节。&lt;/p></description></item><item><title>RDMA 之 Protection Domain</title><link>https://cuterwrite.top/p/rdma-protection-domain/</link><pubDate>Thu, 18 Apr 2024 21:42:00 +0000</pubDate><guid>https://cuterwrite.top/p/rdma-protection-domain/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/d31a474af07682028ca085f871bc5d07195413-2024-04-19.webp" alt="Featured image of post RDMA 之 Protection Domain" />&lt;h1 id="rdma-之-protection-domain">
&lt;a href="#rdma-%e4%b9%8b-protection-domain" class="header-anchor">#&lt;/a>
RDMA 之 Protection Domain
&lt;/h1>
&lt;p>&lt;strong>本文欢迎非商业转载，转载请注明出处。&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>声明：仅用于收藏，便于阅读&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/159493100">&lt;cite>知乎专栏：7. RDMA 之 Protection Domain&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>前文我们简单介绍了 RDMA 中最常见的一些资源，包括各种 Queue，以及 MR 的概念等等。MR 用于控制和管理 HCA 对于本端和远端内存的访问权限，确保 HCA 只有拿到正确 Key 之后才能读写用户已经注册了的内存区域。为了更好的保障安全性，IB 协议又提出了 Protection Domain（PD）的概念，用于保证 RDMA 资源间的相互隔离，本文就介绍一下 PD 的概念。&lt;/p>
&lt;h2 id="pd-是什么">
&lt;a href="#pd-%e6%98%af%e4%bb%80%e4%b9%88" class="header-anchor">#&lt;/a>
PD 是什么
&lt;/h2>
&lt;p>PD 全称是 Protection Domain，意为&amp;quot;保护域&amp;quot;。域的概念我们经常见到，从数学上的“实数域”、“复数域”，到地理上的“空域”、“海域”等等，表示一个空间/范围。在 RDMA 中，PD 像是一个容纳了各种资源（QP、MR 等）的“容器”，将这些资源纳入自己的保护范围内，避免他们被未经授权的访问。一个节点中可以定义多个保护域，各个 PD 所容纳的资源彼此隔离，无法一起使用。&lt;/p>
&lt;p>概念还是有些抽象，下面我们来看一下 PD 有什么作用，具体解决了什么问题。&lt;/p>
&lt;h2 id="pd-的作用">
&lt;a href="#pd-%e7%9a%84%e4%bd%9c%e7%94%a8" class="header-anchor">#&lt;/a>
PD 的作用
&lt;/h2>
&lt;p>一个用户可能创建多个 QP 和多个 MR，每个 QP 可能和不同的远端 QP 建立了连接，比如下图这样（灰色箭头表示 QP 间的连接关系）：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/7_1-2024-04-19.webp"
alt="7_1-2024-04-19" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>图 1：没有 PD 概念时的 RDMA 资源&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>由于 MR 和 QP 之间并没有绑定关系，这就意味着一旦某个远端的 QP 与本端的一个 QP 建立了连接，具备了通信的条件，那么理论上远端节点只要知道 VA 和 R_key（甚至可以靠不断的猜测直到得到一对有效的值），就可以访问本端节点某个 MR 的内容。&lt;/p>
&lt;p>其实一般情况下，MR 的虚拟地址 VA 和秘钥 R_Key 是很难猜到的，已经可以保证一定的安全性了。但是为了更好的保护内存中的数据，把各种资源的权限做进一步的隔离和划分，我们在又在每个节点中定义了 PD，如下图所示&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/7_2-2024-04-19.webp"
alt="7_2-2024-04-19" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>图 2：加入 PD 概念时的 RDMA 资源&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>图中 Node 0 上有两个 PD，将 3 个 QP 和 2 个 MR 分为了两组，此外 Node 1 和 Node 2 中各有一个 PD 包含了所有 QP 和 MR。Node 0 上的两个 PD 中的资源不可以一起使用，也就是说 QP3 和 QP9 不能访问 MR1 的数据，QP6 也不可以访问 MR0 的数据。如果我们在数据收发时，指定硬件使用 QP3 和 MR1，那么硬件校验他们不属于同一个 PD 后，会返回错误。&lt;/p>
&lt;p>对于远端节点来说，Node1 只能通过 QP8 相连的 QP3 来访问 Node0 的内存，但是因为 Node 0 的 QP3 被“圈”到了 PD0 这个保护域中，所以 Node 1 的 QP8 也只能访问 MR0 对应的内存，&lt;strong>无论如何都无法访问 MR1 中的数据&lt;/strong>，这是从两个方面限制的：&lt;/p>
&lt;ol>
&lt;li>Node 1 的 QP8 只跟 Node 0 的 QP3 有连接关系，无法通过 Node 0 的 QP6 进行内存访问。&lt;/li>
&lt;li>Node 0 的 MR1 和 QP3 属于不同的 PD，就算 Node 1 的 QP8 拿到了 MR1 的 VA 和 R_key，硬件也会因为 PD 不同而拒绝提供服务。&lt;/li>
&lt;/ol>
&lt;p>所以就如本文一开始所说的，PD 就像是一个容器，将一些 RDMA 资源保护起来，彼此隔离，以提高安全性。其实 RDMA 中不止有 QP、MR 这些资源，后文即将介绍的 Address Handle，Memory Window 等也是由 PD 进行隔离保护的。&lt;/p>
&lt;h2 id="如何使用-pd">
&lt;a href="#%e5%a6%82%e4%bd%95%e4%bd%bf%e7%94%a8-pd" class="header-anchor">#&lt;/a>
如何使用 PD
&lt;/h2>
&lt;p>还是看上面的图，我们注意到 Node 0 为了隔离资源，存在两个 PD；而 Node 1 和 Node 2 只有一个 PD 包含了所有资源。&lt;/p>
&lt;p>我之所以这样画，是为了说明一个节点上划分多少个 PD 完全是由用户决定的，&lt;strong>如果想提高安全性，那么对每个连接到远端节点的 QP 和供远端访问的 MR 都应该尽量通过划分 PD 做到隔离；如果不追求更高的安全性，那么创建一个 PD，囊括所有的资源也是可以的&lt;/strong>。&lt;/p>
&lt;p>IB 协议中规定：&lt;strong>每个节点都至少要有一个 PD，每个 QP 都必须属于一个 PD，每个 MR 也必须属于一个 PD&lt;/strong>。&lt;/p>
&lt;p>那么 PD 的包含关系在软件上是如何体现的呢？它本身是有一个软件实体的（结构体），记录了这个保护域的一些信息。用户在创建 QP 和 MR 等资源之前，必须先通过 IB 框架的接口创建一个 PD，拿到它的指针/句柄。接下来在创建 QP 和 MR 的时候，需要传入这个 PD 的指针/句柄，PD 信息就会包含在 QP 和 MR 中。硬件收发包时，会对 QP 和 MR 的 PD 进行校验。更多的软件协议栈的内容，我会在后面的文章中介绍。&lt;/p>
&lt;p>另外需要强调的是，&lt;strong>PD 是本地概念，仅存在于节点内部&lt;/strong>，对其他节点是不可见的；而 MR 是对本端和对端都可见的。&lt;/p>
&lt;p>为了方便大家查阅和学习，以后我会列出文章涉及的协议章节，前面的内容有时间的时候我也会补充一下。&lt;/p>
&lt;h2 id="pd-相关协议章节">
&lt;a href="#pd-%e7%9b%b8%e5%85%b3%e5%8d%8f%e8%ae%ae%e7%ab%a0%e8%8a%82" class="header-anchor">#&lt;/a>
PD 相关协议章节
&lt;/h2>
&lt;ul>
&lt;li>3.5.5 PD 的基本概念和作用&lt;/li>
&lt;li>10.2.3 介绍了 PD 和其他一些 RDMA 资源的关系，以及 PD 相关的软件接口。&lt;/li>
&lt;li>10.6.3.5 再次强调 PD 和 MR 及 QP 的关系。&lt;/li>
&lt;li>11.2.1.5 详细介绍 PD 的 Verbs 接口，包括作用、入参、出参和返回值等。&lt;/li>
&lt;/ul>
&lt;p>好了，关于 PD 的介绍就到这里。下文我会介绍用于 UD 服务类型的 Address Handle 的概念。&lt;/p></description></item><item><title>RDMA 之 Memory Region</title><link>https://cuterwrite.top/p/rdma-mr/</link><pubDate>Wed, 03 Apr 2024 16:17:00 +0000</pubDate><guid>https://cuterwrite.top/p/rdma-mr/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/8fa232626b76940fddc8cc52a49c49e9195413-2024-04-04.webp" alt="Featured image of post RDMA 之 Memory Region" />&lt;h1 id="rdma-之-memory-region">
&lt;a href="#rdma-%e4%b9%8b-memory-region" class="header-anchor">#&lt;/a>
RDMA 之 Memory Region
&lt;/h1>
&lt;p>&lt;strong>本文欢迎非商业转载，转载请注明出处。&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>声明：仅用于收藏，便于阅读&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/156975042">&lt;cite>知乎专栏：6. RDMA 之 Memory Region&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>我们假设一种场景，同时也顺便温习一下 RDMA WRITE 操作的流程：&lt;/p>
&lt;p>如下图所示，A 节点想要通过 IB 协议向 B 节点的内存中写入一段数据，上层应用给本节点的 RDMA 网卡下发了一个 WQE，WQE 中包含了源内存地址、目的内存地址、数据长度和秘钥等信息，然后硬件会从内存中取出数据，组包发送到对端网卡。B 节点的网卡收到数据后，解析到其中的目的内存地址，把数据写入到本节点的内存中。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/6_1-2024-04-04.webp"
alt="6_1-2024-04-04" width="auto" loading="lazy">
&lt;/figure>
&lt;p>那么问题来了，APP 提供的地址都是虚拟地址（Virtual Address，下文称 VA），经过 MMU 的转换才能得到真实的物理地址（Physical Address，下文称 PA），我们的&lt;strong>RDMA 网卡是如何得到 PA 从而去内存中拿到数据的呢&lt;/strong>？就算网卡知道上哪去取数据，&lt;strong>如果用户恶意指定了一个非法的 VA，那网卡岂不是有可能被“指使”去读写关键内存&lt;/strong>？&lt;/p>
&lt;p>为了解决上面的问题，IB 协议提出了 MR 的概念。&lt;/p>
&lt;h2 id="mr-是什么">
&lt;a href="#mr-%e6%98%af%e4%bb%80%e4%b9%88" class="header-anchor">#&lt;/a>
MR 是什么
&lt;/h2>
&lt;p>MR 全称为 Memory Region，指的是由 RDMA 软件层在内存中规划出的一片区域，用于存放收发的数据。IB 协议中，用户在申请完用于存放数据的内存区域之后，都需要通过调用 IB 框架提供的 API 注册 MR，才能让 RDMA 网卡访问这片内存区域。由下图可以看到，MR 就是一片特殊的内存而已：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/6_2-2024-04-04.webp"
alt="6_2-2024-04-04" width="auto" loading="lazy">
&lt;/figure>
&lt;p>在对 IB 协议进行相关描述时，我们通常称 RDMA 硬件为&lt;strong>HCA（Host Channel Adapter， 宿主通道适配器）&lt;/strong>，IB 协议中对其的定义是“处理器和 I/O 单元中能够产生和消耗数据包的 IB 设备”，为了与协议保持一致，我们在包括本文及之后的文章中都称硬件部分为 HCA。&lt;/p>
&lt;h2 id="为什么要注册-mr">
&lt;a href="#%e4%b8%ba%e4%bb%80%e4%b9%88%e8%a6%81%e6%b3%a8%e5%86%8c-mr" class="header-anchor">#&lt;/a>
为什么要注册 MR
&lt;/h2>
&lt;p>下面我们来看一下 MR 是如何解决本文开篇提出的两个问题的：&lt;/p>
&lt;h3 id="1-注册-mr-以实现虚拟地址与物理地址转换">
&lt;a href="#1-%e6%b3%a8%e5%86%8c-mr-%e4%bb%a5%e5%ae%9e%e7%8e%b0%e8%99%9a%e6%8b%9f%e5%9c%b0%e5%9d%80%e4%b8%8e%e7%89%a9%e7%90%86%e5%9c%b0%e5%9d%80%e8%bd%ac%e6%8d%a2" class="header-anchor">#&lt;/a>
1. 注册 MR 以实现虚拟地址与物理地址转换
&lt;/h3>
&lt;p>我们都知道 APP 只能看到虚拟地址，而且会在 WQE 中直接把 VA 传递给 HCA（既包括本端的源 VA，也包括对端的目的 VA）。现在的 CPU 都有 MMU 和页表这一“利器”来进行 VA 和 PA 之间的转换，而 HCA 要么直接连接到总线上，要么通过 IOMMU/SMMU 做地址转换后连接到总线上，它是“看不懂”APP 提供的 VA 所对应的真实物理内存地址的。&lt;/p>
&lt;p>所以注册 MR 的过程中，硬件会在内存中创建并填写一个 VA to PA 的映射表，这样需要的时候就能通过查表把 VA 转换成 PA 了。我们还是提供一个具体的例子来讲一下这个过程：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/6_3-2024-04-04.webp"
alt="6_3-2024-04-04" width="auto" loading="lazy">
&lt;/figure>
&lt;p>现在假设左边的节点向右边的节点发起了 RDMA WRITE 操作，即直接向右节点的内存区域中写入数据。假设图中两端都已经完成了注册 MR 的动作，MR 即对应图中的“数据 Buffer”，同时也创建好了 VA-&amp;gt;PA 的映射表。&lt;/p>
&lt;ul>
&lt;li>首先本端 APP 会下发一个 WQE 给 HCA，告知 HCA，用于存放待发送数据的本地 Buffer 的虚拟地址，以及即将写入的对端数据 Buffer 的虚拟地址。&lt;/li>
&lt;li>本端 HCA 查询 VA-&amp;gt;PA 映射表，得知待发数据的物理地址，然后从内存中拿到数据，组装数据包并发送出去。&lt;/li>
&lt;li>对端 HCA 收到了数据包，从中解析出了目的 VA。&lt;/li>
&lt;li>对端 HCA 通过存储在本地内存中的 VA-&amp;gt;PA 映射表，查到真实的物理地址，核对权限无误后，将数据存放到内存中。&lt;/li>
&lt;/ul>
&lt;p>再次强调一下，对于右侧节点来说，&lt;strong>无论是地址转换还是写入内存，完全不用其 CPU 的参与&lt;/strong>。&lt;/p>
&lt;h3 id="2-mr-可以控制-hca-访问内存的权限">
&lt;a href="#2-mr-%e5%8f%af%e4%bb%a5%e6%8e%a7%e5%88%b6-hca-%e8%ae%bf%e9%97%ae%e5%86%85%e5%ad%98%e7%9a%84%e6%9d%83%e9%99%90" class="header-anchor">#&lt;/a>
2. MR 可以控制 HCA 访问内存的权限
&lt;/h3>
&lt;p>因为 HCA 访问的内存地址来自于用户，如果用户传入了一个非法的地址（比如系统内存或者其他进程使用的内存），HCA 对其进行读写可能造成信息泄露或者内存覆盖。所以我们需要一种机制来确保 HCA 只能访问已被授权的、安全的内存地址。IB 协议中，APP 在为数据交互做准备的阶段，需要执行注册 MR 的动作。&lt;/p>
&lt;p>而用户注册 MR 的动作会产生两把钥匙——L_KEY（Local Key）和 R_KEY（Remote Key），说是钥匙，它们的实体其实就是一串序列而已。它们将分别用于保障对于本端和远端内存区域的访问权限。下面两张图分别是描述 L_Key 和 R_Key 的作用的示意图：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/6_4-2024-04-04.webp"
alt="6_4-2024-04-04" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>L_Key&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/6_5-2024-04-04.webp"
alt="6_5-2024-04-04" width="auto" loading="lazy">&lt;figcaption>
&lt;h4>R_Key&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>这里大家可能会有疑问，本端是如何知道对端节点的可用 VA 和对应的 R_Key 的？其实两端的节点在真正的 RDMA 通信之前，都会通过某些方式先建立一条链路（可能是 Socket 连接，也可能是 CM 连接）并通过这条链路交换一些 RDMA 通信所必须的信息（VA，Key，QPN 等），我们称这一过程叫做“建链”和“握手”。我将在后面的文章中详细介绍。&lt;/p>
&lt;p>除了上面两个点之外，注册 MR 还有个重要的作用：&lt;/p>
&lt;h3 id="3-mr-可以避免换页">
&lt;a href="#3-mr-%e5%8f%af%e4%bb%a5%e9%81%bf%e5%85%8d%e6%8d%a2%e9%a1%b5" class="header-anchor">#&lt;/a>
3. MR 可以避免换页
&lt;/h3>
&lt;p>因为物理内存是有限的，所以操作系统通过换页机制来暂时把某个进程不用的内存内容保存到硬盘中。当该进程需要使用时，再通过缺页中断把硬盘中的内容搬移回内存，这一过程几乎必然导致 VA-PA 的映射关系发生改变。&lt;/p>
&lt;p>由于 HCA 经常会绕过 CPU 对用户提供的 VA 所指向的物理内存区域进行读写，如果前后的 VA-PA 映射关系发生改变，那么我们在前文提到的 VA-&amp;gt;PA 映射表将失去意义，HCA 将无法找到正确的物理地址。&lt;/p>
&lt;p>为了防止换页所导致的 VA-PA 映射关系发生改变，注册 MR 时会 &amp;ldquo;Pin&amp;rdquo; 住这块内存（亦称“锁页”），即锁定 VA-PA 的映射关系。也就是说，MR 这块内存区域会长期存在于物理内存中不被换页，直到完成通信之后，用户主动注销这片 MR。&lt;/p>
&lt;p>好了，至此我们介绍完了 MR 的概念和作用，下一篇文章我将给大家介绍一下 PD（Protection Domain，保护域）的概念。&lt;/p>
&lt;h2 id="代码示例">
&lt;a href="#%e4%bb%a3%e7%a0%81%e7%a4%ba%e4%be%8b" class="header-anchor">#&lt;/a>
代码示例
&lt;/h2>
&lt;p>下面是一个简单的 RDMA 程序，展示了如何注册 MR：&lt;/p>
&lt;pre>&lt;code class="language-c">#include &amp;lt;infiniband/verbs.h&amp;gt;
int main() {
// 省略初始化过程...
struct ibv_mr *mr;
mr = ibv_reg_mr(pd, buf, 1024, IBV_ACCESS_LOCAL_WRITE |
IBV_ACCESS_REMOTE_WRITE);
// 获取 L_Key 和 R_Key
uint32_t lkey = mr-&amp;gt;lkey;
uint32_t rkey = mr-&amp;gt;rkey;
// 省略其它代码...
}
&lt;/code>&lt;/pre></description></item><item><title>RDMA 基本服务类型</title><link>https://cuterwrite.top/p/rdma-service-types/</link><pubDate>Sun, 25 Feb 2024 22:04:01 +0000</pubDate><guid>https://cuterwrite.top/p/rdma-service-types/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/f71da3ec40dd74648e15471d47ba3b84195413_crop-2024-02-26.webp" alt="Featured image of post RDMA 基本服务类型" />&lt;h1 id="rdma-基本服务类型">
&lt;a href="#rdma-%e5%9f%ba%e6%9c%ac%e6%9c%8d%e5%8a%a1%e7%b1%bb%e5%9e%8b" class="header-anchor">#&lt;/a>
RDMA 基本服务类型
&lt;/h1>
&lt;p>&lt;strong>本文欢迎非商业转载，转载请注明出处。&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>声明：仅用于收藏，便于阅读&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/144099636">&lt;cite>知乎专栏：5. RDMA 基本服务类型&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>我们在 &lt;a class="link" href="https://cuterwrite.top/p/rdma-element/" >【“3. RDMA 基本元素”】
&lt;/a>
一文中提到过，&lt;strong>RDMA 的基本通信单元是 QP&lt;/strong>，而基于 QP 的通信模型有很多种，我们在 RDMA 领域称其为“服务类型”。IB 协议中通过“可靠”和“连接”两个维度来描述一种服务类型。&lt;/p>
&lt;h2 id="可靠">
&lt;a href="#%e5%8f%af%e9%9d%a0" class="header-anchor">#&lt;/a>
可靠
&lt;/h2>
&lt;p>通信中的可靠性指的是通过一些机制保证发出去的数据包都能够被正常接收。IB 协议中是这样描述可靠服务的：&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Reliable Service&lt;/strong> provides a guarantee that messages are delivered from a requester to a responder at most once, in order and without corruption.&lt;/p>
&lt;/blockquote>
&lt;p>即“可靠服务在发送和接受者之间保证了信息最多只会传递一次，并且能够保证其按照发送顺序完整的被接收”。&lt;/p>
&lt;p>IB 通过以下三个机制来保证可靠性：&lt;/p>
&lt;h2 id="应答机制">
&lt;a href="#%e5%ba%94%e7%ad%94%e6%9c%ba%e5%88%b6" class="header-anchor">#&lt;/a>
应答机制
&lt;/h2>
&lt;p>假设 A 给 B 发了一个数据包，A 怎样才能知道 B 收到了呢，自然是 B 回复一个“我收到了”消息给 A。在通信领域我们一般称这个回复为应答包或者 ACK（Acknowledge）。在 IB 协议的可靠服务类型中，使用了应答机制来保证数据包被对方收到。IB 的可靠服务类型中，接收方不是每一个包都必须回复，也可以一次回复多个包的 ACK，以后我们再展开讨论。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/ib_ack-2024-02-26.webp"
alt="ib_ack-2024-02-26" width="auto" loading="lazy">
&lt;/figure>
&lt;h2 id="数据校验机制">
&lt;a href="#%e6%95%b0%e6%8d%ae%e6%a0%a1%e9%aa%8c%e6%9c%ba%e5%88%b6" class="header-anchor">#&lt;/a>
数据校验机制
&lt;/h2>
&lt;p>这个比较好理解，发端会对 Header 和 Payload（有效载荷，也就是真正要收发的数据）通过一定的算法得到一个校验值放到数据包的末尾。对端收到数据包后，也会用相同的算法计算出校验值，然后与数据包中的校验值比对，如果不一致，说明数据中包含错误（一般是链路问题导致的），那么接收端就会丢弃这个数据包。IB 协议使用的 CRC 校验，本文对 CRC 不做展开介绍。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/crc-2024-02-26.png"
alt="crc-2024-02-26" width="auto" loading="lazy">
&lt;/figure>
&lt;h2 id="保序机制">
&lt;a href="#%e4%bf%9d%e5%ba%8f%e6%9c%ba%e5%88%b6" class="header-anchor">#&lt;/a>
保序机制
&lt;/h2>
&lt;p>保序指的是，保证先被发送到物理链路上的数据包一定要先于后发送的数据包被接收方收到。有一些业务对数据包的先后顺序是有严格要求的，比如语音或者视频。IB 协议中有 PSN（Packet Sequence Number，包序号）的概念，即每个包都有一个递增的编号。PSN 可以用来检测是否丢包，比如收端收到了 1，但是在没收到 2 的情况下就收到了 3，那么其就会认为传输过程中发生了错误，之后会回复一个 NAK 给发端，让其重发丢失的包。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/psn-2024-02-26.webp"
alt="psn-2024-02-26" width="auto" loading="lazy">
&lt;/figure>
&lt;p>不可靠服务，没有上述这些机制来保证数据包被正确的接收，属于“发出去就行，我不关心有没有被收到”的服务类型。&lt;/p>
&lt;h2 id="连接与数据报">
&lt;a href="#%e8%bf%9e%e6%8e%a5%e4%b8%8e%e6%95%b0%e6%8d%ae%e6%8a%a5" class="header-anchor">#&lt;/a>
连接与数据报
&lt;/h2>
&lt;p>&lt;strong>连接（Connection）&lt;/strong> 在这里指的是一个抽象的逻辑概念，需要区别于物理连接，熟悉 Socket 的读者一定对这个其不陌生。连接是一条通信的“管道”，一旦管道建立好了，管道这端发出的数据一定会沿着这条管道到达另一端。&lt;/p>
&lt;p>对于“连接”或者说“面向连接”的定义有很多种，有的侧重于保证消息顺序，有的侧重于消息的传递路径唯一，有的强调需要软硬件开销来维护连接，有的还和可靠性的概念有交集。本专栏既然是介绍 RDMA 技术，那么我们就看一下 IB 协议 3.2.2 节中对其的描述：&lt;/p>
&lt;blockquote>
&lt;p>IBA supports both connection oriented and datagram service. For connected service, each QP is associated with exactly one remote consumer. In this case the QP context is configured with the identity of the remote consumer’s queue pair. &amp;hellip; During the communication establishment process, this and other information is exchanged between the two nodes.&lt;/p>
&lt;/blockquote>
&lt;p>即“IBA 支持基于连接和数据报的服务。对于基于连接的服务来说，每个 QP 都和另一个远端节点相关联。在这种情况下，QP Context 中包含有远端节点的 QP 信息。在建立通信的过程中，两个节点会交换包括稍后用于通信的 QP 在内的对端信息&amp;quot;。&lt;/p>
&lt;p>上面这端描述中的 Context 一般被翻译成上下文，QP Context（简称 QPC）可以简单理解为是记录一个 QP 相关信息的表格。我们知道 QP 是两个队列，除了这两个队列之外，我们还需要把关于 QP 的信息记录到一张表里面，这些信息可能包括队列的深度，队列的编号等等，后面我们会展开讲。&lt;/p>
&lt;p>可能还是有点抽象，我们用图说话：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/QPC-2024-02-26.webp"
alt="QPC-2024-02-26" width="auto" loading="lazy">
&lt;/figure>
&lt;p>A、B 和 A、C 节点的网卡在物理上是连接在一起的，A 上面的 QP2 和 B 上面的 QP7、A 上面的 QP4 和 B 上面的 QP2 建立了逻辑上的连接，或者说“绑定到了一起”。&lt;strong>在连接服务类型中的每个 QP，都和唯一的另一个 QP 建立了连接，也就是说 QP 下发的每个 WQE 的目的地都是唯一的&lt;/strong>。拿上图来说，对于 A 的 QP2 下发的每个 WQE，硬件都可以通过 QPC 得知其目的为 B 的 QP7，就会把组装好的数据包发送给 B，然后 B 会根据 QP7 下发的 RQ WQE 来存放数据；同理，对于 A 的 QP4 下发的每个 WQE，A 的硬件都知道应该把数据发给 Node C 的 QP2。&lt;/p>
&lt;p>“连接”是如何维护的呢？其实就是在 QPC 里面的一个记录而已。如果 A 的 QP2 想断开与 B 的 QP7 的“连接”然后与其他 QP 相“连接”，只需要修改 QPC 就可以了。两个节点在建立连接的过程中，会交换稍后用于数据交互的 QP Number，然后分别记录在 QPC 中。&lt;/p>
&lt;p>&lt;strong>数据报（Datagram）&lt;/strong> 与连接相反，发端和收端间不需要“建立管道”的步骤，只要发端到收端物理上是可以到达的，那么我就可能从任何路径发给任意的收端节点。IB 协议对其的定义是这样的：&lt;/p>
&lt;blockquote>
&lt;p>For datagram service, a QP is not tied to a single remote consumer, but rather information in the WQE identifies the destination. A communication setup process similar to the connection setup process needs to occur with each destination to exchange that information.&lt;/p>
&lt;p>即“对于数据报服务来说，QP 不会跟一个唯一的远端节点绑定，而是通过 WQE 来指定目的节点。和连接类型的服务一样，建立通信的过程也需要两端交换对端信息，但是数据报服务对于每个目的节点都需要执行一次这个交换过程。”&lt;/p>
&lt;/blockquote>
&lt;p>我们举个例子：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/Datagram-2024-02-26.webp"
alt="Datagram-2024-02-26" width="auto" loading="lazy">
&lt;/figure>
&lt;p>在数据报类型的 QP 的 Context 中，不包含对端信息，即每个 QP 不跟另一个 QP 绑定。&lt;strong>QP 下发给硬件的每个 WQE 都可能指向不同的目的地&lt;/strong>。比如节点 A 的 QP2 下发的第一个 WQE，指示给节点 C 的 QP3 发数据；而下一个 WQE，可以指示硬件发给节点 B 的 QP7。&lt;/p>
&lt;p>与连接服务类型一样，本端 QP 可以和哪个对端 QP 发送数据，是在准备阶段提前通过某些方式相互告知的。这也是上文“数据报服务对于每个目的节点都需要执行一次这个交换过程”的含义。&lt;/p>
&lt;h2 id="服务类型">
&lt;a href="#%e6%9c%8d%e5%8a%a1%e7%b1%bb%e5%9e%8b" class="header-anchor">#&lt;/a>
服务类型
&lt;/h2>
&lt;p>上面介绍的两个维度两两组合就形成了 IB 的四种基本服务类型：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align: left">&lt;/th>
&lt;th style="text-align: left">可靠(Reliable)&lt;/th>
&lt;th style="text-align: left">不可靠(Unreliable)&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align: left">连接(Connection)&lt;/td>
&lt;td style="text-align: left">RC（Reliable Connection）&lt;/td>
&lt;td style="text-align: left">UC（Unreliable Connection）&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align: left">数据报(Datagram)&lt;/td>
&lt;td style="text-align: left">RD（Reliable Datagram）&lt;/td>
&lt;td style="text-align: left">UD（Unreliable Datagram）&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>RC 和 UD 是应用最多也是最基础的两种服务类型，我们可以将他们分别类比成 TCP/IP 协议栈传输层的 TCP 和 UDP。&lt;/p>
&lt;p>RC 用于对数据完整性和可靠性要求较高的场景，跟 TCP 一样，因为需要各种机制来保证可靠，所以开销自然会大一些。另外由于 RC 服务类型和每个节点间需要各自维护一个 QP，假设有 N 个节点要相互通信，那么至少需要 &lt;strong>N * (N - 1)&lt;/strong> 个 QP，而 QP 和 QPC 本身是需要占用网卡资源或者内存的，当节点数很多时，存储资源消耗将会非常大。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/RC_Connect-2024-02-26.webp"
alt="RC_Connect-2024-02-26" width="auto" loading="lazy">
&lt;/figure>
&lt;p>UD 硬件开销小并且节省存储资源，比如 N 个节点需要相互通信，只需要创建 &lt;strong>N&lt;/strong> 个 QP 就可以了，但是可靠性跟 UDP 一样没法保证。用户如果想基于 UD 服务类型实现可靠性，那么需要自己基于 IB 传输层实现应用层的可靠传输机制。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/UD_Connect-2024-02-26.webp"
alt="UD_Connect-2024-02-26" width="auto" loading="lazy">
&lt;/figure>
&lt;p>除此之外，还有 RD 和 UC 类型，以及 XRC（Extended Reliable Connection），SRD（Scalable Reliable Datagram）等更复杂的服务类型，我们将在协议解析部分对其进行详细的描述。&lt;/p>
&lt;p>更多关于 QP 类型选择的信息可以参考 RDMAmojo 上的&lt;a class="link" href="https://www.rdmamojo.com/2013/06/01/which-queue-pair-type-to-use/" target="_blank" rel="noopener" >Which Queue Pair type to use?
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
这篇文章，感谢 &lt;a class="link" href="https://www.zhihu.com/people/fc04fe143ad43b66fabb7050dadef923" target="_blank" rel="noopener" >@sinkinben
&lt;span style="white-space: nowrap;">&lt;svg width=".8em" height=".8em" viewBox="0 0 21 21"
xmlns="http://www.w3.org/2000/svg">
&lt;path d="m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z" fill="currentColor" />
&lt;path d="M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z"
fill="currentColor">
&lt;/svg>&lt;/span>
&lt;/a>
同学在评论区指路。&lt;/p>
&lt;h2 id="代码示例">
&lt;a href="#%e4%bb%a3%e7%a0%81%e7%a4%ba%e4%be%8b" class="header-anchor">#&lt;/a>
代码示例
&lt;/h2>
&lt;p>在 RDMA 编程中，我们可以通过 &lt;code>ibv_create_qp&lt;/code> 函数来创建 QP，其中的 &lt;code>struct ibv_qp_init_attr&lt;/code> 结构体中的 &lt;code>qp_type&lt;/code> 字段就是用来指定 QP 的服务类型的。下面是一个简单的示例代码：&lt;/p>
&lt;pre>&lt;code class="language-c">struct ibv_qp_init_attr qp_init_attr;
qp_init_attr.qp_type = IBV_QPT_RC; // RC 类型
qp_init_attr.sq_sig_all = 1; // 1 表示 SQ 中的每个 WQE 都需要对应的接收一个 CQE
qp_init_attr.send_cq = cq; // 发送 CQ
qp_init_attr.recv_cq = cq; // 接收 CQ
qp_init_attr.cap.max_send_wr = 1024; // SQ 的深度
struct ibv_qp *qp = ibv_create_qp(pd, &amp;amp;qp_init_attr);
&lt;/code>&lt;/pre></description></item></channel></rss>