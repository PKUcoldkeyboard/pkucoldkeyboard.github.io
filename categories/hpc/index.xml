<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>高性能计算 on cuterwrite</title><link>https://cuterwrite.top/categories/hpc/</link><description>Recent content in 高性能计算 on cuterwrite</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>cuterwrite</copyright><lastBuildDate>Mon, 01 Jan 2024 01:01:01 +0000</lastBuildDate><atom:link href="https://cuterwrite.top/categories/hpc/index.xml" rel="self" type="application/rss+xml"/><item><title>RDMA 概述</title><link>https://cuterwrite.top/p/rdma-overview/</link><pubDate>Mon, 01 Jan 2024 01:01:01 +0000</pubDate><guid>https://cuterwrite.top/p/rdma-overview/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/crop_65b36f302c1d3715061e824224dcc9ca195413.jpg@1256w_1806h_!web-article-pic-2024-01-14.webp" alt="Featured image of post RDMA 概述" />&lt;h1 id="rdma-概述">RDMA 概述&lt;/h1>
&lt;p>&lt;strong>本文欢迎非商业转载，转载请注明出处。&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>声明：仅用于收藏，便于阅读&lt;/p>&lt;span class="cite">&lt;span>― &lt;/span>&lt;span>Savir, &lt;/span>&lt;a href="https://zhuanlan.zhihu.com/p/138874738">&lt;cite>知乎专栏：1. RDMA 概述&lt;/cite>&lt;/a>&lt;/span>&lt;/blockquote>
&lt;p>本想完全靠自己的语言完成这篇概述，然而开篇并没有想象当中的好写，看样子从宏观上概括一个技术比从微观上探究细枝末节要困难不少。本文是以前人们对 RDMA 技术的介绍为主，加入了一些自己的理解。随着本专栏内容的增加，本篇概述也会更新和逐渐完善。&lt;/p>
&lt;h2 id="什么是-dma">什么是 DMA&lt;/h2>
&lt;p>DMA 全称为 Direct Memory Access，即直接内存访问。意思是外设对内存的读写过程可以不用 CPU 参与而直接进行。我们先来看一下没有 DMA 的时候：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/20240114203040-2024-01-14.png"
alt="无 DMA 控制器时 I/O 设备和内存间的数据路径" width="auto"/>&lt;figcaption>
&lt;h4>无 DMA 控制器时 I/O 设备和内存间的数据路径&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>假设 I/O 设备为一个普通网卡，为了从内存拿到需要发送的数据，然后组装数据包发送到物理链路上，网卡需要通过总线告知 CPU 自己的数据请求。然后 CPU 将会把内存缓冲区中的数据复制到自己内部的寄存器中，再复制到 I/O 设备的存储空间中。如果数据量比较大，那么很长一段时间内 CPU 都会忙于搬移数据，而无法投入到其他工作中去。&lt;/p>
&lt;p>CPU 的最主要工作是计算，而不是进行数据复制，这种工作属于白白浪费了它的计算能力。为了给 CPU“减负”，让它投入到更有意义的工作中去，后来人们设计了 DMA 机制：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/20240114203114-2024-01-14.png"
alt="有 DMA 控制器时 I/O 设备和内存间的数据路径" width="auto"/>&lt;figcaption>
&lt;h4>有 DMA 控制器时 I/O 设备和内存间的数据路径&lt;/h4>
&lt;/figcaption>
&lt;/figure>
&lt;p>可以看到总线上又挂了一个 DMA 控制器，它是专门用来读写内存的设备。有了它以后，当我们的网卡想要从内存中拷贝数据时，除了一些必要的控制命令外，整个数据复制过程都是由 DMA 控制器完成的。过程跟 CPU 复制是一样的，只不过这次是把内存中的数据通过总线复制到 DMA 控制器内部的寄存器中，再复制到 I/O 设备的存储空间中。CPU 除了关注一下这个过程的开始和结束以外，其他时间可以去做其他事情。&lt;/p>
&lt;p>DMA 控制器一般是和 I/O 设备在一起的，也就是说一块网卡中既有负责数据收发的模块，也有 DMA 模块。&lt;/p>
&lt;h2 id="什么是-rdma">什么是 RDMA&lt;/h2>
&lt;p>RDMA（ Remote Direct Memory Access ）意为远程直接地址访问，通过 RDMA，本端节点可以“直接”访问远端节点的内存。所谓直接，指的是可以像访问本地内存一样，绕过传统以太网复杂的 TCP/IP 网络协议栈读写远端内存，而这个过程对端是不感知的，而且这个读写过程的大部分工作是由硬件而不是软件完成的。&lt;/p>
&lt;p>为了能够直观的理解这一过程，请看下面两个图（图中箭头仅做示意，不表示实际逻辑或物理关系）：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/20240115235555-2024-01-15.png"
alt="20240115235555-2024-01-15" width="90%" loading="lazy"/>
&lt;/figure>
&lt;p>传统网络中，“节点 A 给节点 B 发消息”实际上做的是“把节点 A 内存中的一段数据，通过网络链路搬移到节点 B 的内存中”，而这一过程无论是发端还是收段，都需要 CPU 的指挥和控制，包括网卡的控制，中断的处理，报文的封装和解析等等。&lt;/p>
&lt;p>上图中左边的节点在内存用户空间中的数据，需要经过 CPU 拷贝到内核空间的缓冲区中，然后才可以被网卡访问，这期间数据会经过软件实现的 TCP/IP 协议栈，加上各层头部和校验码，比如 TCP 头，IP 头等。网卡通过 DMA 拷贝内核中的数据到网卡内部的缓冲区中，进行处理后通过物理链路发送给对端。&lt;/p>
&lt;p>对端收到数据后，会进行相反的过程：从网卡内部存储空间，将数据通过 DMA 拷贝到内存内核空间的缓冲区中，然后 CPU 会通过 TCP/IP 协议栈对其进行解析，将数据取出来拷贝到用户空间中。&lt;/p>
&lt;p>可以看到，即使有了 DMA 技术，上述过程还是对 CPU 有较强的依赖。&lt;/p>
&lt;p>而使用了 RDMA 技术之后，这一过程可以简单的表示成下面的示意图：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/20240115235612-2024-01-15.png"
alt="20240115235612-2024-01-15" width="90%" loading="lazy"/>
&lt;/figure>
&lt;p>同样是把本端内存中的一段数据，复制到对端内存中，在使用了 RDMA 技术时，两端的 CPU 几乎不用参与数据传输过程（只参与控制面）。本端的网卡直接从内存的用户空间 DMA 拷贝数据到内部存储空间，然后硬件进行各层报文的组装后，通过物理链路发送到对端网卡。对端的 RDMA 网卡收到数据后，剥离各层报文头和校验码，通过 DMA 将数据直接拷贝到用户空间内存中。&lt;/p>
&lt;h2 id="rdma-的优势">RDMA 的优势&lt;/h2>
&lt;p>RDMA 主要应用在高性能计算（HPC）领域和大型数据中心当中，并且设备相对普通以太网卡要昂贵不少（比如 Mellanox 公司的 Connext-X 5 100Gb PCIe 网卡市价在 4000 元以上）。由于使用场景和价格的原因，RDMA 与普通开发者和消费者的距离较远，目前主要是一些大型互联网企业在部署和使用。&lt;/p>
&lt;p>RDMA 技术为什么可以应用在上述场景中呢？这就涉及到它的以下几个特点：&lt;/p>
&lt;ul>
&lt;li>0 拷贝：指的是不需要在用户空间和内核空间中来回复制数据。&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/20240115235643-2024-01-15.png"
alt="20240115235643-2024-01-15" width="60%" loading="lazy"/>
&lt;/figure>
&lt;p>由于 Linux 等操作系统将内存划分为用户空间和内核空间，在传统的 Socket 通信流程中 CPU 需要多次把数据在内存中来回拷贝。而通过 RDMA 技术，我们可以直接访问远端已经注册的内存区域。&lt;/p>
&lt;p>关于 0 拷贝可以参考这篇文章：&lt;a class="link" href="https://www.jianshu.com/p/e76e3580e356" target="_blank" rel="noopener"
>浅谈 Linux 下的零拷贝机制&lt;/a>&lt;/p>
&lt;ul>
&lt;li>内核 Bypass：指的是 IO（数据）流程可以绕过内核，即在用户层就可以把数据准备好并通知硬件准备发送和接收。避免了系统调用和上下文切换的开销。&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/20240115235721-2024-01-15.png"
alt="20240115235721-2024-01-15" width="90%" loading="lazy"/>
&lt;/figure>
&lt;p>上图（原图&lt;a class="link" href="https://pc.nanog.org/static/published/meetings/NANOG76/1999/20190612_Cardona_Towards_Hyperscale_High_v1.pdf" target="_blank" rel="noopener"
>[1]&lt;/a>）可以很好的解释“0 拷贝”和“内核 Bypass”的含义。上下两部分分别是基于 Socket 的和基于 RDMA 的一次收-发流程，左右分别为两个节点。可以明显的看到 Socket 流程中在软件中多了一次拷贝动作。而 RDMA 绕过了内核同时也减少了内存拷贝，数据可以直接在用户层和硬件间传递。&lt;/p>
&lt;ul>
&lt;li>CPU 卸载：指的是可以在远端节点 CPU 不参与通信的情况下（当然要持有访问远端某段内存的“钥匙”才行）对内存进行读写，这实际上是 &lt;strong>把报文封装和解析放到硬件中做了&lt;/strong>。而传统的以太网通信，双方 CPU 都必须参与各层报文的解析，如果数据量大且交互频繁，对 CPU 来讲将是一笔不小的开销，而这些被占用的 CPU 计算资源本可以做一些更有价值的工作。&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/20240115235929-2024-01-15.png"
alt="20240115235929-2024-01-15" width="60%" loading="lazy"/>
&lt;/figure>
&lt;p>通信领域两大出场率最高的性能指标就是“带宽”和“时延”。简单的说，所谓带宽指的是指单位时间内能够传输的数据量，而时延指的是数据从本端发出到被对端接收所耗费的时间。因为上述几个特点，相比于传统以太网，RDMA 技术同时做到了更高带宽和更低时延，所以其在带宽敏感的场景——比如海量数据的交互，时延敏感——比如多个计算节点间的数据同步的场景下得以发挥其作用。&lt;/p>
&lt;h2 id="协议">协议&lt;/h2>
&lt;p>RDMA 本身指的是一种技术，具体协议层面，包含 Infiniband（IB），RDMA over Converged Ethernet（RoCE）和 internet Wide Area RDMA Protocol（iWARP）。三种协议都符合 RDMA 标准，使用相同的上层接口，在不同层次上有一些差别。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/20240116000000-2024-01-16.png"
alt="20240116000000-2024-01-16" width="90%" loading="lazy"/>
&lt;/figure>
&lt;p>上图&lt;a class="link" href="https://www.snia.org/sites/default/files/ESF/RoCE-vs.-iWARP-Final.pdf" target="_blank" rel="noopener"
>[2]g&lt;/a>对于几种常见的 RDMA 技术的协议层次做了非常清晰的对比&lt;/p>
&lt;h3 id="infiniband">Infiniband&lt;/h3>
&lt;p>2000 年由 IBTA（InfiniBand Trade Association）提出的 IB 协议是当之无愧的核心，其规定了一整套完整的链路层到传输层（非传统 OSI 七层模型的传输层，而是位于其之上）规范，但是其无法兼容现有以太网，除了需要支持 IB 的网卡之外，企业如果想部署的话还要重新购买配套的交换设备。&lt;/p>
&lt;h3 id="roce">RoCE&lt;/h3>
&lt;p>RoCE 从英文全称就可以看出它是基于以太网链路层的协议，v1 版本网络层仍然使用了 IB 规范，而 v2 使用了 UDP+IP 作为网络层，使得数据包也可以被路由。RoCE 可以被认为是 IB 的“低成本解决方案”，将 IB 的报文封装成以太网包进行收发。由于 RoCE v2 可以使用以太网的交换设备，所以现在在企业中应用也比较多，但是相同场景下相比 IB 性能要有一些损失。&lt;/p>
&lt;h3 id="iwarp">iWARP&lt;/h3>
&lt;p>iWARP 协议是 IETF 基于 TCP 提出的，因为 TCP 是面向连接的可靠协议，这使得 iWARP 在面对有损网络场景（可以理解为网络环境中可能经常出现丢包）时相比于 RoCE v2 和 IB 具有更好的可靠性，在大规模组网时也有明显的优势。但是大量的 TCP 连接会耗费很多的内存资源，另外 TCP 复杂的流控等机制会导致性能问题，所以从性能上看 iWARP 要比 UDP 的 RoCE v2 和 IB 差。&lt;/p>
&lt;p>需要注意的是，虽然有软件实现的 RoCE 和 iWARP 协议，但是真正商用时上述几种协议都需要专门的硬件（网卡）支持。&lt;/p>
&lt;p>iWARP 本身不是由 Infiniband 直接发展而来的，但是它继承了一些 Infiniband 技术的设计思想。这三种协议的关系如下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/20240116000125-2024-01-16.png"
alt="20240116000125-2024-01-16" width="60%" loading="lazy"/>
&lt;/figure>
&lt;h2 id="玩家">玩家&lt;/h2>
&lt;h3 id="标准生态组织">标准/生态组织&lt;/h3>
&lt;p>提到 IB 协议，就不得不提到两大组织——IBTA 和 OFA。&lt;/p>
&lt;h3 id="ibta3httpswwwinfinibandtaorg">IBTA&lt;a class="link" href="https://www.infinibandta.org/" target="_blank" rel="noopener"
>[3]&lt;/a>&lt;/h3>
&lt;p>成立于 1999 年，负责制定和维护 Infiniband 协议标准。IBTA 独立于各个厂商，通过赞助技术活动和推动资源共享来将整个行业整合在一起，并且通过线上交流、营销和线下活动等方式积极推广 IB 和 RoCE。&lt;/p>
&lt;p>IBTA 会对商用的 IB 和 RoCE 设备进行协议标准符合性和互操作性测试及认证，由很多大型的 IT 厂商组成的委员会领导，其主要成员包括博通，HPE，IBM，英特尔，Mellanox 和微软等，华为也是 IBTA 的会员。&lt;/p>
&lt;h3 id="ofa4httpswwwopenfabricsorg">OFA&lt;a class="link" href="https://www.openfabrics.org/" target="_blank" rel="noopener"
>[4]&lt;/a>&lt;/h3>
&lt;p>成立于 2004 年的非盈利组织，负责开发、测试、认证、支持和分发独立于厂商的开源跨平台 infiniband 协议栈，2010 年开始支持 RoCE。其对用于支撑 RDMA/Kernel bypass 应用的 OFED（OpenFabrics Enterprise Distribution）软件栈负责，保证其与主流软硬件的兼容性和易用性。OFED 软件栈包括驱动、内核、中间件和 API。&lt;/p>
&lt;p>上述两个组织是配合关系，IBTA 主要负责开发、维护和增强 Infiniband 协议标准；OFA 负责开发和维护 Infiniband 协议和上层应用 API。&lt;/p>
&lt;h2 id="开发社区">开发社区&lt;/h2>
&lt;h3 id="linux-社区">Linux 社区&lt;/h3>
&lt;p>Linux 内核的 RDMA 子系统还算比较活跃，经常会讨论一些协议细节，对框架的修改比较频繁，另外包括华为和 Mellanox 在内的一些厂商也会经常对驱动代码进行修改。&lt;/p>
&lt;p>邮件订阅：&lt;a class="link" href="http://vger.kernel.org/vger-lists.html#linux-rdma" target="_blank" rel="noopener"
>http://vger.kernel.org/vger-lists.html#linux-rdma&lt;/a>&lt;/p>
&lt;p>代码位于内核 drivers/infiniband/目录下，包括框架核心代码和各厂商的驱动代码。&lt;/p>
&lt;p>代码仓：&lt;a class="link" href="https://git.kernel.org/pub/scm/linux/kernel/git/rdma/rdma.git/" target="_blank" rel="noopener"
>https://git.kernel.org/pub/scm/linux/kernel/git/rdma/rdma.git/&lt;/a>&lt;/p>
&lt;h3 id="rdma-社区">RDMA 社区&lt;/h3>
&lt;p>对于上层用户，IB 提供了一套与 Socket 套接字类似的接口——libibverbs，前文所述三种协议都可以使用。参考着协议、API 文档和示例程序很容易就可以写一个 Demo 出来。本专栏中的 RDMA 社区专指其用户态社区，在 github 上其仓库的名字为 linux-rdma。&lt;/p>
&lt;p>主要包含两个子仓库：&lt;/p>
&lt;ul>
&lt;li>rdma-core&lt;/li>
&lt;/ul>
&lt;p>用户态核心代码，API，文档以及各个厂商的用户态驱动。&lt;/p>
&lt;ul>
&lt;li>perftest
一个功能强大的用于测试 RDMA 性能的工具。&lt;/li>
&lt;/ul>
&lt;p>代码仓：&lt;a class="link" href="https://github.com/linux-rdma/" target="_blank" rel="noopener"
>https://github.com/linux-rdma/&lt;/a>&lt;/p>
&lt;h2 id="ucx5httpswwwopenucxorg">UCX&lt;a class="link" href="https://www.openucx.org/" target="_blank" rel="noopener"
>[5]&lt;/a>&lt;/h2>
&lt;p>UCX 是一个建立在 RDMA 等技术之上的用于数据处理和高性能计算的通信框架，RDMA 是其底层核心之一。我们可以将其理解为是位于应用和 RDMA API 之间的中间件，向上层用户又封装了一层更易开发的接口。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/20240116000429-2024-01-16.png"
alt="20240116000429-2024-01-16" width="90%" loading="lazy"/>
&lt;/figure>
&lt;p>笔者对其并不了解太多，只知道业界有一些企业在基于 UCX 开发应用。&lt;/p>
&lt;p>代码仓：&lt;a class="link" href="https://github.com/openucx/ucx" target="_blank" rel="noopener"
>https://github.com/openucx/ucx&lt;/a>&lt;/p>
&lt;h2 id="硬件厂商">硬件厂商&lt;/h2>
&lt;p>设计和生产 IB 相关硬件的厂商有不少，包括 Mellanox、华为、收购了 Qlogic 的 IB 技术的 Intel，博通、Marvell，富士通等等，这里就不逐个展开了，仅简单提一下 Mellanox 和华为。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Mellanox
IB 领域的领头羊，协议标准制定、软硬件开发和生态建设都能看到 Mellanox 的身影，其在社区和标准制定上上拥有最大的话语权。目前最新一代的网卡是支持 200Gb/s 的 ConnextX-6 系列。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>华为
去年初推出的鲲鹏 920 芯片已经支持 100Gb/s 的 RoCE 协议，技术上在国内处于领先地位。但是软硬件和影响力方面距离 Mellanox 还有比较长的路要走，相信华为能够早日赶上老大哥的步伐。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="用户">用户&lt;/h2>
&lt;p>微软、IBM 和国内的阿里、京东都正在使用 RDMA，另外还有很多大型 IT 公司在做初步的开发和测试。在数据中心和高性能计算场景下，RDMA 代替传统网络是大势所趋。笔者对于市场接触不多，所以并不能提供更详细的应用情况。&lt;/p>
&lt;p>下一篇将用比较直观的方式比较一次典型的基于 Socket 的传统以太网和 RDMA 通信过程。&lt;/p></description></item><item><title>在 HPC 上运行 Apache Spark</title><link>https://cuterwrite.top/p/run-spark-on-hpc/</link><pubDate>Sat, 30 Dec 2023 01:00:00 +0000</pubDate><guid>https://cuterwrite.top/p/run-spark-on-hpc/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/crop_afb480a4096d16305dc5696f8072d0c0195413.jpg@1256w_2094h_!web-article-pic-2023-12-30.webp" alt="Featured image of post 在 HPC 上运行 Apache Spark" />&lt;h1 id="在-hpc-上运行-apache-spark">在 HPC 上运行 Apache Spark&lt;/h1>
&lt;h2 id="一概述">一、概述&lt;/h2>
&lt;p>&lt;a class="link" href="https://spark.apache.org/" target="_blank" rel="noopener"
>Apache Spark&lt;/a> 是一个多语言引擎，用于在单节点机器或集群上执行数据工程、数据科学和机器学习任务。本文将为您提供在高性能计算（HPC）集群系统上运行多节点 Spark 集群的指南，并展示一个使用 PySpark 的作业示例。&lt;/p>
&lt;h2 id="二开始">二、开始&lt;/h2>
&lt;h3 id="1-下载-openjdk-1102">1. 下载 OpenJDK-11.0.2&lt;/h3>
&lt;p>从 &lt;a class="link" href="https://jdk.java.net/archive/" target="_blank" rel="noopener"
>OpenJDK 官方网站&lt;/a> 下载 OpenJDK-11.0.2。选择 Linux 的对应版本并下载。解压下载的文件并将其放置在 &lt;code>${HOME}/software/openjdk&lt;/code> 中并重命名为 &lt;code>11.0.2&lt;/code> 。&lt;/p>
&lt;h3 id="2-下载-spark-342">2. 下载 Spark-3.4.2&lt;/h3>
&lt;p>从 &lt;a class="link" href="https://spark.apache.org/downloads.html" target="_blank" rel="noopener"
>Apache Spark 下载页面&lt;/a> 下载 Spark 。本文使用的是 Spark-3.4.2，但本指南应该也适用于更新的版本。解压下载的文件并将目录重命名为 3.4.2，放置在 ${HOME}/software/spark 文件夹中。&lt;/p>
&lt;h3 id="3-配置-modulefile">3. 配置 modulefile&lt;/h3>
&lt;p>在自定义目录中安装软件后，需要将软件的可执行文件路径等添加到相应的环境变量中才能使用。&lt;code>module&lt;/code> 是一款环境变量管理工具，通过 &lt;code>module&lt;/code> 实现软件环境变量的管理，快速加载和切换软件环境。集群中安装了一些常用的软件和库，可以通过 &lt;code>module&lt;/code> 进行加载使用。&lt;/p>
&lt;p>在这里，我们需要编写 &lt;code>modulefile&lt;/code> 来管理自己的 JDK 和 Spark 软件环境，以便快速加载 Java 和 Spark 环境。&lt;/p>
&lt;ul>
&lt;li>在 &lt;code>${HOME}/modulefiles/openjdk&lt;/code> 中创建名为 &lt;code>11.0.2&lt;/code> 的文本文件，内容为：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">&lt;span class="c1">#%Module1.0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">##&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">## openjdk modulefile&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">##&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">proc ModulesHelp &lt;span class="o">{&lt;/span> &lt;span class="o">}&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> puts stderr &lt;span class="s2">&amp;#34;This module sets up the environment for OpenJdk 11.0.2 \n&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">module-whatis &lt;span class="s2">&amp;#34;For more information, \$ module help openjdk/11.0.2\n&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">conflict openjdk
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 注意！这里需要进行修改&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">set&lt;/span> root &amp;lt;PATH/WHERE/OPENJDK/DIRECTORY/IS&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">prepend-path PATH &lt;span class="si">${&lt;/span>&lt;span class="nv">root&lt;/span>&lt;span class="si">}&lt;/span>/bin
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>在 &lt;code>${HOME}/modulefiles/spark&lt;/code> 中创建名为 &lt;code>3.4.2&lt;/code> 的文本文件， 内容为：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">&lt;span class="c1">#%Module1.0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">##&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">## spark modulefile&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">##&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">proc ModulesHelp &lt;span class="o">{&lt;/span> &lt;span class="o">}&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> global version
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> puts stderr &lt;span class="s2">&amp;#34;This module loads Apache Spark environment variables and updates the PATH.&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> puts stderr &lt;span class="s2">&amp;#34; &amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> puts stderr &lt;span class="s2">&amp;#34;Version: &lt;/span>&lt;span class="nv">$version&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">module-whatis &lt;span class="s2">&amp;#34;Loads Apache Spark environment variables and updates the PATH. \n For more information, \$ module help spark/3.4.2 .\n&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">conflict spark
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Set the version and installation path&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">set&lt;/span> version 3.4.2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 注意！这里需要进行修改&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">set&lt;/span> root &amp;lt;PATH/WHERE/SPARK/DIRECTORY/IS&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Set the environment variables&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">setenv SPARK_HOME &lt;span class="si">${&lt;/span>&lt;span class="nv">root&lt;/span>&lt;span class="si">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">setenv SPARK_CONF_DIR &lt;span class="si">${&lt;/span>&lt;span class="nv">root&lt;/span>&lt;span class="si">}&lt;/span>/conf
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">setenv PYSPARK_PYTHON python3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Update the PATH&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">prepend-path PATH &lt;span class="si">${&lt;/span>&lt;span class="nv">root&lt;/span>&lt;span class="si">}&lt;/span>/bin
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">prepend-path PATH &lt;span class="si">${&lt;/span>&lt;span class="nv">root&lt;/span>&lt;span class="si">}&lt;/span>/sbin
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Update the CLASSPATH&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">prepend-path CLASSPATH &lt;span class="si">${&lt;/span>&lt;span class="nv">root&lt;/span>&lt;span class="si">}&lt;/span>/jars/*
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="4-使用-pip-安装-pyspark-库">4. 使用 pip 安装 pyspark 库&lt;/h3>
&lt;ul>
&lt;li>创建虚拟 Conda 环境 pyspark&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">conda create -n pyspark &lt;span class="nv">python&lt;/span>&lt;span class="o">=&lt;/span>3.10
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>安装 pyspark&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">conda activate pyspark
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">pip install pyspark
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="5-编写环境加载脚本-set-spark-envsh">5. 编写环境加载脚本 set-spark-env.sh&lt;/h3>
&lt;ul>
&lt;li>在 &lt;code>${HOME}/scripts&lt;/code> 目录下编写 &lt;code>set-spark-env.sh&lt;/code> 脚本文件：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#!/bin/bash
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">source&lt;/span> /etc/profile
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 注意！这里需要修改为你的 Conda 的安装路径&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">CONDA_PATH&lt;/span>&lt;span class="o">=&lt;/span>&amp;lt;PATH/WHERE/CONDA/DIRECTORY/IS&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">PATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">$CONDA_PATH&lt;/span>/bin:&lt;span class="nv">$PATH&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">MODULEPATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="si">${&lt;/span>&lt;span class="nv">HOME&lt;/span>&lt;span class="si">}&lt;/span>/modulefiles:&lt;span class="nv">$MODULEPATH&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">source&lt;/span> activate
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">conda activate pyspark
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">module load openjdk
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">module load spark
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="6-编写-sbatch-脚本">6. 编写 sbatch 脚本&lt;/h3>
&lt;ul>
&lt;li>为了启动 Spark 集群，我们使用以下 Slurm 脚本来请求计算节点。Slurm 脚本请求四个节点，并生成一个 master 节点和三个 worker 节点的 Spark 集群。可以通过更改 Slurm 脚本中的 &lt;code>-N&lt;/code> 选项的值来增加或减少工作节点的数量。&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#!/bin/bash
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">&lt;/span>&lt;span class="c1">#SBATCH --export=ALL&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">#SBATCH --mem=0&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">#SBATCH -p C28M250G&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">#SBATCH -t 1:00:00&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">#SBATCH -N 4&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">#SBATCH -J spark_test&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">#SBATCH -o o.spark_test&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">#SBATCH -e e.spark_test&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">source&lt;/span> ~/scripts/set-spark-env.sh
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">workdir&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="sb">`&lt;/span>&lt;span class="nb">pwd&lt;/span>&lt;span class="sb">`&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">nodes&lt;/span>&lt;span class="o">=(&lt;/span>&lt;span class="k">$(&lt;/span>scontrol show hostnames &lt;span class="si">${&lt;/span>&lt;span class="nv">SLURM_JOB_NODELIST&lt;/span>&lt;span class="si">}&lt;/span> &lt;span class="p">|&lt;/span> sort &lt;span class="p">|&lt;/span> uniq &lt;span class="k">)&lt;/span>&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">numnodes&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="si">${#&lt;/span>&lt;span class="nv">nodes&lt;/span>&lt;span class="p">[@]&lt;/span>&lt;span class="si">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">last&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="k">$((&lt;/span> &lt;span class="nv">$numnodes&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="m">1&lt;/span> &lt;span class="k">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">SCRATCH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="si">${&lt;/span>&lt;span class="nv">workdir&lt;/span>&lt;span class="si">}&lt;/span>/scratch
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">master&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="si">${&lt;/span>&lt;span class="nv">nodes&lt;/span>&lt;span class="p">[0]&lt;/span>&lt;span class="si">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">masterurl&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;spark://&lt;/span>&lt;span class="si">${&lt;/span>&lt;span class="nv">master&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">:7077&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ssh &lt;span class="si">${&lt;/span>&lt;span class="nv">nodes&lt;/span>&lt;span class="p">[0]&lt;/span>&lt;span class="si">}&lt;/span> &lt;span class="s2">&amp;#34;source ~/scripts/set-spark-env.sh; start-master.sh&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> i in &lt;span class="k">$(&lt;/span> seq &lt;span class="m">1&lt;/span> &lt;span class="nv">$last&lt;/span> &lt;span class="k">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">do&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ssh &lt;span class="si">${&lt;/span>&lt;span class="nv">nodes&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="nv">$i&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="si">}&lt;/span> &lt;span class="s2">&amp;#34;source ~/scripts/set-spark-env.sh; start-worker.sh &lt;/span>&lt;span class="si">${&lt;/span>&lt;span class="nv">masterurl&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">done&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ssh &lt;span class="si">${&lt;/span>&lt;span class="nv">nodes&lt;/span>&lt;span class="p">[0]&lt;/span>&lt;span class="si">}&lt;/span> &lt;span class="s2">&amp;#34;cd &lt;/span>&lt;span class="si">${&lt;/span>&lt;span class="nv">workdir&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="s2">; source ~/scripts/set-spark-env.sh; /usr/bin/time -v spark-submit --deploy-mode client --executor-cores 28 --executor-memory 240G --conf spark.standalone.submit.waitAppCompletion=true --master &lt;/span>&lt;span class="nv">$masterurl&lt;/span>&lt;span class="s2"> spark_test.py&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">wait&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">echo&lt;/span> &lt;span class="s1">&amp;#39;end&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">exit&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>该 Slurm 脚本会提交一个用于测试的 python 脚本（ &lt;code>spark_test.py&lt;/code> ），内容如下。此脚本运行 PySpark 代码来测试 Spark 集群。复制下面的内容，并将其保存在 sbatch 脚本所在目录中的 &lt;code>spark_test.py&lt;/code> 文件。你也可以更改 &lt;code>spark_test.py&lt;/code> 文件的路径，但必须适当地更新 Slurm 脚本。&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-py" data-lang="py">&lt;span class="line">&lt;span class="cl">&lt;span class="c1">#spark_test.py&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">random&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">from&lt;/span> &lt;span class="nn">pyspark.sql&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">SparkSession&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kn">import&lt;/span> &lt;span class="nn">pyspark.sql.functions&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">F&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">spark&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">SparkSession&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">builder&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">appName&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;Test-app&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">getOrCreate&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">#Generate sample dataset&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">cola_list&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;2022-01-01&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;2022-01-02&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;2022-01-03&amp;#39;&lt;/span> &lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">colb_list&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;CSC&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;PHY&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;MAT&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;ENG&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;CHE&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;ENV&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;BIO&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;PHRM&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">colc_list&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="mi">100&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">200&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">300&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">400&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">500&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">600&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">700&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">800&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">900&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># declaring a random.seed value to generate same data in every run&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">random&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">seed&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">sample_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">idx&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1000&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">sample_data&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">random&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">choice&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">cola_list&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">random&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">choice&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">colb_list&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">random&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">choice&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">colc_list&lt;/span>&lt;span class="p">)])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">columns&lt;/span>&lt;span class="o">=&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;date&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;org&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;value&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">#creating a Spark dataframe&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">df&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">spark&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">createDataFrame&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">sample_data&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">schema&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">columns&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">res&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">df&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">groupBy&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;date&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="s1">&amp;#39;org&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">.&lt;/span>&lt;span class="n">agg&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">F&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">count&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;value&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">alias&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;count_value&amp;#39;&lt;/span>&lt;span class="p">)))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">res&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">show&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>如果启动了 Spark 集群并且 &lt;code>spark-test.py&lt;/code> 成功执行，那么日志文件 &lt;code>o.spark_test&lt;/code> 中的输出应该如下：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">starting org.apache.spark.deploy.master.Master, logging to ...
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">starting org.apache.spark.deploy.worker.Worker, logging to ...
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">starting org.apache.spark.deploy.worker.Worker, logging to ...
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">starting org.apache.spark.deploy.worker.Worker, logging to ...
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">+----------+----+-----------+
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">| date| org|count_value|
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">+----------+----+-----------+
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">|2022-01-03| BIO| 37|
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">|2022-01-02| ENV| 53|
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">|2022-01-03| CHE| 39|
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">|2022-01-03| PHY| 46|
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">|2022-01-01| CSC| 45|
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">|2022-01-03| CSC| 48|
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">|2022-01-01| BIO| 39|
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">|2022-01-01| MAT| 42|
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">|2022-01-02| CHE| 44|
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">|2022-01-03| ENV| 33|
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">|2022-01-01| ENG| 33|
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">|2022-01-02| ENG| 28|
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">|2022-01-01| ENV| 33|
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">|2022-01-02| CSC| 45|
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">|2022-01-02| MAT| 51|
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">|2022-01-01| PHY| 38|
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">|2022-01-01|PHRM| 40|
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">|2022-01-03|PHRM| 42|
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">|2022-01-02|PHRM| 43|
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">|2022-01-03| ENG| 56|
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">+----------+----+-----------+
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">only showing top 20 rows
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">end
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>Spark 还提供了一个 web UI 来监控集群，您可以通过将 master 节点端口转发到本地机器来在本地机器上访问它。
&lt;ul>
&lt;li>例如，如果 master 节点在 &lt;code>cpu1&lt;/code> 上运行，则可以在本地计算机终端上运行以下代码。&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-cmd" data-lang="cmd">&lt;span class="line">&lt;span class="cl"> ssh -t -t &lt;span class="p">&amp;lt;&lt;/span>USERNAME&lt;span class="p">&amp;gt;&lt;/span>@&lt;span class="p">&amp;lt;&lt;/span>LOGIN_NODE_IP&lt;span class="p">&amp;gt;&lt;/span> -L 8080:localhost:8080 \
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> -i &lt;span class="p">&amp;lt;&lt;/span>PRIVATE_KEY_LOCATION&lt;span class="p">&amp;gt;&lt;/span> ssh cpu1 -L 8080:127.0.0.1:8080
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>然后就可以在本地机器上的 Web 浏览器上使用地址 &lt;a class="link" href="http://localhost:8080/" target="_blank" rel="noopener"
>http://localhost:8080/&lt;/a> 访问 Spark Web UI。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="三总结">三、总结&lt;/h2>
&lt;p>在本文中，我们介绍了如何在 HPC 集群上部署和运行 Apache Spark 集群。通过遵循本指南中的步骤，你应该能够成功地在 HPC 环境中运行 Spark 作业。请注意，根据你的具体 HPC 环境和配置，可能需要进行一些调整。&lt;/p>
&lt;div class="notice notice-note" >
&lt;div class="notice-title">&lt;svg t="1705946198814" class="icon notice-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="23141" width="200" height="200">&lt;path d="M195.541333 739.029333C151.594667 692.352 128 640 128 555.136c0-149.333333 104.832-283.178667 257.28-349.354667l38.101333 58.794667c-142.293333 76.970667-170.112 176.853333-181.205333 239.829333 22.912-11.861333 52.906667-16 82.304-13.269333 76.970667 7.125333 137.642667 70.314667 137.642667 148.864a149.333333 149.333333 0 0 1-149.333334 149.333333 165.162667 165.162667 0 0 1-117.248-50.304z m426.666667 0C578.261333 692.352 554.666667 640 554.666667 555.136c0-149.333333 104.832-283.178667 257.28-349.354667l38.101333 58.794667c-142.293333 76.970667-170.112 176.853333-181.205333 239.829333 22.912-11.861333 52.906667-16 82.304-13.269333 76.970667 7.125333 137.642667 70.314667 137.642666 148.864a149.333333 149.333333 0 0 1-149.333333 149.333333 165.162667 165.162667 0 0 1-117.248-50.304z" p-id="23142" fill="#ffffff">&lt;/path>&lt;/svg>&lt;/div>&lt;p>&lt;a class="link" href="https://spark.apache.org/docs/latest/" target="_blank" rel="noopener"
>Spark 官方文档&lt;/a> 是一个非常有用的工具，通过它可以帮助你找到 Spark 的具体说明并解决问题。所以实际遇到问题时要多使用它。&lt;/p>&lt;/div></description></item><item><title>性能刺客之伪共享</title><link>https://cuterwrite.top/p/false-sharing/</link><pubDate>Sat, 02 Dec 2023 00:00:00 +0000</pubDate><guid>https://cuterwrite.top/p/false-sharing/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/6c3f8961290e41f894f5a1cbb768aba9-2023-12-02.webp" alt="Featured image of post 性能刺客之伪共享" />&lt;h1 id="性能刺客之伪共享">性能刺客之伪共享&lt;/h1>
&lt;h2 id="一前言">一、前言&lt;/h2>
&lt;p>在多核并发编程中，如果将互斥锁的争用比作 &lt;strong>性能杀手&lt;/strong> 的话，那么伪共享则相当于 &lt;strong>性能刺客&lt;/strong>。&lt;strong>杀手&lt;/strong> 与 &lt;strong>刺客&lt;/strong> 的区别在于杀手是可见的，遇到杀手时我们可以选择战斗、逃跑、绕路、求饶等多种手段去应付，但 &lt;strong>刺客&lt;/strong> 却不同， &lt;strong>刺客&lt;/strong> 永远隐藏在暗处，伺机给你致命一击，防不胜防。具体到我们的并发编程中，遇到锁争用影响并发性能情况时，我们可以采取多种措施（如缩短临界区，原子操作等等）去提高程序性能，但是伪共享却是我们从所写代码中看不出任何蛛丝马迹的，发现不了问题也就无法解决问题，从而导致伪共享在暗处严重拖累程序的并发性能，但我们却束手无策。&lt;/p>
&lt;h2 id="二缓存行">二、缓存行&lt;/h2>
&lt;p>为了进行下面的讨论，我们需要首先熟悉缓存行的概念，学过操作系统课程存储结构这部分内容的同学应该对存储器层次结构的金字塔模型印象深刻，金字塔从上往下代表存储介质的成本降低、容量变大，从下往上则代表存取速度的提高。位于金字塔模型最上层的是 CPU 中的寄存器，其次是 CPU 缓存（L1，L2，L3），再往下是内存，最底层是磁盘，操作系统采用这种存储层次模型主要是为了解决 CPU 的高速与内存磁盘低速之间的矛盾，CPU 将最近使用的数据预先读取到 Cache 中，下次再访问同样数据的时候，可以直接从速度比较快的 CPU 缓存中读取，避免从内存或磁盘读取拖慢整体速度。&lt;/p>
&lt;p>CPU 缓存的最小单位就是缓存行，缓存行大小依据架构不同有不同大小，最常见的有 &lt;code>64Byte&lt;/code> 和 &lt;code>32Byte&lt;/code> ，CPU 缓存从内存取数据时以缓存行为单位进行，每一次都取需要读取数据所在的整个缓存行，即使相邻的数据没有被用到也会被缓存到 CPU 缓存中。&lt;/p>
&lt;h2 id="三缓存一致性">三、缓存一致性&lt;/h2>
&lt;p>在单核 CPU 情况下，上述方法可以正常工作，可以确保缓存到 CPU 缓存中的数据永远是 &lt;strong>干净&lt;/strong> 的，因为不会有其他 CPU 去更改内存中的数据，但是在多核 CPU 下，情况就变得更加复杂一些。多 CPU 中，每个 CPU 都有自己的私有缓存（可能共享 L3 缓存），当一个 CPU1 对 Cache 中缓存数据进行操作时，如果 CPU2 在此之前更改了该数据，则 CPU1 中的数据就不再是 &lt;strong>干净&lt;/strong> 的，即应该是失效数据，缓存一致性就是为了保证多 CPU 之间的缓存一致。&lt;/p>
&lt;p>Linux 系统中采用 &lt;code>MESI&lt;/code> 协议处理缓存一致性，所谓 &lt;code>MESI&lt;/code> 即是指 CPU 缓存的四种状态：&lt;/p>
&lt;ul>
&lt;li>M（修改，Modified）：本地处理器已经修改缓存行，即是脏行，它的内容与内存中的内容不一样，并且此 cache 只有本地一个拷贝(专有)；&lt;/li>
&lt;li>E（专有，Exclusive）：缓存行内容和内存中的一样，而且其它处理器都没有这行数据；&lt;/li>
&lt;li>S（共享，Shared）：缓存行内容和内存中的一样, 有可能其它处理器也存在此缓存行的拷贝；&lt;/li>
&lt;li>I（无效，Invalid）：缓存行失效, 不能使用。&lt;/li>
&lt;/ul>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20231202205445-2023-12-02.webp"
alt="20231202205445-2023-12-02" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>每个 CPU 缓存行都在四个状态之间互相转换，以此决定 CPU 缓存是否失效，比如 CPU1 对一个缓存行执行了写入操作，则此操作会导致其他 CPU 的该缓存行进入 Invalid 无效状态， CPU 需要使用该缓存行的时候需要从内存中重新读取。由此就解决了多 CPU 之间的缓存一致性问题。&lt;/p>
&lt;h2 id="四伪共享">四、伪共享&lt;/h2>
&lt;p>何谓伪共享？上面我们提过 CPU 的缓存是 &lt;strong>以缓存行为单位&lt;/strong> 进行的，即除了本身所需读写的数据之外还会缓存与该数据在同一缓存行的数据，假设缓存行大小是 32 字节，内存中有 &lt;code>abcdefgh&lt;/code> 八个 int 型数据，当 CPU 读取 &lt;code>d&lt;/code> 这个数据时， CPU 会将 &lt;code>abcdefgh&lt;/code> 八个 int 数据组成一个缓存行加入到 CPU 缓存中。假设计算机有两个 CPU：CPU1 和 CPU2 ， CPU1 只对 &lt;code>a&lt;/code> 这个数据进行频繁读写， CPU2 只对 &lt;code>b&lt;/code> 这个数据进行频繁读写，按理说这两个 CPU 读写数据没有任何关联，也就不会产生任何竞争，不会有性能问题，但是由于 CPU 缓存是以缓存行为单位进行存取的，也是以缓存行为单位失效的，即使 CPU1 只更改了缓存行中 &lt;code>a&lt;/code> 数据，也会导致 CPU2 中该缓存行完全失效，同理，CPU2 对&lt;code> b&lt;/code> 的改动也会导致 CPU1 中该缓存行失效，由此引发了该缓存行在两个 CPU 之间 &lt;strong>乒乓&lt;/strong> ，缓存行频繁失效，最终导致程序性能下降，这就是伪共享。&lt;/p>
&lt;p>下面是维基百科的定义：&lt;/p>
&lt;blockquote>
&lt;p>In computer science, &lt;strong>false sharing&lt;/strong> is a performance-degrading usage pattern that can arise in systems with distributed, coherent caches at the size of the smallest resource block managed by the caching mechanism. When a system participant attempts to periodically access data that is not being altered by another party, but that data shares a cache block with data that is being altered, the caching protocol may force the first participant to reload the whole cache block despite a lack of logical necessity. The caching system is unaware of activity within this block and forces the first participant to bear the caching system overhead required by true shared access of a resource.&lt;/p>
&lt;p>在计算机科学中，伪共享是一种性能降低的使用模式，可能出现在具有分布式、一致性缓存的系统中，缓存大小为缓存机制管理的最小资源块。当一个系统参与者试图定期访问未被其他方修改的数据，但该数据与正在被修改的数据共享一个缓存块时，缓存协议可能会强制第一个参与者重新加载整个缓存块，尽管在逻辑上没有必要。 缓存系统无法感知这个块内的活动，并强制第一个参与者承担由真正共享资源访问所需的缓存系统开销。&lt;/p>
&lt;/blockquote>
&lt;h2 id="五如何避免伪共享">五、如何避免伪共享&lt;/h2>
&lt;p>避免伪共享主要有以下两种方式：&lt;/p>
&lt;ul>
&lt;li>缓存行填充（Padding）：为了避免伪共享就需要将可能造成伪共享的多个变量处于不同的缓存行中，可以采用在变量后面填充字节的方式达到该目的。&lt;/li>
&lt;li>使用某些语言或编译器中强制变量对齐，将变量都对齐到缓存行大小，避免伪共享发生。&lt;/li>
&lt;/ul>
&lt;h2 id="六获取缓存行大小">六、获取缓存行大小&lt;/h2>
&lt;p>在 C++11 中，可以使用 &lt;code>std::hardware_destructive_interference_size&lt;/code> 和 &lt;code>std::hardware_constructive_interference_size&lt;/code> 获取缓存行大小，前者获取的是缓存行大小，后者获取的是缓存行大小的两倍，即 &lt;code>2 * std::hardware_destructive_interference_size&lt;/code>。&lt;/p>
&lt;p>在 C 语言中，可以读取 &lt;code>coherency_line_size&lt;/code> 文件获取缓存行大小，该文件位于 &lt;code>/sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size&lt;/code> ，该文件中存储的是缓存行大小的字节数，可以使用 &lt;code>cat&lt;/code> 命令查看。也可以通过 &lt;code>long cache_line_size = sysconf(_SC_LEVEL1_DCACHE_LINESIZE)&lt;/code> 的方式获取。&lt;/p>
&lt;h2 id="七通过对齐解决伪共享">七、通过对齐解决伪共享&lt;/h2>
&lt;p>C 语言中可以使用 &lt;code>posix_memalign&lt;/code> 函数来实现对齐，该函数的声明如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="kt">int&lt;/span> &lt;span class="nf">posix_memalign&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">void&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="n">memptr&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kt">size_t&lt;/span> &lt;span class="n">alignment&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kt">size_t&lt;/span> &lt;span class="n">size&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="总结">总结&lt;/h2>
&lt;p>一般伪共享都很隐蔽，很难被发现，当伪共享真正构成性能瓶颈的时候，我们有必要去努力找到并解决它，但是在大部分对性能追求没有那么高的应用中，伪共享的存在对程序的危害很小，有时并不值得耗费精力和额外的内存空间（缓存行填充）去查找系统存在的伪共享。还是那句我们一直以来应该遵循的原则 &lt;strong>“不要过度优化，不要提前优化。”&lt;/strong> 。&lt;/p>
&lt;h2 id="参考资料">参考资料&lt;/h2>
&lt;ul>
&lt;li>&lt;a class="link" href="https://zhuanlan.zhihu.com/p/37069591" target="_blank" rel="noopener"
>C++性能榨汁机之伪共享&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>NEST on HPC 安装教程</title><link>https://cuterwrite.top/p/nest-on-hpe-install/</link><pubDate>Mon, 30 Oct 2023 00:00:00 +0000</pubDate><guid>https://cuterwrite.top/p/nest-on-hpe-install/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20231031002508-2023-10-31.webp" alt="Featured image of post NEST on HPC 安装教程" />&lt;h1 id="nest-on-hpc-安装教程">NEST on HPC 安装教程&lt;/h1>
&lt;h2 id="1-安装-miniconda3">1. 安装 MiniConda3&lt;/h2>
&lt;p>从 &lt;a class="link" href="https://repo.anaconda.com/miniconda/Miniconda3-py39_23.5.2-0-Linux-x86_64.sh" target="_blank" rel="noopener"
>Miniconda3 官方网站&lt;/a> 下载 Miniconda3_py39_23.5.2 。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">wget https://repo.anaconda.com/miniconda/Miniconda3-py39_23.5.2-0-Linux-x86_64.sh
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>执行 Miniconda3-py39_23.5.2-0-Linux-x86_64.sh ，按照提示安装 Miniconda3。（安装在 &lt;code>$HOME/software/miniconda3/23.5.2&lt;/code> 目录下）&lt;/p>
&lt;p>然后，设置 Miniconda3 环境变量。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">PATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">$HOME&lt;/span>/software/miniconda3/23.5.2/bin:&lt;span class="nv">$PATH&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="2-安装-boost">2. 安装 Boost&lt;/h2>
&lt;p>从 &lt;a class="link" href="https://boostorg.jfrog.io/artifactory/main/release/1.77.0/source/boost_1_77_0.tar.gz" target="_blank" rel="noopener"
>Boost 官方网站&lt;/a> 下载 Boost。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">wget https://boostorg.jfrog.io/artifactory/main/release/1.77.0/source/boost_1_77_0.tar.gz
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">tar -zxvf boost_1_77_0.tar.gz
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">cd&lt;/span> boost_1_77_0
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>在 Boost 根目录下执行以下命令安装 Boost：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">module load gcc/8.4.0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">./bootstrap.sh --prefix&lt;span class="o">=&lt;/span>&lt;span class="nv">$HOME&lt;/span>/software/boost/1.77.0-gcc-8.4.0 &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span>&lt;span class="nv">CC&lt;/span>&lt;span class="o">=&lt;/span>gcc &lt;span class="nv">CXX&lt;/span>&lt;span class="o">=&lt;/span>g++ &lt;span class="nv">FC&lt;/span>&lt;span class="o">=&lt;/span>gfortran &lt;span class="nv">CFLAGS&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;-O3&amp;#39;&lt;/span> &lt;span class="nv">CXXFLAGS&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;-O3&amp;#39;&lt;/span> &lt;span class="nv">FCFLAGS&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;-O3&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>配置环境变量：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">BOOST_ROOT&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">$HOME&lt;/span>/software/boost/1.77.0-gcc-8.4.0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">LD_LIBRARY_PATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">$BOOST_ROOT&lt;/span>/lib:&lt;span class="nv">$LD_LIBRARY_PATH&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">LIBRARY_PATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">$BOOST_ROOT&lt;/span>/lib:&lt;span class="nv">$LIBRARY_PATH&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">CMAKE_PREFIX_PATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">$BOOST_ROOT&lt;/span>/lib/cmake:&lt;span class="nv">$CMAKE_PREFIX_PATH&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">CPATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">$BOOST_ROOT&lt;/span>/include:&lt;span class="nv">$CPATH&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">LD_RUN_PATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">$BOOST_ROOT&lt;/span>/lib:&lt;span class="nv">$LD_RUN_PATH&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="3-安装-gnu-scientific-library">3. 安装 GNU Scientific Library&lt;/h2>
&lt;p>从 &lt;a class="link" href="https://mirror.ibcp.fr/pub/gnu/gsl/gsl-latest.tar.gzz" target="_blank" rel="noopener"
>GNU Scientific Library 镜像站&lt;/a> 下载 GSL。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">wget https://mirror.ibcp.fr/pub/gnu/gsl/gsl-latest.tar.gz
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">tar -zxvf gsl-latest.tar.gz
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>在 GSL 根目录执行以下命令安装 GSL：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">module load gcc/8.4.0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">./configure --prefix&lt;span class="o">=&lt;/span>&lt;span class="nv">$HOME&lt;/span>/software/gsl/2.7.1-gcc-8.4.0 &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span>&lt;span class="nv">CC&lt;/span>&lt;span class="o">=&lt;/span>gcc &lt;span class="nv">CXX&lt;/span>&lt;span class="o">=&lt;/span>g++ &lt;span class="nv">FC&lt;/span>&lt;span class="o">=&lt;/span>gfortran &lt;span class="nv">CFLAGS&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;-O3&amp;#39;&lt;/span> &lt;span class="nv">CXXFLAGS&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;-O3&amp;#39;&lt;/span> &lt;span class="nv">FCFLAGS&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;-O3&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">make install
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>配置环境变量：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">GSL_ROOT&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">$HOME&lt;/span>/software/gsl/2.7.1-gcc-8.4.0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">LD_LIBRARY_PATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">$GSL_ROOT&lt;/span>/lib:&lt;span class="nv">$LD_LIBRARY_PATH&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">PATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">$GSL_ROOT&lt;/span>/bin:&lt;span class="nv">$PATH&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">CPATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">$GSL_ROOT&lt;/span>/include:&lt;span class="nv">$CPATH&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">LIBRARY_PATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">$GSL_ROOT&lt;/span>/lib:&lt;span class="nv">$LIBRARY_PATH&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">LD_RUN_PATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">$GSL_ROOT&lt;/span>/lib:&lt;span class="nv">$LD_RUN_PATH&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="4-安装-nest">4. 安装 NEST&lt;/h2>
&lt;p>使用 Miniconda3 创建一个虚拟环境。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">source&lt;/span> activate
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">conda create -n nest &lt;span class="nv">python&lt;/span>&lt;span class="o">=&lt;/span>3.9
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">conda activate nest
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>使用 pip 安装 numpy, scipy, cython==0.29.36&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">pip install numpy scipy &lt;span class="nv">cython&lt;/span>&lt;span class="o">==&lt;/span>0.29.36
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>从 &lt;a class="link" href="https://github.com/nest/nest-simulator/archive/refs/tags/v3.4.tar.gz" target="_blank" rel="noopener"
>NEST github 仓库&lt;/a> 下载 NEST 3.4。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">wget https://github.com/nest/nest-simulator/archive/refs/tags/v3.4.tar.gz
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">tar -zxvf v3.4.tar.gz
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>在 nest-simulator-3.4 目录下执行:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">module load gcc/8.4.0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">module load mvaapich2/2.3.7-gcc-8.4.0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">cmake -DCMAKE_C_COMPILER&lt;span class="o">=&lt;/span>mpicc &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> -DCMAKE_CXX_COMPILER&lt;span class="o">=&lt;/span>mpicxx &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> -Dwith-mpi&lt;span class="o">=&lt;/span>&lt;span class="sb">`&lt;/span>which mpiexec&lt;span class="sb">`&lt;/span> &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> -DCMAKE_C_FLAGS&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;-O3 -fPIC&amp;#39;&lt;/span> &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> -DCMAKE_CXX_FLAGS&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;-O3&amp;#39;&lt;/span> &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> -Dwith-boost&lt;span class="o">=&lt;/span>&lt;span class="nv">$HOME&lt;/span>/software/boost/1.77.0-gcc-8.4.0 &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> -DGSL_INCLUDE_DIR&lt;span class="o">=&lt;/span>&lt;span class="nv">$HOME&lt;/span>/software/gsl/2.7.1-gcc-8.4.0/include &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> -DGSL_LIBRARY&lt;span class="o">=&lt;/span>&lt;span class="nv">$HOME&lt;/span>/software/gsl/2.7.1-gcc-8.4.0/lib/libgsl.a &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> -DGSL_CBLAS_LIBRARY&lt;span class="o">=&lt;/span>&lt;span class="nv">$HOME&lt;/span>/software/gsl/2.7.1-gcc-8.4.0/lib/libgslcblas.a &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span> -DCMAKE_INSTALL_PREFIX:PATH&lt;span class="o">=&lt;/span>&lt;span class="nv">$HOME&lt;/span>/software/nest-simulator/3.4-gcc-8.4.0 .
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>配置环境变量：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">NEST_ROOT&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">$HOME&lt;/span>/software/nest-simulator/3.4-gcc-8.4.0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">LIBRARY_PATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">$NEST_ROOT&lt;/span>/lib:&lt;span class="nv">$LIBRARY_PATH&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">LD_LIBRARY_PATH&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="nv">$NEST_ROOT&lt;/span>/lib:&lt;span class="nv">$LD_LIBRARY_PATH&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="5-运行-hpc_benchmark-测试">5. 运行 hpc_benchmark 测试&lt;/h2>
&lt;p>运行 NEST 前需要配置 nest 环境：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">source&lt;/span> &lt;span class="nv">$HOME&lt;/span>/software/nest-simulator/3.4-gcc-8.4.0/bin/nest_vars.sh
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>接着找到 &lt;code>hpc_benchmark.py&lt;/code> 目录，该文件位于 &lt;code>$HOME/software/nest-simulator/3.4-gcc-8.4.0/share/doc/nest/examples/hpc_benchmark.py&lt;/code>。修改其中的 params 以并行运行更大的模型。&lt;/p>
&lt;ol>
&lt;li>修改 nvp 为所需 MPI 进程数 × 每进程线程数，如 2 MPI 进程 × 14 线程 = 28&lt;/li>
&lt;li>设置合适的 scale ，如 10 。更大的需要更多 nvp 。&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">params&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s1">&amp;#39;nvp&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">28&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="c1"># total number of virtual processes&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="s1">&amp;#39;scale&amp;#39;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mf">10.&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="c1"># scaling factor of the network size&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># others...&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>在 &lt;code>hpc_benchmark.py&lt;/code> 目录下执行：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="nb">export&lt;/span> &lt;span class="nv">OMP_NUM_THREADS&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="m">14&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">mpiexec -N &lt;span class="m">1&lt;/span> -n &lt;span class="m">2&lt;/span> -p &amp;lt;partition_name&amp;gt; --export&lt;span class="o">=&lt;/span>all python3 hpc_benchmark.py
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>其中 -N 指定节点数，-n 指定 MPI 进程数，-p 指定分区名，如 &lt;code>compute&lt;/code>，&amp;ndash;export=all 用于将环境变量导出到 MPI 进程中。&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>本文介绍了在高性能计算机上安装 NEST-3.4 的方法。&lt;/p>
&lt;h2 id="参考资料">参考资料&lt;/h2>
&lt;ol>
&lt;li>&lt;a class="link" href="https://nest-simulator.readthedocs.io/en/latest/" target="_blank" rel="noopener"
>NEST 官方文档&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>CUDA 基础：内存访问模式</title><link>https://cuterwrite.top/p/cuda-base-memory-access-mode/</link><pubDate>Mon, 04 Sep 2023 00:55:55 +0000</pubDate><guid>https://cuterwrite.top/p/cuda-base-memory-access-mode/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/img/14ce26d6f495200cea2cfa76fefadf88eaab94e5.jpg@1256w_754h_!web-article-pic-2023-09-04.webp" alt="Featured image of post CUDA 基础：内存访问模式" />&lt;h1 id="cuda-基础内存访问模式">CUDA 基础：内存访问模式&lt;/h1>
&lt;p>大多数设备端数据访问都是从全局内存开始的，并且多数 GPU 应用程序容易受内存带宽的限制。因此，最大限度地利用全局内存带宽是调控核函数性能的基本。如果不能正确地调控全局内存的使用，其他优化方案很可能也收效甚微。&lt;/p>
&lt;p>为了在读写数据时达到最佳的性能，内存访问操作必须满足一定的条件。CUDA 执行模型的显著特征之一就是指令必须以线程束为单位进行发布和执行。存储操作也是同样。在执行内存指令时，线程束中的每个线程都提供了一个正在加载或存储的内存地址。在线程束的 32 个线程中，每个线程都提出了一个包含请求地址的单一内存访问请求，它并由一个或多个设备内存传输提供服务。根据线程束中内存地址的分布，内存访问可以被分成不同的模式。&lt;/p>
&lt;h2 id="一对齐与合并访问">一、对齐与合并访问&lt;/h2>
&lt;p>全局内存通过缓存实现加载和存储的过程如下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904151729-2023-09-04.webp"
alt="20230904151729-2023-09-04" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>全局内存是一个逻辑内存空间，用户可以通过核函数访问它。所有应用程序数据最初存在于 DRAM 上，即物理设备内存中。核函数的内存请求通常是在 DRAM 设备和片上内存间以 128 字节或 32 字节内存事务来实现。&lt;/p>
&lt;p>所有对全局内存的访问都会通过二级缓存，也有许多访问会通过一级缓存，这取决于访问类型和 GPU 架构。如果这两级缓存都被用到，那么内存访问是由一个 128 字节的内存事务实现的。如果只使用二级缓存，那么这个内存访问是由一个 32 字节的内存事务来实现的。对全局内存缓存其架构，如果允许使用一级缓存，那么可以在编译时选择启用或禁用一级缓存。&lt;/p>
&lt;p>一行一级缓存是 128 字节，它映射到设备内存中一个 128 字节 的对齐段。如果线程束中的每个线程请求一个 4 字节的值，那么每次请求就会获取 128 字节的数据，这恰好与缓存行和设备内存段的大小相契合。&lt;/p>
&lt;p>因此在优化应用程序时，需要注意设备内存访问的两个特性：&lt;/p>
&lt;ul>
&lt;li>对齐内存访问&lt;/li>
&lt;li>合并内存访问&lt;/li>
&lt;/ul>
&lt;p>我们把一次内存请求：也就是从核函数发起请求，到硬件响应返回数据这个过程称为一个内存事务（加载和存储都行）。&lt;/p>
&lt;p>当一个内存事务的首个访问地址是缓存粒度（32 或 128 字节）的偶数倍的时候：比如二级缓存 32 字节的偶数倍 64，128 字节的偶数倍 256 的时候，这个时候被称为对齐内存访问，非对齐访问就是除上述的其他情况，&lt;strong>非对齐的内存访问会造成带宽浪费&lt;/strong>。&lt;/p>
&lt;p>当一个线程束内的线程访问的内存都在一个内存块里的时候，就会出现合并访问。&lt;/p>
&lt;p>&lt;strong>对齐合并访问的状态是理想化的，也是最高速的访问方式&lt;/strong>，当线程束内的所有线程访问的数据在一个内存块，并且数据是从内存块的首地址开始被需要的，那么对齐合并访问出现了。为了最大化全局内存访问的理想状态，尽量将线程束访问内存组织成对齐合并的方式，这样的效率是最高的。下面看一个例子。&lt;/p>
&lt;p>一个线程束加载数据，使用一级缓存，并且这个事务所请求的所有数据在一个 128 字节的对齐的地址段上，如下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904152703-2023-09-04.webp"
alt="20230904152703-2023-09-04" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>上面蓝色表示全局内存，下面橙色是线程束要的数据，绿色就是对齐的地址段。&lt;/p>
&lt;p>而如果一个事务加载的数据分布在不一个对齐的地址段上，就会有以下两种情况：&lt;/p>
&lt;ol>
&lt;li>连续的，但是不在一个对齐的段上，比如，请求访问的数据分布在内存地址 1~128 ，那么 0~127 和 128~255 这两段数据要传递两次到 SM 。&lt;/li>
&lt;li>不连续的，也不在一个对齐的段上，比如，请求访问的数据分布在内存地址 0~63 和 128~191 上，明显这也需要两次加载。&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904152901-2023-09-04.webp"
alt="20230904152901-2023-09-04" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>上图就是典型的一个线程束，数据分散开了，thread 0 的请求在 128 之前，后面还有请求在 256 之后，所以需要三个内存事务，而利用率，也就是从主存取回来的数据被使用到的比例，只有 $\frac{128}{128 \times 3}$ 的比例。这个比例低会造成带宽的浪费，最极端的表现，就是如果每个线程的请求都在不同的段，也就是一个 128 字节的事务只有 1 个字节是有用的，那么利用率只有 $\frac{1}{128}$ 。&lt;/p>
&lt;p>这里总结一下内存事务的优化关键：&lt;strong>用最少的事务次数满足最多的内存请求&lt;/strong>。事务数量和吞吐量的需求随设备的计算能力变化。&lt;/p>
&lt;h2 id="二全局内存读取">二、全局内存读取&lt;/h2>
&lt;p>在 SM 中，数据通过以下 3 种缓存 / 缓冲路径进行传输，具体使用何种方式取决于引用了哪种类型的设备内存：&lt;/p>
&lt;ul>
&lt;li>一级和二级缓存&lt;/li>
&lt;li>常量缓存&lt;/li>
&lt;li>只读缓存&lt;/li>
&lt;/ul>
&lt;p>一 / 二级缓存是默认路径。想要通过其它两种路径传输数据需要&lt;strong>应用程序显式说明&lt;/strong>，但想要提升性能还要取决于使用地访问模式。全局内存加载操作是否会通过一级缓存取决于两个因素：&lt;/p>
&lt;ul>
&lt;li>设备的计算能力：比较老的设备可能没有一级缓存&lt;/li>
&lt;li>编译器选项&lt;/li>
&lt;/ul>
&lt;p>在 Fermi GPU 和 Kepler K40 及以后的 GPU （计算能力为 3.5 及以上）中，可以通过编译器标志启用或禁用全局内存负载的一级缓存。默认情况下，在 Fermi 设备上对于全局内存加载可以使用一级缓存，在 K40 及以上 GPU 中禁用。以下标志通知编译器禁用一级缓存：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">-Xptxas -dlcm=cg
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>如果一级缓存被禁用，所有对全局内存的加载请求将直接进入到二级缓存；如果二级缓存缺失，则由 DRAM 完成请求。每一次内存事务可由一个、两个或四个部分执行，每个部分有 32 个字节。一级缓存也可以使用下列标识符直接启用:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">-Xptxas -dlcm=ca
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>设置这个标志后，全局内存加载请求首先尝试通过一级缓存。如果一级缓存缺失，该请求转向二级缓存。如果二级缓存缺失，则请求由 DRAM 完成。在这种模式下，一个内存加载请求由一个 128 字节的设备内存事务实现。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904164822-2023-09-04.webp"
alt="20230904164822-2023-09-04" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>在 Kepler K10、K20 和 K20X GPU 中一级缓存不用来缓存全局内存加载。一级缓存专门用于&lt;strong>缓存寄存器溢出到本地内存中的数据&lt;/strong>。&lt;/p>
&lt;p>内存加载可以分为两类：&lt;/p>
&lt;ul>
&lt;li>缓存加载&lt;/li>
&lt;li>没有缓存的加载&lt;/li>
&lt;/ul>
&lt;p>内存访问有以下特点：&lt;/p>
&lt;ul>
&lt;li>是否使用缓存：一级缓存是否介入加载过程&lt;/li>
&lt;li>对齐与非对齐的：如果访问的第一个地址是 32 的倍数&lt;/li>
&lt;li>合并与非合并，访问连续数据块则是合并的&lt;/li>
&lt;/ul>
&lt;h3 id="1-缓存加载">1. 缓存加载&lt;/h3>
&lt;p>下面是使用一级缓存的加载过程&lt;/p>
&lt;ol>
&lt;li>对齐合并的访问，总线利用率 $100\%$&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904165226-2023-09-04.webp"
alt="20230904165226-2023-09-04" width="auto" loading="lazy"/>
&lt;/figure>
&lt;ol start="2">
&lt;li>对齐的，但是不是连续的，每个线程访问的数据都在一个块内，但是位置是交叉的，总线利用率 $100\%$&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904165245-2023-09-04.webp"
alt="20230904165245-2023-09-04" width="auto" loading="lazy"/>
&lt;/figure>
&lt;ol start="3">
&lt;li>连续非对齐的，线程束请求一个连续的非对齐的，32 个 4 字节数据，那么会出现，数据横跨两个块，但是没有对齐，当启用一级缓存的时候，就要两个 128 字节的事务来完成，总线利用率为 $50\%$&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904165306-2023-09-04.webp"
alt="20230904165306-2023-09-04" width="auto" loading="lazy"/>
&lt;/figure>
&lt;ol start="4">
&lt;li>线程束所有线程请求同一个地址，那么肯定落在一个缓存行范围内，那么如果按照请求的是 4 字节数据来说，总线利用率是 $\frac{4}{128}=3.125\% $&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904165516-2023-09-04.webp"
alt="20230904165516-2023-09-04" width="auto" loading="lazy"/>
&lt;/figure>
&lt;ol start="5">
&lt;li>比较坏的情况，前面提到过最坏的，就是每个线程束内的线程请求的都是不同的缓存行内，这里比较坏的情况就是，所有数据分布在 $N$ 个缓存行，其中 $1\leq N \leq 32$ ，那么请求 32 个 4 字节的数据，就需要 $N$ 个事务来完成，总线利用率也是 $\frac{1}{N}$&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904165524-2023-09-04.webp"
alt="20230904165524-2023-09-04" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>CPU 和 GPU 的一级缓存有显著的差异， GPU 的一级缓存可以通过编译选项等控制，CPU 不可以，而且 CPU 的一级缓存是的替换算法是有使用频率和时间局部性的， GPU 则没有。&lt;/p>
&lt;h3 id="2-没有缓存的加载">2. 没有缓存的加载&lt;/h3>
&lt;p>没有缓存的加载是指的没有通过一级缓存，二级缓存则是不得不经过的。&lt;/p>
&lt;p>当不使用一级缓存的时候，&lt;strong>内存事务的粒度变为 32 字节&lt;/strong>，更细粒度的加载可以为非对齐或非合并的内存访问带来更好的总线利用率。&lt;/p>
&lt;ol>
&lt;li>对齐合并访问 128 字节，不用说，还是最理想的情况，使用 4 个段，总线利用率 $100\%$&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904170430-2023-09-04.webp"
alt="20230904170430-2023-09-04" width="auto" loading="lazy"/>
&lt;/figure>
&lt;ol start="2">
&lt;li>对齐不连续访问 128 字节，都在四个段内，且互不相同，这样的总线利用率也是 $100\%$&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904170454-2023-09-04.webp"
alt="20230904170454-2023-09-04" width="auto" loading="lazy"/>
&lt;/figure>
&lt;ol start="3">
&lt;li>连续不对齐，一个段 32 字节，所以，一个连续的 128 字节的请求，即使不对齐，最多也不会超过五个段，总线利用率至少为 $\frac{4}{5}=80\%$&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904170542-2023-09-04.webp"
alt="20230904170542-2023-09-04" width="auto" loading="lazy"/>
&lt;/figure>
&lt;ol start="4">
&lt;li>所有线程访问一个 4 字节的数据，那么此时的总线利用率是 $\frac{4}{32} = 12.5\%$ ，在这种情况下，非缓存加载性能也是优于缓存加载的性能。&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904170609-2023-09-04.webp"
alt="20230904170609-2023-09-04" width="auto" loading="lazy"/>
&lt;/figure>
&lt;ol start="5">
&lt;li>最坏的情况：所有目标数据分散在内存的各个角落，那么需要 $N$ 个内存段，由于请求的 128 个字节最多落在 $N$ 个 32 字节的内存分段内而不是 $N$ 个 128 字节的缓存行内，所以相比于缓存加载，即便是最坏的情况也有所改善。需要注意这里比较的前提是$N$ 不变，然而在实际情况下，当使用大粒度的缓存行时，$N$ 有可能会减少。&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904170847-2023-09-04.webp"
alt="20230904170847-2023-09-04" width="auto" loading="lazy"/>
&lt;/figure>
&lt;h3 id="3-只读缓存">3. 只读缓存&lt;/h3>
&lt;p>只读缓存最初是预留给纹理内存加载用的。对计算能力为 3.5 及以上的 GPU 来说，只读缓存也支持使用全局内存加载代替一级缓存。&lt;/p>
&lt;p>只读缓存的加载粒度是 32 个字节。通常，对分散读取来说，这些更细粒度的加载要优于一级缓存。&lt;/p>
&lt;p>有两种方式可以指导内存通过只读缓存进行读取:&lt;/p>
&lt;ul>
&lt;li>使用函数 __ldg&lt;/li>
&lt;li>在间接引用的指针上使用修饰符&lt;/li>
&lt;/ul>
&lt;p>例如：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="n">__global__&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">copyKernel&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">float&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">in&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kt">float&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">out&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">int&lt;/span> &lt;span class="n">idx&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">blockDim&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">blockIdx&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">x&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">threadIdx&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">out&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">idx&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nf">__ldg&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">in&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">idx&lt;/span>&lt;span class="p">]);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>然后就能强制使用只读缓存了。&lt;/p>
&lt;p>也可以将常量 restrict 修饰符应用到指针上。这些修饰符帮助 nvcc 编译器识别无别名指针(即专门用来访问特定数组的指针)。nvcc 将自动通过只读缓存指导无别名指针的加载。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="n">__global__&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">copyKernel&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">__restrict__&lt;/span> &lt;span class="n">out&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="k">const&lt;/span> &lt;span class="kt">int&lt;/span>&lt;span class="o">*&lt;/span> &lt;span class="n">__restrict__&lt;/span> &lt;span class="n">in&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">int&lt;/span> &lt;span class="n">idx&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">blockDim&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">blockIdx&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">x&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">threadIdx&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">out&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">idx&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">in&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">idx&lt;/span>&lt;span class="p">];&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="三全局内存写入">三、全局内存写入&lt;/h2>
&lt;p>内存的存储操作相对简单。一级缓存不能用在 Fermi 或 Kepler GPU 上进行存储操作，在发送到设备内存之间存储操作&lt;strong>只通过二级缓存&lt;/strong>。存储操作在 &lt;strong>32 个字节段&lt;/strong>的粒度上被执行。内存事务可以同时被分为一段、两段或四段。例如，如果两个地址同属于一个 128 字节区域，但是不属于一个对齐的 64 字节区域，则会执行一个四段事务（也就是说，执行一个四段事务比执行两个一段事务效果更好）。&lt;/p>
&lt;ol>
&lt;li>对齐的，访问一个连续的 128 字节范围。存储操作使用一个四段事务完成：&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904172018-2023-09-04.webp"
alt="20230904172018-2023-09-04" width="auto" loading="lazy"/>
&lt;/figure>
&lt;ol start="2">
&lt;li>分散在一个 192 字节的范围内，不连续，使用 3 个一段事务完成：&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904172036-2023-09-04.webp"
alt="20230904172036-2023-09-04" width="auto" loading="lazy"/>
&lt;/figure>
&lt;ol start="3">
&lt;li>对齐的，在一个 64 字节的范围内，使用一个两段事务完成：&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904172052-2023-09-04.webp"
alt="20230904172052-2023-09-04" width="auto" loading="lazy"/>
&lt;/figure>
&lt;ol start="4">
&lt;li>非对齐写入示例与读取情况类似，且更简单，因为始终不经过一级缓存，这里就略过了。&lt;/li>
&lt;/ol>
&lt;h2 id="四结构体数组与数组结构体">四、结构体数组与数组结构体&lt;/h2>
&lt;p>数组结构体（AoS）和结构体数组（SoA）是 C 语言中常见的两种数组组织方式。当存储结构化数据集时，它们代表了可以采用的两种强大的数据组织方式（结构体和数组）。&lt;/p>
&lt;p>下面是存储成对的浮点数据数据集的例子。首先，考虑这些成对数据元素集如何使用 AoS 方法进行存储。如下定义一个结构体，命名为 innerStruct ：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="k">struct&lt;/span> &lt;span class="n">innerStruct&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">float&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">float&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">};&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>然后，按照下面的方法定义这些结构体数组。这是利用 AoS 方式来组织数据的。它存储的是空间上相邻的数据，这在 CPU 上会有良好的缓存局部性。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="k">struct&lt;/span> &lt;span class="n">innerStruct&lt;/span> &lt;span class="n">myAoS&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">N&lt;/span>&lt;span class="p">];&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>接下来，考虑使用 SoA 方法来存储数据：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="k">struct&lt;/span> &lt;span class="n">innerArray&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">float&lt;/span> &lt;span class="n">x&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">N&lt;/span>&lt;span class="p">];&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">float&lt;/span> &lt;span class="n">y&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">N&lt;/span>&lt;span class="p">];&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">};&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这里，在原结构体中每个字段的所有值都被分到各自的数组中。这不仅能将相邻数据点紧密存储起来，也能将跨数组的独立数据点存储起来。可以使用如下结构体定义一个变量：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="k">struct&lt;/span> &lt;span class="n">innerArray&lt;/span> &lt;span class="n">mySoA&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>下图说明了 AoS 和 SoA 方法的内存布局。用 AoS 模式在 GPU 上存储示例数据并执行一个只有 $x$ 字段的应用程序，将导致 $50\%$ 的带宽损失，因为 $y$ 值在每 32 个字节段或 128 个字节缓存行上隐式地被加载。 AoS 格式也在不需要的 $y$ 值上浪费了二级缓存空间。&lt;/p>
&lt;p>用 SoA 模式存储数据充分利用了 GPU 的内存带宽。由于没有相同字段元素的交叉存取， GPU 上的 SoA 布局提供了合并内存访问，并且可以对全局内存实现更高效的利用。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230904173436-2023-09-04.webp"
alt="20230904173436-2023-09-04" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>当 32 个线程同时访问的时候， SoA 的访问就是连续的，而 AoS 则是不连续的。&lt;/p>
&lt;p>对比 AoS 和 SoA 的内存布局，我们能得到下面结论：&lt;/p>
&lt;ul>
&lt;li>并行编程范式，尤其是 SIMD（单指令多数据）对 SoA 更友好。 CUDA 中普遍倾向于 SoA 因为这种内存访问可以有效地合并。&lt;/li>
&lt;/ul>
&lt;h2 id="五性能调整">五、性能调整&lt;/h2>
&lt;p>优化设备内存带宽利用率有两个目标：&lt;/p>
&lt;ol>
&lt;li>对齐及合并内存访问，以减少带宽的浪费&lt;/li>
&lt;li>足够的并发内存操作，以隐藏内存延迟&lt;/li>
&lt;/ol>
&lt;p>实现并发内存访问量最大化是通过以下方式得到的：&lt;/p>
&lt;ol>
&lt;li>增加每个线程中执行独立内存操作的数量&lt;/li>
&lt;li>对核函数启动的执行配置进行试验，已充分体现每个 SM 的并行性&lt;/li>
&lt;/ol>
&lt;p>按照这个思路对程序进行优化，则有两种方法：展开技术和增大并行性。&lt;/p>
&lt;h3 id="1-展开技术">1. 展开技术&lt;/h3>
&lt;p>包含了内存操作的展开循环增加了更独立的内存操作。考虑如下 readOffsetUnroll4 核函数，每个线程都执行 4 个独立的内存操作。因为每个加载过程都是独立的，所以可以调用更多的并发内存访问：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="n">__global__&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">readOffsetUnroll4&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">float&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">A&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kt">float&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">B&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kt">float&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">C&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="k">const&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">offset&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">unsigned&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">blockIdx&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">x&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">blockDim&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">x&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">threadIdx&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">unsigned&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">k&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">offset&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">k&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">3&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">blockDim&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">x&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="n">n&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">C&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">A&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">k&lt;/span>&lt;span class="p">];&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">C&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">blockDim&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">A&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">k&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">blockDim&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">B&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">k&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">blockDim&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">];&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">C&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">2&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">blockDim&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">A&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">k&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">2&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">blockDim&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">B&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">k&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">2&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">blockDim&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">];&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">C&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">3&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">blockDim&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">A&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">k&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">3&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">blockDim&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">B&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">k&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">3&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">blockDim&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">x&lt;/span>&lt;span class="p">];&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>启用一级缓存编译选项：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">nvcc -O3 readSegmentUnroll.cu -o readSegmentUnroll -Xptxas -dlcm&lt;span class="o">=&lt;/span>ca
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>结果表明，展开技术对性能有非常好的影响，甚至比地址对齐还要好。对于 I/O 密集型的核函数，充分说明内存访问并行有很高的优先级。&lt;/p>
&lt;h3 id="2-增大并行性">2. 增大并行性&lt;/h3>
&lt;p>可以通过调整块的大小来实现并行性调整：&lt;/p>
&lt;ul>
&lt;li>线程块最内层维度的大小对性能起着关键的作用&lt;/li>
&lt;li>在所有其它情况下，线程块的数量越多，一般性能越高。因此，增大并行性仍然是性能优化的一个重要因素。&lt;/li>
&lt;/ul>
&lt;h2 id="参考资料">参考资料&lt;/h2>
&lt;p>[1] CUDA C 编程权威指南，机械工业出版社，（美）程润伟（John Cheng） 等著&lt;/p></description></item><item><title>CUDA 基础：内存管理</title><link>https://cuterwrite.top/p/cuda-base-memory-manage/</link><pubDate>Sat, 02 Sep 2023 05:55:55 +0000</pubDate><guid>https://cuterwrite.top/p/cuda-base-memory-manage/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/fb80f7f3a9a0e016420a324823ef950b9847fb8d.jpg@1256w_2128h_!web-article-pic-2023-09-02.webp" alt="Featured image of post CUDA 基础：内存管理" />&lt;h1 id="cuda-基础内存管理">CUDA 基础：内存管理&lt;/h1>
&lt;p>CUDA 编程的内存管理与 C 语言的类似，需要程序员显式地管理主机和设备之间的数据移动。随着 CUDA 版本的升级，NVIDIA 正系统地实现主机和设备内存空间的统一，但对于大多数应用程序来说，仍需要手动移动数据。本文重点在于如何使用 CUDA 函数来显式地管理内存和数据移动。&lt;/p>
&lt;ul>
&lt;li>分配和释放设备内存&lt;/li>
&lt;li>在主机和设备之间传输数据&lt;/li>
&lt;/ul>
&lt;p>为了达到最优性能，CUDA 提供了在主机端准备设备内存的函备内存的函数，并且显式地向设备传输数据和从设备中获取数据。&lt;/p>
&lt;h2 id="一内存分配和释放">一、内存分配和释放&lt;/h2>
&lt;p>CUDA 编程模型假设了一个包含一个主机和一个设备的异构系统，每一个异构系统都有自己独立的内存空间。核函数在设备内存空间中运行，CUDA 运行时提供函数以分配和释放设备内存。用户可以在主机上使下列函数分配全局内存：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="kt">cudaError_t&lt;/span> &lt;span class="nf">cudaMalloc&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">void&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="n">devPtr&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kt">size_t&lt;/span> &lt;span class="n">size&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这个函数在设备上分配了 count 字节的全局内存，并用 devptr 指针返回该内存的地址。所分配的内存支持任何变量类型，包括整型、浮点类型变量、布尔类型等。如果 cudaMalloc 函数执行失败则返回 cudaErrorMemoryAllocation 。在已分配的全局内存中的值不会被清除。用户需要用从主机上传输的数据来填充所分配的全局内存，或用下列函数将其初始化：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="kt">cudaError_t&lt;/span> &lt;span class="nf">cudaMemset&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">void&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">devPtr&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">value&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kt">size_t&lt;/span> &lt;span class="n">count&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这个函数用存储在变量 value 中的值来填充从设备内存地址 devPtr 处开始的 count 字节。&lt;/p>
&lt;p>一旦一个应用程序不再使用已分配的全局内存，那么可以以下代码释放该内存空间：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="kt">cudaError_t&lt;/span> &lt;span class="nf">cudaFree&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">void&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">devPtr&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这个函数释放了 devPtr 指向的全局内存，该内存必须在此前使用了一个设备分配函数（如 cudaMalloc）来进行分配。否则，它将返回一个错误 cudaErrorInvalidDevicePointer 。如果地址空间已经被释放，那么 cudaFree 也返回一个错误。&lt;/p>
&lt;p>设备内存的分配和释放操作成本较高，所以应用程序应&lt;strong>重利用设备内存&lt;/strong>，以减少对整体性能的影响。&lt;/p>
&lt;h2 id="二内存传输">二、内存传输&lt;/h2>
&lt;p>一旦分配好了全局内存，就可以使用下列函数从主机向设备传输数据：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="kt">cudaError_t&lt;/span> &lt;span class="nf">cudaMemcpy&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">void&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">dst&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="k">const&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">src&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kt">size_t&lt;/span> &lt;span class="n">count&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cudaMemcpyKind&lt;/span> &lt;span class="n">kind&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这个函数从内存位置 src 复制了 count 字节到内存位置 dst 。变量 kind 指定了复制的方向，可以有下列取值：&lt;/p>
&lt;ul>
&lt;li>cudaMemcpyHostToHost：从主机内存复制到主机内存&lt;/li>
&lt;li>cudaMemcpyHostToDevice：从主机内存复制到设备内存&lt;/li>
&lt;li>cudaMemcpyDeviceToHost：从设备内存复制到主机内存&lt;/li>
&lt;li>cudaMemcpyDeviceToDevice：从设备内存复制到设备内存&lt;/li>
&lt;/ul>
&lt;p>如果指针 dst 和 src 与 kind 指定的复制方向不一致，那么 cudaMemcpy 的行为就是未定义行为。这个函数在大多数情况下都是同步的。&lt;/p>
&lt;p>下图为 CPU 内存和 GPU 内存间的连接性能。从图中可以看到 GPU 芯片和板载 GDDR5 GPU 内存之间的理论峰值带宽非常高，对于 Fermi C2050 GPU 来说为 144GB/s 。CPU 和 GPU 之间通过 PCIe Gen2 总线相连，这种连接的理论带宽要低得多，为 8GB/s（ PCIe Gen3 总线最大理论限制值是 16GB/s）。这种差距意味着如果管理不当的话，主机和设备间的数据传输会降低应用程序的整体性能。因此，CUDA 编程的一个基本原则应是尽可能地减少主机与设备之间的传输。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230902212815-2023-09-02.webp"
alt="20230902212815-2023-09-02" width="auto" loading="lazy"/>
&lt;/figure>
&lt;h2 id="三固定内存">三、固定内存&lt;/h2>
&lt;p>分配的主机内存默认是 pageable（可分页），它的意思也就是因页面错误导致的操作，该操作按照操作系统的要求将主机虚拟内存上的数据移动到不同的物理位置。虚拟内存给人一种比实际可用内存大得多的假象，就如同一级缓存好像比实际可用的片上内存大得多一样。&lt;/p>
&lt;p>GPU &lt;strong>不能在可分页主机内存上安全地访问数据&lt;/strong>，因为当主机操作系统在物理位置上移动该数据时，它无法控制。当从可分页主机内存传输数据到设备内存时，CUDA 驱动程序首先分配&lt;strong>临时页面锁定的或固定的&lt;/strong>主机内存，将主机源数据复制到固定内存中，然后从固定内存传输数据给设备内存，如下图左边部分所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230903003123-2023-09-03.webp"
alt="20230903003123-2023-09-03" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>左边是正常分配内存，传输过程是：锁页-复制到固定内存-复制到设备&lt;/p>
&lt;p>右边是分配时就是固定内存，直接传输到设备上。&lt;/p>
&lt;p>下面函数用来分配固定内存：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="kt">cudaError_t&lt;/span> &lt;span class="nf">cudaMallocHost&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">void&lt;/span> &lt;span class="o">**&lt;/span> &lt;span class="n">devPtr&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="kt">size_t&lt;/span> &lt;span class="n">count&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这个函数分配了 count 字节的主机内存，这些内存是页面锁定的并且对设备来说是可访问的。由于固定内存能被设备直接访问，所以它能用比可分页内存高得多的带宽进行读写。然而，分配过多的固定内存可能会降低主机系统的性能，因为它减少了用于存储虚拟内存数据的可分页内存的数量，其中分页内存对主机系统是可用的。&lt;/p>
&lt;p>固定的主机内存释放使用：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="kt">cudaError_t&lt;/span> &lt;span class="nf">cudaFreeHost&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">void&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">devPtr&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>总的来说，固定内存的释放和分配成本比可分页内存要高很多，但是传输速度更快，所以对于大规模数据，固定内存效率更高。应该尽量使用流来使内存传输和计算之间同时进行。&lt;/p>
&lt;h2 id="四零拷贝内存">四、零拷贝内存&lt;/h2>
&lt;p>通常来说，主机不能直接访问设备变量，同时设备也不能直接访问主机变量。但有一个例外：零拷贝内存。&lt;strong>主机和设备都可以访问零拷贝内存&lt;/strong>。&lt;/p>
&lt;p>GPU 线程可以直接访问零拷贝内存。在 CUDA 核函数中使用零拷贝内存有以下几个优势。&lt;/p>
&lt;ul>
&lt;li>当设备内存不足时可利用主机内存&lt;/li>
&lt;li>避免主机和设备间的显式数据传输&lt;/li>
&lt;li>提高 PCIe 传输率&lt;/li>
&lt;/ul>
&lt;p>当使用零拷贝内存来共享主机和设备间的数据时，用户必须同步主机和设备间的内存访问，同时更改主机和设备的零拷贝内存中的数据将导致不可预知的后果。&lt;/p>
&lt;p>零拷贝内存是固定内存，不可分页，该内存映射到设备地址空间中。用户可以通过下列函数创建零拷贝内存：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="kt">cudaError_t&lt;/span> &lt;span class="nf">cudaHostAlloc&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">void&lt;/span> &lt;span class="o">**&lt;/span> &lt;span class="n">pHost&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="kt">size_t&lt;/span> &lt;span class="n">count&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="kt">unsigned&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">flags&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>最后一个标志参数，可以选择以下值：&lt;/p>
&lt;ul>
&lt;li>cudaHostAllocDefalt：和 cudaMallocHost 函数一致&lt;/li>
&lt;li>cudaHostAllocPortable：返回能被所有 CUDA 上下文使用的固定内存&lt;/li>
&lt;li>cudaHostAllocMapped：产生零拷贝内存，可以实现主机写入和设备读取被映射到设备地址空间中的主机内存&lt;/li>
&lt;li>cudaHostAllocWriteCombined：返回写结合内存，在某些设备上这种内存传输效率更高&lt;/li>
&lt;/ul>
&lt;p>注意，零拷贝内存虽然不需要显式的传递到设备上，但是设备还不能通过 pHost 直接访问对应的内存地址，设备需要访问主机上的零拷贝内存，需要先获得另一个地址，这个地址帮助设备访问到主机对应的内存，方法是：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="kt">cudaError_t&lt;/span> &lt;span class="nf">cudaHostGetDevicePointer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">void&lt;/span> &lt;span class="o">**&lt;/span> &lt;span class="n">pDevice&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="kt">void&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">pHost&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="kt">unsigned&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">flags&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>pDevice 就是设备上访问主机零拷贝内存的指针了，此处 flags 必须设置为 0 。&lt;/p>
&lt;p>在进行频繁的读写操作时，使用零拷贝内存作为设备内存的补充将显著降低性能。因为每一次映射到内存的传输必须经过 PCIe 总线。与全局内存相比，延迟也显著增加。&lt;/p>
&lt;p>注意不要过度使用零拷贝内存。由于其延迟较高，从零拷贝内存中读取设备核函数可能很慢。&lt;/p>
&lt;h2 id="五统一虚拟寻址">五、统一虚拟寻址&lt;/h2>
&lt;p>计算能力为 2.0 及以上版本的设备支持一种特殊的寻址方式，称为&lt;strong>统一虚拟寻址（UVA）&lt;/strong>。UVA，在 CUDA 4.0 中被引入，支持 64 位 Linux 系统。有了 UVA，主机内存和设备内存可以共享同一个虚拟地址空间，如下图所示：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230903004449-2023-09-03.webp"
alt="20230903004449-2023-09-03" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>UVA 之前，我们要管理所有的设备和主机内存，尤其是它们的指针，零拷贝内存尤其麻烦。有了 UVA，由指针指向的内存空间对应用程序代码来说是透明的。&lt;/p>
&lt;p>通过 UVA，由 cudaHostAlloc 分配的固定主机内存具有相同的主机和设备指针。因此，可以将返回的指针直接传递给核函数。&lt;/p>
&lt;p>前面的零拷贝内存，可以知道以下几个方面：&lt;/p>
&lt;ul>
&lt;li>分配映射的固定主机内存&lt;/li>
&lt;li>使用 CUDA 运行时函数获取映射到固定内存的设备指针&lt;/li>
&lt;li>将设备指针传递给核函数&lt;/li>
&lt;/ul>
&lt;p>有了 UVA ，可以不用上面的那个获得设备上访问零拷贝内存的函数了：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="kt">cudaError_t&lt;/span> &lt;span class="nf">cudaHostGetDevicePointer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">void&lt;/span> &lt;span class="o">**&lt;/span> &lt;span class="n">pDevice&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="n">pHost&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kt">unsigned&lt;/span> &lt;span class="n">flags&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>因为 UVA 之后，主机和设备的指针都是一样的，所以可以直接传递给核函数了。&lt;/p>
&lt;h2 id="六统一内存寻址">六、统一内存寻址&lt;/h2>
&lt;p>在 CUDA 6.0 中，引入了&lt;strong>统一内存寻址&lt;/strong>这一新特性，它用于简化 CUDA 编程模型中的内存管理。统一内存中创建了一个托管内存池，内存池中已分配的空间可以用相同的内存地址（即指针）在 CPU 和 GPU 上进行访问。底层系统在统一内存空间中自动在主机和设备之间进行数据传输。这种数据传输对应用程序是透明的，这大大简化了程序代码。&lt;/p>
&lt;p>统一内存寻址依赖于 UVA 的支持，但它们是完全不同的技术。 UVA 为系统中的所有处理器提供了一个单一的虚拟内存地址空间。但是， UVA 不会自动将数据从一个物理位置转移到另一个位置，这是统一内存寻址的一个特有功能。&lt;/p>
&lt;p>统一内存寻址提供了一个&lt;strong>单指针到数据&lt;/strong>模型，在概念上它类似于零拷贝内存。但是零拷贝内存在主机内存中进行分配，因此，由于受到在 PCIe 总线上访问零拷贝内存的影响，核函数的性能将具有较高的延迟。另一方面，统一内存寻址将内存和执行空间分离，因此可以根据需要将数据透明地传输到主机或设备上，以提升局部性和性能。&lt;/p>
&lt;p>托管内存指的是由底层系统自动分配的统一内存，未托管内存就是用户自己分配的内存，这时候对于核函数，可以传递给它两种类型的内存，已托管和未托管内存，可以同时传递。&lt;/p>
&lt;p>托管内存可以是静态的，也可以是动态的，添加 managed 关键字修饰托管内存变量。静态声明的托管内存作用域是文件，这一点可以注意一下。&lt;/p>
&lt;p>托管内存分配方式：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="kt">cudaError_t&lt;/span> &lt;span class="nf">cudaMallocManaged&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">void&lt;/span> &lt;span class="o">**&lt;/span> &lt;span class="n">devPtr&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kt">size_t&lt;/span> &lt;span class="n">size&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kt">unsigned&lt;/span> &lt;span class="kt">int&lt;/span> &lt;span class="n">flags&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这个函数分配 size 字节的托管内存，并用 devPtr 返回一个指针。该指针在所有设备和主机上都是有效的。使用托管内存的程序行为与使用未托管内存的程序副本行为在功能上是一致的。但是，使用托管内存的程序可以利用自动数据传输和重复指针消除功能。&lt;/p>
&lt;p>在 CUDA 6.0 中，设备代码不能调用 cudaMallocManaged 函数。所有的托管内存必须在主机端动态声明或者在全局范围内静态声明。&lt;/p>
&lt;h2 id="参考资料">参考资料&lt;/h2>
&lt;p>[1] CUDA C 编程权威指南，机械工业出版社，（美）程润伟（John Cheng） 等著&lt;/p></description></item><item><title>CUDA 基础：内存模型概述</title><link>https://cuterwrite.top/p/cuda-base-memory-model/</link><pubDate>Fri, 01 Sep 2023 04:00:00 +0000</pubDate><guid>https://cuterwrite.top/p/cuda-base-memory-model/</guid><description>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/47a9b8a012cf3a3f552c9aba3aeaa93fe669cf70.jpg@1256w_970h_!web-article-pic-2023-09-01.webp" alt="Featured image of post CUDA 基础：内存模型概述" />&lt;h1 id="cuda-基础内存模型概述">CUDA 基础：内存模型概述&lt;/h1>
&lt;p>内存的访问和管理是所有编程语言的重要部分。在现代加速器中，内存管理对高性能计算有着很大的影响。&lt;/p>
&lt;p>因为多数工作负载被加载和存储数据的速度所限制，所以有大量低延迟、高带宽的内存对性能是十分有利的。然而，大容量、高性能的内存造价高且不容易生产。因此，在现有的硬件存储子系统下，必须依靠&lt;strong>内存模型&lt;/strong>获得最佳的延迟和带宽。CUDA 内存模型结合了主机和设备的内存系统，展现了完整的内存层次结构，能显式地控制数据布局以优化性能。&lt;/p>
&lt;h2 id="一内存层次结构的优点">一、内存层次结构的优点&lt;/h2>
&lt;p>程序具有局部性特点，包括：&lt;/p>
&lt;ol>
&lt;li>时间局部性：如果一个数据被访问，那么它在不久的将来也会被访问。&lt;/li>
&lt;li>空间局部性：如果一个数据被访问，那么它附近的数据也会被访问。&lt;/li>
&lt;/ol>
&lt;p>现代计算机的内存结构主要如下：&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230901232704-2023-09-01.webp"
alt="20230901232704-2023-09-01" width="auto" loading="lazy"/>
&lt;/figure>
&lt;p>一个内存层次结构由具有不同延迟、带宽和容量的多级内存组成。通常，随着从处理器到内存延迟的增加，内存的容量也在增加。&lt;/p>
&lt;p>CPU 和 GPU 的主存都采用的是 DRAM（动态随机存取存储器），而低延迟内存（如 CPU 一级缓存）使用的则是 SRAM（静态随机存取存储器）。内存层次结构中最大且最慢的级别通常使用磁盘或闪存驱动来实现。在这种内存层次结构中，当数据被处理器频繁使用时，该数据保存在低延迟、低容量的存储器中；而当该数据被存储起来以备后用时，数据就存储在高延迟、大容量的存储器中。这种内存层次结构符合大内存低延迟的设想。&lt;/p>
&lt;p>GPU 和 CPU 的内存设计有相似的准则和模型。但它们的主要区别是，CUDA 编程模型能将内存层次结构更好地呈现给用户，能让我们显式地控制它的行为。&lt;/p>
&lt;h2 id="二cuda-内存模型">二、CUDA 内存模型&lt;/h2>
&lt;p>对于程序员来说，一般有两种类型的存储器：&lt;/p>
&lt;ol>
&lt;li>可编程的：你需要显式地控制哪些数据存放在可编程内存中&lt;/li>
&lt;li>不可编程的：你不能决定数据的存放位置，程序将自动生成存放位置以获得良好的性能&lt;/li>
&lt;/ol>
&lt;p>CPU 内存结构中，一级二级缓存都是不可编程（完全不可控制）的存储设备。另一方面，CUDA 内存模型相对于 CPU 来说更为丰富，提出了多种可编程内存的类型：&lt;/p>
&lt;ul>
&lt;li>寄存器&lt;/li>
&lt;li>共享内存&lt;/li>
&lt;li>本地内存&lt;/li>
&lt;li>常量内存&lt;/li>
&lt;li>纹理内存&lt;/li>
&lt;li>全局内存&lt;/li>
&lt;/ul>
&lt;p>下图所示为这些内存空间的层次结构，每种都有不同的作用域、生命周期和缓存行为。一个核函数中的线程都有自己私有的&lt;strong>本地内存&lt;/strong>。一个线程块有自己的&lt;strong>共享内存&lt;/strong>，对同一线程块中所有线程都可见，其内容持续线程块的整个生命周期。所有线程都可以访问&lt;strong>全局内存&lt;/strong>。所有线程都能访问的只读内存空间有：&lt;strong>常量内存空间和纹理内存空间&lt;/strong>。全局内存、常量内存和纹理内存空间有不同的用途。&lt;strong>纹理内存&lt;/strong>为各种数据布局提供了不同的寻址模式和滤波模式。对于一个应用程序来说， &lt;strong>全局内存、常量内存和纹理内存&lt;/strong>中的内容具有相同的生命周期。&lt;/p>
&lt;figure>&lt;img src="https://cuterwrite-1302252842.file.myqcloud.com/blog/20230901233955-2023-09-01.webp"
alt="20230901233955-2023-09-01" width="auto" loading="lazy"/>
&lt;/figure>
&lt;h3 id="1-寄存器">1. 寄存器&lt;/h3>
&lt;p>寄存器无论是在 CPU 还是在 GPU 都是速度最快的内存空间，但是和 CPU 不同的是 GPU 的寄存器储量要多一些，而且当我们在核函数内不加修饰的声明一个变量，此变量就存储在寄存器中，但是 CPU 运行的程序有些不同，只有当前在计算的变量存储在寄存器中，其余在主存中，使用时传输至寄存器。在核函数声明的数组中，&lt;strong>如果用于引用该数组的索引是常量且能在编译时确定&lt;/strong>，那么该数组也存储在寄存器中。&lt;/p>
&lt;p>寄存器变量对于每个线程来说都是私有的，一个核函数通常使用寄存器来保存需要频繁访问的线程私有变量。寄存器变量与核函数的生命周期相同。一旦核函数执行完毕，就不能对寄存器变量进行访问了。&lt;/p>
&lt;p>寄存器是 SM 中的稀缺资源，Fermi 架构中每个线程最多 63 个寄存器。Kepler 结构扩展到 255 个 寄存器，一个线程如果使用更少的寄存器，那么就会有更多的常驻线程块，SM 上并发的线程块越多，效率越高，性能和使用率也就越高。&lt;/p>
&lt;p>那么问题就来了，如果一个线程里面的变量太多，以至于寄存器完全不够呢？这时候寄存器发生溢出，本地内存就会过来帮忙存储多出来的变量，这种情况会对效率产生非常负面的影响，所以，不到万不得已，一定要避免此种情况发生。&lt;/p>
&lt;p>为了避免寄存器溢出，可以在核函数的代码中配置额外的信息来辅助编译器优化，比如：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-cpp" data-lang="cpp">&lt;span class="line">&lt;span class="cl">&lt;span class="n">__global__&lt;/span> &lt;span class="kt">void&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nf">__lauch_bounds__&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">maxThreadaPerBlock&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">minBlocksPerMultiprocessor&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">kernel&lt;/span>&lt;span class="p">(...)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="cm">/* kernel code */&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这里面在核函数定义前加了一个 关键字 &lt;strong>lauch_bounds&lt;/strong> ，然后它后面对应了两个变量：&lt;/p>
&lt;ol>
&lt;li>maxThreadaPerBlock：线程块内包含的最大线程数，线程块由核函数来启动&lt;/li>
&lt;li>minBlocksPerMultiprocessor：可选参数，每个 SM 中预期的最小的常驻内存块参数。注意，对于一定的核函数，优化的启动边界会因为不同的结构而不同
也可以在编译选项中加入 &lt;strong>-maxrregcount=32&lt;/strong> 来指定每个线程使用的最大寄存器数。&lt;/li>
&lt;/ol>
&lt;h3 id="2-本地内存">2. 本地内存&lt;/h3>
&lt;p>核函数中符合存储在寄存器中但不能进入被该核函数分配的寄存器空间中的变量将溢出到本地内存中。编译器可能存放到本地内存中的变量有：&lt;/p>
&lt;ul>
&lt;li>在编译时使用未知索引引用的本地数组&lt;/li>
&lt;li>可能会占用大量寄存器空间的较大本地结构体或数组&lt;/li>
&lt;li>任何不满足核函数寄存器限定条件的变量&lt;/li>
&lt;/ul>
&lt;p>本地内存实质上是和全局内存一样在同一块存储区域当中的，其访问特点——高延迟，低带宽。对于计算能力 2.0 以上的设备，本地内存存储在每个 SM 的一级缓存，或者设备的二级缓存上。&lt;/p>
&lt;h3 id="3-共享内存">3. 共享内存&lt;/h3>
&lt;p>在核函数中使用 &lt;strong>__shared__&lt;/strong> 修饰符修饰的变量存放在共享内存中。&lt;/p>
&lt;p>因为共享内存是片上内存，所以与本地内存或全局内存相比，它具有更高的带宽和更低的延迟。它的使用类似于 CPU 一级缓存，但它是可编程的。&lt;/p>
&lt;p>每一个 SM 都有一定数量的由线程块分配的共享内存。因此，必须非常小心不要过度使用共享内存，否则将在不经意间限制活跃线程束的数量。&lt;/p>
&lt;p>共享内存在核函数的范围内声明，其生命周期伴随着整个线程块。当一个线程块执行结束后，其分配的共享内存将被释放并重新分配给其他线程块。&lt;/p>
&lt;p>共享内存是线程之间相互通信的基本方式。因为共享内存是块内线程可见的，所以就有竞争问题的存在，也可以通过共享内存进行通信，当然，为了避免内存竞争，可以使用同步语句：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-cpp" data-lang="cpp">&lt;span class="line">&lt;span class="cl">&lt;span class="n">__syncthreads&lt;/span>&lt;span class="p">();&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>此语句相当于在线程块执行时各个线程的一个障碍点，当块内所有线程都执行到本障碍点的时候才能进行下一步的计算，这样可以设计出避免内存竞争的共享内存使用程序。但是，该语句频繁使用会影响内核执行效率。SM 中的一级缓存和共享内存都使用 64KB 的片上内存，它通过静态划分，但在运行时可以通过如下指令进行动态配置：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-cpp" data-lang="cpp">&lt;span class="line">&lt;span class="cl">&lt;span class="n">cudaError_t&lt;/span> &lt;span class="n">cudaFuncSetCacheConfig&lt;/span> &lt;span class="p">(&lt;/span> &lt;span class="k">const&lt;/span> &lt;span class="kt">void&lt;/span>&lt;span class="o">*&lt;/span> &lt;span class="n">func&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cudaFuncCache&lt;/span> &lt;span class="n">cacheConfig&lt;/span> &lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这个函数在每个核函数的基础上配置了片上内存划分，为 func 指定的核函数设置了配置。支持的缓存配置如下：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">cudaFuncCachePreferNone // 无参考值，默认设置
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">cudaFuncCachePreferShared // 48k 共享内存，16k 一级缓存
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">cudaFuncCachePreferL1 // 48k 一级缓存，16k 共享内存
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">cudaFuncCachePreferEqual // 32k 一级缓存，32k 共享内存
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Fermi 架构支持前三种，后面的设备都支持。&lt;/p>
&lt;h3 id="4-常量内存">4. 常量内存&lt;/h3>
&lt;p>常量内存驻留在设备内存中，每个 SM 都有专用的常量内存缓存，常量内存使用 &lt;strong>__constant__&lt;/strong> 修饰符修饰。&lt;/p>
&lt;p>常量变量必须在全局空间内和所有核函数之外进行声明。对于所有计算能力的设备，都只可以声明 64kB 的常量内存，常量内存是静态声明的，并对同一编译单元中的所有核函数可见。&lt;/p>
&lt;p>核函数只能从常量内存中读取数据（只读）。因此，常量内存必须在主机端使用下面的函数来初始化：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-cpp" data-lang="cpp">&lt;span class="line">&lt;span class="cl">&lt;span class="n">cudaError_t&lt;/span> &lt;span class="n">cudaMemcpyToSymbol&lt;/span> &lt;span class="p">(&lt;/span> &lt;span class="k">const&lt;/span> &lt;span class="kt">void&lt;/span>&lt;span class="o">*&lt;/span> &lt;span class="n">symbol&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="k">const&lt;/span> &lt;span class="kt">void&lt;/span>&lt;span class="o">*&lt;/span> &lt;span class="n">src&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">size_t&lt;/span> &lt;span class="n">count&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">size_t&lt;/span> &lt;span class="n">offset&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">cudaMemcpyKind&lt;/span> &lt;span class="n">kind&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">cudaMemcpyHostToDevice&lt;/span> &lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这个函数将 count 个字节从 src 指向的内存复制到 symbol 指向的内存中，这个变量存放在设备的全局内存或常量内存中。在大多数情况下这个函数是同步的。&lt;/p>
&lt;p>线程束中的所有线程从相同的内存地址中读取数据时，常量内存表现最好。举个例子，数学公式中的系数就是一个很好的使用常量内存的例子，因为一个线程束中所有的线程使用相同的系数来对不同数据进行相同的计算。如果线程束里每个线程都从不同的地址空间读取数据，并且只读一次，那么常量内存中就不是最佳选择，因为每从一个常量内存中读取一次数据，都会广播给线程束里的所有线程。&lt;/p>
&lt;h3 id="5-纹理内存">5. 纹理内存&lt;/h3>
&lt;p>纹理内存驻留在设备内存中，并在每个 SM 的只读缓存中缓存。&lt;strong>纹理内存&lt;/strong>是一种通过指定的只读缓存访问的全局内存。只读缓存包括硬件滤波的支持，它可以将浮点插入作为读过程的一部分来执行。纹理内存是对&lt;strong>二维空间局部性&lt;/strong>的优化所以线程束里使用纹理内存访问二维数据的线程可以达到最优性能。对于一些应用程序来说，这是理想的内存，并由于缓存和滤波硬件的支持所以有较好的性能优势。然而对于另一些应用程序来说，与全局内存相比，使用纹理内存更慢。&lt;/p>
&lt;p>总的来说纹理内存设计目的应该是为了 GPU 本职工作显示设计的，但是对于某些特定的程序可能效果更好，比如需要滤波的程序，可以直接通过硬件完成。&lt;/p>
&lt;h3 id="6-全局内存">6. 全局内存&lt;/h3>
&lt;p>全局内存是 GPU 中最大、&lt;strong>延迟最高&lt;/strong>并且最常使用的内存。 global 指的是其作用域和生命周期。它的声明可以在任何 SM 设备上被访问到，并且贯穿应用程序的整个生命周期。一个全局内存变量可以被静态声明或动态声明。可以使用 &lt;strong>__device__&lt;/strong> 修饰符在设备代码中静态地声明一个变量。&lt;/p>
&lt;p>默认通过 cudaMalloc 声明的所有在 GPU 上访问的内存都是全局内存，也就是没有对内存进行任何优化。因为全局内存的性质，当有多个核函数同时执行的时候，如果使用到了同一全局变量，应注意内存竞争。&lt;/p>
&lt;p>全局内存访问是对齐，也就是一次要读取指定大小 $(32，64，128)$ 整数倍字节的内存，所以当线程束执行内存加载/存储时，需要满足的传输数量通常取决与以下两个因素：&lt;/p>
&lt;ol>
&lt;li>跨线程的内存地址分布&lt;/li>
&lt;li>内存事务的对齐方式&lt;/li>
&lt;/ol>
&lt;p>在一般情况下，用来满足内存请求的事务越多，未使用的字节被传输回的可能性就越高，这就造成了数据吞吐率的降低。&lt;/p>
&lt;p>对于一个给定的线程束内存请求，事务数量和数据吞吐率是由设备的计算能力来确定的。对于计算能力为 1.0 和 1.1 的设备，全局内存访问的要求是非常严格的。对于计算能力高于 1.1 的设备，由于内存事务被缓存，所以要求较为宽松。缓存的内存事务利用数据局部性来提高数据吞吐率。&lt;/p>
&lt;h3 id="7-gpu-缓存">7. GPU 缓存&lt;/h3>
&lt;p>与 CPU 缓存类似， GPU 缓存是不可编程的内存。在 GPU 上有 4 种缓存：&lt;/p>
&lt;ul>
&lt;li>一级缓存&lt;/li>
&lt;li>二级缓存&lt;/li>
&lt;li>只读常量缓存&lt;/li>
&lt;li>只读纹理缓存&lt;/li>
&lt;/ul>
&lt;p>每个 SM 都有一个一级缓存，所有的 SM 共享一个二级缓存。一级和二级缓存都被用来在存储本地内存和全局内存中的数据，也包括寄存器溢出的部分。对 Fermi GPU 和 Kepler K40 或其后发布的 GPU 来说，CUDA 允许我们配置读操作的数据是使用一级和二级缓存，还是只使用二级缓存。&lt;/p>
&lt;p>在 CPU 上，内存的加载和存储都可以被缓存。但是，在 GPU 上只有内存加载操作可以被缓存，内存存储操作不能被缓存。&lt;/p>
&lt;p>每个 SM 也有一个只读常量缓存和只读纹理缓存，它们用于在设备内存中提高来自于各自内存空间内的读取性能。&lt;/p>
&lt;h3 id="8-cuda-变量声明总结">8. CUDA 变量声明总结&lt;/h3>
&lt;p>用表格进行总结：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">修饰符&lt;/th>
&lt;th style="text-align:center">变量名&lt;/th>
&lt;th style="text-align:center">存储器&lt;/th>
&lt;th style="text-align:center">作用域&lt;/th>
&lt;th style="text-align:center">生命周期&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">无&lt;/td>
&lt;td style="text-align:center">float var&lt;/td>
&lt;td style="text-align:center">寄存器&lt;/td>
&lt;td style="text-align:center">线程&lt;/td>
&lt;td style="text-align:center">线程&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">无&lt;/td>
&lt;td style="text-align:center">float var[100]&lt;/td>
&lt;td style="text-align:center">本地&lt;/td>
&lt;td style="text-align:center">线程&lt;/td>
&lt;td style="text-align:center">线程&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">__shared__&lt;/td>
&lt;td style="text-align:center">float var*&lt;/td>
&lt;td style="text-align:center">共享内存&lt;/td>
&lt;td style="text-align:center">块&lt;/td>
&lt;td style="text-align:center">块&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">__device__&lt;/td>
&lt;td style="text-align:center">float var*&lt;/td>
&lt;td style="text-align:center">全局内存&lt;/td>
&lt;td style="text-align:center">全局&lt;/td>
&lt;td style="text-align:center">应用程序&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">__constant__&lt;/td>
&lt;td style="text-align:center">float var*&lt;/td>
&lt;td style="text-align:center">常量内存&lt;/td>
&lt;td style="text-align:center">全局&lt;/td>
&lt;td style="text-align:center">应用程序&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>设备存储器的重要特征：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">存储器&lt;/th>
&lt;th style="text-align:center">片上/片外&lt;/th>
&lt;th style="text-align:center">缓存&lt;/th>
&lt;th style="text-align:center">存取&lt;/th>
&lt;th style="text-align:center">范围&lt;/th>
&lt;th style="text-align:center">生命周期&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">寄存器&lt;/td>
&lt;td style="text-align:center">片上&lt;/td>
&lt;td style="text-align:center">n/a&lt;/td>
&lt;td style="text-align:center">R/W&lt;/td>
&lt;td style="text-align:center">一个线程&lt;/td>
&lt;td style="text-align:center">线程&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">本地&lt;/td>
&lt;td style="text-align:center">片外&lt;/td>
&lt;td style="text-align:center">1.0 以上有&lt;/td>
&lt;td style="text-align:center">R/W&lt;/td>
&lt;td style="text-align:center">一个线程&lt;/td>
&lt;td style="text-align:center">线程&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">共享&lt;/td>
&lt;td style="text-align:center">片上&lt;/td>
&lt;td style="text-align:center">n/a&lt;/td>
&lt;td style="text-align:center">R/W&lt;/td>
&lt;td style="text-align:center">块内所有线程&lt;/td>
&lt;td style="text-align:center">块&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">全局&lt;/td>
&lt;td style="text-align:center">片外&lt;/td>
&lt;td style="text-align:center">1.0 以上有&lt;/td>
&lt;td style="text-align:center">R/W&lt;/td>
&lt;td style="text-align:center">所有线程+主机&lt;/td>
&lt;td style="text-align:center">主机配置&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">常量&lt;/td>
&lt;td style="text-align:center">片外&lt;/td>
&lt;td style="text-align:center">有&lt;/td>
&lt;td style="text-align:center">R&lt;/td>
&lt;td style="text-align:center">所有线程+主机&lt;/td>
&lt;td style="text-align:center">主机配置&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">纹理&lt;/td>
&lt;td style="text-align:center">片外&lt;/td>
&lt;td style="text-align:center">有&lt;/td>
&lt;td style="text-align:center">R&lt;/td>
&lt;td style="text-align:center">所有线程+主机&lt;/td>
&lt;td style="text-align:center">主机配置&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="9-静态全局内存">9. 静态全局内存&lt;/h3>
&lt;p>CPU 内存有动态分配和静态分配两种类型，从内存位置来说，动态分配在堆上进行，静态分配在站上进行，在代码上的表现是一个需要 new，malloc 等类似的函数动态分配空间，并用 delete 和 free 来释放。在 CUDA 中也有类似的动态静态之分，需要 cudaMalloc 的就是动态分配，静态分配与动态分配相同是，也需要显式的将内存 copy 到设备端。下面代码是一个静态分配的例子：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-cpp" data-lang="cpp">&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#include&lt;/span> &lt;span class="cpf">&amp;lt;cuda_runtime.h&amp;gt;&lt;/span>&lt;span class="cp">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#include&lt;/span> &lt;span class="cpf">&amp;#34;dbg.h&amp;#34;&lt;/span>&lt;span class="cp">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">__device__&lt;/span> &lt;span class="kt">float&lt;/span> &lt;span class="n">devData&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">__global__&lt;/span> &lt;span class="kt">void&lt;/span> &lt;span class="nf">checkGlobalVariable&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">printf&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;Device: the value of devData is %f&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">devData&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">devData&lt;/span> &lt;span class="o">+=&lt;/span> &lt;span class="mf">2.0f&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kt">int&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">int&lt;/span> &lt;span class="n">argc&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="kt">char&lt;/span> &lt;span class="o">**&lt;/span>&lt;span class="n">argv&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="kt">float&lt;/span> &lt;span class="n">value&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">3.14f&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">CHECK&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">cudaMemcpyToSymbol&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">devData&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">value&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="k">sizeof&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">float&lt;/span>&lt;span class="p">)));&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">printf&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;Host: copied %f to the global variable&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">value&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">checkGlobalVariable&lt;/span>&lt;span class="o">&amp;lt;&amp;lt;&amp;lt;&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&amp;gt;&lt;/span>&lt;span class="p">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">CHECK&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">cudaMemcpyFromSymbol&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">value&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">devData&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="k">sizeof&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">float&lt;/span>&lt;span class="p">)));&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">printf&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;Host: the value changed by the kernel to %f&lt;/span>&lt;span class="se">\n&lt;/span>&lt;span class="s">&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">value&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">CHECK&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">cudaDeviceReset&lt;/span>&lt;span class="p">());&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">EXIT_SUCCESS&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>运行结果为：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">Host: copied 3.140000 to the global variable
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Device: the value of devData is 3.140000
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Host: the value changed by the kernel to 5.140000
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>唯一要注意的就是这一句：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-cpp" data-lang="cpp">&lt;span class="line">&lt;span class="cl">&lt;span class="n">cudaMemcpyToSymbol&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">devData&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">value&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="k">sizeof&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">float&lt;/span>&lt;span class="p">));&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>设备上的变量定义和主机变量定义的不同，设备变量在代码中定义的时候其实就是一个指针，这个指针指向何处，主机端是不知道的，指向的内容也不知道，想知道指向的内容，唯一的办法还是通过显式的办法即 cudaMemcpyToSymbol 传输过来。&lt;/p>
&lt;p>此外还需要注意的是：&lt;/p>
&lt;ol>
&lt;li>在主机端，devData 只是一个标识符，不是设备全局内存的变量地址&lt;/li>
&lt;li>在核函数中，devData 就是一个全局内存中的变量。主机代码不能直接访问设备变量，设备也不能访问主机变量，这就是 CUDA 编程与 CPU 多核最大的不同之处&lt;/li>
&lt;/ol>
&lt;p>一方面，是无法使用 cudaMemcpy 来给静态变量赋值的，除非：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-cpp" data-lang="cpp">&lt;span class="line">&lt;span class="cl">&lt;span class="kt">float&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">dptr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">NULL&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">cudaGetSymbolAddress&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="kt">void&lt;/span>&lt;span class="o">**&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">dptr&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">devData&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">cudaMemcpy&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dptr&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">value&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="k">sizeof&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">float&lt;/span>&lt;span class="p">),&lt;/span> &lt;span class="n">cudaMemcpyHostToDevice&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>另一方面，主机端不可以对设备变量进行取地址操作，该操作是非法的。想要得到 devData 的地址可以用下面方法：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-cpp" data-lang="cpp">&lt;span class="line">&lt;span class="cl">&lt;span class="kt">float&lt;/span> &lt;span class="o">*&lt;/span>&lt;span class="n">dptr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">NULL&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">cudaGetSymbolAddress&lt;/span>&lt;span class="p">((&lt;/span>&lt;span class="kt">void&lt;/span>&lt;span class="o">**&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">&amp;amp;&lt;/span>&lt;span class="n">dptr&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">devData&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>当然也有一个例外，可以直接从主机引用 GPU 内存——CUDA 固定内存。&lt;/p>
&lt;p>CUDA 运行时 API 能访问主机和设备变量，但这取决于你给正确的函数是否提供了正确的参数，使用运行时 API ，如果参数填错，尤其是主机和设备上的指针，结果是无法预测的。&lt;/p>
&lt;h2 id="参考资料">参考资料&lt;/h2>
&lt;p>[1] CUDA C 编程权威指南，机械工业出版社，（美）程润伟（John Cheng） 等著&lt;/p></description></item></channel></rss>